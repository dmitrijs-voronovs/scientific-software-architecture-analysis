quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Testability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Simple addition of the `layer` argument which is already included in `sc.tl.score_genes` so that you can use your own layer instead of being restricted to what is stored in `adata.X` . <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3138:506,Test,Tests,506,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138,1,['Test'],['Tests']
Testability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy.; While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat.; After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:; 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs?; 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy?; 3. How to be sure we did not undercluster and miss some smaller cell populations?. I would be glad for any feedback or input, and of course if someone knows the answers, that's great!. Best wishes,; Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1531:255,log,log-norm,255,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531,2,['log'],['log-norm']
Testability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hello Scanpy,; In @LuckyMD 's amazing paper (https://www.embopress.org/doi/full/10.15252/msb.20188746), Table 1 shows that using raw data to calculate the maker genes of clusters is the appropriate way. But the raw data was not regressed out with mitochondrial genes, gene counts, cell cycle scores...So there will be so many mito genes ranked on the top of the marker gene list. What shall we do with these mito genes, because usually they represent the dead cell-released RNA contaminations?. In Seurat, they did every downstream analysis and plotting by using the log-transformed and scaled data (see below, the scaled dots in Seurat violin plot). Scanpy draws all plots by setting use_raw=True. I'm wondering which method is better?; ![image](https://user-images.githubusercontent.com/75048821/149461003-ed8d62d9-8aa9-4b5a-905d-e22bd10a1345.png). BTW, logFC will become negative and disappear for the marker genes of clusters when we set `use_raw=False` in `sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon'`. Please check this https://github.com/theislab/scanpy/issues/2057. Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2110:749,log,log-transformed,749,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110,2,['log'],"['log-transformed', 'logFC']"
Testability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hi ; if samples contribute a different number of cells to my object, how to control for variability among samples? ; How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2155:476,test,test,476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155,1,['test'],['test']
Testability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hi,. I'd like to look at the gene expression from WT and the mutant mice from an interesting cluster, I thought I could use ; sc.tl.rank_genes_groups(WT_Donuts, 'leiden', method='t-test', use_raw=False); sc.pl.rank_genes_groups(WT_Donuts, n_genes=5, sharey=False),. Then I realized that it's only for getting the marker genes from clusters. ; Thank you for helping me with this issue!. -Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1035:363,test,test,363,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035,1,['test'],['test']
Testability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; Hi, ; I am little confused about the parameter in pl.ump, use_raw=False. ; When you set raw=False, it takes normalized, log transformed but not corrected gene expression, while when you set user_raw=True, it takes scaled and corrected gene expression. What does corrected gene expression means here? . From tutorial it reads as below:; ""As we set the .raw attribute of adata, the previous plots showed the “raw” (normalized, logarithmized, but uncorrected) gene expression. You can also plot the scaled and corrected gene expression by explicitly stating that you don’t want to use .raw."". Trying to get some clarification on my results, in case, where i performed DE with t-test, and get top 5 genes, When i want to look them in clusters and plot ump, I do not see them with pl.ump with user_raw=True but can see them with user_raw=False. ; Any clarification will be great. . thanks, ; Preeti ; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1266:297,log,log,297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266,3,"['log', 'test']","['log', 'logarithmized', 'test']"
Testability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated?. I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1908:231,test,tests,231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908,2,['test'],"['testing', 'tests']"
Testability,<details>; <summary> Errors look like: </summary>. ```; FAILED scanpy/tests/test_highly_variable_genes.py::test_runs - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_supports_batch - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_batch_matches_batch - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[numpy_ndarray-single] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[numpy_ndarray-batched] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[scipy_csr-single] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[scipy_csr-batched] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[scipy_csc-single] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[scipy_csc-batched] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[dask_array_dense-single] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[dask_array_dense-batched] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_compare_to_upstream[seurat-hvg] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_pca.py::test_pca_sparse - ValueEr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:70,test,tests,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,8,['test'],['tests']
Testability,"<notifications@github.com> wrote:. > Hi, looks great!; >; > The only duplicated code left is that _prepare_weighted_dataframe is very; > similar to _prepare_dataframe. I think you can delete; > _prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. If this is the case, just step; > away for a while and do something else! But I think you won’t regret doing; > this. You’re learning good coding pra",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:1116,test,test,1116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578,1,['test'],['test']
Testability,"= X[:, None]; 141 if X.shape[1] > 1:; 142 colors = palette[: X.shape[1]].by_key()[""color""]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1153, in Series.__getitem__(self, key); 1150 key = np.asarray(key, dtype=bool); 1151 return self._get_rows_with_mask(key); -> 1153 return self._get_with(key). File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1163, in Series._get_with(self, key); 1158 raise TypeError(; 1159 ""Indexing a Series with DataFrame is not ""; 1160 ""supported, use the appropriate DataFrame column""; 1161 ); 1162 elif isinstance(key, tuple):; -> 1163 return self._get_values_tuple(key); 1165 elif not is_list_like(key):; 1166 # e.g. scalars that aren't recognized by lib.is_scalar, GH#32684; 1167 return self.loc[key]. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\series.py:1203, in Series._get_values_tuple(self, key); 1198 if com.any_none(*key):; 1199 # mpl compat if we look up e.g. ser[:, np.newaxis];; 1200 # see tests.series.timeseries.test_mpl_compat_hack; 1201 # the asarray is needed to avoid returning a 2D DatetimeArray; 1202 result = np.asarray(self._values[key]); -> 1203 disallow_ndim_indexing(result); 1204 return result; 1206 if not isinstance(self.index, MultiIndex):. File ~\AppData\Roaming\Python\Python311\site-packages\pandas\core\indexers\utils.py:341, in disallow_ndim_indexing(result); 333 """"""; 334 Helper function to disallow multi-dimensional indexing on 1D Series/Index.; 335 ; (...); 338 in GH#30588.; 339 """"""; 340 if np.ndim(result) > 1:; --> 341 raise ValueError(; 342 ""Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer ""; 343 ""supported. Convert to a numpy array before indexing instead.""; 344 ). ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.; ```. ### Versions. <details>. ```-----; anndata 0.10.5.post1; scanpy 1.10.1; -----; PIL 9.4.0; annoy NA; anyio NA; asttokens NA; attr ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3086:5378,test,tests,5378,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086,1,['test'],['tests']
Testability,=) | `74.94% <100.00%> (ø)` | |; | [scanpy/datasets/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2Fdatasets%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL191dGlscy5weQ==) | `100.00% <100.00%> (ø)` | |; | [scanpy/external/pp/\_magic.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2Fexternal%2Fpp%2F_magic.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3BwL19tYWdpYy5weQ==) | `86.11% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3V0aWxzLnB5) | `97.36% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/fixtures/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2Ftesting%2F_pytest%2Ffixtures%2Fdata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9kYXRhLnB5) | `100.00% <ø> (ø)` | |; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2Ftesting%2F_pytest%2Fmarks.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `100.00% <100.00%> (ø)` | |; | [scanpy/tools/\_ingest.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2Ftools%2F_ingest.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19pbmdlc3QucHk=) | `77.23% <100.00%> (ø)` | |; | [scanpy/tools/\_louvain.py,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3050#issuecomment-2104675113:2679,test,testing,2679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3050#issuecomment-2104675113,1,['test'],['testing']
Testability,"=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds); 671 tl.dendrogram; 672 """"""; --> 673 return _rank_genes_groups_plot(; 674 adata,; 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 590 from .._anndata import heatmap; 591 ; --> 592 return heatmap(; 593 adata,; 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds); 1085 ; 1086 if dendrogram:; -> 1087 dendro_data = _reorder_categories_after_dendrogram(; 1088 adata,; 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories); 2132 """"""; 2133 ; -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby); 2135 ; 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby); 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently.""; 2235 ); -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key); 2237 ; 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2357:1966,log,log,1966,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357,1,['log'],['log']
Testability,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)); Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)); Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat); extracting highly variable genes; Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>; sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes; flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut; duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts; f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,; nan, nan, nan, nan, nan, nan, nan, nan]).; You can drop duplicate edges by setting the 'duplicates' kwarg; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1175:3133,log,logging,3133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175,1,['log'],['logging']
Testability,==================; Files 110 111 +1 ; Lines 12100 12133 +33 ; ==========================================; + Hits 8818 8848 +30 ; - Misses 3282 3285 +3 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/experimental/pp/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9wcC9faGlnaGx5X3ZhcmlhYmxlX2dlbmVzLnB5) | `63.69% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3V0aWxzLnB5) | `45.16% <100.00%> (+1.82%)` | :arrow_up: |; | [scanpy/testing/\_pytest/fixtures/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9fX2luaXRfXy5weQ==) | `94.11% <ø> (-2.44%)` | :arrow_down: |; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `92.77% <100.00%> (-0.03%)` | :arrow_down: |; | [scanpy/testing/\_pytest/params.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9wYXJhbXMucHk=) | `94.73% <94.73%> (ø)` | |; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2696#issuecomment-1766017585:1896,test,testing,1896,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2696#issuecomment-1766017585,1,['test'],['testing']
Testability,"===========================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); normalizing by total count per cell; filtered out 1 ce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2526:2811,Assert,AssertionError,2811,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526,1,['Assert'],['AssertionError']
Testability,"===================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that have less than 1 counts; finished (0:00:00): nor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2526:2717,assert,assert,2717,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526,1,['assert'],['assert']
Testability,"=======================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2526:2133,test,tests,2133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526,1,['test'],['tests']
Testability,"===================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2526:2681,assert,assert,2681,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526,1,['assert'],['assert']
Testability,"=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:6352,assert,assert,6352,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['assert'],['assert']
Testability,"> ## Question; > ; > Does this interact with group colors and dendrograms at all?. Dendrogram and colors seem not affected. > ## Test change; > ; > All of the plots will start failing because this will change the output for every test. I have a few concerns here:; > ; > * I'm worried about repo bloat from the plotting tests. Ideally we could just store the reference images outside of git (git lfs maybe?). Updating all the plots with `tight_layout` would increase repo size by 10%; > ; > * Is `tight_layout` deterministic ([matplotlib/matplotlib#11809 (comment)](https://github.com/matplotlib/matplotlib/issues/11809#issuecomment-432726600))? Also, is matplotlib trying to replace it with [`constrained_layout`](https://matplotlib.org/stable/tutorials/intermediate/constrainedlayout_guide.html)?; > ; > * Does globally adding `tight_layout` add to test times? My impression was that it basically rendered the plot, fixed the borders, then rendered it again.; > ; > ; > Proposed solution:; > ; > Can we just explicitly extend the borders for this test? At a later point we can move plots to a different storage system, then have much more freedom in making changes to how they render. Sounds great, I think I managed to do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1735#issuecomment-796812772:129,Test,Test,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1735#issuecomment-796812772,5,"['Test', 'test']","['Test', 'test', 'tests']"
Testability,"> 'outline' could be good. We already have font outline that works similarly. Great!. > Can you take a look at the new type hints that I added. I am not sure if I did it right?. The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient.; - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return.; - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`; - `Sequence`→`Sequence[?]`; - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py; def _get_vmin_vmax(; […]; color_vector: Sequence[float],; ):; '''; […]; ```. ```py; logg.error(; ""The parameter […]""; […]; ""of plots.""; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/794#issuecomment-523541089:1229,log,logg,1229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794#issuecomment-523541089,1,['log'],['logg']
Testability,"> * Make a case where a threshold can't be found (not sure how this would be done). Obviously I can test the plotting by directly unsetting the relevant things, but I'm not actually sure how to trigger a failure with the test data I'm afraid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2023#issuecomment-963035287:100,test,test,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2023#issuecomment-963035287,2,['test'],['test']
Testability,> * Not all methods have log fold changes (`'logreg'` for example). This will hopefully be fixed: https://github.com/theislab/scanpy/pull/1081#discussion_r393315428,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1152#issuecomment-610639662:25,log,log,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152#issuecomment-610639662,2,['log'],"['log', 'logreg']"
Testability,"> * Shouldn't `var_df` should get similar updates to `obs_df`?. I would suggest a different PR to address this. . > * Could we get tests for `get.obs_df`/ `get.var_df` for the issues you addressed here (repeated indices)?. Sure, I added new tests to `get.obs_df` to check duplicated keys.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-765255875:131,test,tests,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-765255875,2,['test'],['tests']
Testability,"> 2 sc.pl.rank_genes_groups_dotplot(adata, values_to_plot=possible_vals.pop()); 3 . ~/github/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/github/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 940 del kwds['color_map']; 941 ; --> 942 dp = DotPlot(; 943 adata,; 944 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds); 215 # get the same order for rows and columns in the dot_color_df; 216 # using the order from the doc_size_df; --> 217 dot_color_df = dot_color_df.loc[dot_size_df.index][dot_size_df.columns]; 218 ; 219 self.dot_color_df = dot_color_df. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key); 929 ; 930 maybe_callable = com.apply_if_callable(key, self.obj); --> 931 return s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:1816,log,log,1816,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911,1,['log'],['log']
Testability,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:411,test,test,411,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872,1,['test'],['test']
Testability,"> > I'm actually testing and tweaking someone else's code that was written a while ago. I assume they used; > > `import scanpy.api as sc` because it was appropriate then. I personally resolved my issue by downgrading versions, I just wanted to bring this up!; > ; > I encountered the same issue. Which version are you using to fix this?. nm, downgrading to 1.5.1 fixed my problem. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-684933191:17,test,testing,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-684933191,1,['test'],['testing']
Testability,"> > In the other word, the scvelo's 'scv.pl.velocity_embedding_stream' showing terminal differentiation cells develop to original cells. this was incorrected logically. why the scvelo showed the inverted result contrast with monocle result.; > ; > As @LuckyMD said, this is a question for `scvelo`.; > ; > > I guess what i make the cell order was wrong ?; > ; > The best way to check if ordering went wrong is to plot an embedding colored by some known grouping. If colors are all mixed up you know a mistake has done.; > ; > > i wonder whether the code just sorted the cell barcode on annData.obs but the annData.X's matrix? why was the order runing so quickly that the matrix of annData not be sorted at the same time?; > ; > Luckily `AnnData` is quite robust and it reorder any slot (`obs`, `obsp`, `obsm`…) according to the specified cell names.; > ; > d; Thanks i would check currently, and reported the result as soon as possible. ; Best,; hanhuihong",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1718#issuecomment-802436872:158,log,logically,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718#issuecomment-802436872,1,['log'],['logically']
Testability,"> > ooh, this time the benchmark shows really nicely how much faster it is!; > ; > Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. @flying-sheep , can you look at the this benchmark test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110#issuecomment-2181072184:23,benchmark,benchmark,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110#issuecomment-2181072184,3,"['benchmark', 'test']","['benchmark', 'test']"
Testability,"> > what about `X_coords` ?; > ; > Ha, I was mostly just trying to get rid of the `X_`! . ah right, anyway good for me!; > ; > > What about re-open the theislab/spatial branch and merge this PR there? I could then work on how to handle the new uns structure in the plotting functions and have a definitive version of multiple slices support in anndata.; > ; > I'd like to merge the changes currently in this PR to master since it fixes a bug with dataset reading. The changes to uns structure could go in another PR, but I'm waiting for an email back from 10x to make sure using the `library_id` as a key makes sense. Either way, the logic of getting the transformed coordinates etc. should be abstracted into a function so it's easy to change.; > . What do you mean by transformed coordinates? Also, to understand the inputs for anndata (output of spaceranger) you might have a look at this, if you are not already familiar with https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview. ; Also, ok for having `uns` changes in another PR, I can work on that as soon as this is merged.; > Update: heard back, the `library_id` should be fine, at least for this version.; > . good !. > > support for multiple slices should be first; > ; > I'm not sure I'm convinced of this. I've also already got some code ready to go for the connectivities and some examples of what can be done with it.; > ; > I'd like to hear what kind of stuff you want to be able to do with multiple slices. Are you interested in stitching together slides or holding arbitrary slides in an AnnData? I think I'd like to see a more fleshed out idea of what kinds of analysis could be done here before deciding on what kind of an API this should have, and cases we should be ready to handle.; > . support for multiple slices and concatenation of anndata objects is by far the priority to me. It's a really useful functionality since:; * most people don't work with one slide; * having the same ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1088#issuecomment-596965855:634,log,logic,634,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088#issuecomment-596965855,1,['log'],['logic']
Testability,"> @THZ34 can you create a reproducer where this happens, so I can add a test?. OK, I've upload the h5ad file to onedrive: https://bioplot-my.sharepoint.com/:u:/g/personal/tanghongzhen_bioplot_onmicrosoft_com/EUbNHPuin5pGuMPrmch6rsQBjHojfikr38EYgZEL4KAZ2A?e=T2YfkO.; The error will reapper in these code:; import anndata; import scanpy as sc; adata = ad.read_h5ad('debug.h5ad'); sc.tl.dendrogram(adata,groupby='leiden')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2804#issuecomment-2014432043:72,test,test,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2804#issuecomment-2014432043,1,['test'],['test']
Testability,> @Zethson do we really need a test here?. Yes!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2460#issuecomment-1493979120:31,test,test,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1493979120,1,['test'],['test']
Testability,"> @awnimo , for me test_phenograph.py fails with `E TypeError: Expected list, got numpy.ndarray`.; > Could you check please?; > This is certainly related to scipy 1.5. With scipy 1.4 the test works fine. Indeed, this error is related to scipy, and we have fixed that in Phenograph new release [1.5.7](https://github.com/dpeerlab/PhenoGraph#version-157). The `test_phenograph.py` does not fail with the new Phenograph release (`pip install -U phenograph`)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1080#issuecomment-703773746:187,test,test,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080#issuecomment-703773746,1,['test'],['test']
Testability,> @awnimo can you please test this? Does the plot look like you want it to?. @flying-sheep The plots look the same as expected. Compared plots using methods from Scanpy and Harmony,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1004#issuecomment-577771644:25,test,test,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1004#issuecomment-577771644,1,['test'],['test']
Testability,"> @eroell, what do you think?. See Phil's comment above, one more thing would be to add a test I suppose. If you want to try Phil's comments yourself @farhadmd7 please go ahead, else you can write here for more help as Phil mentioned!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3180#issuecomment-2263237897:90,test,test,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180#issuecomment-2263237897,1,['test'],['test']
Testability,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?. Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python; sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False); ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/512#issuecomment-469760800:17,Test,Tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469760800,1,['Test'],['Tests']
Testability,"> @gokceneraslan here's a quick example:. Oh man, just noticed a horrible bug which leads to zero HVGs if batch_key is given but n_top_genes is not 😓 Somehow, highly_variable_genes with batch_key but without n_top_genes (which is the option I always use :) ) is never tested :/ Fixing now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-617446080:268,test,tested,268,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-617446080,1,['test'],['tested']
Testability,"> @pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:; > You'll need to add a scrublet entry to `extras_require` here:. Ahh, I see- thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-734715153:20,test,tests,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-734715153,2,"['log', 'test']","['logs', 'tests']"
Testability,"> @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]). Hi @Zethson ,; I tried running the modified testcase mentioned above , but it seems it is failing because sparse matrix is being passed in it as a parameter. As of now, our scale function is not implemented for the sparse matrices. It is expected that these tests will fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1566771839:109,test,testcase,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1566771839,2,['test'],"['testcase', 'tests']"
Testability,"> About the commit process: That's far far too much work to do it like you suggested. I don't have the time for this. As a general point about this PR: to me, the fair amount of the work of turning on flake8 deciding on the rules. Perhaps we should start with a subset of files then? I realize you did not come to the meeting where we talked about this, so perhaps there is a difference of expectations here, but we agreed to be conservative about the rules we turned on in `pre-commit`. Going through everything to make sure changes are correctly reverted is also takes a lot of time for me as the reviewer. I'd also like to limit that. ----------------. You said you used some automated tools to get faster compliance. What were these? In general, I would prefer to have a formatter that automatically ran than a tool that told me I formatted something wrong. -----------------. > `@ivirshup` I would keep the noqas. They are very easily searchable across the whole project and can be fixed later. I'm pretty strongly against this. `noqa`s just look like the formatter/ linter was wrong, and I'm not accepting that having no plan to address bugs. I think this should be a discussion with a broader set of the team. > ""Whats up with removing leading #s from comments?"" Not my choice either. What we have now is pep8 and flake8 compliant. If you're not happy with this we can ignore the rule. Yes, lets ignore this. >> ""I don't like replacing x == False with not x in all cases. Sometimes a variable could be a container, and an error should be thrown. I think cases have to be evaluated for this.""; >; > This should be covered by tests. In any case it is not good style and a violation. I will try and take a closer look at these changes. I'm particularly concerned that there will be cases where possible values are `None`, `True`, and `False`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-785871670:1631,test,tests,1631,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-785871670,1,['test'],['tests']
Testability,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1213#issuecomment-696776848:63,log,logic,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213#issuecomment-696776848,2,['log'],['logic']
Testability,"> Ah I think I see the issue! Feature branches should be based off `master` and directing the pull request there! I think what's happening is that a pre-commit hook was installed, but the config only exists on the `master` branch.; > ; > I think this should largely be manageable by rebasing onto master (e.g. `git rebase --onto master 1.7.x`) and changing the branch the PR is targeting via the github interface:. Thanks a lot, I rebased and changed the PR target to `master` so I hope everything is on track now! ; The pre-commit style checks were working as expected now (auto-edits only in the files / parts I edited). > Side note: We're considering separating the highly_variable_genes interface into multiple functions, since the arguments to the different methods don't always overlap in meaningful or intuitive ways. There's nothing you need to do about this right now, but just a heads up to keep the logic for this method separate from the main function. Sounds good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-795469189:910,log,logic,910,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-795469189,1,['log'],['logic']
Testability,"> All tests in test_highly_variable_genes.py pass, but others like test_plotting.py::test_violin fail. I'm not sure why -- anyone have an idea?. They also fail for me for an unrelated change that does not even change code.; @ivirshup got any idea?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1985#issuecomment-907001063:6,test,tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985#issuecomment-907001063,1,['test'],['tests']
Testability,"> Also I don't think it returns a copy, so you would need to handle that. I've got a branch which implements cached datasets for testing as:. we could overcome this by simply updating anndata in the test then. > @cache is new in 3.8, but the implementation is:. what do you suggest to do? use your implementation or implement this wrapper?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1053622705:129,test,testing,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1053622705,2,['test'],"['test', 'testing']"
Testability,"> Also isn’t it cool that it points exactly to the problematic line?. Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1492#issuecomment-725996519:382,test,testing,382,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492#issuecomment-725996519,2,"['assert', 'test']","['assert', 'testing']"
Testability,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?); > ; > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-733750462:58,test,test,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-733750462,1,['test'],['test']
Testability,"> Although it states so:. UMAP only uses the representation of a data matrix for determining the number of connected components of the graph for the init conditions [if these aren't explicitly defined (they are if choosing `init_pos='paga'`): https://github.com/lmcinnes/umap/blob/948f60ff0caf7ccef0ab68626c7b99a11e66f1bb/umap/umap_.py#L958-L965. In fact, the only place where it enters is for the computation of the mean positions of the disconnected components: https://github.com/lmcinnes/umap/blob/948f60ff0caf7ccef0ab68626c7b99a11e66f1bb/umap/spectral.py#L50. Implementation-wise, it's a bit unfortunate that the data matrix is carried through all these functions just for that reason... But it's not a problem for the results. The confusing logging is fixed via; https://github.com/theislab/scanpy/commit/a5bd1ecd8ab04ec79369f60d3656f578a4cde40c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666#issuecomment-497630093:747,log,logging,747,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-497630093,1,['log'],['logging']
Testability,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:266,log,logging,266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804,2,"['log', 'test']","['logging', 'test']"
Testability,"> Are we documenting here which of these have counts vs log vs normalized?. yeah, I’d like to do that! It’s really not bad. ```console; ❯ hatch test --internet-tests scanpy/tests/test_datasets.py::test_doc_shape scanpy/datasets/; [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent; ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮; │ # │ path │ physical │; ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤; │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │; ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent; ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮; │ # │ path │ physical │; ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤; │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │; │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │; │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │; │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │; │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │; │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │; │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │; │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │; ╰───┴──────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3060#issuecomment-2117262252:56,log,log,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060#issuecomment-2117262252,4,"['log', 'test']","['log', 'test', 'tests']"
Testability,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > ; > Also: If trying to call a t-test with non-logarithmized data, a warning should be written.; > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?. Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-478377325:214,test,test,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-478377325,4,"['log', 'test']","['log', 'logarithmized', 'test']"
Testability,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial?. no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python; img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]; scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][; ""tissue_hires_scalef""; ]; sc.pl.spatial(; adata,; color=""leiden"",; scale_factor=scalef,; img=img,; size=100,; basis=""spatial"",; groups=[""0""],; ); ```; ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-750338610:1433,test,tests,1433,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-750338610,1,['test'],['tests']
Testability,"> Can we keep the docs on what exactly is happening + how to troubleshoot somewhere in this doc? This means things like: How to tag + build locally, twine check, list contents of distributed file etc. Sure, as we agreed on in person, I’ll just add a section to the end of the document.; If the build process or package structure aren’t touched, doing things manually isn’t necessary. > We should also automate some checks to avoid broken releases. As we agreed in person: Let’s postpone this. E.g. don't allow this except on specific branches + probably turn on merge queue so we know only commits that pass tests + doc builds get to those branches. This PR automatically does `twine check`, which is enough improvement over “trust the person doing the release to do that” to be worth the change, even if it wasn’t for the added convenience!. /edit: all addressed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678:608,test,tests,608,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678,1,['test'],['tests']
Testability,"> Can you point to a package whose test organization you would like our tests to emulate?. - pytest: https://github.com/pytest-dev/pytest/tree/main/testing; - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:35,test,test,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986,8,['test'],"['test', 'testing', 'tests']"
Testability,> Could you add a test to make sure the correct values are being used?. What did you have in mind? A minimum value (e.g. 20?) for the max to check that unlogged values are input?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2025#issuecomment-963032563:18,test,test,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2025#issuecomment-963032563,1,['test'],['test']
Testability,"> Do you know why the test is failing?. @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that?. I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/797#issuecomment-536861482:22,test,test,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797#issuecomment-536861482,2,['test'],['test']
Testability,"> Do you think you could make a PR with this to sklearn? I'd like to see the response it gets, and judge based on that. My preference would be for this to go there, but I'm very open to having this in our codebase until it's in a `sklearn` release. I'll try and do that soon. For now, I'll focus on providing you with the benchmarks you requested!. > * Datasets size (one small, one large (>50k cells)); > * Implicit centering, densifying centering, no centering; > * single threaded, multi-threaded <---------. I could not find a `n_jobs` argument in `scanpy.pp.pca`. Can you elaborate a little on the single threaded, multi-threaded bit?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589512273:322,benchmark,benchmarks,322,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-589512273,1,['benchmark'],['benchmarks']
Testability,> Failing test looks similar to what happens when I run out of memory locally. I’ve mostly seen these “illegal instruction” errors in a case where something is run on the wrong CPU architecture (e.g. compiled for a newer architecture than supported on that specific runner),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1905756533:10,test,test,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1905756533,1,['test'],['test']
Testability,"> First, thanks for adding more tests!. Sure thing. Thanks for all the great feedback!. > 1. Is the file `scanpy/tests/_images/scatter_filtered_genes_raw.png` meant to be here?. No, thanks for catching that. > 2. Could the tests be broken up by what they are asserting? I would prefer to break up what is being tested by test case ; rather than values of parameters. Yes, I've broken both of the tests down into multiple tests. > 3. Could we cut down on the number of reference images generated since those cause manual maintenance burden on some matplotlib updates. These reference based tests are not great for confirming the correct plot is output, only that their output is consistent across commits.; > I think some of these cases could instead be tested with `check_same_image`, e.g. where it doesn't matter whether raw is `True` or `None`. Also testing for checking cases where `use_raw=True` would be equivalent to passing `pbmc.raw.to_adata()`. I've cut the number of reference images down to two. I couldn't figure out a clever way to use `check_same_image()` instead of `save_and_compare_images()` for these as you did for the others. See below for comments about individual suggestions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-966240677:32,test,tests,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-966240677,11,"['assert', 'test']","['asserting', 'test', 'tested', 'testing', 'tests']"
Testability,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE?. ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py; if use_fast_tsne is not None:; warnings.warn(""..."", FutureWarning); match (use_fast_tsne, flavor):; case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'; case (None, _): ... # use specified flavor; case (True, 'auto'): ... # use 'multicore'; case (True, 'sklearn'): ... # throw error; case (True, _): ... # use specified flavor; case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'; case (False, _): ... # Throw error; case _: ... raise AssertionError(); ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668:445,log,logic,445,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668,2,"['Assert', 'log']","['AssertionError', 'logic']"
Testability,"> From my error log it seems the only non-noarch dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py). That’s surprising! I think numba is our most complex dependency, and umap’s dependency PyNNDescent is also compiled. I think if this isn’t a mistake and it’s really just about h5py, we can think about it. Trying to install scanpy and following JupyterLite’s debug instructions gives:. ![image](https://github.com/scverse/scanpy/assets/291575/07a30013-e78d-46af-80fd-fb48af71d45b). ```pytb; ValueError: Can't find a pure Python 3 wheel for: 'umap-learn>=0.3.10', 'session-info', 'numba>=0.41.0'; See: https://pyodide.org/en/stable/usage/faq.html#why-can-t-micropip-find-a-pure-python-wheel-for-a-package; ```. (session-info isn’t a problem, it’s just an old package that doesn’t publish wheels)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731:16,log,log,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731,1,['log'],['log']
Testability,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?. Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-727864463:30,test,test,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-727864463,3,['test'],"['test', 'tests']"
Testability,"> Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with; > ; > ```; > pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; > ```; > ; > Seems to work now for me. Thank you. It just worked for me, in July 2024.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559:211,test,test,211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559,1,['test'],['test']
Testability,"> Hello @LuckyMD Thanks for the response! Could you please also check why the logFC becomes negative and disappear for the marker genes of clusters? #2057 Thanks! Best, YJ. Because adata was regressed, gene expression will become negative, cannot be loged.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2110#issuecomment-1103470609:78,log,logFC,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110#issuecomment-1103470609,2,['log'],"['logFC', 'loged']"
Testability,"> Hello, For information: if I understood correctly, there could be a risk on the current version of `score_genes_cell_cycle` method when the `adata.raw` is present:; > ; > * `score_genes_cell_cycle` is based on `score_genes` method which seems to use `adata.raw` to estimate gene score when it is present by default. As far as I know, people often store log-transformed counts to `adata.raw` (an example could be found [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html)).; > * However, according to [here](https://nbviewer.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb), ""Log-transformation of data and scaling should always be performed before scoring.""; > ; > In this situation, when people use `adata.raw` to store logged values, and apply `score_genes_cell_cycle` method to the object without explicitly setting `use_raw = False`, the results could be problematic, unless there is some specific processing overwritting `score_genes`' initial behaviour that I was not aware of. Hi @LuckyMD , I also have a few uncertainties regarding the `score_genes` function in scanpy. Although the documentation states that it behaves similarly to seurat, I came across some references ([here](https://github.com/satijalab/seurat/blob/763259d05991d40721dee99c9919ec6d4491d15e/R/utilities.R#L273) and [here](https://github.com/mojaveazure/seurat-object/blob/3c9e3df0b44a7f6e31e8e0af5d04d398b2b1f004/R/assay.R#L1040)) that suggest seurat operates on the slot of data corresponding to the value after logNormalize. I would appreciate it if you could help me understand why scanpy suggests operating on the matrix after scale instead. Please forgive me if I missed something obvious.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599#issuecomment-1466032257:355,log,log-transformed,355,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599#issuecomment-1466032257,4,"['Log', 'log']","['Log-transformation', 'log-transformed', 'logNormalize', 'logged']"
Testability,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion!; > ; > To me, this looks pretty close to ready. Just a few things to address:; > ; > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this.; > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns?; > * Any thoughts on solutions for the name collision?; > ; > Thanks!. Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1; Please let me know if there is anything else needed to merge.; Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/503#issuecomment-562279386:209,test,test,209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503#issuecomment-562279386,2,['test'],['test']
Testability,"> Hey @ywen1407!; > ; > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though.; > ; > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1431#issuecomment-699114229:1130,test,tested,1130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431#issuecomment-699114229,1,['test'],['tested']
Testability,"> Hi @sygongcode,; > ; > Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy). Yes, that is what I want to do. Thank you so much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/821#issuecomment-529218989:70,test,testing,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821#issuecomment-529218989,1,['test'],['testing']
Testability,"> Hi, It's not available in scanpy at the moment, but I wrote a wrapper for it via `rpy2` and `anndata2ri` which is available here:; > https://github.com/normjam/benchmark/blob/master/normbench/methods/ad2seurat.py. Hi,. I have been trying to use this wrapper, but seems like there's some error during the conversion process:. RRuntimeError: Error in validObject(.Object) : ; invalid class “dgCMatrix” object: 1: invalid object for slot ""i"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""integer""; invalid class “dgCMatrix” object: 2: invalid object for slot ""p"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""integer""; invalid class “dgCMatrix” object: 3: invalid object for slot ""Dim"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""integer""; invalid class “dgCMatrix” object: 4: invalid object for slot ""x"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""numeric"". Any pointers to get around this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-866121061:162,benchmark,benchmark,162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-866121061,1,['benchmark'],['benchmark']
Testability,"> Hi, for `method='wilcoxon'` this is [Wilcoxon rank-sum test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test), and the scores are U_1 from methods in in the link. Higher absolute value of score -> lower p-value (more evidence the levels of expression between groups are different), higher score indicates higher expression, lower score -> lower expression. Thank you very much !!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1688#issuecomment-785029681:57,test,test,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1688#issuecomment-785029681,1,['test'],['test']
Testability,"> How do we xfail stuff from dev?. [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py; xfail_if_dev_tests = pytest.mark.xfail(; os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",; reason=""..."",; ). @xfail_if_dev_tests; def test_xzy(): ...; ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2114691148:357,test,tests,357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2114691148,2,['test'],"['test', 'tests']"
Testability,"> Huh. This is really weird, since it looks like it's almost entirely due to scipy sparse indexing. Must have something to do with versions. Two things:; > ; > * If you upgrade scipy, do you still run into this error?; > * Could you get the version info from an environment where you've only imported scanpy and run this command?. I will try to update scipy. Here is the output from only import scanpy:; BTW, everything works fine until I updated scanpy to 1.7.0. ```; anndata 0.7.4; scanpy 1.7.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; backcall 0.2.0; cairo 1.19.1; cffi 1.14.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; future_fstrings NA; get_version 2.1; h5py 2.10.0; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.7.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; storemagic NA; tables 3.6.1; texttable 1.6.2; tornado 6.0.4; traitlets 4.3.3; wcwidth 0.2.5; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-02-21 23:42; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1670#issuecomment-783075376:1596,log,logical,1596,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670#issuecomment-783075376,1,['log'],['logical']
Testability,"> I doubt that it would be considered a branch of logic. What do you define as logic here? I was talking about the logic theory that encompasses formal systems and so on. > [Union and intersection are bad names]. I agree, wikipedia enumerates more names, and explains where “union” comes from:. > tagged union, variant, variant record, choice type, discriminated union, disjoint union, or sum type; > …; > Mathematically, tagged unions correspond to disjoint or discriminated unions, usually written using +. Given an element of a disjoint union A + B, it is possible to determine whether it came from A or B. If an element lies in both, there will be two effectively distinct copies of the value in A + B, one from A and one from B. . I think “discriminated union/intersection of types” would make sense here. leaving out the “discriminated/tagged/disjoint” here is the problem. in C there’s actual *untagged* unions, which simply means that C reserves the memory for the largest of the intersected types and you need to keep track yourself of which the type of the value is. In python you can always do `isinstance`, so a more correct name for `Union[A, B]` would be `TaggedUnion[A, B]`. I’d also like `OneOf[A, B]`, but that ship has sailed. And intersections are basically duck types or structural types (when anonymous) and traits/interfaces (when named). (i.e. `hasattr(obj, 'foo')` defines an intersection type of all types having that attribute. So it makes sense for python, it’s just defined more explicitly than by literally intersecting types.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-443178140:50,log,logic,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-443178140,3,['log'],['logic']
Testability,"> I had also thought isort could be a good starting place, but it might actually be some work to turn on due to ""partially initialized module"" errors (imperative programming strikes again!). Yeah, I ran into this stuff when creating the flake8 PR (#1689). isort is dangerous with Scanpy and requires good testing and many exceptions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-785092164:305,test,testing,305,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-785092164,1,['test'],['testing']
Testability,"> I haven't worked much with h5py or tables, is it time-consuming to refactor these functions? It seems like moving to anndata is the most straightforward solution at least logically to me. In this case, I think it should be fine. It might not happen too soon if we're left to our own devices, so a PR is welcome. > I could just see a standalone package being widely used and community driven. What formats that aren't in `anndata` would you see in this package? I'm trying to get an idea of the kind of scope you're thinking of here. I think there are formats where there isn't one obvious ""right way"" to represent them as an AnnData object (e.g. visium), so having a canonical reading/ writing function is difficult.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1387#issuecomment-683586582:173,log,logically,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387#issuecomment-683586582,1,['log'],['logically']
Testability,"> I know all that. :wink:. And I know that you know! I just like to be comprehensive when presenting my arguments!. > But numpy, pandas, scikit learn, tensorflow, seaborn all have the comma-separated list as a convention and I'd really like to stick to that convention. OK. I’d prefer “a, b, or c”, but I’ll concede. It would also be no problem to change it later since all will be automated :+1: . > No, the optional keyword always means that a parameter has a default. Very often, people forget to append ""or None"" (, None) to the list of possible types. Well, when I open scanpy in PyCharm and someone forgot that in a type annotation, it highlights that fact to me. Pretty nice. > As mentioned before, there is no point in using set-theoretic/logical notions like union or intersection as the topic is so simple that it doesn't need it (no need for an intersection, it's not even clear what that would mean; if you're stringent about it, it's also not clear for union). Oh, then you didn’t hear of type theory. It’s a branch of logic: Type systems are formal systems, and in most of them the terms I used are well defined. The kinds of composite types I mentioned are:. - `Union` of types / Sum Type / [Tagged Union](https://en.wikipedia.org/wiki/Tagged_union): Variables with one of those have one of several fixed types.; - Subtype / [Intersection Type](https://en.wikipedia.org/wiki/Type_system#Intersection_types): Variables have all the properties of the supertypes.; - `Tuple` / [Product Type](https://en.wikipedia.org/wiki/Product_type): Variables contain multiple entries that each have one corresponding type.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-442007106:747,log,logical,747,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-442007106,2,['log'],"['logic', 'logical']"
Testability,"> I saw some of the github automated tests test are failing now, but I don't really understand the error messages tbh ;) Are they even related to the execution of the code provided by this PR?. yeah also don't understand them, it might be @cache in py 3.7 has issues? will investigate next week and report back!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1050003610:37,test,tests,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1050003610,2,['test'],"['test', 'tests']"
Testability,"> I see them more as TODOs for later since the ""bad code"" is in master at the moment anyways. But if you want to discuss that - sure. I think it's hard to tell the difference between a `noqa` that was added because: ""most of the time, this rule is right, this time it is wrong"" vs. ""added to get rid of warning"". Could any `noqa`s added in this PR get something searchable added to them (like `# noqa: {rule} TODO: fix me`) so we know why it was added?. In a future meeting we can discuss with the whole team how we will actually fix these. I think it's a good task for a hackathon/ sprint. ------------. Looking at this again, I think this is pretty close to done. Just a few documentation/ minor rule changes left. - [x] Document how to turn off these checks in dev docs; - [x] Document the rules that are turned off (similar to [pandas](https://github.com/pandas-dev/pandas/blob/879cd22dd58b0574cdcaa7a26e396d5ec71a615a/setup.cfg#L71-L79)); - [x] Add autopep8 to precommit. If things can be fixed automatically, they should be. autopep8 should be able to get it's rules from the flake8 config.; - [x] Add annotation to `noqa`s.; - [x] Also add `TODO` annotation to `except Exception`s that have been added.; - [x] Turn off E731; - [x] Turn off the rule that doesn't allow multiple leading `#` in comments; - [x] Turn off F811 for tests (rule violated by using fixture as test argument); - Possible solution: add noqa for this to all files under `tests`, separate check that all files under tests have this.; - [x] Ignore `build` `docs/_build` directories",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-787412099:1333,test,tests,1333,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-787412099,4,['test'],"['test', 'tests']"
Testability,"> I suppose to do this properly one ought to scan the code base for uses of igraph, check which among them require the RNG and then add the seeding to those modules?. This would be nice, but would also be a lot of work. I was thinking a PR would just make the layouts for PAGA reproducible, and add a test making sure this is the case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1859#issuecomment-866576277:301,test,test,301,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859#issuecomment-866576277,1,['test'],['test']
Testability,"> I think that literally nobody is using this function for arrays and sparse matrices. I'm not sure about that. I got the impression from https://github.com/theislab/scanpy/issues/1030#issuecomment-607952458 and (IIRC) a conversation with @scottgigante that people would like these functions to work on arrays as well as AnnData objects. > In the very early days of Scanpy, I thought it'd be nice to also accept other formats of data matrices. I still think it would be nice to support that, it just requires factoring the code better. I agree recursively calling the same function for argument handling gets very confusing. However, I think we could do something more like this (note, it's not tested yet, and could be cleaner... it's my ten minute version):. <details>; <summary> Alternative implementation of scale </summary>. ```python; @singledispatch; def scale(X, *args, **kwargs):; """"""\; Scale data to unit variance and zero mean.; .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and set to 0 during this operation. In; the future, they might be set to NaNs.; Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; If an :class:`~anndata.AnnData` is passed,; determines whether a copy is returned.; Returns; -------; Depending on `copy` returns or updates `adata` with a scaled `adata.X`,; annotated with `'mean'` and `'std'` in `adata.var`.; """"""; return scale_array(X, *args, **kwargs). @scale.register(np.ndarray); def scale_array(; X,; zero_center: bool = True,; max_value: Optional[float] = None,; copy: bool = False,; return_mean_var=False,; ):; if copy:; X = X.copy(); if not zero_center and max_value is not None:; logg.info( # Be careful of w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1135#issuecomment-608200735:695,test,tested,695,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135#issuecomment-608200735,1,['test'],['tested']
Testability,"> I think the result in such a case could just contain nans and emit a warning. This sounds reasonable to me. With sparse values, it's consistently giving results, but it's the wrong results. The iteration is being chunked (probably related to number of available cores), and it looks like within each chunk all values after the constant one are filled with zeros. I should look into whether this is also numba, or a logic bug. If it's numba, it's strange that it's zeros and not `inf` or `nan`. If it's on our end, I'm not sure why the later iterations would be skipped. ----------. > p.s.: I really like how you document everything you do so nicely 😃. Thanks! Is mostly so I can remember my reasoning a month later 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-827271245:417,log,logic,417,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-827271245,1,['log'],['logic']
Testability,"> I trust you that this helps 🤷. I guess we can add a test that cements this behavior, but it's tough to test that swap=original-transpose for the underlying data. I tried applying the ordering to what changed in the PR you referenced but that didn't help unfortunately. I don't know the provenance of that change, so I think this is fair. We are using the public API of seaborn in a way that fixes the underlying issue as one would expect.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3196#issuecomment-2271777638:54,test,test,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196#issuecomment-2271777638,2,['test'],['test']
Testability,"> I was considering to use the same tests from scanpy to identify marker genes but with a given set of markers as I want to know if a cluster could be annotated with a marker (which is different than to annotate a single cell). Any thoughts on this idea?. I think that makes sense too. Without multiple testing correction, I feel like that should be equivalent to just filtering the results for the marker genes you have. And as the scores/p-values of that test are not really measures of significance (#270), it would be difficult to evaluate whether the score/p-value is sufficient to assign the cluster annotation. However, this approach is no worse than mine... I wonder how you can evaluate these approaches? Is there a dataset with very similar cells? Maybe gut with goblet and tuft cells appearing annoyingly similar (@mbuttner)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/290#issuecomment-428506572:36,test,tests,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290#issuecomment-428506572,3,['test'],"['test', 'testing', 'tests']"
Testability,"> I wasn't really expecting this feature PR to also include such a large refactor. It would have been necessary for the Dask Dataframe version. Now I 1. did the work and 2. improved readability, so it would be counter productive to undo it. > I'm still not 100% convinced the behaviour here is exactly the same as before. I have done a few tests, which have been okay, but I haven't tried much parameterization. I'm ~80% convinced the results should be the same. If you have any specific things in mind, you should probably make a PR that adds tests for the properties you think we should preserve. We can then merge that one, update this one, and see if it actually breaks something. I can’t check for speculative differences if I have no idea where those could be. > I would note that the dataframe returned when inplace=False has a different index than it did previously. Yup, now it actually matches instead of discarding the original Index and replacing it with a RangeIndex for no reason. > Apart from the comments, can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. Sure! That’s a concrete thing I can do. I’ll do that on thursday, I did the rest of what you asked today",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931:340,test,tests,340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931,4,['test'],"['test', 'tests']"
Testability,"> I wonder why the tests are not working now?. Sorry, I forgot to update `violin.png` after the latest changes to `_anndata.py`. Let's see if the tests pass now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-696705252:19,test,tests,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-696705252,2,['test'],['tests']
Testability,"> I'd really like to have scanpy and anndata work better with dask, but am wary of a high code overhead. Could you provide examples of where you were running into issues with arrays being materialized?. You can see where the materialization occurs by looking for references to `materialize_as_ndarray` in the existing code. For example, in `filter_genes`: https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_simple.py#L215, where the gene subset of materialized as an ndarray, then used to subset the anndata. Contrast this to the optimized version where the materialize step is not needed, and the data remains a dask array throughout the `filter_genes` method: https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/preprocessing/_dask_optimized.py#L18. > I think this can be worked around in AnnData side in many cases. That would be great. > Any chance you did any profiling of these runs? I'd be interested in seeing the performance impact across the pipeline. The closest I got to this was using the Dask web UI to watch tasks being run (see this part of the benchmark script: https://github.com/tomwhite/scanpy/blob/sparse-dask/benchmark.py#L54-L55). This is useful to see what operations are bottlenecks. The only timings I did were to run the complete recipe. On the GPU questions, these all sound like promising avenues, but I haven't looked into any of them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-555940037:1086,benchmark,benchmark,1086,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921#issuecomment-555940037,2,['benchmark'],['benchmark']
Testability,"> I'm actually testing and tweaking someone else's code that was written a while ago. I assume they used; > `import scanpy.api as sc` because it was appropriate then. I personally resolved my issue by downgrading versions, I just wanted to bring this up!. I encountered the same issue. Which version are you using to fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-684930174:15,test,testing,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-684930174,1,['test'],['testing']
Testability,"> I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. You can see some quick comparisons between Pynndescent and Annoy here: https://github.com/pavlin-policar/openTSNE/issues/101#issuecomment-597178379. But I have not investigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-633735833:548,benchmark,benchmarks,548,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233#issuecomment-633735833,1,['benchmark'],['benchmarks']
Testability,"> I'm not sure I know what the pytest execution model is like, but does it ever start new processes for different tests?. Apparently [it needs a plugin](https://pypi.org/project/pytest-parallel/) for that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/724#issuecomment-513132199:114,test,tests,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/724#issuecomment-513132199,1,['test'],['tests']
Testability,"> I'm not sure we're looking at the same code. I was looking at this:. I was looking at the [TruncatedSVD](https://github.com/scikit-learn/scikit-learn/blob/b194674c4/sklearn/decomposition/_truncated_svd.py#L186) code. Either way, I'm not able to reproduce your assertion error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-593744652:262,assert,assertion,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-593744652,1,['assert'],['assertion']
Testability,"> I'm not to sure what the assumptions are behind each method though. @falexwolf, any reason in particular you've chosen UMAP's method for the KNN calculation?. It's highly competitive in terms of speed and accuracy with other libraries (https://github.com/erikbern/ann-benchmarks, pynndescent is what umap uses, wasn't available at the time for Scanpy), it's a lot easier to install than everything else, and the result has been shown to harmonize well with UMAP, which I expected would become the canonical way of visualizing things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/277#issuecomment-427333649:270,benchmark,benchmarks,270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/277#issuecomment-427333649,1,['benchmark'],['benchmarks']
Testability,"> If I understand the .raw removal alternative correctly, then you would want to add masks to every operation in scanpy that is not DE and work with .layers?. Pretty much every function where you would want to use `highly_variable`. > It seems to me that adding masking like this would be quite a large endeavour, no?. I think a similarly sized endeavor to adding `highly_variable`, except we can use the `highly_variable` code where it's been implemented. I would expect this to be less effort than supporting `raw`, which is a constant maintenance burden, especially for `anndata`. I think this logic could be added to the `_get_obs_rep`, and `_set_obs_rep` functions. --------------. > If you assume anything filtered out was removed because it was predominantly 0. I'm not sure I like having this assumption. Especially when a collaborator asks ""what about gene X"", but it just wasn't in the table I received. Maybe it's an annotation issue, maybe it wasn't expressed, or maybe it wasn't expressed globally at a high enough level – but could have been expressed in the cells of interest. > you can assume it would not be in the HVG intersection for that dataset and if you add it,. Is intersection the way to go? If you have cell types which are only present in some datasets, wouldn't you want to take the union?. > Typically there is sufficient gene-gene covariance that you still keep this signal somehow. I would agree that it is unlikely that this would have a huge effect on analyses like PCA or UMAP. When it comes time to do differential expression or show expression on an embedding, then it starts to be an issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-822937305:597,log,logic,597,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-822937305,1,['log'],['logic']
Testability,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python; import vega_datasets; import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(; iris[""sepalLength""],; iris[""sepalWidth""],; c=iris[""petalLength""],; norm=norm,; vmin=3,; ); plt.colorbar(); ```. ```; MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax ; simultaneously is deprecated since 3.3 and will become an error two minor releases ; later. Please pass vmin/vmax directly to the norm when creating it.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-748567569:453,Log,LogNorm,453,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-748567569,1,['Log'],['LogNorm']
Testability,"> If we return an array of integers we run into trouble downstream with functions that aren't tested with integer arrays. Issues from this have been opened a few times, so when I wrote this I thought it might be worth just maintaining the input type. I'm not sure I agree with that now. This is quite a compelling argument for me (as I was one of the people who reported an issue like this). If an integer matrix is generally returned, then one would have to ensure all other functions will work with this data type as intended (sc.pp.log1p for example). Otherwise this would be backward-breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865#issuecomment-552814583:94,test,tested,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865#issuecomment-552814583,1,['test'],['tested']
Testability,"> If you don’t specify a seed, nondeterminism is to be expected. In general, I thought we went for determinism with default arguments in scanpy. I believe pynndescent faster, if non-deterministic, but I get constant output from scanpy. <details>; <summary> Test case </summary>. ```python; import scanpy as sc; import numpy as np. pbmc = sc.datasets.pbmc3k(). sc.pp.filter_genes(pbmc, min_counts=1); sc.pp.normalize_total(pbmc); sc.pp.log1p(pbmc). adatas = [pbmc.copy() for _ in range(10)]; for adata in adatas:; sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.umap(adata). umap_coords = [adata.obsm[""X_umap""] for adata in adatas]; assert all([np.array_equal(umap_coords[i], umap_coords[i+1]) for i in range(9)]); ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1363#issuecomment-674658333:257,Test,Test,257,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1363#issuecomment-674658333,2,"['Test', 'assert']","['Test', 'assert']"
Testability,"> In docstrings, why would you interpret a comma separated list as intersection or a tuple?. In natural language “a, b, c” usually means “a, b, and c” (i.e. a composite or a logical intersection). And an intersection type is one that has all the attributes of all the types, like in `class x(a, b, c): ...` (where commas are also used). In Python plain `a, b, c` constructs a tuple (a composite type): `tup = a, b, c`. It took me a long time to find a numpy function that uses commas for anything other than the “, optional”, but of course [you’re right](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.matrix_rank.html). They do it like that. Why don’t people think before establishing conventions…. A good example of that function’s docs is also how braindead the “optional” is: for `tol`, it means “or None”, for `hermetian` it means “has a default” (probably, no way to know for sure). Goddamn. > Ah, we already have a contributing sheet. oh, is this visible? or does it need to be uppercase for that? CONTRIBUTING.md? I don’t see it when creating an issue, but maybe because I’m an organization member?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441693979:174,log,logical,174,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441693979,1,['log'],['logical']
Testability,"> In natural language... ... I know all that. :wink: But numpy, pandas, scikit learn, tensorflow, seaborn all have the comma-separated list as a convention and I'd really like to stick to that convention. > A good example... . No, the `optional` keyword always means that a parameter has a default. Very often, people forget to append ""or None"" (`, None`) to the list of possible types. Btw: that's maybe a nice way of thinking about it for you: you use a ""tuple of possible types"" to denote that any of these types can be passed in the function. As mentioned before, there is no point in using set-theoretic/logical notions like union or intersection as the topic is so simple that it doesn't need it (no need for an intersection, it's not even clear what that would mean; if you're stringent about it, it's also not clear for union). So, let's simply take the comma-separated list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441771308:609,log,logical,609,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441771308,1,['log'],['logical']
Testability,"> In the other word, the scvelo's 'scv.pl.velocity_embedding_stream' showing terminal differentiation cells develop to original cells. this was incorrected logically. why the scvelo showed the inverted result contrast with monocle result. As @LuckyMD said, this is a question for `scvelo`. . > I guess what i make the cell order was wrong ? . The best way to check if ordering went wrong is to plot an embedding colored by some known grouping. If colors are all mixed up you know a mistake has done. > i wonder whether the code just sorted the cell barcode on annData.obs but the annData.X's matrix? why was the order runing so quickly that the matrix of annData not be sorted at the same time?. Luckily `AnnData` is quite robust and it reorder any slot (`obs`, `obsp`, `obsm`…) according to the specified cell names. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1718#issuecomment-801970805:156,log,logically,156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718#issuecomment-801970805,1,['log'],['logically']
Testability,> In the tests that I have the heatmap seems to be ok. See https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Visualize-marker-genes-using-heatmap; > ; > Do you think that the problem occurs when lot of cells/genes are plotted?. It's possible.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/637#issuecomment-517332847:9,test,tests,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-517332847,1,['test'],['tests']
Testability,"> Is this enough to get started?. For sure, thank you for the context!. Is it possible to add a unit test that checks that with this set to `True`, clusters are better separated?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2731#issuecomment-1803331795:101,test,test,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2731#issuecomment-1803331795,1,['test'],['test']
Testability,> It is also an easy fix but requires the modification of adata.uns to save the colors. This seems reasonable since we already do it. Can you make sure to use the same `_get_palette` function for this? Maybe that should be moved out of `scatterplots.py` to somewhere more general?. We should probably have some logic for not saving the colors if the object is a view. Would have to think about this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1591#issuecomment-762781618:311,log,logic,311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1591#issuecomment-762781618,1,['log'],['logic']
Testability,"> Moving 10x reading functions to anndata. I haven't worked much with h5py or tables, is it time-consuming to refactor these functions? It seems like moving to anndata is the most straightforward solution at least logically to me. > scanpy as a requirement. I like scanpy, but the only thing we really *require* in scvi is the data loading part. A user could take their scvi outputs and go use Seurat if that makes them happy. And then like the data loading functions are simple enough that we could just implement them ourselves. I'm sure a lot of people are currently doing this, which inspired the idea to have a standalone package. > Splitting off new modules. Your questions are very valid. I don't really have good answers for them. I could just see a standalone package being widely used and community driven, especially if there is some scanpy backing + maybe optional dependencies/functionality to get your objects ready for R analysis pipelines.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1387#issuecomment-680188365:214,log,logically,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387#issuecomment-680188365,1,['log'],['logically']
Testability,"> My current thinking is that Gearys C is more sensitive to sparse features, and may be more in need of significance testing. I think this is not as visible for visium data since features are less sparse. Really interesting comparison @ivirshup . I think it makes sense that is more sensible to sparsity because the score is not computed ""against a mean"" but against the neighborhood graph. In some sense, Moran's I is more smooth. . > And this was the problem with p-values in squdpy-s Moran's I (plot for first 100 genes in my adata, using 100 permutations - but this should not really lead to low pvalues as I think that the reported pvalues are estimated based on null distn shape - not 100% sure though). indeed, they are computed against the null distribution that is computed from permutations. As a personal opinion, I don't think reporting p values for these type of statistics is very useful (as in, I personally wouldn't draw conclusions on significance, but more on effect size, and this holds true for a t-test as well imho...).; I should also say that for squidpy we might want to compute p-values out of completeness... but again I would refrain from looking at them. In that case I also think it's more fair since the graph comes from another source, and is not computed from gexp similarity.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-805613901:117,test,testing,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-805613901,2,['test'],"['test', 'testing']"
Testability,"> My impression has been that doing the densifying scale transform didn't seem to show performance improvements in a number of benchmarks. This is also the workflow used in [sc-best-practices](https://www.sc-best-practices.org/preprocessing_visualization/normalization.html); > ; > @Zethson do you have a good citation for this?. Here's the English version of the reply:. Thank you very much for your authoritative answer! You mentioned that in some benchmarks, performing the densifying scale transform didn't show significant performance improvements. I also noticed that sc-best-practices adopts a similar workflow. However, I have a further question: if the step of adding this densifying scale transform is included, would it negatively impact the overall performance? For example, would it reduce the training or inference speed? Or would the impact be negligible?. Thank you again for taking the time to answer my questions! Your opinions are very insightful and helpful to me. I look forward to your further guidance!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034431485:127,benchmark,benchmarks,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034431485,2,['benchmark'],['benchmarks']
Testability,"> New analysis tool: A simple analysis tool you have been using and are missing in sc.tools. What about alternative normalization tools like SCTransform? I read that they are supposed to be better for spatial data. As non-mathematician of course I'm not sure how big the difference will really be in the end but it would be great if there was a easy way to call and test them if it's worth it. > New plotting function: A kind of plot you would like to seein sc.pl?. I think a plot that shows the gene expression profile along a spatial axis would be nice if this is not planned yet. So to draw in e.g. a line in napari and get the gene expression of certain genes along this line. > External tools: Do you know an existing package that should go into sc.external.*?. A package I found very useful and easy to integrate with scanpy is SpatialDE. Are you planning to provide this in `sc.external.*`? And of course tools to integrate sc-RNA-seq and spatial data (like Stereoscope, cell2location,...) would be great! But I think you mentioned that there are plans for own tools, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1653#issuecomment-782699618:366,test,test,366,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1653#issuecomment-782699618,1,['test'],['test']
Testability,"> Nice! Needs some testing though to make sure it works (e.g. specifying a sequence of markers); > ; > You should also make sure the types are correct: `Optional[X]` means `X | None`. Is `None` a valid option? Does it make sense that the type is different in multiple spots? (`Optional[Sequence[str]]` vs `Union[str, Sequence[str], None]` vs `Union[str, Sequence[str]]`). You're absolutely right about the types. I changed the types such as all are accepting the same `Union[str, Sequence[str]]` now.; I also tested several situations I could think of, in [this notebook](https://colab.research.google.com/drive/1ltg0Qs_dlxS_RMuN7z1DdLLV7VLBtZtd?usp=sharing) and they all worked fine. If any more tests (different situations) are needed, please let me know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2545#issuecomment-1626372312:19,test,testing,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1626372312,3,['test'],"['tested', 'testing', 'tests']"
Testability,"> Oh interesting, I thought it was clear :) I mean you even contributed to the function, no?; > ; > I think we also discussed why not to use intersection by default in the PR: [#614 (comment)](https://github.com/theislab/scanpy/pull/614#issuecomment-485875031); > ; > If intersection is not used by default, why would we write in the documentation that it acts as a lightweight batch correction method. I'm as surprised as you are :). Yes, I fixed sth and reorganized a bit. I also recall our disc on `highly_variable_intersection`. However, I thought your organization of HVGs was only for the ranking in `highly_variable_nbatches`. Didn't see it's also the default for `highly_variable`. I never really looked at the docs... that would have given a hint... I still feel as though I have sth slightly different though if I recall. Will look more carefully once this benchmarking data integration thing is out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-617120764:867,benchmark,benchmarking,867,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-617120764,1,['benchmark'],['benchmarking']
Testability,"> Oh, then you didn’t hear of type theory. It’s a branch of logic:. Indeed, I have never heard of that. But I doubt that it would be considered a branch of logic. 1. `Union type` is a pretty bad descriptor for a variable that can take _one_ of a set of fixed types. A union usually denotes a composition of multiple sets giving rise to a new set that contains all elements from these sets.; 2. `Subtype` is a great descriptor for a type that has properties of supertypes.; 3. `Intersection type` is an insanely bad descriptor for a variable that denotes the intersection of _properties_ of supertypes; the concept of such a subtype might be something useful in some languages and some cases and it might deserve a special name as it's the converse behavior of subclassing. But I have no idea how such a type would be useful in Python and in all cases that I've encountered. The [example on Wikipedia](https://en.wikipedia.org/wiki/Type_system#Intersection_types) already constructs a highly artificial case, whose relevance is opaque to me even though Scanpy features it in many instances: functions that overload parameters and have different overloading-dependent return types (standard example is passing an array instead of an AnnData, which triggers the automatic return of the computed annotation). What do you think about 3, @flying-sheep?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-443072359:60,log,logic,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-443072359,2,['log'],['logic']
Testability,"> One thing that the deviances did was perform a chi-square test on the obtained values, with degrees of freedom based on the number of cells. I was fond of that as it translated into a data-driven cutoff for feature selection rather than requiring some number of top genes. @ktpolanski Thanks for the suggestion. Can you clarify which implementation you used where this is implemented?. I think one can essentially convert the variance of Pearson residuals into a p-value using a chi-square test. Then instead of the fixed number of HVG genes one could use some p-value cutoff. We have not experimented with this approach at all though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-874558246:60,test,test,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-874558246,2,['test'],['test']
Testability,"> One thing we had discussed was moving out the merge logic for multiple batches from being specified by `flavor` to being specified by a different argument, maybe `merge_flavor` or `batch_flavor`. Have you thought about/ looked into this?. I see what you mean. Not yet looked into that here, indeed. Slight risk of increasing confusion potential for users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892781138:54,log,logic,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892781138,1,['log'],['logic']
Testability,"> Please deduplicate the tests though, they have too many identical lines. To do so did across-setting tests with for loop on top of former test... Would you prefer one separate test with that for loop for the across-settings check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3042#issuecomment-2121847271:25,test,tests,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042#issuecomment-2121847271,4,['test'],"['test', 'tests']"
Testability,"> Regarding generated, there’s both no need. I disagree with this. I think we definitely should not be intermingling source and generated files, especially when it's one source file to many generated. This is not a pleasant way to navigate files:. <details>; <summary> </summary>. <img width=""182"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113657454-543ca280-96e1-11eb-901c-675e8f248150.png"">. </details>. Also, looking around at other big projects with sphinx documentation, this is the way they all handled autosummary stub files. > `git clean -fx -- ./docs`. This is a bit of a nuke. I've added removing the generated docs to `make clean`, but we wouldn't want to run `git clean -fx -- ./docs` for `make clean`. > 2. Changing anything wide-reaching this would break many of our incoming links. This would be solved with [redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html). I would be happy to have `docs.scanpy.org/en/latest/api/dotplot.html` be the canonical url, but not if it requires mixing generated and source files. > 3. For case insensitivity let’s use the feature that specifically exists for that problem instead: autosummary_filename_map. Doesn't this only half solve the issue? Since (AFAIK) the generated html page has to have the same name as the rst file, this would break links (as you mentioned above). While we could do a redirect from here, what do we redirect too? Do we have special names for urls for classes which have an associated function? I don't think that would be cleaner than just having all classes be put in a `classes` subdirectory.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1753#issuecomment-813822197:546,stub,stub,546,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753#issuecomment-813822197,1,['stub'],['stub']
Testability,"> Removed 3.6. We should keep 3.6 as long as we support it. It's easy to accidentally add features which only work with 3.7+ otherwise. I'd be happy to drop 3.6 once numpy does (and in general roughly follow [NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html) as soon as the ecosystem does). > is there any reason why we are currently not additionally using Github Actions?. Depends on the task. Also depends on the definition of github actions I think? We aren't using any of their runners for testing because we'd like the ability to integrate with hosted resources on azure. Also, azure seemed like much more of a standard for numeric python packages at the time we chose it. I'd be happy to have github actions for other things, like `precommit`. `twine check` could be another one, but I haven't looked in to how ""artifact"" type things are handled with github actions to know if we'd be able to recover the built objects. We'd talked about using codecov too, which I'd like to add a check for. I'm not totally clear on the distinction between checks and actions yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1602#issuecomment-763590019:509,test,testing,509,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1602#issuecomment-763590019,1,['test'],['testing']
Testability,"> Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:336,log,logging,336,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940,3,['log'],"['log', 'logging']"
Testability,> Skip seurat v3 tests with numpy 2 . Sorry does this mean it doesn't work with numpy 2?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3115#issuecomment-2182427293:17,test,tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115#issuecomment-2182427293,1,['test'],['tests']
Testability,"> So I guess the real culprit is the float32 issue with AnnData. Is this something you all plan to address soon?. I think we can do that. I did a quick check and it's pretty benign in anndata. It causes test failures a few places in scanpy, but I think that's solvable with some conversion. It is a breaking change, so it will need to be in anndata 0.8. But there's a few more minor changes I'd like to make, so maybe we can be quick on that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1415#issuecomment-696580713:203,test,test,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1415#issuecomment-696580713,1,['test'],['test']
Testability,"> So I think the issue is the `foldchanges[global_indices]` that has values that you can't input into `np.log2`. That can be `NaN` or negative values. A fold change is something like `(average expression in condition 1)/(average expression in condition 2)` if expression values can be negative, then one of those values can be negative, giving a negative fold change. I would guess that these testing frameworks don't play well with negative values. I believe this is the reason why it happens. If one of those two averages are negative, then your fold change is negative, and you get an error when feeding that into `np.log2()`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494541028:393,test,testing,393,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494541028,1,['test'],['testing']
Testability,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted?. ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-777382118:2,Test,Test,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-777382118,3,"['Test', 'test']","['Test', 'test']"
Testability,"> Tests are failing and I suspect that this is caused by an update on seaborn or matplotlib... Yes, should be as the introduced changes are not linked to the failing tests. I also checked and both `seaborn` and `matplotlib` have been updated in the last few days. See [here](https://pypi.org/project/seaborn/#history) and [here](https://pypi.org/project/matplotlib/#history).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1417#issuecomment-693331949:2,Test,Tests,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1417#issuecomment-693331949,2,"['Test', 'test']","['Tests', 'tests']"
Testability,"> Thank you! With “tests” I mean “functions named `test_*` with `assert ...` statements inside”; ; Thanks for your guidance, I have added `test_weightedSampling.py` with a folder named `weighted_sampled` in _data folder. . I have updated scanpy for weighted sampling for later tasks (clustering, finding marking genes and plotting). I also suggest to support it for initial tasks like PCA for data where each observation has weight (as in MATLAB). . Regards, ; Khalid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-493362243:19,test,tests,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493362243,2,"['assert', 'test']","['assert', 'tests']"
Testability,"> That's a great idea. It might require some reorganization, though, because currently use_raw is checked two places: once in sc.pl.scatter(), because it needs to know whether to look for variables in raw or not when deciding how to call _scatter_obs(), and again in _scatter_obs() itself. Would it be possible to not call it again in `scatter_obs`? E.g. could `_scatter_obs` not even need to know about the `raw` field?. > On another note, some pytests that are in files I did not edit are now failing because they can't find anndata.tests to import. I'm not sure if I messed something up by adding tests to test_plotting.py or whether this is a different issue. Aww crap, I think that was me making a new release. On the plus side it means our build system is now working as it's supposed to.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-964279124:535,test,tests,535,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-964279124,2,['test'],['tests']
Testability,"> That’s great! I don’t see much change in the test suite duration on Azure, should we expect any change?. I wouldn't expect a change on CI, we're not using pytest-xdist here plus I'm not sure if we have enough CPUs to bother. Mainly for dev machine testing",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934493747:47,test,test,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934493747,2,['test'],"['test', 'testing']"
Testability,"> The following test passes with the fix, and fails with the unfixed prior version. Ah, with `normalize_total`, it works with `seurat`, thank you!. > When multiple genes have the same value of `disp_cut_off`. I think when the n-th highest value is tied with others, returning more than the specified number makes total sense. As done by [`scipy.stats.rankdata`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html), the rank of identical data points is identical. So the “values up to the 4th-highest” of the array `[6,5,3,3,3,1,0]` are `[6,5,3,3,3]`, not `[6,5,3,3]`. It makes no sense to include fewer than all of the 3s here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3157#issuecomment-2258094147:16,test,test,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157#issuecomment-2258094147,1,['test'],['test']
Testability,"> The principle should be that Anndata doesn't change array types to numpy arrays. I mostly agree with this, but think there would be a fair amount of work needed in AnnData. Most array types have special treatment in at least one place. A lot of this is due to our need to support sparse matrices. I'm hoping this can be reduced with some new stuff I'm adding though. This is definitely a good use case to test with. There's also the issue of when converting implicitly makes sense. We will do transformations from sparse to dense if the values becomes dense. We will also convert between sparse matrix formats if it will make calculations more efficient. On the topic of Zappy arrays. Can you take a `view` of a zappy array? This would be useful for some of the expectations around subsetting AnnData objects.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/733#issuecomment-515320589:407,test,test,407,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/733#issuecomment-515320589,1,['test'],['test']
Testability,"> The tests don’t fail, but you should still add the extra to setup.py. Is the fact that you don't list `'docs'` in your pip thing (`pip install -e .[louvain,leiden,test]`) purposeful?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/361#issuecomment-438320501:6,test,tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361#issuecomment-438320501,2,['test'],"['test', 'tests']"
Testability,"> The tests have a tolerance parameter that is set high. The problem is that the stripplot shows different results each time. Also, different versions of matplotlib and seaborn have slight differences. Ah yes, I see. The stripplot result could be fixed by setting a seed with `np.random.seed`. I doubt it will fix the difference due to the used version, though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-696710488:6,test,tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-696710488,1,['test'],['tests']
Testability,> The tolerances need to be tight enough that the tests do anything though …; > ; > I’ve seen and fixed quite some tests where the tolerances meant that completely broken output was accepted. This is exactly what I'm seeing in my PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1899355829:50,test,tests,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1899355829,2,['test'],['tests']
Testability,"> The tsne test is giving me a headache. There are some small difference even setting a `random_state`. I will remove the test. I completely get this... the exact UMAP and tSNE plots are simply not _exactly_ reproducible, just very similar... fortunately, clustering (even though that's also a greedy algorithm) and everything else are exactly reproducible. I also removed the tests for UMAP: https://github.com/theislab/scanpy/blob/1df151f678c50b9f85f5d65e7a47d061e4e6784b/scanpy/tests/notebooks/pbmc3k.py#L88-L91 :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-423783837:11,test,test,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-423783837,4,['test'],"['test', 'tests']"
Testability,"> The underlying issues were with a missing .copy() (now added) and with log'd values getting into the simulation process. So a test could be checking that if you passed correctly simulated data into `sc.external.pp.scrublet` as `adata_sim`, you get the same result as letting the function simulate the data itself. You could recreate the simulation using the `.uns['scrublet']['doublet_parents']` field:. ```python; def create_sim_from_parents(adata, parents):; N_sim = parents.shape[0]; I = sparse.coo_matrix(; (; np.ones(2 * N_sim),; (np.repeat(np.arange(N_sim), 2), parents.flat),; ),; (N_sim, adata.n_obs); ); X = I @ adata.X; return ad.AnnData(; X,; var=pd.DataFrame(index=adata.var_names),; obs=pd.DataFrame({""total_counts"": np.ravel(X.sum(axis=1))}),; obsm={""doublet_parents"": parents.copy()},; ); ```. > (which is now prevented with a simple code rearrangement). I think those fixes are pretty self-evident. Yeah, I do see from the code what was going wrong. The issue is more that I want a check to be sure it does not go wrong again. These things clearly get through code review, but it's harder for them to get through a test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2025#issuecomment-963418664:73,log,log,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2025#issuecomment-963418664,3,"['log', 'test']","['log', 'test']"
Testability,"> There’s a few items I’d like to see changed, and you should add tests. I have modified your suggestions , thanks. For tests you mean the 'test cases' or some 'example' data to run the program? . Thanks ...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-492920628:66,test,tests,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-492920628,3,['test'],"['test', 'tests']"
Testability,"> This is actually something I've been meaning to bug you about @WeilerP, why does scvelo pin umap below 0.5?. This was only a dirty hack to make our unit tests pass (see e.g. [here](https://github.com/WeilerP/scvelo/runs/2112241472?check_suite_focus=true)). It's no longer pinned on `scvelo@develop` which we plan on merging into master in the following days to tag a new version. > We can ban umap 0.5.0 specifically. It's generally important that scanpy has a broad-ish range of versions it's comparable with, since there's a lot downstream. I'd be happy bump umap to above 0.4 though, since it has been a while for that. I believe the problem is using `umap-learn<=0.5.0` with new `numba` versions (I think `numba>=0.53.0`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846973729:155,test,tests,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846973729,1,['test'],['tests']
Testability,"> This is how I understood it anyway. You circumvent the problems caused by random sampling by doing a biased sampling, and the weights correspond to the size of the represented community. If the weights are just cluster-size-related, then this would not be necessary as you are calculating cluster-specific values to compare them in e.g., dot plots and statistical tests. This is a weighting that affects the relative importance of cells in the same cluster.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494348675:366,test,tests,366,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494348675,1,['test'],['tests']
Testability,"> This is mainly a fix for cases when multiple genes have zero variance. Could you add that as the test case? When some genes aren't expressed in a batch you won't get an error. > the best way forward would be to exclude those genes from the function. I think the approach of masking out the non-expressed genes sounds reasonable, since that's what you'd probably do if it were just one dataset. I'd definitely defer to @gokceneraslan on any more about the appropriateness of the approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/824#issuecomment-529851678:99,test,test,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824#issuecomment-529851678,1,['test'],['test']
Testability,"> This is strange, i also tried to run the tests multiple times at the time of committing this and they failed every time. Maybe a dependency had a bugged release at the time?. > I am not sure what king of test. I don't want to add another save_and_compare_images test because plots seem to depend on the system at least sometimes. You could instead use `check_same_image`. Check that running `filter_rank_genes_group` then plotting is equivalent to manually passing those genes to `sc.pl.rank_genes_groups_*` plot on an object that hasn't had `filter_rank_genes_group` run on it. You can search the tests for examples of `check_same_image`. > (i have 3 failing plotting tests locally but they run fine here). Could you open an issue for this and note which tests they are? It would be good to make the tests as resilient as possible on other people's systems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1942#issuecomment-878134649:43,test,tests,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1942#issuecomment-878134649,7,['test'],"['test', 'tests']"
Testability,"> This will hopefully be fixed: [#1081 (comment)](https://github.com/theislab/scanpy/pull/1081#discussion_r393315428). Interesting... a logFC is not sth that comes naturally out of a logistic regression model, no? Sergei would have to add a separate calculation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1152#issuecomment-610653258:136,log,logFC,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152#issuecomment-610653258,2,['log'],"['logFC', 'logistic']"
Testability,"> Unfortunately, I run into; > ; > ```; > __________________________________________________________________________________ test_scale[use_fastpp] ___________________________________________________________________________________; > ; > flavor = 'use_fastpp'; > ; > @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); > def test_scale(flavor):; > adata = pbmc68k_reduced(); > adata.X = adata.raw.X; > v = adata[:, 0 : adata.shape[1] // 2]; > # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; > assert v.is_view; > with pytest.warns(Warning, match=""view""):; > > sc.pp.scale(v, flavor=flavor); > ; > scanpy/tests/test_preprocessing.py:127: ; > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; > return dispatch(args[0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:554,assert,assert,554,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717,2,"['assert', 'test']","['assert', 'tests']"
Testability,"> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. So that's what this PR would replace. The reason I thought this could be replaced is that `numba` now allows on-disk cacheing of parallelized functions. This means that the function would only have to be compiled once per install. That cache only get's invalidated if function's source code get's modified, so this shouldn't cause too much pain for development testing times. I've added a note to the documentation mentioning this, so I think it's fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/844#issuecomment-534371715:480,test,testing,480,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844#issuecomment-534371715,1,['test'],['testing']
Testability,"> Well you have to build the wheels to run the check anyways. Oh, what I meant is that we sorta do a check in the same job as running the tests. I was thinking this should be separated out into a job which does ""build and check"" together, rather than including it in the testing job.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1585#issuecomment-763462643:138,test,tests,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1585#issuecomment-763462643,2,['test'],"['testing', 'tests']"
Testability,"> What I basically do from raw UMI counts:; > 1. total counts normalization / logarithmization; > 2. PCA, bbknn, louvain; > 3. combat, HVG, PCA, UMAP (works well). Just out of curiousity, you use both BBKNN and combat? Does Louvain after ComBat, HVG, and PCA not work as well for you? It's interesting that you go with two different knn graphs for clustering and visualization.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666#issuecomment-496845038:78,log,logarithmization,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496845038,1,['log'],['logarithmization']
Testability,"> What I was thinking: if it's a string get the array from obsm, if it's an array, check that it's shape is right, then use the array directly. I'm really sorry but I still don't get it 😅 . What I unnderstand is to modify `adata.obsm[spatial]` in `pl.spatial` and pass that to emebdding. However, I don't want to modify the adata in place or pass a copy. Maybe I'm missing something fundamental, but I could see doing this only if modifying the adata or passing the spatial coordinates as array (but is it possible in sc.pl.embedding? I couldn't find a way). For the rest, I've added docs and added a test, should be ready to go (?). Thanks again for bearing with me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-755199967:601,test,test,601,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-755199967,1,['test'],['test']
Testability,"> What do you define as logic here?. [Logic](https://en.wikipedia.org/wiki/Logic) as the mother of all formal reasoning and its close relative set theory in mathematics. When you say type theory is a branch of logic then 90% of computer science is a branch of logic. In many contexts this might be a valid but not a very useful statement. > I’d also like `OneOf[A, B]`. I love `OneOf[A, B]`. This also doesn't pretend to be logic or set stuff. > `hasattr(obj, 'foo')` defines an intersection type of all types having that attribute. This is what I meant when I said _intersection of properties of supertypes_. But I still don't know when you'd need such a type in a practical context, given that we just keep overloading functions like crazy and simply treat passed arguments dependent on their type. Any example when intersection types are actually useful? In a function we might see in Scanpy (this was the whole beginning of this discussion; I cannot imagine a case in which we need to label something _intersection type_ in the docs).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-443397973:24,log,logic,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-443397973,6,"['Log', 'log']","['Logic', 'logic']"
Testability,"> What do you think of that?. I actually prefer my current layout- it accomplishes your logic without duplication of arguments etc, and from a user perspective I prefer having one main function I can use in the two ways (one anndata you get 3., Two anndata you get 2). But I'm also very happy for you to tweak things to match your vision!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-730987904:88,log,logic,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-730987904,1,['log'],['logic']
Testability,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using?. <details>; <summary> My versions </summary>. ```; -----; sinfo 0.3.1; -----; IPython 7.23.1; jupyter_client 6.1.11; jupyter_core 4.7.0; jupyterlab 2.2.9; notebook 6.3.0; -----; Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]; macOS-10.15.7-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2021-05-10 10:13; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1477#issuecomment-835965024:446,log,logical,446,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477#issuecomment-835965024,1,['log'],['logical']
Testability,"> `paul15` is downloaded automatically, very practical. Yeah, it’s really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364372580:122,test,testing,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364372580,1,['test'],['testing']
Testability,"> adata.rename_categories doesn't work with dataframes in uns. * What problem is this causing?; * @falexwolf, why did this method get un-deprecated?. > Looks fine with miltindex dataframe. However a bit awkward with this names column when n_genes is set. I will set n_genes to all by default but do we need this at all?. I personally find MultiIndexes a bit hard to work with. Could you show how they would be used here? For example, how would I just get a dataframe for the naive T cells vs. rest?. I'm also not sure I get why we'd order genes by rank, when there are multiple comparisons in the table. What operations does this make easier?. **Most importantly**, I don't think we have support for reading and writing multi indexes in anndata. An alternative would be to just have an entry in `uns` that looked like:. ```python; adata.uns[key_added] = {; ""params"": {; ""groupby"": ""leiden"",; ""reference"": ""rest"",; ""test"": ""wilcoxon"",; ""rep"": ""X""; },; ""results"": {; ""1"": ..., # pd.DataFrame, with index of .var_names; ""2"": ..., #etc; },; }; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1156#issuecomment-620393866:915,test,test,915,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1156#issuecomment-620393866,1,['test'],['test']
Testability,"> can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. I’ll do that today if you can give me more info. Usually “regression test” refers to testing specific properties that were broken in a bug and subsequently fixed. What properties exactly are you looking for? Why `cell_ranger` and not `seurat`? Are you implying that we do that already for seurat?. /edit: done in https://github.com/scverse/scanpy/pull/2851. > There are two more lines which aren't covered, but I believe they should be unreachable (both just ValueError that the arg should be ""cell_ranger"" or ""seurat"") so it's fine. yeah, lines like that are more defensive coding. I add them even to internal code to force us to look at everything instead of having a `else: # flavor == ""cell_ranger""` branch or so. > I'm a little concerned about changing the return for inplace=False, in case anyone was relying on that. You mean the fact that the index makes the dataframe now actually useful? I can’t think of a way in which this breaks things in a way that isn’t immediately obvious and welcome. Of course, code can be infinitely weird, but can you think of a scenario?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1940849400:26,test,test,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1940849400,4,['test'],"['test', 'testing']"
Testability,"> clipping function. I think it's not so bad. I think you can use similar logic. Numpy version is something like:. ```python; if axis == 0:; data_mask = np.repeat(row_mask, np.diff(X.indptr)); elif axis == 1:; data_mask = obs_mask.take(X.indices, mode=""clip""); X.data[(X.data > max_value) & data_mask] = max_value; ```. right?. For numba, I'd just include the clipping in the inner loop so it's still single pass.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2025129938:74,log,logic,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2025129938,1,['log'],['logic']
Testability,"> do you have any references on t-test_overestim_var ? I cannot find papers on this test method. what's the difference from t-test ? @falexwolf. I am also interested in formal descriptions about t-test_overestim_var or related publications, thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365#issuecomment-994325045:84,test,test,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365#issuecomment-994325045,2,['test'],['test']
Testability,"> hmm, you didn’t test with the new changes. please do so for the next PR, I’m trusting you with these! Check out [ce06987](https://github.com/theislab/scanpy/commit/ce06987e6824471d0fe22c5cc7f9faf8840bf5da). sorry about that forgot to do this with the last changes I made!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1063#issuecomment-589706044:18,test,test,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1063#issuecomment-589706044,1,['test'],['test']
Testability,"> like pip install .[dev,test$(test_extras))], and run things once with test_extras='' and once with test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'. Yeah, I was thinking something like this. Except we could just reduce `test` to include the barebones needed to make tests run, and separately have optional dependencies. The hard part here is structuring the tests so they can run without optional dependencies being present. We'd need to establish patterns for optional dependencies in fixtures and parameterized tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539:25,test,test,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539,5,['test'],"['test', 'tests']"
Testability,"> obs-like structure with clusters in rows. Completely agreed!; 1. agreed with @ivirshup that there should be a more comprehensive object (which can possibly simply be stored as a dataframe and params in `.uns['rank_genes_groups']`, that clarify what the reference for the test was, but that might be not powerful enough)... your latest suggestion, @ivirshup, representing things as in 3d array sounds very promising, too... how to make an intuitive object? represent the 3d array in a long-form dataframe where two axes are accessible from one multi-index? or store an actual 3d array in AnnData, which can be cast into a convenient object, through a casting namespace... the logic being `sc.tl....` computes some complicated annotation, `sc.pl...` visualizes this annotation and `sc.ex....` extracts and casts annotation into more easily manageable objects. One example is `sc.Neigbors` (which should go into `sc.ex...`) which takes the weird annotation that `sc.pp.neighbors` writes and casts them into an object that allows accessing things... ; 2. Related, but really independent of `rank_genes_groups`: I had implemented a [draft of a `.collapse()` function](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/zebrafish/zebrafish.ipynb#Collapsing-the-AnnData-object), which is very similar to the [`.groupby()` function](https://github.com/ivirshup/mantis#group-by) that @ivirshup suggests, but much less elegant (I would also never have put it into the main repo...). You take a summary metric like `.mean()` or `.std()` and collapse the object by that (in pandas, would be `df.groupby('louvain').mean()`. > Why is it that .obs, .var, and .uns don't have data frames in them? np.recarray don't seem like a very popular data structure elsewhere. We just did only allow rec arrays in `.uns` as they are natively supported by hdf5 and dataframes aren't. It was really just that reason, nothing else. As mentioned in anndata, I'd love to completely move away from rec arrays as a means o",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241:273,test,test,273,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241,2,"['log', 'test']","['logic', 'test']"
Testability,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata.; 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized.; 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-730939013:133,log,logic,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-730939013,1,['log'],['logic']
Testability,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```; …; tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]; tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]; tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]; …; tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]; tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]; tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]; …; tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]; tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]; tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]; …; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3180#issuecomment-2263349948:35,test,test,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180#issuecomment-2263349948,11,['test'],"['test', 'tests']"
Testability,"> only working on genes. technically it could work on continuos covariates as well, should I add that option?. Sure. I think it would make sense to mimic the API of `gearys_c` as much as possible here. > I think it could be worth it to add a row wise normalization of the weights (standard in pysal). What would this entail? I wonder if this is best left up to the user, who can just chose what values to pass in?. > should consider to skip permutation entirely as well. Yeah, I'm not sure if we need this at the moment. I wonder if calculating p-values should even be a separate method? I would like to understand more about how p-values are calculated, and what you're getting out of this. . For instance, I would assume it's not appropriate to calculate a p-value for gene expression using a nearest neighbor network based on gene expression. --------------------. Side note, on performance. So right now it looks like computing one permutation is fairly fast (which makes sense). Most of the time comes from the permutation testing. After that, most of the time looks like it's coming from `adata.obs_vector`, which is a bit slow especially if you're getting many genes with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1740#issuecomment-799062288:1028,test,testing,1028,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740#issuecomment-799062288,1,['test'],['testing']
Testability,"> ooh, this time the benchmark shows really nicely how much faster it is!. Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110#issuecomment-2177815754:21,benchmark,benchmark,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110#issuecomment-2177815754,1,['benchmark'],['benchmark']
Testability,"> probably we had never tested that combination of parameters because the output was a broking image. got it!. > If I understand you correctly, black can by applied to only some lines? Apparently PyCharm can be used with black, do you have any experience?. AFAIK black can’t be applied to some lines only. Thus my suggestion to just run it on files where you changed a lot. [about pycharm](https://black.readthedocs.io/en/stable/editor_integration.html)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/893#issuecomment-546448504:24,test,tested,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/893#issuecomment-546448504,1,['test'],['tested']
Testability,"> rp_forest storage is still broken though. Is this something you are planning on fixing in this pr?. Also, what's broken about it? I would have thought we'd have a failing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1601#issuecomment-763606483:173,test,test,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1601#issuecomment-763606483,1,['test'],['test']
Testability,"> sklearn has also had a PR on this topic out for a long time and it just does not seem to budge. Allowing sparse support for PCA doesn't seem to be high on their priority list(?). I've read that situation as that particular PR being stalled, but it's also just for the random solver. I think sklearn would really like to have this feature. I think there's support for this from the community (where the referenced comment is yours):. > The perfect implementation of implicit data centering must be solver agnostic, allowing any matrix-free sparse PCA and SVD solver from scipy and scikit to be used. E.g., adding support to call any matrix-free scikit SVD/PCA solver in #12794 (comment) would make it perfect PR for implicit data centering. Do you think you could make a PR with this to sklearn? I'd like to see the response it gets, and judge based on that. My preference would be for this to go there, but I'm very open to having this in our codebase until it's in a `sklearn` release. > what's the best way of sharing the reproducing jupyter notebook with you?. Ha, that's actually a difficult question. I'm not quite sure, zip file should be fine. Thanks for sharing!. Ideally what I'd like from a benchmark of performance would be time and memory usage for the product of these conditions:. * Datasets size (one small, one large (>50k cells)); * Implicit centering, densifying centering, no centering; * single threaded, multi-threaded. I'd also lean towards making this the default for sparse data. But to do that, I will need to look a little closer at correctness. For that, could you show the average residual from a few runs (with different seeds) for all output values between implicit vs explicit centering?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589500984:1203,benchmark,benchmark,1203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-589500984,1,['benchmark'],['benchmark']
Testability,"> sparse_indicator doesn’t have its weights branches hit at all, maybe we should remove that? Or will this be used at some point?. I think it will be used at some point, but also happy to remove. I think parameterizing `test_aggregate_axis_specification` is overkill for what the test does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2590#issuecomment-1953840990:280,test,test,280,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590#issuecomment-1953840990,1,['test'],['test']
Testability,"> tests that check if combinations of input arguments lead to expected output (in terms of returned shapes/columns/...) and don't break the function; tests that check if warnings/errors are raised for ""common mistakes"" (inappropriate data, nonsense input argument combinations..). yes both makes sense, it would also be useful to come up with a dummy example for which the actual output could be tested against. This is done in seurat_v3 for instance, but in that case it's kind of straightforward because the ""expected"" is the output computed with original implementation (and as you catched in #1732 it's still might not be enough 😄 ).; another random thing that comes to mind re this specific case is to make sure that indexing etc. is consistent and robust, as you seem to have to sort and resort a fair bit in the hvg implementation. on another note, I was thinking if it makes sense to also release a short tutorial together with the PR (that would be on theislab/scanpy_tutorials) ? I think that for a lot of people the term ""pearson residuals"" could be alienating, and so they'd rather stick to `normalize_total` for comfort (but they shouldn't!). So maybe just something easy like pearson res norm + umap and hvg plots ? curious to hear what you and the others @ivirshup @LuckyMD think about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797462245:2,test,tests,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-797462245,3,['test'],"['tested', 'tests']"
Testability,"> thank you @jlause for the PR! This is really exciting and super useful!; > This is a first round of review, most comments are re types, args and function behviour. I think it looks really good overall and maybe it's time to start writing tests ?; > please let me know if anything unclear and also thanks in advance for code explanations!. Hey @giovp ,; thanks a lot for the review, this looks very helpful! I'll address the single points above one-by-one and make the required changes over the next few days! Will also add some first tests - are there formal guidelines what you expect to be tested? After looking at the tests for `highly_variable_genes`, from my naive perspective I'd test the following:. - tests that check if combinations of input arguments lead to expected output (in terms of returned shapes/columns/...) and don't break the function; - tests that check if warnings/errors are raised for ""common mistakes"" (inappropriate data, nonsense input argument combinations..). Any advice/ideas what else should be tested?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797435681:240,test,tests,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-797435681,8,['test'],"['test', 'tested', 'tests']"
Testability,"> this is not a test of `filter_rank_genes_groups`. To me the point of the test is that `filter_rank_genes_groups` followed by `.pl.rank_genes_groups_*` returns the right image by comparing it to a reference. I mainly prefer that the reference is generated by as orthogonal a method as possible, since then we're closer to testing functionality than implementation. I also think that this strategy forms a more flexible implementation that can be extended to test other properties. For example, it's easy to modify this to check that the `sc.pl.rank_genes_groups_*(..., min_logfoldchange=)` argument plays well with `filter_rank_genes_groups`. I also like having an example of an equivalent implementation in the test suite.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1942#issuecomment-880411601:16,test,test,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1942#issuecomment-880411601,5,['test'],"['test', 'testing']"
Testability,"> we're not using pytest-xdist here. Ah. you do install it in the minimum-tests PR though. I guess that means that you intended the min-deps install script for local CI as well. anyway, LGTM!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934505176:74,test,tests,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934505176,1,['test'],['tests']
Testability,"> what about `X_coords` ?. Ha, I was mostly just trying to get rid of the `X_`!. > What about re-open the theislab/spatial branch and merge this PR there? I could then work on how to handle the new uns structure in the plotting functions and have a definitive version of multiple slices support in anndata. I'd like to merge the changes currently in this PR to master since it fixes a bug with dataset reading. The changes to uns structure could go in another PR, but I'm waiting for an email back from 10x to make sure using the `library_id` as a key makes sense. Either way, the logic of getting the transformed coordinates etc. should be abstracted into a function so it's easy to change. Update: heard back, the `library_id` should be fine, at least for this version. > support for multiple slices should be first. I'm not sure I'm convinced of this. I've also already got some code ready to go for the connectivities and some examples of what can be done with it. I'd like to hear what kind of stuff you want to be able to do with multiple slices. Are you interested in stitching together slides or holding arbitrary slides in an AnnData? I think I'd like to see a more fleshed out idea of what kinds of analysis could be done here before deciding on what kind of an API this should have, and cases we should be ready to handle. Also, I think spatial plotting code should get moved out of `sc.pl.embedding` before we allow plotting multiple slides at a time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1088#issuecomment-596860000:581,log,logic,581,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088#issuecomment-596860000,1,['log'],['logic']
Testability,"> which did the expected thing, @flying-sheep introduced the bug 22 days ago in ce10d02. damn, the only thing I could have done wrong there…. It went into that commit because the previous code was too convoluted to understand, and I needed to understand that line to improve the docs! I ended up understanding it it but rewrote the line incorrectly. I’m sorry!. Did you add a test after 15593d5?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/393#issuecomment-446532755:376,test,test,376,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446532755,1,['test'],['test']
Testability,> why no test for a longer collection of colors?. what do you mean? just a longer list? what would that test?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3299#issuecomment-2426516514:9,test,test,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3299#issuecomment-2426516514,2,['test'],['test']
Testability,"> yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. . @fidelram, from your comment (https://github.com/theislab/scanpy/pull/1551#issuecomment-761117523), makes me think you'd like to enable this? If you okay this, all this needs to be ready to merge is: . - [x] Figure out where result xml should live; - [x] `.gitignore` update; - [x] Remove failing test (just there as an example); - [x] Document where to find this stuff",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1587#issuecomment-761748373:86,test,test,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1587#issuecomment-761748373,2,['test'],['test']
Testability,"> your logging still has fractions of a second in there. Shouldn’t be possible, in 709bafb8ed600daf5f9ee995a0dc845ac1e7e605 I set the microseconds to 0, and in `timedelta.__str__`, microseconds [only get added](https://github.com/python/cpython/blob/83cec020ba177fa27727330ba4ccf60eebc22a54/Lib/datetime.py#L596-L597) if they’re >0. > I tried updating datetime in case that's secretly responsible, as you seem to use it internally for time tracking. How so? It’s a stdlib module, you can’t update it without updating Python itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/746#issuecomment-514121664:7,log,logging,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746#issuecomment-514121664,1,['log'],['logging']
Testability,">>> ; >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; >>> # ValueError: cannot specify integer `bins` when input data contains infinity; >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False); .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(; File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins); File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut; raise ValueError(; ValueError: cannot specify integer `bins` when input data contains infinity; >>> ; >>> # This works, we pass log tranformed data; >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']; >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False); means dispersions mean_bin dispersions_norm highly_variable; 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; ... ... ... ... ... ...; 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]; >>> ; >>> # This raises ValueError again; >>> pbmc.obs['batch'] = 'A'; >>> column_index = pbmc.obs.columns.get_indexer(['batch']); >>> pbmc.obs.ilo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2396:3475,log,log,3475,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396,1,['log'],['log']
Testability,">It appears to me that the benchmarks show that this only becomes relevant for very large data. Hm, even for my example it is 77.14 MiB vs 893.92 MiB, so 10 times difference. This seems large to me, no?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/403#issuecomment-450029072:27,benchmark,benchmarks,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-450029072,1,['benchmark'],['benchmarks']
Testability,?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19hbm5kYXRhLnB5) | `84.98% <100.00%> (ø)` | |; | [scanpy/plotting/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19kb2NzLnB5) | `100.00% <ø> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `77.28% <ø> (ø)` | |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/plotting/\_matrixplot.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19tYXRyaXhwbG90LnB5) | `95.69% <66.66%> (-1.01%)` | :arrow_down: |; | [scanpy/plotting/\_dotplot.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19kb3RwbG90LnB5) | `91.28% <71.42%> (-0.61%)` | :arrow_down: |; | [scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2769#issuecomment-1830133314:2235,test,testing,2235,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2769#issuecomment-1830133314,1,['test'],['testing']
Testability,"@Hrovatin, if you haven't read it yet I think you would find the [Hotspot](https://www.cell.com/cell-systems/fulltext/S2405-4712(21)00114-9) method from the Yosef lab interesting. It uses something similar to Morans I for feature selection and local Morans I for gene module detection. They use parametric null models to get significances for their scores, which would be significantly faster than permutation testing. I'm a little unsure of how the parametric null models correspond to the non-parametric ones since the only comparison I've found so far is some Q-Q plots in the supp.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-846745204:410,test,testing,410,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-846745204,1,['test'],['testing']
Testability,"@Intron7 this was surprisingly hard to get right. Unfortunately, there are now a few more checks and some `hstack`ing. Do those tank the performance?. /edit: I benchmarked some, this is better than what we had before",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2756#issuecomment-1816509533:160,benchmark,benchmarked,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2756#issuecomment-1816509533,1,['benchmark'],['benchmarked']
Testability,@Koncopd ; This is weird never noticed. How can I restore it??; I only built the docs for me to test the outputs. Could be that building the docs affected somehow docs/api/scanpy.external.rst??,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1080#issuecomment-703785741:96,test,test,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080#issuecomment-703785741,1,['test'],['test']
Testability,"@Koncopd Currently breaking test for me:. ```pytb; $ pytest -k test_ingest; ===================================================== test session starts =====================================================; platform darwin -- Python 3.7.6, pytest-5.3.5, py-1.8.0, pluggy-0.12.0; rootdir: /Users/isaac/github/scanpy, inifile: pytest.ini, testpaths: scanpy/tests/; plugins: pylama-7.7.1, parallel-0.0.10, cov-2.7.1, black-0.3.7, hypothesis-5.6.0; collected 393 items / 389 deselected / 4 skipped . scanpy/tests/test_ingest.py ...F [100%]. ========================================================== FAILURES ===========================================================; _______________________________________________ test_ingest_map_embedding_umap ________________________________________________. def test_ingest_map_embedding_umap():; adata_ref = sc.AnnData(X); adata_new = sc.AnnData(T); ; sc.pp.neighbors(; adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0; ); sc.tl.umap(adata_ref, random_state=0); ; ing = sc.tl.Ingest(adata_ref); ing.fit(adata_new); ing.map_embedding(method='umap'); ; reducer = UMAP(min_dist=0.5, random_state=0, n_neighbors=4); reducer.fit(X); umap_transformed_t = reducer.transform(T); ; > assert np.allclose(ing._obsm['X_umap'], umap_transformed_t); E assert False; E + where False = <function allclose at 0x119616b00>(array([[16.566338, 20.174282],\n [15.368203, 20.291983]], dtype=float32), array([[16.502459, 20.157679],\n [15.581459, 20.302881]], dtype=float32)); E + where <function allclose at 0x119616b00> = np.allclose. scanpy/tests/test_ingest.py:140: AssertionError; ---------------------------------------------------- Captured stderr call -----------------------------------------------------; computing neighbors; finished: added to `.uns['neighbors']`; 'distances', distances for each pair of neighbors; 'connectivities', weighted adjacency matrix (0:00:00); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:00:00); ``",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036#issuecomment-599469073:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036#issuecomment-599469073,5,['test'],"['test', 'testpaths', 'tests']"
Testability,@Koncopd I made an actual test from your notebook :smile:: https://github.com/theislab/scanpy/commit/8d4ec6376c5b338456ced0bc051683052f15aa37,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-404142288:26,test,test,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-404142288,1,['test'],['test']
Testability,"@Koncopd has looked at refactoring the `rank_genes_groups` methods, but in the big picture we don't really love the output format that `rank_genes_groups` uses. Maybe an easier path forward would be to be able to directly pass values into the various plotting functions? You can already generate mostly similar plots from `sc.pl.rank_genes_groups_{plot_func}` and `sc.pl.{plot_func}` apart from using logfc and pvalues. If we allowed passing those in, it would be simple enough to make the same plots/ add a wrapper that generates the plots into `diffxpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1955#issuecomment-886408954:401,log,logfc,401,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955#issuecomment-886408954,1,['log'],['logfc']
Testability,"@Koncopd pre-commit doesn’t *have* to be configured, you can choose not to enable it. Of course tests will fail then. regarding mypy: I guess it’s possible to make everything return `-> t.Any: # TODO fix typing`. I like isort!. Also we should get #1527 in before doing any big restructuring: It’s been through too many rounds of delays and I had to resolve conflicts so many times.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-757907537:96,test,tests,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-757907537,1,['test'],['tests']
Testability,"@Koncopd when we talked about this last there were concerns about backwards reproducibility. I'm wondering if this logic would fix that:. * If the dataset is ""small"" and the metric is defined by scikit-learn, compute complete distances; * For all other cases use pynndescent. Would this be sufficient to keep results the same, or do we compute dense distances for the more esoteric metrics now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1413#issuecomment-861371191:115,log,logic,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1413#issuecomment-861371191,1,['log'],['logic']
Testability,"@Koncopd yes, I believe that should cover everything (maybe test to make sure I'm not missing sth here). However, I still think taking adjacency matrix powers will not be as fast as a BFS/DFS.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-701344124:60,test,test,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-701344124,1,['test'],['test']
Testability,"@Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb; ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------; running ingest; ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():; adata_ref = sc.AnnData(X); adata_new = sc.AnnData(T); ; sc.pp.neighbors(; adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0; ); sc.tl.umap(adata_ref, random_state=0); ; > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; scanpy/tools/_ingest.py:270: in __init__; self._init_neighbors(adata); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 ; uns: 'neighbors', 'umap'; obsm: 'X_umap'. def _init_neighbors(self, adata):; from umap.distances import named_distances; > from umap.nndescent import (; make_initialisations,; make_initialized_nnd_search,; ); E ImportError: cannot import name 'make_ini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036:99,test,tests,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036,1,['test'],['tests']
Testability,"@Koncopd, can we merge this without the `neighbors_update` function and without writing the `rp_forest` to the AnnData object? Your code is good, but we should put it into another PR. > Can you investigate and if it's easy cover in this PR? If it's tricky, let's wait for another PR. Is what I wrote in the beginning. I think it turned out tricky and is a case for https://github.com/theislab/scanpy/issues/562#issuecomment-487409358. So, let's keep this PR really simple and just be about removing the legacy code. Your statement about ""all tests pass except for the PAGA tests"" is still true? Did you manually inspect the PAGA notebook and does it look consistent? Just a few cosmetic things should have changed, I guess. If yes, we'll merge this, now that `1.4.1` is out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-487410333:542,test,tests,542,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487410333,2,['test'],['tests']
Testability,"@Koncopd, updating `logreg` with a proper implementation accounting for `reference` is another story. We can talk about it sometime soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-474305372:20,log,logreg,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-474305372,1,['log'],['logreg']
Testability,"@LisaSikkema, current behavior just changes the groups which are tested (I'd call this the ""left hand side"" in `group vs reference`) not what they are tested against. That is controlled by the `reference` argument. I agree this could be more clear. It would also be nice if `reference` was more flexible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1519#issuecomment-743963259:65,test,tested,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519#issuecomment-743963259,2,['test'],['tested']
Testability,"@LisaSikkema, no worries there's been some flakiness of that test. Can this get a test case like ? Maybe even two, one where groups match, one where they don't?. I'm thinking something that calls `save_and_compare_images`, like https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L272",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1511#issuecomment-739663476:61,test,test,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511#issuecomment-739663476,3,['test'],"['test', 'tests']"
Testability,@LuckyMD . Thank you for the whole in-depth discussion. It makes a lot of sense! :smile:. To your question: Scanpy has used Welch's adaption of Student's t-test from the very beginning. @davidsebfischer . Thank you! I guess it would be nice to have a single-cell tutorial in diffxpy that shows higher sensitivity by accounting for technical covariates.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-450025261:156,test,test,156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-450025261,1,['test'],['test']
Testability,"@LuckyMD @maximilianh Thanks guys for the reply. ; Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X ; If I do ; `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```; import scanpy.external as sce; sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'); ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/506#issuecomment-468460649:643,test,test,643,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506#issuecomment-468460649,1,['test'],['test']
Testability,@LuckyMD I would be interested into looking at your method. It is different than that of `score_genes`. . I was considering to use the same tests from scanpy to identify marker genes but with a given set of markers as I want to know if a cluster could be annotated with a marker (which is different than to annotate a single cell). Any thoughts on this idea?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/290#issuecomment-428457349:140,test,tests,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290#issuecomment-428457349,1,['test'],['tests']
Testability,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:78,log,log-scale,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609,14,"['log', 'test']","['log', 'log-mean', 'log-scale', 'loge', 'test', 'testing', 'tests']"
Testability,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:; * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. ; * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1529#issuecomment-738733928:1430,log,logfoldchange,1430,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529#issuecomment-738733928,2,['log'],['logfoldchange']
Testability,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1529#issuecomment-738292854:188,log,log,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529#issuecomment-738292854,3,"['log', 'test']","['log', 'tests']"
Testability,@LuckyMD why don't you add a test to `scanpy/tests/test_plotting.py`. Thus we can guarantee that future changes do not break your code.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/543#issuecomment-476209255:29,test,test,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-476209255,2,['test'],"['test', 'tests']"
Testability,"@LuckyMD, I think you can get the docker environment travis uses. * [Docker image for travis python env](https://hub.docker.com/r/travisci/ci-python); * [Guide on running it](https://andy-carter.com/blog/setting-up-travis-locally-with-docker-to-test-continuous-integration). I did this a couple years ago, but I know travis has changed a bunch since then. Another good first step would be to figure out if it only fails on the first build, and if caches are being used in any way. Also, do the builds ever fail for forks? I don't think they've been failing [for me](https://travis-ci.org/ivirshup/scanpy/builds).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/580#issuecomment-478823933:245,test,test-continuous-integration,245,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478823933,1,['test'],['test-continuous-integration']
Testability,"@LuckyMD, do you think you ever saw a change without version updates? I'd like to think we were aware of changes through our tests (in particular tests for plotting and the pbmc notebook). However calculations change for different dataset sizes, so we could be missing cases where there's instability.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1363#issuecomment-678129332:125,test,tests,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1363#issuecomment-678129332,2,['test'],['tests']
Testability,"@LustigePerson, would you be able to add a quick test here? Then this could get into the next release",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2190#issuecomment-1081869351:49,test,test,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1081869351,1,['test'],['test']
Testability,@Marius1311 Thanks a lot for adding this. I reviewed the code and do not have any objections to merge it. Would be possible to add or modify one of the plotting tests where this new parameter is used?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1161#issuecomment-620661211:161,test,tests,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1161#issuecomment-620661211,1,['test'],['tests']
Testability,"@MichaelPeibo @falexwolf I started working on points 2 and 3, but it is better if you will work on these points.; I wrote the code for points 1 and 4.; In order to generate volcano plots, I calculated the log2FC relying on the `diffxpy` library.; I can push again the code for tSNE and also the code for volcano plots. Please, check the `rank_genes_groups` function.; Considering 2 groups of cells and using the Wilcoxon test (`de.test.wilcoxon`) provided by the `diffxpy` library, I obtained different marker genes with respect to those calculated by using `rank_genes_groups` function (Wilcoxon test). Many thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471321592:421,test,test,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471321592,3,['test'],['test']
Testability,"@PrimozGodec, probably don't add this to `requirements.txt`, since the requirement should be optional for install. I think instead you should mark it with something like:. ```python; from importlib.util import find_spec. @pytest.mark.skipif(find_spec('pointannotator') is None, reason=""pointannotator not installed""); ```. You can add a requirement for the package to this line in `setup.py`: https://github.com/theislab/scanpy/blob/d8f32c040f3a5f4fc07998b269796ca58de84b40/setup.py#L41. Maybe we should eventually have a second requirements file for CI testing, like we do for anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/812#issuecomment-537465652:554,test,testing,554,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812#issuecomment-537465652,1,['test'],['testing']
Testability,"@THZ34 can you create a reproducer where this happens, so I can add a test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2804#issuecomment-2012516645:70,test,test,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2804#issuecomment-2012516645,1,['test'],['test']
Testability,@WeilerP probably there is a more direct way to overlay the stripplot but I don't think that it makes any big difference. . Can you make a PR to see how the tests work?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1420#issuecomment-694327799:157,test,tests,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1420#issuecomment-694327799,1,['test'],['tests']
Testability,"@WeilerP would you be willing to write a tiny test and to add the release note, please?. Thanks! Happy to merge this then if you ping me. @ivirshup generally, I agree. Think that this tiny change doesn't harm though and deprecating the magic ""read"" is something bigger.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1969#issuecomment-1291807007:46,test,test,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1969#issuecomment-1291807007,1,['test'],['test']
Testability,@WeipengMO if you calculate it like this you are right. However when we move from 64Bit to 32Bit for neighbors the results are reproducible at least to the best of my testing. I would still be open to round the results. @flying-sheep what do you think?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822393557:167,test,testing,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822393557,1,['test'],['testing']
Testability,"@Xparx Thanks for reporting the problem an a potential solution. . Each plotting function has a save parameter which does:; ```; pl.savefig(filename, dpi=dpi, bbox_inches='tight'); ```; So, instead of calling `fig.savefig()`, what you can do in your example is to add `save='test.png'`:. ```; sc.pl.matrixplot(adata, save='test.png', var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/418#issuecomment-453006714:275,test,test,275,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418#issuecomment-453006714,2,['test'],['test']
Testability,"@Zethson I’m adding some in #3031, but it needs more thought: 30 minutes for a benchmark run is too long …",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3044#issuecomment-2100696528:79,benchmark,benchmark,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044#issuecomment-2100696528,1,['benchmark'],['benchmark']
Testability,@Zethson do we really need a test here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2460#issuecomment-1493446043:29,test,test,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1493446043,1,['test'],['test']
Testability,"@a-munoz-rojas Thanks for checking and thank you very much for the PR :smile! I like your version of the implementation a lot better than the manual one, as the code is much more readable. I don't know why @tcallies added the wilcoxon this way at the time, but I assume for speed and memory reasons. So, I'm very happy to merge this PR; I'll just briefly give this another check today or tomorrow and update the tests so that they don't fail anymore. Regarding the general discussion: Yes, let's just add a disclaimer that several assumptions on how meaningful the null hypotheses are both for wilxocon and t-test for single-cell data, should do the job. Then people will interpret the p-values with care.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-427040589:412,test,tests,412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-427040589,2,['test'],"['test', 'tests']"
Testability,@adamgayoso A recent update of seaborn caused some trouble with the tests but is now fixed. Can you merge with master to trigger again the tests?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1421#issuecomment-697317906:68,test,tests,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1421#issuecomment-697317906,2,['test'],['tests']
Testability,"@adamgayoso This is a fair point and thanks for raising this issue. Just to clarify, Jan started this PR because we were explicitly asked by some of the Scanpy core developers to prepare it for the core library. Whether this goes into `external` or into the core, is definitely not our call, so let's see what the Scanpy team says. . --------------------. I just wanted to make some small comments to what you wrote. The main comment is that we don't view this as a ""new method"". We view it basically as ""scTransform done right"". And scTransform is already published and is being used. . > It feels like something that should more go to external, considering the method itself will undergo the peer-review process. . I understand this point, but I guess the distinction here is not only published vs not-yet-published. A lot of stuff gets published but is not included into Scanpy... > As another example, why not add GLM-PCA to sc.tl.glm_pca? It's supposed to be better. See our preprint regarding ""supposed to be better""... . > I even think in GLM-PCA they describe a fast approximation using deviance residuals, so why not add that?. Deviance residuals are very similar to Pearson residuals. We could consider adding deviance residuals as an option to the functions suggested in this PR, it would be all the same logic, just deviance vs. Pearson. Hmm, actually I would need to check what exactly is the expression for deviance residuals for NB model. > shouldn't we put more weight on the peer-review process here?. One option would be to hold this PR until our paper is formally accepted...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-798444591:1316,log,logic,1316,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-798444591,1,['log'],['logic']
Testability,"@adamgayoso, I should definitely get around to merging this. I think I can pretty much do it as is, and open a second issue for getting the docs looking good. I'd like to target an initial `metrics` module for `1.8` (we're working on upping the release cadence as well). Question for your lab, are our implementations equivalent? I haven't actually gotten around to testing against the `VISION` R/C++ version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-763302767:366,test,testing,366,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-763302767,1,['test'],['testing']
Testability,"@aditisk that depends on what you put in `adata.raw` ;). Initially `adata.raw` was used to store the full gene object when `adata.X` was filtered to only include HVGs or remove genes that aren't expressed in enough cells. Now, we just have a boolean mask in `adata.var['highly_variable']` for HVGs and so it's often not used anymore. I typically store my log-normalized expression data there if I do batch correction or regress anything out, as `adata.raw` is used as default to compute `rank_genes_groups` and to show expression values on an embedding plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1039#issuecomment-617882284:355,log,log-normalized,355,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039#issuecomment-617882284,1,['log'],['log-normalized']
Testability,"@aeisenbarth Could you provide a small code sample or point to one of our unit tests where this happens? I am not seeing what you are referring to. For example:. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.leiden(adata, flavor=""igraph"", resolution=5, directed=False, n_iterations=2, copy=True); sc.tl.leiden(adata, flavor=""leidenalg"", resolution=5, copy=True); ```; do not seem to yield the warnings you describe. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2865#issuecomment-2122066123:79,test,tests,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2865#issuecomment-2122066123,1,['test'],['tests']
Testability,"@andrea-tango ; Really awesome!; I am also wondering to find some parameters to tune in scanpy's `rank_genes_groups` like in Seurat. . Because I found there is some difference in makers by scanpy's default(using `wilcoxon` ) and Seurat's default parameters` only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25`. (Seurat's default method is wilcoxon), in this case, I can find interesting markers calculated by Seurat but not in Scanpy's. However, when I tried scanpy's `logreg` method, I found many overlap DEGs between two calculations, aka, scanpy's `logreg` and Seurat's `wilcox`. Have you ever came into similar results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471241654:291,log,logfc,291,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471241654,3,['log'],"['logfc', 'logreg']"
Testability,"@andrea-tango @MichaelPeibo To address the filtering of rank_genes_groups (eg. `min.pct = 0.25, logfc.threshold = 0.25`) I recently added a function called `sc.tl.filter_rank_genes_groups`. See https://github.com/theislab/scanpy/pull/425. @falexwolf I don't know why`sc.tl.filter_rank_genes_groups` does not show up in the docs. I will take a look. Also, I just noticed that this PR with updated examples is still open. I think it would be useful to merge: https://github.com/theislab/scanpy_usage/pull/11",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471531524:96,log,logfc,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471531524,1,['log'],['logfc']
Testability,"@ashish615 after doing some benchmarking myself I found out that your solution for `axis=1` is under performing compared to `axis=0` for larger arrays. I think that is because of the memory access pattern you choose. I rewrote the function with that in mind. I'll again make a PR to you, because for some reason you disallow us from making changes to your PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3099#issuecomment-2191349887:28,benchmark,benchmarking,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099#issuecomment-2191349887,1,['benchmark'],['benchmarking']
Testability,"@atarashansky sorry for getting back to you late! I played around with the implementation, thanks a lot for the notebooks!. few questions before opening the PR:; - do you think it's worth it to allow users to add other variables (beside log_umi) ?; - do you think it would be useful to add other models other than poisson?; - there are other outputs provided by R implementation other than pearson residuals. Do you think it's worth to include them?; - testing: how do you think it should be best tested? we thought about saving results from original implementation in R and test against those (as it's done for others seurat re-implementation like highly variable genes). looking forward to hear what you think! thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-783547730:453,test,testing,453,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643#issuecomment-783547730,3,['test'],"['test', 'tested', 'testing']"
Testability,"@atarashansky, the performance is looking very very good:. ```python; import scanpy as sc; import numpy as np; from sklearn.datasets import fetch_20newsgroups_vectorized. X = fetch_20newsgroups_vectorized(""all"").data; # 18846 x 130107 csr_matrix. a = sc.AnnData(X, dtype=np.float64); %time implicit = sc.pp.pca(a, pca_sparse=True, dtype=np.float64, copy=True); # CPU times: user 34.8 s, sys: 5.52 s, total: 40.3 s; # Wall time: 2.93 s; # Peak memory (including dataset) is about 770 MB; %time explicit = sc.pp.pca(a, pca_sparse=False, dtype=np.float64, copy=True); # CPU times: user 55min 37s, sys: 1min 50s, total: 57min 28s; # Wall time: 7min 43s; # Peak memory is about 36 GB. assert np.allclose(implicit.obsm[""X_pca""], explicit.obsm[""X_pca""]); assert np.allclose(implicit.varm[""PCs""], explicit.varm[""PCs""]); ```. But the variance and explained variance ratio are still off. Why not calculate them the same way sklearn does?. Also, any thoughts on making a PR there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-593738303:680,assert,assert,680,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-593738303,2,['assert'],['assert']
Testability,"@awnimo , for me test_phenograph.py fails with `E TypeError: Expected list, got numpy.ndarray`.; Could you check please?; This is certainly related to scipy 1.5. With scipy 1.4 the test works fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1080#issuecomment-702669779:181,test,test,181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080#issuecomment-702669779,1,['test'],['test']
Testability,"@cchrysostomou Indeed the mean will no longer be zero, I was merely reimplementing exactly what was done in Seurat, and we have tests to show in the single batch case that we get the same exact genes. No need to delete this comment. . I suppose you can think of it as the second moment instead of the variance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/993#issuecomment-1040470890:128,test,tests,128,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993#issuecomment-1040470890,1,['test'],['tests']
Testability,"@coh-racng, I've merged your fix in #790 with a test added. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/764#issuecomment-522894347:48,test,test,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/764#issuecomment-522894347,1,['test'],['test']
Testability,"@dawe ; - the coding style is the [official python coding style](https://www.python.org/dev/peps/pep-0008/), we should all stick to that. in particular: [white spaces](https://www.python.org/dev/peps/pep-0008/#whitespace-in-expressions-and-statements) around operators but **not** around optional keyword arguments; - thank you for a notebook!; - gene list: why not add it as an attribute of your module? or make a class `GeneLists` with a few gene lists in your model? of course, these will not be comprehensive, but might provide a good starting point; - in a few instances, I had to go through the reverse R engineering myself - in particular, if it comes to benchmarking code to floating point precision, it's really a hassle to dig out all the hidden different conventions... but I think it really pays off in the sense that it provides a lot more confidence in code and methods if several tools provide the same result on basic things - even across languages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/76#issuecomment-363733820:662,benchmark,benchmarking,662,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76#issuecomment-363733820,1,['benchmark'],['benchmarking']
Testability,"@dawe Could you also please provide a brief tutorial on how to install `scanpy` on M1? I am having troubles. I have followed [this tutorial ](https://medium.com/geekculture/the-best-way-to-setup-your-m1-mac-for-python-development-fb5dffd08fd) to set up python on my M1 Mac. Thus I have installed `miniforge` with `brew`. My versions are `Python 3.9.6` and `pip 21.2.4`. Also I have read that you succeed in install `scanpy` with `python 3.8` but I am not able to downgrade version. The error I face when I run `pip3 install scanpy` is:. ```; ERROR: Command errored out with exit status 1: /opt/homebrew/Caskroom/miniforge/base/bin/python3.9 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-install-6blz73pw/h5py_c0efce6062af4b4d9f6564a97c24d1a7/setup.py'""'""'; __file__='""'""'/private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-install-6blz73pw/h5py_c0efce6062af4b4d9f6564a97c24d1a7/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-record-lf5rwuj7/install-record.txt --single-version-externally-managed --compile --install-headers /opt/homebrew/Caskroom/miniforge/base/include/python3.9/h5py Check the logs for full command output.```. Thank you in advance!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1840#issuecomment-930949004:1491,log,logs,1491,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840#issuecomment-930949004,1,['log'],['logs']
Testability,"@dawe In all benchmarks that I did maybe a bit less than a year ago, the `python-louvain` didn't seem to produce satisfying results... But maybe I did something stupid. I'll reevaluate this, thanks, Davide! PS: One can easily switch between implementations; simply pass `flavor='taynaud'` to `sc.tl.louvain` and you'll use `python-louvain`. See [here](https://github.com/theislab/scanpy/blob/5299c6caaec6402513f1e0442186350787177d2c/scanpy/tools/louvain.py#L118-L125). However, I removed this from the docs as I was not so satisfied with it... @flying-sheep the only thing where `igraph` is used in Scanpy is for graph drawing, where it's incredibly faster than `networkx` (completely forget about `networkx` in this respect); the performant `louvain` implementation is due to the `louvain` package, which simply uses `igraph`'s graph data structures",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-370393215:13,benchmark,benchmarks,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/97#issuecomment-370393215,1,['benchmark'],['benchmarks']
Testability,"@dawe a cell cycle scoring function would be great! everything that's a bit more extensive and non-standard should go into [sc.tl](https://github.com/theislab/scanpy/tree/master/scanpy/tools), everything that's really just simple preprocessing and stats with a few lines can go to [sc.pp](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/simple.py). usually, there should be a plotting function in sc.pl that presents a canonical visualization of the annotation added in with the tool... writing a test for your function would also be great ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-363250398:517,test,test,517,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45#issuecomment-363250398,1,['test'],['test']
Testability,"@falexwolf . Hi, Alex.; Yes, i'm checking these. Actually, it somehow passes [test_pbmc3k](https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_pbmc3k.py). Only [test_paga_paul15_subsampled](https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_paga_paul15_subsampled.py) fails. It seems that adjacency matrix is a bit different after the change and this affects paga connectivities. But it is preliminary, i'm checking still.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-478741723:145,test,tests,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-478741723,2,['test'],['tests']
Testability,"@falexwolf ; Hi, Alex. What i figured out for now. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105; This can be replaced by importing this; https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L148. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258; This is basicly this; https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L329; But this `fuzzy_simplicial_set` doesn't calculate `distances`, only `connectivities`. What is the right approach to solve this? Writing PR to umap that adds `distances` as a return value for `fuzzy_simplicial_set`?. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107; This line can be directly imported from umap of course, but now their `simplicial_set_embedding` requres also `adata.X` as an input, because the case with the number of connected components > 1 is treated differently. It should not be a problem as we have this in adata. I comment it just because this changes the logic a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/522#issuecomment-476643493:1182,log,logic,1182,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522#issuecomment-476643493,1,['log'],['logic']
Testability,@falexwolf ; It is strange that there are no tests for this. I thought i added them...; I will try to do all these thing in two days. Sorry for the delays.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/594#issuecomment-481276242:45,test,tests,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/594#issuecomment-481276242,1,['test'],['tests']
Testability,"@falexwolf ; MAGIC uses root square transformation, not the frequently used log transformation, which causes the incompatibility with batch correction methods, such as CCA and MNN. Is DCA compatible with MNN and CCA ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/187#issuecomment-403407217:76,log,log,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187#issuecomment-403407217,1,['log'],['log']
Testability,@falexwolf ; This is just a small test for the existing pca. You asked me to write it some time ago.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/466#issuecomment-471328945:34,test,test,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/466#issuecomment-471328945,1,['test'],['test']
Testability,"@falexwolf ; Yes, i inspected the notebook, everything looks the same. Also this PR passes all tests now. So, yes, i think it can be merged",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-487414554:95,test,tests,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487414554,1,['test'],['tests']
Testability,@falexwolf ; some usage examples; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/use_Ingest.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-510218093:76,benchmark,benchmarks,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-510218093,1,['benchmark'],['benchmarks']
Testability,@falexwolf @andrea-tango ; I have a question regarding point 2 (log2FC values in `rank_genes_groups`). I see that only `'logreg'` method doesn't return logfoldchanges. But logfoldchanges don't seem natural for `'logreg'` as this method doesn't even use `reference` for calculation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471938514:121,log,logreg,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471938514,4,['log'],"['logfoldchanges', 'logreg']"
Testability,@falexwolf @ivirshup ; New Ingest api usage; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/Ingest.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-515261645:87,benchmark,benchmarks,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-515261645,1,['benchmark'],['benchmarks']
Testability,@falexwolf @ivirshup ; Tests are also ready.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-524670031:23,Test,Tests,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-524670031,1,['Test'],['Tests']
Testability,"@falexwolf @willtownes @LuckyMD Valentine Svensson suggests that zero inflation does not exist in droplet protocols, but that log-transforming data could be responsible for the apparent zero inflation. Further, the high number of zeros can be accurately modeled with a non-zero-inflated model: https://www.nature.com/articles/s41587-019-0379-5. Since GLM-PCA doesn’t model zero inflation, it’s probably a really good base for distance calculations in scanpy in cases where its performance is sufficient. [From the paper](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1861-6):. > The multinomial model adequately describes negative control data, and there is no need to model zero inflation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-592476723:126,log,log-transforming,126,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-592476723,1,['log'],['log-transforming']
Testability,"@falexwolf Do you know a more efficient way to get the value of a single column given the gene name. Currently, I am using:. ```; adata[:, 'gene_name'].X; ```. This is easy but not optimal. Any idea?. I will start updating the test once we are happy we the new results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-421258458:227,test,test,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-421258458,1,['test'],['test']
Testability,"@falexwolf I agree with you about the `diffxpy` a `scanpy` dependencies, Tensorflow is a very important dependency!. > would you make a PR?. I did it, I pushed the code where I added the parameter `n_components` for `scanpy.tl.tsne` function. > Why not using `diffxpy` Volcano plots right away?. I wrote a function in which you can change the colour of the genes, you can add the names of the genes etc. > How did you write your tests?. I tried them on data coming from the lab in which I am working.; I can write a jupyter notebook using public dataset and push it on my copy of the `scanpy` repository.; Give me a couple of days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471324466:429,test,tests,429,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471324466,1,['test'],['tests']
Testability,"@falexwolf I have the functions in my scanpy branch, right now. It seems to be properly working (take a look, if you want to). I'll add the tests as soon as possibile (now getting back to ""ordinary work"")",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-363458980:140,test,tests,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45#issuecomment-363458980,1,['test'],['tests']
Testability,"@falexwolf I took the opportunity to add a change that I wanted with respect to the palette which is the ability to set a palette based on a matplotlib colormap. For example using `palette='tab20'`:. ![image](https://user-images.githubusercontent.com/4964309/46139067-dcf34180-c24d-11e8-892a-a6f3bbda2c4b.png). or using `palette='Set3'`. ![image](https://user-images.githubusercontent.com/4964309/46139126-feecc400-c24d-11e8-9e34-f8395c70aeb9.png). I didn't want to modify the previous code that handles setting the palette to avoid breaking other code, but if we have some tests for other functions that use that functionality I could try to update the original methods.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-425036021:574,test,tests,574,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-425036021,1,['test'],['tests']
Testability,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:123,test,tests,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088,10,"['log', 'test']","['log', 'test', 'testing', 'tests']"
Testability,@falexwolf Is there anyplace where we can read into `diffxpy`? I've been benchmarking available marker gene detection algorithms and am interested to see what is included in this new package.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-420362783:73,benchmark,benchmarking,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-420362783,1,['benchmark'],['benchmarking']
Testability,"@falexwolf Thanks for the support. . I agree that this is not an urgent changes that can quietly be tested. Have you consider having a 'develop' branch were we can put all code like this? . As you point out some differences are seen with respect to the shape of the plot when multiple panels are plot. This is mostly due to some code to add space for the colorbar and legends that can overlap nearby figures. Nevertheless, I can further adjust this to get plots that are more similar to the actual ones. I think that the tests are failing because there is a clash between the module and a method called `scatter`. Once the code is cleaned this should go away. . If you don't mind I would slowly start removing redundant code and adding further tests. So, lets keep this PR open.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-416855357:100,test,tested,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-416855357,3,['test'],"['tested', 'tests']"
Testability,"@falexwolf The UMAP test works because the umap coordinates are saved along the pbmc datataset that I am using. In contrast, the tsne coordinates need to be computed. Thus I suggest to leave the UMAP test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-424247659:20,test,test,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-424247659,2,['test'],['test']
Testability,"@falexwolf the problem is that there are functions that do now work without them and our down stream packages do not work ootb. Would it be possible to add a second file, e.g. `requirements-ect.txt` to keep track of this?. This file could also be used to create testing environments easily.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/305#issuecomment-433357089:262,test,testing,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/305#issuecomment-433357089,1,['test'],['testing']
Testability,@falexwolf you were a little quick: @davidsebfischer didn’t turn it public yet. maybe david would like to send it to you for beta testing?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-420550464:130,test,testing,130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-420550464,1,['test'],['testing']
Testability,"@falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190; [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037; [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7; [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681; [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189:336,benchmark,benchmarks,336,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189,1,['benchmark'],['benchmarks']
Testability,"@fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs?. Anyways, the docs fail with this traceback:. <details>; <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors; warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)); /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead.; app.add_stylesheet('css/custom.css'). Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1307:369,log,logs,369,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307,1,['log'],['logs']
Testability,"@fidelram Since we are not using tight layout when we save figures for the plotting tests, axis labels are cut off. I enabled it to avoid that with the following modification:. <img width=""759"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/110717685-87ba0900-81d7-11eb-8cfd-a1c71155d276.png"">. Here is the new plot testing this PR without the tight layout:. ![master_dotplot_groupby_list_catorder](https://user-images.githubusercontent.com/1140359/110726467-6cef9080-81e7-11eb-971d-e6b87dd92f6e.png). which is pretty bad because what really matters in this plot for this PR is the labels of the x axis. Here is the same plot with the tight layout:. ![master_dotplot_groupby_list_catorder-tightlayout](https://user-images.githubusercontent.com/1140359/110726408-534e4900-81e7-11eb-9931-adae793d099e.png). However, many plotting tests fail now due to this change :/ Do you mind helping me with the failing tests?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1735#issuecomment-796324421:84,test,tests,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1735#issuecomment-796324421,4,['test'],"['testing', 'tests']"
Testability,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why?. Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6?. Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-751396676:38,test,tests,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-751396676,10,['test'],"['test', 'tests']"
Testability,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1531#issuecomment-739436787:1551,log,log-norm,1551,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531#issuecomment-739436787,1,['log'],['log-norm']
Testability,@fidelram sorry it took so long... I've added the param to one of the tests.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1161#issuecomment-653802860:70,test,tests,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1161#issuecomment-653802860,1,['test'],['tests']
Testability,"@fidelram that's a really great point and something I'd like to discuss at next meeting (already put it in the agenda). Another great example of such examples 😅 is the way @michalk8 set it up for [cellrank](https://cellrank.readthedocs.io/en/latest/auto_examples/index.html) and squidpy [not yet public].; The even nicer thing is that @michalk8 implemented a CI pipeline for the tutorials/examples part of the repo so that every time there is a change in master of the original repo, the examples are refreshed in the notebooks repo, so to have them always up to date. Would be really cool to concentrate efforts and try to get this logic also in scanpy (makes it both very user friendly and robust from a maintainer perspective)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1604#issuecomment-765363376:633,log,logic,633,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1604#issuecomment-765363376,1,['log'],['logic']
Testability,"@fidelram, I merged with master and all tests pass. Should be ready to merge.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1417#issuecomment-696939838:40,test,tests,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1417#issuecomment-696939838,1,['test'],['tests']
Testability,"@fidelram, I've updated this so the tests pass, and think I've caught a few more bugs. Hopefully I didn't misinterpret your intent here, but I'm merging as we'd like to get a release out. Please let me know if I've messed anything up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1529#issuecomment-865866325:36,test,tests,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529#issuecomment-865866325,1,['test'],['tests']
Testability,"@fidelram, we are still working paper/preprint. I will post it soon. . I will add tests. So in order for the test to work should I add my library in the requirements.txt? What I observed is that other external packages are not included in project requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/812#issuecomment-537410912:82,test,tests,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812#issuecomment-537410912,2,['test'],"['test', 'tests']"
Testability,"@fidelram. Related to changes made in #794. . If a categorical column is passed in color, but maximum and minimum colors are passed as functions or strings, an error is thrown. It looks like the same error in each case. I think we just need some logic saying to only try and set vmin and vmax for numeric values. ## Example. Setup. ```python; import scanpy as sc; import numpy as np; from functools import partial. pbmc = sc.datasets.pbmc68k_reduced(); ```. Passing a function. ```python; sc.pl.umap(pbmc, color=[""bulk_labels"", ""HES4""], vmax=partial(np.quantile, q=0.99)); ```. <details>; <summary> Traceback </summary>. ```python; ---------------------------------------------------------------------------; UFuncTypeError Traceback (most recent call last); <ipython-input-13-83df06d6a2e8> in <module>; ----> 1 sc.pl.umap(pbmc, color=[""bulk_labels"",""HES4""], vmax=""p99""). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 436 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 437 """"""; --> 438 return embedding(adata, 'umap', **kwargs); 439 ; 440 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 230 ; 231 # check vmin and vmax options; --> 232 kwargs['vmin'], kwargs['vmax'] = _get_vmin_vmax(vmin, vmax, count, color_vector); 233 ; 234 # make the scatter plot. ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_vmin_vmax(vmin, vmax, index, color_vector); 390 f""correct format for percentiles.""); 391 # interpret value of vmin/vmax as quantile with the following syntax 'p99.9'; --> 392 v_value = np.percentile(color_vector, q=float(v_value[1:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/800:246,log,logic,246,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800,1,['log'],['logic']
Testability,"@fidelram. The test `test_matrixplot_obj` fails if `pandas>1.2.0` as the groups order changes. These groups are meant to be sorted with `plot.add_totals(sort='descending')`. All groups have the same value here, so my assumption is this is fine. I'm going to change the test for now, but it'd be good to hear back from you on whether this is a bug or not. It would probably be good if we could ensure a stable sort was used so this won't change in future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1562:15,test,test,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1562,2,['test'],['test']
Testability,"@flying-sheep , haven't considered all combinations yet but wanted to check if this way is good for testing warnings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2563#issuecomment-1682154329:100,test,testing,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2563#issuecomment-1682154329,1,['test'],['testing']
Testability,"@flying-sheep ; Because the paper have not been published, so i can't offer the data to reproduce this problem.; Here are the codes:; ```python; import scanpy as sc; import numpy as np; import pandas as pd; import matplotlib.pyplot as plt; import seaborn as sns; import anndata; import matplotlib as mpl; import scipy; from IPython.core.display import display, HTML; display(HTML(""<style>.container { width:90% !important; }</style>"")). ###settings###; sc.settings.verbosity = 1; sc.logging.print_versions(); results_file = './write/sp.h5ad'; sc.settings.set_figure_params(dpi=150). sp=sc.read('sp_velo.loom'); sc.pp.normalize_total(sp,target_sum=1e6,key_added='norm_factor'); sc.pp.log1p(sp); sp.raw=sp; sc.pp.highly_variable_genes(sp, n_top_genes=2000); sc.pl.highly_variable_genes(sp); sp = sp[:, sp.var['highly_variable']]; sc.pp.combat(sp,key='batch',covariates=['sample']); sc.pp.scale(sp, max_value=10); sc.tl.pca(sp, svd_solver='arpack'); sc.pl.pca_variance_ratio(sp, log=True); sc.pp.neighbors(sp, n_neighbors=10, n_pcs=30); sc.tl.diffmap(sp); sc.pp.neighbors(sp, n_neighbors=20, use_rep='X_diffmap'); sc.tl.louvain(sp,resolution=1); sc.tl.paga(sp); _, axs = plt.subplots(ncols=1, figsize=(24, 10), gridspec_kw={'wspace': 0.05, 'left': 0.12}); sc.pl.paga(sp,color='louvain',layout='fa',pos=pos_coord,threshold=0.2,ax=axs); from scanpy.tools._utils import get_init_pos_from_paga as init; sc.tl.umap(sp,init_pos=init(sp)); sc.pl.umap(sp,color='louvain'); ```; Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/918#issuecomment-555510263:483,log,logging,483,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918#issuecomment-555510263,2,['log'],"['log', 'logging']"
Testability,@flying-sheep @gokceneraslan great! I agree it's hard to compare these algorithms as the performance of an imputation strategy often depends on the downstream use case. I'm looking forward to checking out the countae preprint. I find the [scVI](https://github.com/YosefLab/scVI) benchmark of imputation methods to be useful for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-367680111:279,benchmark,benchmark,279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45#issuecomment-367680111,1,['benchmark'],['benchmark']
Testability,"@flying-sheep Do you want me to resolve your comments as I addressed them or do you prefer to do that yourself? I've seen it done both ways. Once I know, I'll either resolve or not and then re-request your review. The only thing I'm personally still curious about is if you think the tests are ""too"" duplicated still, but there might be other new things/poorly-fixed old things to look at.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2590#issuecomment-1677604847:284,test,tests,284,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590#issuecomment-1677604847,1,['test'],['tests']
Testability,"@flying-sheep For #890 probably we had never tested that combination of parameters because the output was a broking image. . If I understand you correctly, black can by applied to only some lines? Apparently PyCharm can be used with black, do you have any experience?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/893#issuecomment-546330077:45,test,tested,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/893#issuecomment-546330077,1,['test'],['tested']
Testability,@flying-sheep I see that the same tests are failing in other PRs. Do you have any idea what and when some change was introduced that broke the tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/661#issuecomment-495543522:34,test,tests,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495543522,2,['test'],['tests']
Testability,"@flying-sheep I think that your changes should produce images that are almost equal to the ones on the tests as your changes simply introduce a different way to get the colormap. Btw, what is the advantage of using `ListedColormap` and `BoundaryNorm` instead of `LinearSegmentedColormap` ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/369#issuecomment-441619642:103,test,tests,103,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369#issuecomment-441619642,1,['test'],['tests']
Testability,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3196#issuecomment-2271132251:860,test,testing,860,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196#issuecomment-2271132251,1,['test'],['testing']
Testability,"@flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1169:473,test,tests,473,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169,3,['test'],"['testing', 'tests']"
Testability,"@flying-sheep Not sure. Now that you mention it, the rapids benchmark also takes more time than I'd expect as well...The functions themselves are quite fast.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3031#issuecomment-2100566909:60,benchmark,benchmark,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031#issuecomment-2100566909,1,['benchmark'],['benchmark']
Testability,"@flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. ; It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python; def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):; """"""; Choose array aligned with obs annotation.; """"""; is_layer = layer is not None; is_raw = use_raw is not False; is_obsm = obsm is not None; is_obsp = obsp is not None; choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)); assert choices_made <= 1; if choices_made == 0:; return adata.X; elif is_layer:; return adata.layers[layer]; elif use_raw:; return adata.raw.X; elif is_obsm:; return adata.obsm[obsm]; elif is_obsp:; return adata.obsp[obsp]; else:; assert False, (; ""That was unexpected. Please report this bug at:\n\n\t""; "" https://github.com/theislab/scanpy/issues""; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1109:189,test,test,189,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109,3,"['assert', 'test']","['assert', 'test']"
Testability,"@flying-sheep and idea what's up with this build error? Docstrings are failing tests, but look fine to me. Seems related to https://github.com/theislab/scanpy/commit/3cacdc87ab47bae70b415e93f2fea74a018c39e2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/615#issuecomment-488208287:79,test,tests,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-488208287,1,['test'],['tests']
Testability,@flying-sheep can you cite a reference for scImpute and countae outperforming MAGIC? I'd be curious to learn which hyperparameter optimization methods and performance measures were used in the benchmark.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-367378135:193,benchmark,benchmark,193,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45#issuecomment-367378135,1,['benchmark'],['benchmark']
Testability,"@flying-sheep no worries! We'll steadily increase test coverage. I assume that almost no one should have run into the bug in the past 22 days. Among those that updated their version, only very few will have run the PCA with sparse data... @Koncopd, I'm very happy if you move forward with a proper sparse implementation of PCA! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/393#issuecomment-447614569:50,test,test,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-447614569,1,['test'],['test']
Testability,"@flying-sheep, I made two small changes:. * The 10x readers should no longer return views, fixing `test_read_10x`; * Slightly cleaner providing of categories for leiden/ louvain code. For the clustermap test, it's not clear to me that the problems are even related to pandas, though the cause might be: https://github.com/pandas-dev/pandas/issues/18720. There are two images which are compared in this test. I'll post the comparisons here:. # `master_clustermap.png`. I believe the difference is just the margin, so we should be good to just change the test image. ## Expected. ![master_clustermap](https://user-images.githubusercontent.com/8238804/73589759-d73af980-452e-11ea-9a77-89ecf9e752dc.png). ## Actual. ![master_clustermap](https://user-images.githubusercontent.com/8238804/73589766-e5891580-452e-11ea-9762-aa483399c8b3.png). # `master_clustermap_withcolor.png`. This one looks worse, but I'm not sure how to fix it. @fidelram might know better?. ## Expected. ![master_clustermap_withcolor](https://user-images.githubusercontent.com/8238804/73589782-123d2d00-452f-11ea-828c-5e6fdc0b6091.png). ## Actual. ![master_clustermap_withcolor](https://user-images.githubusercontent.com/8238804/73589788-21bc7600-452f-11ea-9661-ec55aeee07de.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1015#issuecomment-581011973:203,test,test,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1015#issuecomment-581011973,3,['test'],['test']
Testability,"@flying-sheep, I'm pretty sure the logical conclusion of any long discussion about types is that everything should be done in Haskell. I don't like the use of branches with `isinstance` because it breaks polymorphism, which is a key part of pythonic code to me. @falexwolf, I completely agree with you on ""what makes a good docstring"". The knowledge overhead for numeric python doesn't include type theory, so the docs should be interpretable without them. Ideally, interfaces are simple and the documentation makes the expected behavior clear. I'm still not sure I totally understand what the intent of the ""type"" vs. ""class"" system is in python, so I'm often a little unsure what to do with heavily typed code. That said, if expected behaviors could be encapsulated (both formally and intuitively) with some abstract types (representing interfaces or traits) that would be a nicer solution. I don't think we're near that point in python. ## Lattices. Sorry about not giving some info on lattices, I'd thought you didn't want to get into it. It's the [partially ordered set kind](https://en.wikipedia.org/wiki/Lattice_(order)) of lattice, where each type is an element or subset. I'll give a short python based example (ignoring that `Union[]` can't be instantiated). <details>. <summary>The code:</summary>. ```python; from typing import Any, Union. class A():; pass. class B(A):; pass. class C(A):; pass. class D():; pass. class E(D):; pass; ```. </details>. that defines a lattice, which can be represented as a DAG like this:. ```; Any; / \; A D; / \ |; B C E; \ | /; Union[]; ```. It's partially ordered in that you can't say A contains E or vice-versa, but you can say things like A is contains B, and `Any` is a supertype of (contains) everything else. I think that how you're viewing it is pretty close, except the elements are types instead of their properties. My mental model has types being a collection of properties, and being a subtype means an object inherits it's supertypes properti",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-444715545:35,log,logical,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-444715545,1,['log'],['logical']
Testability,"@flying-sheep, do you know of a large package (ideally in our dependencies) which uses the directory structure you're advocating for? I'd ideally like to have another repo to look at/ crib from for test organization strategies.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090364103:198,test,test,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090364103,1,['test'],['test']
Testability,"@flying-sheep: After the recent changes I am getting the following error:. ```bash; /apps/scanpy/scanpy/logging.py in _settings_verbosity_greater_or_equal_than(v); 36 def _settings_verbosity_greater_or_equal_than(v):; 37 if isinstance(settings.verbosity, str):; ---> 38 settings_v = _VERBOSITY_LEVELS_FROM_STRINGS[settings.verbosity]; 39 else:; 40 settings_v = settings.verbosity; KeyError: 'warning'; ```. The problem is solved by setting the verbosity level. E.g. ```; sc.settings.verbosity = 3; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/496:104,log,logging,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/496,1,['log'],['logging']
Testability,"@galamm, thanks for the report! Also thanks for the example, very useful!. I think I see what the issue is here, though your error is unexpected. Are you using the most recent version of scanpy (1.7.0)?. The `gene_symbols` argument is supposed to refer to column in `var` that has more human readable gene names. The idea here is that you might have some unique identifier as `var_names` (like ensembl ids), but would have something more interpretable sorted in `adata.var[gene_symbols]`. On my machine, I get a `KeyError` when I run your example since there is no column `""TEST""` in `adata.var`. This is expected. It's strange to me that you get a `NameError`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1636#issuecomment-776540580:574,TEST,TEST,574,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636#issuecomment-776540580,1,['TEST'],['TEST']
Testability,"@giovp ; In the docs it is mentioned that it expects logarithmized data.; As for `raw=True` i am not sure it is a problem. For example, in [the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html) normalized and logarithmized data is saved to `raw` to be used further in `rank_genes_groups`. Do you think it is a problem?. I don't actually consider raw as a container only for raw counts, i think it is a matter of filtered genes vs unfiltered and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/967#issuecomment-795139196:53,log,logarithmized,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967#issuecomment-795139196,2,['log'],['logarithmized']
Testability,"@giovp Cool! I hadn't seen this. If this is referenced in their paper, then multiplex leiden would fit into the category of ""used in sc analysis"" that I was arguing before, and I would be happy with it being in here. I do think that some testing should ideally happen on our side, so it would be great if you want to take this on, @bio-la !",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1818#issuecomment-860807165:238,test,testing,238,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818#issuecomment-860807165,1,['test'],['testing']
Testability,@giovp Could you check why the visium test fails? I don't think it is related to this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2255#issuecomment-1143708886:38,test,test,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255#issuecomment-1143708886,1,['test'],['test']
Testability,"@giovp thanks for your reply, I agree on all points :) Have a good vacation!; @ivirshup Let me know if you have any feedback on the open points or if I can do anything in the meantime (e.g. failing tests, docs, fast-lane HVG).; Cheers, Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-912511459:198,test,tests,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-912511459,1,['test'],['tests']
Testability,"@giovp, @stephenwilliams22, @Zethson. This PR seems to have broken a number of tests. I believe due to the change in `pixel_row`/ `pixel_col` order, resulting in a number of test plots now being transposed. If this was always wrong... surely usage would have caught that, so we must be correcting for this somewhere else. What's the correction here? And is it something that should be done quickly, or should I revert this PR until we can figure it out?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2296#issuecomment-1433124648:79,test,tests,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1433124648,2,['test'],"['test', 'tests']"
Testability,"@giovp, I'll merge this. I'm merging a couple other things first though. I'm not super happy with the logic flow here at the moment. Could we aim for separating out the code for scatter plots, and overlaying grids on-top of images in the next release cycle?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1217#issuecomment-630021238:102,log,logic,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217#issuecomment-630021238,1,['log'],['logic']
Testability,"@gokceneraslan Do you know why the test is failing? Did you change some of the defaults? I like the change, is really an improvement.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/640#issuecomment-495542139:35,test,test,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/640#issuecomment-495542139,1,['test'],['test']
Testability,@gokceneraslan I've been thinking we should have options like `layer` and `obsm` in many more places. I've started trying to implement this in a systemic way with an internal API and some test helpers in: #1173. What would you think of using that here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/959#issuecomment-617017283:188,test,test,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/959#issuecomment-617017283,1,['test'],['test']
Testability,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-761117523:29,test,tests,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-761117523,6,['test'],"['test', 'tests']"
Testability,"@gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/512#issuecomment-469609880:15,Test,Tests,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469609880,1,['Test'],['Tests']
Testability,@gokceneraslan Thanks for looking at this. Can you add test for this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/776#issuecomment-521567791:55,test,test,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/776#issuecomment-521567791,1,['test'],['test']
Testability,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:852,log,log,852,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448,1,['log'],['log']
Testability,"@gokceneraslan Yes, I agree a transparent benchmark repo would be very valuable. . I'd also like to see a detailed breakdown of the limitations of each method or imputation in general. It seems problematic to me to use imputed data for all downstream analyses, for example sub-clustering or DGE analysis, but I can't find a discussion of those limitations anywhere. I'm a little wary of imputation methods being part of a standard toolkit without sufficient discussion of limitations in the documentation somewhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-404866769:42,benchmark,benchmark,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189#issuecomment-404866769,1,['benchmark'],['benchmark']
Testability,"@gokceneraslan here's a quick example:. ```python; import scanpy as sc; pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.pp.highly_variable_genes(pbmc, batch_key=""louvain""). assert not pbmc.var[""highly_variable""].any(); ```. Alternatively:. ```python; pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); pbmc.obs[""batch""] = ""a""; sc.pp.highly_variable_genes(pbmc, batch_key=""batch""); assert not pbmc.var[""highly_variable""].any(). pbmc.obs[""batch""] = ""a""; pbmc.obs[""batch""][::2] = ""b""; sc.pp.highly_variable_genes(pbmc, batch_key=""batch""); assert not pbmc.var[""highly_variable""].any(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-616960210:182,assert,assert,182,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-616960210,3,['assert'],['assert']
Testability,"@gokceneraslan that might have been an issue before... however I have now specified the tests via column and row names, and generated named recarrays, so I'm still looking now...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/583#issuecomment-479508416:88,test,tests,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-479508416,1,['test'],['tests']
Testability,"@grst Thanks it seems logical, but,. It is mentioned in Seurat Pbmc3k example that best resolution parameter is 0.6-1.2 , but you used less and get more clusters. May be because i didn't explore random seed in leiden. ; In louvain and leiden we usually optimize 'modularity' value, what if we just calculate modularity values for different resolution instead of optimizing for given resolution and then for resolution where 'modularity' is maximum, we optimized 'modalarity'. Is this ok ? But i also think that 'modularity' increases when we have small number of clusters. Any suggestion ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-498158306:22,log,logical,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498158306,1,['log'],['logical']
Testability,"@ilan-gold, could you remind me of what you thought should happen with the PCA test case here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1934501172:79,test,test,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1934501172,1,['test'],['test']
Testability,@ivirshup . `exclude: scanpy/tests/_data`. Added for trailing-whitespace and end-of-file-fixer.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1848#issuecomment-848597315:29,test,tests,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1848#issuecomment-848597315,1,['test'],['tests']
Testability,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/797#issuecomment-537023624:153,test,test,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797#issuecomment-537023624,2,['test'],"['test', 'tested']"
Testability,"@ivirshup ; > * Could you show some examples of the new additions/ let me know where you are on tutorials?. I will do that once we are happy with the current code and naming conventions used. My goal was to update this tutorial https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html but suggestions are welcome. . > * Could you add tests for functionality where the underlying code is changing, but doesn't have coverage yet? I would mostly just like to see more tests of the plotting code. I will try to do that. > * What do you think about the idea of splitting up `_anndata.py` into a few more files? I think it's getting a bit too big, which can make reviewing difficult. We should to that. Currently, as I see it we have two types of plots: ; * embedding scatter plots which are separated already; * the type of plots in this PR that I would describe as `grouping` plots, because they visualize the AnnData matrix subdivided based on a .`obs` column. Any better name for this?. > * Could you run `black` over this?. Will do it at the end. Do we have some style policies for black or the defaults are fine?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1127#issuecomment-608262723:357,test,tests,357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127#issuecomment-608262723,2,['test'],['tests']
Testability,"@ivirshup ; Thanks, i'll add tests ofc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1118#issuecomment-600689830:29,test,tests,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1118#issuecomment-600689830,1,['test'],['tests']
Testability,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this?. Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-822033944:183,test,tests,183,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-822033944,1,['test'],['tests']
Testability,"@ivirshup @falexwolf the new black 20 lets users manually control which parameter lists, lists, tuples, dicts, … to explode onto multiple lines. Another advantage is that the removal of e.g. a parameter doesn’t lead to long diffs because they won’t automatically get collapsed again. Finally, it’s useful for e.g. tests or so, where we can format consecutive similar lines of data consistently. I tried to figure out the cleanest version of every spot where black 20 made changes. If you want to change some, or add new spots that can now be formatted more clearly, just create a new PR. This one is supposed to quickly fix Travis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1394:314,test,tests,314,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1394,1,['test'],['tests']
Testability,"@ivirshup @flying-sheep I would like to merge this code but I have some questions:. - Do you know why the test is failing?; - Currently, this is located in `preprocessing`, but I think that the right place is `external.pp` would you agree on that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/797#issuecomment-536570108:106,test,test,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797#issuecomment-536570108,1,['test'],['test']
Testability,"@ivirshup @ilan-gold just got back to this, thought i could not install wsl as I am on a somewhat company restricted laptop, but turns out i can. installing it now (and probably using that from here on out). will run the tester in a bit and let you know",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2039290843:221,test,tester,221,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2039290843,1,['test'],['tester']
Testability,@ivirshup Honestly don't know what I was thinking here- the parameters are clearly not passed through. Perhaps I broke things when rearranging logic in the PR. In in any case I'll submit a fix soon.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1644#issuecomment-781238831:143,log,logic,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1644#issuecomment-781238831,1,['log'],['logic']
Testability,@ivirshup I am getting same numba errors on windows 10 machine. I can test the workaround if you provide a fix. Currently to make the function working I set `percent_top=None`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/843#issuecomment-542784036:70,test,test,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843#issuecomment-542784036,1,['test'],['test']
Testability,"@ivirshup I checked and now I don't get warnings :). However, I could not plot the layer. In the following example, I make a new layer that is the negative of the default layer. As you see, bot the default and the negative ('test') layer are identical. ![image](https://user-images.githubusercontent.com/4964309/61049083-df411980-a3e3-11e9-8508-978a78d7f3b4.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-510456004:225,test,test,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-510456004,1,['test'],['test']
Testability,@ivirshup I didn't notice until now that you requested the review. The code looks ok but I will do some tests.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/713#issuecomment-509109864:104,test,tests,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/713#issuecomment-509109864,1,['test'],['tests']
Testability,@ivirshup I don't know where the crash in the build is coming from I change nothing in those parts. However I rewrote the sparse logic and to me it's now a lot better.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2025622010:129,log,logic,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2025622010,1,['log'],['logic']
Testability,"@ivirshup I don't think so, unless there's work towards https://github.com/scverse/anndata/issues/244. To follow the ideas in https://github.com/scverse/anndata/issues/706, seems like the steps would be:. - [ ] add an attribute `._X_layer` to store which layer `.X` references;; - [ ] use `.X` to reference `.layers[._X_layer]`;; - [ ] add `in_layer=` and `out_layer=` arguments to scanpy's `.pp` functions;; - [ ] these functions will also alter `._X_layer`. The second to last point can actually be implemented irrespective of the AnnData change as `in_layer=None` will mean taking `.X`. ; The question is, should we consider changing the defaults right away, e.g. `in_layer=""counts"", out_layer=""lognorm""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2261#issuecomment-1157056525:698,log,lognorm,698,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-1157056525,1,['log'],['lognorm']
Testability,@ivirshup I tested and now is working as expected. Thanks for adding the new tests. From my side is ready to go.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-510800095:12,test,tested,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-510800095,2,['test'],"['tested', 'tests']"
Testability,@ivirshup I think the benchmarks have shown satisfactory performance of this PR. Should we move on to polishing the code organization?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-591647662:22,benchmark,benchmarks,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-591647662,1,['benchmark'],['benchmarks']
Testability,"@ivirshup I think this needs some tweaking... ```python; import dask.array as da; import numpy as np; import dask. X = da.random.poisson(2, (1_000, ), chunks = (100, )); def nonzero_median(x):; return np.ma.median(np.ma.masked_array(x, x > 0)); dask_median = da.from_delayed(dask.delayed(nonzero_median)(X), shape=(), meta=X._meta, dtype=X.dtype).compute(); np_median = np.median(X.compute()[X.compute() > 0]); np_ma_median = nonzero_median(X.compute()); assert np_median == dask_median; assert np_ma_median == dask_median; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2856#issuecomment-1981155670:455,assert,assert,455,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2856#issuecomment-1981155670,2,['assert'],['assert']
Testability,"@ivirshup I will revert those, and hopefully tests pass",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952629319:45,test,tests,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952629319,1,['test'],['tests']
Testability,"@ivirshup I'd actually be interest in hearing those. My packages also have the test folder outside the package, but I am happy to learn why many major packages have theirs in the actual package and why that might be a good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1528#issuecomment-1089291545:79,test,test,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528#issuecomment-1089291545,1,['test'],['test']
Testability,"@ivirshup I've merged the changes in master from those factored-out PRs, and added a couple of tests. Ready for review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1965#issuecomment-1017444179:95,test,tests,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965#issuecomment-1017444179,1,['test'],['tests']
Testability,"@ivirshup If I remember correctly, you said that there was a specific anndata operation within the scanpy `pca` that was causing the order to change. And you were comparing the output of that to something else that did not do that operation. So my suggestion was to just do that operation and add a note. If you could point me to the test/line of code causing the order to change, I'd have a better sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1935905257:334,test,test,334,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1935905257,1,['test'],['test']
Testability,"@ivirshup In the last few commits, I added some things to skip some unnecessary computation steps (which were only used for logging/warning). Here's a quick example:. ```python; import fsspec; import zarr; from anndata.experimental import sparse_dataset; from anndata import AnnData; import dask.array as da; from dask import delayed; from scipy import sparse. class AccessTrackingStore(zarr.LRUStoreCache):; def __init__(self, *args, **kwargs):; super().__init__(*args, **kwargs). def __getitem__(self, key):; if key not in self._values_cache:; print(key); return super().__getitem__(key). def csr_callable(shape: tuple[int, int], dtype) -> sparse.csr_matrix:; if len(shape) == 0:; shape = (0, 0); if len(shape) == 1:; shape = (shape[0], 0); elif len(shape) == 2:; pass; else:; raise ValueError(shape). return sparse.csr_matrix(shape, dtype=dtype). class CSRCallable:; """"""Dummy class to bypass dask checks""""""; def __new__(cls, shape, dtype):; return csr_callable(shape, dtype). def make_dask_chunk(x, start: int, end: int) -> da.Array:; def take_slice(x, idx):; return x[idx]. return da.from_delayed(; delayed(take_slice)(x, slice(start, end)),; dtype=x.dtype,; shape=(end - start, x.shape[1]),; meta=CSRCallable,; ). def sparse_dataset_as_dask(x, stride: int):; n_chunks, rem = divmod(x.shape[0], stride). chunks = []; cur_pos = 0; for i in range(n_chunks):; chunks.append(make_dask_chunk(x, cur_pos, cur_pos + stride)); cur_pos += stride; if rem:; chunks.append(make_dask_chunk(x, cur_pos, x.shape[0])). return da.concatenate(chunks, axis=0). def read_w_sparse_dask(group, obs_chunk: int = 1000) -> AnnData:; return AnnData(; X=sparse_dataset_as_dask(sparse_dataset(group[""X""]), obs_chunk),; ); ```; After this setup:; ```python; mapper = fsspec.get_mapper(; ""https://vitessce-demo-data.storage.googleapis.com/anndata-demos/BALF_VIB-UGent_processed_cleaned.zarr/""; ); store = AccessTrackingStore(mapper, max_size=2**28); adata = read_w_sparse_dask(zarr.convenience.open_consolidated(store)); ```; T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2856#issuecomment-1983048375:124,log,logging,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2856#issuecomment-1983048375,1,['log'],['logging']
Testability,"@ivirshup Indeed the problem is `use_raw=True` by default. In the test, I think what happens is that the raw data is being plotted and thus no error appears. The tolerance for the image difference may hide the problem if indeed the test image is correct. To avoid this confusion when plotting a layer I think it is better to override `use_raw`. This is how it was supposed to be working before the changes according to the documentation:. ```; layer : typing.Union[str, NoneType], optional (default: None); Name of the AnnData object layer that wants to be plotted. By default; adata.raw.X is plotted. If `use_raw=False` is set, then `adata.X` is plotted.; If `layer` is set to a valid layer name, then the layer is plotted. `layer`; takes precedence over `use_raw`.; ``` ; The current logic is around this lines https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L744. PS: the `use_raw` has been a source of many confusions for me. Now I know when raw is used by default but for new users this may not be obvious. One solution is to add a warning message everytime that `use_raw` is set to `True` by the code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-510785080:66,test,test,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-510785080,3,"['log', 'test']","['logic', 'test']"
Testability,"@ivirshup Looks great! I like the new spatial test image ;) well done!. I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356#issuecomment-678099918:46,test,test,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356#issuecomment-678099918,1,['test'],['test']
Testability,@ivirshup Re: `AssertionError: Error: Image files did not match.` See https://github.com/scverse/scanpy/pull/2815/files#diff-79d72f67d7be639d5fcd7d63a006524d1317f16261044fdeeae6f6da4d14e88aR30-R34 - I suspect the tolerances need to be udpated and checked. I was getting the opposite (I assume) - images that should be different were not picked up as such for sparse plots (like gene rankings).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896481527:15,Assert,AssertionError,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896481527,1,['Assert'],['AssertionError']
Testability,"@ivirshup Thank you for the feedback. I will add a release note soon. I also thought about the naming of the parameter. However, if we assume that also in the future it is mostly used to subset the number of PCs in PCA arrays stored under different names, it should be fine?. I can not comment further on what these changes may break, at least ideally they should make the use of n_pcs more consistent and as expected. Would you suggest, I implement some further, more comprehensive tests?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2179#issuecomment-1076393928:483,test,tests,483,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1076393928,1,['test'],['tests']
Testability,@ivirshup Thanks for letting me know. It will also update for me once 1.10.1 is out. I use the logic from scanpy for this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2964#issuecomment-2021388747:95,log,logic,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2964#issuecomment-2021388747,1,['log'],['logic']
Testability,"@ivirshup The code diff is [here](https://github.com/scverse/scanpy/compare/master...ilan-gold:scanpy:igraph_leiden?expand=1#diff-9b0695a74ff6002a10a74cef4b450792a39038f204ce166f7cce1b3274b77816) but I'll explain the logic of the changes. . 1. `igraph`'s implementation does not allow directed graphs; we throw a ValueError if someone tries to do directed + `igraph`.; 2. `igraph`'s default resolution parameter is 2, so that changed as well. I don't think we should swap it back to -1 for `leidenalg`.; 3. Of course `use_igraph` is now `True` (and a new argument). I'll look into some larger datasets. ~~Also there is no plotting test from what I see. Should we add that?~~",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1892447669:217,log,logic,217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053#issuecomment-1892447669,2,"['log', 'test']","['logic', 'test']"
Testability,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308:14,test,test,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308,3,['test'],"['test', 'tests']"
Testability,"@ivirshup This looks great! Thanks. The issue with the cropping of the labels is quite annoying and indeed `bbox_inches=""tight""` should help. However, I don't think is nice to add that line for each example, but, on the other hand, if we add this to the scanpy code, many figures will be affected and would need to be updated. The same issue also affects the test images which most are cropped.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1632#issuecomment-775750950:359,test,test,359,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1632#issuecomment-775750950,1,['test'],['test']
Testability,"@ivirshup coloring by boolean values `(True, False)` is now possible:. 1) The solution is based on casting the boolean columns to string columns, so that they can be colored in a categorical way. Actual columns in the anndata object are not modified. 2) I was thinking about the case where True is 1 and False is 0. Current behaviour: colorbar is plotted, since 0 and 1 are treated like continuous variables. Does it make sense to handle this case in scanpy?. 3) Tests fail due to new pandas version, they do not fail locally though. . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2460#issuecomment-1500883671:463,Test,Tests,463,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1500883671,1,['Test'],['Tests']
Testability,"@ivirshup okay, I've tried that (thanks for the snazzy function), fingers crossed on tests. This is somewhat involved. When providing adata_sim I had, by design, made the assumption that the user will have done all their own preprocessing. So to make the comparison you requested (sc.external.pp.scrublet with/without adata_sim) I needed to basically replicate all that preprocessing verbatim in the test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2025#issuecomment-969366293:85,test,tests,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2025#issuecomment-969366293,2,['test'],"['test', 'tests']"
Testability,@ivirshup perfectly fine with me.; Removed 3.6 . So we are now testing against 3.7 and 3.8.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1602#issuecomment-763583210:63,test,testing,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1602#issuecomment-763583210,1,['test'],['testing']
Testability,"@ivirshup sorry super late on this, added a default test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1255#issuecomment-657567661:52,test,test,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255#issuecomment-657567661,1,['test'],['test']
Testability,"@ivirshup, the tests now copies the prefix data into a temp dir.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1250#issuecomment-635277251:15,test,tests,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1250#issuecomment-635277251,1,['test'],['tests']
Testability,"@jarny I have the same error still, but when testing on travis it doesn't fail so I have no clue. Locally I create the `__init__.py` file though to make it work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585#issuecomment-480651534:45,test,testing,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-480651534,1,['test'],['testing']
Testability,"@jlause sorry for not getting back. I just had a look at tests and it looks good!; as discussed via email, we would like to first add this to an `experimental` API before including it in code. Tomorrow I will arrange the code slots were you'd have to copy over the functions from their current places. It's a bit of tedious work but shouldn't take much. Will elaborate better on comments!; I will then take care of fixing docs and links. . Another thing still left to be done would be a tutorial on how to use these function and a more elaborate explanation. We will add that tutorial to `scanpy-tutorials` and link from main docs. Maybe you could start already briefly fleshing it out? I'd move the conversation of the tutorial to https://github.com/theislab/scanpy-tutorials",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-873639813:57,test,tests,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-873639813,1,['test'],['tests']
Testability,"@jlause, thanks for figuring this out as well!. A separate PR for this fix would be great. There should definitely be tests targeting this, since changing how the sort is done doesn't seem to break anything.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1733#issuecomment-802581847:118,test,tests,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733#issuecomment-802581847,1,['test'],['tests']
Testability,"@karenlawwc ; For the test.h5ad that you’ve saved using adata.write, I think you want to load it with sc.read_h5ad() rather than sc.read_10x_h5(), since the saved test file will be in AnnData h5ad format",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2246#issuecomment-1255636170:22,test,test,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1255636170,2,['test'],['test']
Testability,@lazappi you are now the chosen one :). Think that using the size attribute like in https://github.com/scverse/scanpy/pull/1985/files is maybe nicer and more explicit. `len()` could technically be overwritten and return anything. It's less explicit. Could you maybe add a quick test which covers this case?. Thank you very much!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2231#issuecomment-1117367877:278,test,test,278,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1117367877,1,['test'],['test']
Testability,@maarten-hifibio we are indeed actively working on this again. Feel free to join our zulip https://scverse.zulipchat.com/login/ and ping me. I can add you to the conversation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793#issuecomment-1102832260:121,log,login,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793#issuecomment-1102832260,1,['log'],['login']
Testability,@meeseeksdev backport to test-backports,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1384#issuecomment-740500580:25,test,test-backports,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1384#issuecomment-740500580,1,['test'],['test-backports']
Testability,"@michalk8 , would be great to add a test for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1161#issuecomment-621051643:36,test,test,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1161#issuecomment-621051643,1,['test'],['test']
Testability,"@michalk8 thanks for the extensive recommendations!. I think I'd like to keep the number of tools used small. It's the worst when you want to fix a bug, but instead have to learn about configuring a linter. More tools means more configurations people need to be familiar with, and the goal is reducing cognitive load. > Also fixing types for `mypy` takes a while, I'd do it as last. Yeah, I figured this would be the case. Does `mypy` allow partial typing these days? Also, I haven't found the numpy or pandas type stubs to always be great. Have you run into problems around this?. I think this would also need to wait at least until we can drop python 3.6 for `anndata`, since adding types there currently means circular dependencies. > `rstcheck` to check the syntax of .rst files. I would particularly like a linter for `rst`. I noticed you also had `doc8`, but you'd recommend `rstcheck` check over this? I'm a little worried, considering its last release was over a year ago. Spell check for prose in doc-strings could also be great, but I could see this being overzealous (is there a good way to notify about misspelled words, while not being annoying about technical terms?). I'm a little worried about some custom sphinx extensions we have, and conflicting with this, any experience here?. --------------------------------------------. @Koncopd, I think I agree with your concern, as I said above: it's the worst when you want to fix a bug, but instead have to learn about configuring a linter. I also think it's very easy to add new checks, so someone complaining about new ones is valuable. Per commit, this should always be an option with `git commit --no-verify`, though you could also just not install `pre-commit`. I would like to keep the required checks limited, ideally formatting tasks that can be automated as opposed ""this is poor style"" warnings. I also know these tools can be wrong (e.g. `black` when expression's have many operators, sometimes with chaining) so it would be goo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-754352635:515,stub,stubs,515,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-754352635,1,['stub'],['stubs']
Testability,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:; ```sh; pip install --user scikit-misc; ```; But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:; ```py; # find the highly variable genes...; # Since we are using seurat_v3 as the flavor,; # we have to do this before normalization; sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', ; n_top_genes=2000). # Normalize and log transform (over all genes); sc.pp.normalize_total(sc96, target_sum=1e4); sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting; # to just the highly variable genes else our normalization ; # for reads will only be counting the subset. # now select the subset; sc96 = sc96[:,sc96.var.highly_variable]; ```; With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1531#issuecomment-1079775692:906,log,log,906,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531#issuecomment-1079775692,1,['log'],['log']
Testability,"@njbernstein Probably not the right place for this discussion, but a couple of follow-up questions for you:; - Do you happen to have a benchmark of `hashsolo` vs the other demuxing algos? It's been on my todo list for ..a while.. but still haven't gotten around to doing it. I've seen the benchmarks of the doublet finding capabilities of `solo` and they look good. As a user of scrublet, it'd be nice to have one tool/codebase that handles both transcriptomic and tag multiplets.; - Are you open to PRs? I'd at least like to have functionality to generate the initial h5ad object containing the tag counts from the output of `CITE-seq-Count`.; - Regarding non-antibody tags, have you noticed celltype-specific preferential binding? I've had problems with LMO/CMOs where not tagging particular celltypes (like some epithelial subtypes where we had 2-3 orders of magnitude lower tag counts).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-759587209:135,benchmark,benchmark,135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-759587209,2,['benchmark'],"['benchmark', 'benchmarks']"
Testability,"@ontsilla We can take a look at this, but I'm not sure if there will be a solution soon. Have you tried using [conda](https://conda.io/en/latest/miniconda.html) on this system? I think it might be your best bet here. @flying-sheep I can recreate with:. ```; conda create -yn testenv python=3.5.2; conda activate testenv; pip install scanpy; python -c ""import scanpy"" ; ```. It looks like there were a lot of bug fixes to python's `typing` module between v3.5.2 and v3.5.4 ([changelog](https://docs.python.org/3.5/whatsnew/changelog.html#python-3-5-4rc1)). I don't get this error with v3.5.4. Are pre-bugfix versions of python supported?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-476952168:275,test,testenv,275,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-476952168,2,['test'],['testenv']
Testability,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072:83,test,tests,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072,1,['test'],['tests']
Testability,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/525#issuecomment-471455638:43,test,test,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471455638,1,['test'],['test']
Testability,"@pati-ni ; I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy.; Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1298#issuecomment-653900843:192,test,tested,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298#issuecomment-653900843,1,['test'],['tested']
Testability,@patrick-nicodemus What we need more than anything is someone to test out a fix and to confirm that using `wsl` prevents the problem. See https://github.com/scverse/scanpy/pull/3041. The issue is that we don't have windows machines.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2328153544:65,test,test,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2328153544,1,['test'],['test']
Testability,"@pedrofale would you be able to add the suggested test for this, please?; If not, @lazappi PR will succeed this one and we will close this one. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1985#issuecomment-1105164387:50,test,test,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985#issuecomment-1105164387,1,['test'],['test']
Testability,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```; 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]; 204Processing /home/travis/build/theislab/scanpy; 205 Installing build dependencies ... done; 206 Getting requirements to build wheel ... done; 207 Preparing wheel metadata ... done; 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'; ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-734643707:18,test,tests,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-734643707,3,"['log', 'test']","['logs', 'test', 'tests']"
Testability,"@pranzatelli, could you open a new issue for this? In that issue, could you also report what versions of the dependencies you're using via `sc.logging.print_versions()`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1823#issuecomment-983618113:143,log,logging,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823#issuecomment-983618113,1,['log'],['logging']
Testability,"@scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1001:51,test,tests,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001,2,['test'],['tests']
Testability,"@shendong124 @ivirshup I assume `normalize_geometric` was intended to be similar to Seurat's centered log ratio transformation, which is implemented as follows in R: `log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm = TRUE) / length(x = x))))`. This is CLR with some safeguards for 0 counts. Here's a reimplementation of the Seurat CLR transformation for scanpy. Call this with `clr_normalize_each_cell(adata)`:. ```; def clr_normalize_each_cell(adata, inplace=True):; """"""Normalize count vector for each cell, i.e. for each row of .X"""""". import numpy as np; import scipy. def seurat_clr(x):; # TODO: support sparseness; s = np.sum(np.log1p(x[x > 0])); exp = np.exp(s / len(x)); return np.log1p(x / exp). if not inplace:; adata = adata.copy(). # apply to dense or sparse matrix, along axis. returns dense matrix; adata.X = np.apply_along_axis(; seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else adata.X); ); return adata; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1208#issuecomment-638496235:102,log,log,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208#issuecomment-638496235,1,['log'],['log']
Testability,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:394,test,test,394,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051,4,['test'],['test']
Testability,@stefanpeidli is currently testing whether scVelo `pl.scatter` entails all scanpy functionality. @fidelram Can you give me a very brief outline of what functionality you added in `pl.embedding` so that I can account for these as well?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/617#issuecomment-554375694:27,test,testing,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554375694,1,['test'],['testing']
Testability,@swolock why don't you submit a PR? I just tested your code and seems to work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-508722585:43,test,tested,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-508722585,1,['test'],['tested']
Testability,"@tomwhite OK, I added this to the release notes (https://github.com/theislab/scanpy/commit/cee23dc13cf2b77d8e23ee0f91eb55fac0e35ed8, sorry confounded with some style change); it would be nice to have a link to your performance benchmarks... Let me know when we should announce it on twitter. I'm also happy to retweet...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/371#issuecomment-456647889:227,benchmark,benchmarks,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/371#issuecomment-456647889,1,['benchmark'],['benchmarks']
Testability,"@wangjiawen2013 we recommend using square root transform with MAGIC but it's certainly not incompatible. So long as the inputs have been library size normalized and transformed with any of log, sqrt, arcsinh or some other sublinear transformation, MAGIC will work just fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/187#issuecomment-403501006:189,log,log,189,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187#issuecomment-403501006,1,['log'],['log']
Testability,"@wflynny `hashsolo` allows you to set a prior for your expected rate negatives, singlets, and doublets, which helps quite a bit with the issue you described despite modeling the log CMO counts as a normal distribution. Additionally, you can also add cell types if you've done cell-type annotation or even leiden clustering labels to help with cell type variability with CMO counts. This helped me quite a bit in kidney where NK cells had far fewer CMO counts than other cells despite being apparently live cells, e.g. good gene diversity and low mitochondrial gene percentage. @fidelram I'd be happy to add a visualization tool like you suggested if you have the code laying around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-759575072:178,log,log,178,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-759575072,1,['log'],['log']
Testability,"A few comments from my endeavors:; - Not sure how good is max scaling on groups for differently strongly expressed genes, especially due to mean-var bias - e.g. 0.8 of max expression for highly expressed genes is probably more meaningful difference than for a lowly expressed one.; - m=0 s=1 z-standardisation can be problematic if you have a small vs large population that has high expression (relatively to the size of whole data) - in former case you get much higher scores than in the latter as whole data seems higher; - If you have many cells doing [0,1] across cells rather than groups and then averaging may be good option as well (see below). Potential problem if you have outlier cells (less likely if log-norm before), but in this case you could normalise from 1st to 99th percentile - still may be problem for rare populations but at least you can regulate the threshold (so better than z-standardisation maybe).; - [0,1] on groups is not too bad when you expect large variation anyway by definition (e.g. plotting top data-defined markers), but agreed too often misleading so should not be default. Example: See gene Trp53bp1 under old - not much difference across groups:; - [0,1] on groups - seems very variable; ![image](https://user-images.githubusercontent.com/47607471/160437189-dd2c3deb-786e-4317-a4cf-fd31fdbd7f19.png); - no normalisation (currently only other option) - bad for multiple marker comparison; ![image](https://user-images.githubusercontent.com/47607471/160437292-daf03941-1e9a-44ed-8942-f2a180ec2c85.png); - max_abs scale on groups - probably still exaggerates variability; ![image](https://user-images.githubusercontent.com/47607471/160456753-c211d7da-1f72-46f3-9355-87eebc649472.png); - [0,1] on cells (before averaging) - the only one that does not exaggerate between group variability; similar with max_abs scaling on cells - probably as some cells are 0 - but much better in terms of time for large sparse matrices. however, this type of normalisation makes dif",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1757#issuecomment-1080962638:712,log,log-norm,712,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757#issuecomment-1080962638,1,['log'],['log-norm']
Testability,"A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066; - [x] merge https://github.com/theislab/scanpy/pull/1111; - [ ] merge #572; - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`; - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`; - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out!; - [ ] rename `log2fc` or similarly: #446; - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want...; - [ ] rename `n_comps` to `n_components` everywhere; - [ ] consider merging https://github.com/theislab/scanpy/pull/403; - [ ] replace default pca solver with 'arpack'; - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs; - [x] merge #621; - [ ] make `pp.highly_variable_genes` return a df instead of a recarray...; - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:; - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/453:262,test,test,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453,3,"['log', 'test']","['logreg', 'test', 'tests']"
Testability,"A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs; - [ ] Set them up with CUDA etc; - [ ] Explore whether GA or Azure suits us better for a custom runner; - [ ] Hook up the custom runner with the ScanPy repository; - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them; - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793:632,test,tests,632,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793,1,['test'],['tests']
Testability,"A number of multithreaded functions and libraries we use default to `os.cpu_count()` number of threads. This is a problem when multiple processes are running in parallel, as is the case when using pytest-xdist. This oversubscription can lead to an increase in test time when multiple workers are used. This PR limits how many threads most libraries use via `threadpoolctl`, and scales this to the number of workers available on the host. I personally see improvements of ~10x when running with this setting on a server with 16 cores, using `-n auto`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2843:260,test,test,260,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2843,1,['test'],['test']
Testability,"A quick reproducible example:. ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); pbmc.X = pbmc.raw.X; sc.tl.rank_genes_groups( ; pbmc, ; groupby=""bulk_labels"", ; groups=[""CD14+ Monocyte"", ""Dendritic""], ; reference=""Dendritic"", ; n_genes=pbmc.shape[1], ; method='wilcoxon' ; ) ; md_d = ( ; sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") ; .set_index(""names"", drop=False) ; ) ; ; sc.tl.rank_genes_groups( ; pbmc, ; groupby=""bulk_labels"", ; groups=[""CD14+ Monocyte"", ""Dendritic""], ; reference=""CD14+ Monocyte"", ; n_genes=pbmc.shape[1], ; method='wilcoxon' ; ) ; md_m = ( ; sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") ; .set_index(""names"", drop=False) ; ). md_d.head(); # scores names logfoldchanges pvals pvals_adj; # names ; # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36; # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35; # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35; # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34; # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32; md_m.tail()[::-1]; # scores names logfoldchanges pvals pvals_adj; # names ; # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33; # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32; # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32; # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31; # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29; ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/754#issuecomment-517541034:721,log,logfoldchanges,721,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754#issuecomment-517541034,3,['log'],"['log', 'logfoldchanges']"
Testability,A rough implementation of glmpca in python is now available here: https://github.com/willtownes/glmpca-py . I will try to get it organized as an installable package tomorrow and add unit tests. Issues/ pull requests welcome.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-541384867:187,test,tests,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-541384867,1,['test'],['tests']
Testability,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/823#issuecomment-718863510:74,test,tests,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823#issuecomment-718863510,5,['test'],"['test', 'testing', 'tests']"
Testability,"AFAICT `ubuntu 16.04` is what they use in most of their examples. Considering many of our users will be on academic clusters, I think old-ish versions of linux are reasonable to test against. The alternative would probably be `ubuntu-18.04`, which we should switch to when `16` is out of support. [Here are the options](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1520#issuecomment-738557948:178,test,test,178,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520#issuecomment-738557948,1,['test'],['test']
Testability,AILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants_equivalent - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:6581,test,test,6581,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['test'],['test']
Testability,ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68521,test,testing,68521,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.pa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74587,test,tests,74587,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.pa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66237,test,testing,66237,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74916,test,testing,74916,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,"About the commit process: That's far far too much work to do it like you suggested. I don't have the time for this. . About the rules: . 1. ""I don't like replacing `x == False` with `not x` in all cases. Sometimes a variable could be a container, and an error should be thrown. I think cases have to be evaluated for this."" . This should be covered by tests. In any case it is not good style and a violation. 2. ""Whats with changing from single letter variables inside expressions? Seems fine to me."". They are redefinitions of earlier variables and trip up flake8. We can call them whatever we want as long it s not `l` again. . 3. ""`lambda's also are generally fine."". See comment at the section. 4. ""Whats up with removing leading `#`s from comments?"" Not my choice either. What we have now is pep8 and flake8 compliant. If you're not happy with this we can ignore the rule. 5. ""So, some of the things you've adding a `# noqa` to look like bugs. I think we need to have a plan in place for doing something about these. Do you have any suggestions?"". The noqa ignore a rule for a specific line. I did not want to ""fix"" these things myself since Python is a dynamic language and you never know what happens :) Ideally we eventually get rid of all noqas, but not in this PR and not by me. I don't know the internals well enough to know whether this could have any side effects.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-785831068:352,test,tests,352,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-785831068,1,['test'],['tests']
Testability,About the preprocessing plots:. `scanpy/tests/notebooks/_images_pbmc3k/filter_genes_dispersion/expected.png`. * Text and some points are shifted slightly. I'm not totally sure whether any points are actually in a different place. `scanpy/tests/notebooks/_images_pbmc3k/highest_expr_genes/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca_variance_ratio/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/scatter_2/expected.png`. * Axis text shifted slightly; * Can probably be reverted if the tests still pass. `scanpy/tests/notebooks/_images_pbmc3k/scatter_1/expected.png`. * y axis moved,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321:40,test,tests,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321,7,['test'],['tests']
Testability,"Actually deploying this is probably blocked by correcting CPU affinities on the benchmarking machine, but writing the code for this should be manageable otherwise.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3013#issuecomment-2275866445:80,benchmark,benchmarking,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013#issuecomment-2275866445,1,['benchmark'],['benchmarking']
Testability,"Actually this broke our tests (you probably missed it because numba broke them before) and has no type annotations. I’d also like to see a few changes, please fix and resubmit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/976#issuecomment-572730320:24,test,tests,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/976#issuecomment-572730320,1,['test'],['tests']
Testability,"Actually, I call bullshit even more:. ```py; class seq_array(np.ndarray):; def __reversed__(self):; return iter(self[::-1]); def index(self, value) -> int:; return np.in1d(self, value).nonzero()[0]; def count(self, value) -> int:; return (self == value).sum(). assert issubclass(seq_array, cabc.Collection); assert issubclass(seq_array, cabc.Reversible); for meth in ""__contains__ __iter__ __reversed__ index count"".split():; assert hasattr(seq_array, meth), meth; print(issubclass(seq_array, cabc.Sequence)); ```. prints `False`. wat.jpg. /edit: Hilarious. Sequence doesn’t implement `__subclasscheck__`, so only things that are `Sequence.register`ed are considered sequences.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/839#issuecomment-531701106:261,assert,assert,261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839#issuecomment-531701106,3,['assert'],['assert']
Testability,Adata.raw gets modified upon log normalization of adata,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3073:29,log,log,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073,1,['log'],['log']
Testability,Add benchmarks,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2977:4,benchmark,benchmarks,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2977,1,['benchmark'],['benchmarks']
Testability,"Add cell_ranger consistency test, fix test file extensions",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2851:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2851,2,['test'],['test']
Testability,Add figure closing teardown for all tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1662:36,test,tests,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662,1,['test'],['tests']
Testability,Add fsspec as a test dependency due to dask,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/765:16,test,test,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765,1,['test'],['test']
Testability,Add test for reading visium 2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2532:4,test,test,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2532,1,['test'],['test']
Testability,Added PAGA plotting tests and merged.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/806#issuecomment-527687681:20,test,tests,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/806#issuecomment-527687681,1,['test'],['tests']
Testability,Added a quick test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1078#issuecomment-593925534:14,test,test,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1078#issuecomment-593925534,1,['test'],['test']
Testability,"Added p-values output to Wilcoxon tests, as discussed in #270. Left most of the code the same (including the chunking). Wilcoxon test now outputs pvals, adjusted pvals (Bonferroni correction), and log fold changes. The change in speed should be much smaller than before:; Original time:; <img width=""468"" alt=""screen shot 2018-10-08 at 4 04 02 pm"" src=""https://user-images.githubusercontent.com/37122760/46632615-43fbda80-cb19-11e8-9a6b-9f6e06dd656c.png"">. New time:; <img width=""481"" alt=""screen shot 2018-10-08 at 4 02 47 pm"" src=""https://user-images.githubusercontent.com/37122760/46632624-4bbb7f00-cb19-11e8-916a-db518ff60791.png"">. I also fixed a bug where the Wilcoxon test would output the absolute values of the scores when rankby_abs=True, which shouldn't happen according to the function description. . As a side note, I was unable to find a quick/efficient way to rank the full sparse matrix for the wilcoxon test, which is why I kept the chunking along genes as suggested. Hope this helps!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289:34,test,tests,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289,5,"['log', 'test']","['log', 'test', 'tests']"
Testability,"Added restrict_to parameter to leiden by using louvain code as template.; Tests are not yet provided. A simple example of execution and checks:. ```python; # First split on cluster 4; sc.tl.leiden(adata, restrict_to=('leiden_res0.4', ['4']), resolution=0.6,; key_added='leiden_res0.4_4_sub'). # Additional split; sc.tl.leiden(adata, restrict_to=('leiden_res0.4_4_sub', ['1', '2', '3', '4,4']),; resolution=0.6, key_added='leiden_res0.4_4_add_sub'). # All partitions together; sc.pl.tsne(adata, color=['leiden_res0.4', 'leiden_res0.4_4_sub',; 'leiden_res0.4_4_add_sub']). # Partition size check; ## Original size of clusters; adata.obs['leiden_res0.4'].value_counts(); 0 932; 1 853; 3 676; 2 676; 4 338; 5 57; Name: leiden_res0.4, dtype: int64. # Check if first split is correct (can be iterated for subsequent splits); ## Assignment of samples in original clusters to subsplit clusters; adata.obs.loc[(adata.obs['leiden_res0.4'].isin(['4'])),; 'leiden_res0.4_4_sub'].value_counts(); 4,0 103; 4,1 68; 4,2 66; 4,3 57; 4,4 44; 5 0; 3 0; 2 0; 1 0; 0 0; Name: leiden_res0.4_4_sub, dtype: int64; ## Assignment of samples not in original clusters to subsplit clusters; adata.obs.loc[~(adata.obs['leiden_res0.4'].isin(['4'])),; 'leiden_res0.4_4_sub'].value_counts(); 0 932; 1 853; 3 676; 2 676; 5 57; 4,4 0; 4,3 0; 4,2 0; 4,1 0; 4,0 0; Name: leiden_res0.4_4_sub, dtype: int64. ...; ```; ![Image](https://user-images.githubusercontent.com/697622/55434369-7553e100-5565-11e9-91ee-0d0396ee6138.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586:74,Test,Tests,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586,1,['Test'],['Tests']
Testability,"Added test for filter_genes_dispersion, updated docs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/343:6,test,test,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/343,1,['test'],['test']
Testability,"Added tests for normalize_total, changed quantile argument name to fraction.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/605:6,test,tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/605,1,['test'],['tests']
Testability,"Added tests, too. (Tests fail in my setup, though. RMS is usually around 50-60, rather than 15.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/512#issuecomment-469320886:6,test,tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469320886,2,"['Test', 'test']","['Tests', 'tests']"
Testability,Adding test for pca.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/466:7,test,test,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/466,1,['test'],['test']
Testability,"Addresses https://github.com/theislab/scanpy/issues/698. Adds some bug fixes and optional tie correction for wilcoxon rank sum test. ```; # tie_correct=False by default; sc.tl.rank_genes_groups(adata, ..., method='wilcoxon', tie_correct=True); ```. Also the test here compares `rank_genes_groups` method `'wilcoxon'` to `scipy.stats.mannwhitneyu`. @idavydov , thanks for the `matrix_tiecorrect` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1330:127,test,test,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1330,2,['test'],['test']
Testability,"Adds median as aggregation function to https://github.com/scverse/scanpy/blob/0f3161295dbf0cf568376c31eaa5c6e148dcf9f0/src/scanpy/get/_aggregated.py; In case of a sparse matrix, it will be converted to dense matrix before calculating median. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3180:329,Test,Tests,329,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180,1,['Test'],['Tests']
Testability,"After clustering cells with a restricted gene set, I would like to see the contribution of ""specified genes"" in subgrouping the cells. ""sc.tl.rank_genes_groups"" uses all the genes in the background for the statistical calculations. I want to test it for all the Louvain groups against the rest of the data (so, groups='all', reference='rest'). Is there a way, we can specify the gene list? (I tried using the 'use_raw' of sc.tl.rank_genes_groups to subset). I don't find any other options to restrict gene lists here. . `subset_genes = ldata[:, ['Gabrg1', 'Ntrk1', 'Htr1a', 'Plaur', 'Il31ra', 'Gabrg3', 'P2rx3', 'Oprk1', 'P2ry1', 'Cnih3']]. sc.tl.rank_genes_groups(ldata, 'louvain', method='wilcoxon', use_raw= 'subset_genes', n_genes = 100). sc.pl.rank_genes_groups(ldata, n_genes=15, sharey=False)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/748:242,test,test,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748,1,['test'],['test']
Testability,"After we switch to scipy t-test, I started getting a scipy warning (`invalid value encountered`) when I run the following the code:. ```python; adata = sc.datasets.paul15(); adata.X[:, 10] = 0.0; sc.tl.rank_genes_groups(adata, 'paul15_clusters'); ```. Output:. ![image](https://user-images.githubusercontent.com/1140359/57115885-88ea9700-6d1f-11e9-8752-a865cda602b7.png). @ivirshup is having a look now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/629:27,test,test,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629,1,['test'],['test']
Testability,"Again, everyone has raised fair points. Thank you for the responses. > Should this process be somehow formalized, e.g. a common issue title like [new method] My new method ?. Yes!. > I also disagree about peer-review being a gold standard about legitimacy of the method: I find it a bit unusual in light of the ever-lasting discussion of peer-review flaws in academia, and I personally use non-peer-reviewed computational tools all the time. Peer-review is not the gold standard. As far as I understand, cell ranger has not been peer reviewed and everyone I know uses it. IMO this particular paper could benefit from the process based on the sorts of claims it makes. > it is not strictly a new method, but has several connections with previous sctransform and glm-pca (also, not sure on what basis you said that ""glm-pca is supposed to be better"", would be genuinely curious to see some evaluations). My point here was to say that historically Scanpy hasn't rushed to add _any_ method that is better than log normalization -> PCA. I was using GLM-PCA as a generic example, but I then realized that coincidentally in the GLM-PCA paper they describe a fast analytical approximation using deviance residuals, which is not compared to in the analytical Pearson residuals manuscript (and again highlights the potential role of peer-review IMO). If deviance residuals give a similar latent space, what do you do then? Add both?. > So, my take is: let's get the pearson residuals from @jlause @dkobak in scanpy, and keep pushing to get the others methods in here as well! at the end, this will ultimately benefit greatly the users. Personally this is how I feel -- the more the better! But historically getting a method in the scanpy core is not so easy (even just seeing the back and forth on the linked issue makes it seem like this is the case for this method). This is why I think it's practically important for Scanpy to be very choosy if it's not going to offer multiple competing workflows with reall",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-799542693:1006,log,log,1006,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-799542693,1,['log'],['log']
Testability,"Ah I think I see the issue! Feature branches should be based off `master` and directing the pull request there! I think what's happening is that a pre-commit hook was installed, but the config only exists on the `master` branch. I think this should largely be manageable by rebasing onto master (e.g. `git rebase --onto master 1.7.x`) and changing the branch the PR is targeting via the github interface:. <img width=""300"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/110570131-9093e600-81a9-11eb-9223-5b7bc233d75c.png"">. --------------. Side note: We're considering separating the `highly_variable_genes` interface into multiple functions, since the arguments to the different methods don't always overlap in meaningful or intuitive ways. There's nothing you need to do about this right now, but just a heads up to keep the logic for this method separate from the main function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-794790768:847,log,logic,847,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-794790768,1,['log'],['logic']
Testability,"Ah, it looks like `use_raw` was being set to True, even if `layers` was passed. . https://github.com/theislab/scanpy/blob/c748b3558b38e908f00b16b0c18e2846d3599e5c/scanpy/plotting/_tools/scatterplots.py#L74-L76. Any idea why this didn't trigger this test?. https://github.com/theislab/scanpy/blob/c748b3558b38e908f00b16b0c18e2846d3599e5c/scanpy/tests/test_plotting.py#L294-L298. Edit: I'm guessing vmin.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-510467988:249,test,test,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-510467988,2,['test'],"['test', 'tests']"
Testability,"Ah, sorry for being in the way here with the unrelated logging changes. Alex is currently a bit ill I learned, which is why he probably didn’t do it yet. I didn’t have time to review the whole thing, but if y’all want I can do that too",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/425#issuecomment-462858876:55,log,logging,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-462858876,1,['log'],['logging']
Testability,"Ah, sorry, maybe this wasn't clear. You need to set the `.raw` attribute of `AnnData` for doing that at some point.; ```; adata.raw = adata # at the point during preprocessing at which you wish store a copy for visualization and differential testing; ```. You can then set `use_raw=False` in several functions, if you want to acess `.X` instead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/168#issuecomment-395589629:242,test,testing,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168#issuecomment-395589629,1,['test'],['testing']
Testability,"Ah, sorry, that was introduced by a PR quite a while ago; fixed it via https://github.com/theislab/anndata/commit/90bea2c1721d5dbfad20975b14809c63cc126ae8. Added a test that will make sure it doesn't happen again in the future:; https://github.com/theislab/anndata/commit/8737bc2c3fe7946fdab0f6f63f36695e86a4b6a3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/547#issuecomment-475415786:164,test,test,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/547#issuecomment-475415786,1,['test'],['test']
Testability,"Ah, thank you! This might break some small things, as you replaced an exact search with an approximate neighbor search. It might not affect the tests as this is hard to test. Nonetheless, you're completely right, there shouldn't be two neighbor functions... I'll briefly check the harder cases and see whether I can reproduce some old notebooks. Please remind me if I don't get back to this very soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/245#issuecomment-416728795:144,test,tests,144,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/245#issuecomment-416728795,2,['test'],"['test', 'tests']"
Testability,"Ah, that makes sense. Either way, I don't think the intent of the function was to have the axis bounds determined by how many DE tests were saved.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1335#issuecomment-666158255:129,test,tests,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335#issuecomment-666158255,1,['test'],['tests']
Testability,"Ah, yeah that's what I meant. If I use `setup()`, the tests on the linux server fail. However, the images generated are similar (RMSD < 10) to images made on my MacBook after running `setup()`. On the PAGA notebook, I saw errors like that when I was playing around with the dpi. Maybe fig size or dpi is being changed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-435728828:54,test,tests,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-435728828,1,['test'],['tests']
Testability,"Ahh, I think this is just because of the way I've tried to translate into to the Scanpy workflow. There's a sparsing step [at the start of the basic Scrublet workflow](https://github.com/swolock/scrublet/blob/67f8ecbad14e8e1aa9c89b43dac6638cebe38640/src/scrublet/scrublet.py#L100), but I'm [injecting](https://github.com/theislab/scanpy/blob/76814588696d00183e5f6f02e64f145dbcf944a0/scanpy/external/pp/_scrublet.py#L360) the normalised matrix and effectively skipping that step. I'll PR a sparsing check and conversion (and yes @ivirshup , I'll add a test :-) ), but the workaround is perfectly valid for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1645#issuecomment-788832663:551,test,test,551,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1645#issuecomment-788832663,1,['test'],['test']
Testability,"Ahh... this makes sense. And this makes it a bit dangerous as well. I would generally compute HVGs after batch correction.. and batch correction generally takes log-normalized data, so the data you have before performing this function will be log-normalized most of the time. I assume this is true not just for me. Maybe log=False should be the default? Or at least a warning should be output I feel.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/172#issuecomment-398721208:161,log,log-normalized,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/172#issuecomment-398721208,3,['log'],"['log', 'log-normalized']"
Testability,"All of the plotting tests are failing for me. Largely this seems based on font rendering. ![highest_expr_genes-failed-diff](https://user-images.githubusercontent.com/8238804/47278908-46c9f580-d618-11e8-99c0-ac5512994ea3.png). Though there might be something more with the violin plots. ![master_violin_multi_panel-failed-diff](https://user-images.githubusercontent.com/8238804/47278943-990b1680-d618-11e8-8e04-8e987c40b90e.png). Is there some setup required to get these tests to pass? My `matplotlibrc` is empty, so I don't think that's the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317:20,test,tests,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317,2,['test'],['tests']
Testability,"All plotting functions should return an ax or an ax list if `show=False`. `_rank_genes_groups_plot` returns whatever the internally called function returns (which could be tracksplot or heatmap etc). However, I don't recall testing this output in all cases. . Can you provide a non working example using the test data? Here you can see how to use one of the test datasets: https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html. I think that @falexwolf can comment on the original reason to set `show=False` to return the axes. . I agree with @Xparx that is more standard to always return the axes as you usually don't dig into the parameter list for this functionality. However, changing this behaviour now could break some code so I don't know if the benefits are greater than the drawbacks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/419#issuecomment-453012463:224,test,testing,224,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453012463,3,['test'],"['test', 'testing']"
Testability,"All plotting tests failing, mostly trivially",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317:13,test,tests,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317,1,['test'],['tests']
Testability,"Alright! I've got a little example case I'd probably be using for a test case [here](https://gist.github.com/ivirshup/2a0d9a785339b719e7d372027ae2df31) (doublet prediction by simulation and projection). My current thoughts:. * Since we need to be working in the same feature space, we'll at least need PCA projection, but this is pretty easy:. <details>; <summary> Basic PCA projection </summary>. ```python; def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings (just whether to center?) from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt; ```. </details>. * Are you planning on storing the UMAP object in the AnnData? That would make transformation easier, but I see how on-disk representation could get complicated.; * What order should we do this in? Would you like everything to be accomplished by this PR or should we break it up?; * Are we introducing a general transfer learning api? Probably worth considering that a bit. Some relevant questions:; * Does the syntax still work for cases other than 1-to-1 transfer? ; * How do we deal with concatenation/ joins? The current `concatenate` doesn't join things like `obsm`.; * Alternatively, does everything have to be in the same AnnData? It would solve issues with having `var` be the same, but could complicate a lot of other code (many functions would need some kind of masking argument).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-481525842:68,test,test,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-481525842,1,['test'],['test']
Testability,Also @flying-sheep coming back to this - why doesn't this break tests? The underlying number generation mechanism is the same somehow? Or similar enough?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3041#issuecomment-2090759838:64,test,tests,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041#issuecomment-2090759838,1,['test'],['tests']
Testability,Also do `pytest -v` for more immediate display of tests (helps to see e.g. when a test hangs),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2468:50,test,tests,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2468,2,['test'],"['test', 'tests']"
Testability,Also posted here: https://scanpy.discourse.group/t/sc-tl-rank-genes-groups-specify-groups-and-implementation-for-multiple-tests/328 to try to follow the issue submission guidelines. . Expanded documentation on how to to use ```sc.tl.rank_genes_groups``` in conjunction with ```sc.get.rank_genes_groups_df``` would be much appreciated.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1360#issuecomment-719807138:122,test,tests,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1360#issuecomment-719807138,1,['test'],['tests']
Testability,"Also sc.tl.dpt and sc.tl.diffmap functions are not tested in tests, AFAICS.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1118#issuecomment-616759417:51,test,tested,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1118#issuecomment-616759417,2,['test'],"['tested', 'tests']"
Testability,Also there are 2 numerical tests here; https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py; https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups_logreg.py,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1081#issuecomment-595753282:27,test,tests,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1081#issuecomment-595753282,3,['test'],['tests']
Testability,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-733652124:56,test,test,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-733652124,1,['test'],['test']
Testability,"Also, I just found time to read the links you posted @davidsebfischer. Shouldn't we always use a welch t-test instead of a t-test in marker gene detection according to your second stackexchange link? They state that If you don't have a good reason to assume equal variances in the groups, then use the Welch correction... if we have a `group` vs `rest` type of setup as we do in `rank_genes_groups()` at the moment, then we would definitely not expect a single cluster to have an equal variance to the combination of all other cells in other clusters. I think the default is currently `t-test-overestimate-var`... being oblivious to exactly how that works, might it not be better to adapt that to a `welch-t-test-overestimate-var` or something like that @falexwolf?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-449358857:105,test,test,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-449358857,4,['test'],"['test', 'test-overestimate-var']"
Testability,"Also, btw, I like the memory-profiler `mprof` sampling plots a lot for this kind of benchmarking. I took a look at this with this script:. <details>; <summary> `sparse_pca.py` </summary>. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k(); sc.pp.log1p(pbmc). @profile; def implicit_mean_pca():; sc.pp.pca(pbmc, pca_sparse=True). @profile; def explicit_mean_pca():; sc.pp.pca(pbmc). @profile; def nomean_pca():; sc.pp.pca(pbmc, zero_center=False). if __name__ == ""__main__"":; implicit_mean_pca(). nomean_pca(). explicit_mean_pca(). ```. </details>. Run with. ```sh; $ mprof run --interval=0.01 ./sparse_pca.py; ...; $ mprof plot; ```. Shows:. ![pca_mem_benchmark](https://user-images.githubusercontent.com/8238804/75006460-f7266300-54c5-11ea-9378-4fedc2c6d73c.png). So this is looking very good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589503209:84,benchmark,benchmarking,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-589503209,1,['benchmark'],['benchmarking']
Testability,"Alternative to #2255. Fixes #2254, #2227. Puts all the diffmap specific logic inside the diffmap plotting function. ## TODO. - [ ] consider the components argument; - [ ] tests (cause it has none apparently)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2280:72,log,logic,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2280,2,"['log', 'test']","['logic', 'tests']"
Testability,"Although `adata.uns['log1p'][""base""] = None` seems work for `tl.rank_genes_groups` the results is weird in my analysis. When I check, logfoldchange, values didn't make any sense. Some of them are almost near 100. Is there any case also or maybe I'm wrong.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2239#issuecomment-1338287283:134,log,logfoldchange,134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1338287283,1,['log'],['logfoldchange']
Testability,"An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python; In [1]: import scanpy as sc ; ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") ; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']; ```. Previous behavior:. ```python; In [1]: import scanpy as sc ; ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") ; ---------------------------------------------------------------------------; NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/444:228,test,tests,228,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444,3,['test'],['tests']
Testability,"An error was raised when values_to_plot=""logfoldchanges"" was provided.; ```python; sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=5,; groupby='leiden_0.1',; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmax=20,; vmin=-20,; key='leiden_0.1_marker_filtered',; show=False; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107458334:41,log,logfoldchanges,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107458334,2,['log'],['logfoldchanges']
Testability,"An implementation of highly deviant gene identification from the 2019 GLMPCA paper. I'm rather fond of the method, as it's a straightforward statistical measure, and comes with significance testing as a form of data-driven cutoff. I put it in a new `highly_deviant_genes()` function, as:; - it comes with a number of unique parameters, and there's only so many different algorithms `highly_variable_genes()` can house; - the paper argues that highly deviant is different from highly variable. I acknowledge that there are no tests, I'm hoping to get some assistance with that if possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1765:190,test,testing,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765,2,['test'],"['testing', 'tests']"
Testability,"An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1080:298,test,testing,298,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080,2,['test'],"['testing', 'tests']"
Testability,"Another error I get and have no idea how to solve is when using the Wilcoxon rank-sum for testing for differential gene expression:. `sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False)`. ```; ranking genes. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-385-c2fa7bb8ea8d> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 352 ; 353 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 354 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 355 scores[np.isnan(scores)] = 0; 356 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. The logistic regression and t-test work fine.; I guess it is related to my data....",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/566:90,test,testing,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566,3,"['log', 'test']","['logistic', 'test', 'testing']"
Testability,Any idea why `scanpy. logging.print_versions()` is reporting a different version that you've reported above it? . Could be that there's an issue with this environment. Can you replicate the issue in a fresh conda environment?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1872#issuecomment-862230678:22,log,logging,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872#issuecomment-862230678,1,['log'],['logging']
Testability,Any one can help?; All my logFoldChange are NAN.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2338#issuecomment-1274522724:26,log,logFoldChange,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338#issuecomment-1274522724,1,['log'],['logFoldChange']
Testability,Any update on this? Can you add a test (probably reusing the example already in the method docstring)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/812#issuecomment-537020598:34,test,test,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812#issuecomment-537020598,1,['test'],['test']
Testability,"Apologies for again, the late response @fidel! I married and moved to the US with twin babies last week. And in between, I spilled something over my laptop... Yes, please go ahead and remove redundant code and add further tests. We'll merge this PR eventually. And yes, we can think about a `develop` branch starting from 1.3. What do you say, @flying-sheep?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-418062501:222,test,tests,222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-418062501,1,['test'],['tests']
Testability,"Apologies for the late response @ivirshup! I married and moved to the US with twin babies last week. And in between, I spilled something over my laptop... I reproduced all the old notebooks. :smile:. PS: As mentioned, things might ""break"" as you replaced something exact with something approximate. The difference becomes pronounced on ""hard datasets"", which are not present in the test of the neighborhood search but only for the ""standard clustering tutorial"", which doesn't use `knn=False`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/245#issuecomment-418072872:382,test,test,382,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/245#issuecomment-418072872,1,['test'],['test']
Testability,"Are the bottom ranked really not expressed, or just not differentially expressed? The former could still have significant p-values. I guess I wonder if you rank by logFC or by adjusted p-value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1529#issuecomment-738210245:164,log,logFC,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529#issuecomment-738210245,1,['log'],['logFC']
Testability,"Are we committing to support sparse-in-dask?. I’m defaulting to `ARRAY_TYPES_SUPPORTED`, which marks sparse as xfail. That’s how we treat other dask-capable utils so far. You can see the errors with. ```console; $ pytest -vv --runxfail scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_{subset_inplace_consistency,no_inplace} -k sparse; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_su",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:243,test,tests,243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122,4,['test'],['tests']
Testability,Argument to compare absolute values of log fold change with `min_fold_change`.; https://github.com/theislab/scanpy/issues/1325; I think `compare_abs` is a better name than `rankby_abs` for this.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1649:39,log,log,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1649,1,['log'],['log']
Testability,"Arguments for and against converting values in `downsample_counts`:. If we don't convert dtypes back to what they originally were, there's a slight performance boost since we don't have to have two copies. I we return an array of integers we run into trouble downstream with functions that aren't tested with integer arrays. Issues from this have been opened a few times, so when I wrote this I thought it might be worth just maintaining the input type. I'm not sure I agree with that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865#issuecomment-552292197:297,test,tested,297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865#issuecomment-552292197,1,['test'],['tested']
Testability,"As a quick test, I tried the weighted version of the louvain method and it was able to identify small clusters that are no identified with the non weighted louvain. However, I did not use `knn=False` as this does not work well with the UMAP representation. Still, I could see differences (eg. cluster 6 and 9 in the top figure):. ![image](https://user-images.githubusercontent.com/4964309/44581659-e85ed300-a79e-11e8-8236-cc149e9c17d4.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-415728359:11,test,test,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/240#issuecomment-415728359,1,['test'],['test']
Testability,"As an additional example, I was thinking about using [zebra-stripes (like a camera)](https://en.wikipedia.org/wiki/Zebra_patterning) for showing when information was hidden. Not sure if it's quite there yet, but its something:. <img width=""1318"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/104683802-c2f60980-574b-11eb-9a96-8d65e853739d.png"">. <details>; <summary> Code </summary>. ```python; import datashader as ds; from datashader import transfer_functions as tf. import numpy as np; import pandas as pd; from scipy import sparse; import xarray as xr. import scanpy as sc. def diagonal_bands_like(arr, width=3):; assert arr.ndim == 2; a = np.zeros_like(arr, dtype=bool); step = a.shape[1] + 1; # Not sure why end isn't making a difference; end = None; # end = a.shape[1] * a.shape[1]; fill = True; for i in range(arr.shape[0]):; if (i + width // 2) % width == 0:; fill = not fill; if fill:; a.flat[i:end:step] = True; return a. # Setup; adata = sc.read(""/Users/isaac/data/10x_mouse_13MM_processed.h5ad"", backed=""r""); df = sc.get.obs_df(; adata,; [""Sox17"", ""louvain""],; obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]; ); louvain_colors = dict(; zip(; adata.obs[""louvain""].cat.categories, ; adata.uns[""louvain_colors""]; ); ); pts = (; ds.Canvas(1000, 1000); .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")); ). # Make images; pts_ncats = (pts != 0).sum(axis=2); overlap_idx = pts_ncats == 1; zebra_source = xr.DataArray(; diagonal_bands_like(overlap_idx, 13),; coords=overlap_idx.coords; ). color_by_cluster = tf.shade(pts, color_key=louvain_colors); tf.Images(; color_by_cluster,; tf.stack(; tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),; tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")); ),; tf.stack(; color_by_cluster,; tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")); ),; ); ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show tho",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1263#issuecomment-760657953:639,assert,assert,639,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263#issuecomment-760657953,1,['assert'],['assert']
Testability,"As an intermediate solution, we could. 1. implement https://github.com/scverse/anndata/issues/679; 2. write recarrays as dataframes; 3. make sure tests run successfully on anndata objects where `adata.uns[""rank_genes_groups_filtered""][""names""]` has been converted into a DataFrame",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/61#issuecomment-1874144812:146,test,tests,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61#issuecomment-1874144812,1,['test'],['tests']
Testability,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):; """"""; Choose array aligned with obs annotation.; """"""; is_layer = layer is not None; is_raw = use_raw is not False; is_obsm = obsm is not None; is_obsp = obsp is not None; choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)); assert choices_made <= 1; if choices_made == 0:; return adata.X; elif is_layer:; return adata.layers[layer]; elif use_raw:; return adata.raw.X; elif is_obsm:; return adata.obsm[obsm]; elif is_obsp:; return adata.obsp[obsp]; else:; assert False, (; ""That was unexpected. Please report this bug at:\n\n\t""; "" https://github.com/theislab/scanpy/issues""; ); ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/828#issuecomment-560072919:401,assert,assert,401,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828#issuecomment-560072919,2,['assert'],['assert']
Testability,"As discussed in issue #313, score_genes function returns different values on various machines. This is due to using float32 dtype in the `np.nanmean` calls. This PR fixes this behaviour by changing the dtype to float64 in the relevant sections of code ie. functions `gene_score()` and `_sparse_nanmean`. Following the suggestion of @ivirshup the returned value is now also float64. I also adapted the tests `test_add_score` and `test_npnanmean_vs_sparsemean` to use and expect float64.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1890:401,test,tests,401,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890,1,['test'],['tests']
Testability,"As far as I can tell, #1527 still doesn't install all packages in a dev installation required to run the entire code base and tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1419#issuecomment-777252906:126,test,tests,126,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1419#issuecomment-777252906,1,['test'],['tests']
Testability,"As in most Python projects, functions that aren’t in the docs are considered private and not for use from different packages. This is therefore a bug in `desc`: eleozzr/desc#13. As a workaround, you can of course assign the function: `scanpy.api.logging.msg = lambda ...: ...`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/895#issuecomment-546839182:246,log,logging,246,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/895#issuecomment-546839182,1,['log'],['logging']
Testability,"As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented.; The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore; * One of the downloaded datasets changed, so the test got updated; * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1344:515,test,test,515,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344,2,['test'],['test']
Testability,AssertionError: Don’t call _normalize_index with non-categorical/string names,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2979:0,Assert,AssertionError,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2979,1,['Assert'],['AssertionError']
Testability,AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2781,Assert,AssertionError,2781,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Assert'],['AssertionError']
Testability,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1143:0,Assert,AssertionError,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143,1,['Assert'],['AssertionError']
Testability,"At some point we changed the return values of the anndata slicing and that is why I think the check for sparse was needed. My recommendation is to replace this whole block. ```python; for g in _gene_names:; if adata.raw is not None and use_raw:; X_col = adata.raw[:, g].X; if gene_symbols:; g = adata.raw.var[gene_symbols][g]; else:; X_col = adata[:, g].X; if gene_symbols:; g = adata.var[gene_symbols][g]; if issparse(X_col):; X_col = X_col.toarray().flatten(); X_col = X_col.toarray().flatten(); new_gene_names.append(g); df[g] = X_col; ```. by ; ```python; df = sc.get.obs_df(adata, _gene_names, use_raw=use_raw, gene_symbols=gene_symbols; new_gene_names = df.columns; ```. `sc.get.obs_df` is a well tested function and using it makes it easier for maintenance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-801174773:703,test,tested,703,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-801174773,1,['test'],['tested']
Testability,AttributeError: module 'scanpy.api.logging' has no attribute 'msg',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/895:35,log,logging,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/895,1,['log'],['logging']
Testability,Auto-metric and fix logs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3186:20,log,logs,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3186,1,['log'],['logs']
Testability,Avoid warning in rank_genes_groups if 't-test' is passed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1303:41,test,test,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1303,1,['test'],['test']
Testability,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1332#issuecomment-665719954:203,benchmark,benchmarking,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332#issuecomment-665719954,2,"['benchmark', 'test']","['benchmarking', 'tests']"
Testability,"B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 # 0,11 stalled cycles per insn ( +- 9,57% ) (83,34%); 	 67.830.590.839 branches:u # 1,093 G/sec ( +- 9,58% ) (83,35%); 	 1.702.825.180 branch-misses:u # 4,56% of all branches ( +- 9,56% ) (83,28%); 	; 	 7,1623 +- 0,0560 seconds time elapsed ( +- 0,78% ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:1316,test,test,1316,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266,4,['test'],"['test', 'tests']"
Testability,BTW I have successfully run the distributed tests with this change (`pytest scanpy/tests/test_preprocessing_distributed.py`).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/439#issuecomment-456365133:44,test,tests,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456365133,2,['test'],['tests']
Testability,"Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:; `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide; Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]); /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide; self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-7-6472f1ef45f7> in <module>(); ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy); 49 dmap.compute_transitions(); 50 dmap.compute_eigen(n_comps=n_comps); ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis; 52 adata.uns['diffmap_evals'] = dmap.eigen_values; 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr); 104 raise ValueError('Can only assign an array of same length ({}), '; 105 'not of length {}.'; --> 106 .format(self.shape[0], arr.shape[0])); 107 # the following always allocates a new array; 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/123:1049,log,logg,1049,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123,1,['log'],['logg']
Testability,Backport PR #1384 on branch test-backports (Fix values_to_plot literal),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1535:28,test,test-backports,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1535,1,['test'],['test-backports']
Testability,Backport PR #1960 on branch 1.8.x (Fix plotting tests for networkx >= 2.6.2),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1961:48,test,tests,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1961,1,['test'],['tests']
Testability,Backport PR #1960: Fix plotting tests for networkx >= 2.6.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1961:32,test,tests,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1961,1,['test'],['tests']
Testability,Backport PR #2063 on branch 1.8.x (Make louvain optional for tests),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2066:61,test,tests,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2066,1,['test'],['tests']
Testability,Backport PR #2063: Make louvain optional for tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2066:45,test,tests,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2066,1,['test'],['tests']
Testability,Backport PR #2150 on branch 1.8.x (Remove global state changes in plotting tests),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2152:75,test,tests,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2152,1,['test'],['tests']
Testability,Backport PR #2150: Remove global state changes in plotting tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2152:59,test,tests,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2152,1,['test'],['tests']
Testability,Backport PR #2274 on branch 1.9.x (Fix tests),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2275:39,test,tests,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2275,1,['test'],['tests']
Testability,Backport PR #2274: Fix tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2275:23,test,tests,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2275,1,['test'],['tests']
Testability,Backport PR #2521 on branch 1.9.x (Fix paga tests),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2525:44,test,tests,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2525,1,['test'],['tests']
Testability,Backport PR #2521: Fix paga tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2525:28,test,tests,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2525,1,['test'],['tests']
Testability,Backport PR #2575 on branch 1.9.x (Simplify tests),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2599:44,test,tests,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2599,1,['test'],['tests']
Testability,Backport PR #2575: Simplify tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2599:28,test,tests,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2599,1,['test'],['tests']
Testability,Backport PR #2589 on branch 1.9.x (Fixed wrong order for groups with logreg),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2600:69,log,logreg,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2600,1,['log'],['logreg']
Testability,Backport PR #2589: Fixed wrong order for groups with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2600:53,log,logreg,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2600,1,['log'],['logreg']
Testability,Backport PR #2601 on branch 1.9.x (fixed `get.rank_genes_groups_df` with logreg),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2606:73,log,logreg,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606,1,['log'],['logreg']
Testability,Backport PR #2601: fixed `get.rank_genes_groups_df` with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2606:57,log,logreg,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606,1,['log'],['logreg']
Testability,Backport PR #2977 on branch 1.10.x (Add benchmarks),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3016:40,benchmark,benchmarks,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3016,1,['benchmark'],['benchmarks']
Testability,Backport PR #2977: Add benchmarks,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3016:23,benchmark,benchmarks,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3016,1,['benchmark'],['benchmarks']
Testability,Backport PR #3031 on branch 1.10.x (Extend benchmarks from basic tutorial),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3056:43,benchmark,benchmarks,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3056,1,['benchmark'],['benchmarks']
Testability,Backport PR #3031: Extend benchmarks from basic tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3056:26,benchmark,benchmarks,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3056,1,['benchmark'],['benchmarks']
Testability,Backport PR #3035 on branch 1.10.x (Fix benchmark test run),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3037:40,benchmark,benchmark,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3037,2,"['benchmark', 'test']","['benchmark', 'test']"
Testability,Backport PR #3035: Fix benchmark test run,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3037:23,benchmark,benchmark,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3037,2,"['benchmark', 'test']","['benchmark', 'test']"
Testability,Backport PR #3057 on branch 1.10.x (Fix testing),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3059:40,test,testing,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3059,1,['test'],['testing']
Testability,Backport PR #3057: Fix testing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3059:23,test,testing,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3059,1,['test'],['testing']
Testability,Backport PR #3069: Upload scrublet scores on test failure,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3242:45,test,test,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3242,2,['test'],['test']
Testability,Backport PR #3089 on branch 1.10.x (Fix and test zappy support),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3090:44,test,test,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3090,1,['test'],['test']
Testability,Backport PR #3089: Fix and test zappy support,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3090:27,test,test,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3090,1,['test'],['test']
Testability,Backport PR #3092 on branch 1.10.x (Move to src / tests layout),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3105:50,test,tests,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3105,1,['test'],['tests']
Testability,Backport PR #3092: Move to src / tests layout,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3105:33,test,tests,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3105,1,['test'],['tests']
Testability,Backport PR #3147: Run benchmarks for off axis,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3166:23,benchmark,benchmarks,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3166,2,['benchmark'],['benchmarks']
Testability,Backport PR #3162 on branch 1.10.x (Fix tests for dask PCA),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3165:40,test,tests,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3165,1,['test'],['tests']
Testability,Backport PR #3162: Fix tests for dask PCA,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3165:23,test,tests,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3165,1,['test'],['tests']
Testability,Backport PR #3177 on branch 1.10.x (Cache data for subsequent test runs),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3179:62,test,test,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3179,1,['test'],['test']
Testability,Backport PR #3177: Cache data for subsequent test runs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3179:45,test,test,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3179,1,['test'],['test']
Testability,Backport PR #3186 on branch 1.10.x (Auto-metric and fix logs),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3187:56,log,logs,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3187,1,['log'],['logs']
Testability,Backport PR #3186: Auto-metric and fix logs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3187:39,log,logs,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3187,1,['log'],['logs']
Testability,Backport PR #3268 on branch 1.10.x (Split up PCA tests),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3269:49,test,tests,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3269,1,['test'],['tests']
Testability,Backport PR #3268: Split up PCA tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3269:32,test,tests,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3269,1,['test'],['tests']
Testability,Backport PR #3292 on branch 1.10.x (Fix benchmark job: Use upstream asv),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3293:40,benchmark,benchmark,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3293,1,['benchmark'],['benchmark']
Testability,Backport PR #3292: Fix benchmark job: Use upstream asv,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3293:23,benchmark,benchmark,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3293,1,['benchmark'],['benchmark']
Testability,Backport PRs #2478 and #2235 on branch 1.9.x (Separate test utils from tests),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2528:55,test,test,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2528,2,['test'],"['test', 'tests']"
Testability,"Basically just a test to make sure the underlying issue is actually corrected. In this example:. ```python; adata_sim = scrublet_simulate_doublets(; adata_obs,; layer='raw',; sim_doublet_ratio=sim_doublet_ratio,; synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,; ); ```. `.layer[""raw""]` should contain integer data, which you should be able to reconstruct from the parent cells, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2025#issuecomment-963265836:17,test,test,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2025#issuecomment-963265836,1,['test'],['test']
Testability,"Below is the traceback:. ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[10], line 1; ----> 1 sc.pl.rank_genes_groups_dotplot(; 2 adata,; 3 n_genes=5,; 4 groupby='leiden_0.1',; 5 values_to_plot=""logfoldchanges"",; 6 cmap='bwr',; 7 vmax=20,; 8 vmin=-20,; 9 key='leiden_0.1_marker_filtered',; 10 show=False; 11 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:874](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=873), in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 741 @_doc_params(; 742 params=doc_rank_genes_groups_plot_args,; 743 vals_to_plot=doc_rank_genes_groups_values_to_plot,; (...); 768 **kwds,; 769 ):; 770 """"""\; 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`); 772 ; (...); 872 tl.rank_genes_groups; 873 """"""; --> 874 return _rank_genes_groups_plot(; 875 adata,; 876 plot_type='dotplot',; 877 groups=groups,; 878 n_genes=n_genes,; 879 groupby=groupby,; 880 values_to_plot=values_to_plot,; 881 var_names=var_names,; 882 gene_symbols=gene_symbols,; 883 key=key,; 884 min_logfoldchange=min_logfoldchange,; 885 show=show,; 886 save=save,; 887 return_fig=return_fig,; 888 **kwds,; 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 529 values_df = None; 530 if values_to_plot is not None:; --> 531 values_df = _get_values_to_plot(; 532 adata,; 533 values_to_plot,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107618181:283,log,logfoldchanges,283,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107618181,1,['log'],['logfoldchanges']
Testability,Benchmark dask,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3319:0,Benchmark,Benchmark,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3319,1,['Benchmark'],['Benchmark']
Testability,"Benchmark results from my laptop:. | | Parallel | Single |; |-|--------|--------|; | Compilation | ~12s | ~5s |; | Run (3k cells, 37k genes) | ~70ms | ~120ms | ; | Run (50k cells, 35k genes) | ~3.8s | ~8.1s | ; | Run (370k cells, 33k genes) | ~13.7s | ~17.4 s |. So... probably worth it? I recall the difference being more pronounced with larger dataset sizes, but that was with a different numba version and maybe a different machine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/844#issuecomment-534015240:0,Benchmark,Benchmark,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844#issuecomment-534015240,1,['Benchmark'],['Benchmark']
Testability,Benchmarking support with asv,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2482:0,Benchmark,Benchmarking,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2482,1,['Benchmark'],['Benchmarking']
Testability,Benchmarks: Add all from Dask tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3013:0,Benchmark,Benchmarks,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013,1,['Benchmark'],['Benchmarks']
Testability,Benchmarks: Add all from basic tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3012:0,Benchmark,Benchmarks,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3012,1,['Benchmark'],['Benchmarks']
Testability,Better CI test results,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1564:10,test,test,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1564,1,['test'],['test']
Testability,"Bioconda builds are failing for `v1.4.4`, https://github.com/bioconda/bioconda-recipes/pull/16473. From the build logs, it looks like this is related to `importlib_metadata` 😕.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/752:114,log,logs,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752,1,['log'],['logs']
Testability,"Both of these files would need some major clean up, some tests and some documentation, also in notebooks. I'm also happy to merge a pull request adding the new functionality, but I can't do this myself right now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/269#issuecomment-426990596:57,test,tests,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/269#issuecomment-426990596,1,['test'],['tests']
Testability,Branch of #1772 to check that CI reporting is made better. Makes some reference based plotting tests fail.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1773:95,test,tests,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1773,1,['test'],['tests']
Testability,Broken Scrublet Test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3068:16,Test,Test,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068,1,['Test'],['Test']
Testability,Broken test: PCA solver “LOBPCG” can’t handle small test data,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2744:7,test,test,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744,2,['test'],['test']
Testability,Broken test: `TestPreprocessingDistributed::test_normalize_per_cell[dask]`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2526:7,test,test,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526,2,"['Test', 'test']","['TestPreprocessingDistributed', 'test']"
Testability,Broken zappy tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3087:13,test,tests,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087,1,['test'],['tests']
Testability,"Btw, I've separated the visium and non-visium case (since they don't share much code), added tests for the visium case, and removed the warnings. I've rebased so I could re-use some test data from another PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-704130199:93,test,tests,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-704130199,2,['test'],"['test', 'tests']"
Testability,Btw. I think scanpy uses Welch's t-test and not the standard t-test. So the comparison with `stats.ttest_ind` is not entirely correct. I guess `stats.ttest_ind` calculates the asymptote of the statistic (`-inf`) and uses that to give a p-value of 0.0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/620#issuecomment-486585476:35,test,test,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620#issuecomment-486585476,2,['test'],['test']
Testability,Btw: I plan to release version 0.1 later today. Together with benchmarks and many examples for the 10x datasets. Any objections?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/16#issuecomment-298884393:62,benchmark,benchmarks,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16#issuecomment-298884393,1,['benchmark'],['benchmarks']
Testability,"Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1240:118,test,test,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240,4,['test'],"['test', 'tests']"
Testability,"Bumping pandas up to 2.1.3 actually requires bumping the versions on a number of other dependencies whose current minimums do not work with pandas 2.1.3. ### ufunc equal. Something is happening in a lot of plotting functions with the `equal` ufunc. ### Numba NotImplementedError. During `test_highly_variable_genes_pearson_residuals_general`. ### AnnData private methods used in tests. A lot of private anndata methods are used at test time. But these didn't exist at the time. Not totally sure what the best solution here is. * Vendoring anndata test helpers over here.; * Literally pulling in the file is probably not so bad; * I will investigate to see how many functions are really needed, possible it's just a few one liners (`as_dense_dask_array` is getting hit often); * Make a new package with just the test helpers? Probably too much of a pain. ### ImportError: cannot import name 'check_is_fitted' from 'sklearn.base'. <details>; <summary> Raw test output </summary>. ```python; FAILED scanpy/tests/test_datasets.py::test_krumsiek11 - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_datasets.py::test_toggleswitch - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_right-groups.all] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.black_tup-na_in_legend.True-legend.on_data-groups.3] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[spatial-na_color.default-na_in_legend.True-legend.on_right-groups.all] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:1711,test,tests,1711,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1713:173,test,tests,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713,1,['test'],['tests']
Testability,"CC @flying-sheep this is an untested as I don't have a windows machine handy to trigger the platform-int-size problem. I'm also somewhat guessing at the fix! From looking at the scanpy source, I don't think that changing the `dtype` of `ns` to a platform consistent and wider `int` will do anything catastrophic to performance or alter the logic in the alg in which it's used as it seems to be a simple index. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1359#issuecomment-670421732:340,log,logic,340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1359#issuecomment-670421732,1,['log'],['logic']
Testability,"CI runs that report coverage currently don't fail if the tests fail. This is because the way the coverage job is written swallows the error. I'm updating this use the same approach as anndata, which seems to be working.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2874:57,test,tests,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2874,1,['test'],['tests']
Testability,Cache data for subsequent test runs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3177:26,test,test,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3177,1,['test'],['test']
Testability,"Cache datasets so notebook tests can run without requiring an external server, since they cover realistic use cases and a good amount of the API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/717:27,test,tests,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/717,1,['test'],['tests']
Testability,"Calculating the variance on 32 bit floats, especially in the value ranges you have for counts, will result in a fair bit of inaccuracy. Because of this, we calculate variance with 64 bit values internally. To demonstrate:. ```python; import scanpy as sc, numpy as np; from scanpy.pp._utils import _get_mean_var. pbmc = sc.datasets.pbmc3k(). var_np32 = np.var(pbmc.X.toarray(), axis=0, ddof=1); var_np64 = np.var(pbmc.X.toarray(), axis=0, ddof=1, dtype=np.float64); _, var_scanpy = _get_mean_var(pbmc.X). # These are close; np.testing.assert_allclose(var_np64, var_scanpy). # Same values are different; assert (np.isclose(var_np32, var_np64) == np.isclose(var_np32, var_scanpy)).all(); ```. We don't use the numpy function for variance because then we'd need to create a dense intermediate array. We've previously used `sklearn.utils.sparsefuncs.mean_variance_axis` but that didn't let us control `ddof` or collect to 64 bit values from 32 bit input.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1732#issuecomment-799050440:526,test,testing,526,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732#issuecomment-799050440,2,"['assert', 'test']","['assert', 'testing']"
Testability,"Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1985:488,test,tests,488,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985,1,['test'],['tests']
Testability,"Came across this while investigating #1032. . ```python; import scanpy as sc; pbmc = sc.datasets.pbmc3k_processed(); sc.pp.highly_variable_genes(pbmc, inplace=False); ```. ```pytb; /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-36b7cb4d9c0f> in <module>; 1 import scanpy as sc; 2 pbmc = sc.datasets.pbmc3k_processed(); ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 347 ('highly_variable_intersection', np.bool_),; 348 ]); --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder); 615 ; 616 if dtype is not None:; --> 617 descr = sb.dtype(dtype); 618 _names = descr.names; 619 else:. TypeError: data type not understood; ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1033:304,log,log,304,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033,2,['log'],['log']
Testability,"Can rank_genes_groups be linked to use diffxpy on top of the available methods? . I am using the following code to convert the output of rank_genes_groups to a data frame, in case is useful:. ```PYTHON; def rank_genes_groups_df(adata, key='rank_genes_groups'):; # create a data frame with columns from .uns['rank_genes_groups'] (eg. names, ; # logfoldchanges, pvals). ; # Ideally, the list of columns should be consistent between methods; # but 'logreg' does not return logfoldchanges for example. dd = []; groupby = adata.uns['rank_genes_groups']['params']['groupby']; for group in adata.obs[groupby].cat.categories:; cols = []; # inner loop to make data frame by concatenating the columns per group; for col in adata.uns[key].keys():; if col != 'params':; cols.append(pd.DataFrame(adata.uns[key][col][group], columns=[col])); ; df = pd.concat(cols,axis=1); df['group'] = group; dd.append(df). # concatenate the individual group data frames into one long data frame; rgg = pd.concat(dd); rgg['group'] = rgg['group'].astype('category'); return rgg.set_index('group'); ```. This results on a table like this:. ![image](https://user-images.githubusercontent.com/4964309/64006299-5789a880-cb12-11e9-9196-305a318b9395.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/723#issuecomment-526515294:344,log,logfoldchanges,344,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/723#issuecomment-526515294,3,['log'],"['logfoldchanges', 'logreg']"
Testability,Can someone at ICB make the S3 bucket happen and give me the login creds? Then I can merge this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-622393426:61,log,login,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-622393426,1,['log'],['login']
Testability,Can we add a test here to find out (or to at least know) how far our implementation here is from https://github.com/scverse/scanpy/pull/3296 for sparse?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3263#issuecomment-2422635711:13,test,test,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263#issuecomment-2422635711,1,['test'],['test']
Testability,"Can we keep this open until the anndata pr has merged? For instance, I'd like to check this all works after merging #1702. I'm a bit concerned about `scanpy.tests` using stuff from `anndata.tests` while those are being ignored from the `sdist`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1700#issuecomment-788509083:157,test,tests,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1700#issuecomment-788509083,2,['test'],['tests']
Testability,"Can you give a dict of deprecated functions and there new analogues? ; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. ; ; ; <!-- Please check (“- [x]”) and fill in the following boxes --> ; - [x] Closes #2505 ; - [x] Tests included or not required because: ; Didn't add decorator to any function(don't know which are deprecated) ; <!-- Only check the following box if you did not include release notes --> ; - [x] Release notes not necessary because: ; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2713:255,Test,Tests,255,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2713,2,['Test'],['Tests']
Testability,"Can you give a dict of deprecated functions and there new analogues?; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ x] Closes #2505 ; - [x ] Tests included or not required because:; Didn't add decorator to any function(don't know which are deprecated); <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2709:249,Test,Tests,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2709,1,['Test'],['Tests']
Testability,"Can you give a dict of deprecated functions and there new analogues?; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2505 ; - [x] Tests included or not required because:; Didn't add decorator to any function(don't know which are deprecated); <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2710:247,Test,Tests,247,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2710,2,['Test'],['Tests']
Testability,"Can you give me the full code you ran for testing and the results from numpy testing for; `np.testing.assert_array_equal(adata.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""])`; `np.testing.assert_array_equal(adata.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data)`.; The first one should give you an error. The second one shouldn't. How big is your dataset?; Please note that if you use scanpy 1.9.6 that changes of this PR won't have taken effect yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952:42,test,testing,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952,4,['test'],['testing']
Testability,"Can you point to a package whose test organization you would like our tests to emulate?. I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib?. Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863:33,test,test,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863,4,['test'],"['test', 'testing', 'tests']"
Testability,"Can you provide an example that we can test for this?. On Fri, Mar 29, 2019 at 8:37 AM jiawen wang <notifications@github.com>; wrote:. > Dear,; > I used sc.pl.rank_genes_groups_heatmap(adata) to create a heatmap of; > top100 marker genes of 8,000 cells, 4 clusters, but it ran slowly, about 30; > times slowers than seurat's Doheatmap(). Could you modify it to accelerate; > the process ?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/569>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1VPvaV-CHAOc88jcDpj8iSlwQgqUks5vbcK7gaJpZM4cRzgZ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/569#issuecomment-477995981:39,test,test,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/569#issuecomment-477995981,1,['test'],['test']
Testability,Can you run black (https://black.readthedocs.io/en/stable/) on the new files. A test is failing because of this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1432#issuecomment-700582572:80,test,test,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432#issuecomment-700582572,1,['test'],['test']
Testability,Can you share the output of `sc.logging.print_versions()` in the environment that's causing you problems?. I'm unable to reproduce with recent cellranger outputs.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2203#issuecomment-1087572087:32,log,logging,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1087572087,1,['log'],['logging']
Testability,Can you type the command you are using? Or better set up a test case. See the example on #293 maybe you can reproduce your problem with that set up.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/286#issuecomment-429728146:59,test,test,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286#issuecomment-429728146,1,['test'],['test']
Testability,Can't get ordinal regression test with multiple processes to run,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/182:29,test,test,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182,1,['test'],['test']
Testability,Cancel that @flying-sheep sheep helped me find a way around to test with `pbmc68k_reduced`. This should speed up Travis again.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/824#issuecomment-530432997:63,test,test,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824#issuecomment-530432997,1,['test'],['test']
Testability,Change test to actually test `read_visium`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2130:7,test,test,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2130,2,['test'],['test']
Testability,Changeset:; * added new MAGIC parameter `knn_max`; * updated MAGIC default parameters to match KrishnaswamyLab/MAGIC; * added tests to check MAGIC implementation interacts with AnnData object correctly; * increased required version of `magic-impute` to 2.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/988:126,test,tests,126,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/988,1,['test'],['tests']
Testability,"Changing it to a property throws a different error:. <details>; <summary> from make html </summary>. ```sh; reading sources... [ 5%] generated/classes/scanpy.pl.DotPlot ; Exception occurred:; File ""/usr/local/lib/python3.8/site-packages/sphinx/util/docfields.py"", line 369, in transform; new_list += fieldtype.make_field(fieldtypes, self.directive.domain, items,; TypeError: make_field() got an unexpected keyword argument 'inliner'; The full traceback has been saved in /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/sphinx-err-qbzn5se8.log, if you want to report the issue to the developers.; Please also report this if it was a user error, so that a better error message can be provided next time.; A bug report can be filed in the tracker at <https://github.com/sphinx-doc/sphinx/issues>. Thanks!; make: *** [html] Error 2; ```. </details>. <details>; <summary> contents of the referenced log file </summary>. ```python; # Sphinx version: 4.1.0; # Python version: 3.8.10 (CPython); # Docutils version: 0.16 release; # Jinja2 version: 2.11.2; # Last messages:; # reading sources... [ 2%] dev/documentation; # reading sources... [ 2%] dev/external-tools; # reading sources... [ 3%] dev/getting-set-up; # reading sources... [ 3%] dev/index; # reading sources... [ 3%] dev/release; # reading sources... [ 4%] dev/testing; # reading sources... [ 4%] dev/versioning; # reading sources... [ 4%] ecosystem; # reading sources... [ 5%] external; # reading sources... [ 5%] generated/classes/scanpy.pl.DotPlot; # Loaded extensions:; # sphinx.ext.mathjax (4.1.0) from /usr/local/lib/python3.8/site-packages/sphinx/ext/mathjax.py; # sphinxcontrib.applehelp (1.0.2) from /usr/local/lib/python3.8/site-packages/sphinxcontrib/applehelp/__init__.py; # sphinxcontrib.devhelp (1.0.2) from /usr/local/lib/python3.8/site-packages/sphinxcontrib/devhelp/__init__.py; # sphinxcontrib.htmlhelp (2.0.0) from /usr/local/lib/python3.8/site-packages/sphinxcontrib/htmlhelp/__init__.py; # sphinxcontrib.serializinghtml (1.1.5",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1946#issuecomment-877995557:540,log,log,540,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946#issuecomment-877995557,2,['log'],['log']
Testability,"Checks if current axis is colorbar before trying to set the name, see #2681.; This might not be the best solution and does not yet integrate a unit test. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2682:148,test,test,148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682,1,['test'],['test']
Testability,Close figures after all tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1671:24,test,tests,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1671,1,['test'],['tests']
Testability,Closes #3211. Lets you run all parts of UMAP in Parallel. Default will still be False for reproducibility. ; Benchmarks (95k Cells AMD5950X); `parallel = False` 33 s; `parallel = True` 18 s. I copied the doc string from UMAP to explain the impact of parallel execution.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3295:109,Benchmark,Benchmarks,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3295,1,['Benchmark'],['Benchmarks']
Testability,Closing due to lack of information. @jsteward2930 please reopen if the problem persists and you can provide us with the logs.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2675#issuecomment-1801420450:120,log,logs,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675#issuecomment-1801420450,1,['log'],['logs']
Testability,"Collection of fixes for pandas 2.0. Interestingly enough, for is_categorical -> is_categorical_dtype we have already made this change in all but one file. I'm suspecting this file is left because this has no tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2434:208,test,tests,208,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2434,1,['test'],['tests']
Testability,"Companion PR to https://github.com/theislab/anndata/pull/434. Basically, I would like to deprecate the `dtype` argument of `AnnData._init_as_actual`, since it mostly just makes unexpected copies of `X`. Since other elements of an AnnData object are passed by reference, it makes sense for this to happen with `X` as well. Right now, this PR will fail CI. What I've done so far is remove all uses of that argument from the scanpy code base, while keeping the tests passing. I'm trying to figure out how to best preserve compatibility with older versions of `anndata`, without throwing too many warnings. I think the thing to do will be make code work with both (`AnnData(X.astype(dtype), dtype=dtype))` should only make one copy) and catch warnings. This can be removed once scanpy depends on `anndata 0.8`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1430:458,test,tests,458,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1430,1,['test'],['tests']
Testability,"Completely agree, Gökcen!. How I just thought about dealing with this in the past couple of minutes: could we not make a submodule *rtools*? We could show the contained wrapper functions on an extra page of the API. All of the dependencies of this would be optional. In effect, this would be a very shallow wrapper that is only interesting for people who already have a working R installation etc. and use Scanpy along with R packages. As there are quite many of these people, this is definitely meaningful. The code would still look proper. Implementing tests for these wrappers is maybe not so important as these are only shallow interfaces. It would be easier to have this in the main scanpy repository than setting up a `scanpy-contrib`: I imagine less people will like to contribute and take the burden of maintaining another repository. PS: `anndata` is a different story. That's something that is meant to be so basic that it doesn't need a lot of maintenance an contributions. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-381984759:555,test,tests,555,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-381984759,1,['test'],['tests']
Testability,Cool solution! Really cool new logging module! :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/676#issuecomment-499025670:31,log,logging,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499025670,1,['log'],['logging']
Testability,"Cool! . > * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them). I think masking out might be problematic because, `n_genes=adata.n_vars` should return all genes in any case. . > * Revert change (would bring back issue of genes with variance of 0). I feel like using scipy function will slightly increase the maintainability (and simplicity) of the code, so I'm fine with keeping the scipy switch. > * Wrap the t-test with something like `np.errstate` to hide the warning. This sounds good. Replacing weird scipy warning with a proper scanpy warning would also make sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/629#issuecomment-489105754:501,test,test,501,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-489105754,1,['test'],['test']
Testability,"Cool! Can you also try to run the test that fails in the PR please?. Should be `PYTHONPATH=. pytest scanpy/tests/test_plotting.py::test_paga_path`. I have no idea why it does that, as it works for me. If it fails for you, please attach the failed-diff image and the corresponding plot image in a comment here (they’re in `scanpy/tests/figures`)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-586339424:34,test,test,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-586339424,3,['test'],"['test', 'tests']"
Testability,"Could this get a test?. Also, should this be documented somewhere?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1111#issuecomment-629592851:17,test,test,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1111#issuecomment-629592851,1,['test'],['test']
Testability,Could you add a test to make sure the correct values are being used?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2025#issuecomment-959531315:16,test,test,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2025#issuecomment-959531315,1,['test'],['test']
Testability,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446:36,test,testing,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446,6,['test'],"['test', 'testing']"
Testability,"Current thinking on the test failures: #2129 was fixed upstream in pandas, so is no longer needed. This is needed, but I can't retrigger the builds because Azure is down in Europe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2120#issuecomment-1040372589:24,test,test,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2120#issuecomment-1040372589,1,['test'],['test']
Testability,Currently output figures are often cut off at the edges. Adding bbox_inches = 'tight' to savefig no longer cuts off figure text at edges. As far as I've tested it this shouldn't cause any other problems and simply saves figures with proper padding.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/118:153,test,tested,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/118,1,['test'],['tested']
Testability,"Currently there are no tests, so those packages aren't actually needed. Looks good to me!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/361#issuecomment-438352107:23,test,tests,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361#issuecomment-438352107,1,['test'],['tests']
Testability,"Currently there's an error being raised because the following images in don't match. path: `scanpy/tests/notebooks/_images_paga_paul15_subsampled/paga_path.png`. **Expected**; ![paga_path](https://user-images.githubusercontent.com/8322751/90666060-de033280-e21a-11ea-83f9-684908586f6e.png). **Actual**; ![paga_path](https://user-images.githubusercontent.com/8322751/90666074-e2c7e680-e21a-11ea-9f08-fc495d6762b0.png). **Diff**; ![paga_path-failed-diff](https://user-images.githubusercontent.com/8322751/90666089-e78c9a80-e21a-11ea-9e0c-4e7e6a80d140.png). I'm going to update expected to match actual, but I need some help to see if this is okay",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1382#issuecomment-676542244:99,test,tests,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1382#issuecomment-676542244,1,['test'],['tests']
Testability,"Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```; >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'); WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; ranking genes; consider 'louvain_resolution_3.0' groups:; with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups; method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics; for group_index, scores, pvals in generate_test_results:; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test; self._basic_stats(); File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats; self.means[imask], self.vars[imask] = _get_mean_var(X_mask); File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var; var *= X.shape[axis] / (X.shape[axis] - 1); ZeroDivisionError: division by zero; ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490:251,test,test,251,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490,1,['test'],['test']
Testability,"Currently, test collection takes about 11 seconds. This seemed a little long so I played around with the config a bit, and found if all the test files names are prepended with `test_`, and I set `python_files = test_*.py`, collection takes about 1 second. Mind if I make that change?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/326:11,test,test,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/326,2,['test'],['test']
Testability,"D scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_color_cycler - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_repeated_colors_w_missing_value - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_no_copy - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[list-named] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-named] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_sim.py::test_sim_toggleswitch - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/anndata-min...; FAILED scanpy/tools/_dendrogram.py::scanpy.tools._dendrogram.dendrogram; FAILED scanpy/tests/test_neighbors.py::test_connectivities_euclidean[gauss] - AssertionError: ; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_one_marker_multiple_colors-fn6] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_multiple_markers_multiple_colors-fn7] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_marker_with_dimensio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:51794,test,tests,51794,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,D scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stack,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2616,Assert,AssertionError,2616,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Assert'],['AssertionError']
Testability,"DENTIAL_04022019.h5ad'); ```; ---------------------------------------------------------------------------; ```; OSErrorTraceback (most recent call last); <ipython-input-11-759ccdc7c8be> in <module>(); ----> 1 adata=sc.read('/gpfs/ysm/pi/zhao/wd262/sc/CONFIDENTIAL_04022019.h5ad'); 2 #> AnnData object with n_obs × n_vars = 312928 × 45947. /ysm-gpfs/pi/zhao/Softwares/Anaconda3/envs/py35/lib/python3.5/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, sheet=sheet, ext=ext,; 77 delimiter=delimiter, first_column_names=first_column_names,; ---> 78 backup_url=backup_url, cache=cache, **kwargs); 79 # generate filename and read to dict; 80 filekey = filename. /ysm-gpfs/pi/zhao/Softwares/Anaconda3/envs/py35/lib/python3.5/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 433 if ext in {'h5', 'h5ad'}:; 434 if sheet is None:; --> 435 return read_h5ad(filename, backed=backed); 436 else:; 437 logg.msg('reading sheet', sheet, 'from file', filename, v=4). /ysm-gpfs/pi/zhao/Softwares/Anaconda3/envs/py35/lib/python3.5/site-packages/anndata/readwrite/read.py in read_h5ad(filename, backed, chunk_size); 442 else:; 443 # load everything into memory; --> 444 return AnnData(*_read_args_from_h5ad(filename=filename, chunk_size=chunk_size)); 445 ; 446 . /ysm-gpfs/pi/zhao/Softwares/Anaconda3/envs/py35/lib/python3.5/site-packages/anndata/readwrite/read.py in _read_args_from_h5ad(adata, filename, mode, chunk_size); 471 f = adata.file._file; 472 else:; --> 473 f = h5py.File(filename, 'r'); 474 for key in f.keys():; 475 if backed and key in AnnData._BACKED_ATTRS:. /ysm-gpfs/pi/zhao/Softwares/Anaconda3/envs/py35/lib/python3.5/site-packages/anndata/h5py/h5sparse.py in __init__(self, name, mode, driver, libver, userblock_size, swmr, force_dense, **kwds); 139 userblock_size=us",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/626:1148,log,logg,1148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/626,1,['log'],['logg']
Testability,DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:26: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:13902,test,test,13902,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,"DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Attempting uninstall: fa2; Found existing installation: fa2 0.3.5; Uninstalling fa2-0.3.5:; Successfully uninstalled fa2-0.3.5; Running setup.py install for fa2 ... error; error: subprocess-exited-with-error; ; × Running setup.py install for fa2 did not run successfully.; │ exit code: 1; ╰─> [212 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running install; running build; running ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:16534,test,test,16534,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['test'],['test']
Testability,"DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; WARNING: No metadata found in /Users/test/.local/lib/python3.10/site-packages; Rolling back uninstall of fa2; Moving to /Users/test/.local/lib/python3.10/site-packages/fa2-0.3.5.dist-info/; from /Users/test/.local/lib/python3.10/site-packages/~a2-0.3.5.dist-info; Moving to /Users/test/.local/lib/python3.10/site-packages/fa2/; from /Users/test/.local/lib/python3.10/site-packages/~a2; error: legacy-install-failure. × Encountered error while trying to install package.; ╰─> fa2. note: This is an issue with the package mentioned above, not pip.; hint: See above for output from the failure.; test@mac ~/PythonPackag",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:29734,test,test,29734,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['test'],['test']
Testability,"Damn … it’s going to be hard to find out why the test fails on Travis then, and I don’t feel comfortable not adding a test. Do we have an Amazon web service (AWS) subscription at ICB that we could use to upload failed image tests?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-586596871:49,test,test,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-586596871,3,['test'],"['test', 'tests']"
Testability,Dask no longer having fsspec as a required dependency means the dask tests fail. This should fix that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/765:69,test,tests,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/765,1,['test'],['tests']
Testability,"Data object for each sample; 2 for sample in sample_list:; ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index); 1111 def __getitem__(self, index: Index) -> ""AnnData"":; 1112 """"""Returns a sliced view of the object.""""""; -> 1113 oidx, vidx = self._normalize_indices(index); 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index); 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1); 34 ax0, ax1 = unpack_index(index); 35 ax0 = _normalize_index(ax0, names0); ---> 36 ax1 = _normalize_index(ax1, names1); 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index); 88 elif issubclass(indexer.dtype.type, np.bool_):; 89 if indexer.shape != index.shape:; ---> 90 raise IndexError(; 91 f""Boolean index does not match AnnData’s shape along this ""; 92 f""dimension. Boolean index has shape {indexer.shape} while ""; 93 f""AnnData index has shape {index.shape}.""; 94 ); 95 positions = np.where(indexer)[0]; 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnData’s shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```; I would appreciate any insights. Thank you so much! ; #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version; version('scanpy'). I got an output: '1.9.1'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2402:3149,log,logging,3149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402,1,['log'],['logging']
Testability,"Dear @wangjiawen2013,. what is the interest behind your question? Do you have many datasets with very few cells?; Scanpy itself can easily work with very small datasets, but you should always be aware of statistical limitations when performing statistical tests etc on very few cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1764#issuecomment-815287672:256,test,tests,256,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1764#issuecomment-815287672,1,['test'],['tests']
Testability,"Dear All,; running the tutorial `pbmc3k.ipynb`. I get a similar error than above:; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-ea8d9dc47463> in <module>; ----> 1 sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace); 115 # a normalized disperion of 1; 116 one_gene_per_bin = disp_std_bin.isnull(); --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(); 118 if len(gen_indices) > 0:; 119 logg.msg(. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key); 909 key = check_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:764,log,logg,764,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264,1,['log'],['logg']
Testability,"Dear all,. I am writing to ask you some other functionalities.; I have just moved from Seurat to Scanpy and I am finding Scanpy a very nice and well done Python package. . 1. I wrote a function to show the 3D plot of the UMAP, tSNE and PCA spaces. In the `scanpy.tl.tsne` function is not possible to change the number of components, it calculates only the first two components, even if the `scanpy.pl.tsne` function has a parameter `component`. May you add a parameter like the `n_components` of the `scanpy.tl.umap` function?. 2. In the `rank_genes_groups` function the log2FC values are provided only for ‘t-test’ based methods. May you return the log2FC values (maybe named log2FC) for all the implemented statistical methods?. 3. I think that two parameters in the `rank_genes_groups` function should be added.; - `min_pCells` to test only the genes that are detected in a minimum fraction of cells of either of the two populations (e.g., cluster 0 vs rest). For instance, min_pCells=0.3 means that at least 30% of the cells must express that gene.; - `positive`, if it is True, the function should return only positive marker genes for each population. 4. A function showing the volcano plots (based on the log2FC) can help (I can write it if the log2FC values are provided). Thank you in advance.; Best,; Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460:610,test,test,610,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460,2,['test'],['test']
Testability,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. ; I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. ; _name_list_ is a string containing gene names and should be specified. ; _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data ; _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/72#issuecomment-361891662:361,test,testing,361,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72#issuecomment-361891662,2,['test'],"['tested', 'testing']"
Testability,"Dear developers, . in an attempt to instal the latest version of scanpy from GitHub (Master branch), I receive the following error:. Traceback (most recent call last):; File ""/home/vladie/PycharmProjects/PY3/RPE_MYCN_10X.py"", line 4, in <module>; import scanpy.external as sce; File ""/usr/local/lib/python3.6/dist-packages/scanpy/__init__.py"", line 33, in <module>; from . import datasets, logging, queries, external; File ""/usr/local/lib/python3.6/dist-packages/scanpy/external/__init__.py"", line 1, in <module>; from . import tl; File ""/usr/local/lib/python3.6/dist-packages/scanpy/external/tl.py"", line 4, in <module>; from ._tools._palantir import palantir; ModuleNotFoundError: No module named 'scanpy.external._tools'. I would like to run palentir through Scanpy, is this already possible ? ; Kind regards,; Vladie0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/601:390,log,logging,390,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601,1,['log'],['logging']
Testability,"Dear everyone,. This PR adds; 1. Python 3.8 to the build matrix. We were currently only testing vs 3.6 and 3.7. 3.10 is already coming up in April, so it is in my opinion time to use the more latest Python versions. If you feel like this adds too much to the Azure/CI bill, then I would suggest to remove 3.6. ; 2. Solves #1585 . Signed-off-by: Zethson <lukas.heumos@posteo.net>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1602:88,test,testing,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1602,1,['test'],['testing']
Testability,"Dear scanpy Team,; I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? ; Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2180:372,log,log,372,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180,1,['log'],['log']
Testability,"Dear scanpy team,. In your CITE-seq vignette you use the function `sc.pp.normalize_geometric(protein)` to normalize CITE-seq data. However, I think the description and motivation for the method are not detailed enogh to understand what is going on under the hood. Could you please give me a brief explanation on how that works? I've been using the centered log-ratio in Seurat, but there is definetely room for improvement. Thanks a lot for you time and help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1469:357,log,log-ratio,357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469,1,['log'],['log-ratio']
Testability,"Dear scanpy-team,. thank you very much for this great package!. Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,; Tarik",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2671:547,test,test,547,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671,1,['test'],['test']
Testability,"Define `.uns['neighbors']['distances']` as the distance matrix instead of the weighted adjacency matrix in logg.hint. By the way, when `knn=True`, distances to non-neighbor data points are stored as zero in this matrix to keep it sparse, right? But technically these are not zeros, but rather ""unknown values"". Does it make sense to add a note in the documentation about that? Because for `knn=False`, the semantics of zeros change completely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/441:107,log,logg,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441,1,['log'],['logg']
Testability,"Definitely a heavy dependency, you should see the size of the conda environment you need to test it. I think it'd be useful for playing around with ideas on how you'd like to aggregate and scale the values, since they've already got a bunch of methods implemented. Plus the plots often look pretty good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/575#issuecomment-479510188:92,test,test,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-479510188,1,['test'],['test']
Testability,"Definitely love to have more contributions! I believe @LuckyMD and @giovp are quite keen on having this in the library. Excited to see your benchmarks!. Side note: I'd definitely recommend looking into using `joblib` instead of `multiprocessing` for parallelization. It's a bit more simple to use, is much better about not oversubscribing your resources, and copying less data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-777194405:140,benchmark,benchmarks,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643#issuecomment-777194405,1,['benchmark'],['benchmarks']
Testability,"DeprecationWarning is silenced by [default](https://python.readthedocs.io/en/stable/library/warnings.html#default-warning-filters), for not annoying users. But I get all when running unit tests with pytest. Here with all warnings enabled:; ```pycon; >>> import warnings; >>> warnings.filterwarnings(""always""); >>> import scanpy as sc; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.pca(adata); >>> sc.pp.neighbors(adata); >>> sc.tl.leiden(adata, flavor=""igraph"", n_iterations=2); …/lib/python3.9/site-packages/scanpy/tools/_leiden.py:185: DeprecationWarning: resolution_parameter keyword argument is deprecated, use resolution=... instead; part = g.community_leiden(**clustering_args); ```. ```shell; $ pip freeze | grep -E ""anndata|scanpy|igraph|python-igraph|leidenalg""; anndata==0.10.7; igraph==0.11.5; leidenalg==0.10.2; python-igraph==0.11.5; scanpy==1.10.1; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2865#issuecomment-2123565254:188,test,tests,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2865#issuecomment-2123565254,1,['test'],['tests']
Testability,"Description of the bug for anyone interested. As @SabrinaRichter and @TyberiusPrime noted, `sc.pp.highly_variable_genes` modified the `layer` used in one case, which is; 1. `sc.pp.log1p(adata, base=b)` with `b != None` has been done (so another log than the default natural logarithm); 2. `sc.highly_variable_genes(adata, flavor='seurat') `has been used (note that flavor='seurat' is the default). (Reproducible) example:. ```py; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts=1); sc.pp.log1p(adata, base=10). print('original'); print(adata.X.A[1:6,10:15]). sc.pp.highly_variable_genes(adata, flavor='seurat'); print('after hvg'); print(adata.X.A[1:6,10:15]); ```. Output; ```; original; [[0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.30102998]; [0. 0. 0. 0. 1. ]; [0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.30102998]]; after hvg; [[0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.6931472]; [0. 0. 0. 0. 2.3025851]; [0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.6931472]]; ```. The modification of the data which happened in this case is a rebasing; the data in X is log1p transformed with the natural logarithm, instead of the logarithm previously selected by the user. This is unintended and fixed for the next scanpy version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2668#issuecomment-1768622814:245,log,log,245,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668#issuecomment-1768622814,4,['log'],"['log', 'logarithm']"
Testability,Did anyone run scanpy tests with umap 0.4 branch?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/784#issuecomment-522566850:22,test,tests,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/784#issuecomment-522566850,1,['test'],['tests']
Testability,"Didn’t you rephrase the message?. > scanpy/tests/test_read_10x.py: +3 -1; > ; > This above file has < {thresh} changes to black formatting. Please black format it and afterwards remove it from “tool.black.exclude"" in pyproject.toml. Anyway, it should be “remove it from ‘tool.black.exclude’ *and then* black-format it”, as black won’t run on it if it’s excluded.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/989#issuecomment-577155563:43,test,tests,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/989#issuecomment-577155563,1,['test'],['tests']
Testability,Do you guys still want me to try and run the test from @ilan-gold ? Or is it fine now that it is reproduced on your side as well?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2042430100:45,test,test,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2042430100,1,['test'],['test']
Testability,"Do you mean to add a test for TravisCI (sorry, I'm new to this)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1070#issuecomment-590137345:21,test,test,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1070#issuecomment-590137345,1,['test'],['test']
Testability,"Do your input objects have different `dtype` values in `X`? I suspect that is what's causing this. If so, are the results very different? I would expect normalizing 64 bit vs 32 bit values to not be exactly the same (which is what `np.array_equal` is testing), but it's not good if the function is returning very different values. You can check this with `np.all_close`/ `np.isclose` or by looking at the distribution of the differences of the results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1612#issuecomment-768657586:251,test,testing,251,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1612#issuecomment-768657586,1,['test'],['testing']
Testability,"Does scanpy store log fold change, p-value and marker type flag (negative vs positive) somewhere? It looked at scObj.uns[""rank_genes_groups""] but found only 3 fields: params, scores and names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159:18,log,log,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159,1,['log'],['log']
Testability,Done! I've changed the random vector generation to use the code you suggested and added a test to test_embedding.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1858#issuecomment-864529782:90,test,test,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858#issuecomment-864529782,1,['test'],['test']
Testability,Done! Tests fixed in 478e3dcb4706328bb3726fb674473e490f353a33,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/162#issuecomment-392000010:6,Test,Tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162#issuecomment-392000010,1,['Test'],['Tests']
Testability,"Due to a misconfiguration in Travis setup, all tests are now running only with Python 3.7 now and there is a mysterious HDF error somewhat related to Python 3.7 and pytables.; Python version is fixed in https://github.com/theislab/scanpy/pull/201, so until we have Python 3.7 tests, we are good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/199#issuecomment-405085782:47,test,tests,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/199#issuecomment-405085782,2,['test'],['tests']
Testability,ED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[dask_array_dense-single] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[dask_array_dense-batched] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_compare_to_upstream[seurat-hvg] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_pca.py::test_pca_sparse - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_pca.py::test_pca_reproducible[numpy_ndarray] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_pca.py::test_pca_reproducible[scipy_csr] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_pca.py::test_pca_reproducible[scipy_csc] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_pca.py::test_pca_reproducible[dask_array_dense] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_pca.py::test_pca_chunked - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_pca.py::test_pca_n_pcs - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_pca.py::test_pca_layer - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_plotting.py::test_scrublet_plots[scrublet] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_plotting.py::test_scrublet_plots[scrublet_no_threshold] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_plotting.py::test_scrublet_plots[scrublet_with_batches] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_preprocessing_distribut,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:2295,test,tests,2295,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['test'],['tests']
Testability,ED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exc,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49501,test,tests,49501,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62053,test,tests,62053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63367,test,tests,63367,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23196,test,testing,23196,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['test'],['testing']
Testability,ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68112,test,tests,68112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"Each dataset’s documentation should contain. 1. what it contains (listing obs, …); 2. what steps have been run on it; 3. better links (e.g. is pbmc68k_reduced [this one](https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0)? the docstring isn’t clear. It was added by @fidelram in https://github.com/scverse/scanpy/pull/228 …). Especially important is if its `.X` is logarithmized, normalized, and/or filtered. See also: https://github.com/orgs/scverse/projects/18/views/1?pane=issue&itemId=62702062. cc @ilan-gold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3051:394,log,logarithmized,394,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051,1,['log'],['logarithmized']
Testability,Enable scrublet tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2776:16,test,tests,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2776,1,['test'],['tests']
Testability,Enforce stable cluster order in notebook test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2650:41,test,test,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2650,1,['test'],['test']
Testability,"Err, hopefully this isn't inconvenient. Here's a zip file containing the relevant notebook.; [benchmarks_PR1066.zip](https://github.com/theislab/scanpy/files/4234288/benchmarks_PR1066.zip). Benchmarking was done on the raw pbmc3k data. . Summary of the timing and memory results:. With `pca_sparse=False`,; ```; %%memit; t=time.time(); sc.tl.pca(adata1,pca_sparse=False,svd_solver='arpack',random_state=0,zero_center=True); print(str(time.time()-t)+' seconds'); ```; ```; 6.122049570083618 seconds; peak memory: 1332.33 MiB, increment: 1047.04 MiB; ```. With `pca_sparse=True`,; ```; %%memit; t=time.time(); sc.tl.pca(adata2,pca_sparse=True,random_state=0); print(str(time.time()-t)+' seconds'); ```; ```; 2.373802423477173 seconds; peak memory: 401.17 MiB, increment: 56.26 MiB; ```. There are very slight differences between the eigenvalues output by the different methods, which translates to slightly different cluster assignments when using euclidean distance (this is probably exacerbated by the fact that I am benchmarking on raw data). However, for correlation distance, the output is exactly the same. See the attached notebook for more details.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589495486:190,Benchmark,Benchmarking,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-589495486,2,"['Benchmark', 'benchmark']","['Benchmarking', 'benchmarking']"
Testability,Especially weird for since (at least for `scvelo 0.1.25`):. ```python; import scanpy; import scvelo; import anndata; assert scvelo.read_loom == scanpy.read_loom == anndata.read_loom; assert scvelo.read == scanpy.read; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1074#issuecomment-592301994:117,assert,assert,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074#issuecomment-592301994,2,['assert'],['assert']
Testability,"Especially when we visualize raw counts, sometimes it's hard to see the differences between the expression of one gene across cell types in the heatmap since one value can simply dominate the dynamic range of expression. I think we can add a scaling option to matrixplot, which squashes expression values between 0 and 1 to make markers more pronounced. Heatmap of the raw values:. ![image](https://user-images.githubusercontent.com/1140359/53700880-06983200-3dc5-11e9-8bd6-e001fd3d078d.png). Heatmap of the logarithmized values (which also helps a bit but not for all genes):. ![image](https://user-images.githubusercontent.com/1140359/53700890-19ab0200-3dc5-11e9-872d-791eec295262.png). Heatmap of the col-normalized values:. ![image](https://user-images.githubusercontent.com/1140359/53700893-2c253b80-3dc5-11e9-968d-b7a89eb65fbc.png). PS: The option is actually borrowed from Seaborn (https://seaborn.pydata.org/generated/seaborn.clustermap.html). . PPS: There is an edge case such as division by zero. Also, `swap_axes` option makes 'row'/'col' naming a bit confusing. Let me know if you have suggestions about these or the standardization idea in general.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/512:508,log,logarithmized,508,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512,1,['log'],['logarithmized']
Testability,"Even something simple doesn't work anymore, without going through h5ad:. ```; adata = adata[adata.obs['n_genes'] < up_thrsh_genes, :]; Traceback (most recent call last):; File ""/cluster/home/max/projects/czi/cellBrowser/src/cbScanpy"", line 11, in <module>; cellbrowser.cbScanpyCli(); File ""/cluster/home/max/projects/czi/cellBrowser/src/cbPyLib/cellbrowser/cellbrowser.py"", line 4655, in cbScanpyCli; adata, params = cbScanpy(matrixFname, metaFname, inCluster, confFname, figDir, logFname); File ""/cluster/home/max/projects/czi/cellBrowser/src/cbPyLib/cellbrowser/cellbrowser.py"", line 4353, in cbScanpy; adata = adata[adata.obs['n_genes'] < up_thrsh_genes, :]; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py"", line 1224, in __getitem__; return self._getitem_view(index); File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py"", line 1228, in _getitem_view; return AnnData(self, oidx=oidx, vidx=vidx, asview=True); File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py"", line 557, in __init__; self._init_as_view(X, oidx, vidx); File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py"", line 629, in _init_as_view; self._raw = adata_ref.raw[oidx]; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py"", line 333, in __getitem__; oidx, vidx = self._normalize_indices(index); File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py"", line 361, in _normalize_indices; obs = _normalize_index(obs, self._adata.obs_names); File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/anndata/core/anndata.py"", line 160, in _normalize_index; positions = positions[index]; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/series.py"", line 911, in __getitem__; return self._get_with(key); File ""/cluster/home/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-508526138:480,log,logFname,480,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-508526138,1,['log'],['logFname']
Testability,"Everything runs fine on the current master branch, I uploaded the current version of the notebook: https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/paul15/paul15.ipynb. I'll release either 1.3.3 or 1.4 very soon and if there should have been a bug at some point, it seems to have been fixed at some point. Finally, PAGA is also in the continuous integration tests, so no bugs in the future anymore for this. ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/333#issuecomment-435728872:377,test,tests,377,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333#issuecomment-435728872,1,['test'],['tests']
Testability,Example of this kind of bug in https://github.com/theislab/anndata/issues/293. * Now `read_10x_mtx` does not set an integer name for obs_name/ var_name indices; * Additionally improved code re-use and things tested in 10x reading tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/989:208,test,tested,208,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/989,2,['test'],"['tested', 'tests']"
Testability,"Example using scanpy 9dd2e94846aa and anndata `762fdb924e757cdd758231`. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(); sc.pl.umap(pbmc, color=""louvain"") # To make sure that ""louvain_colors"" has been made; bcells = pbmc[pbmc.obs[""louvain""] == ""B cells""]; # This line triggers a copy being made:; sc.pl.umap(bcells); # /Users/isaac/github/anndata/anndata/_core/anndata.py:1120: ImplicitModificationWarning: # Initializing view as actual.; # ""Initializing view as actual."", ImplicitModificationWarning,; assert not bcells.is_view; ```. Pretty sure that shouldn't be making a copy, since nothing should be modified in the view. To make sure:. ```python; from anndata.tests.helpers import assert_equal. bcells_view = pbmc[pbmc.obs[""louvain""] == ""B cells""]; assert_equal(bcells, bcells_view, exact=True); ```. This also seems to be happening with some of the other plotting functions, like `sc.pl.rank_genes_groups_dotplot`. Elaborating a bit:. To me this is an issue since it will use quite a lot of memory for cases where it isn't needed. Why copy a large number of arrays when you don't need to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1000:525,assert,assert,525,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1000,2,"['assert', 'test']","['assert', 'tests']"
Testability,Extend benchmarks from basic tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3031:7,benchmark,benchmarks,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031,1,['benchmark'],['benchmarks']
Testability,Extended gex_only function to visium. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3113; - [x] Tests included or not required because: It's a straightforward argument pass from visium to read_10x_h5; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: not a big change,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3278:363,Test,Tests,363,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3278,1,['Test'],['Tests']
Testability,"Extracting it would be great. What triggered the test to fail on other branches, I'd assume a matplotlib update?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1598724173:49,test,test,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1598724173,1,['test'],['test']
Testability,FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:5572,test,tests,5572,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['test'],['tests']
Testability,FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plot,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48956,test,tests,48956,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"FYI, it appears that this bug remains in louvain version 0.7 ; ```python; In [1]: import numpy as np; ...: import scanpy as sc; ...:; ...: adata = sc.AnnData(np.random.normal(size=(100,3))); ...:; ...: sc.pp.neighbors(adata); ...: sc.tl.louvain(adata); ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-1-3505d1878068> in <module>; 5; 6 sc.pp.neighbors(adata); ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy); 136 partition_kwargs[""weights""] = weights; 137 logg.info(' using the ""louvain"" package of Traag (2017)'); --> 138 louvain.set_rng_seed(random_state); 139 part = louvain.find_partition(; 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__; Out[3]: '0.7.0'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1191#issuecomment-627466608:743,log,logg,743,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191#issuecomment-627466608,1,['log'],['logg']
Testability,Failing test looks similar to what happens when I run out of memory locally: https://dev.azure.com/scverse/scanpy/_build/results?buildId=5329&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=a42f7c48-3122-5ff2-641c-e8a7971de511&l=86. and now this again only on the CI: https://github.com/scverse/scanpy/pull/2815#issuecomment-1894530944,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1903722027:8,test,test,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1903722027,2,"['log', 'test']","['logs', 'test']"
Testability,"Feature selection refers to excluding uninformative genes such as those which exhibit no meaningful biological variation across samples. Since scRNA-Seq experiments usually examine cells within a single tissue, only a small fraction of genes are expected to be informative since many genes are biologically variable only across different tissues (adopted from https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1861-6).; But, in fact some experimental design are very complex, such single-cell RNAseq of tissues from different development stage. The tissues can vary a log along the development timeline.; I find that the number of HVGs can affect data integration and batch effects correction. I've integrated seven cell samples collected at different development stage(1day, 2 day, 3 day, 4day, 5 day, 6 day, 7day after fertilization) with SCVI-tools, using 2000 HVGs, which then shows no ""batch effect"" (cells were mixed with no correlation among samples) left; on the other hand, using all genes, which shows still some extent of ""batch effect"" (some cells were clustered by time obviously) left. This could definitely affect the biological explaination, because the ""batch effect"" can be regarded as the difference of true biological difference at different development stage. The tissues are undergoing intensive differentiation process, so that the cell population are changing a lot during this process. Using only HVGs might lost these development process. ; In sum, HVGs are good for batch effect correction. The ""batch effects"" become less obvious when using less genes and more obvious when using more genes. However, more genes are good for discovery of new cell population. Does this make sense ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1578#issuecomment-764494020:586,log,log,586,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1578#issuecomment-764494020,1,['log'],['log']
Testability,Figured I would try and emphasize tests a bit more in the contributing guide.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/772:34,test,tests,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/772,1,['test'],['tests']
Testability,Filtered warning for when all zero genes have a t-test run on them. There may be a more elegant solution for this.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/683:50,test,test,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/683,1,['test'],['test']
Testability,"First reported by @lazappi, but now confirmed by me. Tests error during collection for a fresh dev install. ```; mamba create -yn scanpy-dev ""python=3.12""; conda activate scanpy-dev; pip install -e "".[dev,test]"" pytest-xdist # pytest-xdist isn't required, but makes this faster; conda deactivate scanpy-dev; conda activate scanpy-dev; pytest -n auto; ```. First everything fails since `dask-expr` isn't installed. This must be someone upstream pinning dask, but is easily solvable by adding dask-expr to the environment. ```; pip install dask-expr; pytest -n auto; ```. <details>; <summary> Failures </summary>. ```; FAILED scanpy/tests/test_score_genes.py::test_score_with_reference - TypeError: 'module' object is not callable; FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:53,Test,Tests,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,6,"['Test', 'test']","['Tests', 'test', 'testing', 'tests']"
Testability,"First step: removed logging of `asctime`, which we never had before: https://github.com/theislab/scanpy/commit/4650568cf61d8a654e64abd1ec0807e19423f1ff",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/684#issuecomment-500209907:20,log,logging,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684#issuecomment-500209907,1,['log'],['logging']
Testability,"Fix (sorta) #1082. Removed a call that required python 3.8 plus. The added test doesn't fully cover this case, since it wouldn't have had the same error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1087:75,test,test,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087,1,['test'],['test']
Testability,Fix / Unit tests `test_violin` and `test_pbmc3k`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422:11,test,tests,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422,1,['test'],['tests']
Testability,Fix PCA tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3336:8,test,tests,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3336,1,['test'],['tests']
Testability,Fix all the various test failures,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3124:20,test,test,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3124,1,['test'],['test']
Testability,Fix and test zappy support,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3089:8,test,test,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3089,1,['test'],['test']
Testability,Fix benchmark job: Use upstream asv,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3292:4,benchmark,benchmark,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3292,1,['benchmark'],['benchmark']
Testability,Fix benchmark test run,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3035:4,benchmark,benchmark,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3035,2,"['benchmark', 'test']","['benchmark', 'test']"
Testability,Fix correlation plot test for new version of matplotlib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1768:21,test,test,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768,1,['test'],['test']
Testability,Fix correlation plot test for new version of matplotlib (#1768),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1769:21,test,test,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769,1,['test'],['test']
Testability,Fix for double log in fold-changes and for indexing in wilcoxon test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519:15,log,log,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519,2,"['log', 'test']","['log', 'test']"
Testability,Fix groupby logic if adata.uns[key]['params']['groupby'] is array,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1656:12,log,logic,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656,1,['log'],['logic']
Testability,Fix issue #310 ; - Import sandbag and cyclone; - Align parameters to the one in `pypairs`; - Add documentation for the parameters. I wanted to add some tests but I was not sure which dataset makes sense. Any idea?. Bérénice,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/312:152,test,tests,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/312,1,['test'],['tests']
Testability,"Fix issue related to #890 and the reordering of stacked_violin_plots when `swap_axes=False` and for the case when `dendrogram` and `order` are given, in which case dendrogram order takes precedence. . Fix issue #891, now if `groups` is set for an embedding, the cells belonging to those groups are plotted on top. I also added missing documentation, pointing that the marker size could be a list of per-cell size. ; Added a new plotting test for the groups option.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/893:437,test,test,437,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/893,1,['test'],['test']
Testability,Fix logic in scatterplot,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/579:4,log,logic,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/579,1,['log'],['logic']
Testability,Fix long test output,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1737:9,test,test,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1737,1,['test'],['test']
Testability,Fix paga tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2521:9,test,tests,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2521,1,['test'],['tests']
Testability,Fix paga tests for new igraph(?) version,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1037:9,test,tests,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1037,1,['test'],['tests']
Testability,Fix plotting tests for networkx >= 2.6.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1960:13,test,tests,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960,1,['test'],['tests']
Testability,Fix rank genes groups when log base is missing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2283:27,log,log,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2283,1,['log'],['log']
Testability,Fix scrublet plot tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2785:18,test,tests,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2785,1,['test'],['tests']
Testability,Fix t-tests when variance is zero,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/621:6,test,tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/621,1,['test'],['tests']
Testability,Fix test breakages,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1015:4,test,test,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1015,1,['test'],['test']
Testability,Fix testing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3057:4,test,testing,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057,1,['test'],['testing']
Testability,Fix tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/162:4,test,tests,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162,2,['test'],['tests']
Testability,Fix tests for dask PCA,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3162:4,test,tests,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162,1,['test'],['tests']
Testability,Fix the dev tests. `square_distances` are not longer an argument in sklearn 1.3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2515:12,test,tests,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2515,1,['test'],['tests']
Testability,Fix uns structure in read visium and tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1137:37,test,tests,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1137,1,['test'],['tests']
Testability,Fixed tests and read function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1048:6,test,tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1048,1,['test'],['tests']
Testability,Fixed the adata_raw issue and added functionality beyond just binary and 1v1 logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/214:77,log,logreg,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/214,1,['log'],['logreg']
Testability,Fixed wrong order for groups with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2589:34,log,logreg,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589,1,['log'],['logreg']
Testability,"Fixed. Also added a couple tests. I didn't change the test mentioned above though, which might be a good thing to do.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-510771212:27,test,tests,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-510771212,2,['test'],"['test', 'tests']"
Testability,Fixes #1170 by not requiring unique `obs_names` to run combat. I also ran formatting over combat and the combat tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1215:112,test,tests,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1215,1,['test'],['tests']
Testability,"Fixes #1396. Branch which I had sitting on my computer, but forgot to open a PR for (doh). Uses joblib to parallelize `regress_out` instead of `multiprocessing` in order to prevent oversubscription of threads. Not sure how to test this. Should I also allow passing more arguments to joblib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1695:226,test,test,226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1695,1,['test'],['test']
Testability,"Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/155:83,test,test,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155,3,['test'],"['test', 'tests']"
Testability,"Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test; 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case).; 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1548:174,test,test,174,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548,1,['test'],['test']
Testability,Fixes #1590 and tests that chunked pca works,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1592:16,test,tests,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1592,1,['test'],['tests']
Testability,Fixes #1646 . Now supports coloring by boolean variables such as `True` and `False`. **Tasks to complete:** . - [x] Add test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2460:120,test,test,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460,1,['test'],['test']
Testability,"Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way.; * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1891:426,log,logic,426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891,1,['log'],['logic']
Testability,"Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note; - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1844:33,test,test,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844,4,"['Test', 'test']","['Test', 'test']"
Testability,"Fixes #1852. In a notebook, with `rich=None, file=None` or `rich=True`, we display the HTML version. I also added docs: https://icb-scanpy--2089.com.readthedocs.build/en/2089/generated/scanpy.logging.print_versions.html. It’s just plain `<details>` and `<summary>` tags, no fancy widgets and should therefore survive rendering using nbsphinx or GitHub’s notebook renderer. Looks like this:. ![unexpanded](https://user-images.githubusercontent.com/291575/146676148-ae14ea6e-7fd2-46ea-b013-f2b55669a35c.png). after a click:. ![expanded once](https://user-images.githubusercontent.com/291575/146676159-84e26f4e-8e16-4587-a3eb-145528abc353.png). after another click:. ![expanded twice](https://user-images.githubusercontent.com/291575/146676172-e38cc3f0-dd06-48d0-91b0-66708294e214.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2089:192,log,logging,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089,1,['log'],['logging']
Testability,"Fixes #1859. `igraph` uses python's random state, not numpy's. TODO:. - [x] Update saved examples for tests; - [x] Release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1922:102,test,tests,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1922,1,['test'],['tests']
Testability,"Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata, ""louvain""); sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]); ```. On master:. <details>; <summary> traceback </summary>. ```python; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-13-e5188d753713> in <module>; 1 adata = sc.datasets.pbmc3k_processed(); 2 sc.tl.paga(adata, ""louvain""); ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params); 135 if legend_fontoutline is not None:; 136 paga_graph_params['fontoutline'] = legend_fontoutline; --> 137 paga(; 138 adata,; 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1898:211,log,logic,211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898,1,['log'],['logic']
Testability,"Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1893:59,test,tests,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893,1,['test'],['tests']
Testability,Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1960:111,test,tests,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960,2,['test'],['tests']
Testability,"Fixes #2211. I’ll first try with all removed. I expect the min_tests run to fail. Seeing what fails,. - If it’s not much, I’ll just refactor the fixtures a bit and so on; - Else I’ll move algorithms to the `test` extra. Then we can merge this PR and over time refactor our tests so more and more extras go from `tests` to `tests-full`. @ivirshup do you like the collection extras’ names (`io`, `speedups`, `algorithms`)? Should we add an extra named `all` that installs all the `-full` extras?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2222:207,test,test,207,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2222,4,['test'],"['test', 'tests', 'tests-full']"
Testability,"Fixes #2246 . A very small change with a small test. The new test fails for the current master branch, but passes with the fix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2248:47,test,test,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2248,2,['test'],['test']
Testability,Fixes #2267 . ## TODO. - [ ] Tests; - [ ] Changelog,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2277:29,Test,Tests,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2277,1,['Test'],['Tests']
Testability,"Fixes #241. I've allowed the choice of metric for finding nearest neighbors when `knn=False`. I've added a small test to make sure it works, but would open to adding more. The fix I've made killed a few code paths, so I've removed the dead code. I also reorganized the test cases a bit (split one monolithic test into separate tests), as having more granular feedback helped with a little debugging.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/245:113,test,test,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/245,4,['test'],"['test', 'tests']"
Testability,"Fixes #356 for me. It's a pretty simple change. It's a little hard for me to add a test at the moment, but I'm pretty sure this works.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/357:83,test,test,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/357,1,['test'],['test']
Testability,"Fixes #435. Breaking case:. ```python; import scanpy as sc, numpy as np; sc.pp.log1p(; sc.AnnData(np.ones((100, 100)), dtype=int); ); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-3-f3ae2b50ac50> in <module>; ----> 1 sc.pp.log1p(a). /usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/scanpy/scanpy/preprocessing/_simple.py in log1p_anndata(adata, base, copy, chunked, chunk_size, layer, obsm); 348 else:; 349 X = _get_obs_rep(adata, layer=layer, obsm=obsm); --> 350 X = log1p(X, copy=False, base=base); 351 _set_obs_rep(adata, X, layer=layer, obsm=obsm); 352 . /usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/scanpy/scanpy/preprocessing/_simple.py in log1p_array(X, base, copy); 316 else:; 317 X = X.copy(); --> 318 np.log1p(X, out=X); 319 if base is not None:; 320 np.divide(X, np.log(base), out=X). TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1400:1398,log,log,1398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1400,1,['log'],['log']
Testability,Fixes #699. Corrects inconsistent logic about when a copy of a view would be made by preprocessing functions. Discussed here: https://github.com/theislab/anndata/issues/171#issuecomment-508619952,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/729:34,log,logic,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/729,1,['log'],['logic']
Testability,Fixes #762. Update to #764. Just adding a test to make sure the `use_raw` argument does something. I'm opening this a new pull request since git didn't me using other PRs branch name.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/790:42,test,test,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/790,1,['test'],['test']
Testability,"Fixes #767. This is a work in progress PR adding ICA as a dimensionality reduction method. Some points:. This is faster and works with larger data than the sklearn version – entirely due to the whitening step. sklearn uses `np.linalg.svd` for whitening, which causes errors about using 32 bit lapack for large datasets since we use 32 bit floats and is slow (but exact). I've swapped that with the arpack svd. I may try and upstream this in the future, but there are a number of open PRs about ICA that I'd like to wait for a bit on: https://github.com/scikit-learn/scikit-learn/pull/11860, https://github.com/scikit-learn/scikit-learn/issues/13056. As a benchmark, I was able to compute 40 dimensions of an ICA on 50k cells (tabula muris) and 7.5k highly variable genes in about a minute (59.3s) on my laptop. As a comparison (for a smaller dataset – 10k PBMCs) here are two pair grid plots showing cell embeddings on ten components compared with the top ten components of a PCA. <details>; <summary> PCA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899041-0c9f5b80-13b5-11ea-973f-81d4c27fe3b1.png). </details>. <details>; <summary> ICA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899077-7cade180-13b5-11ea-9a0b-023868553181.png). </details>. Things left to do:. - [ ] Look into numerical stability; - [ ] Figure out if I should be be scaling the whitening matrix differently; - [ ] More in depth comparison of results with sklearn based ICA; - [ ] Documentation; - [ ] Share `_choose_obs_rep` with `sc.metrics` PR. Once this is done, I'd like to also add sklearns NMF.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941:655,benchmark,benchmark,655,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941,1,['benchmark'],['benchmark']
Testability,Fixes #769. Looks like I only tested my use case in #724. Not sure if this will still be needed once https://github.com/lmcinnes/umap/pull/261 is in a release.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/771:30,test,tested,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/771,1,['test'],['tested']
Testability,"Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1493:32,test,tests,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493,1,['test'],['tests']
Testability,Fixes a bug where the `groups` argument would return a wrongly sorted list for logreg in rank_gene_groups.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2589:79,log,logreg,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589,1,['log'],['logreg']
Testability,"Fixes https://github.com/theislab/scanpy/issues/1326. `pca` was being imported from an old location, and there was no test. Cleaned up a bit of related code while I was at it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1327:118,test,test,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1327,1,['test'],['test']
Testability,"Fixes issue #979 . Note that if you wish to modify the figure in the same jupyter notebook cell in which the plotting function is called, you should set `show=False`:. ```; fig,ax = sc.pl.dotplot(adata,var_names,show=False); ax.set_xlabel('test'); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1069:240,test,test,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1069,1,['test'],['test']
Testability,Fixes the current test failures. I could also do a simpler version where I just rechunk in one way instead of adding parameters here.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3162:18,test,test,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162,1,['test'],['test']
Testability,"Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means; 1. the plugin can’t be imported in `scanpy/tests` but has to be imported globally; 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage; 1. The plugin can’t import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3057:225,test,tests,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057,4,['test'],"['testing', 'tests']"
Testability,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2117664638:6,test,tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2117664638,5,"['log', 'test']","['logs', 'tests']"
Testability,"Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2421:34,test,tests,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421,1,['test'],['tests']
Testability,"Following up on #242. Here's my solution to the current queries being pretty unreliable for me (due to issue with bioservices module). It's all a pretty thin wrapper around `pybiomart`, which has a nice API and is well tested but has maintenance issues. . Currently I've replaced the `gene_coordinates` query with a more generic `biomart_annotations` – the example covers the functionality of `gene_coordinates`. I'm debating how to add tests given that they're network based (could fail when nothing is wrong with the code) and can take a while.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467:219,test,tested,219,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467,2,['test'],"['tested', 'tests']"
Testability,"For incremental PCA: `sc.tl.pca(adata, n_comps=ndim, chunked=True)`; sometimes, the number of samples for the last chunk is smaller than ndim, an error would be throw:; ```pytb; File /anvil/projects/x-mcb130189/Wubin/Software/miniconda3/envs/m3c/lib/python3.9/site-packages/pym3c/clustering.py:377, in run_dimension_reduction(***failed resolving arguments***); 375 if not downsample or obs_chunk_size > downsample or adata.n_obs < downsample:; 376 logger.info(f""Running IncrementalPCA without downsampling""); --> 377 sc.tl.pca(adata, n_comps=ndim, chunked=True,; 378 chunk_size=obs_chunk_size); 379 else: # downsample; 380 logger.info(f""Running IncrementalPCA with downsample = {downsample}""). File /anvil/projects/x-mcb130189/Wubin/Software/miniconda3/envs/m3c/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py:255, in pca(***failed resolving arguments***); 253 for chunk, _, _ in adata_comp.chunked_X(chunk_size):; 254 chunk = chunk.toarray() if issparse(chunk) else chunk; --> 255 pca_.partial_fit(chunk); 257 for chunk, start, end in adata_comp.chunked_X(chunk_size):; 258 chunk = chunk.toarray() if issparse(chunk) else chunk. File /anvil/projects/x-mcb130189/Wubin/Software/miniconda3/envs/m3c/lib/python3.9/site-packages/sklearn/base.py:1473, in _fit_context.<locals>.decorator.<locals>.wrapper(estimator, *args, **kwargs); 1466 estimator._validate_params(); 1468 with config_context(; 1469 skip_parameter_validation=(; 1470 prefer_skip_nested_validation or global_skip_validation; 1471 ); 1472 ):; -> 1473 return fit_method(estimator, *args, **kwargs). File /anvil/projects/x-mcb130189/Wubin/Software/miniconda3/envs/m3c/lib/python3.9/site-packages/sklearn/decomposition/_incremental_pca.py:304, in IncrementalPCA.partial_fit(self, X, y, check_input); 298 raise ValueError(; 299 ""n_components=%r invalid for n_features=%d, need ""; 300 ""more rows than columns for IncrementalPCA ""; 301 ""processing"" % (self.n_components, n_features); 302 ); 303 elif not self.n_components <= n_samples:; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3227:448,log,logger,448,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227,2,['log'],['logger']
Testability,"For me is working properly with an earlier version of scanpy and the same matplotlib version. Can you downgrade and test if the problem is only happening in the last version. Also, you can try to see if the problem is related to some matplotlib parameters by resetting them.; ```PYTHON; matplotlib.rcdefaults(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/998#issuecomment-575066688:116,test,test,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/998#issuecomment-575066688,1,['test'],['test']
Testability,"For me, exactly the opposite happens; adding; ```; from matplotlib.testing import setup; setup(); ```; makes almost all tests fail. If I use it from the beginning and produce all test images with it, then, of course, it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-435647914:67,test,testing,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-435647914,3,['test'],"['test', 'testing', 'tests']"
Testability,"For naming, I'd ask @adamgayoso, since he implemented it. I'm also fine with leaving it for now and merging this as is (pending tests passing). > Would be easier if there was a good declarative plot API for python . Have you seen how `seaborn` does it's tests? Not so many pixel comparison ones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2087#issuecomment-998842552:128,test,tests,128,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2087#issuecomment-998842552,2,['test'],['tests']
Testability,"For the 3k test dataset, introducing edge weights with; ```; import random; random.seed(1234) . adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None); g = sc._utils.get_igraph_from_adjacency(adjacency); clustering = g.community_leiden(objective_function='modularity', weights='weight'); adata.obs['leiden_igraph_edge_weighted'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index); ```; Leads to a more similar clustering to `sc.tl.leiden`. Setting the seed makes all reproducible.; ![image](https://user-images.githubusercontent.com/25825809/154090475-9b5afd35-f254-4c30-92d5-c1a1a86d797d.png). Including igraph edge weights does not seem to impact run times on my larger datasets vs. igraph without weights.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1040389317:11,test,test,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053#issuecomment-1040389317,1,['test'],['test']
Testability,For this - https://github.com/theislab/scanpy/issues/393. Benchmarks; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/pca_for_sparse.ipynb,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/403:58,Benchmark,Benchmarks,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403,2,"['Benchmark', 'benchmark']","['Benchmarks', 'benchmarks']"
Testability,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:; https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1106431960:310,test,tested,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1106431960,1,['test'],['tested']
Testability,"Fresh install in a new env gives me the same error (jupyter kernel crashes):; ```; conda create --name squidpy python=3.8 seaborn scikit-learn statsmodels numba pytables; conda activate squidpy; conda install -c conda-forge leidenalg python-igraph; pip install scanpy squidpy imctools stardist; ```; And here's the `sc.logging.print_versions()`:; ```; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; asciitree NA; backcall 0.2.0; cairo 1.20.0; cffi 1.14.5; cmocean 2.0; constants NA; cycler 0.10.0; cython_runtime NA; dask 2021.03.0; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.2; fasteners NA; get_version 2.1; h5py 2.10.0; highs_wrapper NA; igraph 0.8.3; imagecodecs 2020.12.24; imageio 2.9.0; ipykernel 5.5.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; networkx 2.5; numba 0.52.0; numcodecs 0.7.3; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.3; parso 0.8.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.17; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.1; pyparsing 2.4.7; pytz 2021.1; pywt 1.1.1; scanpy 1.7.1; scipy 1.6.0; seaborn 0.11.1; sinfo 0.3.1; six 1.15.0; skimage 0.18.1; sklearn 0.24.1; squidpy 1.0.0; statsmodels 0.12.2; storemagic NA; tables 3.6.1; texttable 1.6.3; tifffile 2021.3.5; tornado 6.1; traitlets 5.0.5; typing_extensions NA; wcwidth 0.2.5; xarray 0.17.0; yaml 5.4.1; zarr 2.6.1; zmq 22.0.3; -----; IPython 7.21.0; jupyter_client 6.1.11; jupyter_core 4.7.1; notebook 6.2.0; -----; Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]; Linux-3.10.0-1062.1.2.el7.x86_64-x86_64-with-glibc2.10; 72 logical CPU cores, x86_64; -----; Session information updated at 2021-03-12 11:42; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-797629745:319,log,logging,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-797629745,2,['log'],"['logging', 'logical']"
Testability,"From the methods of the paper mentioned by @wangjiawen2013:. > our results were not sensitive to the default values of nPC_max. which reinforces my thinking that overshooting the number of PCs isn't a problem for typical clustering and visualization purposes. For interpreting the variable loadings, some selection might be helpful. I'd definitely be interested in having methods like these for use with other latent variable methods. Also that MCV paper's Figure 2b should probably have the APOE axis share a scale, maybe by removing the cell that has ~twice the APOE log expression of any others. I'd be interested in seeing how different the plots look after that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/872#issuecomment-559334707:569,log,log,569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/872#issuecomment-559334707,1,['log'],['log']
Testability,FuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_data-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:36166,test,tests,36166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,Get rid of logging module and use our own,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/256:11,log,logging,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/256,1,['log'],['logging']
Testability,"Getting back to this. I still have the same issue as before. For some reason this does not work on my data. I don't have any `raw` set at all in this data.; ```; sc.tl.rank_genes_groups(adata, 'celltypes', method='t-test'); sc.pl.rank_genes_groups_matrixplot(adata, n_genes=5, cmap='viridis', gene_symbols='Uniq_Name'); ```. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-41-3b246f8b6bcc> in <module>; ----> 1 sc.pl.rank_genes_groups_matrixplot(adata, n_genes=5, use_raw=False, cmap='viridis', gene_symbols='Uniq_Name'). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_matrixplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds); 823 """"""; 824 ; --> 825 return _rank_genes_groups_plot(; 826 adata,; 827 plot_type='matrixplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds); 448 from .._matrixplot import matrixplot; 449 ; --> 450 _pl = matrixplot(; 451 adata, var_names, groupby, values_df=values_df, return_fig=True, **kwds; 452 ). ~/projects/scanpy/scanpy/plotting/_matrixplot.py in matrixplot(adata, var_names, groupby, use_raw, log, num_categories, figsize, dendrogram, title, cmap, colorbar_title, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, values_df, swap_axes, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 345 """"""; 346 ; --> 347 mp = MatrixPlot(; 348 adata,; 349 var_names,. ~/projects/scanpy/scanpy/plotting/_matrixplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, ax, values_df, vmin, vmax, vcenter, norm, **kwds); 109 **kwds,; 110",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1758#issuecomment-851701172:216,test,test,216,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758#issuecomment-851701172,1,['test'],['test']
Testability,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py; 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html; 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster; 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3013#issuecomment-2419644519:42,benchmark,benchmarks,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013#issuecomment-2419644519,5,['benchmark'],"['benchmark', 'benchmarking', 'benchmarks']"
Testability,"Goals:. - flexibility in creation; - Neighbor querying API; - Harmonize storage of backends’ querying indices. 	- use it in doublet detection and scanorama reimplementations. Current solution: `method` arg. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L32. - if `use_dense_distances`: [`sklearn.metrics.pairwise_distances`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html); - if `method == 'rapids'`: [`cuml.neighbors.NearestNeighbors`](https://docs.rapids.ai/api/cuml/stable/api/#cuml.neighbors.NearestNeighbors); - otherwise: [`umap.umap_.nearest_neighbors`](https://umap-learn.readthedocs.io/en/latest/api.html#umap.umap_.nearest_neighbors); - if `method == 'gauss'`: use umap distances, overwrite its connectivities. ## Evaluating options. See [ann-benchmarks.com](https://ann-benchmarks.com/index.html#datasets). Build time vs query time is not straightforward, see https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180389432 and https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180747770. > If, however, you are simply interested in knn-graph construction then you can get that from pynndescent in less time than even the index construction time (since the prepare phase isn't required, but is a non-trivial part of the index construction time). Plots for index building are on individual dataset pages, like [glove-100-angular](https://ann-benchmarks.com/glove-100-angular_10_angular.html). <details>; <summary>Used metrics</summary>. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L35-L56. </details>. Interesting:. Name | Demo | wheels: Platforms | wheels: Python | Search speed | Index build; --- | --- | --- | --- | --- | ---; [NMSLIB](https://github.com/nmslib/nmslib) | [6 notebooks](https://github.com/nmslib/nmslib/blob/master/python_bindings/notebooks/README.md) | [Linux wheels](",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2519:859,benchmark,benchmarks,859,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2519,2,['benchmark'],['benchmarks']
Testability,"Good, yes, in the meanwhile, test coverage should be high enough. I can't think of any major hole anymore. Still, it would be nice to briefly coordinate for Scanpy; at least, still these days. But yes, in this case, please make release 1.3.8!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460614412:29,test,test,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460614412,1,['test'],['test']
Testability,Gotcha! I'll prioritize getting the benchmarks up and then I'll need some guidance on how to organize it to fit in scanpy's codebase. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-777196655:36,benchmark,benchmarks,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643#issuecomment-777196655,1,['benchmark'],['benchmarks']
Testability,"Great! Can’t say I understand the #890-related fix though: What went wrong before? Is there a test for it?. Please use 4 space indentation, not visual indentation. Basically, running `black` on the any newly changed code should yield minimal changes. Feel free to remove a file where you changed a lot from here:. https://github.com/theislab/scanpy/blob/b3933ac185f9af3908261e939fc5df2336f1932e/pyproject.toml#L9-L13. Then everything will be done automatically. You’ll just have to go through the changes and fix ugly ones like black making `some = code[:] # comment` into `some = (\n code\n) # comment` instead of `#comment\nsome = code`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/893#issuecomment-546319097:94,test,test,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/893#issuecomment-546319097,1,['test'],['test']
Testability,Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-727717155:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-727717155,1,['test'],['test']
Testability,"Great! I'll check it out when I have a chance. If this is close to ready, could it also start getting some tests?. Just to clarify, would a notebook with the pancreas integration stuff be useful to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-519798857:107,test,tests,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519798857,1,['test'],['tests']
Testability,Great! Will this change the test pics? If not LGTM.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/806#issuecomment-527404432:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/806#issuecomment-527404432,1,['test'],['test']
Testability,Great! so that test succeeded because it was testing the wrong thing?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/494#issuecomment-465918085:15,test,test,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/494#issuecomment-465918085,2,['test'],"['test', 'testing']"
Testability,"Great!. I'll replace the dataset in the tests in that case. > It would be good to have tests that actually hit the parts of neighbors where non-pairwise distances are found (>4096 cells I think). We're just completely migrating to a shallow wrapper of umap there, where this is tested. I talked to Leland and he said it should be stable. At some point, we might move to `pynndescent` (when it get's introduced into umap). Long story short, I don't think we need to test the neighbors module within scanpy beyond testing the interface. > I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?. No, happy to have you put some dev docs in a location that you find sensible. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/581#issuecomment-479472437:40,test,tests,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479472437,6,['test'],"['test', 'tested', 'testing', 'tests']"
Testability,"Great!. Some tests should fail as there are probably differences in the neighbor algorithm. This is also why this is a backwards-compat breaking change. Can you just visually inspect https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html and see what's going on?. This is another notebook that should still do something meaningful after the change: https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb. And finally, of course, https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html should give somewhat consistent results. But I expect slight variations and no perfect consistence... Actually, I'd expect the associated tests (https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_pbmc3k.py) to fail. Can you check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-478373219:13,test,tests,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-478373219,3,['test'],['tests']
Testability,"Great!. Yes, I would have expected that the adjacency matrix will differ slightly and hence, `test_paga_paul15` fails. We'll need to rerun and upload https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html with the new version in that case and also update the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-479420690:271,test,tests,271,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-479420690,1,['test'],['tests']
Testability,"Great, just wanted to make sure that we had that out of the way first. About the tie correction, I'm not the most knowledgeable person about our differential expression testing. Maybe @falexwolf or @a-munoz-rojas would be able to comment on this?. @idavydov, what do you think our results should be? Is there a gold standard in scipy.stats which we should be returning the same results as?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/698#issuecomment-513445670:169,test,testing,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/698#issuecomment-513445670,1,['test'],['testing']
Testability,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/526#issuecomment-471317931:548,Benchmark,Benchmark,548,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526#issuecomment-471317931,1,['Benchmark'],['Benchmark']
Testability,"Great, thank you! I wasn't completely happy with how Tobias wrote these tests on pickled files - they never actually passed on travis, it's much better that now, they pass! :smile: :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/60#issuecomment-355011043:72,test,tests,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/60#issuecomment-355011043,1,['test'],['tests']
Testability,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:815,benchmark,benchmarked,815,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809,6,"['Test', 'benchmark', 'test']","['Test', 'benchmarked', 'test', 'tests']"
Testability,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. ; What I did : ; - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently); - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf).; How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot); Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1259#issuecomment-992636183:319,log,lognormalize,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259#issuecomment-992636183,2,['log'],"['log', 'lognormalize']"
Testability,"Ha, got it! Seems like all tools break differently on multiline strings in the metadata. I changed the string back to single ticks to test that metadata problem and then forgot. Now it works and is tested!. Also I checked and `flit build` seems to be working with `setup.py` existing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-760774086:134,test,test,134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-760774086,2,['test'],"['test', 'tested']"
Testability,"Ha, yeah, the issue number definitely encouraged me to fix it. That's a good idea! I'm not sure I know what the pytest execution model is like, but does it ever start new processes for different tests?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/724#issuecomment-510418413:195,test,tests,195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/724#issuecomment-510418413,1,['test'],['tests']
Testability,"Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with ; ```; pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; ```. Seems to work now for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996:202,test,test,202,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996,1,['test'],['test']
Testability,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/779#issuecomment-524128498:141,test,tests,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779#issuecomment-524128498,2,['test'],"['test', 'tests']"
Testability,"Hej,. I stumbled upon your issue. Test for my PR #1440:. ```; python3 -m venv venv; source venv/bin/activate; pip install -e . ; pip install ""anndata<=0.7.3""; python3 -c ""import scanpy as sc""; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1439#issuecomment-703157510:34,Test,Test,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439#issuecomment-703157510,1,['Test'],['Test']
Testability,"Hello ; I am also facing the same problem.; I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that; ` ; sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'); pd.DataFrame(adata.uns['rank_genes_groups']['names']); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names; df= pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}); df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`; ; Any idea how to get in the single file along with pts??; ; Thanks; Akila",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1455#issuecomment-1164848375:75,log,log,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455#issuecomment-1164848375,3,"['log', 'test']","['log', 'logfoldchanges', 'test']"
Testability,"Hello @Koncopd ,; Thanks for the response!. Step 1: I created a fresh new environment (py3.8.12); ```python; !pip install scanpy[leiden]. Successfully installed anndata-0.7.8 cycler-0.11.0 fonttools-4.28.5 h5py-3.6.0 igraph-0.9.9 joblib-1.1.0 kiwisolver-1.3.2 leidenalg-0.8.8 llvmlite-0.38.0 matplotlib-3.5.1 natsort-8.0.2 networkx-2.6.3 numba-0.55.0 numexpr-2.8.1 numpy-1.21.5 pandas-1.3.5 patsy-0.5.2 pillow-9.0.0 pynndescent-0.5.5 python-igraph-0.9.9 scanpy-1.8.2 scikit-learn-1.0.2 scipy-1.7.3 seaborn-0.11.2 sinfo-0.3.4 statsmodels-0.13.1 stdlib-list-0.8.0 tables-3.7.0 texttable-1.6.4 threadpoolctl-3.0.0 tqdm-4.62.3 umap-learn-0.5.2 xlrd-1.2.0. import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from ma",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:789,log,logging,789,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841,1,['log'],['logging']
Testability,"Hello @LuckyMD ; Thanks for the response!; Could you please also check why the logFC becomes negative and disappear for the marker genes of clusters? https://github.com/theislab/scanpy/issues/2057; Thanks!; Best,; YJ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2110#issuecomment-1013526622:79,log,logFC,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110#issuecomment-1013526622,1,['log'],['logFC']
Testability,"Hello @Zethson ; Thanks for the response.; I read the paper. I understand that using the raw data to calculate the maker genes of clusters is an appropriate way, but the raw data was not regressed out with mitochondrial genes, gene counts, cell cycle scores...So there will be so many mito genes ranked on the top of the marker gene list. What shall we do with these mito genes?. In Seurat, they did every downstream analysis and plotting by using the log-transformed and scaled data (see below, the scaled dots in Seurat violin plot). Scanpy draws all plots by setting `use_raw=True`. I'm wondering which method is better?; ![image](https://user-images.githubusercontent.com/75048821/149460182-c5c11295-ca78-4bfe-aa8b-d13bade4b21f.png). Thanks!; Best,; YJ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2029#issuecomment-1012803791:452,log,log-transformed,452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2029#issuecomment-1012803791,1,['log'],['log-transformed']
Testability,"Hello Team,; ```; sc.__version__; '1.7.0rc2.dev6+g5fc12f4a'; ```; I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot ; `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-43-4ca50e495f54> in <module>; ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds); 656 """"""; 657 ; --> 658 return _rank_genes_groups_plot(; 659 adata,; 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds); 435 from .._dotplot import dotplot; 436 ; --> 437 _pl = dotplot(; 438 adata,; 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 940 del kwds['color_map']; 941 ; --> 942 dp = DotPlot(; 943 adata,; 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1758:264,log,logfoldchanges,264,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758,2,['log'],['logfoldchanges']
Testability,"Hello all,; In the “Finding marker genes” part of PBMC3K tutorial, the authors mentioned that “For this, by default, the .raw attribute of AnnData is used in case it has been initialized before” and the fuction `sc.tl.rank_genes_groups(adata, ‘leiden’, method=‘t-test’)` setting `use_raw=True` as default.; I tried `use_raw=False` in this `sc.tl.rank_genes_groups()` function and found that the results of marker genes are quite different. So, which data is recommended for finding the marker genes, adata after scaling, which is `use_raw=False`, or `adata.raw`?; Thanks!; Best; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2029:263,test,test,263,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2029,1,['test'],['test']
Testability,"Hello everyone,. In order to get eigenvalues of the PCs after running PCA, I modified the simple.py code by adding a line to return pca_.explained_variance_ and store it in adata.uns in the pca function definition. This might be useful for users wanting to access eigenvalues of the PCs, which is not possible as far as I know with only the explained_variance_ratio. Would it be a good idea to open a pull request for that?. else:; logg.m('compute PCA with n_comps =', n_comps, r=True, v=4); result = pca(adata.X, n_comps=n_comps, zero_center=zero_center,; svd_solver=svd_solver, random_state=random_state,; recompute=recompute, mute=mute, return_info=True); X_pca, components, pca_variance_ratio, pca_eigenval = result; adata.obsm['X_pca'] = X_pca; adata.varm['PCs'] = components.T; adata.uns['pca_eigenvalues']=pca_eigenval; adata.uns['pca_variance_ratio'] = pca_variance_ratio; logg.m(' finished', t=True, end=' ', v=4). ....... if False if return_info is None else return_info:. return X_pca, pca_.components_, pca_.explained_variance_ratio_, pca_.explained_variance_; else:; return X_pca. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/86:432,log,logg,432,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/86,2,['log'],['logg']
Testability,"Hello everyone,; I have faced the below warning messages during running `sc.tl.rank_genes_groups` with parameters t-test and t-test overestimated. > RuntimeWarning: invalid value encountered in greater; return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less; return (self.a < x) & (x < self.b). > RuntimeWarning: invalid value encountered in less_equal; cond2 = cond0 & (x <= self.a). I found exactly the same warning message in a forum but there the warning message was coming from auto-sklearn package and since there is no auto-sklearn used in scanpy and instead we got scikit-learn I am wondering is it a problem with the version that I am using or is it a bug from scikit or scanpy it self. my versions are:. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/674:116,test,test,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/674,2,['test'],['test']
Testability,Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1332:295,test,testing,295,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332,1,['test'],['testing']
Testability,"Hello, . I am using scanpy version 1.4 from bioconda. I am running one of the examples from the code to query datasets - . ```; import scanpy as sc. pbmc = sc.datasets.pbmc3k(); print(pbmc); plotdf = sc.get.obs_df(; pbmc,; keys=[""CD8B"", ""n_genes""],; obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]; ); plotdf.plot.scatter(""X_umap0"", ""X_umap1"", c=""CD8B""); ```. the library can read the dataset but errors out saying `scanpy` has no attribute `get`. I even tried . ```File ""test.py"", line 2, in <module>; from scanpy.get import obs_df; ModuleNotFoundError: No module named 'scanpy.get'; ```. Did the API change for any of this ? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/851:465,test,test,465,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851,1,['test'],['test']
Testability,"Hello, ; I have run this command again in the fresh conda environment. Again I get the same error as before. AttributeError Traceback (most recent call last); c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 194 try:; --> 195 mod_version = _find_version(mod.__version__); 196 except AttributeError:. AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); <ipython-input-3-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\logging.py in print_versions(file); 159 try:; 160 buf = sys.stdout = io.StringIO(); --> 161 sinfo(dependencies=True); 162 finally:; 163 sys.stdout = stdout. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 196 except AttributeError:; 197 try:; --> 198 mod_version = _find_version(mod.version); 199 except AttributeError:; 200 try:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in _find_version(mod_version_attr); 40 return joined_tuple; 41 elif callable(mod_version_attr):; ---> 42 return mod_version_attr(); 43 else:; 44 # print(f'Does not support module version of type {type(mod_ver_attr)}'). TypeError: version() missing 1 required positional argument: 'distribution_name'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1932#issuecomment-883208028:697,log,logging,697,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932#issuecomment-883208028,2,['log'],['logging']
Testability,"Hello, I get the same error when importing scanpy on 7bridges. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); /tmp/ipykernel_109/912249142.py in <module>; ----> 1 import scanpy as sc. /opt/conda/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 14 from . import tools as tl; 15 from . import preprocessing as pp; ---> 16 from . import plotting as pl; 17 from . import datasets, logging, queries, external, get, metrics, experimental; 18 . /opt/conda/lib/python3.9/site-packages/scanpy/plotting/__init__.py in <module>; 14 from ._preprocessing import filter_genes_dispersion, highly_variable_genes; 15 ; ---> 16 from ._tools.scatterplots import (; 17 embedding,; 18 pca,. /opt/conda/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in <module>; 8 from matplotlib.colors import Normalize; 9 from matplotlib import pyplot as pl; ---> 10 from matplotlib import rcParams, colormaps; 11 from anndata import AnnData; 12 from typing import Union, Optional, List, Sequence, Iterable, Mapping, Literal. ImportError: cannot import name 'colormaps' from 'matplotlib' (/opt/conda/lib/python3.9/site-packages/matplotlib/__init__.py); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1693404137:474,log,logging,474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1693404137,1,['log'],['logging']
Testability,"Hello, I would like to know how the scores are calculated in the case of the differential expression analysis using the wilcoxon's test.; This is what I found in the code of the function _rank_genes_groups.py:; `scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (n_active + m_active + 1) / 12)); scores[np.isnan(scores)] = 0; pvals = 2 * stats.distributions.norm.sf(np.abs(scores))` . Is this the version of the test that works with not paired samples?; Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/436:131,test,test,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/436,2,['test'],['test']
Testability,"Hello,. I am having the same issue as issue #1246 but my version of scipy being used with scanpy is not updating. I don't know if this is related to my using an ubuntu server or what's causing this but I was wondering if there is a workaround to make scanpy use a more updated version? I have scipy 1.4.1 installed when I check the version but for some reason scanpy is using 1.01 and I don't know how to change this. I'm a bit new to python so I'm sorry if this is a novice question. I appreciate any help you can offer. I am using an ubuntu server running python 3.6 with the following versions:; sc.logging.print_versions() ; scanpy==1.5.1 anndata==0.7.3 umap==0.4-dev numpy==1.15.0 scipy==1.0.1 pandas==0.23.3 scikit-learn==0.23.1 statsmodels==0.11.1. This is the error message:. ```pytb; computing tSNE; WARNING: You’re trying to run this on 16872 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; computing PCA; with n_comps=50; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-65-c244be664e51> in <module>(); ----> 1 sc.tl.tsne(adata, n_pcs = 50); 2 # UMAP, first with neighbor calculation; 3 sc.pp.neighbors(adata, n_pcs = 50, n_neighbors = 20); 4 sc.tl.umap(adata). ~/.local/lib/python3.6/site-packages/scanpy/tools/_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 78 start = logg.info('computing tSNE'); 79 adata = adata.copy() if copy else adata; ---> 80 X = _choose_representation(adata, use_rep=use_rep, n_pcs=n_pcs); 81 # params for sklearn; 82 params_sklearn = dict(. ~/.local/lib/python3.6/site-packages/scanpy/tools/_utils.py in _choose_representation(adata, use_rep, n_pcs, silent); 41 'Falling back to preprocessing with `sc.pp.pca` and default params.'; 42 ); ---> 43 X = pca(adata.X); 44 adata.obsm['X_pca'] = X[:, :n_pcs]; 45 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252:602,log,logging,602,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252,1,['log'],['logging']
Testability,"Hello,. I tried to swap BBKNN over to the new logging, and while the timing aspect of it is functional, the `deep` refuses to cooperate. I checked with `sc.pp.neighbors()` just to make sure I'm not screwing things up massively, and it turns out that its deep also doesn't work. <img width=""940"" alt=""Screen Shot 2019-07-23 at 09 37 10"" src=""https://user-images.githubusercontent.com/14993986/61696691-b434bf00-ad2d-11e9-83db-1092dcc61fea.png"">. Any idea what's going on here? I'm on python 3.6.7 on Bionic, jupyter 1.0.0, and all this:. scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/746:46,log,logging,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746,1,['log'],['logging']
Testability,"Hello,. I'm trying out the Graph abstraction and I get this error:; ```; SetKeyError Traceback (most recent call last); <ipython-input-12-928a85d4478e> in <module>(); ----> 1 sc.tl.tsne(adata); 2 sc.tl.draw_graph(adata, random_state=5) # random_state just makes a cosmetic change; 3 sc.write('krumsiek11_blobs', adata). ~/Downloads/scanpy/scanpy/tools/tsne.py in tsne(adata, n_pcs, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, recompute_pca, n_jobs, copy); 108 X_tsne = tsne.fit_transform(X); 109 # update AnnData instance; --> 110 adata.smp['X_tsne'] = X_tsne # annotate samples with tSNE coordinates; 111 logg.info(' finished', t=True, end=' '); 112 logg.info('and added\n'. ~/Downloads/scanpy/scanpy/data_structs/ann_data.py in __setitem__(self, keys, values); 382 # TODO: need to reallocate memory; 383 # or allow storing objects, or use pd.dataframes; --> 384 raise SetKeyError(k, v.dtype, self.dtype[k]); 385 super(BoundStructArray, self).__setitem__(k, v); 386 . SetKeyError: Currently you cannot implicitly reallocate memory:; Setting the array for key X_tsne001of002 with dtype float64 requires too much memory, you should init AnnData with a large enough data type from the beginning.; Probably you try to assign a string of length 8 although the array can only store strings of length 4.; ```. I'm using the latest git version of scanpy.; Any ideas?; Best wishes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/40:638,log,logg,638,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40,2,['log'],['logg']
Testability,"Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ?. I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1800:122,log,logFC,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800,2,['log'],['logFC']
Testability,"Hello,. It would appear that `louvain-igraph` has been obsoleted in favour of `leidenalg`, and the author makes a [persuasive case](https://arxiv.org/abs/1810.08473) as to the superiority of the new approach. To my untrained eye, the algorithm is conceptually similar to the Louvain modification used by Seurat, but introduces an extra collapsed network refinement step. it should be easy to support this in Scanpy - the syntax appears to be identical to the old `louvain` innards, and I was able to construct a very minimal dummy function for testing by taking the key bits of `sc.tl.louvain()` and replacing `louvain.` with `leidenalg.`:. ```py; import leidenalg; import numpy as np; import pandas as pd; from scanpy import utils; from natsort import natsorted. def leiden(adata, use_weights=False, resolution=1, iterations=-1):; 	g = utils.get_igraph_from_adjacency(adata.uns['neighbors']['connectivities'], directed=True); 	weights = None; 	if use_weights:; 		weights = np.array(g.es[""weight""]).astype(np.float64); 	part = leidenalg.find_partition(; 		g, leidenalg.RBConfigurationVertexPartition, ; 		resolution_parameter = resolution, weights = weights, ; 		n_iterations = iterations,; 	); 	groups = np.array(part.membership); 	adata.obs['louvain'] = pd.Categorical(; 		values=groups.astype('U'),; 		categories=natsorted(np.unique(groups).astype('U')),; 	); ```. As such, replacing any `louvain.` with `leidenalg.` in `sc.tl.louvain()` would do most of the work. Probably the only new thing that would need support would the the `n_iterations` parameter in `leidenalg.find_partition()`. The default value is 2, positive values control how many passes of the algorithm are performed. -1 just makes it run until it fails to improve the clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/350:544,test,testing,544,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350,1,['test'],['testing']
Testability,"Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue?. Attached error. Any suggestions? ; Thanks!. <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/769:113,log,log,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769,1,['log'],['log']
Testability,"Hello,; For information: if I understood correctly, there could be a risk on the current version of `score_genes_cell_cycle` method when the `adata.raw` is present:; - `score_genes_cell_cycle` is based on `score_genes` method which seems to use `adata.raw` to estimate gene score when it is present by default. As far as I know, people often store log-transformed counts to `adata.raw` (an example could be found [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html)).; - However, according to [here](https://nbviewer.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb), ""Log-transformation of data and scaling should always be performed before scoring."". In this situation, when people use `adata.raw` to store logged values, and apply `score_genes_cell_cycle` method to the object without explicitly setting `use_raw = False`, the results could be problematic, unless there is some specific processing overwritting `score_genes`' initial behaviour that I was not aware of.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599#issuecomment-1465898381:348,log,log-transformed,348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599#issuecomment-1465898381,3,"['Log', 'log']","['Log-transformation', 'log-transformed', 'logged']"
Testability,"Hello,; I am now facing a problem of failure in computing neighbours when using scanpy or scvelo; when I tried to use the . `sc.pp.neighbors(labelled, n_neighbors=5, n_pcs=4)`; or; `scv.pp.moments(raw, n_pcs=30, n_neighbors=30)`; it will always reports that. ```pytb; `computing neighbors; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 743 try:; --> 744 yield; 745 except NumbaError as e:. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in lower_block(self, block); 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block). ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in lower_inst(self, inst); 327 val = self.lower_assign(ty, inst); --> 328 self.storevar(val, inst.target.name); 329 . ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in storevar(self, value, name); 1277 name=name); -> 1278 raise AssertionError(msg); 1279 . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-37-db298150880d> in <module>; ----> 1 scv.pp.moments(raw, n_pcs=30, n_neighbors=30). ~/.conda/envs/rpy/lib/python3.9/site-packages/scvelo/preprocessing/moments.py in moments(data, n_neighbors, n_pcs, mode, method, use_rep, use_highly_variable, copy); 62 ; 63 if n_neighbors is not None and n_neighbors > get_n_neighs(adata):; ---> 64 neighbors(; 65 adata,; 66 n_neighbors=n_neighbors,. ~/.conda/envs/rpy/lib/python3.9/site-packages/scvelo/preprocessing/neighbors.py in neighbors(adata, n_neighbors, n_pcs, use_rep, use_highly_variable, knn, random_state, method, metric, metric_kwds, num_threads, copy); 161 warnings.simplefilter(""ignore""); 162 neighbors = Neighbors(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796:367,Assert,AssertionError,367,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796,1,['Assert'],['AssertionError']
Testability,"Hello,; This command (sc.logging.print_versions()) gives me the error pasted below:; AttributeError Traceback (most recent call last); c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 194 try:; --> 195 mod_version = _find_version(mod.__version__); 196 except AttributeError:. AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); <ipython-input-19-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\logging.py in print_versions(file); 159 try:; 160 buf = sys.stdout = io.StringIO(); --> 161 sinfo(dependencies=True); 162 finally:; 163 sys.stdout = stdout. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 196 except AttributeError:; 197 try:; --> 198 mod_version = _find_version(mod.version); 199 except AttributeError:; 200 try:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in _find_version(mod_version_attr); 40 return joined_tuple; 41 elif callable(mod_version_attr):; ---> 42 return mod_version_attr(); 43 else:; 44 # print(f'Does not support module version of type {type(mod_ver_attr)}'). TypeError: version() missing 1 required positional argument: 'distribution_name'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1932#issuecomment-874660246:25,log,logging,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932#issuecomment-874660246,3,['log'],['logging']
Testability,Hello. Sorry I have been silent but I haven't used scanpy for a few months and thought there was nothing more for me to do with this pull request. @Koncopd: the commit I made in September last year (e4483e9) triggered the CI and passed the tests. Is there something further you need me to do?. Thanks.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1413#issuecomment-846628296:240,test,tests,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1413#issuecomment-846628296,1,['test'],['tests']
Testability,"Here are some updates:; - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors!; - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1138619110:711,test,tested,711,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1138619110,1,['test'],['tested']
Testability,"Here we go. ~~It’s not done yet~~:. - [x] The timing stuff isn’t yet implemented. I think we just do timing stuff when doing “info” level logging, correct?. If yes, we probably just need to override `RootLogger.info` so it sets `self.handlers[0].formatter.passed_time = kwargs.get('t', False)`. - [x] All the places hackily using `_settings_verbosity_greater_or_equal_than(2|3)` have to work differently. I propose that we just add a kwarg `deepinfo: str` or so which only adds the passed string to the message if the active verbosity is higher than the function’s (i.e. calling `logging.warn('foo', deepinfo='bar')` and the loglevel/verbosity is 'INFO' or noisier adds 'bar'). - [x] We now use vanilla log function syntax, so no more using it like `print`. We switched to Python 3.6+ though, so I propose f-strings everywhere! That looks better and works. Fixes #256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/676:138,log,logging,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676,4,['log'],"['log', 'logging', 'loglevel']"
Testability,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb; Initial shape: 737280x28002; After min_genes: 5128x28002; After max_genes: 1431x28002; Traceback (most recent call last):; File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>; sc.pp.filter_genes(adata, min_cells=3); File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes; adata.var['n_cells'] = number; File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__; self._set_item(key, value); File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item; value = self._sanitize_column(key, value); File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column; value = _sanitize_index(value, self.index, copy=False); File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index; raise ValueError('Length of values does not match length of ' 'index'); ValueError: Length of values does not match length of index; ```. Note that this same error displays on both of the following lines:. ```python; sc.pp.filter_genes(adata, min_cells=3); sc.pp.filter_genes(adata, max_cells=1000); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364468317:8,test,test,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364468317,1,['test'],['test']
Testability,"Here's a demo implementation using `python-graphblas` for `max`:; Setup:. ```python; from scipy import sparse; import numpy as np. N_OBS, N_VAR = 2_000, 10_000; N_CLASSES = N_VAR - int(N_VAR / 1000); rng = np.random.default_rng(0). X = sparse.random(N_OBS, N_VAR, density=0.01, format=""csr"", random_state=rng); var_labels = np.concatenate([np.arange(N_CLASSES), rng.choice(N_CLASSES, size=N_VAR - N_CLASSES)]); ```. Implementation:. ```python; import graphblas as gb; from sklearn.preprocessing import label_binarize. var_labels_mtx = label_binarize(var_labels, classes=np.arange(N_CLASSES), sparse_output=True). result = gb.io.to_scipy_sparse(; gb.semiring.max_times(; gb.io.from_scipy_sparse(X) @ gb.io.from_scipy_sparse(var_labels_mtx); ).new(); ); ```. <details>; <summary> Test </summary>. ```python; import numpy_groupies as npg. npg_result = npg.aggregate(var_labels, X.toarray(), func=""max"", axis=1). np.testing.assert_array_equal(npg_result, result.toarray()); ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2898#issuecomment-1981863739:778,Test,Test,778,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2898#issuecomment-1981863739,2,"['Test', 'test']","['Test', 'testing']"
Testability,"Here's some initial distribution plots for comparison:. Legend: ; - red lines are 0.5% and 99.5% quantiles, a trick used in some cytof papers to deal with extreme outliers (believed to be technical artifacts); here, I simply use it to move the bulk of the data in visible range for the first two plots; while the values are merely a heuristic, the spirit of it follows nonparametric statistics so is pretty reliable in practice. ### raw (ADT counts):; ![image](https://user-images.githubusercontent.com/20694664/83345454-4956fb80-a2e1-11ea-8ae7-e13dfcc10cac.png). ### geometric mean (as used in Issac's notebook); ![image](https://user-images.githubusercontent.com/20694664/83345468-6f7c9b80-a2e1-11ea-8a42-acad50bfb66b.png). seems to only changes the scale, not the shape, so unless I made an error in implementation... it's probably not useful. ### simple log(n+1) (as used in RNAseq); ![image](https://user-images.githubusercontent.com/20694664/83345487-a05cd080-a2e1-11ea-858e-4d98621d12e6.png). can suffer from discretization at low values... note: even though Seurat/Scanpy/Loupe all use different bases, the log base doesn't really matter; it just changes the scale, not the shape/distinguishing power. ### hyperbolic arcsin (as used in CyTOF); ![image](https://user-images.githubusercontent.com/20694664/83345476-81f6d500-a2e1-11ea-8f68-ddff22ffe853.png). not as noisy as log at low values, and doesn't assert that zeros have to be Laplace smoothed with a pseudocount of +1. ### biexponential family (as used in flow cytometry); ![image](https://user-images.githubusercontent.com/20694664/83345554-6fc96680-a2e2-11ea-8112-3bdc09260e63.png). best smoothing so far in the low counts, because that's what it was designed to do. in this case, it is the newest of this family: `vlog(alpha=0, beta=12, xmax=70000, zmax=1)`; - https://doi.org/10.1002/cyto.a.23017; - https://doi.org/10.1002/cyto.a.22030; - https://doi.org/10.1002/cyto.a.20258. ### centered log ratio (as used in CITEseq paper); ![im",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-636429530:858,log,log,858,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-636429530,1,['log'],['log']
Testability,"Here's the test I ran for commit 82e3a59b5905. ```python; import scanpy as sc; import numpy as np. pbmc = sc.datasets.pbmc3k(); pbmc.X = pbmc.X.astype(np.float64); sc.pp.log1p(pbmc). implicit = sc.pp.pca(pbmc, pca_sparse=True, dtype=np.float64, copy=True); explicit = sc.pp.pca(pbmc, pca_sparse=False, dtype=np.float64, copy=True). assert not np.allclose(implicit.uns[""pca""][""variance""], explicit.uns[""pca""][""variance""]); assert not np.allclose(implicit.uns[""pca""][""variance_ratio""], explicit.uns[""pca""][""variance_ratio""]); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-593746949:11,test,test,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-593746949,3,"['assert', 'test']","['assert', 'test']"
Testability,"Hey @LouisFaure,. During the Hackathlon last week we talked again about this PR. For the time being we will keep GPU computing functionality out of scanpy and in rapids-singlecell. RSC is now tested with a CI solution. If you want to contribute to rapids-singlecell I would be very happy. Missing functions like Umap and Neighbors are currently getting updated and also ported to RSC.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1671325998:192,test,tested,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1671325998,1,['test'],['tested']
Testability,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this!. However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values.; ```; log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2); ```; In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. ; ```; log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))); ```; Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720:192,log,log,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720,6,"['log', 'test']","['log', 'tests']"
Testability,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion!. To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this.; * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns?; * Any thoughts on solutions for the name collision?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/503#issuecomment-520200213:195,test,test,195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503#issuecomment-520200213,1,['test'],['test']
Testability,"Hey @chris-rands,. This is a really interesting topic. Sorry in advance for the wordy reply... You are absolutely correct that log transformation removes the perfect comparison of relative expression values that mean normalization provides. Aside from CPM normalization (as provided by `sc.pp.normalize_total()`) not being a good normalization technique anyway (this is argued by any more advanced normalization methods paper, e.g., the [scran pooling paper](http://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0947-7)), there are a couple of things to consider here:; 1. Do we even want relative expression counts?; 2. What assumptions do downstream methods have on the distribution of expression values. For the first question: relative gene expression values ignore differences in cell sizes/number of molecules in the cell. There are some molecules whose numbers scale with the size of the cell, and others that don't (e.g., many housekeeping genes). Choosing relative over absolute expression values to compare gene expression across cells would be helpful to compare expression of those genes that scale with size, but not the others.... so there's not really a perfect answer here. Thus, removing all effects of total counts may not be the desirable outcome. Secondly, many downstream methods assume normally distributed expression data (e.g., DE methods like: t-tests, limma, MAST, or several batch correction/data integration methods). Log transformation is used as a variance stabilization to approximate a normal distribution (quite often poorly, but better than without). This leads to many methods performing better with log transformation. IMO, the ideal approach is probably something like scVI, GLMPCA, or scTransform, where you fit a model directly to the count data and use the residuals to describe the data. This would address both steps of normalization and variance stabilization at the same time. If we have a good model to describe the data, the residuals should",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643:127,log,log,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643,1,['log'],['log']
Testability,"Hey @esrice, thanks for the PR! Those tests are failing due to a recent umap release. This should be fixed on master now, so just merge master into this branch and they should be fixed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-959614946:38,test,tests,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-959614946,1,['test'],['tests']
Testability,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. ; I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-474084027:358,test,testing,358,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-474084027,1,['test'],['testing']
Testability,"Hey @giovp !. Thanks for your review and sorry for the delay, but I think I addressed all requests now:; - code moved to experimental; - fixed broken column ordering when batch argument was used with HVG selection; - tests adapted to the new code location. I was not sure how the `highly_variable_genes()` should look like in its experimental version. For now, I removed everything that is not related Pearson residuals, including input arguments and docstring. I also left a note in non-experimental `highly_variable_genes()`'s docstring that mentions the experimental version with the additional Pearson flavor. Feel free to remove again if you don't like it. Regarding the tutorial: Sure, that would be nice! I can prepare a short demo notebook. Do you think we could start with a rather concise notebook now to package it with the initial release in `experimental` (basically demonstrating how to use it on some example data, and some theory/background info how it works / why it makes sense), and then prepare a longer later on? Then I'd just open a pull request (?) in your tutorial-github for that?. Let me know if there is more to do here :). Cheers, Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-879988467:217,test,tests,217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-879988467,1,['test'],['tests']
Testability,"Hey @giovp @LuckyMD @ivirshup @adamgayoso @dkobak !. I just finished writing a set of tests for all four functions I currently have implemented! I also made some minor changes to the original code of the PR because (as probably intended by tests in general ;)) I found some inconsistencies when developing the tests. For the tests, I tried to test all input arguments and outputs. Only exception was when a bundle function (e.g. `sc.pp.recipe_pearson_residuals`) passes on an argument directly to a lower level function (e.g. `sc.pp.pca`) that has its own tests. But of course, also here, one could include extra tests. Looking forward to your feedback here, as this is my first time writing a larger set of tests. I will be on vacation until June 27th, but after that I can prioritize working on your suggestions for this! Thanks in advance :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-859688292:86,test,tests,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-859688292,8,['test'],"['test', 'tests']"
Testability,"Hey @gokceneraslan,. I'm surprised at how you describe the contents of `adata.var['highly_variable']` when `batch_key` is set. I wrote a function that does pretty much exactly the same thing building upon use of `batch_key` for our data integration benchmarking, as I thought this wasn't available in scanpy. I recall looking through the code and thinking this was missing. Maybe we can compare functions for that to see if we're doing exactly the same thing or not?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-616820714:249,benchmark,benchmarking,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-616820714,1,['benchmark'],['benchmarking']
Testability,"Hey @ivirshup,. thank you for your reply. I was not aware of that issue, but yes, this PR should solve it. I did not know where and how exactly you would prefer the test to be. So for now I put it in test_pca.py and I run a full pca on the pbmc3k data. This might of course be a bit much. Shall I provide and/or use some even smaller sample data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2179#issuecomment-1074432061:165,test,test,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1074432061,1,['test'],['test']
Testability,"Hey @ivirshup,; below is the output after making a small test edit to `_highly_variable_genes.py` and trying to commit.; Could it be that the file has not been style-checked so far (or not on the branch/version I was forking from?), leading to all these automatic changes/style violations in the old part of the code?. hope this helps, let me know if you need anything else. <details>; <summary> </summary>. ```; jlause@8b38045532aa:~/libs/scanpy/scanpy/preprocessing$ git commit -m ""test commit""; black....................................................................Failed; - hook id: black; - files were modified by this hook. reformatted scanpy/preprocessing/_highly_variable_genes.py; All done! ✨ 🍰 ✨; 1 file reformatted. flake8...................................................................Failed; - hook id: flake8; - exit code: 1. scanpy/preprocessing/_highly_variable_genes.py:33:80: E501 line too long (84 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:37:80: E501 line too long (81 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:49:80: E501 line too long (102 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:51:80: E501 line too long (89 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:108:80: E501 line too long (82 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:123:80: E501 line too long (83 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:204:27: W291 trailing whitespace; scanpy/preprocessing/_highly_variable_genes.py:219:5: F821 undefined name 'view_to_actual'; scanpy/preprocessing/_highly_variable_genes.py:220:9: F821 undefined name '_get_obs_rep'; scanpy/preprocessing/_highly_variable_genes.py:244:80: E501 line too long (85 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:257:80: E501 line too long (85 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:282:80: E501 line too long (88 > 79 characters); scanpy/preprocessing/_highly_va",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-794148562:57,test,test,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-794148562,2,['test'],['test']
Testability,"Hey @ywen1407!. The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1431#issuecomment-698818414:1115,test,tested,1115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431#issuecomment-698818414,1,['test'],['tested']
Testability,"Hey Simon,. Thanks for your suggestions. I agree that 1 would be very useful indeed and would be worth implementing.. this is not in the making yet is it @ivirshup ?; As to point 2, this would statistically be difficult as you're comparing a group to itself, which I think should not be done when testing differences between two groups.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2317#issuecomment-1257063310:297,test,testing,297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317#issuecomment-1257063310,1,['test'],['testing']
Testability,"Hey again,. I addressed many of @ivirshup's comments by now and think I am almost done - will finish up the rest next week if all goes well. What is left todo:; - [ ] Make tests faster (re-use results where possible); - [ ] Make tests more code-efficient by code-sharing between functions where possible. Where I could use your / @giovp's input to continue:; - on the keyword/positional argument issue; - on the the ""is median rank a good way to do HVG selection across batches""-issue; - on the question what the final names of the functions should be - your suggestions were:; > `normalize_pearson_residuals` -> `pearson_residuals`; > It's a bit more like log1p; >; > `sc.experimental.pp.highly_variable_genes` -> something else; > I think using an already used function name (highly_variable_genes) and giving it a different API can be confusing. Would calling this pearson_deviant_genes or something like that be better? I do generally dislike how many methods highly_variable_genes wraps already though. Looking forward to the last bits :) ; Cheers, Jan. PS: I'm sorry for the problems that my dirty force-pushing caused before, I hope now everything works fine! I was not aware of the consequences for the comment history back then, but will now take care not to do it again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-902985395:172,test,tests,172,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-902985395,2,['test'],['tests']
Testability,"Hey all!; Sorry for the delay, I finally went over the comments of @ivirshup. Thanks again for the feedback! I think I could address everything, except:. - the issue of how exactly we should select HVGs with simple batch correction. @adamgayoso and @gokceneraslan (and maybe @dkobak ?) might have an opinion here as well. See [thread](https://github.com/theislab/scanpy/pull/1715#discussion_r774980182).; - how to best cache raw data to save time while testing. I proposed a solution but not sure if it is a good-style solution, maybe have another look! See [thread](https://github.com/theislab/scanpy/pull/1715/#discussion_r774915501). Btw, I've also posted a tutorial for PRs a while back (https://github.com/theislab/scanpy-tutorials/pull/43) - any comments to that?. Hope you enjoy your Christmas holidays!; Best,; Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1000800467:453,test,testing,453,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1000800467,1,['test'],['testing']
Testability,"Hey everyone, thanks for the discussion so far! I don't have much to add to what @dkobak said earlier, so let me summarize a bit from my perspective:. I am motivated to contribute the method here because people were interested to use it with scanpy after seeing the preprint, and scanpy devs reached out to us to implement it here. For that it does not matter if it ends up in `external` or `core`, but as @giovp mentioned, the code is easy to integrate into the existing normalize/hvg-selection workflow and the method itself is well connected to established workflows. @adamgayoso raised the question if new preprint methods should be allowed in `core` at all, had several suggestions how this PR could be handled (halt until peer review publication/put in `external` for now/extend method to support also e.g. deviance residuals and others), and some open questions about the exact workflow integration. I would like to clarify with everyone how to proceed now. @ivirshup @LuckyMD, could you help us a bit to decide how to move forward?. In terms of development, I answered all of your code review comments @giovp, so maybe you can briefly check & resolve those you are happy with..?! I am also ready to finally write tests once we are decided on where this PR is going.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-801883490:1221,test,tests,1221,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-801883490,1,['test'],['tests']
Testability,"Hey everyone, thanks for your feedback! In the latest commit, I have tried to include all of your comments, including the more stylistic comments, the references, the numba integration, the unit tests and so on. Have a look and see what you think. I won't be able to work on this any more this year because I am going on holidays. Merry Christmas everyone!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/398#issuecomment-448304646:195,test,tests,195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-448304646,1,['test'],['tests']
Testability,"Hey guys @LuckyMD, @Koncopd, @falexwolf, @flying-sheep. I think this feature would be very useful to have in Scanpy, but this PR has been sort of forgotten. . I would be up to take care of this, but it would be my first contribution and I'd like some advice on how to move forward on this. I take it the main issue with the PR is the missing test for the scran normalization, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/823#issuecomment-718745640:342,test,test,342,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823#issuecomment-718745640,1,['test'],['test']
Testability,"Hey! Check out [scCoda](https://github.com/theislab/scCODA) for a differential abundance testing framework in python that is anndata compatible. As statistics are calculated on the sample level, you would however need more than 2 samples to be able to assess significance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1831#issuecomment-845926484:89,test,testing,89,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831#issuecomment-845926484,1,['test'],['testing']
Testability,"Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:; ```; adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0); adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'); ```. and I get this error:; ```; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-8-463060c90a0b> in <module>(); ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds); 630 X_col = adata.raw[:, key].X; 631 else:; --> 632 X_col = adata[:, key].X; 633 obs_df[key] = X_col; 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index); 1303 def __getitem__(self, index):; 1304 """"""Returns a sliced view of the object.""""""; -> 1305 return self._getitem_view(index); 1306 ; 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index); 1306 ; 1307 def _getitem_view(self, index):; -> 1308 oidx, vidx = self._normalize_indices(index); 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index); 1283 obs, var = super(AnnData, self)._unpack_index(index); 1284 obs = _normalize_index(obs, self.obs_names); -> 1285 var = _normalize_index(var, self.var_names); 1286 return obs, var; 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names); 261 return slice(start, stop, step); 262 elif isinstance(index, (int, str)):; --> 263 return name_idx(index); 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):; 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i); 248 raise IndexError(; 249 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/375:686,log,log,686,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375,1,['log'],['log']
Testability,"Hey!. Just something that crossed my mind... could it be that after subsetting, you have 0 variance in some genes? You may have to rerun `sc.pp.filter_genes()` to take out genes that are 0 everywhere after subsetting. This would give you an `NaN` in the testing. Maybe check that the genes you filter out are the ones that gave you the issues in the initial run.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494316752:254,test,testing,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494316752,1,['test'],['testing']
Testability,"Hey!. Logistic regression currently doesn’t output p-values i believe. Either way, it also treats genes as independent variables, so no need for subsetting here either. As for your second question, you may have misunderstood my answer. `sc.tl.rank_genes_groups()` gives you marker genes just as MAST or diffxpy do (but with more complex models that can incorporate covariates). I was just commenting on the interpretation of marker genes. They tell you which genes characterize a cluster, but don’t necessary tell you which genes contributed most to the global split of clusters that was generated (which i thought you were asking about). That type of question would require a feature importance metric on a multiclass classification problem. For example training a random forest to predict the clusters and then using gini importance to rank the features. That is not a common question asked of single-cell data though, so there’s no tool i’m familiar with that does this. I hope that is clearer.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/748#issuecomment-515168347:6,Log,Logistic,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748#issuecomment-515168347,1,['Log'],['Logistic']
Testability,"Hey, just as a quick summary of how things stand from my view:. ; - [x] Make tests faster (re-use results where possible); - [x] Make tests more code-efficient by code-sharing between functions where possible. Both done, hopefully enough to address @ivirshup 's comments :) Now both tests take less than 20secs (which is a lot shorter than before). These issues are still up for discussion/here I need your input to finish up:. - the keyword/positional argument issue (see [this](https://github.com/theislab/scanpy/pull/1715#discussion_r687448287) code comment) -- here @giovp also mentioned that he could fix it?; - the ""is median rank a good way to do HVG selection across batches""-issue (see [this](https://github.com/theislab/scanpy/pull/1715#discussion_r687465687) code comment); - the question what the final names of the functions should be (see @ivirshup's [last post](https://github.com/theislab/scanpy/pull/1715#pullrequestreview-728217616)); - add an option for fast-lane feature selection? (see my [last post](https://github.com/theislab/scanpy/pull/1715#issuecomment-903315698)); - docs consistency (see @ivirshup's [last post](https://github.com/theislab/scanpy/pull/1715#pullrequestreview-728217616)); - [failing tests](https://github.com/theislab/scanpy/pull/1715#issuecomment-902986463) - I hope I did not break anything here, but I don't really understand how the problems in `scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k` could be caused by changes in my code?!. I'll be off for vacation until Thursday and can respond to any feedback after that - looking forward!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-907829207:77,test,tests,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-907829207,5,['test'],['tests']
Testability,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account; * Set up containers; * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-815455859:163,test,test,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-815455859,1,['test'],['test']
Testability,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. ; [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf); [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-475983631:225,log,log,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-475983631,2,['log'],"['log', 'log-mean']"
Testability,"Hey, thanks for your reply!. I looked a bit around, and here is what the Seurat 3.1.4 docs say:. > Choose the features to use when integrating multiple datasets. This function ranks features by the number of datasets they appear in, breaking ties by the median rank across datasets. It returns the highest features by this ranking. from https://www.rdocumentation.org/packages/Seurat/versions/3.1.4/topics/SelectIntegrationFeatures. From this, I'd conclude that the current docs are correct, but in the sorting order of `_highly_variable_genes_seurat_v3` has it the wrong way around. Also, the test for the `_highly_variable_genes_seurat_v3()` method seems to assume that the method sorts the other way around than it currently does:. From within the method:. https://github.com/theislab/scanpy/blob/ca07fc12bbcd87e4cf67da56f52525a1e519711b/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. From the test:. https://github.com/theislab/scanpy/blob/ca07fc12bbcd87e4cf67da56f52525a1e519711b/scanpy/tests/test_highly_variable_genes.py#L138-L151. So from this it seems save to say that the sorting order should be reversed in `_highly_variable_genes_seurat_v3()`..?!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1733#issuecomment-802052402:594,test,test,594,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733#issuecomment-802052402,3,['test'],"['test', 'tests']"
Testability,"Hey,; So I don't understand how I can get around this issue with the wilcoxon test. I'm following the scanpy tutorial and getting this 'ValueError: math domain error'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/566#issuecomment-582366998:78,test,test,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566#issuecomment-582366998,1,['test'],['test']
Testability,"Hey,; while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`; --> output is a dataframe with the original number of genes as rows :heavy_check_mark: ; --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`; --> Returns nothing :x: ; --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```; if inplace: ; ; #update adata; ; if batch_key is not None:; #drop batch related keys; if subset:; adata._inplace_subset_var(df['highly_variable'].values); else:; if batch_key is None:; #drop batch related keys; if subset: ; df=df.iloc[df.highly_variable.values,:]; ; return df; ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: ; best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1867:20,test,tests,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867,1,['test'],['tests']
Testability,"Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py; import numpy as np; import pandas as pd; import scanpy as sc; import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'; print(adata). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(); ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance.; Cheers. ```pytb; > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 ; ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad; AnnData object with n_obs × n_vars = 2700 × 32738 ; var: 'gene_ids'. Traceback (most recent call last):; File ""test.py"", line 23, in <module>; sc.pp.filter_cells(adata, min_genes=200); File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells; adata._inplace_subset_obs(cell_subset); File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs; adata_subset = self[index].copy(); File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__; return self._getitem_view(inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/734:371,log,logging,371,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734,1,['log'],['logging']
Testability,"Hi @JayalalKJ ,; as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial; It's best if you open an issue there and directly address maintainers of that repo. ; Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo.; Hope this is helpful",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1220#issuecomment-702550857:437,log,log,437,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220#issuecomment-702550857,1,['log'],['log']
Testability,"Hi @Koncopd ,. The error fixed here [df8bbaf](https://github.com/theislab/scanpy/pull/1248/commits/df8bbaf5ffb58eb37d4b80ef62819f69b8fce023). Thank you!. > Hi, @awnimo , sorry for the delay.; > It seems that this PR breaks test_harmony_timeseries.py. I get; > ; > ```; > E ValueError: 'time_points' column does not contain Categorical data; > ; > ../../external/tl/_harmony_timeseries.py:140: ValueError; > ```; > ; > On master the test works fine.; > Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1248#issuecomment-703754388:432,test,test,432,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248#issuecomment-703754388,1,['test'],['test']
Testability,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:946,benchmark,benchmarking,946,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766,1,['benchmark'],['benchmarking']
Testability,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```; adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X; ```; It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ ; Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510#issuecomment-488001552:883,log,log-normalization,883,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488001552,1,['log'],['log-normalization']
Testability,"Hi @Pawan291, It seems `louvain` has not been properly installed in your environment. Could you post the output of `scanpy.logging.print_versions()` as suggested in the template? You should just need to `pip install louvain`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1566#issuecomment-753946626:123,log,logging,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1566#issuecomment-753946626,1,['log'],['logging']
Testability,"Hi @Pawan291,; It looks like your `adata.var_names` do not contain the cell cycle genes you are testing for. Is your dataset human or mouse?. Could you just print `adata.var_names[:10]`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599#issuecomment-762792128:96,test,testing,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599#issuecomment-762792128,1,['test'],['testing']
Testability,"Hi @PedroRaposo, unfortunately not. My colleague told me that this issue could be related to the versions of scanpy, anndata or loompy. I have the same scanpy version with the successful test above. Maybe, it is related to loompy and anndata version but I'm not sure...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-493118269:187,test,test,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-493118269,1,['test'],['test']
Testability,"Hi @ThomasThaewel,; In the current best-practices paper the recommendation is to use ""measured data"" as input for marker gene detection. This includes both raw, normalized, and log-normalized data formats. If you are using a count modelling approach for differential expression analysis (e.g., negative binomial, poisson), then you should use raw data (not-normalized) and include size factors in the model. For non-parametric approaches like the ones implemented in `sc.tl.rank_genes_groups()` log-normalized data is better. Hope that clarifies things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2180#issuecomment-1073786068:177,log,log-normalized,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180#issuecomment-1073786068,2,['log'],['log-normalized']
Testability,"Hi @Zethson I am the creator of Cirun.io, ""GPU"" and ""CI"" caught my eye. FWIW I'll share my two cents. I created a service for problems like these, which is basically running custom machines (including GPUs) in GitHub Actions: https://cirun.io/. It is used in multiple open source projects needing GPU support like the following:. https://github.com/pystatgen/sgkit/; https://github.com/qutip/qutip-cupy. It is fairly simple to setup, all you need is a cloud account (AWS or GCP) and a simple yaml file describing what kind of machines you need and Cirun will spin up ephemeral machines on your cloud for GitHub Actions to run. It's native to GitHub ecosystem, which mean you can see logs/trigger in the Github's interface itself, just like any Github Action run. Also, note that Cirun is free for Open source projects. (You only pay to your cloud provider for machine usage)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793#issuecomment-881043172:683,log,logs,683,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793#issuecomment-881043172,1,['log'],['logs']
Testability,"Hi @a-munoz-rojas, diffxpy will be public very soon, once we finished running all benchmarks that we need for validation. I would be happy to help you set it up if you still want to give it a go then!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-421157493:82,benchmark,benchmarks,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-421157493,1,['benchmark'],['benchmarks']
Testability,"Hi @arutik,. The reason the two DE gene sets are not the same is that `sc.tl.rank_genes_groups()` only reports genes that are upregulated in one cluster (the one in specified in the `group` parameter) compared to the other. The test itself should be symmetric if I'm not mistaken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/919#issuecomment-554271061:228,test,test,228,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/919#issuecomment-554271061,1,['test'],['test']
Testability,"Hi @davidsebfischer, I am writing a simple jupyter notebook where I am analysing the 10x_pbmc68k_reduced.h5ad data. I selected only clusters 0 and 1:; `twoClusters = adata[np.logical_or(adata.obs.louvain == '0', adata.obs.louvain == '1')]; `. Running `sc.tl.rank_genes_groups(twoClusters, groupby='louvain, method='wilcoxon', corr_method=''bonferroni)`, I obtained the following genes. ![image](https://user-images.githubusercontent.com/26186755/54123532-ec2f0b80-43f7-11e9-8c2f-f506b9170e55.png). Trying with `diffxxy` library,; `test = de.test.wilcoxon(data=twoClusters, grouping=""louvain""); `; there is the following error: _All numbers are identical in mannwhitneyu_. > @andrea-tango please use dev right now. For this test, I used the version downloaded with pip.; I can clone the repository and use the diffxpy dev branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471519124:531,test,test,531,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471519124,3,['test'],['test']
Testability,"Hi @dawe ,; I follow your code and it work well, but the result showing weird, the scvelo arrow indicate the development direction just was in contrast to the monocle direction.; In the other word, the scvelo's 'scv.pl.velocity_embedding_stream' showing terminal differentiation cells develop to original cells. this was incorrected logically. why the scvelo showed the inverted result contrast with monocle result.; I guess what i make the cell order was wrong ? i follow your code-adata = adata[cell_names]- to order the cell , i wonder whether the code just sorted the cell barcode on annData.obs but the annData.X's matrix?; why was the order runing so quickly that the matrix of annData not be sorted at the same time?; Best,; hanhuihong",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1718#issuecomment-799993218:333,log,logically,333,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718#issuecomment-799993218,1,['log'],['logically']
Testability,"Hi @erikadudki,. Sorry for the slow replies to this post. There is no test implemented for bimodality in scanpy at the moment. For modeling you could look into [diffxpy](https://github.com/theislab/diffxpy), where you may be able to fit a gaussian mixture model to do model selection. Otherwise I guess `statsmodels` is the way forward for this in python.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1086#issuecomment-603904135:70,test,test,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1086#issuecomment-603904135,1,['test'],['test']
Testability,"Hi @falexwolf, thanks a lot for the clarifications. This helps me a lot. In the example I provided yesterday, `louvain` found 5 clusters, so 0, 1, 2 made up only part of the data. I should have provided the output as well to make this clear right away. Concerning a PR for the documentation, I think I would wait until you will update the behaviour of `logreg`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/278#issuecomment-427339773:353,log,logreg,353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/278#issuecomment-427339773,1,['log'],['logreg']
Testability,"Hi @fidelram !. I just reintroduced the simple multi-panel violin feature that is used right in the beginning of the [introductory tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb): https://github.com/theislab/scanpy/commit/2a869d6060ba0de12feaf08a809bdf745d39ef10. For now, I simply hope this didn't break anything in your https://github.com/theislab/scanpy/pull/199. For future work on the plotting part of Scanpy: I need to think about adding tests for this... In case that you have an idea for doing this in the best way, I'm happy to ready about it... As a simple solution, if you don't mind, I'd add the calls from your [gist](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c) to the introductory clustering notebook, so that I make sure that I don't break anything. Best,; Alex",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/204:504,test,tests,504,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/204,1,['test'],['tests']
Testability,"Hi @fidelram ,. When I try to use . ```; plt = sc.pl.matrixplot(adata, marker_genes, groupby='louvain'); ```; I get this heatmap. . ![louv1](https://user-images.githubusercontent.com/11874103/54995344-d2c8ba80-4fc6-11e9-84fe-4f659915293d.png). But as soon as I add ```standard_scale='var'```:. ```; plt = sc.pl.matrixplot(adata, marker_genes, groupby='louvain', standard_scale='var'); ```. I get the following error. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-24-4ac38158d4d0> in <module>; ----> 1 plt = sc.pl.matrixplot(adata, marker_genes, groupby='louvain', standard_scale='var'). [...]/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in matrixplot(adata, var_names, groupby, use_raw, log, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show, save, **kwds); 1683 _plot_dendrogram(dendro_ax, adata, ticks=y_ticks); 1684 ; -> 1685 pc = matrix_ax.pcolor(mean_obs, edgecolor='gray', **kwds); 1686 ; 1687 # invert y axis to show categories ordered from top to bottom. [...]/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1803 ""the Matplotlib list!)"" % (label_namer, func.__name__),; 1804 RuntimeWarning, stacklevel=2); -> 1805 return func(ax, *args, **kwargs); 1806 ; 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. [...]/lib/python3.6/site-packages/matplotlib/axes/_axes.py in pcolor(self, alpha, norm, cmap, vmin, vmax, *args, **kwargs); 5762 kwargs.setdefault('snap', False); 5763 ; -> 5764 collection = mcoll.PolyCollection(verts, **kwargs); 5765 ; 5766 collection.set_alpha(alpha). [...]/lib/python3.6/site-packages/matplotlib/collections.py in __init__(self, verts, sizes, closed, **kwargs); 931 %(Collection)s; 932 """"""; --> 933 Collection.__init__(self, **kwargs); 934 self.set_sizes(sizes); 935 self.set_verts(verts, closed). [...]/lib/python3.6/site-packages/matplotlib/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/559:800,log,log,800,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/559,1,['log'],['log']
Testability,"Hi @fidelram, good to see you :smile:. I was working on the Galaxy integration. I tested that with the `1.3.2` version from Bioconda. I tested with adata from krumsiek11. - For colors, I tried with `sc.pl.scatter(adata=adata, x='EKLF', y='Cebpa', color=['EgrNab', 'cJun']) and I got the error:. ```; ...; and (color is None or color in adata.obs.keys() or color in adata.var.index)):; File ""path/to/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 2035, in __contains__; hash(key); TypeError: unhashable type: 'list'; ```. - For components: the command was . ```; sc.pl.scatter(; adata=adata,; x='EKLF',; y='Cebpa',; color='EgrNab',; layers=('X', 'X', 'X'),; use_raw=False,; sort_order=True,; components='all',; projection='2d',; legend_loc='right margin',; legend_fontsize=1,; legend_fontweight='normal',; palette='viridis',; frameon=True,; right_margin=1.0,; size=1.0,; show=False,; save='.png'); ```; and the error:. ```; components = np.array(components).astype(int) - 1; ValueError: invalid literal for int() with base 10: 'all'; ```. Did I put the parameters in a wrong way?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/311#issuecomment-431284136:82,test,tested,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311#issuecomment-431284136,2,['test'],['tested']
Testability,"Hi @fidelram,; One way in which I'd like to do it is like the following:. ```python; sc.pl.scatter(adata, x='<gene1>', y='<gene2>', color=['Mki67', 'Pclaf'],; save=False, use_raw=False); ```. to show the relationship between two genes (i.e. gene1 and gene2), and one third gene (in this case Mki67 in one subplot, Pclaf in the second).; One of the subplots could be like the following:. ![test](https://user-images.githubusercontent.com/697622/52814026-1e538480-3069-11e9-9af5-ef7a4761ff25.png). Hope this is clear. Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/311#issuecomment-463771320:389,test,test,389,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311#issuecomment-463771320,1,['test'],['test']
Testability,"Hi @flying-sheep @ilan-gold ,; Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2122306265:613,log,logging,613,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061#issuecomment-2122306265,1,['log'],['logging']
Testability,"Hi @genecell,. We have a review paper on current best-practices in scRNA-seq analysis which is coming out soon in Molecular Systems Biology that discusses this a bit. The issue with batch correction in scRNA-seq data isn't that batch affects different cell types differently, but rather that if cell type compositions change between batches, then transcriptional differences between the cell types that differ between the batches confound the technical batch effect estimation. So you end up correcting for more than just the technical effect. This means that you can use Combat if the cell type compositions are expected to be similar between batches. Indeed, ComBat is shown to outperform MNN for simple batch correction scenarios ([kBet paper](http://www.nature.com/articles/s41592-018-0254-1)). Inspite of the above argument, the better way to do things is definitely to include batch as a covariate. That way you don't underestimate your background variance. In the case of marker gene detection, this is not quite so problematic as:; 1. It is an easy problem, as cell-type differences tend to be very pronounced so you should always detect a signal even with non-optimal methods.; 2. The p-values you calculate from marker gene detection are inflated anyway and therefore not meaningful. We discuss the above points in our manuscript. I'm not aware whether using corrected data for differential expression testing is discussed anywhere else though. If you email me, I could forward you a copy of the manuscript, but it should be available in MSB in the next weeks. The issue with inflated p-values is also discussed is a few other places like [here](https://www.biorxiv.org/content/early/2018/11/05/463265).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691#issuecomment-502582404:1412,test,testing,1412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502582404,1,['test'],['testing']
Testability,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1333#issuecomment-664944535:121,log,log,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333#issuecomment-664944535,2,['log'],['log']
Testability,"Hi @giovp still up for adding a test dataset and tests? If so, this would be a good moment in time, as we should merge this quickly before more changes to master cause conflicts",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1024#issuecomment-584591351:32,test,test,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024#issuecomment-584591351,2,['test'],"['test', 'tests']"
Testability,"Hi @giovp! The test data is too large, it’ll take scanpy a long time to clone once this is in `master`. The way we fix it is that we replace the data and then merge our changes into commit bb70446 (creating a new commit from the two and eliminating any trace of the big dataset). For reference, the test data `filtered_feature_bc_matrix.h5` is <100kb. I’d say you find the smallest of the 10x example datasets, reduce it so the (non-image) data is <100kb all in all, and delete the hires pic. The code should work if there’s only the lores pic anyway, right?. An alternative would be to mark our tests as “internet” tests and dynamically download the data, but I think it’s better to always run the spatial tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1024#issuecomment-586185661:15,test,test,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024#issuecomment-586185661,5,['test'],"['test', 'tests']"
Testability,"Hi @giovp,; no worries, I hope you had a good TAC meeting! And thanks a lot for picking this up again, fixing the docs and also for starting the new issue on batch integration. I saw some of the github automated tests test are failing now, but I don't really understand the error messages tbh ;) Are they even related to the execution of the code provided by this PR?. If there is anything I should look into, let me know - I have some time for this next week!; Best, Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1049902277:212,test,tests,212,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1049902277,2,['test'],"['test', 'tests']"
Testability,"Hi @ivirshup , I replaced the one test image that was causing a failure, as you suggested. (And I checked to make sure the image makes sense... it does...) I think this should do it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1771#issuecomment-844219743:34,test,test,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1771#issuecomment-844219743,1,['test'],['test']
Testability,"Hi @ivirshup ,. Actually we can't see the PR doc builds, for https://readthedocs.com/projects/icb-scanpy/builds/361157/ for example this is what I see:. ![image](https://user-images.githubusercontent.com/1140359/86819388-93a46880-c055-11ea-8f62-458508a6f614.png). It's a bit annoying especially when it build fine locally but fails at readthedocs.com, it would be great if the person who sends the PR can also see the build log on the website.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1307#issuecomment-655012955:424,log,log,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307#issuecomment-655012955,1,['log'],['log']
Testability,"Hi @ivirshup ,. just checked #1529 , that's a more general additions to `rank_genes_groups_matrixplot` and `rank_genes_groups_dotplot`, but does not address this bug of `violinplot` which has to do with sparse `adata.X`. This also adds a test for that case. Thanks for pointing it out.; I'll add release note and merge it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-827461688:238,test,test,238,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-827461688,1,['test'],['test']
Testability,"Hi @ivirshup this would be ready for review. ; Travis test are failing for some figure in diffusion maps, not sure why though :(. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-606045652:54,test,test,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-606045652,1,['test'],['test']
Testability,"Hi @ivirshup, ; I am part of Intel Labs and we are trying to accelerate the genomics pipeline. We are trying to push some changes into scanpy details about which are mentioned in the blog : [https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-Labs-Accelerates-Single-cell-RNA-Seq-Analysis/post/1390715#:~:text=Intel%20Labs%20has%20accelerated%20a,of%20a%20single%20A100%20GPU.](url) ; We are facing some issues while pushing some changes in the leiden and louvain. The error states some issues with pca in the scanpy/tests/external/test_scrublet.py::test_scrublet_params when we have not made any changes for the same. Can you please help us to resolve this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613:551,test,tests,551,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613,1,['test'],['tests']
Testability,"Hi @ivirshup,. This looks like a great function but it's not super clear what the ```group``` arg is. Is it supposed to be one of the levels of the ```groupby``` arg in ```sc.tl.rank_genes_groups```? I would guess so based on the example here: https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html but that does not work for me. ```; # compare expression levels of mel vs all other cell types in pairwise manner; sc.tl.rank_genes_groups(noncycling_adult, groupby='class_1', groups = ['T-cell', 'eccrine', 'mel', 'dendritic', 'krt'], reference = 'mel', key_added='DE_results', method = 'wilcoxon'). results = sc.get.rank_genes_groups_df(noncycling_adult, key = 'DE_results', group = 'mel'). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-32-73add1f79f3a> in <module>; 1 # save as a data frame; 2 ; ----> 3 results = sc.get.rank_genes_groups_df(noncycling_adult, key = 'DE_results', group = 'mel'); 4 ; 5 . ~/software/pkg/miniconda3/envs/melanocyte_env/lib/python3.7/site-packages/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols); 53 d = pd.DataFrame(); 54 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:; ---> 55 d[k] = adata.uns[""rank_genes_groups""][k][group]; 56 if pval_cutoff is not None:; 57 d = d[d[""pvals_adj""] < pval_cutoff]. ~/software/pkg/miniconda3/envs/melanocyte_env/lib/python3.7/site-packages/numpy/core/records.py in __getitem__(self, indx); 517 ; 518 def __getitem__(self, indx):; --> 519 obj = super(recarray, self).__getitem__(indx); 520 ; 521 # copy behavior of getattr, except that here. ValueError: no field of name mel; ```. Thanks for your help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1360#issuecomment-717575616:1262,log,logfoldchanges,1262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1360#issuecomment-717575616,1,['log'],['logfoldchanges']
Testability,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1266#issuecomment-639506245:486,log,log-normalized,486,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266#issuecomment-639506245,3,"['log', 'test']","['log-normalized', 'test']"
Testability,"Hi @r-reeves,; Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-734426157:466,benchmark,benchmark,466,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289#issuecomment-734426157,1,['benchmark'],['benchmark']
Testability,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python; de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""); de_df.query(""abs(logfoldchanges) > 1""); ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API – but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1325#issuecomment-777203347:357,log,logfoldchanges,357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325#issuecomment-777203347,1,['log'],['logfoldchanges']
Testability,"Hi @sygongcode,. Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/821#issuecomment-529213147:62,test,testing,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821#issuecomment-529213147,1,['test'],['testing']
Testability,"Hi @transcriptomics, ; If you want to learn a little more about confounding, there's a pretty nice recent guide to setting up design matrices for differential expression testing [here](https://f1000research.com/articles/9-1444/v1). This is a very related issue as ComBat essentially fits the statistical model that you specify with your parameters in a similar manner than you would with a DE model. In brief, the issue is that the distribution of covariates makes it impossible for the statistical fit to prioritize whether to assign the variation in cells that are e.g., on plates starting with ""F"" to variation from being fetal or variation due to being on those plates.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1606#issuecomment-766739616:170,test,testing,170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606#issuecomment-766739616,1,['test'],['testing']
Testability,"Hi Alex, . Here is an interesting bug with scanpy. For developers, it is useful to be able to reload a previously imported module within the environment containing useful variables and data for testing (a sample scRNA dataset) after changing scanpy's source code. However, scanpy cannot be reloaded. This means that to test, one has to stop the kernel, restart, reload all of the data needed for a plot and then test a plotting function that was just modified (for instance). . Here is a way to demonstrate the reload failure easily:; 1. open utils.py and add the print statement to track the descend_classes_and_funcs() function. ```py; #utils.py; def annotate_doc_types(mod: ModuleType, root: str):; for c_or_f in descend_classes_and_funcs(mod, root):; print(c_or_f) #added line to track descend_classes_and_funcs() function--TR; c_or_f.getdoc = partial(getdoc, c_or_f); ```. 2. open ipython. ```py; import scanpy as sc; # prints out a bunch of function names from the descend_classes_and_funcs() function. import importlib; importlib.reload(sc); # endless loop of function names from the descend_classes_and_funcs() function; # due to recursive yield statement; ```. So what is the purpose of this function? And can it be altered to allow reload? It is called when __init__.py is run by sc.annotate_doc_types(sys.modules[__name__], 'scanpy'). . ```py; #utils.py. def descend_classes_and_funcs(mod: ModuleType, root: str):; for obj in vars(mod).values():; if not getattr(obj, '__module__', getattr(obj, '__qualname__', getattr(obj, '__name__', ''))).startswith(root):; continue; if isinstance(obj, Callable):; yield obj; if isinstance(obj, type):; yield from (m for m in vars(obj).values() if isinstance(m, Callable)); elif isinstance(obj, ModuleType):; yield from descend_classes_and_funcs(obj, root); ```. _________________________________________________________. It is possible to remove the scanpy manually by:. ```py; import sys; sys.modules.pop('scanpy'); ```. and then import scanpy from scr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/468:194,test,testing,194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/468,3,['test'],"['test', 'testing']"
Testability,"Hi Alex, ; The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`; , I get the following error. The igraph I am using is V 0.1.11.; Many thanks; Hashem; `DeprecationWarning Traceback (most recent call last); <ipython-input-20-fb44185f2d28> in <module>(); 1 ; ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True); 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy); 78 directed = False; 79 if not directed: logg.m(' using the undirected graph', v=4); ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed); 81 if flavor == 'vtraag':; 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed); 41 def get_igraph_from_adjacency(adjacency, directed=None):; 42 """"""Get igraph graph from adjacency matrix.""""""; ---> 43 import igraph as ig; 44 sources, targets = adjacency.nonzero(); 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(); 6 __license__ = ""MIT""; 7 ; ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, ""; 9 ""this visualization library has been renamed to ""; 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324587457:756,log,logg,756,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324587457,1,['log'],['logg']
Testability,"Hi Alex,. UMAP throws an error if I use `scanpy.tl.ump` with initial positions from `sc.tl.paga`. Based on the error (see below) I thought it was a problem of UMAP itself. However, the error is not thrown when called without initial positions from paga. Here is the output / error:. ```pytb; sc.tl.umap(adata, init_pos='paga'). computing UMAP; using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------; TypingError Traceback (most recent call last); <ipython-input-35-924452b37e5b> in <module>; ----> 1 sc.tl.umap(adata, init_pos='paga'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy); 137 neigh_params.get('metric', 'euclidean'),; 138 neigh_params.get('metric_kwds', {}),; --> 139 verbose=max(0, verbosity-3)); 140 adata.obsm['X_umap'] = X_umap # annotate samples with UMAP coordinates; 141 logg.info(' finished', time=True, end=' ' if _settings_verbosity_greater_or_equal_than(3) else '\n'). /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, verbose); 984 initial_alpha,; 985 negative_sample_rate,; --> 986 verbose=verbose,; 987 ); 988 . /opt/conda/lib/python3.7/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 348 e.patch_message(msg); 349 ; --> 350 error_rewrite(e, 'typing'); 351 except errors.UnsupportedError as e:; 352 # Something unsupported is present in the user code, add help info. /opt/conda/lib/python3.7/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 315 raise e; 316 else:; --> 317 reraise(type(e), e, None); 318 ; 319 argtypes = []. /opt/conda/lib/python3.7/site-packages/numba/six.py in reraise(tp, value, tb); 656 value = tp(); 657 if value.__traceback__ is not tb:; --> 658 raise v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666:984,log,logg,984,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666,1,['log'],['logg']
Testability,"Hi Alex,; I managed to get the log working by using your function to convert to AnnData rather than mine. (adata = sc.AnnData(x)). However, coloring the plots still does not work. I get the following error.; TypeError: object of type 'numpy.int64' has no len(). You can reproduce the error by the following; ### Load Data; x = pd.read_csv('Trial_data.csv', delimiter=',', index_col=0); ### Drop DAPI; x = x.drop(list(x.filter(regex='DAPI.', axis=1)), axis=1); ### Convert to AnnData; adata = sc.AnnData(x); ### Filter cells; sc.pp.filter_cells(adata, min_genes=1); sc.pp.filter_genes(adata, min_cells=1); adata.obs['n_counts'] = adata.X.sum(axis=1); ### Normalize data; sc.pp.log1p(adata); ### PCA; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata); sc.pl.pca(adata, color='CD3D'). I also tried it on a different dataset.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-456461004:31,log,log,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456461004,1,['log'],['log']
Testability,"Hi Alexis,; sorry about that. I made substantial changes to set up and build the [docs](https://scanpy.readthedocs.io) remotely just in the past days and for that had to experiment on the master branch. I'm fixing everything tonight running tests on all example notebooks. I will also incude more tests in the future so that stuff like this doesn't happen anymore.; Cheers,; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/34#issuecomment-324337710:241,test,tests,241,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34#issuecomment-324337710,2,['test'],['tests']
Testability,"Hi Alma,. thanks for raising your thoughts here!. I’ll try to clarify the output a bit and tag @ivirshup here. `sc.pp.neighbors` produces two main results, which it indeed stores in the `ad.obsp`:. 1. A distance matrix in `adata.obsp['distances']`. This matrix has shape (n_obs, n_obs): for each observation, only `n_neighbors-1 `entries will be non-zero. The nearest neighbor of an observation, itself with distance 0, is discarded, hence the `-1`. It is probably what you have been thinking of in your description. 2. A connectivity graph in `adata.obsp['connectivity']`. This graph has shape (n_obs, flexible), where the flexible number of connections for each observation are determined during the UMAP algorithm. Hence if you’re interested in the distance matrix, `adata.obsp['distances']` would be what you’re looking for! Coming back to your code example, here the test should be a pass:; ```py; # Import packages. import scanpy as sc; import anndata as ad; import numpy as np. # set random seed; np.random.seed(42). # create dummy data; adata = ad.AnnData(shape=(1000,1)); adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities; k = 10; sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell; gr = adata.obsp['distances']; nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k-1; np.testing.assert_equal(nn, k-1); ```. Might actually try to clarify this in documentation, small PR addressing this will follow soon. How does that sound to you? Please persist if you think I miss the point!. That being said, I think that the computation of the distance matrix and the connectivity graph are both correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2587#issuecomment-1691673182:872,test,test,872,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587#issuecomment-1691673182,2,['test'],"['test', 'testing']"
Testability,"Hi Davide!. Thank you very much for this! Sorry that I tend to be late these days, have two 6 week old baby twins to take care of... I'm happy to merge this and I'll add you to the author list! I hope it is ok if I rename the module and the top-level function to `score_gene_lists` and the second top-level function to `score_cell_cylce_genes`? Simply `score` is a bit generic... there might be many other scores in the future and then people will get confused. It's also good if both start with `score` so that auto-lookup gives you directly these suggestions? . Also, do you have a notebook with an example? It would be cool to see this at work. You could push this to a new subdirectory in `scanpy_usage`: https://github.com/theislab/scanpy_usage. I just sent you a collaborator invitation. From the example, we can then mayb design a test that goes a bit more into detail. Would be cool to benchmark with Seurat, for example. Also, one could think about providing a default list of genes, right? In particular for the cell cycle, it would be nice to directly call the function with default parameters - one can then still add user-specified lists. Do you want to provide such a list? I also sent you collaborator invitation for scanpy - maybe only temporarily if we get too many people at some point - so that you can quickly add this, if you like. Cheers,; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/76#issuecomment-363587569:838,test,test,838,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/76#issuecomment-363587569,2,"['benchmark', 'test']","['benchmark', 'test']"
Testability,"Hi Davide,. I like the preprint and the blog post. I agree that differential expression testing deserves a classification perspective. Coincidentally, we (with @tcallies) were also working on a little paper that makes this point but used neither logistic regression nor TCCs as covariates... unfortunately, we still haven't updated our benchmarks, but I'd assume that what Lior Pachter does works best. :smile:. Anyways, yes, we should include it at some point but let's still collect some experience... Until then, people can use your two-line workaround. :wink:. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/95#issuecomment-369860454:88,test,testing,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95#issuecomment-369860454,3,"['benchmark', 'log', 'test']","['benchmarks', 'logistic', 'testing']"
Testability,"Hi I had this problem as well with 1.6.0 it was triggered by scanpy's test code. ```; scanpy.api (unittest.loader._FailedTest) ... ERROR. ======================================================================; ERROR: scanpy.api (unittest.loader._FailedTest); ----------------------------------------------------------------------; ImportError: Failed to import test module: scanpy.api; Traceback (most recent call last):; File ""/usr/lib/python3.9/unittest/loader.py"", line 470, in _find_test_path; package = self._get_module_from_name(name); File ""/usr/lib/python3.9/unittest/loader.py"", line 377, in _get_module_from_name; __import__(name); File ""/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/api/__init__.py"", line 27, in <module>; from . import pl; File ""/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/api/pl.py"", line 1, in <module>; from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot; ImportError: cannot import name 'stacked_violin' from 'scanpy.plotting._anndata' (/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/plotting/_anndata.py). ----------------------------------------------------------------------; Ran 1 test in 0.000s. ```. I ended up with this patch to get the tests to run successfully.; ```; --- a/scanpy/api/pl.py; +++ b/scanpy/api/pl.py; @@ -1,4 +1,7 @@; -from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot; +from ..plotting._anndata import scatter, violin, ranking, clustermap, heatmap, tracksplot; +from ..plotting._stacked_violin import stacked_violin; +from ..plotting._dotplot import dotplot; +from ..plotting._matrixplot import matrixplot; ; from ..plotting._preprocessing import filter_genes_dispersion, highly_variable_genes; ; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-765003952:70,test,test,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-765003952,4,['test'],"['test', 'tests']"
Testability,"Hi Isaac, I've updated to v1.4.4 but I'm still getting this problem. I've finally produced a minimal test case:. ```; import scanpy as sc; sc.logging.print_versions(); #adata = sc.datasets.pbmc3k(); adata = sc.read(""orig/transpose_rsem_cell_by_gene.tsv.gz""); print(adata); adata = adata.T; print(adata); adata.raw = adata; print(adata); sc.pp.filter_cells(adata, min_genes=200); print(adata); adata = adata[adata.obs['n_genes'] < 5000, :]; print(adata); adata = adata[adata.obs['n_genes'] > 100, :]; print(adata); ```. output is:; ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 ; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; AnnData object with n_obs × n_vars = 60498 × 466 ; AnnData object with n_obs × n_vars = 466 × 60498 ; AnnData object with n_obs × n_vars = 466 × 60498 ; AnnData object with n_obs × n_vars = 466 × 60498 ; obs: 'n_genes'; View of AnnData object with n_obs × n_vars = 311 × 60498 ; obs: 'n_genes'; Traceback (most recent call last):; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/series.py"", line 977, in _get_values; return self._constructor(self._data.get_slice(indexer),; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/internals/managers.py"", line 1510, in get_slice; return self.__class__(self._block._slice(slobj),; File ""/cluster/home/max/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/internals/blocks.py"", line 268, in _slice; return self.values[slicer]; IndexError: boolean index did not match indexed array along dimension 0; dimension is 466 but corresponding boolean di",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-516194235:101,test,test,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-516194235,2,"['log', 'test']","['logging', 'test']"
Testability,"Hi Pawel, sorry for the confusion, yes, we just did a major revision. The package is still in the testing phase even though everything should work fine. Any comments from your side would be greatly appreciated!. Packaging will start soon. Development will happen on a development branch from now on. The notebooks are currently being migrated to another repo, links will be updated tomorrow or day after tomorrow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/7#issuecomment-281458534:98,test,testing,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7#issuecomment-281458534,1,['test'],['testing']
Testability,"Hi Philipp,. I have updated accordingly, again no issue but the duplication and i; analysed most of them are from previous code. Regards,; Khalid. On Mon, May 20, 2019 at 5:23 PM Philipp A. <notifications@github.com> wrote:. > Hi, looks great!; >; > The only duplicated code left is that _prepare_weighted_dataframe is very; > similar to _prepare_dataframe. I think you can delete; > _prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:712,test,tests,712,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578,5,"['assert', 'test']","['assert', 'assertions', 'test', 'tests']"
Testability,"Hi Phillip,. I have removed issue from the pull request by the testing tool, now the; tools showed me duplications, which are mostly from other code and 1-2 from; my code. Please have a look into it. It's my first pull request and its; taking too much time :(. Thanks; Khalid. On Tue, May 14, 2019 at 9:28 PM khalid usman <khalid0491@gmail.com> wrote:. > Ok , thanks for letting me know. Please check the pull request. I have; > verified my code by keeping weights 1 and it has same values when; > observations has no weights or all weights equal to 1.; >; > I also suggest to update PCA for weighted sampled data.; >; > Thanks,; > Khalid Usman; >; > On Tue, May 14, 2019 at 7:53 PM Philipp A. <notifications@github.com>; > wrote:; >; >> You can just open a new one, I’ll close this one then 🙂; >>; >> —; >> You are receiving this because you authored the thread.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/theislab/scanpy/pull/630?email_source=notifications&email_token=ABREGOFHXLS2NZRCDSLJHE3PVKR2ZA5CNFSM4HKUCBXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVLHMMQ#issuecomment-492205618>,; >> or mute the thread; >> <https://github.com/notifications/unsubscribe-auth/ABREGOBMZBMFMNA6FCEMFULPVKR2ZANCNFSM4HKUCBXA>; >> .; >>; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/630#issuecomment-493836074:63,test,testing,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-493836074,1,['test'],['testing']
Testability,"Hi Sarah,; thanks for the note and sorry about that; would you install a stable release from PyPi in the meanwhile `pip install scanpy`? I'm currently rewriting quite substantial parts and yes, this is clearly a bug I caused on the weekend; testing will also be more extensive in the future so that this stuff does happen anymore. This kind of stuff will also not happen on master branch in the future; but this rewriting goes along with building some [documentation](https://scanpy.readthedocs.io) and this builds from master... ; Cheers,; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/32#issuecomment-324116498:241,test,testing,241,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32#issuecomment-324116498,1,['test'],['testing']
Testability,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:; `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`; The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2242#issuecomment-1256969218:82,log,log-transformed,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242#issuecomment-1256969218,2,['log'],"['log-transformed', 'logarithmized']"
Testability,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)); * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. 😄",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/26#issuecomment-312623579:950,log,log-normalization,950,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26#issuecomment-312623579,1,['log'],['log-normalization']
Testability,"Hi all, ; Following [this preprint](https://www.biorxiv.org/content/early/2018/02/14/258566) and the polemic [comment](https://liorpachter.wordpress.com/2018/02/15/watermans-egg/amp/?__twitter_impression=true) by its author, I wonder if Logistic Regression should be in scanpy environment.; I tried the `sklearn.linear_model.LogisticRegressionCV` classifier from scikit-learn. It is pretty fast and seems to do the job. Of course there is no urgent need to include in scanpy, as it can be used with two lines like. ```; clf = sklearn.linear_model.LogisticRegressionCV(); clf.fit(adata.X, adata.obs[group]); ```. among the returned elements, `clf.coef_` can be used to rank genes by their importance on each group, `clf.predict_proba` may be used to score the strength of cell/group association given the scored genes. ; Any thought?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/95:237,Log,Logistic,237,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95,3,['Log'],"['Logistic', 'LogisticRegressionCV']"
Testability,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:278,test,tests,278,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617,19,['test'],"['test', 'testing', 'tests']"
Testability,"Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 743 try:; --> 744 yield; 745 except NumbaError as e:; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block); 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst); 327 val = self.lower_assign(ty, inst); --> 328 self.storevar(val, inst.target.name); 329 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name); 1277 name=name); -> 1278 raise AssertionError(msg); 1279 ; ; AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32; ; During handling of the above exception, another exception occurred:; ; LoweringError Traceback (most recent call last); <ipython-input-19-ef300851c737> in <module>; 1 n_neighbors = int(np.sqrt(adata.shape[0])/2); ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799:397,Assert,AssertionError,397,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799,1,['Assert'],['AssertionError']
Testability,"Hi all,. I am analysing some 10x samples generated in my lab and I noticed that there could be some problems with your `read_10x_mtx` function. So, I opened 4 times the `pbmc3k` dataset used in your tutorial by using the following lines of code:. `adata = sc.read_10x_mtx(sample, var_names='gene_symbols', cache=True)`; `adata.var_names_make_unique()`; `sc.pp.filter_cells(adata, min_genes=200)`; `sc.pp.filter_genes(adata, min_cells=3)`; `mito_genes = adata.var_names.str.startswith('MT-')`; `adata.obs['percent_mito'] = np.sum(adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1`; `adata.obs['n_counts'] = adata.X.sum(axis=1).A1`. I generated the violin plots showing the `n_genes`, `n_counts`, and `percent_mito` for each test and they are different in each test (see attached picture). ![Tests](https://user-images.githubusercontent.com/38785099/72088802-d7b2ec80-3302-11ea-91cd-db9d95698c00.gif). Do you have any suggestions to solve this problem?. Thank you in advance,; Simone",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/977:737,test,test,737,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/977,3,"['Test', 'test']","['Tests', 'test']"
Testability,"Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java; sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}; sc.pp.neighbors.{umap,gauss,rapids,tsne}; sc.pp.hvg.{seurat,seurat_v3,dispersion}; sc.pp.norm.{tpm,pearson}; sc.pp.filter.{genes,cells,rank_genes,...}; sc.tl.rank_genes.{logreg,wilcoxon,ttest}; s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1739:433,test,tests,433,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739,1,['test'],['tests']
Testability,"Hi all,. Sorry I sent a PR(https://github.com/theislab/scanpy/pull/1271) without reading any of these, it's my bad. Some thoughts are as follows:. - I think it's fairly straightforward to check for R dependencies in runtime, please see the PR for more info. - For Travis, I used Ubuntu packages for base R installation and then rest of the R deps are installed by the Travis user in home directory, which is cached. apt-install R installation takes around a minute. This is really hard to reduce, I think. . - After the caching, the installation of sctransform itself take around 15-20sec. This can even be reduced to zero if I check whether it's already installed. See https://travis-ci.org/github/theislab/scanpy/jobs/697070834 for a better breakdown. You can compare this with an existing test run e.g. https://travis-ci.org/github/theislab/scanpy/jobs/696758553. - sctransform test overhead is around 30sec, which can also be reduced. Overall, it adds 4 minutes to the travis test time. I don't know exactly where the remaining difference comes from. - However, if we keep adding more Ubuntu and/or R packages in the scanpy travis, it can get a bit bloated. Even if things are cached, for some reason, there is a 45-50 second cache upload overhead which is not negligible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-642835553:792,test,test,792,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-642835553,3,['test'],['test']
Testability,"Hi all,; I'm having a trouble in running a code: ; sc.tl.louvain(adata); So, when I try to run the code, it has an error saying that; ERROR: Failed building wheel for louvain; I tried to install louvain in anaconda prompt, and I can't install it.; When I use:; pip install louvain; to install louvain, I have an error that . ```pytb; ERROR: Command errored out with exit status 1:; 'c:\users\prince and jacky\anaconda3\python.exe' \; -u \; -c '; import sys, setuptools, tokenize; sys.argv[0] = "".../louvain/setup.py""; __file__="".../louvain/setup.py""; f=getattr(tokenize, ""open"", open)(__file__); code=f.read().replace(""\r\n"", ""\n""); f.close(); exec(compile(code, __file__, ""exec"")); ' \; install \; --record '.../install-record.txt' \; --single-version-externally-managed \; --compile; Check the logs for full command output.; ```. I also tried to install using different codes such as:. ```bash; conda install -c conda-forge louvain; ```. There's an error saying that:; PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/786:796,log,logs,796,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786,1,['log'],['logs']
Testability,"Hi all,; Thanks to develop the great tools for singlecell analysis.; <!-- Please give a clear and concise description of what the bug is: -->; The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, ; as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:; Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset; What happen in this situation? ; and how to fix it?; any advices would be grateful; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; Python 3.8.2 ; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy 1.4.6; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1198:785,log,logging,785,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198,1,['log'],['logging']
Testability,"Hi all. I was looking through the `_rank_genes_groups` function and noticed that the fold-change calculations are based on the means calculated by `_get_mean_var`. The only problem with this is that (usually) the expression values at this point in the analysis are in log scale, so we are calculating the fold-changes of the log1p count values, and then further log2 transforming these fold changes. I know that different programs do it differently, but I think it's more intuitive to convert the matrix back to counts, calculate the fold change, and then report the log2 fold change. Any thoughts?. For the actual differential testing, I think it's ok to run the tests on the log1p transformed data, as that seems to be the norm for many pipelines using the types of tests we are using. However, some pipelines do use raw count data, which might be interesting to implement if we want. Either way, I think it's a little unintuitive to report a log2 fold change of log expression values. I can submit a pull request to implement this if this is something you agree with, and can add a parameter to let the user decide whether to use log-transformed or raw-count data. Let me know what you think!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517:268,log,log,268,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517,6,"['log', 'test']","['log', 'log-transformed', 'testing', 'tests']"
Testability,"Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1744:186,test,testing,186,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744,4,['test'],"['test', 'testing']"
Testability,"Hi danli249, . what dataset are you using? If this is your own dataset, can you instead replicate this behavior on a public dataset? e.g. the clustering tutorial https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html?. without much needed context, this looks like some oversight in the preprocessing, for example not normalizing your data or not log-transforming it. Michael",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364138151:353,log,log-transforming,353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364138151,1,['log'],['log-transforming']
Testability,"Hi everyone,; at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25.; This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers.; I've tested the performance; ```python; foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}; sc.pl.paga(adata, color=foo, colorbar=False); ```; ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,; ~4s, but I consider that the worst-case scenario.; More importantly, current version doesn't produce a correct plot, see below:; ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1123:253,test,tested,253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123,1,['test'],['tested']
Testability,"Hi guys,. I am getting the following error after running this:. ```py; sc.pl.dotplot(adata, marker_genes1, groupby='louvain'); ```; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-138-e642551f77de> in <module>(); ----> 1 sc.pl.dotplot(adata, marker_genes1, groupby='louvain'). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, color_map, dot_max, dot_min, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, show, save, **kwds); 1350 if isinstance(var_names, str):; 1351 var_names = [var_names]; -> 1352 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); 1353 ; 1354 # for if category defined by groupby (if any) compute for each var_name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); 1983 matrix = adata[:, var_names].layers[layer]; 1984 elif use_raw:; -> 1985 matrix = adata.raw[:, var_names].X; 1986 else:; 1987 matrix = adata[:, var_names].X. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index); 495 ; 496 def __getitem__(self, index):; --> 497 oidx, vidx = self._normalize_indices(index); 498 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; 499 else: X = self._adata.file['raw.X'][oidx, vidx]. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _normalize_indices(self, packed_index); 523 obs, var = super()._unpack_index(packed_index); 524 obs = _normalize_index(obs, self._adata.obs_names); --> 525 var = _normalize_index(var, self.var_names); 526 return obs, var; 527 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _normalize_index(index, names);",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/593:503,log,log,503,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/593,2,['log'],['log']
Testability,"Hi guys,. I am trying to get the gene expression raw, log, scaled for just a couple of genes from the anndata object but i have tried doesnt seem to work. I just want a simple dataframe with the gene names as colum indexes and row info of the cells. this is waht i used to do in seurat. I am sure there is an easy way to do this in scanpy but just havent figure out. . geneX_df=as.data.frame(as.matrix(GetAssayData(object = anndata, slot = ""data"")[""geneX"",])). Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/870:54,log,log,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/870,1,['log'],['log']
Testability,"Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transfo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/706:245,test,test,245,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706,3,"['log', 'test']","['logreg', 'test']"
Testability,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:219,test,test,219,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611,2,"['log', 'test']","['logreg', 'test']"
Testability,"Hi islab,. I was wondering if there is a way to get statistical significance for a given gene expression between 2 groups on a violin plot or make a calculation separately?. for example:; here is the expression of GZMB between 2 groups and O would like to see if the difference is statistical significant with a simple t-test. <img width=""164"" alt=""image"" src=""https://user-images.githubusercontent.com/29153026/71746338-7631e000-2e21-11ea-95db-0aef5fe6dba7.png"">. Thank you fore your help,; Shen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/970:321,test,test,321,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/970,1,['test'],['test']
Testability,"Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper.; I also added a test in `tests/external/test_scnym.py` that passes.; Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see.; Thanks for building a great ecosystem!. Best,; Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1775:305,test,test,305,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775,2,['test'],"['test', 'tests']"
Testability,"Hi there,. I am doing a DE analysis using the functions `rank_genes_groups` and `filter_rank_genes_groups`.; I noticed that when two groups are compared (I did not check when multiple groups are compared) the parameter `min_in_group_fraction` of the function `filter_rank_genes_groups` is used only to filter the first group. I applied twice the functions `rank_genes_groups` and `filter_rank_genes_groups` to filter the calculated genes (I am asking that a gene is expressed in at least X% of cells).; There are mainly two possibilities, namely:; - a gene is expressed in at least X% of cells of **both** groups;; - a gene is expressed in at least X% of cells of **either** group1 or group2. In Seurat, the function `FindAllMarkers` has the parameter `min.pct `that is used to only test the genes that are detected in a minimum fraction of `min.pct` cells in either group1 or group2. It would be interesting to include these filtering steps in the `filter_rank_genes_groups` (maybe both strategies, i.e., **both** groups and **either** group1 or group2). What do you think? . Thanks!; Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1324:783,test,test,783,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324,1,['test'],['test']
Testability,"Hi there,. I was trying do dig down to understand the problem in #559 , and I found out that in my ```plotting/_anndata.py``` [these lines](https://github.com/theislab/scanpy/blob/f33924011f7d0a7924fada933e1a20d7b5ceaac3/scanpy/plotting/_anndata.py#L828-L837) and all the ones related to ```standard_scale``` are missing. So I created a new conda environment and tried to install a new version of scanpy, but this did not solve the issue (i.e. the problem is not with my old environment) as these lines are still missing. . When I tried to replace the file and re-run my heatmap I got a different error:. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); <ipython-input-5-49e0357ed731> in <module>; ----> 1 sc.pl.matrixplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True, standard_scale='var'). /anaconda3/envs/test/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in matrixplot(adata, var_names, groupby, use_raw, log, num_categories, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show, save, **kwds); 1644 var_names=var_names,; 1645 var_group_labels=var_group_labels,; -> 1646 var_group_positions=var_group_positions); 1647 ; 1648 var_group_labels = dendro_data['var_group_labels']. /anaconda3/envs/test/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions); 2332 """"""; 2333 ; -> 2334 key = _get_dendrogram_key(adata, dendrogram, groupby); 2335 ; 2336 dendro_info = adata.uns[key]. /anaconda3/envs/test/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby); 2406 ; 2407 if dendrogram_key not in adata.uns:; -> 2408 from ..tools._dendrogram import dendrogram; 2409 logg.warn(""dendrogram data not found (using key={}). Running `sc.tl.den",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/560:910,test,test,910,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/560,1,['test'],['test']
Testability,"Hi thinks for the answer and thanks for the link on the test data and visualization, I will try to use that going forward. I will cook up a non working example if needed, however just looking at the code https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L302 there is missing return statements for a few of the plotting functions in the `_rank_genes_groups_plot` unless I missed something they will then not return an axes?. The [heatmap]( https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L1044) function itself return an axis but there is no return statement from the `_rank_genes_groups_plot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/419#issuecomment-453587853:56,test,test,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453587853,1,['test'],['test']
Testability,"Hi! ; Sorry, I don't really have the time to get into this atm, but I have an idea... I think the default for expecting logarithmized data vs non-logarithmized data changed between the two functions for the `method='seurat'` case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-598855980:120,log,logarithmized,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598855980,2,['log'],['logarithmized']
Testability,"Hi! Can you explain a bit what use cases this helps people with? When would one want to set this to True?. Once we have a good example, you can use that to write a small test that checks if it works as intended.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2731#issuecomment-1798081456:170,test,test,170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2731#issuecomment-1798081456,1,['test'],['test']
Testability,"Hi! Here is the source code with data [Nestorowa et al., 2016](https://doi.org/10.1182/blood-2016-05-716480) with added diagnostic tests to produce these results. https://github.com/gmvaccaro/scanpy.tl.score_genes_fix/blob/main/score_genes_diagnostics_tests2.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3167#issuecomment-2383992046:131,test,tests,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167#issuecomment-2383992046,1,['test'],['tests']
Testability,"Hi! I just wrote a quick solution in https://github.com/theislab/scanpy/pull/586; I tested it manually and it seems to work (I used louvain code as template).; I assumed it could be interesting to work on a separate leiden function, due to possible argument clashes with louvain, instead of merging the two functions together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/582#issuecomment-479187750:84,test,tested,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/582#issuecomment-479187750,1,['test'],['tested']
Testability,"Hi! I think we have a different focus here, and not all of what you stated as fact is correct, so I’ll do my best to clear this up:. 1. There is an advantage for type hints in common Scanpy usage. IPython should use Jedi to create autocompletions since this summer, but they forgot to reenable it. I sent them an issue to do so, ipython/ipython#11503 and a fix in ipython/ipython#11506. Jedi supports type hints, so with `c.Completer.use_jedi = True` now or by default in a month, people will profit from them. Furthermore, people are using scanpy in applications and scripts, not just in notebooks. When you use an IDE (or install the jedi extension in EMACS) you should profit from it. 2. The Jupyter shift-tab help being hard to read in the presence of type hints is what I consider a bug. I reported it in ipython/ipython#11504 and fixed it in ipython/ipython#11505. 3. The numpy is on it (see [here](https://github.com/numpy/numpy-stubs)) and will probably integrate it once there needs to be no Python 2 compat. e.g. scikit-learn waits for numpy: scikit-learn/scikit-learn#11170. I see your concern about entry hurdles, but I don’t agree. It’s super easy. `Union` is “or”, `Optional` is “or `None`”. If there’s questions, they can be answered. (or people click on the links in the docs and read like one sentence of explanation). 4. If you want we can change how all that is rendered. `Union[a, b]` could be done as ``` :class:`a` or :class:`b` ``` But it’s really not hard…. Honestly I think the `Callable[…]` is much better than the textual description that was there before: Until it was there, people (including me when i was writing that annotation) had to dive into the code to figure out what function signature is *really* expected there. Now they have to be able to parse what that `Callable[[a,b], c]` there means. If they have never encountered it before, they can click on it, read one sentence of explanation and know that `a` and `b` are parameters and `c` the return type. Done in",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-440619581:936,stub,stubs,936,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-440619581,1,['stub'],['stubs']
Testability,"Hi! Sorry for the very late reply! But yes, this function is assuming the data is log-transformed before ranking genes. That's the typical workflow. It originally had a parameter to check for this, but then we decided to simplify and remove it (#519). There was some brief discussions here about adding an attribute when pp.log1p is run to handle non-transformed data, but I don't think was ever implemented. Might be worth revisiting though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/673#issuecomment-528510773:82,log,log-transformed,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/673#issuecomment-528510773,1,['log'],['log-transformed']
Testability,"Hi! not sure why the two tests failed, I don't think it's related to my edits",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1511#issuecomment-738690458:25,test,tests,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511#issuecomment-738690458,1,['test'],['tests']
Testability,"Hi!. Everything that you write makes sense: if the qPCR values are already on a log scale, you shouldn't log-transform them anymore / if the RNA-seq data is already in FPKM form, you do not need to do account for UMI correction ... Regarding the pseudotime example for RNA-seq data: [here](https://github.com/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb) is a public one. But it would be nice to have more!. Thanks for your input!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/26#issuecomment-312654301:80,log,log,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26#issuecomment-312654301,2,['log'],"['log', 'log-transform']"
Testability,"Hi!. I'm having trouble getting the CI to pass on this PR: https://github.com/theislab/scanpy/pull/1476. This seems to be the issue:. ```; > raise SyntaxError(msg, (filename, lineno, 2, text)); E File ""/home/travis/build/theislab/scanpy/scanpy/external/pp/_scrublet.py"", line 9; E > <; E ^; E SyntaxError: Header of function `scanpy.external.pp._scrublet.scrub_doublets`’s docstring should start with one-line description:; E ; E ␣␣␣␣""""""\; E ␣␣␣␣My one-line␣description.; E ; E ␣␣␣␣…; E ␣␣␣␣""""""; scanpy/tests/test_docs.py:38: SyntaxError; ```. ... but the function does have that one-line description. . Would you be able to suggest to me what I'm doing wrong?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1484:503,test,tests,503,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484,1,['test'],['tests']
Testability,"Hi!. Is it possible to do two-sided (or two-tailed) test in rank_genes_groups?. It seems like the tests you can choose from for now (t-test, wilcoxon etc.) are one-sided in that comparing group A to group B produces a list of DE genes that is not the same as in comparison of B to A. Thank you. Sincerely,; Anna Arutyunyan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/919:52,test,test,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/919,3,['test'],"['test', 'tests']"
Testability,"Hi!; I've noticed that the function `rank_genes_groups` calculate logFC differently than seurat. ; https://github.com/theislab/scanpy/blob/5800db45dde0c2060ad0a9bed8ea931bd41da936/scanpy/tools/_rank_genes_groups.py#L207-L208. https://github.com/theislab/scanpy/blob/5800db45dde0c2060ad0a9bed8ea931bd41da936/scanpy/tools/_rank_genes_groups.py#L223. Thus the equation is; `log(exp(mean(values))`. while in Seurat is; https://github.com/satijalab/seurat/blob/96d07d80bc4b6513b93e9c10d8a9d57ae7016f9f/R/differential_expression.R#L175-L179 . thus; `log(mean(exp(values)))`. I was thus wondering if this was intended, since it leads to different logFC values.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/864:66,log,logFC,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/864,4,['log'],"['log', 'logFC']"
Testability,"Hi, . Actually that's not what I've experienced - if you compare with default rank_genes_groups test you get genes with positive **and** negative logFC, which means that the test reports both upregulated and downregulated genes in that comparison, but again, it's not symmetric - please try on a test dataset for yourself.. Also if I take lists produced by A vs B comparison and B vs A and filter the genes by a common adjusted p-value cutoff (0.05 let's say) I would get lists of different sizes, so all of that makes me think that the tests are not symmetric/two-sided.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/919#issuecomment-554364259:96,test,test,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/919#issuecomment-554364259,5,"['log', 'test']","['logFC', 'test', 'tests']"
Testability,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/859:717,test,test,717,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859,2,['test'],['test']
Testability,"Hi, . I have an issue with the standard_scale ='var' function.; Whenever I try to make any plot and scaling the data from 0 to 1 with the standard_scale = 'var' function I get the following error:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-432-bef389f3fd99> in <module>; ----> 1 gs = sc.pl.matrixplot(adata, marker_genes, groupby='louvain', dendrogram=True, standard_scale='var'). ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\scanpy\plotting\_anndata.py in matrixplot(adata, var_names, groupby, use_raw, log, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show, save, **kwds); 1683 _plot_dendrogram(dendro_ax, adata, ticks=y_ticks); 1684 ; -> 1685 pc = matrix_ax.pcolor(mean_obs, edgecolor='gray', **kwds); 1686 ; 1687 # invert y axis to show categories ordered from top to bottom. ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\__init__.py in inner(ax, data, *args, **kwargs); 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),; 1809 RuntimeWarning, stacklevel=2); -> 1810 return func(ax, *args, **kwargs); 1811 ; 1812 inner.__doc__ = _add_data_doc(inner.__doc__,. ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\axes\_axes.py in pcolor(self, alpha, norm, cmap, vmin, vmax, *args, **kwargs); 5773 kwargs.setdefault('snap', False); 5774 ; -> 5775 collection = mcoll.PolyCollection(verts, **kwargs); 5776 ; 5777 collection.set_alpha(alpha). ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\collections.py in __init__(self, verts, sizes, closed, **kwargs); 931 %(Collection)s; 932 """"""; --> 933 Collection.__init__(self, **kwargs); 934 self.set_sizes(sizes); 935 self.set_verts(verts, closed). ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\collections.py in __init__(self, edgecolors, facecolors, linewidths, linestyles, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/565:622,log,log,622,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/565,1,['log'],['log']
Testability,"Hi, . I tried to run `sc.tl.highly_variable_genes` with `flavor=CellRanger` and `n_top_genes = 2000`. I obtained the following error:; ```pytb; /home/miniconda3/envs/dev/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 280 n_top_genes=n_top_genes,; 281 n_bins=n_bins,; --> 282 flavor=flavor,; 283 ); 284 . /home/miniconda3/envs/dev/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 141 dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]; 142 dispersion_norm[::-1].sort() # interestingly, np.argpartition is slightly slower; --> 143 disp_cut_off = dispersion_norm[n_top_genes-1]; 144 gene_subset = np.nan_to_num(df['dispersions_norm'].values) >= disp_cut_off; 145 logg.debug(. IndexError: index 1999 is out of bounds for axis 0 with size 1898; ```. I run scanpy in Python 3.7 (linux machine) with the following versions:; ```; scanpy==1.4.5.dev114+gd69832a anndata==0.6.22.post1 umap==0.3.9 numpy==1.17.0 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```. I suggest to check if `n_top_genes` is larger than `len(dispersion_norm)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/834:971,log,logg,971,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/834,1,['log'],['logg']
Testability,"Hi, . I was wondering what is a good/accepted way to calculate differential gene expression after batch alignment of multiple datasets?. After reading into it, it seems to me that the DEG are calculated on the raw (=non batch corrected values) and after all some batch correction algorithms don't even transform the data matrix (I don't understand why). See: [Mnn correct docs](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.external.pp.mnn_correct.html), [Seurat issue](https://github.com/satijalab/seurat/issues/1224#issuecomment-473416336), [Harmony preprint](https://www.biorxiv.org/content/biorxiv/early/2018/11/05/461954.full.pdf). But that means I would need to include _batch_ as an interaction in the DEG calculation, therefore I could use _logistic regression_ in scanpy with:; `scanpy.tl.rank_genes_groups(adata, use_raw=True, method='logreg')`; I am struggling though to find out how to add interactions to sklearns logistic regression via scanpy. When using sklearn directly it should work through [patsy or PolynomialFeatures()](https://stackoverflow.com/questions/45828964/how-to-add-interaction-term-in-python-sklearn). [Others](https://github.com/theislab/scanpy/issues/95) seem to use sklearn without the wrapper.; Or maybe I don't need to add interactions if the biological difference between the samples is bigger than the batch effect?. Do you think this is the right way to do this and could you point me in the right direction to solve this?; I think this might actually be not an _issue_ of scanpy but more a matter of understanding how to properly do this and how to use the tool so no worries if you decide to close this. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/669:862,log,logreg,862,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/669,2,['log'],"['logistic', 'logreg']"
Testability,"Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, ; S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/446:87,log,logfoldchange,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446,4,['log'],"['log', 'logfoldchange']"
Testability,"Hi, . Thanks for the quick reply!. I'm attaching the output for `combined_bbknn.obs['scNym']`:. ![Screenshot 2021-03-01 at 11 09 39](https://user-images.githubusercontent.com/3297906/109489440-ca187300-7a7e-11eb-943d-270c0273c3fc.png). This is really weird. When I tested it on my macbook I created a new environment and the problem persisted. However, there I downgraded to `scanpy==1.6` as well, the problem persisted, but the `NA`s weren't there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701#issuecomment-787867150:265,test,tested,265,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701#issuecomment-787867150,1,['test'],['tested']
Testability,"Hi, . We might start testing scanpy with umap 0.4dev branch. Today I ran `sc.pp.neighbors` with umap 0.4dev branch accidentally and got the following exception:. ![image](https://user-images.githubusercontent.com/1140359/62968014-29009380-bdd8-11e9-995f-4131ebcb19f5.png). because `fuzzy_simplicial_set` function in UMAP returns a tuple, not a sparse matrix in 0.4: https://github.com/lmcinnes/umap/blob/0.4dev/umap/umap_.py#L528-L549. It'd be great to write some tests and check if it's enough to fix this exception.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/779:21,test,testing,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779,2,['test'],"['testing', 'tests']"
Testability,"Hi, . is there a possibility to calculate _downregulated_ genes between two clusters? In the function `tl.rank_genes_groups()` I did not find such option though it should be possible with the Wilcoxon test. Afaik in `Seurat.FindMarkers()` there is an option `only.pos` for the Wilcoxon test (https://www.rdocumentation.org/packages/Seurat/versions/3.0.0/topics/FindMarkers).; Following another discussion here about DEG I tried to switch to MAST to get around that but it seems to be available only through R (https://github.com/RGLab/MAST/issues/102). Also Wilcoxon did reasonable well in a recent paper (https://www.nature.com/articles/nmeth.4612).. . Thanks!; Tilo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/625:201,test,test,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/625,2,['test'],['test']
Testability,"Hi, ; I am using weighted sampling data as input of . > scanpy , but i didn't find any help when i have a distinct weight for each observation. So I modified few of the . > scanpy. files. . `use_weights` is a boolean parameter either your data is weighted or not, if weighted then it will calculated weighted mean and weighted variance, in other case it will be same as previous. `Default is False`. `weights` is a 1D weight vector, where each row is weight of observation in original matrix. `Default is None`. I have attached the updated files and tested with well. But you can test again for adding into your tool. . Thanks; [Weighted_Sampling.zip](https://github.com/theislab/scanpy/files/3134213/Weighted_Sampling.zip)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/627:550,test,tested,550,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/627,2,['test'],"['test', 'tested']"
Testability,"Hi, ; I tested your fix and it works! ; ```; scanpy==1.4.5.2.dev6+gfa408dc7 anndata==0.7.1 ; umap==0.3.10 numpy==1.17.4 scipy==1.3.1 ; pandas==0.25.2 scikit-learn==0.21.3 ; statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```; BTW:; `matplotlib==3.1.3`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-586333599:8,test,tested,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-586333599,1,['test'],['tested']
Testability,"Hi, ; Thank you very much for such a detailed explanation. It really helps. I've two more questions: . 1). Can we do this gene subsetting with Logistic regression (where no multiple testing correction is involved)? . 2). Since you nicely pointed out sc.tl_rank_genes_groups doesn't tell about the contribution of genes in the clustering- are there tools that can be integrated with ScanPy to do this job? (for example, diffxpy or MAST). I'm really interested in the differential gene testing to predict the markers (from a gene subset used for clustering). . I shall be grateful if you can suggest a method.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/748#issuecomment-515114575:143,Log,Logistic,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748#issuecomment-515114575,3,"['Log', 'test']","['Logistic', 'testing']"
Testability,"Hi, @ShobiStassen.; As @falexwolf said, i tested the memory usage in the step where you have the problem.; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/cluster_1m_neurons.ipynb; The peak usage is around 121 GB, but it should still be possible to run with 126 GB RAM. Maybe another process took some serious amount of memory?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/511#issuecomment-470255319:42,test,tested,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-470255319,2,"['benchmark', 'test']","['benchmarks', 'tested']"
Testability,"Hi, @awnimo , sorry for the delay.; It seems that this PR breaks test_harmony_timeseries.py. I get ; ```; E ValueError: 'time_points' column does not contain Categorical data. ../../external/tl/_harmony_timeseries.py:140: ValueError; ```; On master the test works fine.; Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1248#issuecomment-702660644:253,test,test,253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248#issuecomment-702660644,1,['test'],['test']
Testability,"Hi, @eroell, I understand what you're saying. You're referring to tests with signed test statistics, like t-tests and Wilcoxon tests. You mentioned that larger scores typically correspond to lower p-values, and conversely, scores further from 0 also tend to have lower p-values. However, I am currently confused about what the positive and negative values of these scores represent. Previously, I believed that positive scores indicated upregulation and negative scores indicated downregulation, but recent results have shown me that this viewpoint is incorrect.; ![image](https://github.com/scverse/scanpy/assets/103617127/5f7d7b5b-939d-4ffe-8822-b68b59ac354f)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246:66,test,tests,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246,4,['test'],"['test', 'tests']"
Testability,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by ; `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`; and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/26#issuecomment-312650646:290,log,log,290,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26#issuecomment-312650646,3,['log'],['log']
Testability,"Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed!. Ubuntu 18.04; Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280:274,Assert,Assertion,274,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280,1,['Assert'],['Assertion']
Testability,"Hi, I am using anndata 0.6.21 and scanpy 1.4.3; I executed this code:; ```; sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]; ```. and I got this error:; `AssertionError: Don’t call _normalize_index with non-categorical/string names; `; Can you help me?. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/747:268,Assert,AssertionError,268,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747,1,['Assert'],['AssertionError']
Testability,"Hi, I just wanted to bring this back up again because I've been logging some of the issue's I've encountered. It seems we're at a bit of a philosophical divide, so perhaps it's best for me to just register which use cases I have that AnnData / scanpy are personally causing me friction:. Instead of pasting all errors, I'm just going to paste code blocks I wish worked. Note, these are actual use cases I have regularly encountered. **1. Cannot pass AnnData to numpy or sklearn operators**. ```python; import scanpy as sc; import numpy as np; import pandas as pd; import matplotlib.pyplot as plt; from sklearn import decomposition, cluster. data = np.random.normal(size=(100,10)); adata = sc.AnnData(data). # All of the following raise errors; np.sqrt(adata); adata[:, adata.var_names[0:3]] - adata[:, adata.var_names[3:6]]. adata.obsm['X_PCA'] = decomposition.PCA(2).fit_transform(adata); ```; To answer the question above, I think it should return the whole AnnData object, like how DataFrames return themselves. I don't know if we think it should ""update"" the original AnnData. I'm also confused by how this results in a performance decrease? If I do `adata = np.sqrt(adata)` then isn't this the same footprint as modifying inplace? If I do `adata_sq = np.sqrt(adata)` then my intention is to duplicate the adata object. In this case, it is my intention to create a duplicate object, and I would like AnnData to respect this intention. ; **2. Requirement to use .var_vector or .obs_vector for single columns**; ```python; # This works as expected; adata[:, adata.var_names[0:3]]. # I wish this did as well.; adata[:, adata.var_names[0]]; ```; **3. .var_vector doesn't return a Series**. ```python; pdata = pd.DataFrame(data); # Returns series; pdata[0]. # Returns ndarray; adata.var_vector[0]; ```. **4. Clusters as categories creates confusing scatterplots**; ```python; sc.pp.neighbors(adata); sc.tl.leiden(adata). plt.scatter(adata.obs['leiden'], adata.X[:,0]); ```; Produces the following plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-607952458:64,log,logging,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-607952458,1,['log'],['logging']
Testability,"Hi, I recently found that the parameter of filtering, n_genes, is determined arbitrarily. Hence, could we use the normal distribution and the threshold value (5% and 95%) to do the job?. The scanpy gives the violin plot for n_genes, but I really want a density plot (imagined as attached). Specifically, after the plot, it could automatically do the ""shapiro test"" to see if it fits the normal distribution and give the the threshold value of 5% and 95% respectively. And the users could decide whether they want to filter the data by these parameters through n_genes. ![imagine](https://user-images.githubusercontent.com/49429496/66399459-3752e080-ea12-11e9-8458-af332e620975.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/866:359,test,test,359,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/866,1,['test'],['test']
Testability,"Hi, I was doing a dataset integration on quite some datasets. . ```py; adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:; i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas); adata.obs_names_make_unique. sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; layer=""logcounts"",; batch_key=""Sample"",; subset=True; ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256); vae.train(); adata.obsm[""X_scVI""] = vae.get_latent_representation(); sc.pp.neighbors(adata, use_rep=""X_scVI""); from scvi.model.utils import mde; import pymde; adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]); adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(); adata.write_h5ad('Integrated.h5ad'); ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb; Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.; Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]; Traceback (most recent call last):; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2432:356,log,logcounts,356,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432,1,['log'],['logcounts']
Testability,"Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date).; Minimal working example:; ```python; import scanpy as sc; paul15 = sc.datasets.paul15(); sc.pp.recipe_zheng17(paul15); sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20); sc.tl.paga(paul15, groups='paul15_clusters'); sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph; nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```; #### Versions; scanpy 1.8.1; networkx 2.6.2; matplotlib 3.4.3. <details>. sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.1; -----; PIL 8.0.1; PyQt5 NA; anndata 0.7.6; autoreload NA; backcall 0.2.0; bottleneck 1.3.2; bs4 4.9.3; cairo 1.20.1; cffi 1.14.3; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2.30.0; dateutil 2.8.1; decorator 4.4.2; h5py 2.10.0; html5lib 1.1; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.1; joblib 1.0.1; kiwisolver 1.3.0; leidenalg 0.8.7; llvmlite 0.34.0; lxml 4.6.1; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; networkx 2.6.2; nt NA; ntsecuritycon NA; numba 0.51.2; numexpr 2.7.1; numpy 1.20.3; packaging 20.4; pandas 1.3.2; parso 0.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.7.2; pyarrow 0.16.0; pycparser 2.20; pygments 2.7.2; pynndescent 0.5.2; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; scanpy 1.8.1; scipy 1.5.2; sinfo 0.3.1; sip NA; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; sphinxcontrib NA; spyder 4.1.5; spyder_kernels 1.9.4; spydercustomize NA; s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1997:868,log,logging,868,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997,1,['log'],['logging']
Testability,"Hi, It's not available in scanpy at the moment, but I wrote a wrapper for it via `rpy2` and `anndata2ri` which is available here:; https://github.com/normjam/benchmark/blob/master/normbench/methods/ad2seurat.py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-590009483:158,benchmark,benchmark,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-590009483,1,['benchmark'],['benchmark']
Testability,"Hi, can you please create an issue with a minimal reproducible example?. Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb; > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`; > |; > 266 | try:; > 267 | pca_.partial_fit(chunk); > 268 | except:; > | ^^^^^^ E722; > 269 | continue; > |; > ```; > ; > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3227#issuecomment-2371113084:105,test,test,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227#issuecomment-2371113084,1,['test'],['test']
Testability,"Hi, did any one ever end up testing Densmap for scRNA ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1619#issuecomment-1906223696:28,test,testing,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1619#issuecomment-1906223696,1,['test'],['testing']
Testability,"Hi, everything is OK with the benchmarks, `regress_out` would fail if called with variables that doesn’t exist. The reason these are named differently is here: https://github.com/scverse/scanpy/blob/ad657edfb52e9957b9a93b3a16fc8a87852f3f09/benchmarks/benchmarks/_utils.py#L27-L31. I did that to be able to run benchmarks benchmarks on multiple data sets with the same code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110#issuecomment-2185859889:30,benchmark,benchmarks,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110#issuecomment-2185859889,5,['benchmark'],['benchmarks']
Testability,"Hi, for `method='wilcoxon'` this is [Wilcoxon rank-sum test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test), and the scores are U_1 from methods in in the link. Higher absolute value of score -> lower p-value (more evidence the levels of expression between groups are different), higher score indicates higher expression, lower score -> lower expression.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1688#issuecomment-784969965:55,test,test,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1688#issuecomment-784969965,1,['test'],['test']
Testability,"Hi, looks great!. Ignore the tool, I think it’s a bit broken. I need to figure out what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that wi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:550,test,tests,550,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412,7,"['assert', 'test']","['assert', 'assertions', 'test', 'tests']"
Testability,"Hi, same confusion here.; According to: https://github.com/scverse/scanpy/issues/969#issuecomment-629667682; If I set `flavor ='cell_ranger'`, dose it mean I should not use `sc.pp.log1p(adata)` to ensure use the ""library size normalized counts""(not log)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1545#issuecomment-1501448104:249,log,log,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545#issuecomment-1501448104,1,['log'],['log']
Testability,"Hi, sorry for the late response... > 1. Can we infer from such an analysis how much a pathway is upregulated? (e.g. by calculating the FC of the mean?) . It would be great to conclude for example, that Pathway X is 30% more active, in condition Y. I think so. Historically, this function has been used to score cell cycle and, in that case, one can say that cells are in a specific state *because* of a different distribution of signatures. This is generally true. I have myself used the score to underline cells with activated/depleted pathways. Also, I have used gene lists from KEGG or Reactome to score single cells. IMHO, once you have those values you can perform any statistical test on their distributions to tell if there's a difference in activation of a certain pathway.; There may be better ways to do this, but it's a start. > 2. How does in your opinion class-imbalance affect the analysis? For example, Condition A has 10 samples, while for Condition B,C.. I only have 3 each?. As @giovp pointed out, it should be ok, as long as you have enough cells to estimate the distributions. > 3. I am happy to provide the code for the density distributions to visualise the results of the gene-set-score function. What I usually do is to calculate the `embedding_density` for signatures, so that it's easy to visualize them on my embeddings (I usually cut values into quartiles).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1629#issuecomment-781323134:686,test,test,686,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1629#issuecomment-781323134,1,['test'],['test']
Testability,"Hi, thank you for the report. However, you deleted. > Put a minimal reproducible example that reproduces the bug in the code block below. Please do that, so we can create a regression test from it:. ```py; import numpy as np; import scanpy as sc; ad = AnnData(np.array([...])); sc.tl.rank_genes_groups(ad) # this line crashes without the fix; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1061#issuecomment-588270826:184,test,test,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061#issuecomment-588270826,1,['test'],['test']
Testability,"Hi, thanks again for your interest in GLM-PCA. We welcome its inclusion in scanpy, but some caveats are that it is about 10x slower than PCA and we are still working to improve its numerical stability and ability to handle sparse data matrices. . With that in mind, we have put together an implementation of [Pearson and deviance residuals](https://github.com/kstreet13/scry/blob/master/R/nullResiduals.R) as an approximation to GLM-PCA via the [scry R package](https://github.com/kstreet13/scry). These residuals, based on binomial and poisson approximation to multinomial, can be computed in closed form so they are computationally as fast as log-transforming. The sctransform method uses a negative binomial likelihood which doesn't have a closed form solution and is more complicated to implement (although we do recomment it from a statistical validity standpoint). . In addition to the null residuals, the scry package has an implementation of [feature selection via deviance](https://github.com/kstreet13/scry/blob/master/R/featureSelection.R), which may also be of interest as an alternative to highly variable genes. This is also a closed form computation. Both the feature selection and null residuals functions allow adjusting for categorical batch labels. I do hope to implement both of these in python eventually but it's pretty far down my to-do list. Given the functions are fairly simple, I welcome anyone to go ahead and copy them into python if they find it potentially useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-593125190:645,log,log-transforming,645,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-593125190,1,['log'],['log-transforming']
Testability,"Hi, thanks for your interest in scanpy!. I’ll try to comment on your observations here with your code example:. ```; import scanpy as sc; import numpy as np; ### Loading and preprocessing data; adata = sc.datasets.pbmc3k_processed(). ### Defining scale function; def mean_var(X, axis=0):; mean = np.mean(X, axis=axis, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); var = mean_sq - mean**2; # enforce R convention (unbiased estimator) for variance; var *= X.shape[axis] / (X.shape[axis] - 1); return mean, var; ```. As a first note of caution, in your code your function actually modifies the original data matrix, of the scanpy object - which is used again later in the snippet.; → We should create a copy of `X`. Else the code overwrites this object, and ends up comparing an object with itself, while simply using two names for it (this caused your `==` comparisons to evaluate as `True`, but is not what you intend to test).; ```; def my_scale_function(X, clip=False):; # need to make a copy of X; Y = X.copy(); mean, var = mean_var(Y, axis=0); Y -= mean; std = np.sqrt(var); #std[std == 0] = 1; Y /= std; if clip:; Y = np.clip(X, -10, 10); return np.matrix(Y); ```. As a second note of caution, floating point numbers should not be compared with the `==` operator (see for example [here](https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/)). → A more common way would be to use e.g. `np.allclose()` for this purpose. ```; ### Scanpy scale vs my_scale_function. print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(adata.X). print(""Do a numpy check for closeness of floats:""); print(np.allclose(adata.X, mtx_rescaled)); ```. ```; Do a numpy check for closeness of floats:; False; ```. You can see that this test actually fails. This is because not all genes appear scaled, and your function now actually is doing that.; ```; adata.X.var(0); ```. ```; array([0.9996213 , 0.97964925, 0.29805112, ..., ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2629#issuecomment-1708220273:956,test,test,956,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629#issuecomment-1708220273,1,['test'],['test']
Testability,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please; 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`; 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3167#issuecomment-2252216712:505,test,tests,505,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167#issuecomment-2252216712,2,['test'],"['test', 'tests']"
Testability,"Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; ```python; adata.var['mt'] = adata.var_names.str.startswith('MT-'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); ```. ```pytb; TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2189:928,log,logging,928,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189,1,['log'],['logging']
Testability,"Hi, yes, i will start adding tests. ; And i think it can be useful but only if you have time for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-520006052:29,test,tests,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-520006052,1,['test'],['tests']
Testability,"Hi,. Currently using covariates in `sc.tl.rank_genes_groups()` is not implemented. In the Wilcoxon and t-test versions this is also not possible. However, in logistic regression this could be added. As a coarse approximation you could correct for batch using `sc.pp.combat()` and then use the corrected data instead of `adata.raw` (which is the default) to calculate marker genes. However, generally I would not recommend performing statistical analysis on batch-corrected data for other tests. Regarding your `anndata2ri` error... you could also check `adata.var` columns to see if any are categorical, but numeric.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691#issuecomment-502549720:105,test,test,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502549720,3,"['log', 'test']","['logistic', 'test', 'tests']"
Testability,"Hi,. I am specifically trying to test something with random_state in sc.tl.umap, and would like to get more info on what random number generator is used. The docs there say that np.random is used if random_state=None, but does not explicitly comment on what the random number generator is otherwise. Could you please help clarify this?. Thank you!; Byron. <!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1626:33,test,test,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1626,1,['test'],['test']
Testability,"Hi,. I am testing `pl.scatter` and it seems that:; - `color` cannot be a list (contrary to what the documentation mentions); - `components='all'` raises the error: `ValueError: invalid literal for int() with base 10: 'all'`. Any idea how to fix that?. Bérénice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/311:10,test,testing,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311,1,['test'],['testing']
Testability,"Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```; >>> import scanpy.api as sc; >>> adata = sc.datasets.krumsiek11(); >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False); ```. No problem, but if I run:. ```; >>> import scanpy.api as sc; >>> adata = sc.datasets.krumsiek11(); >>> adata.write('anndata.h5ad'); >>> adata = sc.read_h5ad('anndata.h5ad'); >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False); ```. then I got the error:. ```; Traceback (most recent call last):; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin; orient='vertical', scale=scale, ax=ax, **kwds); File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot; color, palette, saturation); File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__; self.establish_variables(x, y, hue, data, orient, order, hue_order); File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables; raise ValueError(err); ValueError: Could not interpret input 'variable'; ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea?. Bérénice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/318:10,test,testing,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318,2,['test'],"['tested', 'testing']"
Testability,"Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function; 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Bérénice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/310:10,test,testing,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310,1,['test'],['testing']
Testability,"Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`.; I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```; Traceback (most recent call last):; File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path; idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[; File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__; return self._getitem_column(key); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column; return self._get_item_cache(key); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache; values = self._data.get(item); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get; loc = self.items.get_loc(item); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc; return self._engine.get_loc(self._maybe_cast_indexer(key)); File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/328:198,test,tested,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328,1,['test'],['tested']
Testability,"Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```; Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV); Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110; Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11; Termination Reason: Namespace SIGNAL, Code 0xb; Terminating Process: exc handler [0]. VM Regions Near 0x110:; --> ; __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:; *** multi-threaded process forked ***; crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread; 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108; 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546; 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757; 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182; 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807; 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215; 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188; 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463; 8 org.python.python 	0x0000000102ac30e6 call_function + 491; 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659; 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747; ```. Here's what I was running to cause that:. ```python; import numpy as np; import scanpy.api as sc; from anndata import AnnData; from scipy.sparse import random. adata ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/182:40,test,test,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182,2,"['log', 'test']","['log', 'test']"
Testability,"Hi,. I have been Scanpy for a short time and I find it really great!; However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types.; When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```; ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 374 adata.uns[key_added]['names'] = np.rec.fromarrays(; 375 [n for n in rankings_gene_names],; --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]); 377; 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder); 632 # populate the record array (makes a copy); 633 for i in range(len(arrayList)):; --> 634 _array[_names[i]] = arrayList[i]; 635; 636 return _array. ValueError: setting an array element with a sequence; ```. Do you have any idea of what could cause this error?. Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365:722,test,test,722,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365,1,['test'],['test']
Testability,"Hi,. I just made a test and it seems that it is indeed a problem of non-sparse matrix. How can I render the matrix sparse again from one that is dense? Is there something similar to the `adata.X.todense()` command?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/641#issuecomment-491768644:19,test,test,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/641#issuecomment-491768644,1,['test'],['test']
Testability,"Hi,. I started playing around with `vcenter` and adding support for it in plotting functions. This allows us to do things like:. ```python; import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.log1p(adata); sc.pp.scale(adata); genes = ['Cst3', 'Car1', 'Cd34', 'Apoe', 'Top2a', 'Ccl5', 'Ctsw']; sc.pl.matrixplot(adata, genes, groupby='paul15_clusters', vmin=-2, vmax=5, vcenter=0, cmap='RdBu_r'); ```. ![image](https://user-images.githubusercontent.com/1140359/102667661-ebdcac00-4157-11eb-9aac-d610283511e2.png). I haven't gone further before asking you if it makes sense at all, or not. If yes, I can try to write tests too. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551:619,test,tests,619,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551,1,['test'],['tests']
Testability,"Hi,. I was always a bit perplexed by Scanpy's logo (some sort of shrimp? ant?), since the name doesn't make me think of an animal. Would you mind explaining, @falexwolf? Is it, maybe, a pun on ""scampi""? Because that would explain it. thanks,; Niko",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1347:46,log,logo,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347,1,['log'],['logo']
Testability,"Hi,. I was testing the different functions and found out that some requirements were missing and so in the `requirements.txt`. I tried to add the one I could find on Pypi. Bérénice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/305:11,test,testing,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/305,1,['test'],['testing']
Testability,"Hi,. I wonder whether you have a gene with constant expression value in there... that sounds like it might break the regression step. Otherwise, I would argue that subsetting to highly variable genes for regressing out a covariate is completely fine. In the end you are probably regressing out a covariate to improve the embedding. That is anyway only done on the highly variable genes, so other genes won't affect that. The only thing that might not be ideal is that you don't have the ""corrected"" data (data after regressing out your covariate) for plotting gene expression values, as you probably don't want to do any testing on the corrected data anyway. Still... it should be possible to do this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/667#issuecomment-497027543:621,test,testing,621,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-497027543,1,['test'],['testing']
Testability,"Hi,. I've tried to reproduce this with scanpy 1.4.3+80.g740c557 on the pbmc68k_reduced dataset and it works for me. I did the following:. ```; adata = sc.datasets.pbmc68k_reduced() ; sc.pp.filter_cells(adata, min_counts=10) ; sc.pp.filter_genes(adata, min_cells=5) ; sc.pp.normalize_per_cell(adata) ; sc.pp.log1p(adata); sc.tl.rank_genes_groups(adata, groupby='bulk_labels', groups=['CD56+ NK', 'Dendritic', 'CD34+'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); ```. The `sc.tl.rank_genes_groups()` call is taken more or less from your example. Could you check that this works for you, and otherwise provide a minimal reproducible example that I could test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/706#issuecomment-505335006:702,test,test,702,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706#issuecomment-505335006,1,['test'],['test']
Testability,"Hi,. In scanpy 1.1, sc.pl.pca() and sc.tl.tsne() output changes (but still very similar) if they are executed more than once over an object. I have already set random_state value. I've tested that behavior in different installations in different operating systems. Is there a reason for that? I find that behavior baffling and I don't know which output should be trusted: the first time the functions are run or the following?. Thanks for your time.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/203:185,test,tested,185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/203,1,['test'],['tested']
Testability,"Hi,. Just wanted to start the PR. Passes the tests except one. Also need to deal with solver names since they don't correspond to anything dask uses. Also refactored where the DaskArray mock class is. Pinging @ivirshup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2563:45,test,tests,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2563,2,"['mock', 'test']","['mock', 'tests']"
Testability,"Hi,. Reordering the categories of groups in obs leads to shuffling of marker genes to the wrong groups when using `sc.tl.rank_genes_groups`. Interestingly, this only happens if I use `method='logreg`. It works fine with `method='t-test`. I am not sure how relevant this is. Maybe, one should not reorder categories. However, this was helpful to me when I wanted to plot the categories in a certain order. Here comes a minimal example:. ```; import pandas as pd; import scanpy.api as sc. adata = sc.datasets.blobs(640, 3); sc.tl.pca(adata); sc.pp.neighbors(adata); sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method); print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.obs['louvain'].cat.reorder_categories(['2', '1', '0'], inplace = True). sc.tl.rank_genes_groups(adata, 'louvain', method=method); print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)); ```; The result looks like this:; ```python; 0 1 2; 0 570 63 126; 2 1 0; 0 570 63 126; ```; The expected result would be that the marker genes end up in the same groups as above (watch the change in the lowest row):; ```python; 0 1 2; 0 570 63 126; 2 1 0; 0 126 63 570; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/273:192,log,logreg,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273,3,"['log', 'test']","['logreg', 'test']"
Testability,"Hi,. Thank you for the great tool. I think this is not a bug. . Recently I upgraded some packages and found my results were different from the previous runs. I figured out that it is caused by different versions of `pynndescent` (0.4.7 vs 0.5.1), which is recommended to use in UMAP. So I think `pynndescent` should be included in the output of `sc.logging.print_header()`. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.1; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; constants NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 3.1.0; highs_wrapper NA; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.1; numba 0.52.0; numexpr 2.7.2; numpy 1.19.5; packaging 20.8; pandas 1.2.1; pkg_resources NA; pynndescent 0.5.1; pyparsing 2.4.7; pytz 2020.5; scanpy 1.6.1; scipy 1.6.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; statsmodels 0.12.1; tables 3.6.1; texttable 1.6.3; umap 0.4.6; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.10; 40 logical CPU cores, x86_64. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1613:349,log,logging,349,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1613,2,['log'],"['logging', 'logical']"
Testability,"Hi,. Thank you for your prompt reply and suggestions. I checked the `adata.obs[""n_counts]` and `adata.X` comparing them among the different tests and they are actually identical.; I also identified why there was a stochastic effect in the jitter plots inside the violin plots.; It is due to the `numpy` random seed; indeed, if you call `numpy.random.seed(N)` before calling the `scanpy.pl.violin` function, you obtain the same violin plots.; Notice that you have to call it before every call of `scanpy.pl.violin`.; It seems that the seed is reset somewhere in the code. Best wishes,; Simone",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/977#issuecomment-573112548:140,test,tests,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/977#issuecomment-573112548,1,['test'],['tests']
Testability,"Hi,. Thank you so much for the prompt response. I was able to make the comparisons following your method. As you suggested, I am going to try using MAST or limma for DEG testing in the future. Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447417086:170,test,testing,170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447417086,1,['test'],['testing']
Testability,"Hi,. This can be done by subsetting your dataset to the cluster you're interested in and then using the `.obs` column where you store your condition information to do the differential testing. Something like this might work (note i didn't check for typos):. ```; WT_Donuts_clust1 = WT_Donuts[WT_Donuts.obs.leiden.isin(['1'])]; sc.tl.rank_genes_groups(WT_Donuts_clust1, 'condition', method='t-test', groups=['mut'], reference='ctrl', key_added='mut_up_ctrl_down'); sc.pl.rank_genes_groups(WT_Donuts_clust1, n_genes=5, key='mut_up_ctrl_down'); ```. This code makes the assumption that you have `adata.obs['condition']` which stores the categories `'mut'` and `'ctrl'`, and that you are interested in adata.obs['leiden'] == '1'`. Change these values to match your data.; In the above code you will get the top 5 genes that are up-regulated in `'mut'` compared to `'ctrl'`. If you want the up-regulated genes in `'ctrl'` compared to `'mut'`, just switch around the keywords above. There are of course better, more sensitive tests for differential expression than a t-test, but if you just want a quick top 5... then this should be fine. Also note that your use of `use_raw=False` may be dangerous. You should probably be doing a t-test on log-normalized data (not batch corrected, or scaled data, or data where any covariates were regressed out). The t-test assumes normally distributed data, which is approximated by log-normalization.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1035#issuecomment-583749392:184,test,testing,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035#issuecomment-583749392,8,"['log', 'test']","['log-normalization', 'log-normalized', 'test', 'testing', 'tests']"
Testability,"Hi,. We get this error without swapping axes:. The code is ; ```; genes = [""DES"", ""CD34"", ""COL1A1""]; sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1"", ); ```; The error is ; ```; IndexError Traceback (most recent call last); <ipython-input-35-8f09494e5255> in <module>; ----> 1 sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1""). ~/anaconda3/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); 929 axs_list.append(ax); 930 ax = sns.violinplot('variable', y='value', data=df, inner=None, order=order,; --> 931 orient='vertical', scale=scale, ax=ax, color=row_colors[idx], **kwds); 932 ; 933 if stripplot:. IndexError: list index out of range; ```. However, I would still consider the addition because in many cases where the amount of genes is considerable, if the user wants the genes to be in the rows, `swap_axes = True` should be necessary, and they would not be able to color the violins according to the clusters of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/465#issuecomment-461450618:459,log,log,459,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/465#issuecomment-461450618,1,['log'],['log']
Testability,"Hi,. You are correct that DE testing should be performed on raw or normalized data, but not on batch-corrected data. `sc.tl.rank_genes_groups()` doesn't let you include covariates, but there are plenty of methods that do. You could look into `diffxpy` for this, which is also based on AnnData and is easily integrated into a scanpy script. Otherwise, I have a case study for a best practices workflow, which uses MAST. You could reuse code from there as well. You can find the case study [here](https://www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/669#issuecomment-497118928:29,test,testing,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/669#issuecomment-497118928,1,['test'],['testing']
Testability,"Hi,. You could just create a new `.obs` variable with the two groups and the perform `sc.tl.rank_genes_groups()` over this variable. For example, you could do something like this:. ```; adata.obs['groups'] = ['group 1' if int(i) < 9 else 'group 2' for i in adata.obs['louvain']]; sc.tl.rank_genes_groups(adata, groupby='groups', key_added='group_DE_results'); ```. as there are only two groups the top-ranked genes for either groups will be the up-regulated genes in that group (and down-regulated in the other group) that are most differentially expressed between the groups. . You should however note that `rank_genes_groups` is not a particularly sensitive test for differential gene expression. While it is good for a quick exploratory analysis, other tools like limma or MAST may give you more DEG results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447140464:660,test,test,660,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447140464,1,['test'],['test']
Testability,"Hi,. `sc.tl.rank_genes_groups()` treats each gene as an independent variable in the test. Thus, the only difference if you were to subset the genes would be that the multiple testing correction would be over fewer genes. You can also do that manually by looking at the `adata.uns['rank_genes']['pvals'][CLUSTER_ID]` and doing the multiple-testing correction yourself over the gene set you care about. However, the p-values of this test are inflated anyway, and therefore they should be used with caution. You should be able to extract your test results of interest by doing something along the lines of this:; ```; CLUST_ID = 0; gene_list = ['Gabrg1', 'Ntrk1', 'Htr1a', 'Plaur', 'Il31ra', 'Gabrg3', 'P2rx3', 'Oprk1', 'P2ry1', 'Cnih3']; gene_mask = [gene in gene_list for gene in adata.uns['rank_genes']['names'][CLUST_ID]]; results = adata.uns['rank_genes']['pvals'][CLUST_ID][gene_mask]; ```. Then you need to perform multiple testing correction over those p-values. And that would be the result you would get from a subsetting. However, multiple-testing over only those values, assumes you will not use the other gene results for anything. If you use the other gene results for something else, then you should just use the results of `sc.tl.rank_genes_groups()` as it is. Also note that `sc.tl.rank_genes_groups()` doesn't really tell you the contribution of genes to the clustering, but it just tells you what genes are characteristic of a cluster in the output. Those aren't the same things. For example, one gene could have been responsible for partitioning the data into 2 parts, but then after subclustering those 2 parts it may not show up as a marker gene in the `sc.tl.rank_genes_groups` results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/748#issuecomment-515061065:84,test,test,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/748#issuecomment-515061065,7,['test'],"['test', 'testing']"
Testability,"Hi,. thanks for you interest in scanpy!. Does this issue still persist for you?; If yes, is it possible to extend your example so that I can test it too, to see what might cause the computation to fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2472#issuecomment-1718993973:141,test,test,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472#issuecomment-1718993973,1,['test'],['test']
Testability,"Hi,. thanks for your interest in scanpy!. Regarding your question on ordering, and test statistic scores vs p-values:. 1. The structured array is [ordered according to scores](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.rank_genes_groups.html#scanpy.tl.rank_genes_groups), not the p-values. 2. For tests with a signed test statistic (for example the t-test and the wilcoxon test), a ‘larger’ score does necessarily correspond to a lower p-value: rather, a score ‘further away from 0’ corresponds to lower p-value. Hence as currently the output stored in `adata.uns['rank_genes_groups']` is ordered according to scores, this does not mean it is ordered according to p-values. To the part where you mention you went into the code: My best guess is you refer to [this computation](https://github.com/scverse/scanpy/blob/1df92d61f00cec83b2ab2feb9c977cfcda84ebc0/scanpy/tools/_rank_genes_groups.py#L290). Here, considering the absolute value is used to get the two tails of the distribution when using the survival function (`stats.distribution.sf`). Generally if you’re interested in the Wilcoxon computation and the normal approximation used here, you can check [this](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test) for a start. This also introduces the relation between the scores and the p-value. Hope this helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586#issuecomment-1717970663:83,test,test,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-1717970663,5,['test'],"['test', 'tests']"
Testability,"Hi,; I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:; ```python; sc.pl.pca_variance_ratio(adata_h, log=True, save=True); ```; Result:; ```; /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log; if log: scores = np.log(scores). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-7-48cc676a34cc> in <module>(); 1 # log is natural logarithm; ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save); 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}.; 158 """"""; --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log); 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save); 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show); 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]); 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,; --> 557 (1.05 if score_max > 0 else 0.95) * score_max); 558 if show == False: return gs; 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs); 1588 if not args and not kwargs:; 1589 return ax.get_ylim(); -> 1590 ret = ax.set_ylim(*args, **kwargs); 1591 return ret; 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in set_ylim(self, bottom, top, emit, auto, **kw); 3455 bottom, top = bot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/264:204,log,log,204,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264,8,['log'],"['log', 'logarithm']"
Testability,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1468:961,log,logging,961,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468,2,['log'],"['logg', 'logging']"
Testability,"Hi,; I have some problems running Louvain clustering.; The first time I tried to run, it complains about missing library `igraph`.; I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```; ---------------------------------------------------------------------------; DeprecationWarning Traceback (most recent call last); <ipython-input-17-329d7c2ac26c> in <module>(); ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy); 79 directed = False; 80 if not directed: logg.m(' using the undirected graph', v=4); ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed); 82 if flavor == 'vtraag':; 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed); 92 def get_igraph_from_adjacency(adjacency, directed=None):; 93 """"""Get igraph graph from adjacency matrix.""""""; ---> 94 import igraph as ig; 95 sources, targets = adjacency.nonzero(); 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(); 6 __license__ = ""MIT""; 7 ; ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, ""; 9 ""this visualization library has been renamed to ""; 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.; ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```; import jgraph as ig; ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,; Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/138:684,log,logg,684,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138,1,['log'],['logg']
Testability,"Hi,; I have two levels in my ```groupby``` variable and was trying to find the differential expression genes between the two levels using the wilcoxon rank sum test. The following two commands will give different pvals and slightly different logfoldchanges; ```; sc.tl.rank_genes_groups(adata, groupby='status', groups=['ALS'], reference='ctrl', n_genes=100000, method='wilcoxon', use_raw=False); sc.tl.rank_genes_groups(adata, groupby='status', groups=['ctrl'], reference='ALS', n_genes=100000, method='wilcoxon', use_raw=False); ```; ```; 	gene	logfoldchanges_ALS_ctrl	pvals_ALS_ctrl	logfoldchanges_ctrl_ALS	pvals_ctrl_ALS; 0	SLC11A1	2.9489155	5.91E-75	-2.9489155	2.08E-73; 1	NEAT1	1.1250153	5.11E-66	-1.1250151	6.82E-64; 2	FKBP5	2.7334108	8.94E-47	-2.7334108	1.78E-45; 3	SPP1	2.1242297	2.27E-42	-2.1242297	2.69E-41; 4	FCGR3A	2.6661332	6.95E-40	-2.6661332	5.37E-39; 5	HAMP	5.394592	1.27E-37	-5.394592	2.27E-36; 6	CD163	3.0886266	9.11E-36	-3.0886264	1.71E-34; 7	RASSF4	2.3211384	2.83E-34	-2.3211384	3.74E-33; 8	DSE	2.8529236	7.43E-33	-2.8529236	7.86E-32; 9	MAFB	2.7013724	3.67E-32	-2.7013724	6.43E-31; 10	DENND3	1.4753485	5.13E-29	-1.4753484	1.19E-27; 11	APOE	1.4111803	1.12E-28	-1.4111804	9.04E-28; 12	C1QB	1.5169998	3.53E-27	-1.5169998	1.68E-25; 13	C3	1.3675922	1.05E-25	-1.3675922	2.62E-25; ```; Am I not doing it right, or because of the tie issue mentioned here?; #698 ; Thanks for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/754:160,test,test,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754,2,"['log', 'test']","['logfoldchanges', 'test']"
Testability,"Hi,; I was trying to run the quick example described in the magic api cmd using datasets.paul15 but it keeps on giving me the same error. See below the code I used and the error it gives. . import numpy as np; import pandas as pd; import scanpy.api as sc; import matplotlib.pyplot as pl; import phate; import magic. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures; sc.logging.print_version_and_date(); # we will soon provide an update with more recent dependencies; sc.logging.print_versions_dependencies_numerics(). Running Scanpy 1.2.2+72.gbc6661c on 2018-07-18 19:40.; Dependencies: anndata==0.6.5 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . adata = sc.datasets.paul15(). WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical. sc.pp.normalize_per_cell(adata); sc.pp.sqrt(adata); adata_magic = sc.pp.magic(adata, name_list=['Mpo', 'Klf1', 'Ifitm1'], k=5); adata_magic.shape. computing PHATE. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-79-129f35d34dbd> in <module>(); 2 sc.pp.normalize_per_cell(adata); 3 sc.pp.sqrt(adata); ----> 4 adata_magic = sc.pp.magic(adata.X, name_list=['Mpo', 'Klf1', 'Ifitm1'], k=5); 5 adata_magic.shape. ~/software/scanpy/scanpy/preprocessing/magic.py in magic(adata, name_list, k, a, t, n_pca, knn_dist, random_state, n_jobs, verbose, copy, **kwargs); 131 n_jobs=n_jobs,; 132 verbose=verbose,; --> 133 **kwargs).fit_transform(adata,; 134 genes=name_list); 135 logg.info(' finished', time=True,. TypeError: 'module' object is not callable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/208:498,log,logging,498,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/208,5,['log'],"['logarithmized', 'logg', 'logging']"
Testability,"Hi,; I'd like to plot a bunch of figures using the sc.pl.xx functions.; Is there some solution to suppress the Warning message during saving the figure?; the warning looks like that:; ```; WARNING: saving figure to file /home/test/figure/umap.marker1.png; WARNING: saving figure to file /home/test/figure/umap.marker2.png; WARNING: saving figure to file /home/test/figure/umap.marker3.png; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2238:226,test,test,226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2238,3,['test'],['test']
Testability,"Hi,; I'm encountering an error when trying to write result file, after perform cell cycle score.; After normalizing, I import cell cycle file and perform the score:. `cc_genes=[gene.strip() for gene in open('[my_cell_cycle_genes]')]; s_genes=[g for g in cc_genes[:43] if g in adata.var_names]; g2m_genes=[g for g in cc_genes[43:] if g in adata.var_names]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes, g2m_genes=g2m_genes); `. The field 'phase' of the obs. matrix is of type object:; `adata.obs.phase.dtypes; dtype('O')`. When I write the annData object, I got the error:; `adata.write(results_file); ... storing 'phase' as categorical; TypeError: Categorical is not ordered for operation max; you can use .as_ordered() to change the Categorical to an ordered one`. and now the field 'phase' is categorical:; `adata.obs.phase.dtypes; CategoricalDtype(categories=['G1', 'G2M', 'S'], ordered=False)`. I can modify it as suggested, but it's converted into categorical when writing file again.; Following my version packages:; `sc.logging.print_versions(); scanpy==1.4.2 anndata==0.6.17 umap==0.3.7 numpy==1.16.3 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1`. My annData, also on a subset of variables, is too big to attach here, but I could send you by email if you need it. Thanks a lot!; Raffaella",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/645:1034,log,logging,1034,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/645,1,['log'],['logging']
Testability,"Hi,; I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`?. Something like this:; ```; adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0); sc.pp.regress_out(adata, genes_of_interest); ```; If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:; ```; adata_tmp = adata.copy(); sc.pp.scale(adata_tmp); adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0); sc.pp.regress_out(adata, genes_of_interest); ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/492#issuecomment-465046253:769,test,tested,769,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492#issuecomment-465046253,1,['test'],['tested']
Testability,"Hi,; I'm using the version from the main branch ```scanpy==1.4.5.dev104+g1a5defb```, and got some warnings at start up:; ```py; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc; sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_versions(); ```. ```; /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function annotate_doc_types at 0x2ac365a5f200>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function matrix at 0x2ac36c882950>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries at 0x2ac36c897830>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries_subplot at 0x2ac36c8977a0>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries_as_heatmap at 0x2ac36c8978c0>; warnings.warn(f""Found an util with public name: {obj}""); ```. ```; scanpy==1.4.5.dev104+g1a5defb anndata==0.6.22.post1 umap==0.3.10 numpy==1.16.4 scipy==1.3.1 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/840:344,log,logging,344,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/840,1,['log'],['logging']
Testability,"Hi,; Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/188:64,log,logarithmized,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188,2,['log'],"['logarithmize', 'logarithmized']"
Testability,"Hi,; Thank you for your amazing package!. I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? ; Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful.; Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1869:228,log,logfoldchanges,228,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869,3,"['log', 'test']","['logfoldchanges', 'test']"
Testability,"Hi,; Thank you so much! It worked this time! I got a lot ""Keyerror"" before, but I tried your tested code, it worked perfectly! ; I really appreciate it!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1035#issuecomment-585508877:93,test,tested,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035#issuecomment-585508877,1,['test'],['tested']
Testability,"Hi,; Thanks a lot for the library. We're having some issues with Wilcoxon-Rank-Sum test in `rank_genes_groups`. And I noticed a suspicious code in the [implementation](https://github.com/theislab/scanpy/blob/9b71dab77768fe0eb8b86aed473bee76b3aefd8e/scanpy/tools/_rank_genes_groups.py#L311):; ```; scores[left:right] = np.sum(ranks.loc[0:n_active, :]); ```. Shouldn't it be `.iloc`?. Additionally, it seems there is no tie correction in the code. I think for sparse data correction this could be an issue. ![image](https://user-images.githubusercontent.com/671660/59773834-9ac3d180-92ae-11e9-9530-b8d271bd58e5.png). There is an [implementation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.tiecorrect.html?highlight=tiecorrect#scipy.stats.tiecorrect) of `tiecorrect` in scipy. Thanks,; Iakov",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/698:83,test,test,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/698,1,['test'],['test']
Testability,"Hi,; could you please try ; ```; sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata); ```; As highly_variable_genes expects logarithmized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-445038953:127,log,logarithmized,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-445038953,1,['log'],['logarithmized']
Testability,"Hi,; currently, our notebooks tests fail (see https://travis-ci.com/github/theislab/cellrank_notebooks/jobs/357647707) because of missing `exists_ok` in `mkdir`.; `_check_datafile_present_and_download` eventually calls `_download` (where `exists_ok=True`), so I've deferred creation + logging of the directory to `_download`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1305:30,test,tests,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305,2,"['log', 'test']","['logging', 'tests']"
Testability,"Hi,; the parameter `log_transformed` looks as it's not used inside the method.; Is it a stub or is it used in other ways?. https://github.com/theislab/scanpy/blob/9b71dab77768fe0eb8b86aed473bee76b3aefd8e/scanpy/tools/_rank_genes_groups.py#L28",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/671:88,stub,stub,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/671,1,['stub'],['stub']
Testability,"Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers; Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162:307,test,test,307,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162,3,['test'],['test']
Testability,"Hi. I have successfully installed scanpy but ; ImportError Traceback (most recent call last); <ipython-input-5-99fcf407c387> in <module>; ----> 1 import scvelo as scv; 2 import scanpy as sc; 3 import numpy as np. ~/anaconda3/lib/python3.7/site-packages/scvelo/__init__.py in <module>; 14 del version; 15 ; ---> 16 from .read_load import AnnData, read, read_loom, load, read_csv, get_df, DataFrame; 17 from .preprocessing.neighbors import Neighbors; 18 from .tools.run import run_all, test. ~/anaconda3/lib/python3.7/site-packages/scvelo/read_load.py in <module>; 10 from scipy.sparse import issparse; 11 from anndata import AnnData; ---> 12 from scanpy import read, read_loom; 13 ; 14 . ImportError: cannot import name 'read' from 'scanpy' (unknown location). Would you please help me to fix this problem. Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1433:484,test,test,484,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433,1,['test'],['test']
Testability,"Hi. Maybe I can help a little as well. Typically batch correction or data integration methods would be used to obtain good clustering of the data, however once differential testing is performed it is still unclear whether the corrected data can or should be used (no batch correction method is perfect and may overcorrect). The standard strategy would be to correct for batch, and any other covariates that you are not interested in for the clustering process. Once you have the clusters, it is standard practice to go back to the raw data and use a differential testing algorithm that allows you to account for batch and other technical covariates in the model (e.g. MAST).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/168#issuecomment-395726806:173,test,testing,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168#issuecomment-395726806,2,['test'],['testing']
Testability,"Hi. This is unlikely to be a scanpy issue. You probably don’t have enough memory or there’s some problem with your Jupyter configuration. But in any case, we need more information to tell which one it is. Please share the logs that `jupyter lab` created, especially any stack traces around “kernel died, restarting”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2675#issuecomment-1750301889:222,log,logs,222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675#issuecomment-1750301889,1,['log'],['logs']
Testability,"Hia everyone, this should actually make`hatch test -i deps=min` work even on Macbooks. Maybe there’s a way to put the constraint file inside of the venv, then it’ll survive reboots on Linux. I tagged you all because I thought you might be interested in this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3337:46,test,test,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3337,1,['test'],['test']
Testability,"Hi，here is a bug in the funtion named ""scanpy.tl.rank_genes_groups"". I tried to filter the genes starting with ""HLA"", then I used ""scanpy.tl.rank_genes_groups"" to check the marker genes in each group. However, the genes starting with ""HLA"" still existed. ### Minimal code sample (that we can copy&paste without having any data). ```python; no_HLA_genes =~adata.var_names.str.startswith(('HLA')); adata = adata[:, no_HLA_genes].copy(); print(adata.var_names[adata.var_names.str.startswith(('HLA'))]); ```; output: Index([], dtype='object'). ```python; sc.tl.rank_genes_groups(adata , 'leiden_r2', method='wilcoxon',n_genes=-1); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(20); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names; pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names','logfoldchanges']}).head(20); ```; ![image](https://user-images.githubusercontent.com/53402047/96684056-8feee480-13ad-11eb-9aef-00858ce3394e.png). #### Versions. <details>; scanpy==1.5.1 anndata==0.7.1 umap==0.4.6 numpy==1.17.3 scipy==1.5.2 pandas==0.23.4 scikit-learn==0.23.2 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1461:870,log,logfoldchanges,870,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1461,1,['log'],['logfoldchanges']
Testability,"Hm, I am a bit lost wrt to the checks failing @giovp ; the doc build doesn't show any logs and travis fails because of black complaining about scanpy/tools/_sim.py and some version checking problem. None of this seems related to my PR 🤔",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1811#issuecomment-827726391:86,log,logs,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1811#issuecomment-827726391,1,['log'],['logs']
Testability,"Hm, I've wanted to add a PAGA notebook to the tests and I'm struggling to get it to run on travis. The tests run through for me on a MacBook and on a remote linux machine, but travis seems even to be able to produce differently-shaped output images: https://travis-ci.org/theislab/scanpy/jobs/450416143. My current suspicion is that networkx does something strange as it really only affects the graph plot... I'll investigate further, but if you've seen this already, a hint would be very welcome! 🙂",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-435650013:46,test,tests,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-435650013,2,['test'],['tests']
Testability,"Hm, strange, the notebook is in the tests... I also just ran it through myself, manually, everything got me exactly the same results as available online: my versions are; ```; scanpy==1.3.7+86.g2c80c7a anndata==0.6.17+1.ga0cd0c6 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Could it be that you're using an older anndata or scanpy or something? I think I added the notebook to the tests around Scanpy 1.3 or so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/445#issuecomment-457346216:36,test,tests,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445#issuecomment-457346216,2,['test'],['tests']
Testability,"Hm, the tests work for me. And I never set up a specific environment. Obviously, they also run through on Travis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-432352461:8,test,tests,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-432352461,1,['test'],['tests']
Testability,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:41,test,test,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,12,['test'],"['test', 'tests']"
Testability,"Hm, yes it's nice that things are simpler now, but the point of the script before was to use the fast installation of the conda binaries... . Before your commit: 3 min 46 s test time (https://travis-ci.org/theislab/scanpy/builds/454438531?utm_source=github_status&utm_medium=notification). After your commit: 6 min 46 s test time (https://travis-ci.org/theislab/scanpy/builds/454487170?utm_source=github_status&utm_medium=notification). While the 3 min 46 s are way too long, there is still a good chance that you realize that your commit broke everything. After almost 7 min, you're almost always doing something else already. I also feel kind of bad about travis's servers. ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/360#issuecomment-439746463:173,test,test,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/360#issuecomment-439746463,2,['test'],['test']
Testability,"Hmm, I also consistently get a slightly different result for computing the mean between numpy and numba (I think it's one floating point step). When you were seeing differences, did they show up as different with `np.allclose`? If they did, I think we can go with adding a small reference test that checks with `np.testing.assert_almost_equal`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1890#issuecomment-866651210:289,test,test,289,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890#issuecomment-866651210,2,['test'],"['test', 'testing']"
Testability,"Hmm, I think it's more complicated than that. First, cell type labels may not come from clustering. Even if it's the case, the design of Louvain does not rely on univariate mean difference between groups due to the distance metrics used in kNN graph, which take all genes into account at once. . Besides, I believe that how cell types are defined e.g. by biologist's manually annotation of each cell, Louvain, bulk comparison etc. doesn't really make the null hypothesis invalid. t-test just tests if the means are the same or not. Regarding false positives with random clustering, that's why we have Bonferroni, no? But this is now a different story about p-values and multiple testing correction in general. So it's not our duty to solve it in rank_genes_group function. I'd rather prefer reporting a p-value (or maybe t-stat) and letting the user decide how valid/useful it is for his/her research instead of not outputting it with the consideration of the chance that it's not valid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-425375105:482,test,test,482,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-425375105,3,['test'],"['test', 'testing', 'tests']"
Testability,"Hmm, I'm having trouble reproducing using the same release. Could be an issue with an underlying library? I'm using a slightly newer scipy. <details>; <summary> My environment </summary>. ```; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; IPython 7.21.0; PIL 8.1.0; anndata 0.7.5; backcall 0.2.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; ipython_genutils 0.2.0; jedi 0.17.2; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; llvmlite 0.35.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; numba 0.52.0; numexpr 2.7.2; numpy 1.20.1; packaging 20.9; pandas 1.2.2; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.7.0; pygments 2.8.1; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.1; scipy 1.6.1; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; storemagic NA; tables 3.6.1; traitlets 5.0.5; wcwidth 0.2.5; -----; Python 3.8.5 (default, Sep 4 2020, 02:22:02) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2021-03-20 16:27; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1749#issuecomment-803253215:1018,log,logical,1018,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749#issuecomment-803253215,1,['log'],['logical']
Testability,"Hmm, I’m pretty happy with my self-documented test code:. ```py; def test_deferred_imports(imported_modules):; slow_to_import = {; 'umap', # neighbors, tl.umap; 'seaborn', # plotting; 'sklearn.metrics', # neighbors; 'scipy.stats', # tools._embedding_density; 'networkx', # diffmap, paga, plotting._utils; # TODO: 'matplotlib.pyplot',; # TODO (maybe): 'numba',; }; falsely_imported = slow_to_import & imported_modules; > assert not falsely_imported; E AssertionError: assert not {'scipy.stats'}; ```. Do you think this could be clearer?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/797#issuecomment-537474116:46,test,test,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797#issuecomment-537474116,4,"['Assert', 'assert', 'test']","['AssertionError', 'assert', 'test']"
Testability,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py; from __future__ import annotations. import numpy as np; from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T; expected = np.array(; [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],; dtype=np.float32,; ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)); transformed = pca.fit_transform(data).astype(np.float32); np.testing.assert_almost_equal(transformed, expected, decimal=5); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3047#issuecomment-2098389353:116,test,tests,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047#issuecomment-2098389353,2,['test'],"['testing', 'tests']"
Testability,"Hmm, you're right. I think it must have been the that the ordering of cells in the `adata` object was also non-random. We had this quite a bit in the benchmarking data integration project while plotting batch. In several methods (e.g., scanorama), individual batch anndata objects are concatenated to generate the final output, which results in batch-ordered anndata objects. . Maybe instead of just having `sort_order=False` it would be better to have randomized ordering for plotting categorical variables? Unless it is an ordered categorical I guess.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1588#issuecomment-760249638:150,benchmark,benchmarking,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1588#issuecomment-760249638,1,['benchmark'],['benchmarking']
Testability,"Hmm... you are right, that should also create an error by the above logic. It does look like this check is done for the case that `adata.n_vars < n_comps` here:; https://github.com/theislab/scanpy/blob/be1a0555252cfd97b9d00f51dc5fbab462588da0/scanpy/preprocessing/_simple.py#L472-L477. I'm not sure why that wasn't also done for `n_obs`. @Koncopd you made this fix at the time... any reason for not also checking `adata.n_obs` in the same way? Could quickly add a check for `adata.n_obs` unless there is a reason not to @ivirshup, @flying-sheep?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1051#issuecomment-586494795:68,log,logic,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051#issuecomment-586494795,1,['log'],['logic']
Testability,"Hmmm, you got it to successfully run? The last thing I had posted was failures in testing (see above)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-367706813:82,test,testing,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-367706813,1,['test'],['testing']
Testability,"How about an empty `DataFrame` instead of `None`? I think I prefer `len(results) == 0` to `results is None`. Also, I need to look into the arguments to `gprofiler` a bit more before this is ready to merge. I'd also like to add tests, but probably ones that are optional. Does `scanpy` have a preferred way of adding tests that don't run by default?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-464278846:227,test,tests,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-464278846,2,['test'],['tests']
Testability,How are you building the package and running the tests? Are you working with a clone of the repo?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969078321:49,test,tests,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969078321,1,['test'],['tests']
Testability,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'?. Manual sorting from 2 files is not quite optimal:; ```; sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names; degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]; for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}); degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""); pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']); pts.to_csv(""pts_adata.csv""); ```. Could you help with a more efficient way to do that? ; @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1455#issuecomment-1066545407:123,log,logfoldchanges,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455#issuecomment-1066545407,2,['log'],['logfoldchanges']
Testability,"How did you installed scanpy?. Try:. conda install --file requirements.txt. this may install all the right versions of the packages that you need. On Thu, Oct 4, 2018 at 2:26 AM ar-baya <notifications@github.com> wrote:. > Hi, I am reproducing this tutorial; > https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb; >; > the line sc.pp.neighbors(adata) produces the following error:; >; > Inconsistency detected by ld.so: dl-version.c: 205:; > _dl_check_map_versions: Assertion `needed != NULL' failed!; >; > Ubuntu 18.04; > Python 3.6.6; >; > scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4; > scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; >; > Can you help me? Thank You; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/280>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1Sgm2UxCRL2y2-EGlah7YmtIrmmeks5uhVXGgaJpZM4XHKo6>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-426896350:513,Assert,Assertion,513,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-426896350,1,['Assert'],['Assertion']
Testability,"Howdy y'all, working on a tool to convert packages to JSON and noticed there were some functions missing their parameters in the docstring. I've updated a few that were missing for better pydoc accessibility. All param descriptions were either copied from other similar param or made based on their functionality. - [x] Tests included or not required because:. Docstring updates only. - [x] Release notes not necessary because:. No changes to logic",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2888:320,Test,Tests,320,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2888,2,"['Test', 'log']","['Tests', 'logic']"
Testability,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console; $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no; Numba function called from a non-threadsafe context. Try installing `tbb`.; Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads.; - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):; File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _; File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get; File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks; File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", li",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478:342,test,test,342,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478,2,['test'],"['test', 'tests']"
Testability,"Huh, I don't think the tests are checking what I thought they were. . 1. It doesn't look like you can have an AnnData object with a Dask array, what am I doing wrong here?. ```python; from anndata import AnnData; import numpy as np; import dask.array as da; from scipy.sparse import csr_matrix. X_total = [[1, 0], [3, 0], [5, 6]]. adata = AnnData(np.array(X_total), dtype='float32'); print(type(adata.X) # is a numpy matrix, as expected. adata = AnnData(csr_matrix(X_total), dtype='float32'); print(type(adata.X) # is a sparse matrix, as expected. adata = AnnData(da.from_array(X_total), dtype='float32'); print(type(adata.X) # is a numpy array NOT a dask array, not what I expected; ```. 2. The change I made to `_normalize_data()` changed coercion of `counts`, not `X`. When I stepped through this private function, it seemed like things were working the way I'd expected, but there's a lot of other stuff happening before & afterwards in `normalize_total()` which I haven't looked at much. What combinations of inputs to `_normalize_data()` need to be supported?; * numpjy `X`, numpy `counts`; * dask `X`, dask `counts` ; * csr_matrix `X`, csr_matrix `counts` . Combinations?; * numpjy `X`, dask `counts`; * dask `X`, numpy `counts`; * numpjy `X`, csr_matrix `counts`; * csr_matrix `X`, numpy `counts`; * dask `X`, csr_matrix `counts`; * csr_matrix `X`, dask `counts`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1663#issuecomment-781880180:23,test,tests,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663#issuecomment-781880180,1,['test'],['tests']
Testability,"Huh, it looks like pandas does not have the option for doing a stable sort here, so maybe we should change the test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1584#issuecomment-759955470:111,test,test,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1584#issuecomment-759955470,1,['test'],['test']
Testability,"I actually had not set that attribute. But I just tested it now. ```; sc.settings.n_jobs = 15; sc.pp.neighbors(adata_B, n_neighbors=100, n_pcs=11); ```. OR. ```; sc.settings.n_jobs = 15; with parallel_backend('threading', n_jobs=15):; sc.pp.neighbors(adata_B, n_neighbors=100, n_pcs=11); ```. and in either case it only uses one cpu and takes the same amount of time as above.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/913#issuecomment-552997835:50,test,tested,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/913#issuecomment-552997835,1,['test'],['tested']
Testability,"I added UMAP support for visualization \o/ Here is how MNIST ""single cells"" look like:. ![image](https://user-images.githubusercontent.com/1140359/36549038-bee9d1c4-17bf-11e8-9383-19a70c9ee018.png). ![image](https://user-images.githubusercontent.com/1140359/36549046-c74cbcb4-17bf-11e8-9d8f-595dc7be3e8c.png). I'm not so familiar with code sytle and variable naming etc. yet, and I haven't fully tested things like additional umap kwargs ~and 3d visuazliation~ etc. but let's keep PR here and resolve things along the way.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/92:396,test,tested,396,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/92,1,['test'],['tested']
Testability,"I added a method for programmatic retrieval of mitochondrial gene symbols through BioMart (instead of using a regular expression, this may be less error-prone and constantly up-to-date).; Let me know if you are interested in merging it, and if the code style is acceptable for this library.; I was unsure on how to test it, in case do you have any suggestions?. Thanks,; Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/141:315,test,test,315,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/141,1,['test'],['test']
Testability,"I added a scalar dataset to the `scanpy/tests/_data/10x_data/1.2.0/multiple_genomes.h5` file in the last commit. Diff between the h5ls of old vs new files:. ```diff; @@ -6,6 +6,7 @@; /another_genome/genes Dataset {343/4681}; /another_genome/indices Dataset {12/8192}; /another_genome/indptr Dataset {13/8192}; +/another_genome/scalar_dataset Dataset {SCALAR}; /another_genome/shape Dataset {2/16384}; /hg19_chr21 Group; /hg19_chr21/barcodes Dataset {12/3640}; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2344#issuecomment-1267397231:40,test,tests,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344#issuecomment-1267397231,1,['test'],['tests']
Testability,I added a test and a release node,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2589#issuecomment-1666905237:10,test,test,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589#issuecomment-1666905237,1,['test'],['test']
Testability,I added a test that fails on master,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2546#issuecomment-1625353939:10,test,test,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2546#issuecomment-1625353939,1,['test'],['test']
Testability,"I added helper functions. I am working on the tests.; Apparently there's a test https://github.com/theislab/scanpy/blob/fc24dfc62c049a0d0c9cc491d4647d03b52bfb10/scanpy/tests/test_rank_genes_groups_logreg.py#L22; that fails locally in my machine.; It is because after `rank_genes_groups` categories are naturally sorted. I don't think this is due to my changes, but let me know how can I help. I am unsure why it is failing on Travis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-479539907:46,test,tests,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-479539907,3,['test'],"['test', 'tests']"
Testability,I added tests for both louvain and leiden with restrict parameter. Please review the test code to be sure it is clear and working.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-479587681:8,test,tests,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-479587681,2,['test'],"['test', 'tests']"
Testability,I added two tests in `scanpy/tests/test_embedding_density.py`... one of them just to test if the plotting functions run. Should this have been placed in a different file?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/543#issuecomment-476406754:12,test,tests,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-476406754,3,['test'],"['test', 'tests']"
Testability,I added unit tests and reformated the code.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/812#issuecomment-537955879:13,test,tests,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812#issuecomment-537955879,1,['test'],['tests']
Testability,"I addressed some of the points in your review already and will finish latest on Monday :). > > tests that check if combinations of input arguments lead to expected output (in terms of returned shapes/columns/...) and don't break the function; > > tests that check if warnings/errors are raised for ""common mistakes"" (inappropriate data, nonsense input argument combinations..); > ; > yes both makes sense, it would also be useful to come up with a dummy example for which the actual output could be tested against. This is done in seurat_v3 for instance, but in that case it's kind of straightforward because the ""expected"" is the output computed with original implementation (and as you catched in #1732 it's still might not be enough smile ).; > another random thing that comes to mind re this specific case is to make sure that indexing etc. is consistent and robust, as you seem to have to sort and resort a fair bit in the hvg implementation. Sounds good, thanks for the input! I will prepare some tests early next week.; ; > on another note, I was thinking if it makes sense to also release a short tutorial together with the PR (that would be on theislab/scanpy_tutorials) ? I think that for a lot of people the term ""pearson residuals"" could be alienating, and so they'd rather stick to `normalize_total` for comfort (but they shouldn't!). So maybe just something easy like pearson res norm + umap and hvg plots ? curious to hear what you and the others @ivirshup @LuckyMD think about it. I think that would be really nice - I'd very happy prepare to some examples if everyone agrees that this would be useful to have :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797689998:95,test,tests,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-797689998,4,['test'],"['tested', 'tests']"
Testability,"I agree and had also noticed it. Double logs make no sense. It should be the log2 basis. @a-munoz-rojas, as you implemented this, would you make PR to fix it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-470311545:40,log,logs,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470311545,1,['log'],['logs']
Testability,"I agree with @LuckyMD about the points regarding covariates. . With respect to two group comparisons without confounding, rank-sum tests have less statitical power than t-tests (https://stats.stackexchange.com/questions/130562/why-is-the-asymptotic-relative-efficiency-of-the-wilcoxon-test-3-pi-compared), disclaimer I haven't checked this proof, I think this is a standard statistics result though, this is also discussed here https://stats.stackexchange.com/questions/121852/how-to-choose-between-t-test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl. I havent run simulations to check how big the influence of the difference in power is on the kind of data we encounter. However, as also pointed out by the second link, violations of the distributional assumptions for t-test impact these results and these violations will be major on scRNAseq. Intuitively I would therefore tend to rank-sum tests. With respect to [diffxpy](https://github.com/theislab/diffxpy): We can account for other noise models in the two-group comparisons by performing model fitting, tutorial [here](https://github.com/theislab/diffxpy_tutorials/blob/master/diffxpy_tutorials/test/single/wald_test.ipynb). The bioarxiv will hopefully be up in the next few weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358:131,test,tests,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358,7,['test'],"['test', 'test-', 'test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl', 'tests']"
Testability,"I agree with malte that there's so much more ML out there that just adding a function cause it can be quickly implemented can be risky.; however if we're not the ones to try then who else should. so what if we test the leiden_multiplex in comparison to seurat's WNN on the tutorial data, and decide then? I would be surprised if we didn't find a set of params for leiden_multiplex that allows to replicate the seurat clustering results. also comes to mind similarity network fusion (implemented for citeseq in the citefuse package). prob a project of its own sake tbh. ; happy to help with this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1818#issuecomment-857832028:210,test,test,210,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818#issuecomment-857832028,1,['test'],['test']
Testability,"I agree, I've been trying to reduce the dataset and save it as 10x_h5 format again but it seems to be more complicated than I thought. I think it would be best to have an 10x_h5 format so to also use it for the read function test. Also, yes will only keep the lowres image",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1024#issuecomment-586196692:225,test,test,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024#issuecomment-586196692,1,['test'],['test']
Testability,I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1805:241,Test,Tested,241,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805,1,['Test'],['Tested']
Testability,"I also just found this: https://docs.pytest.org/en/stable/pythonpath.html#import-modes. > `importlib`: new in pytest-6.0, this mode uses importlib to import test modules.; > […]; > makes test modules non-importable by each other.; > […]; > ; > **We intend to make importlib the default in future releases.**",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1528#issuecomment-741748332:157,test,test,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528#issuecomment-741748332,2,['test'],['test']
Testability,I also re-activated tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/60:20,test,tests,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/60,1,['test'],['tests']
Testability,"I am also getting the error `RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion)` when running `sc.pp.highly_variable_genes(adata, min_mean=1.7, max_mean=5, min_disp=0.5, flavor='seurat')` on log scale data in the adata.X slot with mean=0 and max=16.336065. Any ideas?. Update: I just noticed that my adata.X contains a numpy array instead of a sparse matrix. Perhaps that's the issue? Will try updating to a sparse matrix and will report back",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561:74,log,log,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561,3,['log'],['log']
Testability,"I am also getting the error when running. sc.pp.neighbors(). AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. I tried pip uninstall numba and pip install numba==0.52.0 and numba==0.51.0, but nothing works. I had umap-learn 0.4.6, and updating it resolved the issue for me:; conda install -c conda-forge umap-learn",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799#issuecomment-867004309:61,Assert,AssertionError,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799#issuecomment-867004309,1,['Assert'],['AssertionError']
Testability,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python; colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]; test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames); test = test.stack(level=1).reset_index(); test[""group""] = test[""group""].astype(""int""); test.sort_values('group', inplace=True). test; ```; I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1530#issuecomment-1236487688:149,log,logreg,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530#issuecomment-1236487688,14,"['log', 'test']","['logfoldchange', 'logistic', 'logreg', 'test']"
Testability,"I am experiencing a similar issue with a dataset I am using. This runs fine:; ```; variable_genes_min_mean = 0.01; variable_genes_max_mean = 5; variable_genes_min_disp = 0.5. sc.pp.filter_genes_dispersion(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor='seurat',; log = True); ```. But this:; ```; variable_genes_min_mean = 0.01; variable_genes_max_mean = 5; variable_genes_min_disp = 0.5. sc.pp.highly_variable_genes(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor = 'seurat') ; ```. Throws the following error: ; ```; /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scipy/sparse/data.py:135: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: overflow encountered in log; dispersion = np.log(dispersion); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-69d6424effb2> in <module>; 3 max_mean=variable_genes_max_mean,; 4 min_disp=variable_genes_min_disp,; ----> 5 flavor = 'seurat') . /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preproces",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026:343,log,log,343,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026,1,['log'],['log']
Testability,"I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example; ```python; import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data; adata = sc.read_h5ad(dataset_path, backed='r'); print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here; ```. #### Error output; ```pytb; # I printed the AnnData object to ensure it was backed; AnnData object with n_obs × n_vars = 4166 × 16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'; obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'; var: 'gene_symbol', 'n_cells'; obsm: 'X_tsne'. # Actual error after calling log1p; Traceback (most recent call last):; File ""log1p_test.cgi"", line 129, in <module>; main(); File ""log1p_test.cgi"", line 81, in main; adata.raw = sc.pp.log1p(adata, copy=True); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p; data = data.copy(); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy; ""To copy an AnnData object in backed mode, ""; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`.; ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1153:177,log,logarithmizing,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153,2,"['log', 'test']","['logarithmizing', 'test']"
Testability,"I am not sure if it has been already addressed.; This should fix the following import error of scanpy from master, due to missing `__init__.py` in external. Probably a more clean solution would be to wrap the import for external in a try/except block. ```python; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); in ; ----> 1 import scanpy as sc; 2 sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); 3 sc.settings.set_figure_params(dpi=200) # low dpi (dots per inch) yields small inline figures; 4 sc.settings.figdir = out('fig_supp'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/__init__.py in ; 31 from . import preprocessing as pp; 32 from . import plotting as pl; ---> 33 from . import datasets, logging, queries, settings, external; 34 ; 35 from anndata import AnnData. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/external/__init__.py in ; ----> 1 from . import tl; 2 from . import pl; 3 from . import pp; 4 ; 5 from .. import _exporting as exporting. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/external/tl.py in ; 2 from ..tools._phate import phate; 3 from ..tools._phenograph import phenograph; ----> 4 from ._tools._palantir import palantir. ModuleNotFoundError: No module named 'scanpy.external._tools'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585:862,log,logging,862,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585,1,['log'],['logging']
Testability,I am not sure what king of test. I don't want to add another `save_and_compare_images` test because plots seem to depend on the system at least sometimes (i have 3 failing plotting tests locally but they run fine here).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1942#issuecomment-878118310:27,test,test,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1942#issuecomment-878118310,3,['test'],"['test', 'tests']"
Testability,"I am running Python 3.6.0. The following is the output of running just the snippet above:. > File ""test.py"", line 13, in <module>; print(ViewArgs(None, ""a"")); TypeError: __new__() missing 1 required positional argument: 'keys'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/734#issuecomment-509615807:99,test,test,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734#issuecomment-509615807,1,['test'],['test']
Testability,"I am using the latest M1 macbook pro with python 3.10.3. For some reason if you clone the repository then compile it works in python 3.9+; I cannot explain why the release tarball has issues. As per some other documentation, it is because [tp_print has been removed from type objects for python 3.9+.](https://docs.python.org/3/c-api/typeobj.html) See below. So, if you clone the repository using git and then install it works! (I am sure there is an explanation). ```; test@mac ~/PythonPackages/forceatlas2$ git pull; Already up to date.; test@mac ~/PythonPackages/forceatlas2$ pip3 install . --user; Processing /Users/test/PythonPackages/forceatlas2; Preparing metadata (setup.py) ... done; Requirement already satisfied: numpy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.21.5); Requirement already satisfied: scipy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.8.0); Requirement already satisfied: tqdm in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (4.63.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... done; Created wheel for fa2: filename=fa2-0.3.5-cp310-cp310-macosx_12_0_x86_64.whl size=155419 sha256=23d907bfec5df0e9d0d522865d1c288b1f8894134bd61b6c5a02467128dfd102; Stored in directory: /private/var/folders/0s/67yn6b6n3lx4882xx_86ps2m0000gp/T/pip-ephem-wheel-cache-i69s_t3j/wheels/51/1c/a5/5a9ef4f0bc9387d300190bc15adbb98dbda9d90c6da9c2da04; Successfully built fa2; Installing collected packages: fa2; Successfully installed fa2-0.3.5 ; test@mac ~/PythonPackages/forceatlas2$; ```. However, if you try to install the release version you get an error:. ```; test@mac ~/PythonPackages$ wget https://github.com/bhargavchippada/forceatlas2/archive/refs/tags/v0.3.5.tar.gz; --2022-03-24 02:54:21-- https://github.com/bhargavchippada/forceatlas2/archive/refs/tags/v0.3.5.tar.gz; Resolving github.com (github.com)... 140.82.114.3; Connecting to github.com (github.com)|140.82.114.3|:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:470,test,test,470,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,6,['test'],['test']
Testability,I answered that back then already. - https://github.com/scverse/scanpy/pull/2235#discussion_r850302669; - https://github.com/scverse/scanpy/pull/2235#discussion_r850304636. This PR has exactly the scope necessary to separate test utils and tests. The only thing that I can think of to add to those answers is that the repeated code for all the data fixtures is necessary to make editors understand them. A more dynamic way to make all those fixtures breaks ctrl/cmd-clicking fixtures.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1597183580:225,test,test,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1597183580,2,['test'],"['test', 'tests']"
Testability,I believe numba will always throw a warning if some part of the requested compilation failed. We could add tests for compilation based on this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/462#issuecomment-461279367:107,test,tests,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/462#issuecomment-461279367,1,['test'],['tests']
Testability,"I can add the changes you suggested but. >since if there was a bug in how `filter_rank_genes_groups` sets those values this test would still pass. this is not a test of `filter_rank_genes_groups`, we have a separate test for this. Do you think we need to double check this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1942#issuecomment-879832703:124,test,test,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1942#issuecomment-879832703,3,['test'],['test']
Testability,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni; > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy.; > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1298#issuecomment-662450011:261,test,tested,261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298#issuecomment-662450011,1,['test'],['tested']
Testability,"I can get the data by skipping the spatial plot. . If I run this in a fresh IPython session I get the attached plot. ```; import scanpy; from matplotlib import pyplot; from scanpy.tests.test_embedding_plots import HERE; from scanpy.plotting._tools import scatterplots; adata = scanpy.read_visium(HERE / ""_data"" / ""visium_data"" / ""1.0.0""); adata.obs = adata.obs.astype({'array_row': 'str'}); data_points, components = scatterplots._get_data_points(adata, ""spatial"", None, None, None); pyplot.scatter(data_points[0][:, 0], data_points[0][:, 1]); pyplot.savefig(""visium.png""). ```; ![visium](https://user-images.githubusercontent.com/975038/141928846-993b0fc9-33ad-4edf-b0b3-44b56274494e.png). If I call scanpy.pl.spatial before I call pyplot.scatter I get the black plot, so it's probably some default isn't right.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969888153:180,test,tests,180,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969888153,1,['test'],['tests']
Testability,"I can reproduce this bug on my machine as well. I can supply additional information or context if needed, and I can test fixes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2322143716:116,test,test,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2322143716,1,['test'],['test']
Testability,I can test tomorrow,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2276255849:6,test,test,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2276255849,1,['test'],['test']
Testability,I can understand your line of reasoning @a-munoz-rojas. But is it not also dangerous to allow a user an interpretation which may be incorrect? I think outputting logFC values is great... I just have issues with calling the other output P-values. It is at the very least contentious whether they are measures of significance.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-425737907:162,log,logFC,162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-425737907,1,['log'],['logFC']
Testability,"I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn; - [x] Test metric; - [x] Test deprecations",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1854:375,test,test,375,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854,3,"['Test', 'test']","['Test', 'test']"
Testability,"I checked the new tests locally, can't work out why they're not running in the CI here- hopefully it's obvious to you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-728104293:18,test,tests,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-728104293,1,['test'],['tests']
Testability,"I completely agree. It should simply go in the `test` extra. @tomwhite, would you do that? It might that the tests don't run through on Travis for some reason and then, I guess, it would be great if you could look into it (would for sure be a problem that would pop elsewhere, too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/439#issuecomment-460071018:48,test,test,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-460071018,2,['test'],"['test', 'tests']"
Testability,"I could probably be convinced to include `radius_neighbors`. I'd mainly need a test case. My initial opposition was that (1) it's a pretty trivial implementation and (2) without a real example I'm not sure if it's missing any obvious edge cases. For n-rings, I think that walking some steps from each node generalizes beyond graph construction, and might be reasonable to have as a separate method. I also haven't seen any recommendations about how to weigh the edges, which I think is pretty important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-707610846:79,test,test,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-707610846,1,['test'],['test']
Testability,"I created a PR to this branch to add GPU support for :; *`tl.rank_gene_groups` with method='logreg'; *`tl.embedding_density`; *`correlation_matrix`; *`diffmap`; I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow.; The default pca solver for device GPU is now ""auto""; I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy.; ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1189986399:92,log,logreg,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1189986399,2,['log'],['logreg']
Testability,"I definitely don't define the consensus, but I normally prefer FDR correction. It makes a bit more sense to me to correct for a false discovery rate, rather than a test-based error, if you are only interested in the rejected null hypotheses. . They also test for FDR control in a [recent comparison of differential testing methods](http://www.nature.com/doifinder/10.1038/nmeth.4612).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-428239213:164,test,test-based,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-428239213,3,['test'],"['test', 'test-based', 'testing']"
Testability,"I didn't change any defaults I think. Test fails in rename_category of pandas in pbmc, not sure it's related.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/640#issuecomment-495574383:38,Test,Test,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/640#issuecomment-495574383,1,['Test'],['Test']
Testability,I didn't know about `testing.setup()` I will take a look. Seems very promising.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-435785931:21,test,testing,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-435785931,1,['test'],['testing']
Testability,"I don't know what changes caused this, but now there are 2 problems with test_preprocessing_distributed.py. When `adata_dist.X` is a dask array, `adata_dist.X.chunks` is `((2000, 2000, 2000, 2000, 2000), (1000,))`. It leads to an error in `adata.write_zarr(temp_store, chunks)` because zarr chunks should be a tuple with an integer entry per dimension, not a tuple of tuples. The second problem is that `adata_dist.X.to_zarr(temp_store.dir_path(""X""))` causes an error because there is already `'X'` in `temp_store`, it needs to be overwritten. This pr removes these problems but maybe logic of the function should be changed somehow instead of the test.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/963:585,log,logic,585,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/963,2,"['log', 'test']","['logic', 'test']"
Testability,I don't know what is happening with the new matplotlib but I had to increase the tolerance for the image comparison in order for the tests to pass. Locally I noticed small differences in the margins and axis labels. Also I noticed that running a single test is different than running several tests at once. This probably has to do with some internal matplotlib parameters that are modified. . At least the tests are passing now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-426281432:133,test,tests,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-426281432,4,['test'],"['test', 'tests']"
Testability,I don't know what makes the tests fail with dask in utils,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3017#issuecomment-2131272074:28,test,tests,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017#issuecomment-2131272074,1,['test'],['tests']
Testability,I don't know why the tests related to violin plots fail. I assume that it has to do with different libraries that produce slightly different shapes. But without access to the images generated during the testing would be difficult to say.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/228#issuecomment-411070568:21,test,tests,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/228#issuecomment-411070568,2,['test'],"['testing', 'tests']"
Testability,I don't think we need to test against 3.8 until a stable release is out. I'm thinking we can just drop that from travis and merge?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/704#issuecomment-506145082:25,test,test,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704#issuecomment-506145082,1,['test'],['test']
Testability,"I don't think you'll be able to do this with the tracksplot. Were you looking for something more like a volcano plot?. I've used something like this snipped (using `hvplots`) for these:. ```python; import hvplot.pandas. def plot_volcano(dedf):; dedf = dedf.copy(); dedf = dedf[dedf[""pvals""].notnull()]; dedf.loc[dedf[""logfoldchanges""] == np.inf, ""logfoldchanges""] = 10; dedf.loc[dedf[""logfoldchanges""] == -np.inf, ""logfoldchanges""] = -10; return dedf.hvplot.scatter(; ""logfoldchanges"",; ""pvals"",; xlim=(dedf[""logfoldchanges""][dedf[""logfoldchanges""].abs() != np.inf].min(), dedf[""logfoldchanges""][dedf[""logfoldchanges""].abs() != np.inf].max()),; ylim=(dedf[""pvals""][dedf[""pvals""].abs() != np.inf].min(), dedf[""pvals""][dedf[""pvals""].abs() != np.inf].max() + .5),; hover_cols=list(dedf.columns),; logy=True,; flip_yaxis=True; ). plot_volcano(sc.get.rank_genes_groups(adata, ...)); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1778#issuecomment-814594367:318,log,logfoldchanges,318,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1778#issuecomment-814594367,10,['log'],"['logfoldchanges', 'logy']"
Testability,"I downloaded the github source archive at the 1.8.2 tag. The build process applies a few patches viewable [here](https://salsa.debian.org/med-team/python-scanpy/-/tree/master/debian/patches). One is a small change to some R code, and the other is I marked several more tests as needs internet because the Debian builds in an environment without network access and those ultimately tried to download something. (And it's really unclear if we can legally redistributed the 10x pbmc3k dataset.). The Debian build file is (here)[https://salsa.debian.org/med-team/python-scanpy/-/blob/master/debian/rules] though mostly it lets you see what tests I was skipping because of missing dependencies. Also if I set a color like in_tissue, or array_row the data shows up. I can paste the full build log if you'd like but this is the dependencies installed and the environment variables. . ```; Build-Origin: Debian; Build-Architecture: amd64; Build-Date: Sun, 14 Nov 2021 20:11:26 +0000; Build-Path: /<<PKGBUILDDIR>>; Installed-Build-Depends:; adduser (= 3.118),; adwaita-icon-theme (= 41.0-1),; autoconf (= 2.71-2),; automake (= 1:1.16.5-1),; autopoint (= 0.21-4),; autotools-dev (= 20180224.1+nmu1),; base-files (= 12),; base-passwd (= 3.5.52),; bash (= 5.1-3.1),; binutils (= 2.37-8),; binutils-common (= 2.37-8),; binutils-x86-64-linux-gnu (= 2.37-8),; blt (= 2.5.3+dfsg-4.1),; bsdextrautils (= 2.37.2-4),; bsdutils (= 1:2.37.2-4),; build-essential (= 12.9),; bzip2 (= 1.0.8-4),; ca-certificates (= 20211016),; coreutils (= 8.32-4.1),; cpp (= 4:11.2.0-2),; cpp-11 (= 11.2.0-10),; dash (= 0.5.11+git20210903+057cd650a4ed-3),; dbus (= 1.12.20-3),; dbus-bin (= 1.12.20-3),; dbus-daemon (= 1.12.20-3),; dbus-session-bus-common (= 1.12.20-3),; dbus-system-bus-common (= 1.12.20-3),; dbus-user-session (= 1.12.20-3),; dconf-gsettings-backend (= 0.40.0-2),; dconf-service (= 0.40.0-2),; debconf (= 1.5.79),; debhelper (= 13.5.2),; debianutils (= 5.5-1),; dh-autoreconf (= 20),; dh-python (= 5.20211105),; dh-strip-no",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616:269,test,tests,269,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616,3,"['log', 'test']","['log', 'tests']"
Testability,"I encountered the same problem, when I created a small artificial `AnnData` with a single gene in `gene_list` for some unit test. Here is my analysis of the problem:. In this line; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L182; `control_genes` was actually empty, hence the index error.; The reason for the empty `control_genes` genes is; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L173; `control_genes` contained some genes before (in my artificial case only one), but they are removed here, since the genes in `control_genes` also appeared in `gene_list`. I think this is where the bug resides:; I assume `control_genes` should not contain genes from `gene_list` in the first place. Hence, this line; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L167; would need to be changed/complemented:; An additional filter for not being a gene in `gene_list` should fix this issue, if I understand this code correctly. That being said, I suppose that this issue appears rather rarely in the realistically sized datasets. I assume, that the probability of *accidentally* picking genes from `gene_list` as `control_genes` decreases with increasing number of genes.; At least I have not encountered this exception in my experimental datasets.; Furthermore, this issue does not make the result *wrong*, as far as I understand the algorithm, because the control genes are selected randomly anyway.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2153#issuecomment-1910410846:124,test,test,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153#issuecomment-1910410846,1,['test'],['test']
Testability,I expect unrelated test fails; see #162,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/161:19,test,test,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/161,1,['test'],['test']
Testability,"I feel like it's a bit of a weird include anyways. What would you call it?. ------------. Btw, some of the matplotlib tests are being flaky with the size of the plot generated. Not really sure what's up with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2087#issuecomment-998071678:118,test,tests,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2087#issuecomment-998071678,1,['test'],['tests']
Testability,"I figured it out. I forgot that I should (or at least, I think I should?) set `adata_sub.raw = adata.sub`. Adding this step before running a new embedding and clustering seemed to have fixed my issue. I guess a follow-up question would be is this an acceptable approach? I stored my full data set in `raw` after log-normalizing my data (so, `adata.raw = adata`) during initial preprocessing. Since `adata_sub` is just a subset of `adata`, I am guessing it is ok to set `adata_sub.raw = adata.sub`?. Apologies for opening this issue based on what was an oversight on my part.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2007#issuecomment-931566526:312,log,log-normalizing,312,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2007#issuecomment-931566526,1,['log'],['log-normalizing']
Testability,"I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python; import statsmodels.api as sm; def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):; norm_gene_vars = []; del_batch = False; if ""batch"" not in adata.obs_keys():; del_batch = True; adata.obs[""batch""] = np.zeros((adata.X.shape[0])); for b in np.unique(adata.obs[""batch""]):; var = adata[adata.obs[""batch""] == b].X.var(0); print(var.shape); mean = adata[adata.obs[""batch""] == b].X.mean(0); estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var); x = np.log10(mean); if use_lowess is True:; lowess = sm.nonparametric.lowess; # output is sorted by x; v = lowess(y, x, frac=0.15); estimat_var[np.argsort(x)] = v[:, 1]; else:; estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var); # as in seurat paper, clip max values; norm_values = np.clip(; norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)); ); norm_gene_var = norm_values.var(0); norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0); ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1); median_norm_gene_vars = np.median(norm_gene_vars, axis=0); median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(; ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0; ); df = pd.DataFrame(index=np.array(adata.var_names)); df[""highly_variable_n_batches""] = num_batches_high_var; df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median_variance""] = median_norm_gene_vars; df.sort",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/993:96,test,tests,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993,2,"['log', 'test']","['log-transformed', 'tests']"
Testability,I fixed the bug: https://github.com/theislab/scanpy/commit/15593d532fbaa696bf1ea328d1991d31b334e175. . And I'll immediately make a new release and put a warning on the webpage... @Koncopd: Thank you for adding the tests!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/393#issuecomment-446373823:214,test,tests,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446373823,1,['test'],['tests']
Testability,"I forgot to mention, additionally the same code executes with no problem with older versions of the packages. I've tested it on anndata = 0.8.0 and scanpy 1.9.3 and it executes fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3102#issuecomment-2154843905:115,test,tested,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102#issuecomment-2154843905,1,['test'],['tested']
Testability,"I found the same problem in `sc.pl.dotplot`, but i found in `\scanpy\plotting\_anndata.py` 2236th line：; ```; if dendrogram_key not in adata.uns:; from ..tools._dendrogram import dendrogram. logg.warning(; f""dendrogram data not found (using key={dendrogram_key}). ""; ""Running `sc.tl.dendrogram` with default parameters. For fine ""; ""tuning it is recommended to run `sc.tl.dendrogram` independently.""; ); dendrogram(adata, groupby, key_added=dendrogram_key); ```; `dendrogram` is not add `var_names`, and i fixed it in my source code. ------; anndata 0.7.8; scanpy 1.9.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1549#issuecomment-1298339775:191,log,logg,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549#issuecomment-1298339775,1,['log'],['logg']
Testability,"I found the testing in the [original R implementation](https://github.com/willtownes/scrna2019/blob/master/util/functions.R) of the deviances, and then mirrored it in [my implementation](https://github.com/theislab/scanpy/pull/1765). Glad to hear there seems to be potential for something analogous here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-874842313:12,test,testing,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-874842313,1,['test'],['testing']
Testability,"I found this problem too. Now logFC is still calculated in this way, that I am not satisfied with. When we are talking about average fold change of gene expression, the fold change of non-loged average expression is expected. In this way people get an intuitive feeling about how many times a gene is expressed compared with another group. **So the expm() step must be done before the mean() step.** Swap this order not only changes the logFC vaule, but also loses the biological meaning and doesn't make any sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/864#issuecomment-1109443073:30,log,logFC,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/864#issuecomment-1109443073,3,['log'],"['logFC', 'loged']"
Testability,"I get inconsistent results when I use the parameter groups in `rank_genes_groups`. What I want to achieve is to focus on some groups for the DE genes computation. However, the results I get using the parameter groups, to select a subset of groups, are the same, in terms of DE genes, with respect to using the full set of groups. For example, l get different results if I run the following two snippets of code (which should provide instead the same set of DE genes).; ``` python; # Subsetting should be done by method; sc.tl.rank_genes_groups(; adata=adata,; groupby='leiden',; use_raw=False,; method='t-test',; groups=['1', '2'],; ); ```. ``` python; # Explicit subsetting; adata_f = adata[adata.obs['leiden'].isin(['1','2'])].copy(); sc.tl.rank_genes_groups(; adata=adata_f,; groupby='leiden',; use_raw=False,; method='t-test',; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/842:605,test,test,605,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842,2,['test'],['test']
Testability,"I get the error below when trying to run the following:. `>>> sc.tl.rank_genes_groups(adata, 'louvain', groups=['5','16','19','30'], reference='0', method='wilcoxon')`. ```bash; C:\Users\myuser\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py:298: RuntimeWarning: overflow encountered in long_scalars; (n_active * m_active * (n_active + m_active + 1) / 12)); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-160-dd19114ff660> in <module>; 1 #adata.obs['groups'] = ['group 1'= ['0'], 'group 2'= ['5','16','19','30']]; ----> 2 sc.tl.rank_genes_groups(adata, 'louvain', groups=['5','16','19','30'], reference='0', method='wilcoxon') # wilcoxon-rank-sum/mann-whitney u test, the default of Seurat. ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 296 ; 297 scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; --> 298 (n_active * m_active * (n_active + m_active + 1) / 12)); 299 scores[np.isnan(scores)] = 0; 300 pvals = 2 * stats.distributions.norm.sf(np.abs(scores)). ValueError: math domain error; ```. Here `adata` is real data from our lab, not the tutorial data. Have been trying to replicate the cluster analysis tutorial. All previous steps work fine. Interestingly, if I remove group '5' from the list of groups it works. Also, this error only happens with the `wilcoxon` method, not with `t-test`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530:768,test,test,768,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530,2,['test'],['test']
Testability,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2037449650:10,test,test,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2037449650,7,"['log', 'test']","['logs', 'test', 'tests']"
Testability,"I guess both distance and connectivities matrices are full, and in order to get a sparse matrix, they apply a cutoff. I guess that that cutoff is a hard cutoff on distances, and a softer cutoff on connectivities. From some tests I've done for a particular project, in some datasets there are differences between distances and connectivities, and for others aren't. We'll have to wait to see the answer.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1984#issuecomment-920706904:223,test,tests,223,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1984#issuecomment-920706904,1,['test'],['tests']
Testability,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-470456611:314,test,test,314,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470456611,5,"['log', 'test']","['log', 'test']"
Testability,I had a go a making these changes but I didn't have time to get the tests working locally so there is a fair chance I broke something in the process,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2921#issuecomment-2083598014:68,test,tests,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2921#issuecomment-2083598014,1,['test'],['tests']
Testability,"I had a look at scanpy's [setup file](https://github.com/theislab/scanpy/blob/master/setup.py) `setup.py` and realised that running. ```bash; pip install -e .; pip install "".[dev]""; ```. does neither install all packages used within Scanpy's code base nor packages required for documentation or testing. IMO, these packages should be installed in a _developer installation_ as they are all part of the development cycle. Adding a file `requirements-dev.txt` including all needed packages would be an option to allow for an easy _developer installation_ via. ```bash; pip install -e .; pip install -r requirements-dev.txt; ```. Any thoughts on this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1419#issuecomment-703124876:295,test,testing,295,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1419#issuecomment-703124876,1,['test'],['testing']
Testability,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:354,test,test,354,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541,1,['test'],['test']
Testability,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py; import anndata2ri; import logging. import rpy2.rinterface_lib.callbacks as rcb; import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR); ro.pandas2ri.activate(); anndata2ri.activate(). %load_ext rpy2.ipython; ```; Convert adata_p and adata_g to R objects. ```r; ro.globalenv['r_adata_p'] = adata_p; ro.globalenv['r_adata_g'] = adata_g; ```. ```r; %%R -w 800 -h 400 -u px. library(Seurat); library(viridis); library(viridisLite); library(ggplot2); library(cowplot). df_poor= data.frame(; total_counts = colData(r_adata_p)$total_counts,; n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,; pct_counts_mt = colData(r_adata_p)$pct_counts_mt; ). df_good= data.frame(; total_counts = colData(r_adata_g)$total_counts,; n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,; pct_counts_mt = colData(r_adata_g)$pct_counts_mt; ). #head(df); # Create a scatter plot using ggplot2; p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +; geom_point() +; scale_color_viridis() +; labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +; theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +; geom_point() +; scale_color_viridis() +; labs(title = ""good (after outlier and mitochrondrial gene removal)"") +; theme_minimal(). p2 + g2; ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1258#issuecomment-1853651085:153,log,logging,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258#issuecomment-1853651085,3,['log'],"['logger', 'logging']"
Testability,"I had to fix a few issues, if you want you can check it out: 66e64b40870035c3ee869e3baf34cf7110508d85. - I unified the parameter order with `louvain`; - I actually import it in `sc.tl`; - I added it to the docs here: https://scanpy.readthedocs.io/en/latest/api/#clustering-and-trajectory-inference; - I added a test; - I fixed the references (you had typos there: 2018 instead of 18 and a missing “L”); - You did this:. ```py; partition_kwargs['weights'] = None; if use_weights:; weights = np.array(g.es['weight']).astype(np.float64); # “weights” is never used then; ```. But I assume you meant this. Am I correct?. ```py; if use_weights:; partition_kwargs['weights'] = np.array(g.es['weight']).astype(np.float64); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/361#issuecomment-439331820:311,test,test,311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361#issuecomment-439331820,1,['test'],['test']
Testability,"I had to use the pbmc3k dataset for testing, as the error doesn't occur on blobs or pbmc68k_reduced. To test I need sufficient genes that have 0 variance in a subset of the cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/824#issuecomment-530426113:36,test,testing,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824#issuecomment-530426113,2,['test'],"['test', 'testing']"
Testability,"I have a short script which reads a tab file and writes h5 using scanpy. I've found that unless I provide a full path to the write() function or at least a relative one via ""./foo.h5"" it fails. Simplified version:. ```py; adata = sc.read(args.input_file, ext='txt', first_column_names=True).transpose(); adata.write('./test.h5') # this works; adata.write('test2.h5') # this fails; ```. Here's the stack:. ```pytb; WARNING: This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file.; Traceback (most recent call last):; File ""./convert_gear_group_single_cell_to_hdf5.py"", line 47, in <module>; main(); File ""./convert_gear_group_single_cell_to_hdf5.py"", line 43, in main; adata.write('test2.h5'); File ""/usr/local/lib/python3.5/dist-packages/anndata/base.py"", line 1471, in write; compression=compression, compression_opts=compression_opts); File ""/usr/local/lib/python3.5/dist-packages/anndata/base.py"", line 1513, in _write_h5ad; os.makedirs(os.path.dirname(filename)); File ""/usr/lib/python3.5/os.py"", line 241, in makedirs; mkdir(name, mode); FileNotFoundError: [Errno 2] No such file or directory: ''; _____________________________. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/66:319,test,test,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/66,1,['test'],['test']
Testability,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files.; With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error.; I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be?; The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step.; Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128:872,test,test,872,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128,2,['test'],['test']
Testability,"I have an AnnData object whose .X matrix has been transformed by size factor division, +1 and log. Subsequent ```sc.pp.highly_variable_genes(dataset, flavor='cell_ranger', n_top_genes=1000)``` yields the ```ValueError: Bin edges must be unique: ... You can drop duplicate edges by setting the 'duplicates' kwarg``` error discussed above. Transformation to a sparse matrix did not alleviate the error, and neither did any other solutions suggested. Edit: **However!** While I could not get ```flavor='cell_ranger'``` to work on the data I normalised myself, ```flavor='seurat'``` has worked okay. Therefore, I recommend people also encountering this error to stick with this second flavour, because as I understand it they utilise a similar methodology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-751495201:94,log,log,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-751495201,1,['log'],['log']
Testability,"I have gotten fairly different clustering results when using `svd_solver='arpack'` in all but 1 case actually. The biological interpretation is still roughly the same, but the depth of subclustering you can do does differ. Based on a preliminary test, using arpack for all `sc.pp.pca()` calls does improve the reproducibility, although clustering results still differ (tested on Fedora 25 and Fedora 28, e.g. cluster sizes change by 100-200 cells). I can show you the differences when you're around next if you like. This is definitely a discussion for a different thread though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-474334322:246,test,test,246,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-474334322,2,['test'],"['test', 'tested']"
Testability,"I have log normalised the data and have filtered out the genes. . I have : ; 1. adata.var[adata.var[""n_cells""]==np.nan] - result is 0.; 2. np.isinf(adata.X.todense()).sum() - result is 0. Data I'm using is GSE158055. Link : https://drive.google.com/file/d/1TXDJqOvFkJxbcm2u2-_bM5RBdTOqv56w/view?usp=sharing",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2193#issuecomment-1079813917:7,log,log,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193#issuecomment-1079813917,1,['log'],['log']
Testability,"I have modified the following files in `scanpy` version `1.4`. 1. _anndata.py (added support for weighted sampling data , where each row has its non-zero weight, changes made for dotPlot, violinPlot and heatmap). 2. _rank_genes_groups ( To find marker genes for data where each row has different non-zero weight, I have modified 't-test' and 'wilcoxon'). Suggestion : . For weighted sampling data one can modify the PCA as well, I used matlab pca for weighted data. Thanks; Khalid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644:332,test,test,332,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644,1,['test'],['test']
Testability,I have not set the precision to float64 manually anywhere. It may however be the case that ComBat batch correction automatically uses float64. I will test and let you know.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/324#issuecomment-433383722:150,test,test,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/324#issuecomment-433383722,1,['test'],['test']
Testability,"I have removed issue from the pull request by the testing tool, now the tools showed me duplications, which are mostly from other code and 1-2 from my code. Please have a look into it. It's my first pull request and its taking too much time :(. Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-493836759:50,test,testing,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493836759,1,['test'],['testing']
Testability,"I have several plotting functions that allow to compare any two categorical columns in `.obs` to achieve similar output but never found the time to integrate them into scanpy. Is really quite some effort to add proper tests, documentation and code standards. I will be happy to share the code if other people is willing to help. . One problem with the stacked bar plot is that with lot of samples it is difficult to compare the fractions. To solve this I had used the dot plot with good results, see for example a comparison of the `louvain` clusters and the `bulk labels` annotation from `sc.datasets.pbmc68k_reduced()`:. ![image](https://user-images.githubusercontent.com/4964309/104466204-3e718280-55b5-11eb-9b87-ac3860af7979.png). and . ![image](https://user-images.githubusercontent.com/4964309/104466234-49c4ae00-55b5-11eb-92c8-45140de9e107.png). The dot plot also computes enrichment with respect to random expectations and sorts the rows and columns.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1573#issuecomment-759496093:218,test,tests,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1573#issuecomment-759496093,1,['test'],['tests']
Testability,"I have something that might be related:. ```python; ad = ad[ad.obs['cell type'] != 'nan'].copy(); assert np.all(ad.obs['cell type'] != 'nan'); sc.utils.sanitize_anndata(ad); assert np.all(ad.obs['cell type'] != 'nan'); ```. This fails in the second assert:. ```python; AssertionError Traceback (most recent call last); <ipython-input-103-2f44e51fdcae> in <module>; 8 assert np.all(ad.obs['cell type'] != 'nan'); 9 sc.utils.sanitize_anndata(ad); ---> 10 assert np.all(ad.obs['cell type'] != 'nan'); 11 ; 12 . AssertionError: ; ```. It's really black magic, any ideas?. PS: `nan`s are really string, not proper NaNs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/166#issuecomment-491099687:98,assert,assert,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166#issuecomment-491099687,7,"['Assert', 'assert']","['AssertionError', 'assert']"
Testability,I have tests which are being flaky locally which is making it quite difficult to debug other issues. This is me trying to fix some of those problems.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2106:7,test,tests,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2106,1,['test'],['tests']
Testability,"I have written a couple of functions to match clusters and marker genes. The simplest case is just a table of overlap score. Alternatively, I know someone who has used the Jaccard Index and enrichment tests. The other functions I wrote calculate average z-scores of marker genes in clusters (not sure if this is similar to `score_genes` or not. I could paste the functions in here if you like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/290#issuecomment-428240965:201,test,tests,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290#issuecomment-428240965,1,['test'],['tests']
Testability,"I have written a function to do this... I could add it to scanpy. But for the moment, this is it:. ```; def marker_gene_expression(anndata, marker_dict, gene_symbol_key=None, partition_key='louvain_r1'):; """"""A function go get mean z-score expressions of marker genes; # ; # Inputs:; # anndata - An AnnData object containing the data set and a partition; # marker_dict - A dictionary with cell-type markers. The markers should be stores as anndata.var_names or ; # an anndata.var field with the key given by the gene_symbol_key input; # gene_symbol_key - The key for the anndata.var field with gene IDs or names that correspond to the marker ; # genes; # partition_key - The key for the anndata.obs field where the cluster IDs are stored. The default is; # 'louvain_r1' """""". #Test inputs; if partition_key not in anndata.obs.columns.values:; print('KeyError: The partition key was not found in the passed AnnData object.'); print(' Have you done the clustering? If so, please tell pass the cluster IDs with the AnnData object!'); raise. if (gene_symbol_key != None) and (gene_symbol_key not in anndata.var.columns.values):; print('KeyError: The provided gene symbol key was not found in the passed AnnData object.'); print(' Check that your cell type markers are given in a format that your anndata object knows!'); raise; . if gene_symbol_key:; gene_ids = anndata.var[gene_symbol_key]; else:; gene_ids = anndata.var_names. clusters = anndata.obs[partition_key].cat.categories; n_clust = len(clusters); marker_exp = pd.DataFrame(columns=clusters); marker_exp['cell_type'] = pd.Series({}, dtype='str'); marker_names = []; ; z_scores = sc.pp.scale(anndata, copy=True). i = 0; for group in marker_dict:; # Find the corresponding columns and get their mean expression in the cluster; for gene in marker_dict[group]:; ens_idx = np.in1d(gene_ids, gene) #Note there may be multiple mappings; if np.sum(ens_idx) == 0:; continue; else:; z_scores.obs[ens_idx[0]] = z_scores.X[:,ens_idx].mean(1) #works for both s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/181#issuecomment-400238103:775,Test,Test,775,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/181#issuecomment-400238103,1,['Test'],['Test']
Testability,"I have yet to install the most latest `scanpy` and I do not have CPUs to test for this specific case, but I had some issue of reproducing `leiden` results from `scanpy` from a published paper, and found that running `leiden` 10 times (per `n_iteration` option) resolved any discrepancy. Wonder whether it adds to the discussion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014#issuecomment-946665831:73,test,test,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014#issuecomment-946665831,1,['test'],['test']
Testability,"I haven't benchmarked against scanpy, only against `scipy.stats.mannwhitneyu` (which at this point can handle arrays, I know it couldn't before). On my laptop (an 8-core Intel MacBook Pro) it's about a 10x speedup. But with more cores it can be a lot more. Even without parallelization, you can get some improvement by just using `numba.njit` on some of the internal bits (e.g. `tiecorrect`). Of course, your code has a lot of options that I didn't bother with, because I didn't need them. Some of them might be harder to JIT than others.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2060#issuecomment-981723859:10,benchmark,benchmarked,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2060#issuecomment-981723859,1,['benchmark'],['benchmarked']
Testability,"I haven't performed an in-depth benchmark comparison. But results from a single run of modularity detection on an example (a [Facebook graph](http://konect.uni-koblenz.de/networks/facebook-wosn-links)) is sufficiently revealing I think:; ```; Running Leiden 0.7.0.post1+71.g14ba1e4.dirty; Running igraph 0.8.0; Read graph (n=63731,m=817035), starting community detection.; leidenalg: t=8.048258741036989, m=0.6175825273363675; igraph community_leiden: t=1.159165252931416, m=0.6298702028415605; ```; This is only a relatively small graph, and the difference is likely to be even bigger for larger graphs. Perhaps the `igraph` Leiden algorithm can indeed be the default, with `leidenalg` being an optional choice or something?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-586969791:32,benchmark,benchmark,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053#issuecomment-586969791,1,['benchmark'],['benchmark']
Testability,"I haven't tried `read_direct ` yet but, in my opinion, it is not that helpful when we are reading the full array in memory without any type conversions. But i will check it of course. Now it seems like the problem in the recursion as reading simple files with pre-specified paths is faster and takes less memory.; Also, it can be that the problem is somewhere in the step of transforming dictionary to AnnData, but i don't see where for now. I'll check a few things, prepare readable benchmarks next week and we can have a call about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/303#issuecomment-441478499:484,benchmark,benchmarks,484,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/303#issuecomment-441478499,1,['benchmark'],['benchmarks']
Testability,I haven't used np.allclose for comparison but if I remember correctly (it was a while ago) the differences were around 4th or 5th decimal point. I will write a test using np.allclose against a reference and run it on different machines to see how it looks. I will post here the results.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1890#issuecomment-867445206:160,test,test,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890#issuecomment-867445206,1,['test'],['test']
Testability,"I hope that soon I can add some figures into the documentation and add further test. ; . > Am 23.07.2018 um 23:12 schrieb Alex Wolf <notifications@github.com>:; > ; > OK, merged this into master on the command line after fixing plotting/anndata.py, where some changes would have otherwise been reversed...; > ; > Thank you very much, Fidel! Really cool!; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207#issuecomment-407332243:79,test,test,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207#issuecomment-407332243,1,['test'],['test']
Testability,"I input pip show scipy I get:. Name: scipy; Version: 1.4.1; Summary: SciPy: Scientific Library for Python; Home-page: https://www.scipy.org; Author: None; Author-email: None; License: BSD; Location: /home/ubuntu/.local/lib/python3.6/site-packages; Requires: numpy; Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata; You are using pip version 18.0, however version 20.2b1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:; Name: scanpy; Version: 1.5.1; Summary: Single-Cell Analysis in Python.; Home-page: http://github.com/theislab/scanpy; Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrés R. Muñoz-Rojas; Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de; License: BSD; Location: /home/ubuntu/.local/lib/python3.6/site-packages; Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata; Required-by: ; You are using pip version 18.0, however version 20.2b1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user; when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252#issuecomment-635681942:1799,log,logging,1799,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252#issuecomment-635681942,1,['log'],['logging']
Testability,I just add the versions I used:; ```python; sc.logging.print_versions(). scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/536#issuecomment-474301705:47,log,logging,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536#issuecomment-474301705,1,['log'],['logging']
Testability,"I just found out that raw was already log transformed. Now I fixed it and nanmin seems a bit too conservative, any ideas?. ![image](https://user-images.githubusercontent.com/1140359/56463105-ea177f80-639b-11e9-80d3-f96463734634.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/614#issuecomment-485188655:38,log,log,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-485188655,1,['log'],['log']
Testability,"I just increased the noise in the testdata. With this, the assertion fails with the wrong number of noise barcodes.; The original test data was to ""clean"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2190#issuecomment-1082217533:34,test,testdata,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1082217533,3,"['assert', 'test']","['assertion', 'test', 'testdata']"
Testability,"I just noticed I forgot to answer to your point about multiple-testing-correction. Multiple testing correction deals with the effect that obtaining any false positives become more likely with repeated tests. However, it does not deal with bias. Bias is however present in the test given that the correct null hypothesis should assume some genes are different between groups, and not that all genes are equal. This comes back to the observation that some genes will be always be different between groups in random data, given that clustering defines the groups over which we test. And as for louvain using whole transcriptome similarities rather than individual gene similarities... these are related. If you defined groups by differences of whole transcriptomes, this necesitates individual genes having different means. The correct p-value would be the output of a permutation test. . Could discuss this offline if you like @gokceneraslan. I'm preparing a manuscript which makes a point of this... if I am wrong, please convince me of this soon ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-425737634:63,test,testing-correction,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-425737634,6,['test'],"['test', 'testing', 'testing-correction', 'tests']"
Testability,"I just stumbled upon a similar bug using SciKit Learn. It's not ScanPy, but this issue is the only result Google returned when I looked up my error. Here's my crash log:. ```; Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV); Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110; Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11; Termination Reason: Namespace SIGNAL, Code 0xb; Terminating Process: exc handler [0]. VM Regions Near 0x110:; --> ; __TEXT 000000010ddfb000-000000010ddfd000 [ 8K] r-x/rwx SM=COW /usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:; crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread; 0 libdispatch.dylib 	0x00007fff4fb578e1 _dispatch_root_queue_push + 108; 1 libBLAS.dylib 	0x00007fff24844c9a rowMajorTranspose + 546; 2 libBLAS.dylib 	0x00007fff24844a65 cblas_dgemv + 757; 3 multiarray.cpython-36m-darwin.so	0x00000001104e3f86 gemv + 182; 4 multiarray.cpython-36m-darwin.so	0x00000001104e3527 cblas_matrixproduct + 2807; 5 multiarray.cpython-36m-darwin.so	0x00000001104a9b27 PyArray_MatrixProduct2 + 215; 6 multiarray.cpython-36m-darwin.so	0x00000001104aeabf array_matrixproduct + 191; 7 org.python.python 	0x000000010de4712e _PyCFunction_FastCallDict + 463; 8 org.python.python 	0x000000010dead0e6 call_function + 491; 9 org.python.python 	0x000000010dea5621 _PyEval_EvalFrameDefault + 1659; 10 org.python.python 	0x000000010dead866 _PyEval_EvalCodeWithName + 1747; ```. It's not very useful as it's the same as the OP's, but it might help shifting the blame to a common dependency of SciKit Learn and ScanPy (like BLAS having an issue with macOS' Grand Central Dispatch).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/182#issuecomment-408848214:165,log,log,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182#issuecomment-408848214,1,['log'],['log']
Testability,"I just tested this out... The idea was that if `sc.pp.pca()` has the parameter `use_highly_variable` that be extension `sc.tl.umap()`, `sc.tl.tsne()`, and `sc.tl.draw_graph()` would also be based only on highly variable genes. That however doesn't seem to be the case. When I subset my anndata object to only highly variable genes I get a different result than when I just run it with `sc.pp.pca(adata, use_highly_variable=True)`. The `sc.pl.pca()` is the same, but `sc.pl.diffmap` seems somehow inverted, and umap, tsne, and draw_graph are all slightly different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/284#issuecomment-432836664:7,test,tested,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/284#issuecomment-432836664,1,['test'],['tested']
Testability,"I just tried; ```python; import scanpy.api as sc; sc.queries.mitochondrial_genes('www.ensembl.org', 'strange_organism'); ```; I would expect scanpy complains that it does not know `'strange_organism'`, but I get the error ; ```python; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-13-6a41b361ab41> in <module>(); 1 import scanpy.api as sc; ----> 2 sc.queries.mitochondrial_genes('www.ensembl.org', 'drerio'). ~/software/scanpy/scanpy/queries/__init__.py in mitochondrial_genes(host, org); 34 s.add_attribute_to_xml('mgi_symbol'); 35 else:; ---> 36 logg.msg('organism ', str(org), ' is unavailable', v=4, no_indent=True); 37 return None; 38 s.add_attribute_to_xml('chromosome_name'). NameError: name 'logg' is not defined; ```; It seems to me like `queries/__init__.py` misses an `from .. import logging as logg` statement. Would maybe also make sense to show the the message that an organism is not available at verbosity level 1 instead of 4?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/258:639,log,logg,639,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/258,4,['log'],"['logg', 'logging']"
Testability,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```; gene1 = 'XXX'; gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &; (adata.raw[:,'{}'.format(gene2)].X.todense() > 0); ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/490#issuecomment-587473372:244,log,log,244,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-587473372,1,['log'],['log']
Testability,"I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066:551,benchmark,benchmarks,551,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066,2,['benchmark'],['benchmarks']
Testability,"I like the `calculateQCMetrics` function from [`scater`](https://bioconductor.org/packages/release/bioc/html/scater.html), and have had a half finished python version drifting between my notebooks for a while. Is there is interest in adding this to scanpy?. I'm aiming to mostly copy the interface of `calculateQCMetrics` while being memory efficient, since this is likely run before filtering. # Todo. - [x] Figure out how I want to deal with more types of sparse matrix; - [x] Add `feature_control` argument, possibly `variable_control`; - [x] Clean up and expand tests; - [x] Expand documentation. # Questions. * What's up with sparse matrix choice in scanpy? Is `adata.X` expected to be any of the matrix types, or is it more limited? Just trying to figure out how much effort I should put into that.; * Are there any additional metrics that could be useful?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316:566,test,tests,566,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316,1,['test'],['tests']
Testability,"I like the thought... for exactly the reason you brought up, I recommended storing log-normalized data in `adata.raw` in my best practices workflow. That way DE analysis and plotting is done on that data type rather than raw counts. I have been working with `adata.layers['counts']` for count data and don't keep filtered out cells/genes (easy to recreate anyway).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-819683830:83,log,log-normalized,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-819683830,1,['log'],['log-normalized']
Testability,"I like this idea, but think it could be expanded on a bit. I think there are benefits to approaching this through logging. Some advantages of doing this through logging:. * Global record. If a copy is made or an AnnData split, you could figure out which object came from where.; * Control over level of detail. What kind of information is recorded can be customized. Maybe the user wants provenance, but maybe they want performance information. What if tracking was done through logging? Here's a couple quick examples of what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 cal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:114,log,logging,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273,6,"['Log', 'log']","['Logs', 'logged', 'logger', 'logging']"
Testability,I like your suggestions. Especially the `filter_rank_genes_groups` use makes a lot of sense to me. The one thing I would suggest to take into account is that some of these filtering steps can be done before significance testing and therefore you would not have to perform multiple testing correction on the filtered out genes. This may be quite useful to some. That precludes filtering on p-value though. It also makes a case for filtering already in `rank_genes_groups` rather than in `sc.get`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1529#issuecomment-738766770:220,test,testing,220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529#issuecomment-738766770,2,['test'],['testing']
Testability,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`?. Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148:36,test,test,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148,8,['test'],"['test', 'testing', 'tests']"
Testability,I looked at a few genes and it looks like I'm getting pretty similar residuals compared to the R implementation. Something weird is going on with the genes in the last couple images so I'm currently trying to figure that before generating more thorough benchmarks. (I clip negative values to zero to preserve sparsity structure). ![image](https://user-images.githubusercontent.com/16548075/107794002-c4dfc800-6d0b-11eb-8c69-eca5963a2cc4.png); ![image](https://user-images.githubusercontent.com/16548075/107794217-02445580-6d0c-11eb-9c12-a1fce473a69a.png); ![image](https://user-images.githubusercontent.com/16548075/107794044-d1642080-6d0b-11eb-9659-bd72e7a9aa99.png); ![image](https://user-images.githubusercontent.com/16548075/107794308-23a54180-6d0c-11eb-8b2e-59bb479b09af.png),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-778299582:253,benchmark,benchmarks,253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643#issuecomment-778299582,1,['benchmark'],['benchmarks']
Testability,"I looked at it a while ago (for one test dataset, probably), and got the impression that `louvain` was faster. That said, they're both very fast. I would note that solutions from either can be pretty unstable, frequently depending on size of the community. @LuckyMD When you say heavy tailed, are you thinking of the unweighted KNN graph case or both?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-483207692:36,test,test,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-483207692,1,['test'],['test']
Testability,"I looked into that, but I'm not sure it actually makes this any less complicated. The issue is getting the `tqdm` thing to update, and requests would need all of the same logic to do that as far as I can tell. Plus, at that point it's copying from stack overflow vs. copying from python's stdlib. You'd think this would be a convenience function somewhere. Or you'd think that `urlretrieve` could take a `Request` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1344#issuecomment-666336406:171,log,logic,171,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344#issuecomment-666336406,1,['log'],['logic']
Testability,I merged it and moved it into `rtools`. There is a reexport so that you should be able to call it using `sc.rtools.mnn_concatenate` where `sc` is `scanpy.api`. Could you test whether this works?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-384126068:170,test,test,170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-384126068,1,['test'],['test']
Testability,I modified the code to reintroduce `chunked` but I confess I haven't tested it because I've never been able to get it to work. I think there might be other issues with that functionality...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-403244826:69,test,tested,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-403244826,1,['test'],['tested']
Testability,"I must also mention that upon reading in the data:; - running `adata.uns['log1p']` returns `{}`;; - setting `adata.uns['log1p'][""base""] = None` after reading doesn't help.; - running `del adata.uns['log1p']` solves the problem. Visual inspection of expression values in `adata.X` seem to not be log-transformed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1333#issuecomment-1210570611:295,log,log-transformed,295,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333#issuecomment-1210570611,1,['log'],['log-transformed']
Testability,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback.; ```; TypeErrorTraceback (most recent call last); <ipython-input-963-f4f784156b06> in <module>; ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 285 If `show==False` a `matplotlib.Axis` or a list of it.; 286 """"""; --> 287 return plot_scatter(adata, 'umap', **kwargs); 288 ; 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 202 _data_points[:, 0], _data_points[:, 1],; 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,; --> 204 **kwargs,; 205 ); 206 . ~/.virtualenvs/intel_default/lib/python3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/555#issuecomment-483342652:573,test,test,573,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555#issuecomment-483342652,4,['test'],['test']
Testability,"I noticed that `pl.diffmap` interacts differently with the `show` and `save` options than most of the other plotting functions. Namely, if both `show` and `settings.autoshow` are true, `pl.diffmap` saves but does not show. Most of the other functions will both save and show. I looked in the code a bit and it looks like this is because other plotting functions use `utils.savefig_or_show` versus `pl.diffmap` has some custom plotting logic (I assume because `pl.diffmap` allows multiple plots to be generated by passing a list to `components`). Changing:; ```python; if not settings.autosave and show: pl.show(); ```; to just:; ```python; if show: pl.show(); ```; should make `pl.diffmap` more consistent with the other plotting functions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/227:435,log,logic,435,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/227,1,['log'],['logic']
Testability,I noticed that matplotlib v. 3 is being installed in travis. This may be the reason why some tests not related to the changes are now failing. I am updating my matplotlib version to update de tests.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-425947033:93,test,tests,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-425947033,2,['test'],['tests']
Testability,"I noticed, however, that the tests pass even when removing the `if stripplot:` part. Any idea on why this is happening and how to prevent it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-694832160:29,test,tests,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-694832160,1,['test'],['tests']
Testability,I pushed to your branch. It failed yesterday while Github was having issues. The test should pass.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1541518384:81,test,test,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1541518384,1,['test'],['test']
Testability,"I reckon that's a fair consideration. In the end we don't use `sc.tl.rank_genes_groups()` for complex DE tests that require this amount of detail, but instead for marker gene calculations where it's mainly about ranking genes. It would be interesting to see the error of the approximation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-471500111:105,test,tests,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471500111,1,['test'],['tests']
Testability,"I removed all this automatic setting of backends etc. . Currently ""is_interactive"" is only used to choose different progress bars (tqdm behaves very differently on the command line, in jupyter and then, unfortunately again differently in Rodeo) and to decide on whether a `total wall time` should be output when leaving the session. It's now left to the user to choose the matplotlib backend. If she/he logs in via ssh without setting an -X tunnel, the default interactive backend will simply fail. But that's left to the user now, no longer output of, which seemed to annoy you (I can understand that); ```; ... WARNING: did not find DISPLAY variable needed for interactive plotting; --> try ssh with `-X` or `-Y`; setting `sett.savefigs = True`; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/16#issuecomment-298663054:403,log,logs,403,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/16#issuecomment-298663054,1,['log'],['logs']
Testability,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-470239225:30,log,logs,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470239225,5,"['log', 'test']","['log-fold', 'log-normalized', 'log-scale', 'logs', 'test']"
Testability,"I see no reason why the possibility shouldn't exist to run the weighted version on the full graph. I'm still curious about the quality of the outcome though. Using protein-protein interaction data, I've noticed that similarity scores perform worse than using network neighbourhoods based on cutoffs to cluster data (this does not have to be the case for scRNA-seq of course). In the latter case you require cells to be each others nearest neighbours to create dense network regions, rather than highly similar transcriptomes based on one calculation of similarity. I would have thought the cutoff approach is more robust to changing similarity metrics as well. It's definitely worth testing this though. Maybe I'm just too skeptical of similarity metrics over all. @fidelram do you have labels on your data where you could verify the quality of those two partitions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-416161676:683,test,testing,683,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/240#issuecomment-416161676,1,['test'],['testing']
Testability,"I see your point, no problem. krumsiek11 dataset does not actually cause inconsistencies float32/float64 (without/with the fix). I suspect this is because it has fewer decimal digits and fewer genes so does not accumulate enough imprecision.; Paul15 data behaves as reported before, so I used that one instead. Hope this is fine!. As previously the test passes with the fix but not without it on the two machines I tested.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1890#issuecomment-873623806:349,test,test,349,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890#issuecomment-873623806,2,['test'],"['test', 'tested']"
Testability,"I see, [densmap](https://umap-learn.readthedocs.io/en/latest/densmap_demo.html). Hmm, I think that `method='densmap'` and `method_kwds={...}` would be a better API for us (which would then be translated into `densmap=True, densmap_kwds=method_kwds`). This also needs tests and a release note. Also we probably should just remove the umap 0.4 compatibility code, what do you think @ivirshup?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2684#issuecomment-1764564449:267,test,tests,267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684#issuecomment-1764564449,1,['test'],['tests']
Testability,"I simplified the `_prepare_dataframe code` by using `sc.get.df`. However, this change uncovered two issues with `sc.get.obs_df` that I have now addressed in this PR. . The most relevant is the case when the call to `sc.get.obs_df` contains keys with duplicates (e.g. `keys=['gene1', 'gene1']`). This case is not rare as for example in `sc.pl.dotplot` the same gene can be visualized several times, which requires calling `sc.get.obs_df` with keys that contain duplications. An example is when `sc.pl.rank_genes_groups_dotplot` is called and, frequently, the same gene appears as top up-regulated for more than one category. To address this, `sc.get.obs_df` removes all duplicates (which correspond to DataFrame columns) and after the DataFrame is complete, the duplicates are added back. A second problem was for non-unique adata.obs indices which should be a rare situation. However, it turns out that one of the test adata object used in `test_plotting` have this issue. Also, for the goal of this PR (allow adata.obs.index as groupby option) it could be expected that the index may not be unique. . In general, non unique obs indices are ok as long as `.obs` DataFrame is not joined or merge based on index. However, because internally in `sc.get.obs_df` the DataFrames are merged using `adata.obs.index` this non-unique indices caused an increase in rows due to multiple matching. To fix this, the code now checks for unique index, and if it is not unique then a temporary index is added to allow proper join operations and then the non-unique index is put back.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583:914,test,test,914,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583,1,['test'],['test']
Testability,"I simplified this quite a bit. I decided against blocking this on an upstream `anndata` helper for multiple reasons:. 1. we test on older anndata versions that won’t have that parameter immediately; 2. needs some designing, e.g. the API should be able to do “use `ceil(shape[0] / 2)` as chunk size for dim 0, and `-1` (=full size) for dim 1”; 3. it would make no sense for the non-dask array types, should we still add it for them?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3162#issuecomment-2250061054:124,test,test,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162#issuecomment-2250061054,1,['test'],['test']
Testability,"I started to test also with 3.8, but sadly there’s a bug in scipy: scipy/scipy#10354",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/704#issuecomment-505415647:13,test,test,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704#issuecomment-505415647,1,['test'],['test']
Testability,"I submitted both the exact changes suggested by @flying-sheep and . normalize = matplotlib.colors.Normalize(vmin=kwds.get('vmin'), vmax=kwds.get('vmax')); colors = [cmap(normalize(value)) for value in mean_flat]. as a second submission, trying to pass the tests. But it looks like the tests are failing for some other reason outside of the anndata.py file (only file modified in my commit). . I don't think the tests are failing from the changes made here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/390#issuecomment-446061532:256,test,tests,256,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390#issuecomment-446061532,3,['test'],['tests']
Testability,"I support the idea of tidying up plotting arguments. I think there are mainly two problems. 1) the high number of plotting arguments 2) lack of reusability of plotting ""styles"". . Chaining looks really cool and improves 1). Also, it logically partitions the plotting arguments. However, it doesn't solve 2). In other words, if we plot two figures, we'll need to copy the entire thing, and it'll be very verbose:. ```python; sc.pl.umap(adata, color='clusters').scatter_outline(width=0.1); .legend(loc='on data', outline=1); .add_edges(color='black', width=0.1). sc.pl.umap(adata2, color='fluffy').scatter_outline(width=0.1); .legend(loc='on data', outline=1); .add_edges(color='black', width=0.1); ```. One thing that comes to mind for reusability is to store the result of the chain somewhere and, well, reuse it:. ```python; style = sc.pl.styles.scatter_outline(width=0.1); .legend(loc='on data', outline=1); .add_edges(color='black', width=0.1). # using simple arguments, similar to https://stat.ethz.ch/R-manual/R-devel/library/nlme/html/lmeControl.html; sc.pl.umap(adata, color='clusters', style=style); sc.pl.umap(adata2, color='fluffy', style=style). # using context managers, similar to https://seaborn.pydata.org/tutorial/aesthetics.html#temporarily-setting-figure-style; with style:; sc.pl.umap(adata, color='clusters'); sc.pl.umap(adata2, color='fluffy'). # overriding an existing style object; with style.legend(fontsize=12):; sc.pl.umap(adata, color='clusters'); sc.pl.umap(adata2, color='fluffy'). # or use predefined styles (?); with sc.pl.style('malte'):; sc.pl.umap(adata, color='clusters'); sc.pl.umap(adata2, color='fluffy'). ```. WDYT?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/956#issuecomment-567321810:233,log,logically,233,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/956#issuecomment-567321810,1,['log'],['logically']
Testability,"I tentatively added a benchmark that runs just on `_get_mean_var`. Locally I don’t see any difference though, what’s wrong? Too small data? Numba not set up with correct number of threads?. /edit: also I think the machine is not sufficiently tuned. The original run (before I added the `mean_var` benchmarks) said “No changes in benchmarks.”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3015#issuecomment-2066327499:22,benchmark,benchmark,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3015#issuecomment-2066327499,3,['benchmark'],"['benchmark', 'benchmarks']"
Testability,"I tested myself and obtained exactly the same results. :). You probably don't have the FA2 package installed, that's why your graph look different... :). I'm merging this! Awesome work!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-487797746:2,test,tested,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487797746,1,['test'],['tested']
Testability,"I tested the code, now it is possible to calculate more components for the tSNE embedding method",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/461#issuecomment-460703629:2,test,tested,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/461#issuecomment-460703629,1,['test'],['tested']
Testability,"I tested this in a couple of machine and the pipeline works fine there. However, I just re-installed `leidenalg` and this is now resolved! . Thanks a lot for the feedback.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1410#issuecomment-689637466:2,test,tested,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1410#issuecomment-689637466,1,['test'],['tested']
Testability,I tested this. 🙂,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/927#issuecomment-556003335:2,test,tested,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/927#issuecomment-556003335,1,['test'],['tested']
Testability,"I think I'll leave codecov to a separate PR, since this immediately improves test reporting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1564#issuecomment-754438743:77,test,test,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1564#issuecomment-754438743,1,['test'],['test']
Testability,"I think `adata.obsm` could make sense, but `adata.uns` would maybe be a bit too messy given the unstructured nature and the assumptions and tests that would have to be added.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1189#issuecomment-621466673:140,test,tests,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189#issuecomment-621466673,1,['test'],['tests']
Testability,I think it is more or less complete.; Here are the tutorials; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/Ingest-realistic.ipynb; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/Ingest-simple.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-519155566:104,benchmark,benchmarks,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519155566,2,['benchmark'],['benchmarks']
Testability,I think it just needs a test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2280#issuecomment-1592923701:24,test,test,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2280#issuecomment-1592923701,1,['test'],['test']
Testability,I think it makes sense. I will open a new PR cause I'll have to change the test as well.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1149#issuecomment-628521440:75,test,test,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1149#issuecomment-628521440,1,['test'],['test']
Testability,"I think it's normally just the string `""euclidean""`, but you can just test what is stored in `.uns['neighbors']['params']['metric']` after running `sc.pp.neighbors()` on some test data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1201#issuecomment-658658158:70,test,test,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201#issuecomment-658658158,2,['test'],['test']
Testability,"I think maybe i found a solution to solve this problem.; Maybe this problem is caused by the version of scikit—misc，when you use pip install --user scikit-misc or pip install scikit-misc，the system will install scikit-misc==0.1.4.; so,i try to install another verion of scikit-misc,you can use install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1.; In addition, this line of command needs to be used when python is greater than or equal to 3.8.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497:313,test,test,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497,1,['test'],['test']
Testability,"I think separating static analysis from running the tests is the way to go (in #841 I added black checking as a separate step.). Also mypy is very strict, so we might have to fix *a lot*.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/839#issuecomment-531489355:52,test,tests,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839#issuecomment-531489355,1,['test'],['tests']
Testability,"I think the current approach - a very simple interface as in `scanpy/tools/phate.py` and a bunch of others is the easiest way to go for the developer. So, I'd say we make a submodule `.ext` with the `.tools`, `.plotting`, `.preprocessing` substructure in it. We move things like `phate.py` into `scanpy/ext/tools`. We maintain backwards compat by still reexporting it in `scanpy.api`. The canonical way of calling these extension will be by importing `import scanpy.ext as sce` and people can use that extension namespace and call everything in the same way that they are used to. Users can look up extension tools on docs site like [this](https://scanpy.readthedocs.io/en/latest/api/index.html). It will also be clear to users that these extensions will require installing additional packages, which don't come with the default scanpy. Of course, all of this needs none of the ""extension mechanisms"" mentioned above. But people really don't want to write actual ""scanpy extensions""; they want to write their own packages and have them interface with scanpy so that convenient calls are enabled without the need to adapt to new conventions. For the scanpy users, the cool things is that a large number of tools can be quickly tested out. If you don't mind, @fidelram and @flying-sheep, @Koncopd would go along and make this modest change.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/271#issuecomment-431634492:1226,test,tested,1226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/271#issuecomment-431634492,1,['test'],['tested']
Testability,"I think the plotting parameter would make a lot of sense. We should take a few things into account though when determining defaults here.; 1. Not all methods have log fold changes (`'logreg'` for example); 2. Ordering based on log FC will be different than based on the scoring (lowly expressed genes will typically have higher logFC). I'm not sure how meaningful the plot would then be...; 3. We initially didn't have any fold changes or p-values at all, partially because the marker gene DE test setup is ill-defined. You test gene in two groups where the groups are defined based on the genes you test... that will generate inflated p-values. Hence it might be a good idea to only consider the test as a way to order genes rather than a robust statistical test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1152#issuecomment-610607335:163,log,log,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152#issuecomment-610607335,9,"['log', 'test']","['log', 'logFC', 'logreg', 'test']"
Testability,"I think the problem is the option `sort_order` which is True by default for; numerical data. This changes the ordering of the dots and thus it messes; up with your own sizes. Setting `sort_order=False` should fix the problem. On Tue, Feb 12, 2019 at 6:07 AM Andreas <notifications@github.com> wrote:. > I'm trying to use an array for the size argument to my umap/scatterplot; > with the following code; >; > import scanpy.api as sc; > import numpy as np; > sc.settings.figdir = ""testdir""; > sc.settings.file_format_figs = ""png""; > sc.logging.print_versions(); >; > With these libraries; > scanpy==1.3.7 anndata==0.6.16 numpy==1.16.1 scipy==1.2.0 pandas==0.23.4; > scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; >; > Running the following code bit. I use some dummy variable for size.; >; > somedata = sc.datasets.paul15(); > sc.pp.pca(somedata); > sc.pp.neighbors(somedata, n_neighbors=4, n_pcs=20); > sc.tl.umap(somedata, spread=1, min_dist=0.1, random_state=42); > sc.tl.leiden(somedata, resolution=0.5, random_state=42); > z = np.abs(somedata.obsm['X_pca'][:,0])**1; > sc.pl.umap(somedata, color=['1110007C09Rik'], size=z, cmap='viridis', save='continuous_expr.png'); > sc.pl.umap(somedata, color=['leiden'], size=z, cmap='viridis', save='group_value.png'); >; > I get the following two figure as output; > [image: umapcontinuous_expr]; > <https://user-images.githubusercontent.com/715716/52612879-951a3300-2e59-11e9-9dad-a8afc60a4b54.png>; > [image: umapgroup_value]; > <https://user-images.githubusercontent.com/715716/52612880-95b2c980-2e59-11e9-9a44-81dd84e3274d.png>; >; > I would expect to see a similar size allocation/distribution but they are; > very different. I Could not really find a cause for this looking at the; > scatter plot function so it might be somewhere deeper.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/478>, or ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/478#issuecomment-462722152:479,test,testdir,479,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/478#issuecomment-462722152,2,"['log', 'test']","['logging', 'testdir']"
Testability,"I think this could use a consolidated effort for consistent behavior. Especially since testing whether it works will probably have some common patterns. In some cases `Raw` will need to be an option. I like the convention of having the arguments `use_raw`, `layers`, and (when appropriate) `obsm_key`/ `varm_key`. With these at most one of the values can be not None, and if all are None (the default) `X` is used. An alternative convention is `use_rep: Optional[str]`. I’m less a fan of this due to potential key collisions. Some relevant issues/ prs: #826 #801 #730",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/828:87,test,testing,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828,1,['test'],['testing']
Testability,"I think this is an important conversation to have not just for imputation, but also for other analysis methods like visualization and batch effect correction. Every algorithm makes some assumptions and biases, and it is possible to misinterpret for misuse almost any machine learning algorithm. . For example, t-SNE, often used for visualization, is also used as dimensionality reduction for clustering. However, most clustering algorithms assume that global distances in a dataset are relevant. This assumption is broken with t-SNE, as evidenced by the inconsistency of t-SNE embeddings on the same data and inability for t-SNE to capture some global trends in a dataset (especially with continuous data, leading to the popularity of graph-based visualizations). . On top of this, each clustering algorithm makes assumptions that data is in fact distributed in clusters, but this is often not the case in single cell data. I agree that it's important to warn users about the limitations of imputation methods, and make them aware that their decision on which algorithm to run can affect their output. However, it seems to me that this conversation could be much broader in scope. We don't currently have a system for unified benchmarking and standardization of single cell analysis methods, so all approaches should be used with some caution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-413591251:1226,benchmark,benchmarking,1226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189#issuecomment-413591251,1,['benchmark'],['benchmarking']
Testability,"I think this is orthogonal to that. The idea with having a separate argument for how we merge the results from different batches would mean factoring out the merge logic from each flavor and having it be a stand alone operation. It would also change the API here, since we wouldn't be adding a new `flavor`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892297913:164,log,logic,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892297913,1,['log'],['logic']
Testability,"I think this looks pretty good. One thing we had discussed was moving out the merge logic for multiple batches from being specified by `flavor` to being specified by a different argument, maybe `merge_flavor` or `batch_flavor`. Have you thought about/ looked into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892277383:84,log,logic,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892277383,1,['log'],['logic']
Testability,"I think this should fix it – it fixes it on my machine and the tests pass. There's no reason to access raw if `use_raw` isn't passed, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/578:63,test,tests,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/578,1,['test'],['tests']
Testability,"I think this would be more appropriate in `anndata`. Since it's not an on disk format, maybe it the function could be called something like `from_starfish`?. * This would also need tests, so some kind of example data.; * Why the differences between this and [starfish's `save_anndata` method](https://spacetx-starfish.readthedocs.io/en/latest/_modules/starfish/core/expression_matrix/expression_matrix.html#ExpressionMatrix.save_anndata)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1362#issuecomment-671720357:181,test,tests,181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362#issuecomment-671720357,1,['test'],['tests']
Testability,"I think umap works on the connectivities matrix generated from `sc.pp.neighbors`. I guess you can test this by omitting `sc.pp.neighbors` before running umap. Or just running umap after your step 2 and look at the difference. >Yes, my batches have very similar (if not the same) cell type composition. In that case it would make sense for both bbknn and combat to work quite well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666#issuecomment-496866953:98,test,test,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496866953,1,['test'],['test']
Testability,"I think we can merge this for now. I will add other tests I think next week. There is something I don't understand: For the docs, I see that an image is presented together with the API documentation. E.g. [api.pl.dotplot](https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pl.dotplot.html) But I don't see how is this image is referred in the function description. How does this work?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207#issuecomment-405917660:52,test,tests,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207#issuecomment-405917660,1,['test'],['tests']
Testability,"I think we can work without this particular fix, we probably only need to update the test data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-799447066:85,test,test,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-799447066,1,['test'],['test']
Testability,"I think we should introduce a standardized “mask” argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A’],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells’,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2234:1497,test,tests,1497,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234,1,['test'],['tests']
Testability,"I think with a recent numpy or Pandas update, an if clause in sc.tl.dendrogram no longer works properly. . ```python; import numpy as np; import pandas as pd; import scanpy as sc. # Use pbmc3k dataset; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts=1); sc.pp.log1p(adata); sc.pp.normalize_total(adata); sc.pp.highly_variable_genes(adata); sc.tl.pca(adata); sc.pp.neighbors(adata); sc.tl.leiden(adata); sc.tl.rank_genes_groups(adata, groupby='leiden'). # Save the ranks.; results_dict = dict(); for cluster_i in adata.uns['rank_genes_groups']['names'].dtype.names:; # print(cluster_i); # Get keys that we want from the dataframe.; data_keys = list(; set(['names', 'scores', 'logfoldchanges', 'pvals', 'pvals_adj']) &; set(adata.uns['rank_genes_groups'].keys()); ); # Build a table using these keys.; key_i = data_keys.pop(); results_dict[cluster_i] = pd.DataFrame(; row[cluster_i] for row in adata.uns['rank_genes_groups'][key_i]; ); results_dict[cluster_i].columns = [key_i]; for key_i in data_keys:; results_dict[cluster_i][key_i] = [; row[cluster_i] for row in adata.uns['rank_genes_groups'][key_i]; ]; results_dict[cluster_i]['cluster'] = cluster_i; marker_df = pd.concat(results_dict, ignore_index=True). marker_df = marker_df.sort_values(by=['scores'], ascending=False); # Make dataframe of the top 3 markers per cluster; marker_df_plt = marker_df.groupby('cluster').head(3); ; # here sc.tl.dendrogram will fail; _ = sc.pl.dotplot(; adata,; var_names=marker_df_plt['names'],; groupby='leiden',; dendrogram=True,; use_raw=False,; show=False,; color_map='Blues'; save='{}.png'.format('test'); ); ```. ```pytb; /lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace); 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering; 131 ); --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True); 133; 134 # order o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1300:694,log,logfoldchanges,694,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1300,1,['log'],['logfoldchanges']
Testability,"I think you are using a view of the anndata object, rather than the object with that method of subsetting. That shouldn't be related to the issue, but if you want to work with the subset, I would use `.copy()` at the end. Also, does this give you the number of cells and genes as intended? I typically put a `:` for the genes to get something like `adata[cell_filter,:].copy()`. Not sure if that's necessary though. So I think the issue is the `foldchanges[global_indices]` that has values that you can't input into `np.log2`. That can be `NaN` or negative values. A fold change is something like `(average expression in condition 1)/(average expression in condition 2)` if expression values can be negative, then one of those values can be negative, giving a negative fold change. I would guess that these testing frameworks don't play well with negative values. . It is likely that this only pops up now, as the average expression value for the e.g., ""not cluster 3"" data is now negative, where before it wasn't as there was different data to average over. If this is the issue, I'm not entirely sure what to do about this... fold changes aren't defined for such a case. I would either:; 1. rescale the data to be between two non-negative values.; 2. Set all negative values to 0. You could take the code in the `sc.tl.rank_genes_groups()` function and calculate the fold changes for your genes step by step to see if this is the problem. I assume that it is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494347969:807,test,testing,807,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494347969,1,['test'],['testing']
Testability,"I think you might be using an out of date version of scanpy. Try updating that. If that fails, please show your version info by running `sc.logging.print_versions()` and pasting the result here. Probable duplicate of: #781",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1139#issuecomment-608251007:140,log,logging,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1139#issuecomment-608251007,1,['log'],['logging']
Testability,"I think you're all good. Taking another look at the function I believe I had actually tried to completely replace the whole thing (since the logic is fairly convoluted), which ended up breaking functions that relied on the convoluted parts. I think ultimately the whole function should be replaced, ideally using `sc.get._get_obs_rep`. At that point we can rename the argument and make it more widely available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2179#issuecomment-1081877491:141,log,logic,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1081877491,1,['log'],['logic']
Testability,"I took about 20 minutes on it, but couldn't figure out how to add more annotations. I've got interactive versions with hover over, but log scale is bugged in those libraries... I believe the bins that are the darkest shade in the minimum cluster size for the unweighted graph actually correspond to a minimum cluster size of 1 cell. Megakaryocytes were detected as a distinct cluster every time that k was 10 in the unweighted case, but no other times. I think that when we make a call on ""this is a kind of cell"" from unsupervised clustering, those results should be robust. That is, if there's strong signal in the data and your clustering algorithm can pick up that signal, good clusters shouldn't change much if you vary the parameters a little. If you can pick any parameters from a wide range and get results that are pretty consistent, that seems like good data and a good method to me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-488191694:135,log,log,135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-488191694,1,['log'],['log']
Testability,"I tried to improve the ticklabel location which now looks like this. Also, I added a parameter to turn on the labels. ```PYTHON; sc.pl.stacked_violin(adata,marker_genes,groupby='louvain',log=False, yticklabels=True, row_palette='muted'); ```; ![image](https://user-images.githubusercontent.com/4964309/89010208-6a05f680-d30e-11ea-995b-bd5b1a673c51.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1342#issuecomment-666974308:187,log,log,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342#issuecomment-666974308,1,['log'],['log']
Testability,"I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2483:371,test,tested,371,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483,1,['test'],['tested']
Testability,"I try to use `sc.pl.pca` selecting components. According to the documentation the following should work:. ```python; import scanpy.api as sc; sc.logging.print_versions(); adata = sc.datasets.blobs(); sc.tl.pca(adata); sc.pl.pca(adata, components=['1,2', '2,3']); ```. However, I get an error. The output of the code above is:. ```python; scanpy==0+unknown anndata==0.6.9 numpy==1.14.5 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ... storing 'blobs' as categorical. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-16-4cd21e9edf25> in <module>(); 3 adata = sc.datasets.blobs(); 4 sc.tl.pca(adata); ----> 5 sc.pl.pca(adata, components=['1,2', '2,3']). ~/software/scanpy/scanpy/plotting/tools/__init__.py in pca(adata, color, use_raw, sort_order, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save, ax); 114 title=title,; 115 show=False,; --> 116 save=False, ax=ax); 117 utils.savefig_or_show('pca_scatter', show=show, save=save); 118 if show == False: return axs. ~/software/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 110 show=show,; 111 save=save,; --> 112 ax=ax); 113 elif x is not None and y is not None:; 114 if ((x in adata.obs.keys() or x in adata.var.index). ~/software/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 291 if components is None: components = '1,2' if '2d' in projection els",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/254:145,log,logging,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/254,1,['log'],['logging']
Testability,"I updated anndata to 0.8.0 and was not able to load my scanpy 1.8.2 properly. Any ideas?. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /tmp/ipykernel_31935/912249142.py in <module>; ----> 1 import scanpy as sc. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2264:1053,log,logging,1053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2264,2,['log'],"['logg', 'logging']"
Testability,"I updated release notes and added a test for this specific case. I did not write many tests before, so I looked at the other tests and tried to stick to what I saw there. I noted something unexpected when writing the test: When used `np.mean` and `np.var(.., ddof=1)` to compare against the test failed because some of the variances were off. The current version of the test uses `sc.pp._utils._get_mean_var()` (thats what `highly_variable_genes()` uses internally...), and does not fail.. Is it ok to use that instead? Is it expected that numpy and `_get_mean_var()` are slightly different here?. Test code with numpy ground truth:; ```; def test_seurat_v3_mean_var_output_with_batchkey_vs_numpy():; pbmc = sc.datasets.pbmc3k(); pbmc.var_names_make_unique(); n_cells = pbmc.shape[0]; batch = np.zeros((n_cells), dtype=int); batch[1500:] = 1; pbmc.obs[""batch""] = batch. true_mean = np.mean(pbmc.X.toarray(), axis=0); true_var = np.var(pbmc.X.toarray(), axis=0, ddof=1). result_df = sc.pp.highly_variable_genes(; pbmc, batch_key='batch', flavor='seurat_v3', n_top_genes=4000, inplace=False; ); np.testing.assert_allclose(true_mean, result_df['means'], rtol=2e-05, atol=2e-05); np.testing.assert_allclose(true_var, result_df['variances'], rtol=2e-05, atol=2e-05); ```; Test output:; ```; E AssertionError: ; E Not equal to tolerance rtol=2e-05, atol=2e-05; E ; E Mismatched elements: 172 / 32738 (0.525%); E Max absolute difference: 0.01117667; E Max relative difference: 0.00013328; E x: array([0., 0., 0., ..., 0., 0., 0.], dtype=float32); E y: array([0., 0., 0., ..., 0., 0., 0.]). tests/test_highly_variable_genes.py:279: AssertionError; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1732#issuecomment-797052072:36,test,test,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732#issuecomment-797052072,13,"['Assert', 'Test', 'test']","['AssertionError', 'Test', 'test', 'testing', 'tests']"
Testability,"I updated the rank_genes_groups function to output p-values for t-tests and the wilcoxon rank-sum test, as discussed with @falexwolf in #159. ; The changes are outlined below:; - The t-test in the original file used a Welch t-test. I kept this, calculated the relevant degrees of freedom for a Welch test and then extracted the corresponding two-tailed p-value for the t-statistic (score). ; - The Wilcoxon test was originally done in chunks. To get the p-values I had to simplify this approach and use the ranksums function in scipy.stats. This caused me to loop through all of the genes being tested, which was fine for my dataset, but might need to be optimized for larger datasets.; - The adjusted p-values (pvals_adj) were calculated with a standard Bonferroni correction.; - All p-values are outputted and sorted the same way as 'names' or 'scores'. The only difference is that the p-values recarrays use float64 as a datatype to avoid converting a lot of the very small p-values to 0. Hope this is helpful!. Andrés",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270:66,test,tests,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270,7,['test'],"['test', 'tested', 'tests']"
Testability,I used the 68k pbmc dataset from 10x genomics for the large dataset. Jupyter notebook with residuals:; [benchmarks_PR1066_residuals.ipynb.zip](https://github.com/theislab/scanpy/files/4234730/benchmarks_PR1066_residuals.ipynb.zip). The memory and timing benchmarks:; ![large](https://user-images.githubusercontent.com/16548075/75012333-97cd4200-5436-11ea-883a-94512bac16a4.png); ![small](https://user-images.githubusercontent.com/16548075/75012334-97cd4200-5436-11ea-9393-696a00b884f8.png),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589529166:254,benchmark,benchmarks,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-589529166,1,['benchmark'],['benchmarks']
Testability,"I want to second this issue!! I just spent many hours digging into the source code to figure out why `filter_rank_genes_groups` was filtering out genes that reported really high fold changes from `rank_genes_groups`, only to discover the discrepancy in the fold change calculation. Here is an example of how confusing this inconsistency can be:. - I run `rank_genes_groups` and see that many marker genes have high log2 fold changes in `adata.uns['rank_genes_groups']['logfoldchanges'][<cluster_string>]`. For example, gene X has a fold change of -27.720167.; - Then, I run `filter_rank_genes_groups` -- and none of these genes with high negative fold changes are retained; - There are two issues here: one is that negative fold changes don't get retained at all. [This is the issue I notice first, and report in #1325]. I fix that in my fork of the repo (solution below), but STILL these genes are removed when filtering for a min absolute fold change of 1.5 (0.58 on log scale)... ?!; - This boils down to the inconsistency in fold change calculation. Mean expression of gene X within my cluster of interest is 0, and outside it is 0.1997576. `np.log2((0 + 1e-9)/(0.1997576 + 1e-9)) = -27.720167`, as reported originally by `rank_genes_groups`. As a user, I completely expect this gene to pass my threshold. `filter_rank_genes_groups`, however, calculates fold change as `np.log2(np.exp(0)/np.exp(0.199758)) = -0.288189`, which does NOT pass my fold change threshold, thus it gets filtered out. All this happens silently of course [the only number I have seen is a whopping fold change of -27] leaving me utterly confused. I'm not sure which is more correct (though -27 seems pretty inflated to me given the raw numbers), but it would make a lot more sense for it to at least be consistent, especially so that `filter_rank_genes_groups` could give expected results. p.s. Here is my fix to retain downregulated genes in `filter_rank_genes_groups`: update the third condition to `(np.absolute(np.log2(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/863#issuecomment-661497061:469,log,logfoldchanges,469,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/863#issuecomment-661497061,2,['log'],"['log', 'logfoldchanges']"
Testability,"I was able to set up a dev environment with a little work. I think it works? Ran into some other issues though. <details>; <summary> Roughly what I ran </summary>. ```sh; mamba create -yn ""numba-0.55.0rc1-pip"" -c conda-forge python=3.10 pip; conda activate numba-0.55.0rc1-pip; pip install ""numba== 0.55.0rc1-pip""; pip install flit_core setuptools_scm; cd ~/github/anndata; pip install -e "".[dev,doc,test]""; cd ~/github/scanpy; pip install -e --no-build-isolation "".[dev,doc,test]""; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911:400,test,test,400,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911,2,['test'],['test']
Testability,"I was also investigating how `leiden` got `use_weights=True` by default, and noticed the lack of discussion. Seems like it just sorta happened when `leiden` got added #361?. I think it'd be pretty different from clustering on the embedding, because the embedding has constraints based on things like minimum distance two points can be from each other, and the number of dimensions it's embedded in. On the binarized KNN-graph, I think we've actually talked about this before (#240). I personally think using a weighted graph makes more sense. For example, say you have a cell type of which occurs 15 times in your dataset, but you've set k to 30. With a binarized graph there will be a less clear signal that this is a distinct cell-type. From a slightly more empirical/ anecdotal perspective, on a couple datasets I tested, total degree of the generated graph was sub-linear (looked log-ish) w.r.t. `k` for the weighted umap graph. Here's using one of the bone marrow donors from the hca immune census (y-axis is log scaled so you can still see the total weighted degree increase):. ![image](https://user-images.githubusercontent.com/8238804/56469005-400d2580-6477-11e9-98f1-b9dfe70bd1d7.png). To me, this suggested a stable representation of the dataset was being found. As a connected point, in my experience clustering results seems fairly robust to `k` for weighted graphs above a low threshold (I think dataset dependent, but 30-60 range). Using an unweighted graph, there is a much stronger dependence on `k` and some smaller clusters seem less stable (show up in a smaller proportion of clustering solutions from a parameter space).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638:817,test,tested,817,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638,3,"['log', 'test']","['log', 'log-ish', 'tested']"
Testability,"I was following Scanpy's tutorial for preprocessing and clustering the 3k PBMC data set, as seen [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). Unfortunately, many of the most informative marker genes are simply missing/discarded from the data set. Some of the genes a contributor has pointed out are missing from this set are: CD14, CD68, FTH1, SERPINA1, LYZ. Similar R tools, such as [rook/pagoda1](http://pklab.med.harvard.edu/cgi-bin/R/rook/10x.pbmc/index.html), have these genes displayed, some of them with quite high variance values (e.g. LYZ). Is this an issue with the tutorial itself, or is there a bug in scanpy that we are unaware of?. ```; >>> import anndata; >>> adata = anndata.read('./src/tests/test.h5ad'); >>> adata; AnnData object with n_obs × n_vars = 2638 × 1838; obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'cell_ids'; var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'gene_names'; >>> adata.var; gene_ids n_cells mt n_cells_by_counts mean_counts ... dispersions dispersions_norm mean std gene_names; TNFRSF4 ENSG00000186827 155 False 155 0.077407 ... 2.086050 0.665406 -3.672069e-10 0.424481 TNFRSF4; CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L; ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C; C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86; RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1; ... ... ... ... ... ... ... ... ... ... ... ...; ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG; SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3; SLC19A1 ENSG00000173638 31 False 31 0.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1338:729,test,tests,729,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338,2,['test'],"['test', 'tests']"
Testability,"I was just about to ask about the chunking along genes - you read my mind @falexwolf. I think it might be possible to do a multi-dimensional adaptation of the scipy.stats code you linked to, and still do the math with sparse matrices, similar to how we implemented the t-tests. This way we could possibly avoid the chunking (it might help with readability of the code). Would this be worth pursuing?. I'll give this a quick try, but I am a little limited in bandwidth. I'll let you know soon if it would be best to get some help from @Koncopd (if they have time!)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-427489214:271,test,tests,271,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-427489214,1,['test'],['tests']
Testability,"I was looking at the scanpy function to compute the mean and variance an noticed that it had some comments inside, pointing to performance issues. Thus, I looked for an alternative method, found the sklearn sparse function and then tested it in an artificially large matrix. Otherwise, I did not have any trouble with the current implementation. The floating point precision is higher in the sklearn method, thus I suppose this is not an issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/163#issuecomment-392049026:232,test,tested,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163#issuecomment-392049026,1,['test'],['tested']
Testability,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/512#issuecomment-469314623:21,test,tests,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469314623,1,['test'],['tests']
Testability,"I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations ; - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1667:617,Test,Tests,617,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667,1,['Test'],['Tests']
Testability,"I was running this:; `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`; Which gave me this error:; ```; Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/ipykernel_30806/3135920018.py in <module>; ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction); 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the; 587 # structure of the gene_names dataFrame; --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values; 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values; 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key); 929 ; 930 maybe_callable = com.apply_if_callable(key, self.obj); --> 931 return self._getitem_axis(maybe_callable, axis=axis); 932 ; 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis); 1161 ; 1162 # fall thru to straight lookup; -> 1163 self._validate_key(key, axis); 1164 return self._get_label(key, axis=axis); 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis); 970 # boolean not in slice and with boolean index; 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):; --> 972 raise KeyError(; 973 f""{key}: boolean label can not be used without a boolean index""; 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```; Any ideas? I'm using Scanpy 1.5.0 and pandas 1.3.1. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1990:590,log,log,590,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990,1,['log'],['log']
Testability,"I was thinking about these in the context of of feature selection, where you may want a principled cutoff for inclusion. From looking at this in one visium datasets and one single cell dataset. It looks like expected value for any gene with a high morans I were quite low. This was not the case for Geary's C on the umap connectivity with single cell data. Here are some plots around this. Values from permuting the order are in blue, measured values are in black. This only shows the genes which were in the 95th percentile of scores. I inverted the values of gearys C so it was easier to compare with morans I. The x-axis is score between 0 and 1, the y axis is gene rank. It's pretty clear there is much greater dispersion of expected value for Geary's C. <details>; <summary> Morans I UMAP connectivity </summary>. ![image](https://user-images.githubusercontent.com/8238804/112266866-bac8c600-8cc8-11eb-96bc-922256b7e52e.png). </details>. <details>; <summary> Geary's C UMAP connectivity </summary>. ![image](https://user-images.githubusercontent.com/8238804/112266847-b3092180-8cc8-11eb-8e1a-56b26c6bfe23.png). </details>. <details>; <summary> Morans I spatial connectivity </summary>. ![image](https://user-images.githubusercontent.com/8238804/112269342-5b6cb500-8ccc-11eb-8339-b0b9512a5081.png). </details>. <details>; <summary> Geary's C spatial connectivity </summary>. ![image](https://user-images.githubusercontent.com/8238804/112266893-c5835b00-8cc8-11eb-931e-0169ccc0471f.png). </details>. Comparing distribution of scores for the single cell PBMC data:. ![image](https://user-images.githubusercontent.com/8238804/112268036-76d6c080-8cca-11eb-8d0d-a22c1e11ff7c.png). My current thinking is that Gearys C is more sensitive to sparse features, and may be more in need of significance testing. I think this is not as visible for visium data since features are less sparse.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-805564864:1795,test,testing,1795,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-805564864,1,['test'],['testing']
Testability,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>; <summary> Example output: </summary>. ```; -----; IPython 7.16.1; scanpy 1.5.2.dev38+g6728bdab; sinfo 0.3.1; -----; IPython 7.16.1; PIL 7.2.0; anndata 0.7.5.dev0+g58886f0.d20200729; asciitree NA; backcall 0.2.0; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dask 2.21.0; dateutil 2.8.1; decorator 4.4.2; fasteners NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.2; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.33.0; louvain 0.7.0; matplotlib 3.3.0; monotonic NA; mpl_toolkits NA; msgpack 1.0.0; natsort 7.0.1; numba 0.50.1; numcodecs 0.6.4; numexpr 2.7.1; numpy 1.19.0; packaging 20.4; pandas 1.0.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.5.2.dev38+g6728bdab; scipy 1.5.1; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.23.1; sphinxcontrib NA; storemagic NA; tables 3.6.1; tblib 1.6.0; texttable 1.6.2; tlz 0.10.0; toolz 0.10.0; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zarr 2.4.0; -----; Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]; macOS-10.15.6-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2020-07-30 19:28; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1343#issuecomment-666257831:1488,log,logical,1488,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343#issuecomment-666257831,1,['log'],['logical']
Testability,"I was wondering if using the initial `total_counts` versus the post-filtering `total_counts` really matter that much. In the end we typically only filter out genes that have very few counts, so that the difference between the initial and post-filtering `total_counts` should be minimal. Principally using pre-filtering values is probably more logical, although I'm not sure it really changes anything. I wonder how hard it would be to put scran's size factor calculation into python... that might be a good HiWi project.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/429#issuecomment-460629186:343,log,logical,343,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/429#issuecomment-460629186,1,['log'],['logical']
Testability,"I welcome @VolkerBergen ideas about plot scatter. I have used the scvelo version of scatter and works quite well and always thought that we could integrate this. Our comprehensive collection of tests related to embeddings should facilitate the recreation of the current functionality using a scatter module. As @flying-sheep points out we have a mess with respect to `pl.scatter` and `pl.embeddings` and would be great to unify the code. Currently, `pl.scatter` is used to plot two genes or any two variables like in `sc.pl.highly_variable_genes`. `pl.embedding` takes x,y (and z if 3D) from `.obsm` while adjusting color and size depending on given parameters. When I started working on the plotting functions I didn't touch `pl.scatter` which remains quite convoluted and hard to follow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/617#issuecomment-554257192:194,test,tests,194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554257192,1,['test'],['tests']
Testability,"I went over all the places where we use the `array_type` fixture and thought about your idea to use `@pytest.mark.parametrize` and I came around to it for this case:. For **unfinished** features, it’s great. Everwhere we can’t say “we fully support this” and gradually build in support, we should use it. It has its disadvantages:. - `@pytest.mark.parametrize(""array_type"", ARRAY_TYPES)` is so long that in practice, it’s hard to see the difference to something like this: `@pytest.mark.parametrize(""array_type"", ARRAY_TYPES_XYZ)`. 	E.g. I don’t like seeing; 	; 	```py; 	@pytest.mark.parametrize(""array_type"", ARRAY_TYPES); 	@pytest.mark.parametrize(""dtype"", [""float32"", ""int64""]); 	```. 	4 times in `test_normalize_total`. If the 3rd test had a different list of values in one of the params, it would be near impossible to see. - Fixtures can depend on other fixtures, but can’t easily have a parameter matrix without that. (`pytest.fixture(params=...)` only accepts a single list of parameters, we’d have to manually use `product` in there for a matrix). That’s why I didn’t go away from a fixture in `test_pca.py`. I therefore propose that we use `@pytest.mark.parametrize` for. - things that aren’t heavily reused; - things we don’t fully support. and fixtures for everything where there’s ~3 or more test functions using the same list of parameter values.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2696#issuecomment-1781361678:735,test,test,735,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2696#issuecomment-1781361678,2,['test'],['test']
Testability,"I will check. Meanwhile, I realized that some errors were introduced in the latest plotting functions, thus I started working in a list of tests to avoid those problems in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/204#issuecomment-405303780:139,test,tests,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/204#issuecomment-405303780,1,['test'],['tests']
Testability,"I will take a look later to see how we can integrate better the visualizations, the tests and the documentation. I will put back `kwds` also. . Have you consider adding another dataset to the repository? This will be good for showing examples.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207#issuecomment-405505301:84,test,tests,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207#issuecomment-405505301,1,['test'],['tests']
Testability,"I will take a look. On Fri, Jan 11, 2019 at 6:08 PM Andreas <notifications@github.com> wrote:. > Hi thinks for the answer and thanks for the link on the test data and; > visualization, I will try to use that going forward.; >; > I will cook up a non working example if needed, however just looking at; > the code; > https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L302; > there is missing return statements for a few of the plotting functions in; > the _rank_genes_groups_plot unless I missed something they will then not; > return an axes?; >; > The heatmap; > <https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L1044>; > function itself return an axis but there is no return statement from the; > _rank_genes_groups_plot.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/419#issuecomment-453587853>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1aJAKobdjZYdCil5CcJ3vJz8h-2nks5vCMUmgaJpZM4Z4pAD>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/419#issuecomment-453606922:153,test,test,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453606922,1,['test'],['test']
Testability,I wonder why the tests are not working now?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-696687023:17,test,tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-696687023,1,['test'],['tests']
Testability,"I would definitely recommend using the `sc.logging.print_versions` function for a more complete listing of dependencies, which does include `pynndescent`. That said, I'm not against adding it to the more compact version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1613#issuecomment-768656224:43,log,logging,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1613#issuecomment-768656224,1,['log'],['logging']
Testability,"I would like to change the var name when plotting dotplot by setting the `gene_symbols` to the desired name. But this generates the NameError. Below is an example using the scanpy built-in dataset. ```python; adata = sc.datasets.pbmc68k_reduced(); ax = sc.pl.dotplot(adata, 'C1QA', groupby=['bulk_labels'], swap_axes=False, gene_symbols='TEST'); ```. ```pytb; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-45-206578ef4fd5> in <module>; 1 adata = sc.datasets.pbmc68k_reduced(); ----> 2 ax = sc.pl.dotplot(adata, 'C1QA', groupby=['bulk_labels'], swap_axes=False, gene_symbols='TEST'); 3 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 930 dot_color_df=dot_color_df,; 931 ax=ax,; --> 932 **kwds,; 933 ); 934 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds); 142 layer=layer,; 143 ax=ax,; --> 144 **kwds,; 145 ); 146 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, **kwds); 111 num_categories,; 112 layer=layer,; --> 113 gene_symbols=gene_symbols,; 114 ); 115 . ~/anaconda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1636:338,TEST,TEST,338,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636,3,"['TEST', 'log']","['TEST', 'log']"
Testability,"I would say there is a more general problem. You should be able to expect that `sc.tl.rank_genes_groups(adata)` and then `sc.pl.rank_genes_groups(adata)` always works. However, if adata is subsetted to HVGs and then `sc.tl.rank_genes_groups()` is run with the default of use_raw=True, then you can get genes as top ranked markers which are not in the adata.X subset. Thus, `sc.pl.rank_genes_groups()` or `sc.pl.rank_genes_groups_violin()` will fail as the gene in `adata.uns['rank_genes_groups']['name']` is not found in adata.var_names. This occurs as the plotting is done on adata.X and not adata.raw.X. I've tested this when using the gene_symbols parameter, but it feels like it should also happen when just using regular var_names.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/210#issuecomment-407082502:611,test,tested,611,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/210#issuecomment-407082502,1,['test'],['tested']
Testability,"I would say this is not a scanpy question.; It is not clear what do you mean by correlation of a categorical variable with multiple categories and a continuous variable. ; If you have a binary categorical variable, you can calculate Point Biserial Correlation, but for a multicategorical variable you would have to discretize your continuous variable and calculate Chi-squared test. You can also try ANOVA. If you think you know what variables are dependent and independent you can use logistic regression and look at its coefficients or try ANCOVA.; some additional information with examples; https://datascience.stackexchange.com/questions/893/how-to-get-correlation-between-two-categorical-variable-and-a-categorical-variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1845#issuecomment-848101984:377,test,test,377,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845#issuecomment-848101984,2,"['log', 'test']","['logistic', 'test']"
Testability,I would suggest `scanpy\[test\]` . Works with BASH and ZSH.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1441#issuecomment-703314166:25,test,test,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441#issuecomment-703314166,1,['test'],['test']
Testability,I'd appreciate a quick review from @fidelram or @flying-sheep on this. It'd be nice to get this soon since the tests failing are blocking the merging of other PRs.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1090#issuecomment-596377120:111,test,tests,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090#issuecomment-596377120,1,['test'],['tests']
Testability,"I'd be interested in hearing what this might break. While I was checking to see if the euclidean distance implementation here got different results than the sklearn one, my (fairly cursory) tests at the repl passed the `np.allclose` test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/245#issuecomment-416827079:190,test,tests,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/245#issuecomment-416827079,2,['test'],"['test', 'tests']"
Testability,"I'd be up for all of the numbered ones. IIRC, I had some issues with the trailing whitespace/ end of file fixers and some binary files/ csvs in the test suite. I'm a bit worried about false positives with `check-large-files`, but so long as it's easy to allow certain things (e.g. intentionally added test data) it should be fine. In terms of breaking these things down into small tasks/ PRs how about: (1), (2, 3), (4, 5)?. `prettier` looks a bit heavy and like it's targeting a lot of stuff we don't use, so you'd have to make a good case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-842799143:148,test,test,148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-842799143,2,['test'],['test']
Testability,"I'd have to think about the naming scheme, since its something I've been going back and forth on recently. I'm playing around with these semantic a bit over in my [mantis](https://github.com/ivirshup/mantis) repo, but I don't think I'm ready to make a call on which one I like best. Right now I'm split between following [plyexperiment](https://github.com/sa-lee/plyexperiment) and `xarray`. I think I'd like to keep them as separate functions, since the `calculate_qc_metrics` function already has about as complicated a relationship as I'd want with parameter values and return type. How about these keep their current name for now, but we don't export these functions beyond `_qc.py`? This will let me play around with their naming scheme and the usefulness a bit more, while scanpy gets the faster, more thorough tests and improved `calculate_qc_metrics`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/615#issuecomment-487265939:817,test,tests,817,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-487265939,1,['test'],['tests']
Testability,"I'd like to add this function plus tests to scanpy. I think I'll leave out `n_rings` argument and the `radius_neighbors` functions until there are clear use-cases. I would recommend just having a copy of the code in spatial-tools, which can be deduplicated later.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-707603083:35,test,tests,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-707603083,1,['test'],['tests']
Testability,"I'll keep the focused PRs in mind. The new control flow seems reasonbale. I was unfamiliar with the `@singledispatch` decorator, so it was not directly self explanatory for me. I expected infinity loops and unreachable code, but it turned out to be correct (:. `inf` is there for the sparse case `zero_center=False` and a gene with zero variance but finite mean. Here is the example (slightly modified from the new `tests/test_scaling.py`), with the four cases for genes `(mean==0,mean!=0) x (var==0,var!=0)`:; ```; X = csr_matrix([[-1,2,0,0],[1,2,4,0],[0,2,2,0]]); X = sc.pp.scale(Xtest, copy=True, zero_center=False); X; ```; If `std[std == 0] = eps` (`eps!=0`) is only in the dense path, I get: `array([[-1., inf, 0., 0.], [ 1., inf, 2., 0.], [ 0., inf, 1., 0.]])`; if `std[std == 0] = 1` is before the sparse/dense split, I get: `array([[-1., 2., 0., 0.], [ 1., 2., 2., 0.], [ 0., 2., 1., 0.]])`; if `std[std == 0] = 1e-12` is before the sparse/dense split, I get: `array([[-1., 2.e+12, 0., 0.], [ 1., 2.e+12, 2., 0.], [ 0., 2.e+12, 1., 0.]])`. This suggests, that `0/0` in a sparse setting remains `0` (I guess thats what you see); it makes sense for an efficient sparse matrix implementation, as the `0` is not even represented in the sparse data, so scaling with anything is optimized away. If it were not, it should probably yield `nan` and not `0`.; But if you have something finite with zero variance, you get an explicit `<finite>/0=inf`. [This IS an edge case, and probably never the case in real expression data, but still the behaviour should be consistent and well defined.]; Now, if you have the statement `std[std == 0] = eps` before the sparse/dense split, the `inf` is caught in both cases. The change from `eps=1e-12` to `eps=1` only makes the values keep their original values without zero centering, instead of having these values multiplied by the arbitrary `1e12`. I read the intent for this behaviour into the Note in the docs ""Variables (genes) that do not display any variat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1160#issuecomment-622613221:416,test,tests,416,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1160#issuecomment-622613221,1,['test'],['tests']
Testability,"I'll take a look at this to make sure I've not messed up in writing this wrapper (I'm actually doing some more testing myself for production use right now). . But you should know that what we've done here is mirror some of the internals of scrublet, but using Scanpy functions. Scrublet should be supplied with raw counts, but does do its own normalisations internally before doing the actual doublet prediction, which is what we're doing here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1957#issuecomment-889126422:111,test,testing,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957#issuecomment-889126422,1,['test'],['testing']
Testability,"I'll work a little bit with this branch for a couple of days to test it out myself, I might also push little changes to it. I'm super happy to merge after these tests. :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-424803869:64,test,test,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-424803869,2,['test'],"['test', 'tests']"
Testability,"I'm a little confused about the question. `normalize_total` does try to modify the data inplace:. ```python; adata = sc.AnnData(np.arange(16).reshape((4, 4))); a = adata.X; sc.pp.normalize_total(adata); assert a is adata.X; ```. In general, we try to make most operations in place for efficiency. This should allow people to work with datasets that fit uncomfortably in memory, which might not be an option if a copy was made. Your screenshot does show some weirdness in the anndata constructor where a copy get's made, which there are more details on here: https://github.com/theislab/anndata/issues/129. Basically there's a line in the constructor where:. ```python; adata.X = X.astype(dtype=dtype); ```. where `dtype` defaults to float32. This is something we'd like to remove, but it was troublesome when last attempted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1415#issuecomment-694688826:203,assert,assert,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1415#issuecomment-694688826,1,['assert'],['assert']
Testability,"I'm actually testing and tweaking someone else's code that was written a while ago. I assume they used; `import scanpy.api as sc` because it was appropriate then. I personally resolved my issue by downgrading versions, I just wanted to bring this up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-683807774:13,test,testing,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-683807774,1,['test'],['testing']
Testability,"I'm also a bit confused about how the CLR is applied. In the CITE-seq paper, I think it was done within a cell (over proteins), then I think they had switched to within a protein (over cells), and now in Seurat v4 it appears to be back to within a cell. Any per cell normalization is a bit tricky because the panels will differ between datasets as well as the titration of antibodies used. The simplest thing to me seems to be a simple log transformation combined with per protein scaling, as values between proteins are not comparable to begin with. We have some additional thoughts in the appendix of our totalVI paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1469#issuecomment-729339290:436,log,log,436,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469#issuecomment-729339290,1,['log'],['log']
Testability,I'm also not sure why the test is failing -- it works interactively locally for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1182#issuecomment-618699783:26,test,test,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182#issuecomment-618699783,1,['test'],['test']
Testability,"I'm also suddenly having this problem with ""ValueError: Length of values (1) does not match length of index()"" for certain Scanpy functions like `sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac')` and numpy functions `adata.obs['log_counts'] = np.log(adata.obs['n_counts'])`. The error is not due to a problem with my adata file because it reproduces with datasets that were previously error-free.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-944874522:258,log,log,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-944874522,1,['log'],['log']
Testability,I'm as puzzled as you are... We've been discussing this a bit here: #549 . I didn't really change anything of note when Travis started failing. And I have no idea why the test would result in a `1.0`. Do you know if there are any instructions on how to rebuild the test environment in conda? Is it just python 3.5 and scanpy from github?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/580#issuecomment-478620980:171,test,test,171,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478620980,2,['test'],['test']
Testability,I'm confused too. The documentation says that flavor ='seurat' or flavor ='cell_ranger' needs logarithmic data. Why the data is transformed back out of logspace using X=np.expm1(X) if flavor='seurat' ? Doesn't this do nothing if expm1(log1p(X))?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1545#issuecomment-1222015647:94,log,logarithmic,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545#issuecomment-1222015647,2,['log'],"['logarithmic', 'logspace']"
Testability,"I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```; /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors); 1768 ; 1769 if k <= 0 or k >= min(n, m):; -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)); 1771 ; 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066); ```; Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/331:730,test,test,730,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331,1,['test'],['test']
Testability,"I'm getting the same error using the CellBender tutorial output. Attaching the file to make it easier to reproduce. [tiny_10x_pbmc_filtered.h5.zip](https://github.com/scverse/scanpy/files/8766499/tiny_10x_pbmc_filtered.h5.zip). `sc.logging.print_versions()`. ```; -----; anndata 0.7.8; scanpy 1.9.1; -----; PIL 9.0.1; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; doubletdetection 4.2; entrypoints 0.4; executing 0.8.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.10.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; mudata 0.1.1; muon 0.1.2; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; organize_metadata NA; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.28; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2022.1; scikits NA; scipy 1.8.0; seaborn 0.11.2; session_info 1.0.0; setuptools 62.0.0; setuptools_scm NA; six 1.16.0; sklearn 1.0.2; stack_data 0.2.0; statsmodels 0.13.2; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.63.1; traitlets 5.1.1; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 8.2.0; jupyter_client 7.1.2; jupyter_core 4.9.2; notebook 6.4.10; -----; Python 3.9.11 (main, Mar 28 2022, 10:10:35) [GCC 7.5.0]; Linux-4.15.0-142-generic-x86_64-with-glibc2.27; -----; Session information updated at 2022-05-24 15:05; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284:232,log,logging,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284,1,['log'],['logging']
Testability,"I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1517:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517,2,['test'],"['test', 'tests']"
Testability,"I'm having some trouble debugging whatever is going wrong with the notebook tests here. I get the same results if I run `pytest` on my machine, but don't get a failure if I run the code manually. Additionally, I don't get an error (the `abort`) if I *only* run the notebook tests (`pytest -k ""test_pbmc3k""`). Pretty sure the error is happening on the call to louvain in the notebook tests – an `assert False` fails the tests, one after gives current result – but I can't reproduce the abort interactively. Any idea what's going on/ how I can get a more helpful error message here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-419695136:76,test,tests,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-419695136,5,"['assert', 'test']","['assert', 'tests']"
Testability,"I'm not comfortable with doing an absolute switch without significant testing. I would want a few frequent contributors (Fidel, Sergei, Goecken?) to try it out, try and break it, and make sure we could get things done. I also still have concerns about the limitations of what flit can distribute, and would like to hear other's thoughts on this. If a `setuptools` based workflow can happen, then I don't think these steps are necessarily blocking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-760622794:70,test,testing,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-760622794,1,['test'],['testing']
Testability,"I'm not completely sure this doesn't break anything, but the regression tests pass. The internal code is very similar, so I'm not too worried about these changes. It does look like it's (very) slightly slower. Running this a thousand times for pbmc68k dataset took ~2.3% longer (about 1.4 ms per run) than the previous version. That said, we're very inefficient about mean and variance calculation, so I think that's a better place to optimize. Edit: I've force pushed to fix some minor formatting issues (trailing white space, blank line, typo) that I didn't think deserved it's own commit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/621#issuecomment-487260802:72,test,tests,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/621#issuecomment-487260802,1,['test'],['tests']
Testability,"I'm not super familiar with this code, I had no idea a pie chart could even be used here. @falexwolf or @fidelram may be able to say more here. A few points:. * This should have a regression test, similar to [these](https://github.com/theislab/scanpy/blob/c255fa10fb75f607780ed7d9afc6683cbcecc38e/scanpy/tests/test_plotting.py#L742-L774); * Could you give some more details about the benchmark? 14 seconds seems far too slow for that plot. Also, is that plotting right? The pie charts all look the same.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1123#issuecomment-604224882:191,test,test,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123#issuecomment-604224882,3,"['benchmark', 'test']","['benchmark', 'test', 'tests']"
Testability,I'm not sure I totally trust that generated test data to be reproducible across scipy versions. Could you use one of the small example datasets modified in a deterministic way instead? Something like `sc.datasets.krumsiek11()`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1890#issuecomment-871135647:44,test,test,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890#issuecomment-871135647,1,['test'],['test']
Testability,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof; >; > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode; * Changing organization of tests; * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922:303,test,testing,303,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922,5,['test'],"['test', 'testing', 'tests']"
Testability,I'm not sure the benefits from using mypy would outweigh the pain in using unstable numpy type-stubs,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/839#issuecomment-531642595:95,stub,stubs,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839#issuecomment-531642595,1,['stub'],['stubs']
Testability,"I'm sure it will be... Just having network issues atm, so server storage is too slow to do anything. Can't really test this atm I'm afraid :/.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/614#issuecomment-486205965:114,test,test,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-486205965,1,['test'],['test']
Testability,"I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `; adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'); reading GSE164690_RAW/GSM5017021_HN01_PBL/; ---------------------------------------------------------------------------; IsADirectoryError Traceback (most recent call last); Input In [3], in <cell line: 1>(); ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url); 178 if not is_present:; 179 logg.debug(f'... did not find original file {filename}'); --> 180 with h5py.File(str(filename), 'r') as f:; 181 v3 = '/matrix' in f; 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds); 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,; 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds); 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,; 505 fs_persist=fs_persist, fs_threshold=fs_threshold,; 506 fs_page_size=fs_page_size); --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr); 509 if isinstance(libver, tuple):; 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr); 218 if swmr and swmr_support:; 219 flags |= h5f.ACC_SWMR_READ; --> 220 fid = h5f.open(name, flags, fapl=fapl); 221 elif mode == 'r+':; 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_ph",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2328:745,log,logg,745,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328,1,['log'],['logg']
Testability,"I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.external.pp.bbknn(; adata,; batch_key=""batch"",; n_pcs=21,; neighbors_within_batch=5,; trim=0); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Command error:; Traceback (most recent call last):; File ""~/sc_batch_effect_correction.py"", line 160, in <module>; trim=args.trim); File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn; **kwargs,; File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn; approx=approx, metric=metric, **kwargs); File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix; neighbors_within_batch=neighbors_within_batch); File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph; knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]; ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1222:1235,log,logging,1235,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222,1,['log'],['logging']
Testability,"I'm trying to use an array for the size argument to my umap/scatterplot with the following code; ```; import scanpy.api as sc; import numpy as np; sc.settings.figdir = ""testdir""; sc.settings.file_format_figs = ""png""; sc.logging.print_versions(); ```; With these libraries; `scanpy==1.3.7 anndata==0.6.16 numpy==1.16.1 scipy==1.2.0 pandas==0.23.4 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `. Running the following code bit. I use some dummy variable for size.; ```; somedata = sc.datasets.paul15(); sc.pp.pca(somedata); sc.pp.neighbors(somedata, n_neighbors=4, n_pcs=20); sc.tl.umap(somedata, spread=1, min_dist=0.1, random_state=42); sc.tl.leiden(somedata, resolution=0.5, random_state=42); z = np.abs(somedata.obsm['X_pca'][:,0])**1; sc.pl.umap(somedata, color=['1110007C09Rik'], size=z, cmap='viridis', save='continuous_expr.png'); sc.pl.umap(somedata, color=['leiden'], size=z, cmap='viridis', save='group_value.png'); ```; I get the following two figure as output; ![umapcontinuous_expr](https://user-images.githubusercontent.com/715716/52612879-951a3300-2e59-11e9-9dad-a8afc60a4b54.png); ![umapgroup_value](https://user-images.githubusercontent.com/715716/52612880-95b2c980-2e59-11e9-9a44-81dd84e3274d.png). I would expect to see a similar size allocation/distribution but they are very different. I Could not really find a cause for this looking at the scatter plot function so it might be somewhere deeper. . I'm need help with getting some grasp on how to interpret this issue and if possible how to map the size argument to the same data points over different plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/478:169,test,testdir,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/478,2,"['log', 'test']","['logging', 'testdir']"
Testability,"I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```; adata.raw = adata; sc.pp.recipe_weinreb17(adata, log=False); sc.tl.pca(adata); ```. I keep getting this output:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-4-bfa4168a87e6> in <module>; 1 adata.raw = adata; ----> 2 sc.pp.recipe_weinreb17(adata, log=False); 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy); 48 ); 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself; ---> 50 X_pca = pp.pca(; 51 pp.zscore_deprecated(adata.X),; 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'; ```. Versions:; `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1326:231,log,log,231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326,3,['log'],['log']
Testability,"I'm using Scanpy with the following software versions:. python==3.7; scanpy==1.4.4; numpy==1.17.2; anndata==0.6.22.post1. on Ubuntu 18.04. I am able to save my AnnData object just fine with . ```py; sc.write(results_file, adata); ```; and to load it again with . ```py; adata = sc.read(results_file); ```. however if I save it after I run the command . ```py; sc.tl.rank_genes_groups(adata, 'louvain12_lab', method='wilcoxon'); ```. the AnnData object will save but when I try to reload it, I get an error message:. ```pytb; ValueError Traceback (most recent call last); <ipython-input-141-159082f1696f> in <module>; 1 results_file = os.path.join(adir, '{project}.count_{count}.gene_{gene}.mito_{mito}.HVGs_{nhvgs}.TPT.{log}.scale.TEST.h5ad'.format(project=project_name, count=count_thresh, gene=gene_thresh, mito=mitothresh, nhvgs=nhvgs, log=logstatus)); 2 print(results_file); ----> 3 adata = sc.read(results_file). /opt/miniconda3/envs/py37/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. /opt/miniconda3/envs/py37/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed=backed); 500 else:; 501 logg.debug(f'reading sheet {sheet} from file {filename}'). /opt/miniconda3/envs/py37/lib/python3.7/site-packages/anndata/readwrite/read.py in read_h5ad(filename, backed, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. /opt/min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832:720,log,log,720,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832,4,"['TEST', 'log']","['TEST', 'log', 'logstatus']"
Testability,"I'm wondering if it would be possible to make a gradient descent based version of COMBAT or similar. It would involve some level of benchmarking, but presumably you would be able to get past the memory issue by streaming data in batches, letting the final weights and correction being informed by the whole data while not needing all of it in memory at once. Could possibly implement with a pytorch backend.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1977#issuecomment-1949231015:132,benchmark,benchmarking,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977#issuecomment-1949231015,1,['benchmark'],['benchmarking']
Testability,I've added a test in https://github.com/theislab/scanpy/pull/1654/commits/189354eb0074140e3f2204d09b02aaa912d13934,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1654#issuecomment-781473683:13,test,test,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654#issuecomment-781473683,1,['test'],['test']
Testability,"I've added the test mentioned above and checked on two machines (MacOS and CentOS) with the same results. ; The differences in output are after 5th decimal point, the test:; - passes np.allclose both with and without the fix (master branch vs this PR); - passes np.array_equal only with the fix (this PR); Hence, I've kept only the np.array_equal test. This series of tests uses _create_sparse_nan_matrix, so I had to set the np.random.seed to make the test reproducible and agree with the reference.; The reference is stored in tests/_data/ as a pkl file, as I've noticed that there were some analogous files stored there for other tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1890#issuecomment-869646597:15,test,test,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890#issuecomment-869646597,7,['test'],"['test', 'tests']"
Testability,"I've been able to get the tests to pass on a different machine (this one running linux). I can get rid of most of the discrepancies between plots between the two machines by replacing:. ```python; mpl.use(""agg""); ```. with. ```python; from matplotlib.testing import setup; setup(); ```. However violin plots still get a large RMS value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-434538616:26,test,tests,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-434538616,2,['test'],"['testing', 'tests']"
Testability,"I've been using a rough python implementation of Chris McGinnis's MULTIseq demuxing code for all my multiplexed experiments. This algorithm has been incorporated into Seurat as an alternative to their default `HTODemux` function. This [recent preprint](https://www.biorxiv.org/content/10.1101/2020.11.16.384222v1) suggests it's one of the better algorithms for sample demultiplexing. I recently put my implementation on GitHub here: https://github.com/wflynny/multiseq-py. Is there interest in including this in `scanpy.external` in addition to solo? If so, I can invest effort into cleaning up the implementation, adding tests, etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-758885784:622,test,tests,622,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-758885784,1,['test'],['tests']
Testability,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:; ```; import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'); adata.raw=adata.copy() #data to save; sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should; adata=adata.raw.to_adata(); sc.pp.log1p(adata); ##>>> no warning; ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:; ```; import scanpy as sc. ## same as above; adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'); adata.raw=adata.copy() #data to save; sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw; ### saving object, reading, testing again; ### Doesnt work; adata.write_h5ad(tmp+'scanpy_test.h5ad'); adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'); adata=adata.raw.to_adata(); sc.pp.log1p(adata); ###>>>WARNING: adata.X seems to be already log-transformed.; ```. I'm on scanpy 1.9.1 if it matters",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1333#issuecomment-1209486748:304,log,logaritmize,304,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333#issuecomment-1209486748,6,"['Test', 'log', 'test']","['Test', 'log-transformed', 'logaritmize', 'testing']"
Testability,"I've made a few changes:. ## Numba bug. First, the reason that you were getting different issues with floats is that there's a numba bug where the generated parallelized code is completely wrong. I ran into this with gearys_c too, so I've just done a similar thing. It seems to be triggered by having a `np.sum` in a `prange` loop, plus some minor other things. You can check the linked comment info for more details. I believe calculation of `z2ss` in the outer loop was triggering this bug, so I've just moved this into the inner function. Since we're not doing iterations anymore this shouldn't be a performance issue. ## Argument order. So, one bigger organizational change I made is to have consistent argument orders for the elements of a sparse matrix. Basically, always use the same order for positional arguments between functions, otherwise it's very easy to introduce bugs. ## Minor things. * I've modified one of the `morans_i` tests to check that if you pass a dense matrix and a sparse matrix of the same data, you should get the same results.; * I've removed the use of an intermediate array in `_morans_i_vec_W`, since you can just accumulated directly to `inum`.; * Fixed up typing, removed unused exports",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1740#issuecomment-802562555:940,test,tests,940,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740#issuecomment-802562555,1,['test'],['tests']
Testability,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356#issuecomment-674738421:288,test,tests,288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356#issuecomment-674738421,2,['test'],['tests']
Testability,"I've managed to mostly fix this with only a slightly hacky change to AnnData (no longer requiring X to have a view type defined when making a copy). However the `normalize_per_cell` test still fails, as it seems like the matrix isn't actually being modified. I think it's because the reference to the dask array on [this line](https://github.com/theislab/scanpy/blob/610a955f025f5f17328865926a9341a55553e081/scanpy/preprocessing/_simple.py#L667) becomes a copy when assigned to. I've asked about this behaviour, and if it might change or throw a warning in https://github.com/dask/dask/issues/5199",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/733#issuecomment-517226549:182,test,test,182,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/733#issuecomment-517226549,1,['test'],['test']
Testability,"I've noticed this behavior too. Here's a couple examples:. ```python; # First, using a standard test dataset; In [1]: %load_ext memory_profiler . In [2]: import scanpy as sc . In [3]: adatas = [] . In [4]: adatas_backed = [] . In [5]: for i in range(10): ; ...: %memit adatas.append(sc.read(""data/pbmc3k_raw.h5ad"")) ; ...: ; peak memory: 223.52 MiB, increment: 48.47 MiB; peak memory: 275.66 MiB, increment: 52.14 MiB; peak memory: 319.36 MiB, increment: 43.71 MiB; peak memory: 361.41 MiB, increment: 42.04 MiB; peak memory: 403.64 MiB, increment: 42.24 MiB; peak memory: 446.02 MiB, increment: 42.37 MiB; peak memory: 488.57 MiB, increment: 42.56 MiB; peak memory: 530.31 MiB, increment: 41.74 MiB; peak memory: 573.53 MiB, increment: 43.21 MiB; peak memory: 615.81 MiB, increment: 42.29 MiB. In [6]: for i in range(10): ; ...: %memit adatas_backed.append(sc.read(""data/pbmc3k_raw.h5ad"", backed=""r"")) ; ...: ; peak memory: 658.04 MiB, increment: 42.07 MiB; peak memory: 700.22 MiB, increment: 42.19 MiB; peak memory: 742.49 MiB, increment: 42.27 MiB; peak memory: 784.62 MiB, increment: 42.14 MiB; peak memory: 827.00 MiB, increment: 42.38 MiB; peak memory: 869.21 MiB, increment: 42.21 MiB; peak memory: 911.36 MiB, increment: 42.14 MiB; peak memory: 953.34 MiB, increment: 41.98 MiB; peak memory: 996.37 MiB, increment: 43.03 MiB; peak memory: 1038.57 MiB, increment: 42.20 MiB. In [7]: %memit ; peak memory: 1038.62 MiB, increment: -0.09 MiB. In [8]: sc.__version__ ; Out[8]: '1.3.7+59.ge0d2ea6'; ```. Using a larger dataset:. ```python; # In a new session:; In [4]: %memit adata = sc.read(""tmp_bm.h5ad"") ; peak memory: 2975.57 MiB, increment: 2799.25 MiB. # In another session:; In [4]: %memit adata_backed = sc.read(""tmp_bm.h5ad"", backed=""r"") ; peak memory: 2969.57 MiB, increment: 2794.57 MiB; ```. While making those examples I got a range of results, though what I've posted are the ones I saw most often. It's enough to make me think there's something strange going on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/434#issuecomment-456037752:96,test,test,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434#issuecomment-456037752,1,['test'],['test']
Testability,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:565,test,testing,565,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932,2,"['log', 'test']","['logging', 'testing']"
Testability,"I've ran into this before (`sc.read_10x_mtx()` has the same default of course). One possible issue with defaulting to `gex_only=False` is that someone might accidentally run a 'regular pipeline' with multi-modal data, e.g. log-normalizing RNA+protein+cell hashing counts together without first subsetting the adata based on `.var[""feature_types""]`. By contrast, anyone who know they have multi-modal data would hopefully notice the missing the data with `gex_only=True`. Either way, logging warnings sounds good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1949#issuecomment-879247652:223,log,log-normalizing,223,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949#issuecomment-879247652,2,['log'],"['log-normalizing', 'logging']"
Testability,"I've tested this quite a bit in the past 5 days and am merging it into master. In essence, it's a superficial change.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/406#issuecomment-450768851:5,test,tested,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450768851,1,['test'],['tested']
Testability,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh; isaac@Mimir:~/github/scanpy ‹master›; $ pytest --version; pytest 6.1.2; isaac@Mimir:~/github/scanpy ‹master›; $ pytest -n 6 --import-mode=importlib; ...; ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================; ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1528#issuecomment-742213296:79,test,tests,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528#issuecomment-742213296,10,['test'],"['test', 'testing', 'tests']"
Testability,"I've update the code to ; - test that the file is actually a tiff image; - automatically add the path to the image to `adata.uns['spatial'][library_id]['metadata']['tissue_image_path']`. It's looking for a tiff or jpeg file with the name `""image""` or `library_id""_image""`. This should cover most cases hopefully?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-734405082:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-734405082,1,['test'],['test']
Testability,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-733605592:106,test,test,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-733605592,4,['test'],['test']
Testability,ILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47114,test,tests,47114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48406,test,tests,48406,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"IPython/core/formatters.py in __call__(self, obj); ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; 0294638c8bf50491b025b096f3dba0a1 NA; absl NA; anyio NA; appnope 0.1.0; astunparse 1.6.3; attr 19.3.0; babel 2.9.0; backcall 0.2.0; brotli 1.0.9; certifi 2020.06.20; cffi 1.14.5; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; gast NA; get_version 2.2; google NA; h5py 2.10.0; idna 2.10; igraph 0.8.3; ipykernel 5.3.3; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.2; keras_preprocessing 1.1.2; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.36.0; markupsafe 1.1.1; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.0.7; numba 0.53.1; numexpr 2.7.3; numpy 1.19.0; opt_einsum v3.3.0; packaging 20.4; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.5; psutil 5.8.0; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pynndescent 0.5.2; pyparsing 2.4.7; pyrsistent NA; pytz 2019.3; requests 2.24.0; scipy 1.4.1; seaborn 0.10.0; send2trash NA; six 1.14.0; sklearn 0.23.1; sniffio 1.2.0; statsmodels 0.12.2; storemagic NA; swig_runtime_data4 NA; tables 3.6.1; tensorboard 2.2.2; tensorflow 2.2.0; termcolor 1.1.0; texttable 1.6.3; tornado 6.1; traitlets 4.3.3; typing_extensions NA; umap 0.5.1; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.3.1; zipp NA; zmq 19.0.1; -----; IPython 7.16.1; jupyter_client 6.1.6; jupyter_core 4.6.3; jupyterlab 3.0.5; notebook 6.0.3; -----; Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]; Darwin-20.2.0-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2021-05-26 22:36. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1857:2661,log,logical,2661,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857,1,['log'],['logical']
Testability,"If I catch your point the function prototype would then be. ```; def pca_loadings(; adata: AnnData,; components: Union[str, Sequence[int], None] = None,; include_lowest: bool = True,; n_points: Union[int, None] = None,; show: Optional[bool] = None,; save: Union[str, bool, None] = None,; ):; ```. Then . ```; if n_points is None and adata.n_vars < 30:; n_points = adata.n_vars; elif n_points is None:; n_points = 30. ## should we also prevent user from plotting more than adata.n_vars?. else:; n_points = min(n_points, adata.n_vars); ```; ; considering the tests, I don't see what you expect (sorry, I'm quite new to collaborative work on github):; looking at test_rankings in test_plottings.py, the test should look like; sc.pl.pca(pbmc, n_points=10); save_and_compare_images(""pca_loadings_with_10_points""). but what will it compare to?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2061#issuecomment-985389044:557,test,tests,557,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2061#issuecomment-985389044,2,['test'],"['test', 'tests']"
Testability,"If a linter flexible enough to enforce this existed, it would be great. The test should definitely exist, something in our code requires the docstrings to have that format, I just forgot which part. (But in any case it guarantees consistent formatting so that’s nice). #1492 should fix that test to ignore blank lines for the time being. Also isn’t it cool that it points exactly to the problematic line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1484#issuecomment-725978155:76,test,test,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484#issuecomment-725978155,2,['test'],['test']
Testability,"If it passes the tests I'm sure it works, feel free to pull it in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1199#issuecomment-826288598:17,test,tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199#issuecomment-826288598,1,['test'],['tests']
Testability,"If p-values are regarded as a valuable output rather than just the ranks, it might be worth recomputing as thresholding would ease the multiple testing burden. I guess that's the idea behind the `min_pCells` parameter request.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471664988:144,test,testing,144,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471664988,1,['test'],['testing']
Testability,"If plots fail on CI, this should let us see the expected, actual, and diff through azure. ~~Hopefully~~ It works!. I think this could make debugging plotting issues much easier. Here's an example of what the results look like:. <img width=""1090"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/104561575-b5814680-569b-11eb-8d1e-a9971affc645.png"">. Current issue, if tests are run in parallel, this does not work (https://github.com/pytest-dev/pytest-nunit/issues/40), which is not an immediate problem for CI, but limits applicability for local usage. I believe this is an issue with this particular pytest plugin, not necessarily this strategy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1587:385,test,tests,385,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1587,1,['test'],['tests']
Testability,"If values of color dict are not unique, `categorical.map(non_unique)` returns a string array, which caused `to_hex` to be called on each element, not just the categories. This was quite slow. Using a dataset of 13million cells, with 38 clusters but only 20 colors, benchmarking the following line . ```python; sc.pl.umap(adata, color=""louvain""); ```. On master:. ```; CPU times: user 12.3 s, sys: 187 ms, total: 12.4 s; Wall time: 12.4 s; ```. This pr:. ```; CPU times: user 6.82 s, sys: 149 ms, total: 6.97 s; Wall time: 6.97 s; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1596:265,benchmark,benchmarking,265,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1596,1,['benchmark'],['benchmarking']
Testability,"If we can cleanly switch to the igraph implementation for modularity with weights, it could make sense for that to be the default. Any chance you could point me to some benchmarks on performance? An initial test looks very impressive!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-586696126:169,benchmark,benchmarks,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053#issuecomment-586696126,2,"['benchmark', 'test']","['benchmarks', 'test']"
Testability,"If you @a-munoz-rojas would give it another try, using a multi-dimensional chunked implementation along the current implementation and the comment above, then that would be very cool! If you don't have bandwidth for that, could you pass this on to @Koncopd, who might have bandwidth? It would be nice to clean up the whole module (in particular, split up the long code chunks into three functions `_t_test()`, `_wilcoxon()`, `_logreg()`). I also made the tests work again; I guess they failed as the current implementation and scipy are handling ties a little different; the results for scores were exactly the same up to the position of a single gene. . Please make a new PR for any of this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-427484452:455,test,tests,455,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-427484452,1,['test'],['tests']
Testability,"If you have to regress out covariates, maybe you could do it after log transformation? I'm not 100% sure about this approach either though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2110#issuecomment-1103608129:67,log,log,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110#issuecomment-1103608129,1,['log'],['log']
Testability,"If you use `knn=False` to calculate neighbors, any choice of metric is ignored. [Here's the offending line of code.](https://github.com/theislab/scanpy/blob/6c1daba7448be72de84dec16a038fcaeda1636ad/scanpy/neighbors/__init__.py#L706). A quick example:. ```python; import scanpy.api as sc; import numpy as np. adata = sc.datasets.krumsiek11(); adata.obs_names_make_unique(); sc.pp.pca(adata) # To get rid of warnings; adata_eucl = sc.pp.neighbors(adata, knn=False, method=""gauss"", copy=True); adata_spear = sc.pp.neighbors(adata, knn=False, method=""gauss"", copy=True, metric=""correlation""). assert np.all(adata_eucl.uns[""neighbors""][""connectivities""] == adata_spear.uns[""neighbors""][""connectivities""]); ```. Additionally, I suspect this should throw an error:. ```python; sc.pp.neighbors(adata, method=""gauss"", knn=False, metric=""not a real metric""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/241:589,assert,assert,589,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/241,1,['assert'],['assert']
Testability,"If your implementation already uses scanpy, the best is to keep it in your repository and we can link to it from scanpy (see https://scanpy.readthedocs.io/en/stable/ecosystem.html). I did some work on HTOs in the past and for me what worked best was to fit a gaussian mixture but I had not followed the new methods. Something that helped was to visualize the results as follows (each row a different barcode, x axis = log HTO):. ![image](https://user-images.githubusercontent.com/4964309/104469555-edfc2400-55b8-11eb-9f47-580395b255a7.png). If you are interested I can share the code with you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-759510507:418,log,log,418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-759510507,1,['log'],['log']
Testability,Ignore blank lines in docstring test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1492:32,test,test,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492,1,['test'],['test']
Testability,Ignore dask dataframe warning in tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2852:33,test,tests,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2852,1,['test'],['tests']
Testability,Image files did not match.`; * Some missing function from scipy; * Missing pynndescent; * 3 or 4 more unique ones. <details>; <summary> </summary>. ```python; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_metrics.py::test_consistency[morans_i-allclose] - AssertionError: ; FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:1245,test,tests,1245,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['test'],['tests']
Testability,"ImplicitModificationWarning; 8 from ._core.merge import concat; 9 from ._core.raw import Raw. ~\.conda\envs\NewPy38\lib\site-packages\anndata\_core\anndata.py in <module>; 15 from typing import Tuple, List # Generic; 16 ; ---> 17 import h5py; 18 from natsort import natsorted; 19 import numpy as np. ~\.conda\envs\NewPy38\lib\site-packages\h5py\__init__.py in <module>; 31 raise; 32 ; ---> 33 from . import version; 34 ; 35 if version.hdf5_version_tuple != version.hdf5_built_version_tuple:. ~\.conda\envs\NewPy38\lib\site-packages\h5py\version.py in <module>; 13 ; 14 from collections import namedtuple; ---> 15 from . import h5 as _h5; 16 import sys; 17 import numpy. h5py\h5.pyx in init h5py.h5(). ImportError: DLL load failed while importing defs; ````; Step4: I do `!pip uninstall h5py` and `conda install -c conda-forge pytables h5py`, then; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_14912/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 27 from .. import logging as logg; 28 ; ---> 29 from .compute.is_constant import is_constant; 30 ; 31 . ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\compute\is_constant.py in <module>; 3 ; 4 import numpy as np; ----> 5 from numba import njit; 6 from scipy import sparse; 7 . ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in <module>; 198 ; 199 _ensure_llvm(); --> 200 _ensure_critical_d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:5748,log,logging,5748,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841,1,['log'],['logging']
Testability,"ImportError Traceback (most recent call last); <ipython-input-1-b6c916879140> in <module>(); 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc. ~\Anaconda3-6\lib\site-packages\scanpy\__init__.py in <module>(); 1 # some technical stuff; 2 import sys; ----> 3 from .utils import check_versions, annotate_doc_types; 4 from ._version import get_versions # version generated by versioneer; 5 . ~\Anaconda3-6\lib\site-packages\scanpy\utils.py in <module>(); 17 from pandas.api.types import CategoricalDtype; 18 ; ---> 19 from ._settings import settings; 20 from . import logging as logg; 21 import warnings. ~\Anaconda3-6\lib\site-packages\scanpy\_settings.py in <module>(); 7 from typing import Tuple, Union, Any, List, Iterable, TextIO, Optional; 8 ; ----> 9 from . import logging; 10 from .logging import _set_log_level, _set_log_file, RootLogger; 11 . ~\Anaconda3-6\lib\site-packages\scanpy\logging.py in <module>(); 7 from typing import Optional; 8 ; ----> 9 import anndata.logging; 10 ; 11 . ~\Anaconda3-6\lib\site-packages\anndata\__init__.py in <module>(); ----> 1 from .core.anndata import AnnData, Raw; 2 from .readwrite import (; 3 read_h5ad, read_loom, read_hdf,; 4 read_excel, read_umi_tools,; 5 read_csv, read_text, read_mtx,. ~\Anaconda3-6\lib\site-packages\anndata\core\anndata.py in <module>(); 46 LayersBase, Layers; 47 ); ---> 48 from .. import h5py; 49 from .views import ArrayView, SparseCSRView, SparseCSCView, DictView, DataFrameView; 50 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\__init__.py in <module>(); 22 SparseDataset; 23 """"""; ---> 24 from .h5sparse import File, Group, SparseDataset, _load_h5_dataset_as_sparse; 25 from h5py import Dataset, special_dtype; 26 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\h5sparse.py in <module>(); 4 from typing import Optional, Union, KeysView, NamedTuple; 5 ; ----> 6 import h5py; 7 import numpy as np; 8 import scipy.sparse as ss. ~\Anaconda3-6\lib\site-packages\h5py\__init__.py in <module>(); 34 _errors.silen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/900:588,log,logging,588,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/900,5,['log'],"['logg', 'logging']"
Testability,ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_nor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:20388,test,tests,20388,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['test'],['tests']
Testability,ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot imp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:5986,test,tests,5986,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['test'],['tests']
Testability,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549#issuecomment-478933342:257,assert,assert,257,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478933342,3,"['assert', 'test']","['assert', 'testing']"
Testability,"In my opinion, we'll likely move away from logging everything. Isaac built this in so that one can conveniently visualize things in seaborn; I added the switch to turn it off so that the basic tutorial of v1.5 doesn't lead to a completely cluttered AnnData object. But, I guess, we all agree that this here isn't the final solution. 😄",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1226#issuecomment-630023263:43,log,logging,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1226#issuecomment-630023263,1,['log'],['logging']
Testability,"In my test, even we check `if isinstance(index, int) or isinstance(index, np.int64) or isinstance(index, np.int32):`, it still doesn't work on my 32-bit numpy and an _TypeErorr_ will be raised. Anyway, _isinstance(index, np.integer)_ works well and is a better choice.; Reference: [http://stackoverflow.com/questions/37726830/how-to-determine-if-a-number-is-any-type-of-int-core-or-numpy-signed-or-not](url)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/21:6,test,test,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/21,1,['test'],['test']
Testability,"In scanpy 1.10, the line referenced is:. * https://github.com/scverse/scanpy/blob/214e05bdc54df61c520dc563ab39b7780e6d3358/scanpy/preprocessing/_highly_variable_genes.py#L226. But in 1.9.8 the line is:. * https://github.com/scverse/scanpy/blob/6da39f128ecf78cf572f453ee2865d1b901715f3/scanpy/preprocessing/_highly_variable_genes.py#L226. So, to me it seems like the warning would require running an older version of the code. . Can you demonstrate that in a session where `sc.__version__ == ""1.10.0""` you get this warning and show that here? Something like:. ```python; import scanpy as sc; sc.pp.highly_variable_genes(sc.pp.pbmc3k_processed()); sc.logging.print_versions(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2967#issuecomment-2034397517:649,log,logging,649,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2967#issuecomment-2034397517,1,['log'],['logging']
Testability,"In some edge cases, the control gene selection retrieves the same gene(s) that are also in the gene_list used for scoring.; As a result, when the following line is called, we end up with an empty control gene set, causing the downstream error in #2153; https://github.com/scverse/scanpy/blob/383a61b2db0c45ba622f231f01d0e7546d99566b/scanpy/tools/_score_genes.py#L173. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2153 ; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2875:694,Test,Tests,694,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2875,1,['Test'],['Tests']
Testability,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not.; Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1446#issuecomment-1759598407:97,log,logFC,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446#issuecomment-1759598407,3,['log'],['logFC']
Testability,"In the scanpy documentation for sc.pl.dotplot, it indicates that it returns a list of matplotlib.axes.Axes. However, this is not true, it returns a gridspec object instead. I noticed this because I wanted to make some subtle edits to the results to enhance the figure such as changing axis labels, adding overlapping lines to delineate the marker genes for each cell type, etc. But I am struggling to do so. I am wondering how the API intends for us to interact with the gridspec object returned to modify the figure. If I edit the code to return the figure object as well as the gridspec, I can access the axis like so. ```; ax = fig.add_subplot(gs[1,0]); ```. but I can't seem to overwrite the default axis labels or add new lines as commands like; ```; ax.set_ylabel('new label'); ```. Don't change the figure at all. This is all Scanpy 1.4.5.post1 but it was the same for 1.4.4.post1. Thanks!. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.17.2 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. but the same things happened with scanpy==1.4.4.post1; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/979:936,log,logging,936,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/979,1,['log'],['logging']
Testability,In the tests that I have the heatmap seems to be ok. See https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Visualize-marker-genes-using-heatmap. Do you think that the problem occurs when lot of cells/genes are plotted?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/637#issuecomment-517276810:7,test,tests,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-517276810,1,['test'],['tests']
Testability,Incorrect names on logistic regression gene ranking plot,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/209:19,log,logistic,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/209,1,['log'],['logistic']
Testability,Indeed the tests have been modified and now `testing.setup` is being used. Thanks for the tip. You can close this issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-453920643:11,test,tests,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-453920643,2,['test'],"['testing', 'tests']"
Testability,"Indeed, ~3-7x faster for me & of course quite a bit more memory efficient (quickly checked with scalene). Tests keep working (for `seurat_v3`/`seurat_v3_paper` somewhat tight numeric comparison with Seurat results), nice.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3017#issuecomment-2122484190:106,Test,Tests,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017#issuecomment-2122484190,1,['Test'],['Tests']
Testability,Install packages necessary to run distributed tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/485:46,test,tests,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/485,1,['test'],['tests']
Testability,"Interesting ideas. I actually didn't notice scanpy has no logging implemented - this would indeed be useful and could already solve half the problem indeed. However, I doubt the best way to go about this would be post hoc with decorators etc, but rather intrinsically throughout the various API functions. Regardless of logging, I still think that having something which is intrinsically attached to the object would have the advantage of knowing the exact set of operations solely from the h5ad file/AnnData object itself. Don't know if people are actually out there are also sharing these or not but it could be useful from that perspective too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/472#issuecomment-464492356:58,log,logging,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464492356,2,['log'],['logging']
Testability,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>; <summary> me trying </summary>. ```python; isaac@Mimir:~/tmp/genomic-features-docs; $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy; [ ... ]; isaac@Mimir:~/tmp/genomic-features-docs; $ conda activate test-2978 ; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help.; [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""); Out[4]: <Version('0.9.0')>. In [5]: quit(); (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ pip install -U anndata; Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0); Collecting anndata; Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB); [ ... ]; Downloading anndata-0.10.6-py3-none-any.whl (122 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00; Downloading array_api_compat-1.6-py3-none-any.whl (36 kB); Installing collected packages: array-api-compat, anndata; Attempting uninstall: anndata; Found existing installation: anndata 0.9.0; Uninstalling anndata-0.9.0:; Successfully uninstalled anndata-0.9.0; Successfully installed anndata-0.10.6 array-api-compat-1.6; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ conda list | grep anndata; anndata 0.10.6 pypi_0 pypi; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""); Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757:203,test,test-,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757,5,['test'],['test-']
Testability,"Introduces a function to calculate marker gene overlaps between a reference set of marker genes provided as a dictionary, and data-derived marker genes as calculated by `sc.tl.rank_genes_groups()`. Currently implemented overlap functions are: overlap counts (with row or column normalization), overlap coefficient, and jaccard index. Still to do:; - write a test; - finish documentation; - allow p-value thresholding when available; - allow using top X marker genes rather than all calculated markers; - test that it works properly...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549:358,test,test,358,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549,2,['test'],['test']
Testability,"Is because we changed dot edge the defaults shortly before the release. Time to add a test for this. I will make a fix but meanwhile you can trigger the dynamic coloring by setting `dot_edge_color` and `dot_edge_lw` as `None`:. ```PYTHON; sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True)\; .style(color_on='square', dot_edge_color=None, dot_edge_lw=None).show(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1210#issuecomment-682371282:86,test,test,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210#issuecomment-682371282,1,['test'],['test']
Testability,"Is it generally a good idea to output P-values for marker gene identification? As the null model is not valid for this setup, P-values are not really a measure of significance, but should only serve to order genes. I can see the point of outputting log fold changes, but outputting P-values may be misleading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-425353186:249,log,log,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-425353186,1,['log'],['log']
Testability,Is it possible to test for bimodality in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1086:18,test,test,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1086,1,['test'],['test']
Testability,"Is that in embedding? I had thought we'd removed all that. There shouldn't be any special meaning to strings starting with `X_` anyways, it's just a convention. I'd like to give this a review, but I'd need to see that tests are passing. Do you know why travis isn't running on this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-600684687:218,test,tests,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-600684687,1,['test'],['tests']
Testability,"Is there a way to test if particular genes of a single-cell-RNA-seq-dataset show bimodal distributions, in order to infer heterogeneity? ; e.g. like in: https://www.nature.com/articles/nature13437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1086:18,test,test,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1086,1,['test'],['test']
Testability,"Is there anybody meeting the same error with me?; I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python; test_sf = de.test.wald(; data=adata.layers['counts'],; formula_loc=""~ 1 + disease + size_factors"",; factor_loc_totest=""disease"",; as_numeric=['size_factors'],; gene_names=adata.var_names,; sample_description=adata.obs; ); ```. ```pytb; error: 'i' format requires -2147483648 <= number <= 2147483647; ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1874:60,test,test,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874,2,['test'],['test']
Testability,"It appears that in the cell ranger code, the dispersion is calculated using the negative binomial relationship between mean and dispersion, see. https://github.com/10XGenomics/cellranger/blob/5f5a6293bbc067e1965e50f0277286914b96c908/lib/python/cellranger/analysis/stats.py#L44. Furthermore, these summary statistics are calculated on the count matrix normalized by library size, but not log-transformed. https://github.com/10XGenomics/cellranger/blob/5f5a6293bbc067e1965e50f0277286914b96c908/lib/python/cellranger/analysis/pca.py#L91-L95. As a follow-up, the ""Seurat"" flavor seems to be no longer used in Seurat. Any plans to implement their ""vst"" method?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/969:387,log,log-transformed,387,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/969,1,['log'],['log-transformed']
Testability,"It doesn't look like I can make the install process a matrix expansion, so this only tests against one version of python for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1005:85,test,tests,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1005,1,['test'],['tests']
Testability,"It doesn't matter for the topic of this discussion indeed. I reckon line 201 is the cause. If you want to solve this as scipy does, you will probably have to test for 0 variance and then assign a `-Inf` score, which defaults to a p-value of 0. I wonder if you get spurious marker gene results then though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/620#issuecomment-486600972:158,test,test,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620#issuecomment-486600972,1,['test'],['test']
Testability,"It happened many times on centos os I am using and I have been pulling at my hair. Finally what solved my issue is reinstalling traitlets to 5.9.0, which is apparently critical to operations in jupyter notebook. Reading the output logs of the crashed sessions really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2359#issuecomment-1551035497:231,log,logs,231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1551035497,1,['log'],['logs']
Testability,"It is now possible to have several neighbors graphs in adata. For example,. ```py; sc.pp.neighbors(adata); sc.pp.neighbors(adata, use_rep='some', key_added='test'); sc.pp.neighbors(adata, use_rep='some1', key_added='test1'); sc.pp.neighbors(adata, key_added='test2'). sc.tl.umap(adata, neighbors_key='test'); sc.tl.diffmap(adata, neighbors_key='test1'); ```. and so on.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1118:157,test,test,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1118,2,['test'],['test']
Testability,"It is said that ""Be reminded that it is not advised to use the corrected data matrices for differential expression testing."" in scanpy document (http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.mnn_correct.html) when execute MNN correction. However, Haghverdi Laleh (the one who presents MNN correction strategy, https://www.nature.com/articles/nbt.4091) says ""MNN correction improves differential expression analyses, After batch correction is performed, the corrected expression values can be used in routine downstream analyses such as clustering prior to differential gene expression identification"" in his Nature Biotech paper. So, I am a little confused. We have compared some corrections methods, such as regress_out, combat, MNN and MultiCCA (used by seurat), the results show that MNN and CCA have a better effect than regress_out and combat.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/168#issuecomment-395615173:115,test,testing,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168#issuecomment-395615173,1,['test'],['testing']
Testability,"It is working fine for me and is part of the testing. Which version do you; have? maybe you need to use `n_panels_per_row`. On Thu, Dec 6, 2018 at 3:55 AM Alex Wolf <notifications@github.com> wrote:. > Hm, the code; > <https://github.com/theislab/scanpy/blob/21adc0c9a31fb1eebb16579aa4f41700bc939aa2/scanpy/plotting/tools/__init__.py#L180-L188>; > for this looks fine: do you have less than 5 groups?; >; > n_panels_x = min(n_panels_per_row, len(group_names)); >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/389#issuecomment-444730523>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1du-PES9h_EXgZVonUcbuvlvFKdWks5u2IcsgaJpZM4ZCXJs>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/389#issuecomment-444820105:45,test,testing,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/389#issuecomment-444820105,1,['test'],['testing']
Testability,It looks like all of the tests that failed have to do with ingest functionality and are thus unrelated to this PR. The same ones failed on the PR after this one as well. Let me know what I can do to fix this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-955073297:25,test,tests,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-955073297,1,['test'],['tests']
Testability,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018:24,Assert,AssertionError,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018,2,"['Assert', 'test']","['AssertionError', 'tests']"
Testability,"It looks like the underlying issue (`np.zeros` was being called with a heterogeneous `shape` tuple) has been marked to be resolved in the next numba release. We could implement a workaround here where we force the dtype, though numba does have a pretty fast release cadence. @fkoegel, if we implemented a fix here would you be able to test it for us on master branches?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/843#issuecomment-532086499:335,test,test,335,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843#issuecomment-532086499,1,['test'],['test']
Testability,"It looks like those warning are being raised from `scipy.stats.distributions.t.sf`. . This was also happening in the tests, but there's already a bunch of warnings in the tests so we didn't see it. ~~I believe we didn't get this warning from the older code because of these lines:~~. ```python; dof[np.isnan(dof)] = 0		; pvals = stats.t.sf(abs(scores), dof)*2 # *2 because of two-tailed t-test; ```. I don't think it's the above lines anymore, since the replacing the `ttest_ind_from_stats` call with the following still throws the warning:. ```python; df, denom = stats.stats._unequal_var_ttest_denom(; v1=var_group, n1=ns_group, v2=var_rest, n2=ns_rest; ); df[np.isnan(df)] = 0; scores, pvals = stats.stats._ttest_ind_from_stats(; mean_group, mean_rest, denom, df; ); ```. Other than that, potential solutions include:. * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them); * Revert change (would bring back issue of genes with variance of 0); * Wrap the t-test with something like `np.errstate` to hide the warning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/629#issuecomment-488907170:117,test,tests,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-488907170,4,['test'],"['test', 'tests']"
Testability,"It makes sense to use AND logic, because the function keeps genes that satisfy all three conditions. ; 1) Fraction of cells inside the cluster expressing the gene must be greater than `min_in_group_fraction`; 2) Fractions of cells outside the cluster expressing the gene must be less than `max_out_group_fraction`; 3) Fold change must be greater than `min_fold_change`. But there are remaining issues (calculation of fold change and using the absolute value of the fold change) in this function that needs to be updated #863",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1213#issuecomment-629970781:26,log,logic,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213#issuecomment-629970781,1,['log'],['logic']
Testability,It seems like I run into segfaults with the csc implementation. I could not reproduce these with on my PC. I run the tests a lot of times. Since the csr-kernel seems to be working and csr is anyway better for row-based subsets I would propose that we transform the `csc` into a `csr` and than return that for `mask_obs`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2015068347:117,test,tests,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2015068347,1,['test'],['tests']
Testability,"It seems to be a stalled build in CI. Something to do with a URL request... if the tests run through on your end, everything should be fine. Do they?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/343#issuecomment-436045072:83,test,tests,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/343#issuecomment-436045072,1,['test'],['tests']
Testability,"It should definitely run through with these resources, and I and many other people ran it already. @Koncopd, could you check whether everything behaves still normally? I don't know how we can test this, but I also can't see who we might have broken it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/511#issuecomment-469641352:192,test,test,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-469641352,1,['test'],['test']
Testability,It started to go wrong with ff26149 and all I changed there was that I moved the `if inplace:` statement up to the user tests instead of down to where the outputs were written. Is python 3.5 somehow sensitive to whitespace after if statements? I found a whitespace after the `if inplace: `... maybe that's it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549#issuecomment-478395193:120,test,tests,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478395193,1,['test'],['tests']
Testability,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/787#issuecomment-532125401:141,test,tests,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787#issuecomment-532125401,1,['test'],['tests']
Testability,"It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1919:133,test,tested,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919,2,['test'],"['tested', 'testing']"
Testability,"It would've succeeded anyways, it just wasn't testing the right thing",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/494#issuecomment-465924110:46,test,testing,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/494#issuecomment-465924110,1,['test'],['testing']
Testability,"It'd be great have a test for this to catch such bugs next time, like checking the range of the scores.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1335#issuecomment-665417204:21,test,test,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335#issuecomment-665417204,1,['test'],['test']
Testability,"It'll take a little doing, but it's certainly do-able. Something like this should do it:. ```python; import numpy as np; from functools import reduce. def concat(arrays: ""list[np.recarray]""):; names = arrays[0].dtype.names; dtypes = [dict(a.dtype.descr) for a in arrays]; assert all(arrays[0].dtype.names == a.dtype.names for a in arrays[1:]), ""All arrays should have same names""; ; offset = 0; out_dtypes = {}; for k in names:; out_dtype = reduce(np.result_type, (dtype[k] for dtype in dtypes)); out_dtypes[k] = (out_dtype, offset); offset += out_dtype.alignment. out_recarray = np.recarray(sum(map(len, arrays)), dtype=out_dtypes) ; np.concatenate(arrays, out=out_recarray); ; return out_recarray; ```. Maybe the solution should happen upstream though. . Do we concatenate recarrays often?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/753#issuecomment-522930652:272,assert,assert,272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753#issuecomment-522930652,1,['assert'],['assert']
Testability,"It's a hard to be sure without a reproducible example (e.g., we'd need to be able to make an `AnnData` object that could trigger this issue), but I suspect some categories in your batch and covariates are completely confounded. Here's an example that would also trigger this:. ```python; import scanpy as sc; import pandas as pd. blobs = sc.datasets.blobs(); blobs.obs[""blobs""] = pd.Categorical(blobs.obs[""blobs""]); blobs.obs[""cov""] = pd.Categorical(blobs.obs[""blobs""] == ""0""). sc.pp.combat(blobs, ""blobs"", covariates=[""cov""]); # LinAlgError: Singular matrix; ```. <details>; <summary> Full traceback </summary>. ```pytb; ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <ipython-input-13-5685c001369c> in <module>; ----> 1 sc.pp.combat(blobs, ""blobs"", covariates=[""cov""]). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 204 # standardize across genes using a pooled variance estimator; 205 logg.info(""Standardizing Data across genes.\n""); --> 206 s_data, design, var_pooled, stand_mean = _standardize_data(model, data, key); 207 ; 208 # fitting the parameters on the standardized data. ~/github/scanpy/scanpy/preprocessing/_combat.py in _standardize_data(model, data, batch_key); 102 ; 103 # compute pooled variance estimator; --> 104 B_hat = np.dot(np.dot(la.inv(np.dot(design.T, design)), design.T), data.T); 105 grand_mean = np.dot((n_batches / n_array).T, B_hat[:n_batch, :]); 106 var_pooled = (data - np.dot(design, B_hat).T) ** 2. <__array_function__ internals> in inv(*args, **kwargs). /usr/local/lib/python3.8/site-packages/numpy/linalg/linalg.py in inv(a); 544 signature = 'D->D' if isComplexType(t) else 'd->d'; 545 extobj = get_linalg_error_extobj(_raise_linalgerror_singular); --> 546 ainv = _umath_linalg.inv(a, signature=signature, extobj=extobj); 547 return wrap(ainv.astype(result_t, copy=False)); 548 . /usr/local/lib/python3.8/site-packages/numpy/linalg/linalg.p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1606#issuecomment-766480303:1011,log,logg,1011,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606#issuecomment-766480303,1,['log'],['logg']
Testability,It's convenient to be able to specify multiple variables in combat in the R package. So I added the support for extra covariates (categorical or numeric) and converted some methods to private. There are tests for the new covariate option and also the private _design_matrix function now.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/618:203,test,tests,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/618,1,['test'],['tests']
Testability,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1469#issuecomment-725916572:566,log,log,566,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469#issuecomment-725916572,1,['log'],['log']
Testability,It's not clear to me why these `test_10x` tests are failing here and not on master -- there shouldn't be anything in this diff that affects those tests.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1003#issuecomment-577253898:42,test,tests,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1003#issuecomment-577253898,2,['test'],['tests']
Testability,"Its an issue with numba. See here https://github.com/jmschrei/apricot/blob/98693788ca315ceceeb2eb0f4ce8526f40e0049b/README.md. *Update* Quoting from the REAME above. > If you get an error that looks like; > ; > Inconsistency detected by ld.so: dl-version.c: 224: _dl_check_map_versions: Assertion `needed != NULL' failed!; > ; > or a segmentation fault when importing apricot for the first time then you should try reinstalling numba through conda using; > ; > conda install numba.; > ; > or; > ; > pip install numba==0.39.0; > ; > The issue appears to be with the most recent verson of numba, v0.40.0. Downgrading to numba v0.39.0 should solve the issue. ; > . That means numba should be frozen to v0.39.0 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-427364460:287,Assert,Assertion,287,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-427364460,1,['Assert'],['Assertion']
Testability,It’s 3 separate unit tests in a trenchcoat. I’m only not going with `pytest.mark.parametrize` since #3263 and #3267 are making things more complicated and might cause a split anyway. The PCA code is too branched for these tests to be helpful with debugging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3268:21,test,tests,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3268,2,['test'],['tests']
Testability,"It’s both bullshit that that numpy/numpy#2776 is unfixed since 2012 and Python doesn’t have instance checks for collections without testing for all the mixed-in methods. What we mostly want to test for is if something is iterable and/or indexable. For “sized iterable”, this is possible via `isinstance(x, cabc.Collection)`, but everything more complex has all those mixin methods that are checked for …. At least what we have now is better than `isinstance(x, list)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/839#issuecomment-531701000:132,test,testing,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839#issuecomment-531701000,2,['test'],"['test', 'testing']"
Testability,"It’s connected because the paga tests don’t `copy` the objects and therefore run sequentially, but I can extract it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1598722003:32,test,tests,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1598722003,1,['test'],['tests']
Testability,"It’s needed when you modify the `AnnData` object afterwards. The above slices it twice, and only then copies it, because slicing isn’t a modification. So what’s happening is:. ```py; adata_orig = AnnData(...). adata_sliced_view = adata_orig[..., :]; assert adata_sliced_view.is_view; adata_sliced_copy = adata_sliced_view[..., :].copy(); assert not adata_sliced_copy.is_view. do_modify(adata_sliced_copy); ```. The slicing could also have been done in one operation. ```py; adata = adata_orig[(adata.obs[""n_genes_by_count""] < 2500) & (adata.obs[""pct_counts_mt""] < 5), :].copy(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3073#issuecomment-2180456998:250,assert,assert,250,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073#issuecomment-2180456998,2,['assert'],['assert']
Testability,It’s using `__orig_doc__` so the line should be correct. `assert lines[0]` just asserts that the first line is non-empty. `any(broken)` checks if there’s under-indented lines.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1492#issuecomment-726004959:58,assert,assert,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492#issuecomment-726004959,2,['assert'],"['assert', 'asserts']"
Testability,"I’d advise to use the R package. The score is still off and I didn’t figure out why. Sorry. /edit: it works now. I’d like to have a good toy example for the tests that actually has a batch effect, then I’d merge this",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/364#issuecomment-453448469:157,test,tests,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/364#issuecomment-453448469,1,['test'],['tests']
Testability,"I’d classify the kinds of selections we make into. - recipe/algorithm/statistical test/…; - backend/implementation package/…. Of course there’s overlap, but I think that’s broadly it. Currently, we have the following. - `flavor`. - [`sc.pp.highly_variable_genes`](https://scanpy.readthedocs.io/en/latest/generated/scanpy.pp.highly_variable_genes.html): choose algorithm/recipe (seurat, seurat_v3, cell_ranger); - [`sc.tl.louvain`](https://scanpy.readthedocs.io/en/latest/generated/scanpy.tl.louvain.html): choose implementation package (vtraag’s louvain package, igraph, rapids). - `method`. - [`sc.pp.neighbors`](https://scanpy.readthedocs.io/en/latest/api/generated/scanpy.pp.neighbors.html): choose algorithm to calculate connectivity (gauss or umap). kNN impl is `transformer`; - [`sc.tl.umap`](https://scanpy.readthedocs.io/en/latest/generated/scanpy.tl.umap.html): choose implementation package (umap or rapids). > **Note**; > should probably be changed. - [`sc.tl.rank_genes_groups`](https://scanpy.readthedocs.io/en/latest/generated/scanpy.tl.rank_genes_groups.html): choose differential expression test (t-test, wilcoxon test, …) (also has `corr_method` for p-value correction); - [`sc.tl.marker_gene_overlap`](https://scanpy.readthedocs.io/en/latest/generated/scanpy.tl.marker_gene_overlap.html): choose how to determine overlap (overlap_count, overlap_coef, jaccard). - `backend`: _nowhere_; - `algorithm`: _nowhere_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2828:82,test,test,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2828,4,['test'],['test']
Testability,"I’m doing all the tests @ivirshup proposed. If my explanations to the questions I left open are sufficient, I’ll merge this! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/676#issuecomment-498701054:18,test,tests,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-498701054,1,['test'],['tests']
Testability,"I’m not a fan of duplicating things. We already install optional requirements via the list of extras here:. https://github.com/theislab/scanpy/blob/f428848ece1d7a4794090eb70a34a3b8f1953dee/.travis.yml#L8. so we should simply add them to the `test` extra:. https://github.com/theislab/scanpy/blob/f428848ece1d7a4794090eb70a34a3b8f1953dee/setup.py#L35. or add more extras (e.g. `dask=['dask[array]'],`) and add them to the list of extras to be installed in .travis.yml",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/439#issuecomment-457915041:242,test,test,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-457915041,1,['test'],['test']
Testability,"I’m talking about unit test. please add one here. You can just add one or more parameter sets to the list, and the test will create a file at `scanpy/tests/figures/master_{id}.png`.; Just copy that file to `scanpy/tests/_images/` and commit it together with the added test. https://github.com/scverse/scanpy/blob/9c6996f374370a7d50768c634e76e50173d22839/scanpy/tests/test_plotting.py#L973-L1082. if you need help, please tell us!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929:23,test,test,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929,6,['test'],"['test', 'tests']"
Testability,Just a follow up here. I found the code from the Zheng et al. paper:. It appears they do calculate dispersion as var/mean but on the library size normalized counts (not log). https://github.com/10XGenomics/single-cell-3prime-paper/blob/265433ebf858c7fdcab759ca9f36b5e0241ceece/pbmc68k_analysis/util.R#L122-L135,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/969#issuecomment-629667682:169,log,log,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/969#issuecomment-629667682,1,['log'],['log']
Testability,"Just a heads up, I would like to run a few benchmarks on this before merging.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/844#issuecomment-532173941:43,benchmark,benchmarks,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844#issuecomment-532173941,1,['benchmark'],['benchmarks']
Testability,"Just a heads up, it looks like Pandas 1.3.3 might break things again, was experiencing errors that I was able to resolve by downgrading. I can create a new issue if you'd like. Error below so you can determine if this is the same issue or not:; ```; adata.obs['log_counts'] = np.log(adata.obs['n_counts']); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py"", line 3612, in __setitem__; self._set_item(key, value); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py"", line 3784, in _set_item; value = self._sanitize_column(value); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py"", line 4509, in _sanitize_column; com.require_length_match(value, self.index); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/common.py"", line 531, in require_length_match; raise ValueError(; ValueError: Length of values (1) does not match length of index (38978); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1918#issuecomment-925478453:279,log,log,279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1918#issuecomment-925478453,1,['log'],['log']
Testability,"Just a quick comment... Benjamini-Hochberg correction is usually the standard for multiple-testing correction in differential expression testing. Not sure if you want to take it into account, but I thought I should mention it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-428010274:91,test,testing,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-428010274,2,['test'],['testing']
Testability,"Just added a test and changed the behaviour of scale a little more.; The case of zero variance was until now replace with an arbitrary tiny variance, which arbitrarily blew up the scaled value and made it completely meaningless `scale[scale == 0] = 1e-12`.; Now I put instead `scale[scale == 0] = 1`. This yields the same result for `zero_center == True`: all values set to `0`, anyway (but with less arbitrary magic numbers and maybe less rounding errors). But if `zero_zenter == False`, unscalable values are untouched. This only affected the dense codepath where zero-centering was done afterwards anyway due to the original bug. Therefore this is no code breaking change.; But I also moved this statement before the sparse check to have consistent handling of sparse and dense data. Before that the sparse path wrote infs in the values (unchecked divison by zero) - this is a potentially code breaking change, but it only leads to the behaviour already stated in the documentation. I personally think that code relying on this undocumented behaviour should be rewritten, anyway...; In the new test I explicitly check for this behaviour to make it well defined.; Similar for integer datatypes (resulted in an error), they are now converted to floating point for scaling and return a copy. BTW: In order to make the tests run in my conda environment, I had to remove every reference to compare_images from matplotlib.testing.compare. There seems to be a version conflict in the version checking... It always gave errors like the following:; `________________ ERROR collecting scanpy/tests/test_plotting.py ________________; scanpy/tests/test_plotting.py:16: in <module>; from matplotlib.testing.compare import compare_images; ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:240: in <module>; _update_converter(); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:222: in _update_converter; mpl._get_executable_info(""gs""); ~/.conda/envs/cus",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330:13,test,test,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330,1,['test'],['test']
Testability,Just changed the argument a little and added a test. Will be out soon!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1821#issuecomment-1084806101:47,test,test,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821#issuecomment-1084806101,1,['test'],['test']
Testability,"Just checked on this example; ```; adata = sc.AnnData(np.array([[1, 2],[-1, 2]])); adata.write_loom('test.loom'); adata = sc.read('test.loom', sparse=True); ```; and it looks fine, with retaining the negative value, for both sparse and non-sparse read-in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/712#issuecomment-505890739:101,test,test,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/712#issuecomment-505890739,2,['test'],['test']
Testability,"Just checked using this dockerfile, works flawlessly:. ```dockerfile; FROM continuumio/miniconda. RUN conda install python=3.8; RUN pip install flit>=3.1; RUN git clone https://github.com/theislab/scanpy.git; WORKDIR /scanpy; # Go to the mainline-pip branch if it hasn’t been merged into master yet; RUN git checkout mainline-pip || true; RUN FLIT_ROOT_INSTALL=1 flit install -s --dep=develop # Make development install of scanpy; # Make sure the dist-info folder has a plus in its name; RUN SCANPY_VERSION=$(python -c 'from importlib.metadata import version; print(version(""scanpy""))') && \; echo $SCANPY_VERSION | grep '+' &&; test -d /opt/conda/lib/python3.8/site-packages/scanpy-$SCANPY_VERSION.dist-info; # Install project that depends on scanpy; RUN pip install scvelo; # Make sure it’s still a dev install; RUN test -L /opt/conda/lib/python3.8/site-packages/scanpy; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1702#issuecomment-788200617:629,test,test,629,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702#issuecomment-788200617,2,['test'],['test']
Testability,"Just load any data, e.g. pbmc3k, then do `sc.pp.calculate_qc_metrics(adata, percent_top=[])` which gives the following: (this is on v1.3.7, haven't tested on earlier versions). ```; In [5]: sc.pp.calculate_qc_metrics(adata, percent_top=[]) ; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-385-66af52bcd3f3> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata, percent_top=[]). ~/miniconda2/envs/py3/lib/python3.6/site-packages/scanpy/preprocessing/qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, inplace); 70 obs_metrics[""log1p_total_{expr_type}""] = np.log1p(; 71 obs_metrics[""total_{expr_type}""]); ---> 72 proportions = top_segment_proportions(X, percent_top); 73 # Since there are local loop variables, formatting must occur in their scope; 74 # Probably worth looking into a python3.5 compatable way to make this better. ~/miniconda2/envs/py3/lib/python3.6/site-packages/scanpy/preprocessing/qc.py in top_segment_proportions(mtx, ns); 182 if not isspmatrix_csr(mtx):; 183 mtx = csr_matrix(mtx); --> 184 return top_segment_proportions_sparse_csr(mtx.data, mtx.indptr, ns); 185 else:; 186 return top_segment_proportions_dense(mtx, ns). IndexError: index -1 is out of bounds for axis 0 with size 0; ```. Not sure if there are other impacts, but I think perhaps basically one just need to check `percent_top` before calling `top_segment_proportions()` at line 72.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/421#issuecomment-453896450:148,test,tested,148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421#issuecomment-453896450,1,['test'],['tested']
Testability,"Just my 2cents: ; I made really good experiences with Github actions.; * I find them easy to set-up and they run many (20-40?) jobs in parallel. ; * Really good integration with Github (e.g. upload to PyPI on release) ; * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1358#issuecomment-674834154:230,test,testing,230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358#issuecomment-674834154,3,['test'],"['test', 'testing']"
Testability,"Just opened a PR to fix this. Quoting from the PR (#1069):. > Note that if you wish to modify the figure in the same jupyter notebook cell in which the plotting function is called, you should set show=False:. ```; fig,ax = sc.pl.dotplot(adata,var_names,show=False); ax.set_xlabel('test'); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/979#issuecomment-589863225:281,test,test,281,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/979#issuecomment-589863225,1,['test'],['test']
Testability,"Just re run it, [tests passed](https://travis-ci.org/github/theislab/scanpy/builds/663089197?utm_medium=notification&utm_source=github_status); No sure why it does not appear on github",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-600685036:17,test,tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-600685036,1,['test'],['tests']
Testability,"Just tested, works perfectly with the main command. Brilliant job @flying-sheep!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/281#issuecomment-484503926:5,test,tested,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281#issuecomment-484503926,1,['test'],['tested']
Testability,"Just took a look at pbmc3k, your logging still has fractions of a second in there. This logging does not capture times with that accuracy anymore. I tried updating `datetime` in case that's secretly responsible, as you seem to use it internally for time tracking. It was not secretly responsible, the timing discrepancy and lack of deep persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/746#issuecomment-514115289:33,log,logging,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/746#issuecomment-514115289,2,['log'],['logging']
Testability,Just wanted to bring this question back up - it would be great if we could get fold changes and p-values returned from the relevant methods for differential testing in scanpy. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-420329092:157,test,testing,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-420329092,1,['test'],['testing']
Testability,"Kinda related, I was about to open an issue on the memory usage of this function. The current implementation can double the memory usage of a program, I believe due to intermediate arrays in the current code. I'd come up with a slower but fewer allocation method for dense arrays (which could probably be sped up with a little `numba`):. ```python; def lessalloc_dense(X):; mean = X.mean(axis=0); mean_sq = np.apply_along_axis(lambda x: np.square(x).mean(), 0, X); var = (mean_sq - mean**2) * ((X.shape[0]/(X.shape[0]-1))); return mean, var; ```. And looked at memory usage using [`memory_profiler`](https://github.com/pythonprofilers/memory_profiler/releases), including @fidelram 's method:. ![mean_var_memory](https://user-images.githubusercontent.com/8238804/40597918-eacd8764-6287-11e8-98ff-017e697b350d.png). [Full script for benchmark here.](https://gist.github.com/ivirshup/a6facfa1ace5b356ea2d18ff3ffe0cb9)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/163#issuecomment-392421567:832,benchmark,benchmark,832,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163#issuecomment-392421567,1,['benchmark'],['benchmark']
Testability,LED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_violin_without_raw - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_path - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[pca] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[spatial] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_dimension_broadcasting - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_marker_broadcasting - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:45428,test,tests,45428,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,LED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plottin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49943,test,tests,49943,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,LED scanpy/tests/test_plotting.py::test_scatterplots[pca_multiple_markers_multiple_colors-fn7] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_marker_with_dimensions-fn8] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[3dprojection-fn2] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap-fn14] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_markers_with_dimensions-fn9] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_one_marker-fn5] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca-fn0] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_with_fonts-fn1] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_markers_colors_with_dimensions-fn10] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class ',MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:53491,test,tests,53491,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,LED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::te,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2387,test,tests,2387,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['test'],['tests']
Testability,"LGTM! . Don't worry about the test failures, those are due to a networkx update changing how plots look, which we'll deal with.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1950#issuecomment-887218018:30,test,test,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1950#issuecomment-887218018,1,['test'],['test']
Testability,"Let me check if dot sizes work now. Also, I still have another function I would like to add, which probably requires less work. Just some marker gene overlap test that takes a dictionary as input. Could you give til next week Wednesday for that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/543#issuecomment-475592847:158,test,test,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-475592847,1,['test'],['test']
Testability,"Let's please test this thoroughly, I'm not sure about how stable fold change estimates are in base 2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/931#issuecomment-558659047:13,test,test,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/931#issuecomment-558659047,1,['test'],['test']
Testability,"Log PCA time at info level, like other steps in the pipeline (recipes…",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/623:0,Log,Log,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/623,1,['Log'],['Log']
Testability,Log2 fold changes in rank_genes_groups are calculated from log-transformed data,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517:59,log,log-transformed,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517,1,['log'],['log-transformed']
Testability,Logging cosmetics and link to spatial tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1206:0,Log,Logging,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1206,1,['Log'],['Logging']
Testability,Logging overhaul,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/676:0,Log,Logging,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676,1,['Log'],['Logging']
Testability,Logistic Regression in scRNA,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/95:0,Log,Logistic,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/95,1,['Log'],['Logistic']
Testability,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:47,test,tests,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166,3,['test'],"['test', 'tests']"
Testability,"Looks good! Remaining questions:. - The plan is to add the Visium reading function to `anndata`, right?; - You’re repeating yourself with the docs: `doc_scatter_basic` (and therefore `doc_scatter_embedding`) and the docstring of `pl.spatial` both contain similar text for the same parameters. If you want to reorder them, you could do something fancy (like slicing doc_scatter_embedding) or just mention the parameter names in the free text, something like:. ```restructuredtext; Scatter plot in spatial coordinates. Use the parameter `img_key` to see the microscopy image in the background.; Use `crop_coord`, `alpha_img`, and `bw` to control how it is displayed,; and `scale_spot` to control the size of the Visium spots plotted on top.; ```. - Is it possible to derive the amount of cropping? Then we could extend the `crop_coord` parameter to this:. ```py; Union[; Iterable[Literal['left', 'l', 'right', 'r', 'top', 't', 'bottom', 'b']],; Tuple[int, int, int, int], # l, r, t, b; ]; ```. - Maybe it makes sense to add some test data and a test plot? (very low res of course)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1012#issuecomment-578688703:1027,test,test,1027,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1012#issuecomment-578688703,2,['test'],['test']
Testability,"Looks great! I wasn't aware of this high-dimensional version of a t-test in Scipy, which seems to be as efficient as the current implementation. I only investigated thoroughly for Wilcoxon rank and found that Scipy doesn't have a scalable version to offer. But yes, this will get merged after 1.4.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/621#issuecomment-487019494:68,test,test,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/621#issuecomment-487019494,1,['test'],['test']
Testability,Looks great! Let's wait for the tests to complete and merge!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/539#issuecomment-474326729:32,test,tests,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539#issuecomment-474326729,1,['test'],['tests']
Testability,"Looks great! Optimally we’d add a test image like the bottom one in https://github.com/theislab/scanpy/pull/794#issuecomment-523515331, but I’d be up for merging this as-is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/794#issuecomment-524364576:34,test,test,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794#issuecomment-524364576,1,['test'],['test']
Testability,Looks like the tests passed! @fidelram,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1432#issuecomment-700952241:15,test,tests,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432#issuecomment-700952241,1,['test'],['tests']
Testability,"Looks like this is not available for python yet ([docs](https://docs.microsoft.com/en-us/azure/devops/pipelines/test/codecoverage-for-pullrequests?view=azure-devops#prerequisites)). > While you can collect and publish code coverage results for many different languages using Azure Pipelines, the code coverage for pull requests feature discussed in this document is currently available only for .NET and .NET core projects using the Visual Studio code coverage results format (file extension .coverage). Support for other languages and coverage formats will be added in future milestones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1576#issuecomment-758366276:112,test,test,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1576#issuecomment-758366276,1,['test'],['test']
Testability,"Looks like this not working with `multi_panel` would be introduced by #1422. At the moment my matplotlib tests are being flaky, so I may have some trouble fixing this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2051#issuecomment-993445505:105,test,tests,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2051#issuecomment-993445505,1,['test'],['tests']
Testability,"Looks simple enough! Please deduplicate the tests though, they have too many identical lines.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3042#issuecomment-2092792623:44,test,tests,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042#issuecomment-2092792623,1,['test'],['tests']
Testability,"Looks very good to me, thank you very much!. Would you mind adding an option to select for the correction type that defaults to 'benjamini-hochberg' and can be set to 'bonferroni'?. In the best of all world's, you'd also extend the tests for rank_genes_groups so that the p values are tested and not messed up by pull requests in the future. We want people to get the same p values again and again. And as the whole module sort of involves a lot of custom code as the scipy alternatives are not there for mult-dimensional and sparse data, it's easy to mess this up in the future. Thank you so much for the awesome addition @a-munoz-rojas , I'll add you both to the Scanpy author list and to the release notes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-429445105:232,test,tests,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-429445105,2,['test'],"['tested', 'tests']"
Testability,"Louvain is being difficult to build since a new setuptools release dropped any python2 compatibility https://github.com/vtraag/louvain-igraph/issues/57. We've largely worked around this in #2063, by making louvain dependent tests optional. However, the paul15 PAGA test is difficult to extract louvian from. It checks hardcoded values based on the results of a louvain clustering. To adapt this test to use leiden, we would have to redo the tutorial and create new results. Or louvain building could be fixed, but the package is deprecated anyways.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2065:224,test,tests,224,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2065,3,['test'],"['test', 'tests']"
Testability,MAGIC in external causes test failures if its not installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1001:25,test,test,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001,1,['test'],['test']
Testability,Made the `.size` change and added a test. Not entirely sure I have done the test correctly so let me know if that needs adjusting.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2231#issuecomment-1118266184:36,test,test,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1118266184,2,['test'],['test']
Testability,Make external tests for MAGIC optional,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1003:14,test,tests,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1003,1,['test'],['tests']
Testability,Make harmonypy test optional,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1428:15,test,test,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1428,1,['test'],['test']
Testability,Make louvain optional for tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2063:26,test,tests,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063,1,['test'],['tests']
Testability,Makes sense that backwards compatibility has to take priority. Integer check will work for most cases (at least it checks if it's still count data). The only exception I can think of is for CPM/size factor normalized data where it would fail (although usually you'd do log-transformation after you normalize otherwise). I can't think of a better method atm either way.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/172#issuecomment-398761924:269,log,log-transformation,269,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/172#issuecomment-398761924,1,['log'],['log-transformation']
Testability,"Malte, don't you have `pytest` installed locally? Debugging using all these `added prints` etc. commits doesn't help maintain a clean git history. :wink:. Is it possible that there is any ambiguity regarding floating point precision? It's a bit hard for me to debug this. In case you don't have python 3.5 installed. Simply do `conda create -n py35 python=3.5`. Calling `pytest scanpy/tests/marker_gene_overlap.py` should rapidly reveal what's going on. Or simply debugging this in a notebook. Thank you and sorry that this causes trouble!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/583#issuecomment-479387950:385,test,tests,385,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-479387950,1,['test'],['tests']
Testability,"Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1090:52,test,tests,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090,1,['test'],['tests']
Testability,"Matplotlib 3.4 has dropped 3.6 support. Since matplotlib is our most painful dependency (reliably causes test failures when it updates), it's a great time to drop 3.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1697#issuecomment-809011473:105,test,test,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697#issuecomment-809011473,1,['test'],['test']
Testability,"Maybe fixes #1736, tested with #1735 and it seemed to do the trick. @flying-sheep, you're the most familiar with the logging setup. Any thoughts?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1737:19,test,tested,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1737,2,"['log', 'test']","['logging', 'tested']"
Testability,"Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=426) self.state.lifted = (); [428](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=427) self.state.lifted_from = None; --> [429](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=428) return self._compile_bytecode(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:497, in CompilerBase._compile_bytecode(self); [493](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=492) """"""; [494](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=493) Populate and run pipeline for bytecode input; [495](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=494) """"""; [496](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=495) assert self.state.func_ir is None; --> [497](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=496) return self._compile_core(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:476, in CompilerBase._compile_core(self); [474](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=473) self.state.status.fail_reason = e; [475](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=474) if is_final_pipeline:; --> [476](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=475) raise e; [477](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=476) else:; [478](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=477) raise CompilerError(""All available pipelines exhausted""). File D:\Users\xiang",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:20470,assert,assert,20470,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['assert'],['assert']
Testability,"Minimal example (scanpy commit: 7266e67fe15a6320bc6d5e1642479f53e44a6d6b):; ```python; import scanpy as sc; sc.logging.print_versions(); from pypairs import __version__; print('pypairs==', __version__). adata = sc.datasets.blobs(); marker_pairs = {'G1': [('1', '2')], 'S': [('3', '4')], 'G2M': [('5', '6')]}. sc.external.tl.cyclone(adata, marker_pairs, adata.var_names, adata.obs_names); ```. ```python; scanpy==0+unknown anndata==0.6.19 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; pypairs== v3.1.0. ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-20-33f7b7cad989> in <module>; 7 marker_pairs = {'G1': [('1', '2')], 'S': [('3', '4')], 'G2M': [('5', '6')]}; 8 ; ----> 9 sc.external.tl.cyclone(adata, marker_pairs, adata.var_names, adata.obs_names). ~/software/scanpy/scanpy/tools/_pypairs.py in cyclone(adata, marker_pairs, gene_names, sample_names, iterations, min_iter, min_pairs); 132 ; 133 from pypairs.pairs import cyclone; --> 134 from . import settings; 135 from pypairs import settings as pp_settings; 136 . ImportError: cannot import name 'settings'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/655:111,log,logging,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/655,1,['log'],['logging']
Testability,"Minimal example:; ```python; import scanpy.api as sc; sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata); ```; Output:; ```python; **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-11-5d93fbf298b7> in <module>; 4 adata = sc.datasets.blobs(); 5 ; ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace); 115 # a normalized disperion of 1; 116 one_gene_per_bin = disp_std_bin.isnull(); --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(); 118 if len(gen_indices) > 0:; 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key); 909 Please use .at[] or .iat[] accessors.; 910 ; --> 911 Parameters; 912 ----------; 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 -------; 952 series : Series; --> 953 If label is contained, will be reference to calling Series,; 954 otherwise a new object; 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4344 ; 4345 elif not is_list_like(value):; -> 4346 new_data = self._data.fillna(value=value, limit=limit,; 4347 inplace=inplace,; 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450:57,log,logging,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450,2,['log'],"['logg', 'logging']"
Testability,Minimum dependency test job,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816:19,test,test,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816,1,['test'],['test']
Testability,Minor Bug: scanpy.logging.print_versions() throws Key Error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2580:18,log,logging,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580,1,['log'],['logging']
Testability,"Mmh, very strange. Graph abstraction will be in the next Scanpy release and is not stable yet... Are you simply running the [minimal example](https://github.com/theislab/graph_abstraction/blob/master/minimal_examples/minimal_examples.ipynb)? Maybe reread and reload your data? At some point a few months ago, the format for AnnData files changed. Also, the master branch on Github doesn't have all tests on all notebooks yet, I'd recommend to wait until the release that is scheduled for the next week. Cheers,; alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/40#issuecomment-333528844:398,test,tests,398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40#issuecomment-333528844,1,['test'],['tests']
Testability,"More comprehensive test, similar to the current AnnData slicing tests (no use of external data). Each try/except block will (currently) fail on its last assertion. ```; import sys, traceback; import numpy as np; import scanpy.api as sc. adata = sc.AnnData(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])). # integer indexing; print(""\n>>> integer indexing, obs first""); try:; assert adata[0:2, :][:, 0:2].X.tolist() == [[1,2], [4,5]]; assert adata[0, 0].X.tolist() == 1; assert adata[0:1, 0:1].X.tolist() == 1; assert adata[0, :][:, 0].X.tolist() == 1. except Exception as e:; traceback.print_exc(file=sys.stdout). print(""\n>>> integer indexing, vars first""); try:; assert adata[:, 0:2][0:2, :].X.tolist() == [[1,2], [4,5]]; assert adata[0, 0].X.tolist() == 1; assert adata[0:1, 0:1].X.tolist() == 1; assert adata[:, 0][0, :].X.tolist() == 1. except Exception as e:; traceback.print_exc(file=sys.stdout). # boolean indexing; print(""\n>>> boolean indexing, obs first""); try:; obs_selector = np.zeros(len(adata.obs), dtype=bool); vars_selector = np.zeros(len(adata.var), dtype=bool). obs_selector[:] = [True, True, False]; vars_selector[:] = [True, True, False]; assert adata[obs_selector, :][:, vars_selector].X.tolist() == [[1,2], [4,5]]. obs_selector[:] = [True, False, False]; vars_selector[:] = [True, False, False]; assert adata[obs_selector, :][:, vars_selector].X.tolist() == 1. except Exception as e:; traceback.print_exc(file=sys.stdout). print(""\n>>> boolean indexing, vars first""); try:; obs_selector = np.zeros(len(adata.obs), dtype=bool); vars_selector = np.zeros(len(adata.var), dtype=bool). obs_selector[:] = [True, True, False]; vars_selector[:] = [True, True, False]; assert adata[:, vars_selector][obs_selector, :].X.tolist() == [[1,2], [4,5]]. obs_selector[:] = [True, False, False]; vars_selector[:] = [True, False, False]; assert adata[:, vars_selector][obs_selector, :].X.tolist() == 1. except Exception as e:; traceback.print_exc(file=sys.stdout); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/332#issuecomment-434005191:19,test,test,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332#issuecomment-434005191,15,"['assert', 'test']","['assert', 'assertion', 'test', 'tests']"
Testability,"Most of the time? There is an issue with fairly old CPUs (no AVX2, so like >5 years), but that was the last I saw. My guess is that there are more reproducibility issues on windows than linux, likely because it is tested less. I would like to confirm that it's UMAP and not the PCA though. After that could be worth checking the threading (e.g. reduce to one thread, though I thought UMAP should be as reproducible as possible w.r.t. threading by default).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016712689:214,test,tested,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016712689,1,['test'],['tested']
Testability,"Most things?. - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing; - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly!. They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090388986:150,test,testing,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090388986,4,['test'],"['test', 'testing', 'tests']"
Testability,Move adding `--internet-tests` option back to `conftest.py`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/685:24,test,tests,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/685,1,['test'],['tests']
Testability,Move to src / tests layout,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3092:14,test,tests,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3092,1,['test'],['tests']
Testability,My impression has been that doing the densifying scale transform didn't seem to show performance improvements in a number of benchmarks. This is also the workflow used in [sc-best-practices](https://www.sc-best-practices.org/preprocessing_visualization/normalization.html). @Zethson do you have a good citation for this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034405597:125,benchmark,benchmarks,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034405597,1,['benchmark'],['benchmarks']
Testability,"My point is: The paper suggests that the reason for the zero inflation idea might be the log-transform, so we should offer a better path from counts to distances. Our current path is to go via normally distributed “expression” values which can be used to calculate distances. Something like fold changes, i.e. what we currently do by log-transforming (because `log(count) = foldchange`):. > counts (→ normalization) → expressions (→ normalization) (→ embedding) → distances → analyses. We use PCA as a latent space embedding here for efficiency purposes but it’s not required, we could calculate distances directly from expressions.; One alternative is to stay with (possibly bias-normalized) counts, and create our latent space from those directly using a suitable model (like GLM-PCA):. > counts (→ normalization) → embedding → distances → analyses. The other alternative is to offer something like SCTransform and stay with our original path, bu better. ---. All of this is of course only super important if the log transform turns out to be maximally problematic (which the amount of successful data analyses using it doesn’t suggest), but I think offering alternatives will definitely be very beneficial!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-592503518:89,log,log-transform,89,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-592503518,4,['log'],"['log', 'log-transform', 'log-transforming']"
Testability,"My priority are intuitive semantics so people can add or bump dependencies without 100% understanding the algorithm of the minimum dependency script. So I can think of options:. 1. Each version must be fully specified (`>=1.2.0`, not `>=1.2`). The script installs exactly the specified minimum version. Implementation: Would be quickly done now, just check the job run and change `matplotlib>=3.6` to `matplotlib>=3.6.3` and so on. Effect: whenever we bump something, we probably need to bump more things, which might sometimes be painful. The minimum versions will be more accurate, as we know that the exact versions specified successfully run out test suite. 4. We maintain a list of all dependencies we have together with data about which version segment denotes the patch version (i.e. for semver it’s the third, for calendar ver, it’s nothing), then modify versions based on that knowledge (e.g. semver `>=1.2.3` → `>=1.2.3, <1.3`). Implementation: Each newly added dependency needs to be added to that list. Effect: This would be basically a more powerful (able to specify minimum patch) and obvious version of what you’re doing now (explicit data instead of the presence of a patch version indicating if something is semver or not). In both versions, there’s no hidden semantics in `>=1.2` that would distinguish it from `>=1.2.0`, which is what I’m after. What does your experience while implementing this so far say to these? Any other ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1943497240:650,test,test,650,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1943497240,1,['test'],['test']
Testability,"My questions from #929 don’t apply since you don’t use numba here. Except for “What's the performance difference here”:. It’s not too bad, but we should use base 2 for everything that isn’t the natural logarithm: log2 can be calculated much faster on regular hardware due to binary storage.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/931#issuecomment-558143591:202,log,logarithm,202,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/931#issuecomment-558143591,1,['log'],['logarithm']
Testability,"My thinking on this right now is that:. * The code for masking logic (pre this PR) is kind of a mess; * This PR doesn't make the code nicer. But the performance benefit is quite good, and for sure the operation `X[mask_obs, :] = scale_rv` is something we don't want to do with sparse matrices. I also think we could get even faster, plus a bit cleaner if we instead modified scale array to use something like what I suggest [here](https://github.com/scipy/scipy/issues/20169#issuecomment-1973335172) to accept a `row_mask` argument:. ```python; from scipy import sparse; import numpy as np; from operator import mul, truediv. def broadcast_csr_by_vec(X, vec, op, axis):; if axis == 0:; new_data = op(X.data, np.repeat(vec, np.diff(X.indptr))); elif axis == 1:; new_data = op(X.data, vec.take(X.indices, mode=""clip"")); return X._with_data(new_data); ```. Which *I think* would be something like:. ```python; def broadcast_csr_by_vec(X, vec, op, axis, row_mask: None | np.ndarray):; if row_mask is not None:; vec = np.where(row_mask, vec, 1); if axis == 0:; new_data = op(X.data, np.repeat(vec, np.diff(X.indptr))); elif axis == 1:; new_data = op(X.data, vec.take(X.indices, mode=""clip"")); return X._with_data(new_data); ```. Or, since we're doing numba already we could do just write out the operation with a check to see if we're on a masked row (which *should* be even faster since we're not allocating anything extra). I think either of these solutions would be simpler since we do the masking all in one place, and don't have to have a second update step.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2024951345:63,log,logic,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2024951345,1,['log'],['logic']
Testability,"NaN is a special floating point sentinel value, meaning ""Not a Number."" In general, Python prefers raising an exception to returning NaN, so things like sqrt(-1) and log(0.0) will generally raise instead of returning NaN. However, you may get this value back from some other library. From v0.24, you actually can. [Pandas](http://net-informations.com/ds/pd/default.htm) introduces Nullable Integer Data Types which allows integers to coexist with NaNs. You need to say what you want to do with nans. You can either drop those rows (df.dropna()) or replace nans with something else (0 for instance: df.fillna(0)). My suggestion would be to specifically try to identify this problem (why are you getting this particular NaN), and then write some code to provide a replacement. Also, even at the lastest versions of pandas if the column is object type you would have to convert into float first, something like:. `df['column_name'].astype(np.float).astype(""Int32"")`. NB: You have to go through numpy float first and then to nullable Int32, for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1259#issuecomment-799095321:166,log,log,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259#issuecomment-799095321,1,['log'],['log']
Testability,"Need a file `highly_variable_genes.py` in `scanpy.preprocessing` with a function `highly_variable_genes`. This function is very similar to `filter_genes_dispersion`. However, by default, it assumes data has been logarithmized using `sc.pp.log1p`. Hence, in the “Seurat” method, an exponentiation with `expm1` is necessary (the current way in which the parameter `log` treats things is inconsistent as it doesn’t properly transform back using `expm`). Also, the new function doesn’t actually perform the filtering but simply annotates the data (`subset=False`). No need in an option `subset` in the new function. Of course, the old function remains for backwards compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/300:212,log,logarithmized,212,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/300,2,['log'],"['log', 'logarithmized']"
Testability,"Never mind, just turned off the problem option for the purpose of the tests :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1659#issuecomment-781357674:70,test,tests,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1659#issuecomment-781357674,1,['test'],['tests']
Testability,"Nevermind... it turns out I had changed the parameter before, but not rerun it apparently... I reproduced it setting `log=True`. My bad...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/246#issuecomment-416572288:118,log,log,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/246#issuecomment-416572288,1,['log'],['log']
Testability,New logging clutters output,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/684:4,log,logging,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684,1,['log'],['logging']
Testability,"Nice catch - agree on all points regarding inconsistency, the causing sections & the solution with @jlause. Made the PR implementing the ""half-pseudocode"" and added tests which catch your described unexpected behavior for all `flavor`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1867#issuecomment-1814616200:165,test,tests,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867#issuecomment-1814616200,1,['test'],['tests']
Testability,"Nice! Can you please explain your rationale for why they shouldn’t a) be normal tools and b) saved into the AnnData object?. ```py; sc.tl.gearys_c(pbmc, layer=""logcounts""); to_plot = pbmc.var_names[np.argsort(pbmc.var.gearys_c)[:4]]; ```. Sure, adding more and more features is a good point to think about the API, I’d just like to hear why all current analysis tools belong into `tl` and these two don’t!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-553322915:160,log,logcounts,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-553322915,1,['log'],['logcounts']
Testability,"Nice! Tests should also be run by Travis, shouldn't they? Or have we missed out on demanding dependencies and your tests won't run through for that reason? If so, please point me to it and I'll make sure that Travis actually runs the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/439#issuecomment-456635443:6,Test,Tests,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456635443,3,"['Test', 'test']","['Tests', 'tests']"
Testability,No idea about the error in the performance test. @flying-sheep ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/945#issuecomment-561423626:43,test,test,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/945#issuecomment-561423626,1,['test'],['test']
Testability,No idea why the unrelated plot tests fail.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1942#issuecomment-877144170:31,test,tests,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1942#issuecomment-877144170,1,['test'],['tests']
Testability,No longer getting errors on plotting tests. Was this being actively worked on? I think it's ready to close otherwise.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-453901572:37,test,tests,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-453901572,1,['test'],['tests']
Testability,"No matter what it returns, it definitely shouldn't make stuff fail. I think that `downsample_counts` was returning integers before the most recent PR as well. iirc, I made `downsample_counts` use integers because a) numba was failing inference unless I was explicit about integers and b) downsampling counts only makes sense for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_coun",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:762,Log,Logarithmize,762,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239,4,"['Log', 'log']","['Logarithmize', 'log', 'logarithm']"
Testability,No negative logFC values after running scanpy.tl.rank_genes_groups(),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1800:12,log,logFC,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800,1,['log'],['logFC']
Testability,No problem - is there a standard input dataset you use for testing? Otherwise I can just use one I have on-hand.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364154163:59,test,testing,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364154163,1,['test'],['testing']
Testability,"No problem, I'll change it to your preferred style. I don't think it's a problem to add the chunking but I'll need to test it for sparse matrices. Just to clarify, what I meant by ""more functional style"" is something like this:. ```; processed_data = raw_data.log1p().normalize(options...).some_other_method(options...); ```. That is, it allows a [functional programming](https://en.wikipedia.org/wiki/Functional_programming) style. Similar to libraries like `scikit-learn` (e.g. `fit()` returns `self` so you can immediately call another method) or `keras` (see the [functional API guide](https://keras.io/getting-started/functional-api-guide/). But as you say, that might be a dramatic change in coding style for your library. I find it can lead to simpler code but that's a personal preference. The above examples are notable because they allow both functional and declarative styles of coding, depending on the user.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-403242179:118,test,test,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-403242179,1,['test'],['test']
Testability,"No problem. . To give you a quick example with some of the inbuilt datasets:. ```; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); adata_sub = adata[adata.obs.bulk_labels.isin(['Dendritic'])]; sc.tl.rank_genes_groups(adata_sub, 'phase', method='t-test', groups=['G1'], reference='S', key_added='g1_upreg') ; sc.pl.rank_genes_groups(adata_sub, key='g1_upreg'); ```. This version actually works and was tested... just to rule out issues with the code I put above.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1035#issuecomment-584271804:259,test,test,259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035#issuecomment-584271804,2,['test'],"['test', 'tested']"
Testability,No problem. I think increasing the test coverage should be prioritised to make scanpy more robust.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/114#issuecomment-378183576:35,test,test,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/114#issuecomment-378183576,1,['test'],['test']
Testability,"No problem. Maybe something we should consider comes from my attempt to use; plotly with the scatter functions output (probably for bokeh is similar).; Plotly has a function to convert a matplotlib fig object to plotly.; However, for this to work the figure object (the one returned by; pyplot.figure()) has to be returned. Currently, only the axes object are; returned. Thus, we should consider returning the fig object instead of the; axis or add this separately not to break any other code. On Wed, Sep 26, 2018 at 7:33 PM Alex Wolf <notifications@github.com> wrote:. > I'll work a little bit with this branch for a couple of days to test it; > out myself, I might also push little changes to it. I'm super happy to; > merge after these tests. 😄; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/244#issuecomment-424803869>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1afq5UYTS8faVtwGlqyLCpKCIgQkks5ue7pWgaJpZM4WNj5_>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-424844986:637,test,test,637,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-424844986,2,['test'],"['test', 'tests']"
Testability,"No vendored versioneer.py anymore, no setup.cfg! This is vastly simpler. Could you please check if my logic holds?. Package metadata and content will be correctly derived from the git repo’s status. 1. before building, `setuptools_scm` will be installed through `setup_requires=['setuptools_scm']` or `[build-requires]`.; 2. during building, due to `use_scm_version=True`, it will populate the package metadata with a proper version from git. (Looks like `scanpy-1.4.5.dev60+g0adf706`). `scanpy.__version__` will be the version of scanpy you’re currently developing (if applicable) or the installed one:. 1. scanpy tries to use `setuptools_scm.get_version`; 2. if `setuptools_scm` can’t be imported or we’re not in a git repo, it will just use the version from package metadata (like `check_versions` does for other installed packages)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/798:102,log,logic,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/798,1,['log'],['logic']
Testability,"No, each of '1' and '2' is tested against the ""rest"" of the data, that is the union of '2' & '3' in the first, and the union of '1' and '3' in the second case. `groups` merely subsets which groups to look at, the default is to look at all, where 'all' will be equivalent to `['1', '2', '3']`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/278#issuecomment-427037743:27,test,tested,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/278#issuecomment-427037743,1,['test'],['tested']
Testability,"No, i see the same test failures on the PR unrelated to plotting. No, i haven't looked yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020492061:19,test,test,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020492061,1,['test'],['test']
Testability,"No, it currently doesn't. Instead it uses the `scores`... usually some ""differential z-score"" that goes into the t-test. We will extend differential testing in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-390656402:115,test,test,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-390656402,2,['test'],"['test', 'testing']"
Testability,"No, looks good and we test the QC metrics.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/462#issuecomment-464624309:22,test,test,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/462#issuecomment-464624309,1,['test'],['test']
Testability,"No, there aren't any references. It's most easy to understand from this: https://github.com/theislab/scanpy/blob/662f66a4c2bc9a254990792f570cc971a444c575/scanpy/tools/_rank_genes_groups.py#L191. We had quite some material before (@tcallies, where did it go?), but we're now moving away from it and will set a different default test in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365#issuecomment-474304007:327,test,test,327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365#issuecomment-474304007,1,['test'],['test']
Testability,"Nope, I don't think we can work around this. If the fix is not right, could someone take the tests that are included here and fix them ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-800046083:93,test,tests,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-800046083,1,['test'],['tests']
Testability,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306#issuecomment-662072716:31,log,login,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306#issuecomment-662072716,2,['log'],"['log', 'login']"
Testability,"Not exactly sure how to test this - it's not that the axis is misordered, it's that we were not informing the violin plot of this ordering. I am not sure if there is a way to access the underlying data of a plot...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3196#issuecomment-2269833379:24,test,test,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196#issuecomment-2269833379,1,['test'],['test']
Testability,Not sure what kind of test to add for this...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/403#issuecomment-453966774:22,test,test,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-453966774,1,['test'],['test']
Testability,"Not sure what the best way of posting this is, but I'll just paste it for now:. Function to score clusters using multiple cell-type markers; ```; #Define cluster score for all markers; def evaluate_partition(anndata, marker_dict, gene_symbol_key=None, partition_key='louvain_r1'):; # Inputs:; # anndata - An AnnData object containing the data set and a partition; # marker_dict - A dictionary with cell-type markers. The markers should be stores as anndata.var_names or ; # an anndata.var field with the key given by the gene_symbol_key input; # gene_symbol_key - The key for the anndata.var field with gene IDs or names that correspond to the marker ; # genes; # partition_key - The key for the anndata.obs field where the cluster IDs are stored. The default is; # 'louvain_r1' . #Test inputs; if partition_key not in anndata.obs.columns.values:; print('KeyError: The partition key was not found in the passed AnnData object.'); print(' Have you done the clustering? If so, please tell pass the cluster IDs with the AnnData object!'); raise. if (gene_symbol_key != None) and (gene_symbol_key not in anndata.var.columns.values):; print('KeyError: The provided gene symbol key was not found in the passed AnnData object.'); print(' Check that your cell type markers are given in a format that your anndata object knows!'); raise; . if gene_symbol_key:; gene_ids = anndata.var[gene_symbol_key]; else:; gene_ids = anndata.var_names. clusters = np.unique(anndata.obs[partition_key]); n_clust = len(clusters); n_groups = len(marker_dict); ; marker_res = np.zeros((n_groups, n_clust)); z_scores = sc.pp.scale(anndata, copy=True). i = 0; for group in marker_dict:; # Find the corresponding columns and get their mean expression in the cluster; j = 0; for clust in clusters:; cluster_cells = np.in1d(z_scores.obs[partition_key], clust); marker_genes = np.in1d(gene_ids, marker_dict[group]); marker_res[i,j] = z_scores.X[np.ix_(cluster_cells,marker_genes)].mean(); j += 1; i+=1. variances = np.nanvar(marker_re",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/290#issuecomment-428502782:782,Test,Test,782,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290#issuecomment-428502782,1,['Test'],['Test']
Testability,"Not sure what's going on here, but it sounds like your environment. Could you post your version info with `sc.logging.print_versions()`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1143#issuecomment-608192740:110,log,logging,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143#issuecomment-608192740,1,['log'],['logging']
Testability,"Not sure what's up with Travis... the tests pass on my machine, and they were passing on Travis the whole time... my last commit hasn't really changed anything that would cause this fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549#issuecomment-478161476:38,test,tests,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478161476,1,['test'],['tests']
Testability,"Not sure what's up with the test - is it flaky? If not, I can look into it. maybe https://github.com/scverse/scanpy/pull/2889/commits/4bc1c48bee697bc520720723bf3033dd621544fe?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2923#issuecomment-2003908465:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2923#issuecomment-2003908465,1,['test'],['test']
Testability,NotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacke,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2322,Assert,AssertionError,2322,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Assert'],['AssertionError']
Testability,"Notebook tests: there is only one there in the tests, see https://github.com/theislab/scanpy/tree/master/scanpy/tests/notebooks. I run all other linked examples notebooks run manually... So this is not really an option for you, I'd say. I think I can add two important further notebooks very soon so that almost all of the functionality is covered. `setup.py`: yes, definitely, `louvain-igraph>=0.6` is fine! no one should use an earlier version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-419283151:9,test,tests,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-419283151,3,['test'],['tests']
Testability,"Nothing should be hardcoded `np.float32`, but it might be that some functions still do that from an early time, where, for instance, scikit-learn's PCA was silently transforming to `float64` (and Scanpy silently transformed back etc.). Nothing should change the dtype that the user wants, except, for instance, when we logarithmize an integer matrix etc. Here, there should be a default `dtype='float32'` parameter. [PS: In algorithms that inherently are unstable and would profit more from higher precision, one could think about increasing precision.]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475999342:319,log,logarithmize,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475999342,1,['log'],['logarithmize']
Testability,"Now seurat performs DE analysis using alternative tests including MAST and DESeq2 in a convinent way, such as FindMarkers(pbmc, ident.1 = ""CD14+ Mono"", ident.2 = ""FCGR3A+ Mono"", test.use = ""MAST""). So I hope that Scanpy could interated more methods too, such as diffxpy in this way:; sc.tl.rank_gene_groups(adata, method='diffxpy' or 'MAST'). Here is the hyperlink of DE analysis in Seurat:. https://satijalab.org/seurat/v3.0/de_vignette.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-529105173:50,test,tests,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-529105173,2,['test'],"['test', 'tests']"
Testability,Now that tests are passing I will replace the outdated doc images.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1309#issuecomment-656592229:9,test,tests,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309#issuecomment-656592229,1,['test'],['tests']
Testability,OK! Tests should pass now too,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2870#issuecomment-1954676453:4,Test,Tests,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2870#issuecomment-1954676453,1,['Test'],['Tests']
Testability,"OK! Thanks! @fidelram Should we simply regenerate all images using `matplotlib.testing.setup()`, which seems to be the most stable way to go and in the future restrict ourselves to that? I guess this is closer to a reliable test setup for all the images than the current solution via `mpl.use(""agg"")`. Also the name suggests that matplotlib does it this way. But you did some research at the time when introducing the first tests, right?. Thanks for the comment on the PAGA notebook, too, @ivirshup. I'll make sure that I didn't hard-code anything into the plotting functions that might collide with anything else happening on travis... but it's astonishing... In the meanwhile I work-around with a data-base test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-435729565:79,test,testing,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-435729565,4,['test'],"['test', 'testing', 'tests']"
Testability,"OK, I'll add the tests myself. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-430649606:17,test,tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-430649606,1,['test'],['tests']
Testability,"OK, my changes in 426f028708cdd203b7d97d48eb558e695090da82 didn’t make the tests break!. Do we currently not use the plotting test results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/369#issuecomment-441216129:75,test,tests,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369#issuecomment-441216129,2,['test'],"['test', 'tests']"
Testability,"OK, one more change. The log functions now all return the current time and have the optional parameter `time: datetime`. If you pass something there, the time will be logged:. ```py; start = log.info('foo'); # do stuff; log.hint('bar', time=start) # --> bar (00:00:02); ```. You can customize where the time ends up via `log.*('blah {time_passed}: blub', time=...)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/676#issuecomment-499002256:25,log,log,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499002256,5,['log'],"['log', 'logged']"
Testability,"OK, reproducible with smaller test data:. ```py; adata_file = cache.mkdir(""rank_gene_groups_violin"") / ""test_adata.h5ad""; if not Path(adata_file).exists():; ssl._create_default_https_context = ssl._create_unverified_context; urllib.request.urlretrieve(; ""https://apps-01.i-med.ac.at/resources/tmp/toy_adata.h5ad"", adata_file; ); adata_full = sc.read_h5ad(adata_file); adata = ad.concat([; adata[adata.obs.cell_type == 'Naive CD4+ T cells'][:4, :4],; adata[adata.obs.cell_type == 'Naive CD8+ T cells'][:4, :4],; ], merge='unique'); adata.write(data_path / 't-cells.h5ad'); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2258#issuecomment-1658188074:30,test,test,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258#issuecomment-1658188074,1,['test'],['test']
Testability,"OK, since Isaac has no time, I guess we add more tests in a follow-up PR if necessary",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2776#issuecomment-1857829967:49,test,tests,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2776#issuecomment-1857829967,1,['test'],['tests']
Testability,"OK, that’s weird: Now there’s a bunch of `ImageComparisonFailure`s in the minimal tests job. are they unrelated? A fluke?. https://dev.azure.com/scverse/scanpy/_build/results?buildId=5487&view=logs&j=50ff7263-9206-5a84-1219-938c9ee7fde7&t=2e49bd34-47bd-5a56-3183-6247e293d44d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2836#issuecomment-1915065037:82,test,tests,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2836#issuecomment-1915065037,2,"['log', 'test']","['logs', 'tests']"
Testability,"OK, this is absolutely great, thank you for actually doing the benchmarks! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/303#issuecomment-443549085:63,benchmark,benchmarks,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/303#issuecomment-443549085,1,['benchmark'],['benchmarks']
Testability,"OK, this should be mostly it. Maybe some cleanup, but no major changes. Test failures are all the server for `ebi_expression_atlas` breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1910279573:72,Test,Test,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1910279573,1,['Test'],['Test']
Testability,"OK, very interesting! Can we have a video call on this? I'd be very interested in seeing a few benchmarks. . At first sight, I'd say it shouldn't be that as the problem also appears when there are no ""deep"" recursions. I'd have thought that it could be this line that brings considerable performance gain (I sent you the reference in an email some time ago):. https://github.com/cmap/cmapPy/blob/7a2e18030f713865e8038bc7351e5ca44d061205/cmapPy/pandasGEXpress/parse_gctx.py#L332-L333. To get away from the recursions and to use `read_direct`, one needs to start exploiting the naming conventions in the `.h5ad` files. As these has have converged since about a year ago, it's save to do it, along with a table that explains the file format and provides an official reference. Right now, the only reference on the file format is [this](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/info_h5ad.md), which is ridiculous. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/303#issuecomment-441476938:95,benchmark,benchmarks,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/303#issuecomment-441476938,1,['benchmark'],['benchmarks']
Testability,OK. I initially thought that PCA is such a fast step that much logging is not needed. But you're right. :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/623#issuecomment-487026385:63,log,logging,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/623#issuecomment-487026385,1,['log'],['logging']
Testability,OR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60745,test,tests,60745,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,OR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62548,test,tests,62548,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,OR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16750,test,testing,16750,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['test'],['testing']
Testability,OR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62224,test,tests,62224,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pyt,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64104,test,testing,64104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,OS: Windows 10; Python version: 3.7.7; sc.logging.print_versions() gives; scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.4 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1246#issuecomment-633439038:42,log,logging,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246#issuecomment-633439038,1,['log'],['logging']
Testability,Offsets for factors were being calculated wrong. It was being done with a sum when it should have been product. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2964; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2965:203,Test,Tests,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2965,1,['Test'],['Tests']
Testability,"Oh, I also added tests for example dataset loading since checking they worked manually was a pain. These won't run by default (they take a while, and can fail for network access reasons), but will run with `pytest --internet-tests`. Note that `test_burczynski06` will fail until this get's rebased on master. Thoughts?. Also travis failed this for `scanpy/tests/test_marker_gene_overlap.py` failing an assertion on the first time around, but passed when I triggered a new build. Not sure what's up with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-478414881:17,test,tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414881,4,"['assert', 'test']","['assertion', 'tests']"
Testability,"Oh, I had assumed the test failures were related. Any idea what's up with those?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020439130:22,test,test,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020439130,1,['test'],['test']
Testability,"Oh, I specifically meant `tests` not `{package}/tests`. Though looking through the pandas test it does look like there are fewer internal imports than I recall.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090414562:26,test,tests,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090414562,3,['test'],"['test', 'tests']"
Testability,"Oh, I think I misunderstood earlier when you said:. > I just think that you should probably also add the top-level function to the qc.py file in preprocessing.; ; I wasn't sure if you meant move `calculate_qc_metrics` to `qc.py` or add `top_proportions` and `top_segment_proportions` to the preprocessing module. If you're not asking for that, I'm not sure if they're important enough to go there. I use `top_proportions` to make a `plotScater` kind of plot, but that's about it. Otherwise, I think this might be good for now. I was thinking I'd update the tutorial to use this function after the PR is merged. Once that's done, is there a script to update the tests under `notebooks` or is that done manually?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316#issuecomment-433771528:661,test,tests,661,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316#issuecomment-433771528,1,['test'],['tests']
Testability,"Oh, and one more thing. It would be great if the test for the batched version could check it was equivalent to computing the doublets separately. E.g. <details>; <summary> modified `test_scrublet_batched` </summary>. ```python; def test_scrublet_batched():; """"""; Test that Scrublet run works with batched data. Check that scrublet runs and detects some doublets.; """"""; pytest.importorskip(""scrublet""). adata = sc.datasets.pbmc3k(); adata.obs['batch'] = 1350 * ['a'] + 1350 * ['b']; split = [adata[adata.obs[""batch""] == x].copy() for x in (""a"", ""b"")]. sce.pp.scrublet(adata, use_approx_neighbors=False, batch_key='batch'). # replace assertions by conditions; assert ""predicted_doublet"" in adata.obs.columns; assert ""doublet_score"" in adata.obs.columns. assert adata.obs[""predicted_doublet""].any(), ""Expect some doublets to be identified""; assert (; 'batches' in adata.uns['scrublet'].keys(); ), ""Expect .uns to contain batch info"". # Check that results are independent; for s in split:; sce.pp.scrublet(s, use_approx_neighbors=False); merged = sc.concat(split). pd.testing.assert_frame_equal(adata.obs[merged.obs.columns], merged.obs); ```. </details>. --------. For the docs, I think you might need to merge from master to get them to build. Sphinx has been acting up a lot recently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1965#issuecomment-1075220656:49,test,test,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965#issuecomment-1075220656,8,"['Test', 'assert', 'test']","['Test', 'assert', 'assertions', 'test', 'testing']"
Testability,"Oh, no need to do this, I've already got this working a bit more generically (also supports `obsm`) with tests. Just wasn't sure about how to do the keys.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1308#issuecomment-654812288:105,test,tests,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308#issuecomment-654812288,1,['test'],['tests']
Testability,"Oh, thanks! Sorry for the long downtime, the whole family was sick... I'm going through the PR now. The tests question was actually targeted towards @davidsebfischer, but thanks anyways! The comparison question was also targeted to @davidsebfischer, @tcallies. But if you do it, @andrea-tango, awesome!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471327039:104,test,tests,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471327039,1,['test'],['tests']
Testability,"Oh, that's wonderful and exactly what I had hoped pip on the travis server would do! :smile: You mentioned that you might look into it at some point. I just didn't notice the ; ```; cache: pip; ```; line in the commit... Great that you figured this out! Test times now are really nice, in particular, as I can easily speed them up further... So cool! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/360#issuecomment-439837732:254,Test,Test,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/360#issuecomment-439837732,1,['Test'],['Test']
Testability,"Oh, wow, sorry! I completely missed your comment here!. > What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? . What I was thinking: if it's a string get the array from `obsm`, if it's an array, check that it's shape is right, then use the array directly. > It is possible to do something like this. That looks great, thanks!. > I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning. For sure! I was waiting on this actually, just managed to miss any notifications about it. Sorry again about that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-754420131:464,test,tests,464,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-754420131,1,['test'],['tests']
Testability,"Ok @RubenVanEsch we have to assume that this is a windows problem then. I think we will try to set up a test job and hopefully this catches the problem, although will likely catch others. What happens without a `random_state` set?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034479245:104,test,test,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034479245,1,['test'],['test']
Testability,"Ok this should be good to go @ivirshup , I've incorporated the suggestion from @fidelram , thanks @mvdbeek for first attempt and tests!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-826764814:129,test,tests,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-826764814,1,['test'],['tests']
Testability,"Ok, I found a workaround by subsetting the dataset to 100 obs and 100 vars and writing it back to file with this R package 😅 ; https://bioconductor.org/packages/release/bioc/html/DropletUtils.html . . This dataset now works for both `read_visium` and `pl.spatial` tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1048#issuecomment-586269616:264,test,tests,264,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1048#issuecomment-586269616,1,['test'],['tests']
Testability,"Ok, I ran the test and was successful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-586343222:14,test,test,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-586343222,1,['test'],['test']
Testability,"Ok, good to read that it wasn't log-transformed!. @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-478391082:32,log,log-transformed,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-478391082,1,['log'],['log-transformed']
Testability,"Ok, now the tests are actually passing again, everything is in the three commits prior and including this one: https://github.com/theislab/scanpy/commit/d889faf9a58d8981c0783584b3f333680fc161ce",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-427485305:12,test,tests,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-427485305,1,['test'],['tests']
Testability,"Ok, thank you! Maybe I just didn't find them. If so, please point me to them. Merging this in the meanwhile, you can add the tests in a new PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/594#issuecomment-481653813:125,test,tests,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/594#issuecomment-481653813,1,['test'],['tests']
Testability,"Ok, while trying to implement what I've suggested, I realized I made a mistake and it won't work - I can't specify different markers per 1 call of `ax.scatter`. I don't think the speed is a major issue, since the above example is an extreme case (255 categories). Currently, I don't have any trick up my sleeve on how to speed it up. I've also tried including the regression test, but I can't seem to produce an expected figure. I have the default parameters + 40 dpi as it's in `test_plotting.py`, but the plots that I save are always larger for some reason (tried running it from CLI as well, saving the result from the test case [both options failed]). I've tried whether this is related specifically to the pie chart - it isn't - plotting it without still produces larger plots. @ivirshup any idea what I'm doing wrong?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1123#issuecomment-605284449:375,test,test,375,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123#issuecomment-605284449,2,['test'],['test']
Testability,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users.; - plot function moved to scanpy/external/pl.py as scrublet_score_distribution().; - functions linked via 'See also' sections.; - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-727953553:187,log,logic,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-727953553,2,"['log', 'test']","['logic', 'tests']"
Testability,"Okay, test added!. Couldn't test for use_approx_neighbors since we know from the above that one version of that breaks the CI. Also, 'stdev_doublet_rate' rate seems to have no impact, but I'm fairly sure it's passed correctly, so I'm going to blame the Scrublet code itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1659#issuecomment-782141395:6,test,test,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1659#issuecomment-782141395,2,['test'],['test']
Testability,"Okay... I have no idea what else I can do... . I put print statements into the tests and saw that the assignment of names of the `adata.uns['rank_genes_groups']['names']` recarrays is not in the expected order when the tests fail. That's why I put in explicit names into the test data and started testing by these names. For some reason the tests fail when I take the print statements out, but they pass when the print statements are in there... so I can't even look at why they are failing anymore... I may continue to play with this when I have some more time tonight, but I need to focus on some other things atm. If you have any ideas @flying-sheep @ivirshup @falexwolf, I'd be super keen to hear them. Should I just leave print statements in the tests so that it's super verbose when tests fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/583#issuecomment-478954628:79,test,tests,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-478954628,7,['test'],"['test', 'testing', 'tests']"
Testability,"On a test dataset I compute neighbors and then immediately compute/plot both tSNE and UMAP and show them next to each other. Sometimes, we get pretty dramatic differences such as the one attached. Is this an algorithmic difference or something wrong with my approach?. ```; sc.pp.neighbors(adata, n_pcs=n_pcs, n_neighbors=n_neighbors); sc.tl.tsne(adata, n_pcs=n_pcs, random_state=random_state); sc.tl.umap(adata). sc.pl.tsne(adata, color=genes_to_color, color_map='RdBu_r', use_raw=False, save="".png""); sc.pl.umap(adata, color=genes_to_color, color_map='RdBu_r', use_raw=False, save="".png""); ```. ![screenshot from 2018-10-22 11-57-49](https://user-images.githubusercontent.com/330899/47306454-25561300-d5f2-11e8-98e9-939703dcf61b.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/319:5,test,test,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/319,1,['test'],['test']
Testability,"On current master:. ```python; import scanpy as sc. a = sc.datasets.krumsiek11(); assert a.raw is None. sc.tl.rank_genes_groups(a, ""cell_type"", method=""wilcoxon""). a.uns[""rank_genes_groups""][""params""][""use_raw""]; # True; ```. This is bad, and causes issues with downstream plotting functions which use `use_raw` to check where they should be getting expression values from. This PR fixes that. Along with other recent bug fixes, fixes #1114.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1895:82,assert,assert,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1895,1,['assert'],['assert']
Testability,"On master (37851434b2) from the base of the repo, I haven't seen the following code finish running:. ```python; import scanpy.api as sc; adata = sc.read(""./data/pbmc3k_raw.h5ad""); %time sc.pp.downsample_counts(adata, 1500); ```. This PR implements an optimized version of the same thing, which gives:. ```python; %time sc.pp.downsample_counts(adata, 1500) ; CPU times: user 2.25 s, sys: 44.7 ms, total: 2.29 s; Wall time: 2.32 s; ```. ## What's changed. * I've rewritten the function to use numba along with fewer allocations; * Added a test for the function; * Added argument `replace`, which indicates whether subsampling should happen with replacement. ## Notes. To me, it makes more sense to sample without replacement, since for small changes in total counts you'll have more similar profiles. However, I've set the default for replacement to `True` to preserve the current behavior. Neither this or the previous method scale well with sampling depth, and it's maybe worth using a call to sample a multinomial or multivariate hypergeometric distribution instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/340:537,test,test,537,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340,1,['test'],['test']
Testability,"On the other hand, the tests are in the source distribution, including test data, blowing up scanpy’s size to 6MB. I usually put tests next to the package and don’t deliver them to users. We should probably start doing that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/995#issuecomment-574584113:23,test,tests,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995#issuecomment-574584113,3,['test'],"['test', 'tests']"
Testability,"One comprehensive benchmark is [this one](https://ieeexplore.ieee.org/document/8388285/) by Zhang et al (not so up-to-date anymore, though). It'd be nice to establish a ""live"" benchmark repository and compare all methods in a transparent, comprehensive and up-to-date way.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-404781382:18,benchmark,benchmark,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189#issuecomment-404781382,2,['benchmark'],['benchmark']
Testability,"One important thing: pip supports self-depending. I’ve written dep lists like. ```toml; [project]; name = 'myproj'. [project.optional-dependencies]; # myproj’s exported testing tools depend on those:; testing = ['pytest-postgresql']; # to run our package’s tests, we need:; test = ['pytest', 'myproj[testing]']; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295:169,test,testing,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295,5,['test'],"['test', 'testing', 'tests']"
Testability,"One last thing, could you exclude the test data files from any automatic formatting? I guess it's good to know that new lines at the end of files doesn't matter, but I'd prefer to keep those files exactly as they were written by `spaceranger`/ `zarr`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1848#issuecomment-848593645:38,test,test,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1848#issuecomment-848593645,1,['test'],['test']
Testability,"One of the shortcomings of scanpy's default DE testing is that p-values (or FDR) of a few genes are very significant (equal 0 or approximately 0 in some datasets), then it's impossible to execute -log transformation, even there is only one 0. The volcano plot will be not beautiful because of the high significance.; @falexwolf",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-551419621:47,test,testing,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-551419621,2,"['log', 'test']","['log', 'testing']"
Testability,"Only the tests that fail on master also fail here, so this is fine and can be merged",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/161#issuecomment-391988495:9,test,tests,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/161#issuecomment-391988495,1,['test'],['tests']
Testability,"Otherwise this fails with:; ```; ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1828 import IPython; 1829 IPython.embed(); -> 1830 raise ValueError(; 1831 'groupby has to be a valid observation. '; 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index""; ```. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1656:173,log,log,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656,1,['log'],['log']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; $ git checkout 1.7.x; $ git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; $ git cherry-pick -m1 5fc12f4a918e21f0c57937b787d52040db046f01; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; $ git commit -am 'Backport PR #1587: Attach failing plots to CI results'; ```. 4. Push to a named branch :. ```; git push YOURFORK 1.7.x:auto-backport-of-pr-1587-on-1.7.x; ```. 5. Create a PR against branch 1.7.x, I would have named this PR:. > ""Backport PR #1587 on branch 1.7.x"". And apply the correct labels and milestones. Congratulation you did some good work ! Hopefully your backport PR will be tested by the continuous integration and merged soon!. If these instruction are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1587#issuecomment-787808128:860,test,tested,860,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1587#issuecomment-787808128,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; $ git checkout 1.7.x; $ git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; $ git cherry-pick -m1 ce508c4084e8df272163f4e17136386cfaec2605; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; $ git commit -am 'Backport PR #1768: Fix correlation plot test for new version of matplotlib'; ```. 4. Push to a named branch :. ```; git push YOURFORK 1.7.x:auto-backport-of-pr-1768-on-1.7.x; ```. 5. Create a PR against branch 1.7.x, I would have named this PR:. > ""Backport PR #1768 on branch 1.7.x"". And apply the correct labels and milestones. Congratulation you did some good work ! Hopefully your backport PR will be tested by the continuous integration and merged soon!. If these instruction are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1768#issuecomment-809014499:516,test,test,516,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768#issuecomment-809014499,2,['test'],"['test', 'tested']"
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; $ git checkout 1.7.x; $ git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; $ git cherry-pick -m1 f7279f6342f1e4a340bae2a8d345c1c43b2097bb; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; $ git commit -am 'Backport PR #1679: enables highly_variable_genes_seurat_v3 to accept pseudocounts'; ```. 4. Push to a named branch :. ```; git push YOURFORK 1.7.x:auto-backport-of-pr-1679-on-1.7.x; ```. 5. Create a PR against branch 1.7.x, I would have named this PR:. > ""Backport PR #1679 on branch 1.7.x"". And apply the correct labels and milestones. Congratulation you did some good work ! Hopefully your backport PR will be tested by the continuous integration and merged soon!. If these instruction are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1679#issuecomment-814587648:888,test,tested,888,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1679#issuecomment-814587648,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.10.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 5c0e89e99dc2461c654c549435a73f547f3573ce; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #3339: Add PYI lints'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.10.x:auto-backport-of-pr-3339-on-1.10.x; ```. 5. Create a PR against branch 1.10.x, I would have named this PR:. > ""Backport PR #3339 on branch 1.10.x (Add PYI lints)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3339#issuecomment-2457653625:856,test,tested,856,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3339#issuecomment-2457653625,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.10.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 5d5d873b1fb0353089569f85580b43437df9c6cd; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #3104: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.10.x:auto-backport-of-pr-3104-on-1.10.x; ```. 5. Create a PR against branch 1.10.x, I would have named this PR:. > ""Backport PR #3104 on branch 1.10.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3104#issuecomment-2160085624:904,test,tested,904,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3104#issuecomment-2160085624,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.10.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 8d046ff37e024ae88eadfb22ea8fd142a6b95aa1; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #3093: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.10.x:auto-backport-of-pr-3093-on-1.10.x; ```. 5. Create a PR against branch 1.10.x, I would have named this PR:. > ""Backport PR #3093 on branch 1.10.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3093#issuecomment-2146729991:904,test,tested,904,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3093#issuecomment-2146729991,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 05dcf68f32ce255447ea804de55babefb3c47c92; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2753: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2753-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2753 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2753#issuecomment-1809942763:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2753#issuecomment-1809942763,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 330a099ffe76286f0f047387701af7e9fd58831a; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2838: Fix pytest 8 compat'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2838-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2838 on branch 1.9.x (Fix pytest 8 compat)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2838#issuecomment-1923260036:863,test,tested,863,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2838#issuecomment-1923260036,2,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 47664d83a7bc47756356b907e5719076ab187361; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2784: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2784-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2784 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2784#issuecomment-1862463379:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2784#issuecomment-1862463379,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 4f4b1c3a655546d981360bcce625d354a4291385; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2811: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2811-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2811 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2811#issuecomment-1893536608:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2811#issuecomment-1893536608,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 585f58c9e4dd82dd7809a831538c4e230b008818; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2841: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2841-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2841 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2841#issuecomment-1929072209:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2841#issuecomment-1929072209,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 5ccce795b19a5aa59a6b1f1c3552884ed6fc94d1; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2544: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2544-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2544 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2544#issuecomment-1619899808:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2544#issuecomment-1619899808,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 86dc4d5d96eb7547833e7805ea2f7d603bd3ba2d; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2779: Fix anndata warnings'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2779-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2779 on branch 1.9.x (Fix anndata warnings)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2779#issuecomment-1858121974:865,test,tested,865,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2779#issuecomment-1858121974,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 95206dc54c8bb0d9d478f09f47dff9477a5c58c4; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2704: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2704-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2704 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2704#issuecomment-1776676386:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2704#issuecomment-1776676386,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 b23229f9bfc95ff90a5d6393b4d53d062190d5bb; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2732: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2732-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2732 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2732#issuecomment-1795950835:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2732#issuecomment-1795950835,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 bf5f27aa9e968de6e73fc7abb46a89084ddf6880; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2831: Prepare 1.9.8, stop ignoring citation errors'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2831-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2831 on branch 1.9.x (Prepare 1.9.8, stop ignoring citation errors)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2831#issuecomment-1911960423:913,test,tested,913,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2831#issuecomment-1911960423,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 c2f706b35d52a5e21ccf84f1cd299b0dadf49668; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2716: Add missing link targets'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2716-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2716 on branch 1.9.x (Add missing link targets)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2716#issuecomment-1780921886:873,test,tested,873,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2716#issuecomment-1780921886,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 c410cd123f5487f25c08b421c8d06da50551ff73; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2799: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2799-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2799 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2799#issuecomment-1882962300:899,test,tested,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2799#issuecomment-1882962300,1,['test'],['tested']
Testability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 e5d41d4aa58a925f0fa5cfcf580cb975167a71c9; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2235: Separate test utils from tests'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2235-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2235 on branch 1.9.x (Separate test utils from tests)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870:499,test,test,499,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870,5,['test'],"['test', 'tested', 'tests']"
Testability,P-values added to t-tests and wilcoxon test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270:20,test,tests,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270,2,['test'],"['test', 'tests']"
Testability,"PCA, ""RuntimeWarning: divide by zero encountered in log"" and wrong PCs ordering with svd_solver arpack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/264:52,log,log,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264,1,['log'],['log']
Testability,PES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72626,test,testing,72626,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,PES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66563,test,testing,66563,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,PES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66881,test,testing,66881,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,PES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspac,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69340,test,testing,69340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,PES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62793,test,tests,62793,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,PES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63448,test,testing,63448,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,"PI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.09.1; dateutil 2.8.2; debugpy 1.5.0; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fsspec 2021.10.0; google NA; h5py 3.4.0; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.2; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; mudata 0.1.0; muon 0.1.1; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.3; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 2.0.10; psutil 5.9.0; ptyprocess 0.7.0; pycparser 2.20; pydev_ipython NA; pydevconsole NA; pydevd 2.4.1; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.10.0; pynndescent 0.5.4; pyparsing 2.4.7; pyreadr 0.4.4; pytz 2021.3; scipy 1.7.1; seaborn 0.11.2; six 1.16.0; sklearn 1.0; sphinxcontrib NA; statsmodels 0.13.0; storemagic NA; tables 3.6.1; threadpoolctl 3.0.0; tlz 0.11.1; toolz 0.11.1; tornado 6.1; tqdm 4.62.3; traitlets 5.1.0; typing_extensions NA; umap 0.5.1; wcwidth 0.2.5; yaml 5.4.1; zipp NA; zmq 22.3.0; -----; IPython 7.28.0; jupyter_client 7.0.6; jupyter_core 4.8.1; notebook 6.4.4; -----; Python 3.7.2 (default, Dec 29 2018, 06:19:36) [GCC 7.3.0]; Linux-4.15.0-70-generic-x86_64-with-debian-buster-sid; 4 logical CPU cores, x86_64; -----; Session information updated at 2022-01-25 10:12. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2122:4559,log,logical,4559,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2122,1,['log'],['logical']
Testability,PPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61490,test,testing,61490,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,PPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/wo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74430,test,tests,74430,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"PPS: I see that I'm getting test failures with some github automatic tests, with none of the failures clearly coming from the code I edited -- do you know what is going on here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-902986463:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-902986463,2,['test'],"['test', 'tests']"
Testability,"PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata = sc.datasets.pbmc3k(); sc.pp.scale(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-5-d1141fe2ca57> in <module>; ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy); 910 if isinstance(data, AnnData):; 911 adata = data.copy() if copy else data; --> 912 view_to_actual(adata); 913 # need to add the following here to make inplace logic work; 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata); 377 ; 378 def view_to_actual(adata):; --> 379 if adata.is_view:; 380 warnings.warn(; 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > Current scanpy master branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1151:840,log,logic,840,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151,2,['log'],"['logging', 'logic']"
Testability,"PR to solve #1321 . ```PYTHON; marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True,log=False).style(yticklabels=True,row_palette='muted').show(); ```; ![image](https://user-images.githubusercontent.com/4964309/88898994-cbb25c00-d24d-11ea-8de2-5768752c9939.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1342:186,log,log,186,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342,1,['log'],['log']
Testability,"PS: You don't need a test for this... it would require installing phate on travis and this would take time... Also, the interface is trivial. You should simply link to your package within the docs to redirect people for bugs and more info.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/136#issuecomment-385960220:21,test,test,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136#issuecomment-385960220,1,['test'],['test']
Testability,"PYTHON_VERSION variable is empty, so we actually pass `python=` in `conda create` so Travis always tests scanpy with latest Python in Conda distribution. Therefore Python 3.5 is actually never tested. Furthermore, conda switched to python 3.7, so now all test are run on Python 3.7. This is also the reason of weird HDF error message we get in tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/201:99,test,tests,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/201,4,['test'],"['test', 'tested', 'tests']"
Testability,Paga plotting had some half-finished support for supplying a root by its label. This is supposed to finish this. Fixes #909. @falexwolf needs to say if this corresponds to his intentions and we need to add a test.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/910:208,test,test,208,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/910,1,['test'],['test']
Testability,"Part of [scanpy 2.0](https://github.com/orgs/scverse/projects/18/views/1). <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. I implemented a Ruff check (PLR0917) for this, but setting `max-positional-args = 3` would make this massive PR even larger, so I opted to do it in a separate one. ## Reviewers. Your main job is to check if the position of the `*` makes sense for each exported function (i.e. the ones with the `@legacy_api` decorator). I tried my best to base it on internal usage of each API, but one placement or the other might be to early. The only real logic changes are in `scanpy/tests/test_package_structure.py`. This PR:. - makes public APIs with more than 5 parameters keyword-only without breaking backwards compatibility (for now); - makes private APIs with more than 5 parameters keyword-only; - checks that we don’t internally use the old positional APIs using a warning filter with `action='error'`; - checks that APIs use our convention for the `copy` parameter (`adata` as first param, returns `adata` type or None`); - manually checked that APIs use our convention `filename: Path | str`/`path: Path | str`. ## Follow-up changes. - [ ] Set `max-positional-args = 3`; - [ ] make sure that no new public API gets introduced without being included in the `api_module_names` list; - [ ] enforce convention `show`, `return_fig`, `ax`; - [ ] enforce convention for `random_seed: AnyRandom`; - [ ] https://github.com/scverse/scanpy/issues/2331",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2702:162,Test,Tests,162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2702,3,"['Test', 'log', 'test']","['Tests', 'logic', 'tests']"
Testability,"Part of why I would like this to be in `sklearn` is that it lessens our responsibility to maintain it, and simplifies our code. I think it'll be easiest to do this sooner, rather than later, since these things have a tendency to lose momentum. For sklearn submission, I don't think you'd have to implement any classes. Your solution would just be what happened if someone passed a sparse matrix and `solver=""arpack""` to `PCA.fit`, like what https://github.com/scikit-learn/scikit-learn/pull/12841 does. Does this make it more appealing? If not, would you mind if I opened a PR to sklearn with this code (crediting you, of course)?. ----------------. About this PR, could you add tests for:. * The variance and variance explained entries being correct; * Explicit and implicit centering returning equivalent results. After that and the code reorganization I mentioned above, this should be about ready to merge.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-593822877:679,test,tests,679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-593822877,1,['test'],['tests']
Testability,"Perf measurements for the use case of running the HVG tests on my machine (not very accurate, and not very reminiscent of how users use it). Tests get a bit slower, real world gets faster. - scanpy master:. ```console; $ git switch master; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:54,test,tests,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266,6,"['Test', 'test']","['Tests', 'test', 'tests']"
Testability,"Phil, thanks for this! I'm slowly finding time again to deal with these things. I looked through it and it's a very nice solution. I'll test it these days and merge it into master. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/38#issuecomment-335447670:136,test,test,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/38#issuecomment-335447670,1,['test'],['test']
Testability,"Ping @fidelram. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ); ```. ```pytb; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); <ipython-input-7-594171c15db1> in <module>; ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 710 ; 711 if groupby is not None:; --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw); 713 if kwds.get('palette', None) is None:; 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 200 # add var values; 201 if len(var_names) > 0:; --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw); 203 if use_raw:; 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp); 341 return adata.obsp[obsp]; 342 else:; --> 343 assert False, (; 344 ""That was unexpected. Please report this bug at:\n\n\t""; 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues; ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1546:253,Assert,AssertionError,253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546,4,"['Assert', 'assert', 'log']","['AssertionError', 'assert', 'log']"
Testability,"Ping @flying-sheep @giovp @Mirkazemi. Turns out that the `sc.datasets.visium_sge` would just read in whatever images were most recently added, not the one that fit the dataset. This fixes that. Additionally, `sc.read_visium` now takes a directory as the first argument. If a reading function assumes a directory structure, that directory should be passed, not a specific path inside of it. This follows our other functions like: `sc.read_10x_mtx`. Similarly, I've rearranged how the example datasets are stored and how the test data is stored to better match the outputs from 10x pipelines. A few more changes I'd like to make:. * Restructure how elements are added to `uns`, as mentioned in https://github.com/theislab/anndata/issues/295#issuecomment-596164456; * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`.; * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1088:523,test,test,523,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088,1,['test'],['test']
Testability,"Please adapt the corresponding test to:. ```; @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; sc.pp.scale(v, flavor=flavor); assert not v.is_view; assert_allclose(v.X.var(axis=0), np.ones(v.shape[1]), atol=0.01); assert_allclose(v.X.mean(axis=0), np.zeros(v.shape[1]), atol=0.00001); ```. It fails for me with `FAILED scanpy/tests/test_preprocessing.py::test_scale[use_fastpp] - numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267:31,test,test,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267,4,"['assert', 'test']","['assert', 'test', 'tests']"
Testability,"Please add the relevant part of `jupyter lab`’s log. If it’s a SEGFAULT, please reproduce with the [`PYTHONFAULTHANDLER`](https://docs.python.org/3/using/cmdline.html#envvar-PYTHONFAULTHANDLER) env variable set to a non-empty string to get a traceback",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2840#issuecomment-1929143068:48,log,log,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2840#issuecomment-1929143068,1,['log'],['log']
Testability,"Please go ahead!. On Tue, Feb 12, 2019 at 6:41 PM Philipp A. <notifications@github.com> wrote:. > Ah, sorry for being in the way here with the unrelated logging changes.; > Alex is currently a bit ill I learned, which is why he probably didn’t do; > it yet. I didn’t have time to review the whole thing, but if y’all want I; > can do that too; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/425#issuecomment-462858876>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1RE9LYK4sL6sLFd586y_cpEBQKxwks5vMvzRgaJpZM4Z-M3d>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/425#issuecomment-463080680:153,log,logging,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-463080680,1,['log'],['logging']
Testability,"Possible TODO:. - normalize_pearson_residuals_pca. @ivirshup I reverted the change in a6290ee9e0d1baf0e3483118aa552b6f6dcf02c0 where you changed. ```diff; -X_pca = np.zeros((X.shape[0], n_comps), X.dtype); +X_pca = np.zeros((adata_comp.shape[0], n_comps), adata.X.dtype); ```. the commit message is “Fix up pca tests”, but that change doesn’t seem to impact tests and it takes properties from several different object without reasoning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2272#issuecomment-1807755523:311,test,tests,311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272#issuecomment-1807755523,2,['test'],['tests']
Testability,Possible enhancement: multithreaded (via numba) mann-whitney tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2060:61,test,tests,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2060,1,['test'],['tests']
Testability,"Possibly related to #275. The provided `sc.datasets.pbmc3k` does not have values for `""gene_ids""`. It'd be useful to have a standard dataset with ensembl ids and gene symbols for testing visualization functions with the `gene_symbols` argument. ```python; In [1]: import scanpy.api as sc ; ...: sc.datasets.pbmc3k().var.head() ; Out[1]: ; gene_ids; index ; MIR1302-10 NaN; FAM138A NaN; OR4F5 NaN; RP11-34P13.7 NaN; RP11-34P13.8 NaN. In [2]: import h5py ; ...: with h5py.File(""./data/pbmc3k_raw.h5ad"") as f: ; ...: print(repr(f[""var""][:])) ; ...: ; array([(b'MIR1302-10', -1), (b'FAM138A', -1), (b'OR4F5', -1), ...,; (b'CU459201.1', -1), (b'AC002321.2', -1), (b'AC002321.1', -1)],; dtype=[('index', 'S19'), ('gene_ids', 'i1')]); ```. However, if I download the source files, everything works out fine:. ```python. In [3]: !wget http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz ; ...; In [4]: !tar xzf pbmc3k_filtered_gene_bc_matrices.tar.gz; ...; In [5]: sc.read_10x_mtx(""./filtered_gene_bc_matrices/hg19"").var.head() ; Out[5]: ; gene_ids; MIR1302-10 ENSG00000243485; FAM138A ENSG00000237613; OR4F5 ENSG00000186092; RP11-34P13.7 ENSG00000238009; RP11-34P13.8 ENSG00000239945; ```. Which makes me think the file hosted at `http://falexwolf.de/data/pbmc3k_raw.h5ad` was created when there was a bug in the `read_10x_mtx` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/428:179,test,testing,179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/428,1,['test'],['testing']
Testability,"Potentially fixes #1355. * Would still need tests/ further consideration.; * Need to fix missing values not being plotted below present ones. Using this branch:. ```python; import scanpy as sc; import numpy as np; import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(); pbmc.obs[""louvain""].iloc[::2] = np.nan; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain""); ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])); ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well); - [x] Decide on adding arguments, and default values; - [x] Decide on whether continuous legend update happens in this PR",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356:44,test,tests,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356,3,"['Test', 'test']","['Tests', 'tests']"
Testability,"Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere; - [x] test everything using `array_type` or similar with the same fixture; - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. it’s not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2595:30,test,testing,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595,2,['test'],"['test', 'testing']"
Testability,"Prepare release 1.4.5 with docs, logging, default parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/960:33,log,logging,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/960,1,['log'],['logging']
Testability,Prevent oversubscription during tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2843:32,test,tests,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2843,1,['test'],['tests']
Testability,"Previously discussed in #240. A few things left to discuss:. ## Tests. These are pretty simple, ""this doesn't intrinsically throw an error"" type tests. Should the tests cover more than that? Should they be more thorough is checking arguments won't throw errors? I'm open to suggestions on other things that could be checked. Also, is there a place they'd be more appropriate?. ## Allowing storage of multiple network representations . I think this would also be a pretty simple addition, but wanted to check again before implementing it. I'm thinking of adding a `use_network` argument which would allow key access to network stored in the AnnData object – similar to the `use_rep` argument. @LuckyMD mentioned there might be some storage concerns here, though I think the user is ultimately responsible for size in this case. The value added here is different representations are useful for different analysis, and it'd be useful to not have to have two objects when the rest of the data would be shared. ## Allow more choice of partition method for `louvain-igraph` package. I'm not too fussed on this one. It's just that `""RBConfiguration""` is hard coded when other methods are available, and I'm not aware of a reason it would be the best choice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248:64,Test,Tests,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248,3,"['Test', 'test']","['Tests', 'tests']"
Testability,Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:52: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: no,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:8647,test,test,8647,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12133:52: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:26: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:11270,test,test,11270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['test'],['test']
Testability,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytest’s test files (`test_*.py` and `conftest.py`) aren’t Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225:20,test,test,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225,10,['test'],"['test', 'testing', 'tests']"
Testability,"Question for this, what heuristics have you tried? My guess would be that `min(distances_between_points) / 3` should be fine for an upper bound. Second, I think this logic is a little convoluted, and I don't know that `library_id` will always be associated with visium only. Would a better check be for `[""metadata""][""software_version""]` or something like that?. It might help for me to know what exactly you're planning on putting in the `""spatial""` entry.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-738578221:166,log,logic,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-738578221,1,['log'],['logic']
Testability,"Quick question to you @ivirshup, can't we simply replace all the `adata_neighbors` stuff with `scanpy.datasets.pbmc68k_reduced`? It already has the neighbor graph etc. in it and is smaller, that is, would speed up tests considerably.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/581#issuecomment-479418054:214,test,tests,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479418054,1,['test'],['tests']
Testability,R scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65504,test,tests,65504,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,R scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportEr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:13588,test,testing,13588,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['test'],['testing']
Testability,R scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportErr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69585,test,tests,69585,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,RAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.para,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66069,test,tests,66069,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,RAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68362,test,testing,68362,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,ROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60906,test,tests,60906,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - Imp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68770,test,tests,68770,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,ROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:14215,test,testing,14215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['test'],['testing']
Testability,ROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - I,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:14009,test,testing,14009,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['test'],['testing']
Testability,ROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportErr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64848,test,tests,64848,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,RROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3724,test,tests,3724,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['test'],['tests']
Testability,RROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - Im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61892,test,tests,61892,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,RROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_resi,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:8267,test,testing,8267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['test'],['testing']
Testability,RROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69098,test,tests,69098,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,RROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_grou,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72211,test,tests,72211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,RROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64353,test,tests,64353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,Random test failure of `test_plotting.py::test_paga`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:7,test,test,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,1,['test'],['test']
Testability,"Re: quotes: Yes, the difference is that escape sequences work in double quoted strings. So for me a double quoted string in otherwise single quoted TOML means “pay attention, this one has special stuff in it”. Re: Build: The problem is that. 1. we’re installing louvain and it; 2. [doesn’t have a Python 3.9 wheel](https://pypi.org/project/louvain/#files), which causes us to download the sdist,; 3. [Sets `2to3=True` in setup.py](https://github.com/vtraag/louvain-igraph/blob/0.7.0/setup.py#L827-L828), for which [setuptools has removed support](https://setuptools.pypa.io/en/latest/history.html#v58-0-0). I think the best course of action would be to just port louvain to Python 3 only, and until then make sure our build environment as setuptools 57 installed. See https://github.com/vtraag/louvain-igraph/issues/57. Or we can deactivate louvain tests, skip installing it in the tests, and let people who need it deal with that. Or we ask @vtraag to upload Python 3.9 and 3.10 wheels, then we kicked the problem back two releases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2042#issuecomment-967619897:849,test,tests,849,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2042#issuecomment-967619897,2,['test'],['tests']
Testability,"Re: testing externals, I've tried my best to just test the way it interfaces with scanpy. i.e., if MAGIC silently fails to return the correct output, scanpy tests would pass so long as the output is the right type / shape. If MAGIC throws an error when run from scanpy, this might be something you would like to address (i.e. by contacting the relevant external developer) regardless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/988#issuecomment-573589189:4,test,testing,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/988#issuecomment-573589189,3,['test'],"['test', 'testing', 'tests']"
Testability,Refactoring t-test default warning,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2798:14,test,test,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798,1,['test'],['test']
Testability,"Regarding Pearson vs. deviance residuals @adamgayoso: we looked into in in detail for the second version of the manuscript (just posted to bioRxiv: https://www.biorxiv.org/content/10.1101/2020.12.01.405886v2.full.pdf). Our conclusion is that deviance residuals don't work here at all because they -- unlike Pearson residuals -- show a very strong mean-variance relationship. Here, see an excerpt from Figure S2:. ![Screenshot from 2021-04-28 09-29-02](https://user-images.githubusercontent.com/8970231/116365322-6f449300-a805-11eb-8458-0bbf2aceb23a.png). I was surprised by that because I fully expected that deviance and Pearson residuals would be very similar and we'd see no qualitative difference between them. But this wasn't the case. See also a new benchmark in Figure 5. > I was using GLM-PCA as a generic example, but I then realized that coincidentally in the GLM-PCA paper they describe a fast analytical approximation using deviance residuals, which is not compared to in the analytical Pearson residuals manuscript (and again highlights the potential role of peer-review IMO). Re peer review -- as I already mentioned, none of the actual reviewers asked us about deviance residuals ;-) So thanks a lot for voicing these concerns here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-828228025:756,benchmark,benchmark,756,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-828228025,1,['benchmark'],['benchmark']
Testability,"Regarding running CI with minimal optional deps, I’d say we could change this line:. https://github.com/scverse/scanpy/blob/86e2a35c1df2b61772e5f898bfcd11abb8d9fb2c/.azure-pipelines.yml#L46. … to be parametric like `pip install .[dev,test$(test_extras))]`, and run things once with `test_extras=''` and once with `test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'`. we’d probably have to make a lot of tests optional with `@skipif(not find_spec('thing'), ...)` though, and of course remove some things from the `test` extra",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088710180:234,test,test,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088710180,3,['test'],"['test', 'tests']"
Testability,Reminder: Check Benchmarks,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3284#issuecomment-2435684966:16,Benchmark,Benchmarks,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3284#issuecomment-2435684966,1,['Benchmark'],['Benchmarks']
Testability,Remove global state changes in plotting tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2150:40,test,tests,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2150,1,['test'],['tests']
Testability,"Removes the need for a pytables dependency. * pytables has been a source of installation heisenbugs, particularly on windows (#1468, #1284, #454); * why use two hdf5 libraries; * Makes it easier to move reading 10x files into anndata or elsewhere #1387. I've edited the code as lightly as possible, since these readers were originally contributed by someone at 10X, so I assume they had better knowledge of possible edge cases. - [ ] ~~Test with h5py 2~~; - [ ] Add release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2064:436,Test,Test,436,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2064,1,['Test'],['Test']
Testability,"Reorder operations to avoid overflows. Behavior Fixed:; ```py; import scanpy as sc; import numpy as np; X = np.random.randint(0,1000, size= (3000,2000)); ann = sc.AnnData(np.log(X+1)); gsize = X.shape [0] / 2; ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize); sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000); ```; ```pytb; ... storing 'group' as categorical; C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars; (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-7-bccdb587a644> in <module>; 5 gsize = X.shape [0] / 2; 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize); ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000); 8; 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); --> 372; 373 scores[np.isnan(scores)] = 0; 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. After the fix, the same code no longer raises an error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1062:174,log,log,174,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062,1,['log'],['log']
Testability,Reordering categories leads to issues with `sc.tl.rank_genes_groups` when using `method='logreg'`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/273:89,log,logreg,89,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273,1,['log'],['logreg']
Testability,Reorganize plotting test outputs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1772:20,test,test,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772,1,['test'],['test']
Testability,Replace `is` for `==` in string testing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/508:32,test,testing,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/508,1,['test'],['testing']
Testability,Replace sklearn.utils.testing with numpy.testing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1557:22,test,testing,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1557,2,['test'],['testing']
Testability,Replace stdout and stderr prints in ComBat with logg.info,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/552:48,log,logg,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/552,1,['log'],['logg']
Testability,Report pynndescent version in sc.logging.print_header,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1613:33,log,logging,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1613,1,['log'],['logging']
Testability,"Reproducible example. ```py; import scanpy as sc; import scanpy.external as ice; from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(); sc.pp.pca(adata); sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False)`; ```. ```pytb; TypeError Traceback (most recent call last); <ipython-input-231-50baef9a10a9> in <module>; 5 pbmc = sc.datasets.pbmc68k_reduced(); 6 sc.pp.pca(adata); ----> 7 sce.pp.bbknn(adata, batch_key='batch', copy=False,trim=0, save_knn=False). ~/Library/Python/3.7/lib/python/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs); 82 except ImportError:; 83 raise ImportError('Please install bbknn: `pip install bbknn`.'); ---> 84 return bbknn(**params, **kwargs). ~/Bioinformatics/usr/local/lib/python3.7/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, approx, metric, copy, **kwargs); 281 ; 282 	logg.info('	finished', time=start,; --> 283 		deep=('added to `.uns[\'neighbors\']`\n'; 284 ' \'distances\', weighted adjacency matrix\n'; 285 		'	\'connectivities\', weighted adjacency matrix')). ~/Library/Python/3.7/lib/python/site-packages/scanpy/logging.py in info(*args, **kwargs); 17 ; 18 def info(*args, **kwargs):; ---> 19 return msg(*args, v='info', **kwargs); 20 ; 21 . TypeError: msg() got an unexpected keyword argument 'deep'`; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/770:899,log,logg,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770,2,['log'],"['logg', 'logging']"
Testability,Restrict files written by tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2559:26,test,tests,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2559,1,['test'],['tests']
Testability,Reverts scverse/scanpy#2296 due to broken tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2422:42,test,tests,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2422,1,['test'],['tests']
Testability,Run benchmarks for off axis,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3147:4,benchmark,benchmarks,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3147,1,['benchmark'],['benchmarks']
Testability,"Runs static analysis concurrently with tests, while currently static analysis is run first. This cuts down on total test time, and will always test both correctness and style.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/846:39,test,tests,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/846,3,['test'],"['test', 'tests']"
Testability,SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65585,test,testing,65585,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,S_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69840,test,tests,69840,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,S_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.pa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61975,test,testing,61975,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,S_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/worksp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69181,test,testing,69181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,S_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65751,test,tests,65751,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,"Same error here...any ideas?. ```; -----; anndata 0.8.0; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.8.0; anndata2ri 0.0.0; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; bs4 4.10.0; cached_property 1.5.2; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.02.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.10.0; entrypoints 0.4; fsspec 2022.02.0; get_version 3.5.4; h5py 3.6.0; igraph 0.9.9; ipykernel 6.9.1; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.1.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.7; pytz 2021.3; pytz_deprecation_shim NA; rpy2 3.4.2; scanpy 1.8.2; scipy 1.7.3; seaborn 0.11.2; setuptools 59.8.0; sinfo 0.3.1; sip NA; six 1.16.0; sklearn 1.0.2; soupsieve 2.3.1; sphinxcontrib NA; spyder 5.2.2; spyder_kernels 2.2.1; spydercustomize NA; statsmodels 0.13.2; storemagic NA; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tlz 0.11.2; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; tzlocal NA; wcwidth 0.2.5; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 7.32.0; jupyter_client 7.1.2; jupyter_core 4.9.2; -----; Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]; Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-04-20 18:16; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2239#issuecomment-1104127300:1879,log,logical,1879,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1104127300,1,['log'],['logical']
Testability,Same issue here. Using `pip` +pyhton3.7 and not conda to install from pypi. Is there a way to resolve it without installing using conda?. Logs:. ```; [dilawars@chamcham scanpy_exp]$ python planaria.py ; /home1/dilawars/.local/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses; import imp; scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1 ; ... storing 'clusters' as categorical; computing tSNE; using data matrix X directly; using the 'MulticoreTSNE' package by Ulyanov (2017); finished (0:02:53.98); saving figure to file ./figures/tsne_full.pdf; computing neighbors; using data matrix X directly; Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed!; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-427357518:138,Log,Logs,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-427357518,2,"['Assert', 'Log']","['Assertion', 'Logs']"
Testability,"Scanpy 1.5.0; Out of curiousity I set min_fold_change to different values but it didn't work. Even when I set min_fold_change=100 it doesn't shorten the gene list. So is it because the filters are working in an OR logic? If that's the case, I don't think the default values for each filter should be the ones you set - they should be a very harsh condition to make sure customer-specified parameters are the bottleneck.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1447:214,log,logic,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1447,1,['log'],['logic']
Testability,Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313; ```; scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (n_active + m_active + 1) / 12)); ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`; _rank_gene_groups.py:313; ```; scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (1/12.0) * (n_active + m_active + 1))); ```; Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1061:31,test,tested,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061,2,['test'],['tested']
Testability,"Scanpy does have logging implemented (examples: [neighbors](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/neighbors/__init__.py#L84), [highly variable genes](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:17,log,logging,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063,2,['log'],"['logged', 'logging']"
Testability,Scanpy precisely reproduces Seurat's output as outlined in the first tutorial. You can also feed in logarithmized data by passing the parameter `log=True`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/188#issuecomment-402090857:100,log,logarithmized,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188#issuecomment-402090857,2,['log'],"['log', 'logarithmized']"
Testability,"Scanpy vs. 1.3.6; installed using pip3; OSX 10.10.5; Jupyter lab. code:; `list_of_list_of_marker_genes = [mg1, mg2, mg3]; for mg in list_of_list_of_marker_genes:; sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90); print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run; sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then; 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/405:763,test,tested,763,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405,1,['test'],['tested']
Testability,"Second step: reverted things that were logged at a level equal or higher than 4 to `debug`. a37efc71876f1cd9ace1165d7f774e390d30343d. The only thing that remains is to reformat the time output, which now displays many useless digits after the seconds comma [and fix all other places in which similar things happened].",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/684#issuecomment-500211162:39,log,logged,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684#issuecomment-500211162,1,['log'],['logged']
Testability,See #2682 for a putative fix. Might need a unit test though.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2681#issuecomment-1757749996:48,test,test,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681#issuecomment-1757749996,1,['test'],['test']
Testability,"See my last comment. After fixing the colormaps in this PR, I didn’t update the images, but the tests still pass. What’s up with that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/369#issuecomment-441571449:96,test,tests,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369#issuecomment-441571449,1,['test'],['tests']
Testability,Seems it works properly; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/log1p_test.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-403512265:67,benchmark,benchmarks,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-403512265,1,['benchmark'],['benchmarks']
Testability,"Seems like some shell shenanigans. For some reason you passed `'scanpy` as a first parameter instead of the whole thing as a string. In any case, I either need someone to confirm that the fix works, or better, a reproducible example that we can derive a test case from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028#issuecomment-2089789779:254,test,test,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028#issuecomment-2089789779,1,['test'],['test']
Testability,"Seems like the logic was broken. ```; # we test for raw, but check in adata.var_names; elif use_raw and value_to_plot in adata.var_names:; color_vector = adata.raw[:, value_to_plot].X; # use_raw might be false but we still check adata.raw.var_names; elif value_to_plot in adata.raw.var_names:; color_vector = adata[:, value_to_plot].X; ```. Apart from fixing that I also simplify the code above. Fixes #577",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/579:15,log,logic,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/579,2,"['log', 'test']","['logic', 'test']"
Testability,Seems like we don’t have a benchmark for the clipping. Should we add one?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3100#issuecomment-2173601937:27,benchmark,benchmark,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100#issuecomment-2173601937,1,['benchmark'],['benchmark']
Testability,"Separate static analysis, move tests out of the package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1528:31,test,tests,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528,1,['test'],['tests']
Testability,Separate test utils from tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235:9,test,test,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235,2,['test'],"['test', 'tests']"
Testability,Separate testing utils from tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225:9,test,testing,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225,2,['test'],"['testing', 'tests']"
Testability,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/511#issuecomment-470050466:18,test,tested,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-470050466,1,['test'],['tested']
Testability,Set NUMBA_THREADING_LAYER in tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1933:29,test,tests,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1933,1,['test'],['tests']
Testability,"Seurat uses log-transformed and scaled data for analysis, Scanpy uses raw, which method is better?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2110:12,log,log-transformed,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110,1,['log'],['log-transformed']
Testability,"Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1102:331,test,tested,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102,2,['test'],"['tested', 'testing']"
Testability,"Should be possible to turn the y ticks legends on. But I just tested it and didn't work. I will try to fix it. The syntax is:; ```PYTHON; sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True).style(yticklabels=True,row_palette='muted').show(); ```. `style` needs to be used to tune the graphical parameters to avoid overcrowding the parameters list. But I am open to have a discussion on what the users think is best. Documentation is here: https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1321#issuecomment-666170536:62,test,tested,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321#issuecomment-666170536,1,['test'],['tested']
Testability,"Should fix #218. I have tested it, both with all groups and with some restricted groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/221:24,test,tested,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/221,1,['test'],['tested']
Testability,"Should probably figure out what's happening with these tests. @flying-sheep, has this been happening for other PRs?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1014#issuecomment-580247580:55,test,tests,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1014#issuecomment-580247580,1,['test'],['tests']
Testability,Show score name in logging,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/83:19,log,logging,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/83,1,['log'],['logging']
Testability,Show test durations,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2786:5,test,test,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2786,1,['test'],['test']
Testability,"Simple test case; ```; data = sc.read(""pbmc3k.h5ad""); logical_ar = data.var[""name""] == ""RER1""; df = data[:, logical_ar]; df.uns = data.uns # this causes an error ; ```. Causes this error; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-16-8b2cadedfe9b> in <module>(); 1 l = data.var[""name""] == ""RER1""; 2 df = data[:, l]; ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value); 987 # here, we directly generate the copy; 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)); --> 989 self._init_as_actual(adata); 990 self._uns = value; 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode); 816 self._varm = BoundRecArr(varm, self, 'varm'); 817 ; --> 818 self._check_dimensions(); 819 self._check_uniqueness(); 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key); 1692 raise ValueError('Observations annot. `obs` must have number of '; 1693 'rows of `X` ({}), but has {} rows.'; -> 1694 .format(self._n_obs, self._obs.shape[0])); 1695 if 'var' in key and len(self._var) != self._n_vars:; 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/323:7,test,test,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323,1,['test'],['test']
Testability,Simplify tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2575:9,test,tests,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2575,1,['test'],['tests']
Testability,Since this is an overflow any data set with 1000's of cells I can use for this? I think it is Windows specific crash and how python implements sqrt() on windows which probably is a wrapper of the native math library in C. I may be wrong. So will the regression test work in this case?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1061#issuecomment-588274013:261,test,test,261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061#issuecomment-588274013,1,['test'],['test']
Testability,"Since we can’t test this without your help, could you check if passing your own RNG here makes it work?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2275985402:15,test,test,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2275985402,1,['test'],['test']
Testability,"Since we don't know when a release of `pynndescent` will go out, I think it's fine to keep this a little hacky for now. I think it can be less hacky than now doing something like this:. ```python; from_init = pynndescent.NNDescent(train, n_neighbors=15, init_graph=indices); from_init._rp_forest = rp_forest; query_indices_init, query_distances_init = from_scratch.query(test); ```. Once a release of pynndescent comes out we can support doing it the proper way. . I'd say it's up to you whether you want to have the kinda hacky solution or not. I definitely don't want UMAP to be pinned to below 0.5 when we release 1.7 proper, and it would be good for ingest to work with UMAP 0.5. The only downside I see to the kinda hacky solution as an intermediate is that you're fixing it twice. I don't think it'll be hard to go from this to the clean version however. -------------------------. I haven't looked into what needs to happen for the UMAP embedding transfer stuff to work. Is that pretty straight forward?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1589#issuecomment-762553133:371,test,test,371,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1589#issuecomment-762553133,1,['test'],['test']
Testability,"Since we don’t have a chatroom yet, I’ll announce this with an issue. I created the branch stable to have the 1.4 docs without development features, but also the scanpy logo:. ```console; $ git checkout 1.4 -b stable; $ git cherry-pick 4b1504c c78de5b # the logo commits; ```. Once 1.4.1 comes along, we can simply delete it and readthedocs/stable will point to the 1.4.1 tag again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/571:169,log,logo,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/571,2,['log'],['logo']
Testability,Skip louvain-dependent tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1524:23,test,tests,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1524,1,['test'],['tests']
Testability,"Slicing causes inconsistent state when either n_obs or n_vars == 1, resulting in a slice that can no longer be sliced again on the other axis, due to shape inconsistencies between the AnnData and X object. anndata 0.6.11, scanpy 1.3.2, WSL/Ubuntu. Test case:; ```; import scanpy.api as sc; data = sc.read('example-dataset/data.h5ad'); >>> data.shape, data.X.shape, data._X.shape; ((2638, 1838), (2638, 1838), (2638, 1838)); >>> slice = data[0, :]; >>> slice.shape, slice.X.shape, slice._X.shape; ((1, 1838), (1838,), (1, 1838)); >>> slice[:, 0]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__; return self._getitem_view(index); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view; return AnnData(self, oidx=oidx, vidx=vidx, asview=True); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__; self._init_as_view(X, oidx, vidx); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view; self._init_X_as_view(); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 741, in _init_X_as_view; X = self._adata_ref.X[self._oidx, self._vidx]; IndexError: too many indices for array; >>> slice[0]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__; return self._getitem_view(index); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view; return AnnData(self, oidx=oidx, vidx=vidx, asview=True); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__; self._init_as_view(X, oidx, vidx); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 726, in _init_as_view; self._init_X_as_view(); File ""/cellxgene/venv/lib/python3.6/site-packages/an",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/332:248,Test,Test,248,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332,1,['Test'],['Test']
Testability,"So I just reproduced this error for `sc.pp.log1p()` using my own data after using the `sc.pp.downsample_counts()` function. It might have to do with that?. i noticed that `sc.pp.downsample_counts()` returns `np.int64` rather than `np.float64` I reckon that's what the log transformation is complaining about. If I add the line:; ```; adata.X = adata.X.astype(np.float64); ```; after the downsampling call, it works again. Maybe add that to `sc.pp.log1p()`? Or change `sc.pp.downsample_counts()` to return `np.float64`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475709600:268,log,log,268,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475709600,1,['log'],['log']
Testability,"So I was writing a test for `rank_genes_groups_df` from #619 when I got some results that seem pretty wrong. Here's an example:. ```python; import scanpy as sc. import numpy as np; import pandas as pd; from scipy import stats. from itertools import repeat, chain. # Making data where ""gene0"" is definitely differentially expressed. a = np.zeros((20, 3)); a[:10, 0] = 5; adata = sc.AnnData(; a,; obs=pd.DataFrame(; {""celltype"": list(chain(repeat(""a"", 10), repeat(""b"", 10)))},; index=[f""cell{i}"" for i in range(a.shape[0])]; ),; var=pd.DataFrame(index=[f""gene{i}"" for i in range(a.shape[1])]),; ). # Running differential expression with t-test:. sc.tl.rank_genes_groups(adata, groupby=""celltype""); print(adata.uns[""rank_genes_groups""][""pvals""][""a""]); # array([1., 1., 1.]) # This seems wrong. sc.tl.rank_genes_groups(adata, groupby=""celltype"", method=""t-test""); print(adata.uns[""rank_genes_groups""][""pvals""][""a""]); # array([1., 1., 1.]) # This also seems wrong. # Checking to make sure I'm not forgetting something obvious; print(stats.ttest_ind([0,0,0,0,0], [5,5,5,5,5])); # Ttest_indResult(statistic=-inf, pvalue=0.0) # This seems right. # Wilcoxon seems fine:. sc.tl.rank_genes_groups(adata, groupby=""celltype"", method=""wilcoxon""); print(adata.uns[""rank_genes_groups""][""pvals""][""a""]); # array([1.57052284e-04, 1.00000000e+00, 1.00000000e+00]) # This seems right; ```. `""logreg""` on the other hand, throws an error:. ```python; sc.tl.rank_genes_groups(adata, groupby=""celltype"", method=""logreg""); <ipython-input-7-29e46f287a31> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby=""celltype"", method=""logreg""). ~/github/scanpy/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 397 adata.uns[key_added]['scores'] = np.rec.fromarrays(; 398 [n for n in rankings_gene_scores],; --> 399 dtype=[(rn, 'float32') for rn in groups_order_save]); 400 adata.uns[key_added",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/620:19,test,test,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620,3,['test'],['test']
Testability,"So actually, I run a test on a fresh docker image (with this [Dockerfile](https://gist.github.com/pwl/005c781cbe19f5e961b59366f738caaf)) and it still fails to install scanpy with the same error. I had some success with changing the default python encoding to utf-8 as shown in the Dockerfile but it only works when calling python3 directly and not for pip3. However, it worked with python2. I guess python3 is not supported by scanpy, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43#issuecomment-343252579:21,test,test,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43#issuecomment-343252579,1,['test'],['test']
Testability,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668:185,log,log,185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668,1,['log'],['log']
Testability,"So for a fix, we’d simply need to change. https://github.com/scverse/scanpy/blob/414092f68b4b40aa99153556377c32839b392636/scanpy/preprocessing/_highly_variable_genes.py#L197-L199. into. ```py; X = X.copy(); if 'log1p' in adata.uns_keys() and adata.uns['log1p'].get('base') is not None:; X *= np.log(adata.uns['log1p']['base']); np.expm1(X, out=X); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2668#issuecomment-1766402734:295,log,log,295,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668#issuecomment-1766402734,1,['log'],['log']
Testability,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2112322713:150,log,logs,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2112322713,2,['log'],['logs']
Testability,"So it will only work on non-negative expression values without any pre-process?; I guess that make sense, thank you for the reply. The version of the package:. scanpy==1.4.6 anndata==0.7.1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. The AnnData objects were all read through same commands without any modification. sc.read_10x_h5(filepath, gex_only=False). the dataset I used to test them are:. https://support.10xgenomics.com/single-cell-vdj/datasets/2.2.0/vdj_v1_hs_nsclc_5gex; https://support.10xgenomics.com/single-cell-gene-expression/datasets/3.0.0/pbmc_10k_protein_v3; https://support.10xgenomics.com/single-cell-gene-expression/datasets/3.0.0/malt_10k_protein_v3. It appears to me that it only works on the v2 nsclc h5 data. I was trying to merge the three data sets and run through SAM to compare with the result of BBKNN, didn't work. So I tried to run each of them individually in the loop. I guess it won't work on CITESeq data without other processing?. I tried removed all the antibody read counts from adata.X and ran it once, still got same error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1157#issuecomment-614976989:457,test,test,457,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157#issuecomment-614976989,1,['test'],['test']
Testability,"So one small update here -- it works like a charm for categorical variables, but not for continuous variables.; e.g.; > sc.pl.umap(testData, save = fileName, color='CCL5',s=50,frameon=False,legend_loc = None). Still gives something like a legend:; ![image](https://user-images.githubusercontent.com/10536275/99786010-40234a80-2b1e-11eb-83ab-77c9341dab05.png). Presumably this is because the color strip on the right is not actually a legend in the underlying matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1502#issuecomment-731065768:131,test,testData,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502#issuecomment-731065768,1,['test'],['testData']
Testability,"So the reason you didn't get this before, would be that if you do a `sc.tl.rank_genes_groups()` call with default parameters, you compare the expression in one cluster with the expression in the rest of the dataset. The ""rest of the dataset"" has changed, so you could now get -ve average expression for genes in the ""rest of the dataset"". This will likely create -ve fold changes, which cannot be logged and probably give you `NaN`. This is hiding a signal that is actually there, and not because the gene is not actually differentially expressed. > I did a rescale of my data to 10 again but unfortunately the same warning is happening!; What do you mean by this?. Turning negative values to 0, doesn't mean you lose the data. You have some expression space, of which 0 is a valid number. The question is really what does a negative expression value mean after MAGIC? Is it just a confidence of the gene not being expressed? Then putting it to zero makes sense. Again... if you ignore this, you will just ignore particular genes which are likely differentially expression, because MAGIC has rescaled the expression values in the ""rest of the dataset"" to a negative value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494353628:397,log,logged,397,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494353628,1,['log'],['logged']
Testability,"So we've just put out a release of 1.7.0rc1, and will be releasing it proper soon.; I'm looking at making a 1.6.1 release where the only change is pinning umap, but there are some CI issues (largely tests failing due to Matplotlib outputs changing slightly).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579#issuecomment-760014261:199,test,tests,199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579#issuecomment-760014261,1,['test'],['tests']
Testability,"So you should easily be able to see that the null hypothesis is not valid by the distribution of p-values for all genes in one rank_genes_groups test. If it is valid, this distribution should be uniform. In that case it's only a multiple testing problem... I would guarantee you that it's not uniform though. Cell type labels from expression-independent sources should not have the same confounding effect. However, I would bet you can trace back all biological annotations of cell types back to expression.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-425395345:145,test,test,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-425395345,2,['test'],"['test', 'testing']"
Testability,"So, I'm not too surprised to see this, since I don't think much of the distributed stuff has good testing, and I'm not too familiar with it. I believe the `AnnData` constructor is converting the array. You can get around this by assigning X to be a dask array, e.g.:. ```python; a = ad.AnnData(np.ones((1000, 100))); a.X = da.from_array(a.X); type(a.X); # dask.array.core.Array; ```. Better support for dask arrays would be a great feature request and series of additions to anndata. I think this is the endemic numeric python problem of ""these things are all like arrays, so can kinda use the same API, but in practice every type needs to be special cased"". > but there's a lot of other stuff happening before & afterwards in normalize_total() which I haven't looked at much. Yeah, I think this function has built up some cruft. I've opened a PR to streamline this #1667, but will need to check with people more familiar with the code. The private method should handle all of the computation, while the outer wrapper will do more argument handling/ getting data out of the `AnnData`/ assigning it back. > What combinations of inputs to _normalize_data() need to be supported. I believe `counts` should always be generated from `X`, so we don't need to worry about the combinations of types.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1663#issuecomment-782803190:98,test,testing,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663#issuecomment-782803190,1,['test'],['testing']
Testability,"So, bumping pandas to above 2.0 fixes most of the plotting tests. Almost all the differences were in ordering, and frequently where the ordering would change, but the dendrogram being displayed would not. It's not immediately obvious to me which piece of code is the problem, so I am going to temporarily bump the required pandas version and come back to it after resolving the other remaining issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1903981693:59,test,tests,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1903981693,1,['test'],['tests']
Testability,"So, that dataset is used pretty extensively in the tests, and especially around plotting (plus it's actually shipped with the library). I don't think we're likely to modify it, given that it's used so heavily as a reference. What do you need it for, and could you use `pbmc3k_processed` for that purpose?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1762#issuecomment-807908934:51,test,tests,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1762#issuecomment-807908934,1,['test'],['tests']
Testability,"So, we could also not early load `scanpy.testing._pytest` or load `pytest-cov` first?. I would like to keep the `xdist` support and use a similar interface.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2874#issuecomment-1956920175:41,test,testing,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2874#issuecomment-1956920175,1,['test'],['testing']
Testability,"So, without any evidence, I think it should be fine. The reason I had put an error in the first place is that the typical behavior is to pass log normalized data to this HVG function, and I didn't want people to run this incorrectly. I think another solution would be to just throw a UserWarning, though in a way I like the idea of having an argument that disables the `check_nonnegative_integer()`. I think I would call it `enforce_counts_seurat_v3` though. You might also consider bypassing the check if the flag is set, because it can be slowish for large datasets.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1642#issuecomment-776841793:142,log,log,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1642#issuecomment-776841793,1,['log'],['log']
Testability,Solution here is `adata.obs.index = adata.obs.index.astype(str)`. Should be called by default if this assertionerror is raised.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/747#issuecomment-1242183366:102,assert,assertionerror,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747#issuecomment-1242183366,1,['assert'],['assertionerror']
Testability,"Solved same problem for me as well. . For the record, the output of `sc.logging.print_versions()` in my conda environment is: . `scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.2 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/948#issuecomment-571371654:72,log,logging,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948#issuecomment-571371654,1,['log'],['logging']
Testability,"Some changes to @giovp #1512, just pushing here so they are visible. Still needs going through the tests to update offsets, and some doc tweaks (behaviour of `na_color`, what `spot_size` is, move `scale_factor` to be `spatial` only).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1580:99,test,tests,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1580,1,['test'],['tests']
Testability,Some changes to normalize_total and tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/605:36,test,tests,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/605,1,['test'],['tests']
Testability,"Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do?. * Let's us delete `_get_data_points`, an awful function; * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element; * Move spatial specific code to spatial specific functions; * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated?. I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed?; * Isn't it the same amount of keystrokes?; * How useful is `""all""`?. I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented?. We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement?. ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>; <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-931",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1538:721,test,testing,721,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538,2,['test'],"['testing', 'tests']"
Testability,"Some notes from a brief discussion with Sergei. 1. make helper functions for each method so that level of indentation and length is decreased; 2. replace lists `rankings_gene_...` by DataFrame; 3. think about simplifying the wilcoxon implementation, compare with scipy stats implementation and potentially update the test; 4. investigate how the logreg implementation behaves for different choices of reference groups",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/723#issuecomment-526079225:317,test,test,317,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/723#issuecomment-526079225,2,"['log', 'test']","['logreg', 'test']"
Testability,"Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python; if plot:; from .. import plotting as pl # should not import at the top of the file; pl.filter_genes_dispersion(filter_result, log=True); ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python; In [1]: import numpy as np; ...: import pandas as pd; ...: import scanpy.api as sc; ...: ; ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures; ...: sc.logging.print_versions(); /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.; from ._conv import register_converters as _register_converters; adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file.; In [3]: sc.pp.recipe_zheng17(adata, plot=True); running recipe zheng17; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-3-c19f237f1c6e> in <module>(); ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy); 106 if plot:; 107 from .. import plotting as pl # should not import at the top of the file; --> 108 pl.filter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/153:304,log,log,304,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153,2,['log'],"['log', 'logging']"
Testability,Some of the tests fail for reasons unrelated to the PR (`test_preprocessing`). Locally all tests pass for me. Any ideas?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/661#issuecomment-495233581:12,test,tests,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495233581,2,['test'],['tests']
Testability,"Some refactoring:. - single-source AggType in aggregate tests; - fix warnings in aggregate; - fix logs in pca, umap, and tsne",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3186:56,test,tests,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3186,2,"['log', 'test']","['logs', 'tests']"
Testability,"Some small benchmarks for 32 cores with `CSR.shape=(196943, 20867)`:; | axis |old|new|; |------|-----|------|; |minor|804 ms|96 ms|; |major|520 ms|40 ms|",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3015#issuecomment-2066134612:11,benchmark,benchmarks,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3015#issuecomment-2066134612,1,['benchmark'],['benchmarks']
Testability,"Some tests are broken, here are some fixes for that. * Visium reference test was just wrong, dots should have been transparent.; * igraph 0.9.11 has different results for `""fr""` layout, updated tests accordingly (https://github.com/igraph/python-igraph/issues/545); * 32 bit PCA computation is now accurate within 32 bit rounding, so tests checking for random seed changes have been disabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2274:5,test,tests,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2274,4,['test'],"['test', 'tests']"
Testability,"Some tests are still failing, but not because of `uns/spatial`. They all throw errors along these lines:; ```; assert 'Error: Image files did not match.\n RMS Value: 15.114361035293829\n; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-600196432:5,test,tests,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-600196432,2,"['assert', 'test']","['assert', 'tests']"
Testability,Some things on pancreas dataset; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/ingest_pancreas.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-527675546:75,benchmark,benchmarks,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-527675546,1,['benchmark'],['benchmarks']
Testability,"Somehow, updating anndata fixes the PCA test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1915626230:40,test,test,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1915626230,1,['test'],['test']
Testability,"Something like this should work. Note, this is not tested. ```pytb; target_cells = 5000. adatas = [adata[adata.obs[cluster_key].isin(clust)] for clust in adata.obs[cluster_key].cat.categories]. for dat in adatas:; if dat.n_obs > target_cells:; sc.pp.subsample(dat, n_obs=target_cells). adata_downsampled = adatas[0].concatenate(*adatas[1:]); ```. Hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/987#issuecomment-574063629:51,test,tested,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/987#issuecomment-574063629,1,['test'],['tested']
Testability,Something went wrong ... Please have a look at my logs. It seem that the branch you are trying to backport to does not exists.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1628#issuecomment-781794583:50,log,logs,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1628#issuecomment-781794583,1,['log'],['logs']
Testability,"Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>; <summary> </summary>. ```; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call; item.runtest(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest; self.ihook.pytest_pyfunc_call(pyfuncitem=self); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/loggi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1736:10,test,tests,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736,2,['test'],"['test', 'tests']"
Testability,"Sorry @ivirshup , still not quite getting what you're after. The underlying issues were with a missing .copy() (now added) and with log'd values getting into the simulation process (which is now prevented with a simple code rearrangement). I think those fixes are pretty self-evident. Non-integer values don't necessarily mean normalised or log'd data, so I can't add a check in the code for that. I could add a check on the values of the simulated doublets, that they are the sum of the parent counts we send to scrublet's simulate function, but that seems outside the scope of these fixes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2025#issuecomment-963353519:132,log,log,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2025#issuecomment-963353519,2,['log'],['log']
Testability,"Sorry I missed the logging. I also didn't see the `sc.settings.logfile` option, which obviously makes absolute sense and is convenient to have persistent records when working interactively with anndata objects. I guess just more consistent logging across scanpy functions would be really great. Something like `sc.logging.get_operations(adata_id=id(adata))` would also be super cool, but would it be able to retrieve records of operations performed within rounds of object serialization?. e.g.:; ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""). adata = sc.read(""./cache/01_simple_process.h5ad""); sc.pp.scale(adata); adata.write(""./cache/01_simple_process.h5ad""); print(sc.logging.get_operations(adata_id=id(adata))); ```; would probably forget the first set of operations?; ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""scale"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```; I guess one solution would be to follow the path of ids up the log to retrieve all which seems doable, so this could be a good system. The one thing this wouldn't cover though is persistence within the h5ad object itself. This would be useful in the case of sharing the object with someone for example. As I mentioned before, I'm not sure this is a widespread use case yet, but could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/472#issuecomment-464691691:19,log,logging,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464691691,6,['log'],"['log', 'logfile', 'logging']"
Testability,"Sorry about that bug and thanks for reporting it. It only occurred with the `copy` parameter set, which is why no one noticed it till now. The bug is fixed: https://github.com/theislab/scanpy/commit/f6a41f140a646c350ab12d8bd6aeff7499df069e. The docs are updated, there's now an example: http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.normalize_per_cell.html. I wrote a test that checks that this doesn't break again in the future: https://github.com/theislab/scanpy/blob/f6a41f140a646c350ab12d8bd6aeff7499df069e/scanpy/tests/preprocessing.py#L11-L31. There will be a new release 0.3 with many improvements tomorrow. Cheers,; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/47#issuecomment-344400517:379,test,test,379,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/47#issuecomment-344400517,2,['test'],"['test', 'tests']"
Testability,"Sorry about the delay, I've been working on some writing about this stuff (though from a different perspective). I'm not sure `k` is ""meant"" to have any particular effect, since these methods weren't designed for KNN graphs. I'd also argue if the parameters are analogous, there's an advantage of simplicity to just choosing one of them. I've got some plots for the effect of resolution and number of neighbors on the size of clusters which are found. This is for the 10x example dataset with 10k pbmcs using the v3 chemistry. What I've done is build the networks at 5 different values of k, four times each (different random seeds). For each of those networks, I ran clustering at 50 different resolutions (`np.geomspace(0.05, 20, 50)`). Here are the maximum cluster sizes found for each combination of k and resolution for the unweighted and weighted graph (color bar is logscale, from 1 to 6000, but I couldn't get useful ticks to work):. ![image](https://user-images.githubusercontent.com/8238804/56872793-2c158500-6a70-11e9-91fd-ee7aac91b811.png); ![image](https://user-images.githubusercontent.com/8238804/56872794-2d46b200-6a70-11e9-9607-67147d7493f9.png). Overall, pretty similar. Now, the minimum cluster sizes (color scales are different, but you'll see why):. ![image](https://user-images.githubusercontent.com/8238804/56872836-a34b1900-6a70-11e9-9a60-7b2a51b53da2.png); ![image](https://user-images.githubusercontent.com/8238804/56872837-a6460980-6a70-11e9-8722-be6576f605e7.png). This looks to me like using the weighted graph allows identifying small clusters even at low resolutions. The cluster of 25 cells looks like megakaryocytes, and are being detected at pretty much every clustering (996 out of 1000) using the weighted graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-487432411:873,log,logscale,873,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-487432411,1,['log'],['logscale']
Testability,"Sorry about the super late response and thank you for the PR, @a-munoz-rojas. I have not read most of the above discussion, yet. Right now, I just wanted to note that (@a-munoz-rojas), the tests are failing as the wilcoxon test seems to yield different results, now. I don't know whether it's just marginal, but it should be clarified; users should still get the same results as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-426409855:189,test,tests,189,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-426409855,2,['test'],"['test', 'tests']"
Testability,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**; > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py; def test_no_filter_genes(flavor):; """"""Test that even with 0 columns in the data, n_top_genes is respected.""""""; adata = sc.datasets.pbmc3k(); means, _ = _get_mean_var(adata.X); assert (means == 0).any(); sc.pp.normalize_total(adata, target_sum=10000); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000); assert adata.var[""highly_variable""].sum() == 10000; test_no_filter_genes(""seurat""); ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3157#issuecomment-2255721845:384,test,test,384,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157#issuecomment-2255721845,6,"['Test', 'assert', 'test']","['Test', 'assert', 'test']"
Testability,"Sorry for late reply, wasn't catched by the previous test because the test set the size of the spot for plotting.; Current test:; ```python; sc.pl.spatial(; adata,; color=""array_row"",; groups=[""24"", ""33""],; crop_coord=(100, 400, 400, 100),; alpha=0.5,; size=1.3,; ); ```; Shall i remove the `size` param from this test or make a new one?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1255#issuecomment-640493235:53,test,test,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255#issuecomment-640493235,4,['test'],['test']
Testability,"Sorry for the PR, was not prop tested.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/219#issuecomment-408230756:31,test,tested,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/219#issuecomment-408230756,1,['test'],['tested']
Testability,"Sorry for the late reply, the notifications for this thread got sent to my spam folder. @giovp . - I think so! It’s not difficult to extend it to more latent variables. We could allow them to specify any column(s) in the `obs` DataFrame.; - Hmm, I think `statsmodels` can do regression on lots of different models, but from the source paper it sounds like using Poisson was simplest/fastest and did not affect the results too much when compared to negative binomial regression. I think parameter estimation for other models might be a bit more involved.; - I think that would be pretty straightforward. What outputs are you referring to, specifically?; - I’ve been testing by computing correlations between the genes from the python and R implementations. You could also compare rank-ordering of cells by variance. Another approach might be to compare the output of downstream analysis methods (like clustering) to see if the results are similar, and compare to the output of unprocessed data as a negative control.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-786183077:665,test,testing,665,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643#issuecomment-786183077,1,['test'],['testing']
Testability,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter!. I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-531683547:738,log,logging,738,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819#issuecomment-531683547,1,['log'],['logging']
Testability,"Sorry for the super-late response! I just worked through almost 60 issues starting with the most recent, this is the last one... Sorry about that. `paga_path` requires computing a pseudotime before-hand as one needs to order cells at single-cell resolution along the path. I added a more meaningful error message stating that. PS: Now, there is also a test for PAGA [here](https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_paga_paul15_subsampled.py), making sure that the canonical use ([here](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/paul15/paul15.ipynb)) remains unchanged.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/328#issuecomment-435736335:352,test,test,352,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328#issuecomment-435736335,2,['test'],"['test', 'tests']"
Testability,"Sorry this is a little off topic, but it's something I've found useful:. @LuckyMD and anyone else looking for an interactive volcano plot, I've been using [`hvplot`](https://hvplot.pyviz.org) in my notebooks. A volcano plot can be made from DE data frame with something like:. ```python; de_df.hvplot.scatter(; ""logfoldchanges"", ""pvals_adj"", ; flip_yaxis=True, logy=True, ; hover_cols=[""names""]; ); ```. <details>; <summary> Complete example using scanpy </summary>. ```python; import pandas as pd; import numpy as np; import hvplot.pandas; import scanpy as sc. def rank_genes_groups_df(adata, group, pval_cutoff : float =None, logfc_cutoff=None): ; d = pd.DataFrame() ; for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']: ; d[k] = adata.uns[""rank_genes_groups""][k][group] ; if pval_cutoff is not None: ; d = d[d[""pvals_adj""] < pval_cutoff] ; if logfc_cutoff is not None: ; d = d[d[""logfoldchanges""].abs() > logfc_cutoff] ; return d. pbmcs = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(pbmcs, ""bulk_labels"", n_genes=pbmcs.var_names.size); de_df = rank_genes_groups_df(pbmcs, ""CD34+""). de_df.hvplot.scatter(; ""logfoldchanges"", ""pvals_adj"", ; flip_yaxis=True, logy=True, ; hover_cols=[""names""]; ); ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-473498942:312,log,logfoldchanges,312,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-473498942,6,['log'],"['logfoldchanges', 'logy']"
Testability,"Sorry yeah, the branch name might not be accurate when we’re done. What dependency causes those mismatches? Locally the image comparisons succeed unless I create a venv …. > master_clustermap.png; > ; > I believe the difference is just the margin, so we should be good to just change the test image. nah, it also has an ugly white gap between tree and heatmap, probably caused by the same reason as the other one …. /edit: the space seems exactly enough to hold the color bar’s x tick labels, that might be the cause. /edit2: also appears without scanpy’s style or anything: mwaskom/seaborn#1953",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1015#issuecomment-581052169:288,test,test,288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1015#issuecomment-581052169,1,['test'],['test']
Testability,"Sorry! I've been preoccupied with some stuff on my end (and also super distracted by this coronavirus hullabaloo). I'll add the requested tests, soon. . EDIT: Done!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-600646753:138,test,tests,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-600646753,1,['test'],['tests']
Testability,"Sorry, but I think there still is a range-related bug in the tests:; ```; E matplotlib.testing.exceptions.ImageComparisonFailure: Image sizes do not match expected size: (376, 439, 3) actual size (376, 440, 3); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207#issuecomment-405943292:61,test,tests,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207#issuecomment-405943292,2,['test'],"['testing', 'tests']"
Testability,"Sorry, just realizing that this function expects logarithmized data. My fault.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763#issuecomment-517851311:49,log,logarithmized,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763#issuecomment-517851311,1,['log'],['logarithmized']
Testability,"Sorry, no, I didn't open a PR since I hadn't heard back regarding above comments. Fine to close it in favour of #1563, although it only concerns pre-commit hooks, right? The original idea of this issue was to make the dev installation easier, i.e. installing all required packages to run the full code base, tests etc. This currently doesn't happen when installing through `pip install "".[dev]""`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1419#issuecomment-776896243:308,test,tests,308,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1419#issuecomment-776896243,1,['test'],['tests']
Testability,"Sorry, there is a small bug in the wilcoxon method, that might hit sometimes. @a-munoz-rojas, it should be resolved after merging your fix, don't you think so? I'd be happy to move forward as soon as the code-overhead issue around double logarithmization is fixed. Should be very simple. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530#issuecomment-474301716:238,log,logarithmization,238,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-474301716,1,['log'],['logarithmization']
Testability,Sounds good - added an entry to the release note and updated the tests to not use the parameterization.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2859#issuecomment-1947513767:65,test,tests,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2859#issuecomment-1947513767,1,['test'],['tests']
Testability,"Sounds good, we are currently hosting the whole scanpy-scripts as a bioconda package, but we could look into having it as pip installable as well. Does this means that scanpy administrators are happy to have the scanpy-scripts code poured here to make them pip installable, or that you want to contribute the pip packaging to the repo where we currently have scanpy-scripts? We have travis testing for our scripts layer, that would make maintenance easier on your side, as it would detect any changes on scanpy that break the scripts layers (taking you to only break API if extremely necessary - in turn making your tool more stable for external users).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/281#issuecomment-437031478:390,test,testing,390,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281#issuecomment-437031478,1,['test'],['testing']
Testability,"Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:; - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size); - The structure of a probe barcode h5 file is; ```; /matrix Group; /matrix/barcodes Dataset {4987}; /matrix/data Dataset {17581240/Inf}; /matrix/features Group; /matrix/features/feature_type Dataset {21178}; /matrix/features/filtered_probes Dataset {21178}; /matrix/features/gene_id Dataset {21178}; /matrix/features/gene_name Dataset {21178}; /matrix/features/genome Dataset {21178}; /matrix/features/id Dataset {21178}; /matrix/features/name Dataset {21178}; /matrix/features/probe_region Dataset {21178}; /matrix/features/target_sets Group; /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}; /matrix/filtered_barcodes Dataset {4987}; /matrix/indices Dataset {17581240/Inf}; /matrix/indptr Dataset {4988}; /matrix/shape Dataset {2}; ```; - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - thi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2470:752,test,tests,752,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470,1,['test'],['tests']
Testability,Specify var subsets for stats testing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1744:30,test,testing,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744,1,['test'],['testing']
Testability,Speed up test collection,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/327:9,test,test,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327,1,['test'],['test']
Testability,Split up PCA tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3268:13,test,tests,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3268,1,['test'],['tests']
Testability,"Still need to figure out why paga test fails. Also `simplicial_set_embedding` from umap requires data and metrics. Data is `adata.X` and i set `metrics='euclidean'`, but this is not clear. Fixes #522",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576:34,test,test,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576,1,['test'],['test']
Testability,"Still the error message could be a lot better. I’ve made the same mistake,; it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>; wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763#issuecomment-517929825:99,log,log,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763#issuecomment-517929825,1,['log'],['log']
Testability,Stop tests from writing files everywhere,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2555:5,test,tests,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2555,1,['test'],['tests']
Testability,"Suggested changes to the test function, and harmony_timeseries",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1007:25,test,test,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1007,1,['test'],['test']
Testability,"Sure thing, I'll make a PR now. I'll add a parameter and leave the default assuming that the data passed is log-transformed. Sorry for missing this earlier! I also added a fix for an indexing bug that was left-over from the original chunking done during the wilcoxon test. I'll add the details to the PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-470319979:108,log,log-transformed,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470319979,2,"['log', 'test']","['log-transformed', 'test']"
Testability,"Sure! @ivirshup figured out independently within 2 hours of me that `is_string_dtype` now works differently: theislab/anndata#107. The fix needed three parts:. 1. I fixed the tests to actually work (they were broken since forever because they used a hardcoded file name instead of `tmp_path`, and therefore reused the same file); 2. I pulled his changes, which covered the writing portion of the needed fixes; 3. I fixed the reading portion in theislab/anndata@4c8163129302391419c7ee4943e7fb766599e2a2; 4. I fixed the highly variable genes function that relied on a slightly different behavior of series in 0.23",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460184736:175,test,tests,175,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460184736,1,['test'],['tests']
Testability,"Sure, I’ll happily elaborate!. As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py; def test_score_genes():; adata = TODO # create test data here; gene_list = TODO; gene_pool = TODO; gene_list, gene_pool, get_subset = _check_score_genes_args(; adata, gene_list, gene_pool, use_raw=use_raw, layer=layer; ). bins = list(_score_genes_bins(; gene_list,; gene_pool,; ctrl_as_ref=False, # needs to be renamed; ctrl_size=50,; n_bins=25,; get_subset=get_subset,; )). assert 0 not in map(len, bins); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3167#issuecomment-2264758331:51,test,test,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167#issuecomment-2264758331,8,"['assert', 'test']","['assert', 'test', 'tests']"
Testability,"Sure, only problem is that there’s now so much spatial-specific code in `embedding`. But we can fix that after this PR. I’d still like to see this change though:. > It’s good to have [a test], but it should of course also make sure that the flipping works!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1078#issuecomment-594055279:186,test,test,186,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1078#issuecomment-594055279,1,['test'],['test']
Testability,TED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62636,test,tests,62636,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,TED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.para,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72133,test,testing,72133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,TODO: add quantitative tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2703#issuecomment-1787395391:23,test,tests,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703#issuecomment-1787395391,1,['test'],['tests']
Testability,"TODO: creation of zarr store conditional on failed test, and then do the upload conditional on file existence",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3069#issuecomment-2203028566:51,test,test,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069#issuecomment-2203028566,1,['test'],['test']
Testability,TODO: test. Fixes #834,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/835:6,test,test,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/835,1,['test'],['test']
Testability,TODO:. - [x] tests; - [x] go over changes if they’re good or the code should be changed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/841:13,test,tests,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/841,1,['test'],['tests']
Testability,"TODOs:. 1. Figure out why some tests are passing when they shouldn't (hence why I pushed the branch, curious about CI). UPDATE: `tol` for `matplotlib.testing.compare.compare_images` is too high for a sparse-ish plot like `rank_genes_groups`. This is somewhat worrying so will need to be amended. Other than that, changed plotting outputs make sense so this should be resolved.; 2. Check with scanpy tutorials to see what needs to be changed there as well, if anything (if needed, the two PRs should be merged in tandem). The following use leiden in some capacity:; a. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; b. https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html; c. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html; d. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html; 3. Do a large dataset test - check NMI for accuracy of the new default against the old one, check speed to confirm what we're doing makes sense (although this was covered, it seems, in #1053), and scalability",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210:31,test,tests,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210,3,['test'],"['test', 'testing', 'tests']"
Testability,TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69997,test,tests,69997,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['tests']
Testability,TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70483,test,testing,70483,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70650,test,testing,70650,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['test'],['testing']
Testability,Test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2936:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2936,1,['Test'],['Test']
Testability,Test against pre-release dependencies,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2478:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478,1,['Test'],['Test']
Testability,Test all PCA param combinations,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3294:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3294,1,['Test'],['Test']
Testability,Test are failing because of the new version of dask.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/651#issuecomment-517224731:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-517224731,1,['Test'],['Test']
Testability,Test are passing now! . @flying-sheep can you tell me more about the images that appear in the automatic API documentation?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207#issuecomment-406266348:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207#issuecomment-406266348,1,['Test'],['Test']
Testability,Test case failure with test_visium_default not having any visible data points,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048,1,['Test'],['Test']
Testability,Test case is included in https://github.com/theislab/scanpy/pull/1669,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1199#issuecomment-800058390:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199#issuecomment-800058390,1,['Test'],['Test']
Testability,Test codecov code annotation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2847:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2847,1,['Test'],['Test']
Testability,"Test collection was taking a while, this should cut that time by about 90%. For some reason, pytest test collection seems dependent on the number of files the `python_files` parameter matches. Having a more specific path under `testpaths` doesn't – which would be a simpler change. Should close #326.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/327:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/327,3,"['Test', 'test']","['Test', 'test', 'testpaths']"
Testability,Test failing plot,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1773:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1773,1,['Test'],['Test']
Testability,Test fails seem unrelated to this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1081#issuecomment-595784602:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1081#issuecomment-595784602,1,['Test'],['Test']
Testability,"Test failures are not mine, seems like numba breaks on python 3.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-777364572:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-777364572,1,['Test'],['Test']
Testability,"Test full Dask support for `log1p`, `normalize_per_cell`, `filter_cells`/`filter_genes`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2814:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2814,1,['Test'],['Test']
Testability,"Test full dask support for `log1p`, `normalize_per_cell`, `filter_cells`/`filter_genes`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2813:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2813,1,['Test'],['Test']
Testability,Test hashsolo docs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1541:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1541,1,['Test'],['Test']
Testability,Test new upperlimit for dask for rapids 24.10. ; https://github.com/scverse/rapids_singlecell/actions/runs/11325725585/job/31493220507?pr=277,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3281:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3281,1,['Test'],['Test']
Testability,Test on 3.5,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/161:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/161,1,['Test'],['Test']
Testability,Test rtd failures,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1900:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1900,1,['Test'],['Test']
Testability,Test that the fallback fr layout works,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1026:0,Test,Test,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1026,1,['Test'],['Test']
Testability,"Tested scvelo's vs scanpy's `pl.scatter` (will share test modules + notebooks later). scvelo entails scanpy's functionality (and adds a couple extensions as explained above), except for the following:; - we don't have `left_margin` and `right_margin` attributes (don't think they're necessary).; - point `size` convention acc. to scanpy (if settings._rcParams_style == 'scanpy') else slightly adjusted.; - when `basis` is in `.var_names`, then an unspliced/spliced phase portrait is plotted (I guess that's not needed in scanpy?). Further we have some more defaults:; - if `basis` is None, then use a default basis in the given order if available: umap, tsne, pca; - if `color` is None, then use a default color in the given order if available: clusters, louvain; - if `frameon` is None, then only set frame if it is not embedding and axes values do matter.; - if `color_map` is None, then use 'viridis_r' if vals in [0,1], else matplotlib's default. Further, these can be used interchangeably: `size` and `s`, `color` and `c`, `color_map` and `cmap`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/617#issuecomment-554758886:0,Test,Tested,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554758886,2,"['Test', 'test']","['Tested', 'test']"
Testability,Testing codecov comment to make seeing coverage easier.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1704:0,Test,Testing,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1704,1,['Test'],['Testing']
Testability,"Testing if I did the pyproject.toml right for pep-621. Still need to decide if it's also worth updating it for the 1.8.x branch, or if this should wait until we're near `1.9`. Fixes #1776 if merged.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2042:0,Test,Testing,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2042,1,['Test'],['Testing']
Testability,Testing plotting functions,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/204:0,Test,Testing,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/204,1,['Test'],['Testing']
Testability,"Testing some azure stuff for better CI test results. Mainly:. * I don't like what `pytest-azurepipelines` does with warnings; * I'd like to have test coverage; * Azure's is a bit meh (no diffs), maybe we should use codecovs ([example usage](https://github.com/codecov/example-python/blob/74883884e480b523e0db9e92e97264908ecb9b8f/azure-pipelines.yml#L32-L34)); * I like having the test results be easy to read",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1564:0,Test,Testing,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1564,4,"['Test', 'test']","['Testing', 'test']"
Testability,Testing to see if the way versions are being retrieved is the problem,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1902:0,Test,Testing,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1902,1,['Test'],['Testing']
Testability,Testing to see if this will allow github UI for viewing codecov annotations. https://about.codecov.io/blog/announcing-line-by-line-coverage-via-github-checks/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2847:0,Test,Testing,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2847,1,['Test'],['Testing']
Testability,Tests are failing and I suspect that this is caused by an update on seaborn or matplotlib...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1417#issuecomment-693318284:0,Test,Tests,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1417#issuecomment-693318284,1,['Test'],['Tests']
Testability,"Tests are failing, I believe, because the gene_list genes are removed from control genes before random sampling, not after, resulting in a different control gene set. Not quite sure why the difference in scores is so large though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2875#issuecomment-1957270508:0,Test,Tests,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2875#issuecomment-1957270508,1,['Test'],['Tests']
Testability,Tests are working now,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-964557208:0,Test,Tests,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-964557208,1,['Test'],['Tests']
Testability,Tests fail with pytest 8.1 when a `data` dir exists,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:0,Test,Tests,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['Test'],['Tests']
Testability,Tests for spatial functions,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1041:0,Test,Tests,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1041,1,['Test'],['Tests']
Testability,Tests passing! With exception of silly Black formatting issue I've just corrected.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-734758379:0,Test,Tests,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-734758379,1,['Test'],['Tests']
Testability,Tests sometimes have really long logging output,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1736:0,Test,Tests,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736,2,"['Test', 'log']","['Tests', 'logging']"
Testability,Tests were updated to include instances of the requirements.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/304:0,Test,Tests,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/304,1,['Test'],['Tests']
Testability,"Thank you @LuckyMD. Naive question, but what is the advantage of `diffxpy` over `sc.tl.rank_genes_groups`? I read comments above about noise models and technical covariates, but I don't fully understand the model fitting aspect and both methods seem to offer similar tests like T-tests and Wilcoxon rank-sum.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-635821693:267,test,tests,267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-635821693,2,['test'],['tests']
Testability,"Thank you for checking the code. I have also been thinking about possible test(s), the only thing that comes to my mind is to check the output against a fixed reference result, which I could verify on a few different machines. But I'm not sure whether this wouldn't cause problems in the future. This could be troublesome to maintain as the matrix will need be stored somewhere and may need re-checking if e.g. numpy has some relevant updates. I am open to suggestions!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1890#issuecomment-866352349:74,test,test,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890#issuecomment-866352349,1,['test'],['test']
Testability,"Thank you for developing the method, I'm looking forward to being able to use it. One thing that the deviances did was perform a chi-square test on the obtained values, with degrees of freedom based on the number of cells. I was fond of that as it translated into a data-driven cutoff for feature selection rather than requiring some number of top genes. Is there a chance of something similar showing up here? Apologies if this is not the place to ask this, but I'd be even more likely to switch over if I could have the option to avoid the parameterisation that tends to come with HVG identification.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-872954063:140,test,test,140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-872954063,1,['test'],['test']
Testability,"Thank you for the detailed response @mrocklin!. > It would be great to get a slimmed down version of the operations that you're running with pydata/sparse and submit those to the issue tracker there. I will try to produce a test case and post it there. > Another option would be to see if you can swap out Anndata for Xarray. This has been discussed before (https://github.com/theislab/anndata/issues/32) but the sticking point was sparse support.; Perhaps with some of the techniques being discussed in this issue it might become an option again, with all the benefits you outlined. > I could imagine that these might be in scope for NVidia folks to work on in a few months (no promises though). If you wanted to raise these as issues there to track things that would be helpful. Thanks - I've opened issues for these features on the CuPy issue tracker.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-557463310:224,test,test,224,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921#issuecomment-557463310,1,['test'],['test']
Testability,"Thank you for the kind words!. Hm, it's in the [docs in the returns section](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.api.tl.rank_genes_groups.html). Should it be somewhere else?. But you're right, I'm also not completely happy with the name `logfoldchange`. We'll harmonize with what's out there at some point and I'm currently tending to `log2FC` because @davidsebfischer started to using that in `diffxpy` and I guess it's also used in some R tools.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/446#issuecomment-457339569:265,log,logfoldchange,265,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446#issuecomment-457339569,1,['log'],['logfoldchange']
Testability,"Thank you for this! Unfortunately, it breaks the tests. It's such a small change, but I guess @fidelram had something in mind when setting it the way he did...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/525#issuecomment-471318618:49,test,tests,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471318618,1,['test'],['tests']
Testability,"Thank you so much for fielding so many of the issues, @LuckyMD! :smile:. Can we elaborate a bit further on this one, though? For simple two-group comparisons, `rank_genes_groups` with `method='wilcoxon'` (Wilcoxon-Rank-Sum/Mann-Whitney U test) should be a legit choice, shouldn't it? It's used in many of this year's Nature, Cell and Science single-cell papers, it's the default test of Seurat (https://satijalab.org/seurat/de_vignette.html) and several people reported that it performs well in [Sonison & Robinson, Nat Meth (2018)](https://doi.org/10.1038/nmeth.4612). So, I don't think one needs to encourage people to immediately go to the great and powerful MAST, limma and DESeq2. Can you point me to a reference that shows that a Wilcoxon-Rank-Sum test is less _sensitive_? How is this even a useful statement if you don't talk about the false positives you buy in? We should look at an AUC that scans different p-values, right? A bit more than a year ago, @tcallies and I had a full paper draft discussing AUCs for marker gene detection formulated as a classification problem, but we never finished it. In the general setting, it's not at all straightforward to make the evaluation a well-defined problem and other people will for sure have done a better job. Unfortunately, I have never fully caught up with the literature, I fear...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447598981:238,test,test,238,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447598981,3,['test'],['test']
Testability,"Thank you very much @LuckyMD for those insightful comments, that gives me plenty to think about beyond my original question about the mean normalisation being 'distorted' by log transformation. I had not considered how tricky a problem normalisation is. This actually makes me feel that perhaps the long term solution will be mostly experimental rather than computational, through developing better spike-ins. Anyway, I guess this discussion is not a Scanpy issue, so I will close this, but I appreciate your thoughts.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678816818:174,log,log,174,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364#issuecomment-678816818,1,['log'],['log']
Testability,"Thank you very much! I merged this via the command line after adapting to the private module design. I still get a to me cryptic AttributeError from patsy on my Mac, but the tests are fine and on the Linux server it also runs fine:; ```; preprocessing/_combat.py:150: in combat; s_data, design, var_pooled, stand_mean = stand_data(model, data); preprocessing/_combat.py:78: in stand_data; design = design_mat(model, batch_levels); preprocessing/_combat.py:32: in design_mat; model, return_type=""dataframe""); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:291: in dmatrix; NA_action, return_type); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:165: in _do_highlevel_design; NA_action); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:62: in _try_incr_builders; formula_like = ModelDesc.from_formula(formula_like); ../../../miniconda3/lib/python3.6/site-packages/patsy/desc.py:164: in from_formula; tree = parse_formula(tree_or_string); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:148: in parse_formula; _atomic_token_types); ../../../miniconda3/lib/python3.6/site-packages/patsy/infix_parser.py:210: in infix_parse; for token in token_source:; ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:94: in _tokenize_formula; yield _read_python_expr(it, end_tokens); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:44: in _read_python_expr; for pytype, token_string, origin in it:; ../../../miniconda3/lib/python3.6/site-packages/patsy/util.py:332: in next; return six.advance_iterator(self._it); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . code = ''. def python_tokenize(code):; # Since formulas can only contain Python expressions, and Python; # expressions cannot meaningfully c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/398#issuecomment-451762530:174,test,tests,174,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-451762530,1,['test'],['tests']
Testability,"Thank you very much, @falexwolf! I really appreciate the addition to the author list! I'm glad this is useful. I just now added the option to choose which correction method to use, and set benjamini-hochberg as the default, so that should be all set. With regards to the test, I unfortunately don't have experience building those tests, and have limited bandwidth at the moment. So it would probably be best if someone else could extend those tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-429919051:271,test,test,271,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-429919051,3,['test'],"['test', 'tests']"
Testability,"Thank you! :smile: There is also taking the logarithm of the means involved and I'll add this for clarifcation, but of course you're right... there's no logarithm of the variance taken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/104#issuecomment-374291211:44,log,logarithm,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/104#issuecomment-374291211,2,['log'],['logarithm']
Testability,"Thank you! So you say it doesn’t work, but I see a green checkmark. Would you mind adding a test that exposes the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364153382:92,test,test,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364153382,1,['test'],['test']
Testability,"Thank you! This looks great!. What do you think, @ivirshup?. Now, @Koncopd, can you also add a `logg.warn(""default of method has been changed to 't-test' from 't-test_overestim_var'"")`. And actually change the value?. Finally, can you test this on the Scanpy default tutorial and a a test based on the numerical values in addition to the image based tests? https://github.com/theislab/scanpy/blob/7e058a1a6a082e34a101d65fc7ac5e9cb6563220/scanpy/tests/notebooks/test_pbmc3k.py#L109-L111. Thank you very much!. Otherwise, this is good to be merged, IMO.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1081#issuecomment-595724233:96,log,logg,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1081#issuecomment-595724233,6,"['log', 'test']","['logg', 'test', 'tests']"
Testability,Thank you! With “tests” I mean “functions named `test_*` with `assert ...` statements inside”. See here: https://github.com/theislab/scanpy/tree/master/scanpy/tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-493022431:17,test,tests,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493022431,3,"['assert', 'test']","['assert', 'tests']"
Testability,"Thank you!. > step: removed logging of `asctime`, which we never had before. I took that from your logging code in the data science bowl notebook, but I agree: People should add `{asctime}` to all formatting themselves if they use scanpy in some non-interactive code. We should document how to do that. > Second step: reverted things that were logged at a level equal or higher than 4 to `debug`. Good! FYI: I changed the log levels because the initial version of the overhaul only allowed timing information in `info`. > The only thing that remains is to reformat the time output, which now displays many useless digits after the seconds comma [and fix all other places in which similar things happened]. I’m on it. Seems like I missed that because testing code only uses full seconds, which prevents the milliseconds from showing up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/684#issuecomment-500225994:28,log,logging,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684#issuecomment-500225994,5,"['log', 'test']","['log', 'logged', 'logging', 'testing']"
Testability,"Thank you!. One further thing to consider: with all these frequent image updates the repository will at some point explode in size. In all the image-based tests, we should use the smallest sizes possible. Images are already relatively small, but we can further reduce the size in the future. No necessary to remake all of them now, but something to keep in mind for future PRs. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/321#issuecomment-432347980:155,test,tests,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/321#issuecomment-432347980,1,['test'],['tests']
Testability,Thank you!. Would it be possible to catch and validate this behavior with a test here https://github.com/theislab/scanpy/blob/master/scanpy/tests/external/test_hashsolo.py ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2190#issuecomment-1079689047:76,test,test,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1079689047,2,['test'],"['test', 'tests']"
Testability,"Thank you, both! It very likely wasn't there in the beginning and I probably messed it up at some point. It seems that I should make a test that checks that memory usage behaves properly...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/434#issuecomment-457867258:135,test,test,135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434#issuecomment-457867258,1,['test'],['test']
Testability,"Thank you, do you have sankey plot also. another point, do you know which test to use to see which cell types are significant between groups?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1824#issuecomment-835867261:74,test,test,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824#issuecomment-835867261,1,['test'],['test']
Testability,"Thank you, great! I meant moving `calculate_qc_metrics` to `qc.py`. Updating the tutorial after this is good!. The tests under `notebooks/` are currently updated manually. . :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316#issuecomment-434085531:115,test,tests,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316#issuecomment-434085531,1,['test'],['tests']
Testability,"Thank you, judging from the test pics, those look like very useful changes!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/899#issuecomment-548282891:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/899#issuecomment-548282891,1,['test'],['test']
Testability,"Thank you. We’re using pytest though, so please write the tests that way:. 1. Remove the class and make all its methods top-level functions; 2. Make `setUp` into `fixture`s; 3. Just use `assert`. ```py; @pytest.fixture; def markers():; return pd.DataFrame(; ...; ). @pytest.fixture; def adata():; ...; return AnnData(data.values, var=data.columns.values). def test_remove_empty_column(adata, markers):; ...; annotations = annotator(adata, markers, num_genes=20); ...; assert len(annotations) == len(self.anndata); ...; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/812#issuecomment-538909554:58,test,tests,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812#issuecomment-538909554,3,"['assert', 'test']","['assert', 'tests']"
Testability,"Thank you~ Firstly, it's an AssertionError in sc.pp.normalize_per_cell step ; secondly , toy example csv data is presented as below:. ```; Group,Group1,Group1,Group3,Group6,Group5; Gene1,11,0,0,14,0; Gene2,12,17,9,34,11; Gene3,0,0,0,0,2; ```. so, u can test this error locally by:. ```python; df = pd.read_csv('data/dropout/dropout1/counts.csv', index_col=0); genes = df.index.values; barcodes = df.columns; adata = sc.AnnData(np.transpose(df.values), var=pd.DataFrame(genes), obs=pd.DataFrame(barcodes)); adata.var_names_make_unique(); sc.pp.filter_genes(adata, min_cells=1); adata.raw = adata; sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4); ```; lastly, the version is 1.4.3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/727#issuecomment-508621001:28,Assert,AssertionError,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/727#issuecomment-508621001,2,"['Assert', 'test']","['AssertionError', 'test']"
Testability,"Thanks @falexwolf !! I will test if the feature works. Of course I've tested seurat cca, but it seems to work better when integrating data from different sequencing platforms. As for my own data, several batches generated by 10x, output if the MNN method looks more pleasing...; ![unknown](https://user-images.githubusercontent.com/8361080/39244909-b8d3cb38-48c4-11e8-9cdc-82c78703ceee.png). Plus, I haven't looked into the maths of CCA, but I have for MNN and feel more comfortable using it. Actually, @gokceneraslan 's comments do make sense to me, and I've spent quite some time working on a native implementation of MNN correct on python. Now it's nearly complete and features more complete multicore support than the scran implementation.; ![screen shot 2018-04-25 at 20 25 17](https://user-images.githubusercontent.com/8361080/39245687-0a17319a-48c7-11e8-934b-904ee6d75978.png); I built it to be fully compatible with anndata and scanpy. Now it already runs much faster than the scran version, and I'm planning to add more speedups, eg Cython and CUDA. I'm thinking of creating a full toolbox for scanpy, like scran for scater/sce, in python. Perhaps we could work together? 😄. I'm currently writing docstrings and will pack and upload the code to a repository shortly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-384268335:28,test,test,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-384268335,2,['test'],"['test', 'tested']"
Testability,Thanks @falexwolf. The tests are not run by default since dask etc are not installed. I install them with the following to get them to be picked up:. ```; pip install dask[array] zappy zarr; pip install pytest; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/439#issuecomment-456825801:23,test,tests,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456825801,1,['test'],['tests']
Testability,"Thanks @flying-sheep for the thorough feedback! I made the changes. There is still a Travis CI error about slow_to_import modules. Since trimap is now in external, I am now sure how this test is being affected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/862#issuecomment-561830094:187,test,test,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/862#issuecomment-561830094,1,['test'],['test']
Testability,Thanks @flying-sheep! I haven't added any new imports other those for type hints and copying anndata: [https://github.com/eamid/scanpy/compare/9ae6c19...b7ed705](https://github.com/eamid/scanpy/compare/9ae6c19...b7ed705). My previous commit passed the tests. Could this be because of recent commits on your side?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/862#issuecomment-562259348:252,test,tests,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/862#issuecomment-562259348,1,['test'],['tests']
Testability,"Thanks @ivirshup. The parallelism is achieved using a MapReduce scheme operating on a single NumPy array, as described here: https://github.com/lmcinnes/pynndescent/pull/12. This would be amenable to multi-machine parallelism, and in fact I have started a [Dask implementation](https://github.com/tomwhite/pynndescent/tree/dask) that should work on a cluster. However, I haven't benchmarked the Dask implementation, so I don't know how competitive it is with the single (multi-core) machine version using threads. I have successfully run pynndescent on 10^7 rows on a single machine (50 columns, 96 cores), and I don't see why it wouldn't go further than that, although the bottleneck is memory for the heap updates.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/659#issuecomment-495256545:379,benchmark,benchmarked,379,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/659#issuecomment-495256545,1,['benchmark'],['benchmarked']
Testability,"Thanks David, I completely agree, but I was really just talking about the naming convention: `log2FC` vs. `log2foldchange` vs. `logfoldchange` vs. other possibilities... 🙂",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/446#issuecomment-457868274:128,log,logfoldchange,128,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446#issuecomment-457868274,1,['log'],['logfoldchange']
Testability,Thanks a lot @LuckyMD!; MAST seems to be what I was looking for. An alternative might be the logistic regression with covariates Seurat offers within their FindMarkers function.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/669#issuecomment-497725644:93,log,logistic,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/669#issuecomment-497725644,1,['log'],['logistic']
Testability,"Thanks a lot @a-munoz-rojas!. For the DE approach, I would go with the same thing you suggest. I would definitely not do DE testing on the corrected data (violation of distributional assumptions, potential overcorrection of background variation leading to false significant results). . Regarding altering the number of HVGs or latent dimensions... this is difficult to say in general. I would normally err on the higher side of the number of HVGs, but the latent dimensions will depend heavily on the complexity of the dataset i would imagine. I don't think it's possible to give a general recommendation there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061642536:124,test,testing,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061642536,1,['test'],['testing']
Testability,"Thanks a lot for submitting a PR!!!; Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing.; ```bash; pip install black #if you don't have it installed; black scanpy/plotting/_tools/scatterplots.py; ```; or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1470#issuecomment-718970596:202,test,tests,202,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470#issuecomment-718970596,2,['test'],['tests']
Testability,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). ; ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510#issuecomment-489055148:651,Log,Logistic,651,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-489055148,1,['Log'],['Logistic']
Testability,Thanks all for the interesting discussion- did a consensus emerge on the 'best' way to do differential expression testing in scanpy?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-635495778:114,test,testing,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-635495778,1,['test'],['testing']
Testability,"Thanks alot Philip for your help, I just learned testing :). Hopefully this version will be accepted, as I tested now on my laptop and; push when it passed tests for all 5 plots. Thanks,; Khalid. On Mon, May 20, 2019 at 12:37 PM khalid usman <khalid0491@gmail.com> wrote:. > Hi Phillip,; >; > I have removed issue from the pull request by the testing tool, now the; > tools showed me duplications, which are mostly from other code and 1-2 from; > my code. Please have a look into it. It's my first pull request and its; > taking too much time :(; >; > Thanks; > Khalid; >; > On Tue, May 14, 2019 at 9:28 PM khalid usman <khalid0491@gmail.com> wrote:; >; >> Ok , thanks for letting me know. Please check the pull request. I have; >> verified my code by keeping weights 1 and it has same values when; >> observations has no weights or all weights equal to 1.; >>; >> I also suggest to update PCA for weighted sampled data.; >>; >> Thanks,; >> Khalid Usman; >>; >> On Tue, May 14, 2019 at 7:53 PM Philipp A. <notifications@github.com>; >> wrote:; >>; >>> You can just open a new one, I’ll close this one then 🙂; >>>; >>> —; >>> You are receiving this because you authored the thread.; >>> Reply to this email directly, view it on GitHub; >>> <https://github.com/theislab/scanpy/pull/630?email_source=notifications&email_token=ABREGOFHXLS2NZRCDSLJHE3PVKR2ZA5CNFSM4HKUCBXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVLHMMQ#issuecomment-492205618>,; >>> or mute the thread; >>> <https://github.com/notifications/unsubscribe-auth/ABREGOBMZBMFMNA6FCEMFULPVKR2ZANCNFSM4HKUCBXA>; >>> .; >>>; >>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/630#issuecomment-494076520:49,test,testing,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-494076520,4,['test'],"['tested', 'testing', 'tests']"
Testability,"Thanks for all these fixes @mvdbeek!. It looks like the issue here is less about `use_raw` and more about `X` being a two dimensional dense array. I think a more appropriate test would be to check that: if the plots are made using the same data, regardless of whether that data is dense, sparse, or in raw it should look the same. Basically, I'd expand the test introduced in #1548. It might be worth waiting to hear back from @fidelram before that though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-782814776:174,test,test,174,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-782814776,2,['test'],['test']
Testability,"Thanks for catching this! Could you add a test so this doesn't happen again in the future?. Also, I believe the tests that were failing were due to a umap release, not anything you changed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1160#issuecomment-613874802:42,test,test,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1160#issuecomment-613874802,2,['test'],"['test', 'tests']"
Testability,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that; > satisfy all three conditions.; >; > 1. Fraction of cells inside the cluster expressing the gene must be; > greater than min_in_group_fraction; > 2. Fractions of cells outside the cluster expressing the gene must be; > less than max_out_group_fraction; > 3. Fold change must be greater than min_fold_change; >; > But there are remaining issues (calculation of fold change and using the; > absolute value of the fold change) in this function that needs to be; > updated #863 <https://github.com/theislab/scanpy/issues/863>; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1213#issuecomment-630475750:176,log,logic,176,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213#issuecomment-630475750,1,['log'],['logic']
Testability,"Thanks for digging up the seurat code! Somehow failed to find it when I looked for it.. Should I add the correction to PR #1732, which fixes another little issue in the same function?; And should the test also be changed? Currently only the intersection of the hvgs is checked between scanpy and seurat, so instead of sorting the output again and take the top4000 manually (as done now), one could just take `df['highly_variable']` directly for comparison:. ```; df = sc.pp.highly_variable_genes(; pbmc, n_top_genes=4000, flavor='seurat_v3', batch_key=""batch"", inplace=False; ). df = df.loc[df['highly_variable'],:]; seurat_hvg_info_batch = pd.read_csv(; FILE_V3_BATCH, sep=' ', dtype={""variances_norm"": np.float64}; ). # ranks might be slightly different due to many genes having same normalized var; seu = pd.Index(seurat_hvg_info_batch['x'].values); assert len(seu.intersection(df.index)) / 4000 > 0.95; ```. Unfortunately I have no lead where to start with the remaining discrepancy and not enough time at the moment to look into this.. :(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1733#issuecomment-802390464:200,test,test,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733#issuecomment-802390464,2,"['assert', 'test']","['assert', 'test']"
Testability,"Thanks for looking at this... it is surprising that this bug was not detected earlier. . I looked at the code and looks fine but, I would like to add a test. @LisaSikkema can you check this? If this is too much trouble I can do it or I can help you because the plot test are difficult as they require similar setup as in the CI tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1511#issuecomment-739858710:152,test,test,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511#issuecomment-739858710,3,['test'],"['test', 'tests']"
Testability,"Thanks for merging. I did some test and the memory usage was not very high with 1 or 20 regressors. Nevertheless, I tried more memory efficient methods but the gain was minimal.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/164#issuecomment-394292079:31,test,test,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164#issuecomment-394292079,1,['test'],['test']
Testability,"Thanks for opening the issue. Can you provide a full traceback with any warnings?. I can replicate this when passing count data, but the issue there seems to have to do with us assuming we're getting log transformed data. I do not see this error when I pass log normalized data. E.g. this works:. ```python; import scanpy as sc; a = sc.read_h5ad(""/Users/isaac/Downloads/GSE158055_covid19.h5ad""); sc.pp.log1p(a); sc.pp.highly_variable_genes(a, n_top_genes=3000, flavor=""seurat""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2193#issuecomment-1081867209:200,log,log,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193#issuecomment-1081867209,2,['log'],['log']
Testability,"Thanks for opening this PR!. Similar to #1775, I think this might fit better in ecosystem than `external`. Initially, we started `external` as a way of providing a `scanpy`-like API for tools which didn't use `scanpy`. Since your tool already has this kind of API, I think it's a better fit for the ecosystem page. We are working on making this page more visible to users (#1801), but the addition of this tool will be in change log and mentioned in the announcement of the next minor release. How does this sound?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1780#issuecomment-822961476:429,log,log,429,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780#issuecomment-822961476,1,['log'],['log']
Testability,"Thanks for posting that code, it's very helpful for figuring this stuff out. I tried running that code on one of our example datasets, and wasn't able to reproduce your results (however, one of the variables `pos_coord` wasn't defined):. ```python; import scanpy as sc; import numpy as np; import pandas as pd; import matplotlib.pyplot as plt; import seaborn as sns; import anndata; import matplotlib as mpl; import scipy. sc.logging.print_versions(); # scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 ; # pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. sp = sc.datasets.pbmc3k(); sc.pp.normalize_total(sp,target_sum=1e6,key_added='norm_factor'); sc.pp.log1p(sp); sp.raw=sp; sc.pp.highly_variable_genes(sp, n_top_genes=2000); sc.pl.highly_variable_genes(sp); sp = sp[:, sp.var['highly_variable']]; sc.pp.scale(sp, max_value=10); sc.tl.pca(sp, svd_solver='arpack'); sc.pl.pca_variance_ratio(sp, log=True); sc.pp.neighbors(sp, n_neighbors=10, n_pcs=30); sc.tl.diffmap(sp); sc.pp.neighbors(sp, n_neighbors=20, use_rep='X_diffmap'); sc.tl.louvain(sp,resolution=1); sc.tl.paga(sp); _, axs = plt.subplots(ncols=1, figsize=(24, 10), gridspec_kw={'wspace': 0.05, 'left': 0.12}); # Modified this call because pos_coord wasn't defined:; # sc.pl.paga(sp,color='louvain',layout='fa',pos=pos_coord,threshold=0.2,ax=axs) ; sc.pl.paga(sp,color='louvain',layout='fa',threshold=0.2,ax=axs); from scanpy.tools._utils import get_init_pos_from_paga as init; sc.tl.umap(sp,init_pos=init(sp)); sc.pl.umap(sp,color='louvain'); ```. The final plot looks normal enough:. ![image](https://user-images.githubusercontent.com/8238804/69206364-8c9d1880-0ba0-11ea-8180-3bbd0b8c825e.png). Right now, there are a lot of variables in this script. There's a few things to try:. * Check if `pos_coord` is causing the issue; * I noticed your scanpy version wasn't the same as the current release, could you update that?; * If you run the script with the datas",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/918#issuecomment-555819868:426,log,logging,426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918#issuecomment-555819868,2,['log'],"['log', 'logging']"
Testability,"Thanks for reporting @dawe and thanks for updating @WeilerP .; I ran into the same problem with the pip version.; When using **python 3.9** in a fresh virtual enviroment, there's an error related to llvmlite:; <details>; <summary>; error message; </summary>. ```; Building wheel for llvmlite (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: /home/mischko/test/python_virtual/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/setup.py'""'""'; __file__='""'""'/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-rb92hbao; cwd: /tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/; Complete output (15 lines):; running bdist_wheel; /home/mischko/test/python_virtual/bin/python /tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py; LLVM version... 11.1.0; ; Traceback (most recent call last):; File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 143, in main_posix; raise RuntimeError(msg); RuntimeError: Building llvmlite requires LLVM 10.0.x or 9.0.x, got '11.1.0'. Be sure to set LLVM_CONFIG to the right executable path.; Read the documentation at http://llvmlite.pydata.org/ for more information about building llvmlite.; ; error: command '/home/mischko/test/python_virtual/bin/python' failed with exit code 1; ; ERR",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799#issuecomment-830137752:385,test,test,385,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799#issuecomment-830137752,1,['test'],['test']
Testability,"Thanks for taking a look at this @giovp!. `@cache` is new in 3.8, but the implementation is:. ```; def cache(user_function, /):; 'Simple lightweight unbounded cache. Sometimes called ""memoize"".'; return lru_cache(maxsize=None)(user_function); ```. Also I don't think it returns a copy, so you would need to handle that. I've got a branch which implements cached datasets for testing as:. ```python; from functools import wraps; import scanpy as sc. def cached_dataset(func):; store = []; @wraps(func); def wrapper():; if len(store) < 1:; store.append(func()); return store[0].copy(); return wrapper. pbmc3k = cached_dataset(sc.datasets.pbmc3k); pbmc68k_reduced = cached_dataset(sc.datasets.pbmc68k_reduced); pbmc3k_processed = cached_dataset(sc.datasets.pbmc3k_processed); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1050030241:375,test,testing,375,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1050030241,1,['test'],['testing']
Testability,Thanks for the PR! Could you add a test to make sure it works?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1070#issuecomment-590137170:35,test,test,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1070#issuecomment-590137170,1,['test'],['test']
Testability,Thanks for the PR! Could you add a test too?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/764#issuecomment-517982481:35,test,test,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/764#issuecomment-517982481,1,['test'],['test']
Testability,"Thanks for the PR! I've just renamed the variable to be a bit more clear. I do think this test could be a bit better (e.g. check that the structure of the object is correct), but also this is an improvement so LGTM.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2170#issuecomment-1061626692:90,test,test,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170#issuecomment-1061626692,1,['test'],['test']
Testability,"Thanks for the PR! This looks really interesting. I've got a couple questions: . * Why not submit this to scikit-learn? In general I'd be more confident in their vetting.; * This should work with other solvers from scipy, like `lobpcg`, right?; * Could you provide some benchmarks on time, memory usage, and accuracy? . From a brief benchmark on my end, this looks very good from a memory usage perspective, with similar compute times. The components also seem highly correlated, but the components are scaled differently. Would you mind commenting on that?. ------------------. Edit: It seems like the factors are making our nearest neighbor network quite different. It also looks like the calculated variances are different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589477958:270,benchmark,benchmarks,270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-589477958,2,['benchmark'],"['benchmark', 'benchmarks']"
Testability,"Thanks for the PR!. Could you add a test for this?. Also, do you think the behavior should be different for when `n_points > adata.n_vars`? I'm thinking there could be a block like:. ```python; if n_points is None and adata.n_vars < 30:; n_points = adata.n_vars; elif n_points is None:; n_points = 30; ```. Btw, the tests and docs should succeed if you merge changes from master into this branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2061#issuecomment-983857708:36,test,test,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2061#issuecomment-983857708,2,['test'],"['test', 'tests']"
Testability,"Thanks for the PR, that’s it. We know about the two broken tests (e.g. see #3068), they can be ignored for this PR. Not all changes I made in #3097 were necessary, just re-adding the `if len(gene_pool) < len(var_names)` branch. I made the refactoring PR since your changes already refactored the function in a good way, I just went a bit further so the repeated code for “get row/col means of a gene subset of `adata`” code could be reused, and your `get_indexer` change would only need to be added in a single location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2921#issuecomment-2149299253:59,test,tests,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2921#issuecomment-2149299253,1,['test'],['tests']
Testability,"Thanks for the PR. I think if this is added it should be added as a function parameter. It should also get some tests, I'm a bit concerned how just passing `hue` will work with the groupby and palette parameters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1822#issuecomment-829878212:112,test,tests,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1822#issuecomment-829878212,1,['test'],['tests']
Testability,"Thanks for the bug report! Thats definitely strange, since we should almost certainly be catching that in the tests... What's the full version string of python you're runnning?. Could you also try running this snippet with the same interpreter?. ```python; from typing import Tuple, NamedTuple. class ViewArgs(NamedTuple):; parent: ""AnnData""; attrname: str; keys: Tuple[str, ...] = (). print(ViewArgs(None, ""a"")); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/734#issuecomment-509605817:110,test,tests,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734#issuecomment-509605817,1,['test'],['tests']
Testability,"Thanks for the demo code! now its clear to me. I adapted the test to use `np.var(..,dtype=np.float64)` as ground truth, making the internal datatype conversion explicit. Any other requests? I think everything else is ready :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1732#issuecomment-801986131:61,test,test,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732#issuecomment-801986131,1,['test'],['test']
Testability,"Thanks for the docker image. I'll take a look at that when I can. I thought I had pinpointed the error via print statements in the tests and fixed it, but it's back now and when I put print statements the error is gone :/. Might try to experiment with Travis a bit by just pushing to #583. I don't know much about Travis, so not sure how cache comes into play here... or how Travis builds work. I guess it'll be a bit of reading later. Haven't tried forking to check what happens... good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/580#issuecomment-478996906:131,test,tests,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478996906,1,['test'],['tests']
Testability,"Thanks for the explanations @ivirshup! This makes quite a bit more sense to me now (the block sparse matrix stuff). If I understand the `.raw` removal alternative correctly, then you would want to add masks to every operation in scanpy that is not DE and work with `.layers`? I assume that e.g., MT or ribo genes are mainly removed for cellular representation analysis. Some people will also want to remove them from DE analysis to have a set of results that are easy to interpret and have less multiple testing burden. It seems to me that adding masking like this would be quite a large endeavour, no?. > What if a highly variable gene in one dataset just isn't present in another? Is it because it wasn't found in that dataset at all, or because it was only present in a few cells? If it was only present in a few cells, how can I be sure a particular cell type wasn't just poorly represented in that dataset?. I don't see this as such a big issue. If you assume anything filtered out was removed because it was predominantly 0, then it would not have been included in the HVG set of that dataset anyway. So you can assume it would not be in the HVG intersection for that dataset and if you add it, then a 0 for each cell would probably not be that problematic. And whether this was due to a particular cell type being poorly represented can be answered by the gene set that you do have for these cells. Typically there is sufficient gene-gene covariance that you still keep this signal somehow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-822616661:504,test,testing,504,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-822616661,1,['test'],['testing']
Testability,"Thanks for the feedback. I have now merged master into the fix branch and the CI tests are happy. To address the shrewd questions asked by @gokceneraslan:; 1) I pondered over this myself. As I mentioned (above), I based my approach on a pull request in umap's own codebase which also resorts to densification of the matrix. As far as I can see, `pairwise_special_metric` doesn't directly support a sparse matrix and I don't see an alternative approach that wouldn't involve duplicating some of its implementation and (probably) sacrificing some of the benefits (i.e. parallel processing). A deeper analysis by another brain might draw different conclusions.; 2) Another good question. Based on my ""git blame"" detective work, `pairwise_special_metric` was introduced in [a change on 20 Nov 2018](https://github.com/lmcinnes/umap/commit/edade6841bd9b3c80454bf7f4386177c9aa35ab5) which should have seen it incorporated into version [0.3.7](https://github.com/lmcinnes/umap/tree/0.3.7). Since then its signature has remained compatible (with the only change being the addition of the `kwds` argument). scanpy's `requirements.txt` already has `umap-learn` set to a minimum version of 0.3.10 so I believe we're good on that front.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1413#issuecomment-698903808:81,test,tests,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1413#issuecomment-698903808,1,['test'],['tests']
Testability,"Thanks for the feedback. I will add a regression test soon. The plot should be right - there's the color gradient fron blue to green and is a bit more than 1/4 (0.255 to be exact).; As for time, the problem is, that each pie charts are being plotted one by one - that is - there are 2 loops:; ```; for node in nodes:; for pie_fraction in fractions[node]:; ...; ```; I did it because this is the general case of the following matplotlib [example](https://matplotlib.org/3.2.0/gallery/lines_bars_and_markers/scatter_piecharts.html), where they in essence do only `for pie_fraction in fractions`. However, this approach would fail if in the above example; ```; foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}; foo[0] = {'black': 0.5}; ```; the the nodes don't contain the same colors, which user could (although not sure why) specify.; I will test out how much speedup can be gained by using the matplotlib approach (assuming the colors for every node are the same) and get back to you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1123#issuecomment-604356387:49,test,test,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123#issuecomment-604356387,2,['test'],['test']
Testability,"Thanks for the heads up for the typo. That is fixed now. About the feature request... this is not entirely straightforward. The challenges to do this are:; 1. As densities are calculated relative to the sample (or the category subset from `.obs`), the values are not directly comparable. For example, you would get a value of 0.5 if you subtract the maximum density in one condition from a density of half the maximum in the other condition... but maybe the overall density is higher in the second condition. You could just interpret this as the relative differences within the samples I guess...; 2. Densities are currently calculated over cells... to subtract one from the other, you'd have to interpolate this to a grid layout.; 3. Ideally you'd want some kind of statistical test on differential densities... that's a whole other question... What do you think about the above points? If this were implemented, it probably wouldn't be a matter of a day or so... as I'm a bit low on time at the moment, I wouldn't be able to implement this in the next month even if we did find a good way forward unfortunately. You are welcome to submit a pull request though...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/575#issuecomment-478268425:779,test,test,779,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-478268425,1,['test'],['test']
Testability,"Thanks for the quick response. My understanding is that diffusion maps are extremely sensitive to sigma, so I'm curious why you don't allow direct control of this parameter?. I also notice the following comment in your source code:; ""choose sigma, the heuristic here doesn't seem to make much of a difference"". Does this mean that in your tests, varying sigma doesn't make much of a difference? If so, I'm curious why this is because in my own tests using the destiny package, choice of sigma matters quite a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/120#issuecomment-380258000:339,test,tests,339,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/120#issuecomment-380258000,2,['test'],['tests']
Testability,"Thanks for the reference, I added a number of tests to where you mentioned. I also changed the `broadcasting` method for `markers` so now it has the same process as `color` and `dimensions`, and therefore if broadcasting fails, the output error is more understandable (same as when `color` and `dimensions` broadcasting fails). I also added a test for `marker broadcasting`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631633257:46,test,tests,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631633257,2,['test'],"['test', 'tests']"
Testability,Thanks for the report! Could you let us know a little bit about your environment by showing the output of `sc.logging.print_versions()`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1932#issuecomment-874647705:110,log,logging,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932#issuecomment-874647705,1,['log'],['logging']
Testability,"Thanks for the report! I believe the results should be the same for multiple runs. Could you provide an example of this? I'm having a bit of trouble reproducing. Here's what I ran:. ```python; import scanpy as sc; import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(); a = pbmc.copy(); b = pbmc.copy(). sc.pp.regress_out(a, ""phase""); sc.pp.regress_out(b, ""phase""). assert np.array_equal(a.X, b.X); assert not np.array_equal(a.X, pbmc.X); ```. Is this what you meant?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1346#issuecomment-669056636:368,assert,assert,368,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1346#issuecomment-669056636,2,['assert'],['assert']
Testability,"Thanks for the report. I can broadly reproduce the error for passing `values_to_plot`. The error I get is a little different, but I expect that's due to pandas versions. A more minimal example:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.tl.rank_genes_groups(adata, groupby=""louvain"", reference=""B cells""). # Errors with any of ['scores', 'logfoldchanges', 'pvals', 'pvals_adj','log10_pvals', 'log10_pvals_adj']; sc.pl.rank_genes_groups_dotplot(adata, values_to_plot='logfoldchanges'); ```. <details>; <summary> Traceback </summary>. ```pytb; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/ipykernel_62013/1545772980.py in <module>; 1 while len(possible_vals) > 0:; ----> 2 sc.pl.rank_genes_groups_dotplot(adata, values_to_plot=possible_vals.pop()); 3 . ~/github/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/github/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:387,log,logfoldchanges,387,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911,2,['log'],['logfoldchanges']
Testability,"Thanks for the report. I'm having trouble reproducing this behaviour locally. Two thoughts:. 1. It looks like there's a newer version of leidenalg available, could you upgrade that?; 2. Maybe there is something about the neighborhood graph. Could you either: reproduce this with some dummy data (e.g. `sc.datasets.blobs`) or share the `test` object?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2906#issuecomment-1997818178:336,test,test,336,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2906#issuecomment-1997818178,1,['test'],['test']
Testability,"Thanks for the suggestions and that concrete implementation! :smile: @flying-sheep has been suggesting this for quite some time already, but has not yet found the time to implement it. The difficulty will be to replace the visual inspection of all the plots from version to version with something testable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/34#issuecomment-324376016:297,test,testable,297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34#issuecomment-324376016,1,['test'],['testable']
Testability,"Thanks for the wishes! :). If it's not much work for you: could you paste your workaround here? In my tests, the reading of old AnnData backing files worked fine, but I only tested from version to version... 0.2.8 is already quite old for the speed with which Scanpy evolves, so I probably missed something. In principle, Scanpy should be fully backward compatible; several people have written pipelines and stored files that still have to run with more recent versions of Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/56#issuecomment-354906745:102,test,tests,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/56#issuecomment-354906745,2,['test'],"['tested', 'tests']"
Testability,"Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing.; My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10。; I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,; but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors.; Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/276:131,log,login-,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276,1,['log'],['login-']
Testability,"Thanks for your reply. I have modified code and sent a pull request, but it seems that test is; failed, but i don't know why test is failed. I have double check my code,; its fine. Thanks ,; Waiting for your reply. Regards,; Khalid. On Fri, May 3, 2019 at 5:17 PM Philipp A. <notifications@github.com> wrote:. > Hi! Thank you for your contribution!; >; > Maintaining scanpy is a lot of work, so we like to rely on GitHub to help; > us here. Please read up on how to use github so you can create a pull; > request <https://help.github.com/en/articles/creating-a-pull-request>; > with your changes.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/627#issuecomment-489024928>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOHDRLVEO2QTVBGAQ2TPTP7J7ANCNFSM4HJSV4RQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/627#issuecomment-489157164:87,test,test,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/627#issuecomment-489157164,2,['test'],['test']
Testability,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:426,test,testing,426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823,2,['test'],['testing']
Testability,"Thanks so much for the amazing work @Koncopd 🎊. I think it'd be more convenient to have the same type of ""keys"" regardless of the provided `reference` option in sc.tl.rank_genes_groups. Right now I get . `['params', 'pts', 'scores', 'names', 'pvals', 'pvals_adj', 'logfoldchanges']` . keys in .uns['rank_genes_groups'], if I set a reference and . `['params', 'pts', 'pts_rest', 'scores', 'names', 'pvals', 'pvals_adj', 'logfoldchanges']`. if I don't. Wouldn't it be better to replace all *_rest in the code with *_reference, and calculate them based on whatever the reference is, rest or a specific group? . Then we can provide . `['params', 'pts', 'pts_reference', 'scores', 'names', 'pvals', 'pvals_adj', 'logfoldchanges']` . without thinking about what the reference is. Seurat reports pct1 for the first group and pct2 for the second group, for example, which is nice and simple, IMO. Also `sc.get.rank_genes_groups_df` should return pct and pct_reference. It'd be also great to have `pct` cutoffs in the `sc.get.rank_genes_groups_df` function like `pct_min`. . People typically define DE genes using cutoffs like pval_adj < 0.05, log2fc>1, pct>0.1. Edit: Just noticed similar comments from @ivirshup, sorry about replicating :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1156#issuecomment-615322862:265,log,logfoldchanges,265,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1156#issuecomment-615322862,3,['log'],['logfoldchanges']
Testability,"Thanks to everyone who commented here. Hey @flying-sheep, it passes the tests in https://github.com/scverse/scanpy/blob/e285c0f6ec77631d14d748d0927d38aae4391886/tests/test_aggregated.py; please let me know if I should fix or refactor anything; Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3180#issuecomment-2325176926:72,test,tests,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180#issuecomment-2325176926,2,['test'],['tests']
Testability,"Thanks! A little bit of context. We needed this aggregation for one of the projects using pseudobulks of the data. We could use scanpy aggregation methods for simple averaging, but to test the outlier-robust median aggregation, we had to write our code. scanpy didn't have it for some reason, so @farhadmd7 kindly agreed to contribute here. Perhaps someone else will find it helpful, too. @eroell, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3180#issuecomment-2258670730:184,test,test,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180#issuecomment-2258670730,1,['test'],['test']
Testability,"Thanks! Hopefully I'll find some time to test it out this week, I'll get back to you once I do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/7#issuecomment-284341109:41,test,test,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7#issuecomment-284341109,1,['test'],['test']
Testability,"Thanks! Using the most formal of logic :-), line length is now 80 chars.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/382#issuecomment-443462331:33,log,logic,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382#issuecomment-443462331,1,['log'],['logic']
Testability,"Thanks, all I had to do was:. ```; # Log-transform the data; sc.pp.log1p(adata); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763#issuecomment-1854543723:37,Log,Log-transform,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763#issuecomment-1854543723,1,['Log'],['Log-transform']
Testability,"Thanks, that option is very useful and works perfectly. mini-benchmark on my data (compared to non-compressed): ; gzip: 35% memory, 3x runtime; lzf: 66% memory, 2x runtime",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/831#issuecomment-531750992:61,benchmark,benchmark,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/831#issuecomment-531750992,1,['benchmark'],['benchmark']
Testability,Thanks. I just confirmed that the newer versions for both packages were used in the tests. I am checking now what is the difference.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1417#issuecomment-693339957:84,test,tests,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1417#issuecomment-693339957,1,['test'],['tests']
Testability,That definitely looks wrong on our end.... Can you add a test for this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2183#issuecomment-1081870894:57,test,test,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2183#issuecomment-1081870894,1,['test'],['test']
Testability,"That error is not specific to scanpy. It would be good to know which; library is causing the problem such that it can be updated but most likely; is either numpy, scipy, matplotlib or sklearn. Maybe try to update those; packages and see if the error goes away or try to google the error to find; some solution. On Fri, Oct 5, 2018 at 2:59 PM Dilawar Singh <notifications@github.com>; wrote:. > Same issue here. Using pip +pyhton3.7 and not conda to install from pypi.; > Is there a way to resolve it without installing using conda?; >; > Logs:; >; > [dilawars@chamcham scanpy_exp]$ python planaria.py; > /home1/dilawars/.local/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses; > import imp; > scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1; > ... storing 'clusters' as categorical; > computing tSNE; > using data matrix X directly; > using the 'MulticoreTSNE' package by Ulyanov (2017); > finished (0:02:53.98); > saving figure to file ./figures/tsne_full.pdf; > computing neighbors; > using data matrix X directly; > Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed!; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/280#issuecomment-427357518>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1WzuXR5Mhpb3jNte9UkVDqzQjb1pks5uh1eZgaJpZM4XHKo6>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-427359171:538,Log,Logs,538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-427359171,2,"['Assert', 'Log']","['Assertion', 'Logs']"
Testability,"That is a good question, I'm just porting our test suite that we used in 1.4.4.post1, so I assume this is an old default ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1656#issuecomment-781413662:46,test,test,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656#issuecomment-781413662,1,['test'],['test']
Testability,"That is evidently a problem of [psutil](https://pypi.python.org/pypi/psutil); do you have an old version of it? I have tested with 5.2.2 and 5.1.2. Earlier, psutil seemed to have had a [different convention](https://stackoverflow.com/questions/31216835/python-psutil-psutil-get-process-list-error). But both is not related to Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324463747:119,test,tested,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324463747,1,['test'],['tested']
Testability,"That'd be great, thanks!. I was thinking it could replace this step in the test builds:. https://github.com/theislab/scanpy/blob/5fc12f4a918e21f0c57937b787d52040db046f01/.azure-pipelines.yml#L78-L81. And was thinking of using azure for it instead of actions, just to consolidate CI stuff a bit. I was thinking a build and check could just be a separate job? Open to suggestions on this however.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1585#issuecomment-763304270:75,test,test,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1585#issuecomment-763304270,1,['test'],['test']
Testability,"That's a good point! I just added the Benjamini-Hochberg correction to the Wilcoxon code (as well as to the t-tests) and left that as the default. I left the Bonferroni code in there and marked the place with comments. If and when the pull request is complete, they can choose what to keep and remove the extra comments. Either way, since the uncorrected p-values are also outputted, the user can choose whichever correction they want downstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-428734103:110,test,tests,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-428734103,1,['test'],['tests']
Testability,"That's a great idea. It might require some reorganization, though, because currently `use_raw` is checked two places: once in `sc.pl.scatter()`, because it needs to know whether to look for variables in raw or not when deciding how to call `_scatter_obs()`, and again in `_scatter_obs()` itself. And it would probably be bad to do `adata = adata.raw.to_adata()` twice?. On another note, some pytests that are in files I did not edit are now failing because they can't find `anndata.tests` to import. I'm not sure if I messed something up by adding tests to `test_plotting.py` or whether this is a different issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-964269046:482,test,tests,482,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-964269046,2,['test'],['tests']
Testability,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-471054932:185,log,log,185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471054932,4,"['log', 'test']","['log', 'tests']"
Testability,"That's odd. sklearn calculates the explained variance and variance ratio as follows:; ```python; # Calculate explained variance & explained variance ratio; X_transformed = U * Sigma; self.explained_variance_ = exp_var = np.var(X_transformed, axis=0); if sp.issparse(X):; _, full_var = mean_variance_axis(X, axis=0); full_var = full_var.sum(); else:; full_var = np.var(X, axis=0).sum(); self.explained_variance_ratio_ = exp_var / full_var; ```. I do it in the same way:; ```python; X_pca = (u * s)[:, idx] # sort PCs in decreasing order; ev = X_pca.var(0). total_var = _get_mean_var(X)[1].sum(); ev_ratio = ev / total_var; ```; I'll investigate... EDIT: Strange, your assertion error is not reproducible on my end. The code runs fine for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-593741930:667,assert,assertion,667,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-593741930,1,['assert'],['assertion']
Testability,"That's really cool, thank you!. I'll add a logging output about that `replace=False` is the more natural choice and we'll make it the default in the next major release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/340#issuecomment-435638913:43,log,logging,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340#issuecomment-435638913,1,['log'],['logging']
Testability,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/756#issuecomment-523026212:118,test,testing,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756#issuecomment-523026212,2,['test'],"['testing', 'tests']"
Testability,"That’s the way anyway. I think first step would be to rewrite our `test` extra in terms of a) what’s needed for testing and b) what really are scanpy features being tested:. ```toml; test = [; 'pytest',; 'scanpy[dask]',; 'scanpy[zarr]',; ]; ```. then we can extra-by-extra make parts of our test suite optional.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088726702:67,test,test,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088726702,5,['test'],"['test', 'tested', 'testing']"
Testability,The CI tests failed due to the image matching problems (in test_violin and test_pbmc3k) fixed by PR #1422 which is now merged into master. Should I merge master into my fix branch?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1413#issuecomment-696949167:7,test,tests,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1413#issuecomment-696949167,1,['test'],['tests']
Testability,"The Jaccard metric, taken from umap, I believe, returns for a pair of vectors x and y the Jaccard distance between their sets of nonzeros. ([Code](https://github.com/theislab/scanpy/blob/7975f0774c0737bccfc312be0f2a81a3922c2185/scanpy/neighbors/umap/distances.py#L156).). In the case that you feed the raw or logged gene expression matrix, this is reasonable: it's the fraction of genes with nonzero expression shared by the two cells. If you compute this on PCA vectors, however, which are essentially all nonzero, you are getting some version of the complete graph, downsampled to k in some random way. This would explain why clustering and embedding based on that graph is garbage. While investigating this, we (me and @sidneymbell) came across some behavior that may or may not be the desired default. If you call `tools._utils.choose_representation` with `use_rep=None, n_pcs=None`, then it will return `X_pca` (all columns) because `X_pca[:,:None] = X_pca`, which will be the top 50 PCs if one is running with defaults. I might have expected this to instead return `X`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/177#issuecomment-399263207:309,log,logged,309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177#issuecomment-399263207,1,['log'],['logged']
Testability,"The PCA test `test_mask_defaults` only passed because of `float32` being to loose in some situation. When the mask randomly was `[True, True, True, True, True]` the test should have failed. Now the test works as intended.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2914:8,test,test,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2914,3,['test'],['test']
Testability,The PCA test is failing because in older versions of anndata the order of the returned array is different (e.g. fortran vs C). This causes a surprisingly large change in the results. I don't really know what the right solution is here. I've just xfailed it with anndata<0.9 for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1932650529:8,test,test,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1932650529,1,['test'],['test']
Testability,The `rankby_abs` parameter is ignored for `method=logreg` in the `rank_genes_groups` function.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/470:50,log,logreg,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/470,1,['log'],['logreg']
Testability,"The `tl.rank_genes_groups` function already sorts genes by their statistic score from greatest to smallest. ; If you want to sort the genes by log fold change from greatest to smallest, you can get the pandas dataframe of genes for each group and sort them using pandas function.; ```python; df = sc.get.rank_genes_groups_df(adata, group=""1""); df_sorted = df.sort_values('logfoldchanges', ascending=False); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2247#issuecomment-1150425238:143,log,log,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2247#issuecomment-1150425238,2,['log'],"['log', 'logfoldchanges']"
Testability,"The additional cases that would need to be handled (and what I believe the current internal solutions are):. * What if colors haven't been saved to uns yet; * If it's an view, we just return what the colors would be by default; * If it's an ""actual"" we return the colors, but also assign them to the object; * What if there's a different number of colors and categories; * We warn and reassign the colors. If it's a view, we don't modify the object, but probably still warn. Most of the logic for handling this internally is wrapped in `_get_palette`: https://github.com/theislab/scanpy/blob/ed364a887db2eb604d0a09cd72325cb5e1f4e27e/scanpy/plotting/_tools/scatterplots.py#L1192-L1204",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1881#issuecomment-863776992:487,log,logic,487,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1881#issuecomment-863776992,1,['log'],['logic']
Testability,"The biggest advantage would be the possibility to create such panels as shown in the example, where e.g. quality metrics have different cmaps as gene expression.; Another advantage would be that cmaps could be defined globally for each parameter, resulting in simpler plotting calls. ```; adata = sc.datasets.paul15(); adata.X = adata.X.astype('float64'); sc.pp.filter_cells(adata, min_genes=100); sc.pp.recipe_zheng17(adata); sc.tl.pca(adata, svd_solver='arpack'); adata.uns['n_counts_all_cmap'] = 'copper'; adata.uns['n_genes_cmap'] = 'copper'; sc.pl.pca(adata, color=['paul15_clusters', 'n_counts_all', 'n_genes', 'Zyx', 'calp80', 'slc43a2'], ncols=3); ```; ![test](https://user-images.githubusercontent.com/23263654/99387978-28a55100-28d5-11eb-975d-f91211370c16.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1489#issuecomment-728884186:663,test,test,663,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489#issuecomment-728884186,1,['test'],['test']
Testability,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py; import scanpy as as; adata = sc.datasets.pbmc3k(); # sc.pp.normalize_total(adata, target_sum=10000); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000); adata.var[""highly_variable""].sum(); ```; ```; 10367; ```; Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)); Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R; library(dplyr); library(Seurat); library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)); ```; ```; 2292; ```; However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3157#issuecomment-2255759888:1278,Log,LogNormalize,1278,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157#issuecomment-2255759888,1,['Log'],['LogNormalize']
Testability,"The docs should now be fixed on master. Updating the branch should fix that. I've added a commit to fix that formatting test. @adamgayoso could you compress the data files you're using for testing, and remove to uncompressed files from the git history? This is to keep the repo size as small as possible. Otherwise, @gokceneraslan were you happy with the state this PR is in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1204#issuecomment-650924757:120,test,test,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204#issuecomment-650924757,2,['test'],"['test', 'testing']"
Testability,"The failing test is here https://travis-ci.org/theislab/scanpy/jobs/574409535#L386. However test_var_df should not be affected by this PR, and this test is also failing on master,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/791#issuecomment-523073188:12,test,test,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791#issuecomment-523073188,2,['test'],['test']
Testability,The failing test is un-related to the PR. @LuckyMD can you take a look at the changes?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/628#issuecomment-488684629:12,test,test,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/628#issuecomment-488684629,1,['test'],['test']
Testability,"The failing test seems unrelated. I'm merging this. [@fidelram, you could have merged it yourself. :)]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/540#issuecomment-474352903:12,test,test,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/540#issuecomment-474352903,1,['test'],['test']
Testability,"The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc; import pandas as pd; import matplotlib.pyplot as plt; import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""); adata.var_names_make_unique(); adata.var[""mt""] = adata.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""); sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""); ```. The results are as follows:; ```ranking genes; finished: added to `.uns['rank_genes_groups']`; 'names', sorted np.recarray to be indexed by group ids; 'scores', sorted np.recarray to be indexed by group ids; 'logfoldchanges', sorted np.recarray to be indexed by group ids; 'pvals', sorted np.recarray to be indexed by group ids; 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02); WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.; using 'X_pca' with n_pcs = 50; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-19-a44c51f396af> in <module>; 2 # genes across clusters.; 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""); ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds); 454 show=show,; 455 save=save,; --> 456 **kwds,; 457 ); 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1313:640,test,test,640,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313,2,"['log', 'test']","['logfoldchanges', 'test']"
Testability,"The idea of having ""smart subsample"" functionality available in scanpy has been a topic of discussion for a while. I would like to see a benchmark of these methods on single cell data before choosing one to include here. Are you aware of anything in this space?. Update:. It looks like the lab it's from have put out some writing on this: https://dl.acm.org/doi/pdf/10.1145/3388440.3412409",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2862#issuecomment-1948573055:137,benchmark,benchmark,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2862#issuecomment-1948573055,1,['benchmark'],['benchmark']
Testability,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1484#issuecomment-725894623:161,test,test,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484#issuecomment-725894623,3,['test'],"['test', 'tests']"
Testability,"The last test. In an environment with scanpy (1.9.3) and leidenalg installed, I can get reproducible runs for the code above. If I install the following packages:. ```; conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia; ```; Then I start to have problems with reproducibility. I have no idea how this is possible but perhaps one clue is that torch is being reported in the package versions even though I am not loading it or using scvi-tools. Probably this is related to the latest update in anndata. <details><summary>Details</summary>; <p>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; gmpy2 2.1.2; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.22.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; nvfuser NA; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.1.0; torch 2.0.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; zmq 25.0.2; zoneinfo NA; -----; IPython 8.13.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993:9,test,test,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993,1,['test'],['test']
Testability,"The logic used in `add_colors_for_categorical_sample_annotation` looks kinda messed up (should check `>` not `<=`). I think `paga` should just use `_get_palette` the same way embedding plots do. It looks like there are a number of plotting functions that will have this behavior. I would note I'm not totally convinced we should allow setting more colors than there are categories, since they could be misaligned. This would be irrelevant if we stored colors in a dict.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1972#issuecomment-893092263:4,log,logic,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1972#issuecomment-893092263,1,['log'],['logic']
Testability,The max categorical error was one that I thought was addressed by anndata 0.6.18. I assume this is still on 0.6.22rc1? There was previously a switch from defaulting to ordered categoricals to unordered instead. There are quite a few unit tests... but clearly not perfect coverage. Others will be able to say more about the coverage than me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-508770744:238,test,tests,238,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-508770744,1,['test'],['tests']
Testability,The only solution so far is to increase the tolerance threshold of the tests! I don't know where those differences come from. Is always a problem. I will be very glad if you find a better solution.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-431812136:71,test,tests,71,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-431812136,1,['test'],['tests']
Testability,"The only thing missing from the test in #1413 is `ll_dirichlet`, which seems to be a metric that’s implemented in `umap` but not PyNNDescent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1011#issuecomment-2370978435:32,test,test,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011#issuecomment-2370978435,1,['test'],['test']
Testability,The original bug you hit was with the `sc.pl.scatter` which has few tests. I'd recommend trying out the master branches of `AnnData` and `scanpy` until new releases can be made in cases like these.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-508906927:68,test,tests,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-508906927,1,['test'],['tests']
Testability,"The original issue seems to be scikit-learn/scikit-learn#2969. It says that issues arise if there’s a 64 bit index, so the logic should look like. ```py; if not issparse(X):; mean = np.mean(X, axis=0, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=0, dtype=np.float64); var = mean_sq - mean ** 2; elif STANDARD_SCALER_FIXED or np.issubdtype(X.indices.dtype, np.int32):; from sklearn.preprocessing import StandardScaler; scaler = StandardScaler(with_mean=False).partial_fit(X); mean, var = scaler.mean_, scaler.var_; else:; mean, var = sparse_mean_variance_axis(X, axis=0) ; ```. But actually StandardScaler handles dense matrices just fine, so why not. ```py; if not issparse(X) or STANDARD_SCALER_FIXED or np.issubdtype(X.indices.dtype, np.int32):; from sklearn.preprocessing import StandardScaler; scaler = StandardScaler(with_mean=False).partial_fit(X); mean, var = scaler.mean_, scaler.var_; else:; mean, var = sparse_mean_variance_axis(X, axis=0) ; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/857#issuecomment-537406138:123,log,logic,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/857#issuecomment-537406138,1,['log'],['logic']
Testability,"The original line was; ```; zero_center = zero_center if zero_center is not None else False if issparse(adata_comp.X) else True; ```; which did the expected thing, @flying-sheep introduced the bug 22 days ago in https://github.com/theislab/scanpy/commit/ce10d02f58c3308b60c23c43a36949b6aeed3ea8. Damn, I wouldn't have expected such a thing in a commit ""improved docs"". It went into release 1.3.4 and 1.3.5... Of course, it's my fault. I should have written a test in the first place. @Koncopd: can you write a test for PCA both for sparse and dense data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/393#issuecomment-446372971:459,test,test,459,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446372971,2,['test'],['test']
Testability,The package is now available on [pypi](https://pypi.org/project/glmpca/0.1.0/) and there is an [automated test suite](https://github.com/willtownes/glmpca-py/blob/master/tests/glmpca_tests.py).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-541505929:106,test,test,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-541505929,2,['test'],"['test', 'tests']"
Testability,"The packages do need a GPU, unfortunately. There is no way to fallback to run on a CPU, so I don't think Travis can test them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/830#issuecomment-535090728:116,test,test,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830#issuecomment-535090728,1,['test'],['test']
Testability,"The previous test failed but is not clear to me why, as it passes the local tests (anndata 0.7.5). It seems that on travis server, backed slicing requires integer indices and will not work with a boolean vector. I changed to sorted integers hoping that this will solve the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1499#issuecomment-733745048:13,test,test,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499#issuecomment-733745048,2,['test'],"['test', 'tests']"
Testability,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:83,test,test,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,2,['test'],['test']
Testability,The problem seems to be [here](https://github.com/theislab/scanpy/blob/f704f724529def21769ee6407f9b47b5c161564c/scanpy/plotting/_anndata.py#L745) and [here](https://github.com/theislab/scanpy/blob/f704f724529def21769ee6407f9b47b5c161564c/scanpy/plotting/_anndata.py#L747) as `seaborn` throws the warning. ```bash; UserWarning: Vertical orientation ignored with only `x` specified.; ```. in the stack trace of the failed tests. I'll open a separate issue as it is unrelated to this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1417#issuecomment-693574261:420,test,tests,420,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1417#issuecomment-693574261,1,['test'],['tests']
Testability,"The rehauled logging module tends to clutter output, see, for instance; ```; import scanpy as sc; sc.settings.verbosity = 2; adata_sc = sc.datasets.pbmc68k_reduced(); sc.pp.neighbors(adata_sc); ```; which produces; ![image](https://user-images.githubusercontent.com/16916678/59159145-a56bb300-8ac5-11e9-8371-170995e43dfa.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/684:13,log,logging,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684,1,['log'],['logging']
Testability,The remaining failed test is related to matplotlib 3.1.0 and 3d scatter plots. There is a report of a similar error (https://github.com/matplotlib/matplotlib/issues/14298). My suggestion is to wait for those issues to be solved and then upgrade the dependencies.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/661#issuecomment-496144015:21,test,test,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-496144015,1,['test'],['test']
Testability,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763#issuecomment-1137813331:155,log,logging,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763#issuecomment-1137813331,1,['log'],['logging']
Testability,"The same issue happens when renaming categories with the built-in rename categories function. I think, this definitely should not happen. Example:. ```python; import pandas as pd; import scanpy.api as sc. adata = sc.datasets.blobs(640, 3); sc.tl.pca(adata); sc.pp.neighbors(adata); sc.tl.louvain(adata). method='logreg'. sc.tl.rank_genes_groups(adata, 'louvain', method=method); print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)). adata.rename_categories('louvain', ['Zero', 'One', 'Two']). sc.tl.rank_genes_groups(adata, 'louvain', method=method); print(pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(1)); ```; gives; ```python; 0 1 2; 0 570 63 126; Zero One Two; 0 63 126 570; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/273#issuecomment-425136119:312,log,logreg,312,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/273#issuecomment-425136119,1,['log'],['logreg']
Testability,"The score_genes procedure currently uses a ranking system to split genes into bins of similar expression levels. The current approach fails with some datasets. - Currently the code doesn’t produce the expected number of bins of equal or approximately equal size, see #3168; - The code fails completely when the gene set has zero expression in some cells, see #3169. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3168, closes #3169; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3167:471,Test,Tests,471,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167,1,['Test'],['Tests']
Testability,"The short answer is that `flit_core`, which provides the PEP 517 hooks, makes a minimal sdist which should always have the files you need to install the module, but may leave out e.g. tests and docs. The Flit CLI tries to make a 'publication quality' sdist. It's kind of an ugly compromise, because how I approached sdists (before PEP 517) wasn't a good fit for the PEP 517 `build_sdist` hook. I view sdists on PyPI as like a snapshot of the development process, so it should (by default) include everything that you'd get if you checked out the corresponding tag from git (except the git history). But using git assumes that it's something the maintainer makes once and publishes on PyPI. PEP 517 defined a `build_sdist` hook which user tools (like pip) can call. I didn't want this to depend on git, so I gave it a way to make working but minimal sdists. Specifying includes & excludes under `[tool.flit.sdist]` should affect both the Flit CLI and the PEP 517 hooks. So if you want to make the sdists to publish with `python -m build` or similar, you'll need to use those to determine what goes in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1909#issuecomment-874715324:184,test,tests,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909#issuecomment-874715324,1,['test'],['tests']
Testability,"The test `test_marker_overlap` keeps failing on the travis build for python 3.5. This seems to happen on the first build from a PR, but if the build is restarted it passes. Given that my `n=3` for this, it could also be random. Grabbed the error log from #579 (build [1735.1](https://travis-ci.org/theislab/scanpy/jobs/514097606)):. ```; _____________________________ test_marker_overlap ______________________________; def test_marker_overlap():; # Test all overlap calculations on artificial data; test_data = sc.AnnData(X = np.ones((9,10))); test_data.uns['rank_genes_groups'] = dict(); test_data.uns['rank_genes_groups']['names'] = np.rec.fromarrays(; [['a', 'b','c','d','e'], ['a','f','g','h','i']]); test_data.uns['rank_genes_groups']['pvals_adj'] = np.rec.fromarrays(; [[0.001, 0.01, 0.02, 0.05, 0.6], [0.001, 0.01, 0.02, 0.05, 0.6]]); ; marker_genes = {'type 1':{'a','b','c'}, 'type 2':{'a','f','g'}}; ; t1 = sc.tl.marker_gene_overlap(test_data, marker_genes); t2 = sc.tl.marker_gene_overlap(test_data, marker_genes, normalize='reference'); t3 = sc.tl.marker_gene_overlap(test_data, marker_genes, method='overlap_coef'); t4 = sc.tl.marker_gene_overlap(test_data, marker_genes, method='jaccard'); t5 = sc.tl.marker_gene_overlap(test_data, marker_genes, top_n_markers=2); t6 = sc.tl.marker_gene_overlap(test_data, marker_genes, adj_pval_threshold=0.01); ; > assert t1.iloc[1,1] == 3.0; E assert 1.0 == 3.0; scanpy/tests/test_marker_gene_overlap.py:22: AssertionError; ```. Here's a [gist](https://gist.github.com/ivirshup/6965ebe2530c4eac67aebf41c3961959) of the full output. Any idea what's up @LuckyMD?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/580:4,test,test,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580,7,"['Assert', 'Test', 'assert', 'log', 'test']","['AssertionError', 'Test', 'assert', 'log', 'test', 'tests']"
Testability,The test is failing because `scipy.stats` is not a wanted import. Let me know how you'd like to deal with that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/797#issuecomment-524381733:4,test,test,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797#issuecomment-524381733,1,['test'],['test']
Testability,"The test is not good neither. If you look carefully at the heatmap generated with sc.pl.rank_genes_groups_heatmap(pbmc, n_genes=3, standard_scale='var'), you would find it is not aligned perfectly, especially for the local magnified heatmap. @fidelram @brianpenghe ; ![Figure_1](https://user-images.githubusercontent.com/29703450/62337090-c4a32180-b505-11e9-8757-73bc248d7754.png); ![1](https://user-images.githubusercontent.com/29703450/62337095-c66ce500-b505-11e9-8391-74b7b9948ab2.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/637#issuecomment-517510719:4,test,test,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-517510719,1,['test'],['test']
