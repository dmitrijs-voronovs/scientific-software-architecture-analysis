quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,filename,wiki,url,total_similar,target_keywords,target_matched_words
Performance,"subsequent loads from; speculatively executing until all prior mispredicted predicates have resolved.; We can use this broader barrier to speculative loads executing between; functions. We emit it in the entry block to handle calls, and prior to each; return. This approach also has the advantage of providing the strongest degree; of mitigation when mixed with unmitigated code by halting all misspeculation; entering a function which is mitigated, regardless of what occurred in the; caller. However, such a mixture is inherently more risky. Whether this kind of; mixture is a sufficient mitigation requires careful analysis. Unfortunately, experimental results indicate that the performance overhead of; this approach is very high for certain patterns of code. A classic example is; any form of recursive evaluation engine. The hot, rapid call and return; sequences exhibit dramatic performance loss when mitigated with `lfence`. This; component alone can regress performance by 2x or more, making it an unpleasant; tradeoff even when only used in a mixture of code. ##### Use an internal TLS location to pass predicate state. We can define a special thread-local value to hold the predicate state between; functions. This avoids direct ABI implications by using a side channel between; callers and callees to communicate the predicate state. It also allows implicit; zero-initialization of the state, which allows non-checked code to be the first; code executed. However, this requires a load from TLS in the entry block, a store to TLS; before every call and every ret, and a load from TLS after every call. As a; consequence it is expected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate perf",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:42289,perform,performance,42289,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['perform'],['performance']
Performance,"such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_LINK_JOBS. Link jobs will ; be between one and amount of logical cores. Link jobs will not run ; exclusively therefore you should add an offset of one or two compile jobs ; to be sure its not terminated in your memory restricted environment. On ELF; platforms also consider ``LLVM_USE_SPLIT_DWARF`` in Debug build. **LLVM_PROFDATA_FILE**:PATH; Path to a profdata file to pass into clang's -fprofile-instr-use flag. This; can only be specified if you're building wi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:32463,concurren,concurrent,32463,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['concurren'],['concurrent']
Performance,"sult type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Combines a store with a GEP. See description of G_INDEXED_LOAD for indexing behaviour. G_ATOMIC_CMPXCHG_WITH_SUCCESS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomic cmpxchg with internal success check. Expects a; MachineMemOperand in addition to explicit operands. G_ATOMIC_CMPXCHG; ^^^^^^^^^^^^^^^^. Generic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:16219,load,loaded,16219,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,2,['load'],['loaded']
Performance,"sults in a poison value.; %poison2 = sub i32 poison, 1 ; Also results in a poison value.; %still_poison = and i32 %poison, 0 ; 0, but also poison.; %poison_yet_again = getelementptr i32, ptr @h, i32 %still_poison; store i32 0, ptr %poison_yet_again ; Undefined behavior due to; ; store to poison. store i32 %poison, ptr @g ; Poison value stored to memory.; %poison3 = load i32, ptr @g ; Poison value loaded back from memory. %poison4 = load i16, ptr @g ; Returns a poison value.; %poison5 = load i64, ptr @g ; Returns a poison value. %cmp = icmp slt i32 %poison, 0 ; Returns a poison value.; br i1 %cmp, label %end, label %end ; undefined behavior. end:. .. _welldefinedvalues:. Well-Defined Values; -------------------. Given a program execution, a value is *well defined* if the value does not; have an undef bit and is not poison in the execution.; An aggregate value or vector is well defined if its elements are well defined.; The padding of an aggregate isn't considered, since it isn't visible; without storing it into memory and loading it with a different type. A constant of a :ref:`single value <t_single_value>`, non-vector type is well; defined if it is neither '``undef``' constant nor '``poison``' constant.; The result of :ref:`freeze instruction <i_freeze>` is well defined regardless; of its operand. .. _blockaddress:. Addresses of Basic Blocks; -------------------------. ``blockaddress(@function, %block)``. The '``blockaddress``' constant computes the address of the specified; basic block in the specified function. It always has an ``ptr addrspace(P)`` type, where ``P`` is the address space; of the function containing ``%block`` (usually ``addrspace(0)``). Taking the address of the entry block is illegal. This value only has defined behavior when used as an operand to the; ':ref:`indirectbr <i_indirectbr>`' or for comparisons against null. Pointer; equality tests between labels addresses results in undefined behavior ---; though, again, comparison against null is ok, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:199536,load,loading,199536,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loading']
Performance,"sure that the shared library is rebuilt you can use the ++; syntax:. ``` {.cpp}; root[] .L MyScript.C++; ```. To build, load, and execute the function with the same name as the; file you can use the `.x` command. This is the same as executing a; named script; you can also provide parameters. The only; difference is you need to append a + or a ++. ``` {.cpp}; root[] .x MyScript.C+(4000); Creating shared library /home/./MyScript_C.so; ```. You can select whether the script in compiled with debug symbol or; with optimization by appending the letter 'g' or 'O' after the '+' or; '++'. Without the specification, the script is compiled with the same; level of debugging symbol and optimization as the currently running; ROOT executable. For example:. ``` {.cpp}; root[] .L MyScript.C++g; ```. will compile `MyScript.C` with debug symbols; usually this means; giving the `-g` option to compiler. ``` {.cpp}; root[] .L MyScript.C++O; ```. will compile `MyScript.C` with optimizations; usually this means; giving the `-O` option to compiler. The syntax:. ``` {.cpp}; root[] .L MyScript.C++; ```. is using the default optimization level. The initial default is to; compile with the same level of optimization as the root executable; itself. The default can be changed by:. ``` {.cpp}; root[] gSystem->SetAclicMode(TSystem::kDebug);; root[] gSystem->SetAclicMode(TSystem::kOpt);; ```. Note that the commands:. ``` {.cpp}; root[] .L MyScript.C+g; root[] .L MyScript.C+O; ```. respectively compile `MyScript.C` with debug and optimization if the; library does not exist yet; they will not change the debug and the; optimization level if the library already exist and it is up to date.; To use ACLiC from compiled code or from inside another macro, we; recommend using `gROOT->ProcessLine()`. For; example, in one script you can use ACLiC to compile and load another; script. ``` {.cpp}; gROOT->ProcessLine("".L MyScript.C+""); gROOT->ProcessLine("".L MyScript.C++""); ```. ### Setting the Include Path. You can",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md:15387,optimiz,optimizations,15387,documentation/users-guide/Cling.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md,1,['optimiz'],['optimizations']
Performance,"sures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global dat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247685,load,load,247685,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"sures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singleth",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:215745,load,load,215745,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"sy to use and obtain, and strives to maximize the quantity and impact of scientific ; results obtained per unit cost, both of human effort and computing resources. ROOT provides a very efficient storage system for data models, ; that demonstrated to scale at the Large Hadron Collider experiments: Exabytes ; of scientific data are written in columnar ROOT format.; ROOT comes with histogramming capabilities in an arbitrary number of ; dimensions, curve fitting, statistical modelling, minimization, to allow; the easy setup of a data analysis system that can query and process the data; interactively or in batch mode, as well as a general parallel processing; framework, RDataFrame, that can considerably speed up an analysis, taking ; full advantage of multi-core and distributed systems. ROOT is performance critical software written in C++ and enables rapid prototyping ; powered by a unique C++ compliant interpreter called Cling. ; Cling also enables performant C++ type introspection which is a building block of automatic ; interoperability with Python. Thanks to PyROOT, leveraging the cppyy technology, ; ROOT offers efficient, on-demand C++/Python interoperability in a uniform cross-language ; execution environment. ROOT fully embraces open-source, it's made with passion by its community,; for the benefit of its community. [![License: LGPL v2.1+](https://img.shields.io/badge/License-LGPL%20v2.1+-blue.svg)](https://www.gnu.org/licenses/lgpl.html); [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5060/badge)](https://bestpractices.coreinfrastructure.org/projects/5060). ## Contribution Guidelines; - [How to contribute](https://github.com/root-project/root/blob/master/CONTRIBUTING.md); - [Coding conventions](https://root.cern/coding-conventions); - [Meetings](https://root.cern/meetings). ## Cite; When citing ROOT, please use both the reference reported below and the DOI specific to your ROOT version available [on Zenodo](https://zenodo.org/badge/l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README.md:1367,perform,performant,1367,README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README.md,1,['perform'],['performant']
Performance,"symbol table it creates; includes both native and bitcode symbols. *Deterministic Archives*. By default, :program:`llvm-ar` always uses zero for timestamps and UIDs/GIDs; to write archives in a deterministic mode. This is equivalent to the; :option:`D` modifier being enabled by default. If you wish to maintain; compatibility with other :program:`ar` implementations, you can pass the; :option:`U` modifier to write actual timestamps and UIDs/GIDs. *Windows Paths*. When on Windows :program:`llvm-ar` treats the names of archived *files* in the same; case sensitive manner as the operating system. When on a non-Windows machine; :program:`llvm-ar` does not consider character case. OPTIONS; -------. :program:`llvm-ar` operations are compatible with other :program:`ar`; implementations. However, there are a few modifiers (:option:`L`) that are not; found in other :program:`ar` implementations. The options for; :program:`llvm-ar` specify a single basic Operation to perform on the archive,; a variety of Modifiers for that Operation, the name of the archive file, and an; optional list of file names. If the *files* option is not specified, it; generally means either ""none"" or ""all"" members, depending on the operation. The; Options, Operations and Modifiers are explained in the sections below. The minimal set of options is at least one operator and the name of the; archive. Operations; ~~~~~~~~~~. .. option:: d [NT]. Delete files from the ``archive``. The :option:`N` and :option:`T` modifiers; apply to this operation. The *files* options specify which members should be; removed from the archive. It is not an error if a specified file does not; appear in the archive. If no *files* are specified, the archive is not; modified. .. option:: m [abi]. Move files from one location in the ``archive`` to another. The :option:`a`,; :option:`b`, and :option:`i` modifiers apply to this operation. The *files*; will all be moved to the location given by the modifiers. If no modifiers are; used, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-ar.rst:2455,perform,perform,2455,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-ar.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-ar.rst,1,['perform'],['perform']
Performance,"symbol. Unlike regular reexports however, lookups of lazy reexports; do not trigger immediate materialization of the reexported symbol. Instead, they; only trigger materialization of a function stub. This function stub is; initialized to point at a *lazy call-through*, which provides reentry into the; JIT. If the stub is called at runtime then the lazy call-through will look up; the reexported symbol (triggering materialization for it if necessary), update; the stub (to call directly to the reexported symbol on subsequent calls), and; then return via the reexported symbol. By re-using the existing symbol lookup; mechanism, lazy reexports inherit the same concurrency guarantees: calls to lazy; reexports can be made from multiple threads concurrently, and the reexported; symbol can be any state of compilation (uncompiled, already in the process of; being compiled, or already compiled) and the call will succeed. This allows; laziness to be safely mixed with features like remote compilation, concurrent; compilation, concurrent JIT'd code, and speculative compilation. There is one other key difference between regular reexports and lazy reexports; that some clients must be aware of: The address of a lazy reexport will be; *different* from the address of the reexported symbol (whereas a regular; reexport is guaranteed to have the same address as the reexported symbol).; Clients who care about pointer equality will generally want to use the address; of the reexport as the canonical address of the reexported symbol. This will; allow the address to be taken without forcing materialization of the reexport. Usage example:. If JITDylib ``JD`` contains definitions for symbols ``foo_body`` and; ``bar_body``, we can create lazy entry points ``Foo`` and ``Bar`` in JITDylib; ``JD2`` by calling:. .. code-block:: c++. auto ReexportFlags = JITSymbolFlags::Exported | JITSymbolFlags::Callable;; JD2.define(; lazyReexports(CallThroughMgr, StubsMgr, JD,; SymbolAliasMap({; { Mangle(""foo""), { M",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:17754,concurren,concurrent,17754,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,2,['concurren'],['concurrent']
Performance,"t %reg1037 is an; operand of the PHI node in bb76 and its operand %reg1039 is the result of the; PHI node. We should treat it as a two-address code and make sure the ADDri is; scheduled after any node that reads %reg1039. //===---------------------------------------------------------------------===//. Use local info (i.e. register scavenger) to assign it a free register to allow; reuse:; ldr r3, [sp, #+4]; add r3, r3, #3; ldr r2, [sp, #+8]; add r2, r2, #2; ldr r1, [sp, #+4] <==; add r1, r1, #1; ldr r0, [sp, #+4]; add r0, r0, #2. //===---------------------------------------------------------------------===//. LLVM aggressively lift CSE out of loop. Sometimes this can be negative side-; effects:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; load [i + R1]; ...; load [i + R2]; ...; load [i + R3]. Suppose there is high register pressure, R1, R2, R3, can be spilled. We need; to implement proper re-materialization to handle this:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; R1 = X + 4 @ re-materialized; load [i + R1]; ...; R2 = X + 7 @ re-materialized; load [i + R2]; ...; R3 = X + 15 @ re-materialized; load [i + R3]. Furthermore, with re-association, we can enable sharing:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; T = i + X; load [T + 4]; ...; load [T + 7]; ...; load [T + 15]; //===---------------------------------------------------------------------===//. It's not always a good idea to choose rematerialization over spilling. If all; the load / store instructions would be folded then spilling is cheaper because; it won't require new live intervals / registers. See 2003-05-31-LongShifts for; an example. //===---------------------------------------------------------------------===//. With a copying garbage collector, derived pointers must not be retained across; collector safe points; the collector could move the objects and invalidate the; derived pointer. This is bad enough in the first place, but safe points can; crop up unpredictably. Consider:. %array = load { i32, [0",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:2011,load,load,2011,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,1,['load'],['load']
Performance,"t CUs and so a ``buffer_inv sc0`` is required which will invalidate; the L1 cache. * A ``buffer_inv sc0`` is required to invalidate the L1 cache for coherence; between wavefronts executing in different work-groups as they may be; executing on different CUs. * Atomic read-modify-write instructions implicitly bypass the L1 cache.; Therefore, they do not use the sc0 bit for coherence and instead use it to; indicate if the instruction returns the original value being updated. They; do use sc1 to indicate system or agent scope coherence. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Therefore, the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and the same L2 cache can be reordered; relative to each other.; * A ``s_waitcnt vmcnt(0)`` is required to ensure synchronization between; vector memory operations of different CUs. It ensures a previous vector; memory operation has completed before executing a subsequent vector memory; or LDS operation and so can be used to meet the requirements of acquire and; release.; * An L2 cache can be kept coherent with other L2 caches by using the MTYPE RW; (read-write) for memory local to the L2, and MTYPE NC (non-coherent) with; the PTE C-bit set for memory not local to the L2. * Any local memory cache",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:287526,cache,caches,287526,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance,"t Crossing Point. Supposing we have found out that a particle will cross a boundary during; the next step, it is sometimes useful to compute the normal to the; crossed surface. The modeller uses the following convention: we define; as `normal` (\f$\vec{n}\f$) the unit vector perpendicular; to a surface in the `next crossing point`, having the orientation such; that: \f$\vec{n}.\vec{d}>0\f$. Here \f$\vec{d}\f$; represents the current direction. The next crossing point represents the; point where a ray shot from the current point along the current; direction crosses the surface. ~~~{.cpp}; Double_t *TGeoManager::FindNormal(Bool_t forward=kTRUE);; ~~~. The method above computes the normal to the next crossed surface in; forward or backward direction (i.e. the current one), assuming the state; corresponding to a current arbitrary point is initialized. An example of; usage of normal computation is ray tracing. The two most important features of the geometrical modeller concerning; tracking are scalability and performance as function of the total number; of physical nodes. The first refers to the possibility to make use of; the available memory resources and at the same time be able to resolve; any geometrical query, while the second defines the capability of the; modeller to respond quickly even for huge geometries. These parameters; can become critical when simulating big experiments like those at LHC. \anchor GP02h; ### Creating and Visualizing Tracks. In case the modeller is interfaced with a tracking engine, one might; consider quite useful being able to store and visualize at least a part; of the tracks in the context of the geometry. The base class; TVirtualGeoTrack provides this functionality. It currently has one; implementation inside the drawing package (TGeoTrack class). A; track can be defined like:. ~~~{.cpp}; TVirtualGeoTrack(Int_t id,Int_t pdg,TVirtualGeoTrack *parent=0,; TObject *particle=0);; ~~~. Where: `id` is user-defined id of the track, `pdg` - `pdg`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:84319,scalab,scalability,84319,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,2,"['perform', 'scalab']","['performance', 'scalability']"
Performance,"t MaterializationResponsibility &R) {; // Create a function pass manager.; auto FPM = std::make_unique<legacy::FunctionPassManager>(M.get());. // Add some optimizations.; FPM->add(createInstructionCombiningPass());; FPM->add(createReassociatePass());; FPM->add(createGVNPass());; FPM->add(createCFGSimplificationPass());; FPM->doInitialization();. // Run the optimizations over all functions in the module being added to; // the JIT.; for (auto &F : *M); FPM->run(F);. return M;; }. At the bottom of our JIT we add a private method to do the actual optimization:; *optimizeModule*. This function takes the module to be transformed as input (as; a ThreadSafeModule) along with a reference to a reference to a new class:; ``MaterializationResponsibility``. The MaterializationResponsibility argument; can be used to query JIT state for the module being transformed, such as the set; of definitions in the module that JIT'd code is actively trying to call/access.; For now we will ignore this argument and use a standard optimization; pipeline. To do this we set up a FunctionPassManager, add some passes to it, run; it over every function in the module, and then return the mutated module. The; specific optimizations are the same ones used in `Chapter 4 <LangImpl04.html>`_; of the ""Implementing a language with LLVM"" tutorial series. Readers may visit; that chapter for a more in-depth discussion of these, and of IR optimization in; general. And that's it in terms of changes to KaleidoscopeJIT: When a module is added via; addModule the OptimizeLayer will call our optimizeModule function before passing; the transformed module on to the CompileLayer below. Of course, we could have; called optimizeModule directly in our addModule function and not gone to the; bother of using the IRTransformLayer, but doing so gives us another opportunity; to see how layers compose. It also provides a neat entry point to the *layer*; concept itself, because IRTransformLayer is one of the simplest layers that; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:5451,optimiz,optimization,5451,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,1,['optimiz'],['optimization']
Performance,"t No True − Use weight to count kNN events. UseLDA No False − Use local linear discriminant - experimental feature. Configuration options for MVA method :. Configuration options reference for MVA method: BDT. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). NTrees No 800 − Number of trees in the forest. MaxDepth No 3 − Max depth of the decision tree allowed. MinNodeSize No 5% − Minimum percentage of training events required in a leaf node (default: Classification: 5%, Regression: 0.2%). nCuts No 20 − Number of grid points in variable range used in finding optimal cut in node splitting. BoostType No AdaBoost AdaBoost, RealAdaBoost, Bagging, AdaBoostR2, Grad Boosting type for the trees in the forest . AdaBoostR2Loss No Quadratic Linear, Quadratic, Exponential Type of Loss function in AdaBoostR2. UseBaggedGrad No False − Use only a random subsample of all events for growing the trees in each iteration. (Only valid for GradBoost). Shrinkage No 1 − Learning rate for GradBoost algorithm. AdaBoostBeta No 0.5 − Learning rate for AdaBoost algorithm. UseRandomisedTrees No False − Determine at each node splitting the cut variable only as the best out of a random subset of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:11844,perform,performance,11844,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,1,['perform'],['performance']
Performance,"t Opaque *__attribute__((NSObject)) objectPointer = ...;; ...; void (^foo)(void) = ^{ CFPrint(objectPointer); };. would have the following helper functions generated:. .. code-block:: c. void __block_copy_foo(struct __block_literal_5 *dst, struct __block_literal_5 *src) {; _Block_object_assign(&dst->objectPointer, src-> objectPointer, BLOCK_FIELD_IS_OBJECT);; }. void __block_dispose_foo(struct __block_literal_5 *src) {; _Block_object_dispose(src->objectPointer, BLOCK_FIELD_IS_OBJECT);; }. Imported ``__block`` marked variables; -------------------------------------. Layout of ``__block`` marked variables; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The compiler must embed variables that are marked ``__block`` in a specialized; structure of the form:. .. code-block:: c. struct _block_byref_foo {; void *isa;; struct Block_byref *forwarding;; int flags; //refcount;; int size;; typeof(marked_variable) marked_variable;; };. Variables of certain types require helper functions for when ``Block_copy()``; and ``Block_release()`` are performed upon a referencing ``Block``. At the ""C""; level only variables that are of type ``Block`` or ones that have; ``__attribute__((NSObject))`` marked require helper functions. In Objective-C; objects require helper functions and in C++ stack based objects require helper; functions. Variables that require helper functions use the form:. .. code-block:: c. struct _block_byref_foo {; void *isa;; struct _block_byref_foo *forwarding;; int flags; //refcount;; int size;; // helper functions called via Block_copy() and Block_release(); void (*byref_keep)(void *dst, void *src);; void (*byref_dispose)(void *);; typeof(marked_variable) marked_variable;; };. The structure is initialized such that:. a. The ``forwarding`` pointer is set to the beginning of its enclosing; structure. b. The ``size`` field is initialized to the total size of the enclosing; structure. c. The ``flags`` field is set to either 0 if no helper functions are needed; or (1<<25) if they a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst:11879,perform,performed,11879,interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,1,['perform'],['performed']
Performance,"t RFC`: https://lists.llvm.org/pipermail/llvm-dev/2021-September/153007.html. Binary Ids; ^^^^^^^^^^^^^^^^^^^^^^; The section is used to carry on `binary id`_ information from raw profiles. Temporal Profile Traces; ^^^^^^^^^^^^^^^^^^^^^^^^; The section is used to carry on temporal profile information from raw profiles.; See `temporal profiling`_ for the design. Profile Data Usage; =======================================. ``llvm-profdata`` is the command line tool to display and process instrumentation-; based profile data. For supported usages, check out `llvm-profdata documentation <https://llvm.org/docs/CommandGuide/llvm-profdata.html>`_. .. [1] For usage, see https://clang.llvm.org/docs/UsersManual.html#profiling-with-instrumentation; .. [2] For example, IR-based instrumentation supports `lightweight instrumentation`_; and `temporal profiling`_. Frontend instrumentation could support `single-byte counters`_.; .. [3] A raw profile file could contain the concatenation of multiple raw; profiles, for example, from an executable and its shared libraries. Raw; profile reader could parse all raw profiles from the file correctly.; .. [4] The counter section is used by a few variant types (like temporal; profiling) and might have different semantics there.; .. [5] The step size of data pointer is the ``sizeof(ProfileData)``, and the step; size of value profile pointer is calcuated based on the number of collected; values. .. _`lightweight instrumentation`: https://groups.google.com/g/llvm-dev/c/r03Z6JoN7d4; .. _`temporal profiling`: https://discourse.llvm.org/t/rfc-temporal-profiling-extension-for-irpgo/68068; .. _`single-byte counters`: https://discourse.llvm.org/t/rfc-single-byte-counters-for-source-based-code-coverage/75685; .. _`binary profile correlation`: https://discourse.llvm.org/t/rfc-add-binary-profile-correlation-to-not-load-profile-metadata-sections-into-memory-at-runtime/74565; .. _`binary id`: https://lists.llvm.org/pipermail/llvm-dev/2021-June/151154.html; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst:18302,load,load-profile-metadata-sections-into-memory-at-runtime,18302,interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,1,['load'],['load-profile-metadata-sections-into-memory-at-runtime']
Performance,"t ``-cl-kernel-arg-info`` enables more information about the original; kernel code to be added e.g. kernel parameter names will appear in the OpenCL; metadata along with other information. The IDs used to encode the OpenCL's logical address spaces in the argument info; metadata follows the SPIR address space mapping as defined in the SPIR; specification `section 2.2; <https://www.khronos.org/registry/spir/specs/spir_spec-2.0.pdf#18>`_. OpenCL Specific Options; -----------------------. In addition to the options described in :doc:`UsersManual` there are the; following options specific to the OpenCL frontend. All the options in this section are frontend-only and therefore if used; with regular clang driver they require frontend forwarding, e.g. ``-cc1``; or ``-Xclang``. .. _opencl_finclude_default_header:. .. option:: -finclude-default-header. Adds most of builtin types and function declarations during compilations. By; default the OpenCL headers are not loaded by the frontend and therefore certain; builtin types and most of builtin functions are not declared. To load them; automatically this flag can be passed to the frontend (see also :ref:`the; section on the OpenCL Header <opencl_header>`):. .. code-block:: console. $ clang -Xclang -finclude-default-header test.cl. Alternatively the internal header `opencl-c.h` containing the declarations; can be included manually using ``-include`` or ``-I`` followed by the path; to the header location. The header can be found in the clang source tree or; installation directory. .. code-block:: console. $ clang -I<path to clang sources>/lib/Headers/opencl-c.h test.cl; $ clang -I<path to clang installation>/lib/clang/<llvm version>/include/opencl-c.h/opencl-c.h test.cl. In this example it is assumed that the kernel code contains; ``#include <opencl-c.h>`` just as a regular C include. Because the header is very large and long to parse, PCH (:doc:`PCHInternals`); and modules (:doc:`Modules`) can be used internally to improve the comp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenCLSupport.rst:2908,load,loaded,2908,interpreter/llvm-project/clang/docs/OpenCLSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenCLSupport.rst,1,['load'],['loaded']
Performance,"t all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:271900,load,load,271900,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"t an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:8562,optimiz,optimize,8562,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['optimiz'],['optimize']
Performance,"t aware of atomics can treat this like a nothrow call. For; SequentiallyConsistent loads and stores, the same reorderings are allowed as; for Acquire loads and Release stores, except that SequentiallyConsistent; operations may not be reordered. Notes for code generation; SequentiallyConsistent loads minimally require the same barriers as Acquire; operations and SequentiallyConsistent stores require Release; barriers. Additionally, the code generator must enforce ordering between; SequentiallyConsistent stores followed by SequentiallyConsistent loads. This; is usually done by emitting either a full fence before the loads or a full; fence after the stores; which is preferred varies by architecture. Atomics and IR optimization; ===========================. Predicates for optimizer writers to query:. * ``isSimple()``: A load or store which is not volatile or atomic. This is; what, for example, memcpyopt would check for operations it might transform. * ``isUnordered()``: A load or store which is not volatile and at most; Unordered. This would be checked, for example, by LICM before hoisting an; operation. * ``mayReadFromMemory()``/``mayWriteToMemory()``: Existing predicate, but note; that they return true for any operation which is volatile or at least; Monotonic. * ``isStrongerThan`` / ``isAtLeastOrStrongerThan``: These are predicates on; orderings. They can be useful for passes that are aware of atomics, for; example to do DSE across a single atomic access, but not across a; release-acquire pair (see MemoryDependencyAnalysis for an example of this). * Alias analysis: Note that AA will return ModRef for anything Acquire or; Release, and for the address accessed by any Monotonic operation. To support optimizing around atomic operations, make sure you are using the; right predicates; everything should work if that is done. If your pass should; optimize some atomic operations (Unordered operations in particular), make sure; it doesn't replace an atomic load or store with a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:16047,load,load,16047,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['load'],['load']
Performance,"t by 1. Possible solutions; ^^^^^^^^^^^^^^^^^^; Let's briefly consider possible options about how and what we have to implement; in order to create full-featured functions merging, and also what it would; mean for us. Equal function detection obviously supposes that a ""detector"" method to be; implemented and latter should answer the question ""whether functions are equal"".; This ""detector"" method consists of tiny ""sub-detectors"", which each answers; exactly the same question, but for function parts. As the second step, we should merge equal functions. So it should be a ""merger""; method. ""Merger"" accepts two functions *F1* and *F2*, and produces *F1F2*; function, the result of merging. Having such routines in our hands, we can process a whole module, and merge all; equal functions. In this case, we have to compare every function with every another function. As; the reader may notice, this way seems to be quite expensive. Of course we could; introduce hashing and other helpers, but it is still just an optimization, and; thus the level of O(N*N) complexity. Can we reach another level? Could we introduce logarithmical search, or random; access lookup? The answer is: ""yes"". Random-access; """"""""""""""""""""""""""; How it could this be done? Just convert each function to a number, and gather; all of them in a special hash-table. Functions with equal hashes are equal.; Good hashing means, that every function part must be taken into account. That; means we have to convert every function part into some number, and then add it; into the hash. The lookup-up time would be small, but such an approach adds some; delay due to the hashing routine. Logarithmical search; """"""""""""""""""""""""""""""""""""""""; We could introduce total ordering among the functions set, once ordered we; could then implement a logarithmical search. Lookup time still depends on N,; but adds a little of delay (*log(N)*). Present state; """"""""""""""""""""""""""; Both of the approaches (random-access and logarithmical) have been implemented; and te",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst:5462,optimiz,optimization,5462,interpreter/llvm-project/llvm/docs/MergeFunctions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst,1,['optimiz'],['optimization']
Performance,"t care about block livein lists. - The (global) `liveins:` list is typically only interesting for early; instruction selection passes and can be removed when testing later passes.; The per-block `liveins:` on the other hand are necessary if; `tracksRegLiveness` is true. - Branch probability data in block `successors:` lists can be dropped if the; test doesn't depend on it. Example:; `successors: %bb.1(0x40000000), %bb.2(0x40000000)` can be replaced with; `successors: %bb.1, %bb.2`. - MIR code contains a whole IR module. This is necessary because there are; no equivalents in MIR for global variables, references to external functions,; function attributes, metadata, debug info. Instead some MIR data references; the IR constructs. You can often remove them if the test doesn't depend on; them. - Alias Analysis is performed on IR values. These are referenced by memory; operands in MIR. Example: `:: (load 8 from %ir.foobar, !alias.scope !9)`.; If the test doesn't depend on (good) alias analysis the references can be; dropped: `:: (load 8)`. - MIR blocks can reference IR blocks for debug printing, profile information; or debug locations. Example: `bb.42.myblock` in MIR references the IR block; `myblock`. It is usually possible to drop the `.myblock` reference and simply; use `bb.42`. - If there are no memory operands or blocks referencing the IR then the; IR function can be replaced by a parameterless dummy function like; `define @func() { ret void }`. - It is possible to drop the whole IR section of the MIR file if it only; contains dummy functions (see above). The .mir loader will create the; IR functions automatically in this case. .. _limitations:. Limitations; -----------. Currently the MIR format has several limitations in terms of which state it; can serialize:. - The target-specific state in the target-specific ``MachineFunctionInfo``; subclasses isn't serialized at the moment. - The target-specific ``MachineConstantPoolValue`` subclasses (in the ARM and; SystemZ b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MIRLangRef.rst:4641,load,load,4641,interpreter/llvm-project/llvm/docs/MIRLangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MIRLangRef.rst,1,['load'],['load']
Performance,"t command line option can be passed directly to tools such; as opt, llc and lli. The syntax is as follows:. ::. <tool name> [other options] -opt-bisect-limit=<limit>. If a value of -1 is used the tool will perform all optimizations but a message; will be printed to stderr for each optimization that could be skipped; indicating the index value that is associated with that optimization. To skip; optimizations, pass the value of the last optimization to be performed as the; opt-bisect-limit. All optimizations with a higher index value will be skipped. In order to use the -opt-bisect-limit option with a driver that provides a; wrapper around the LLVM core library, an additional prefix option may be; required, as defined by the driver. For example, to use this option with; clang, the ""-mllvm"" prefix must be used. A typical clang invocation would look; like this:. ::. clang -O2 -mllvm -opt-bisect-limit=256 my_file.c. The -opt-bisect-limit option may also be applied to link-time optimizations by; using a prefix to indicate that this is a plug-in option for the linker. The; following syntax will set a bisect limit for LTO transformations:. ::. # When using lld, or ld64 (macOS); clang -flto -Wl,-mllvm,-opt-bisect-limit=256 my_file.o my_other_file.o; # When using Gold; clang -flto -Wl,-plugin-opt,-opt-bisect-limit=256 my_file.o my_other_file.o. LTO passes are run by a library instance invoked by the linker. Therefore any; passes run in the primary driver compilation phase are not affected by options; passed via '-Wl,-plugin-opt' and LTO passes are not affected by options; passed to the driver-invoked LLVM invocation via '-mllvm'. Passing ``-opt-bisect-print-ir-path=path/foo.ll`` will dump the IR to; ``path/foo.ll`` when -opt-bisect-limit starts skipping passes. Bisection Index Values; ======================. The granularity of the optimizations associated with a single index value is; variable. Depending on how the optimization pass has been instrumented the; value may be asso",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst:2668,optimiz,optimizations,2668,interpreter/llvm-project/llvm/docs/OptBisect.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst,1,['optimiz'],['optimizations']
Performance,"t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Float_t fCharge; //Charge of this track; Float_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion. // method definitions ...; ClassDef(Track,1) //A track segment; };; ```. ### Writing the Tree. We create a simple tree with two branches both holding `Event` objects.; One is split and the other is not. We also create a pointer to an; `Event` object (`event`). ``` {.cpp}; void tree4w() {; // check to see if the event class is in the dictionary; // if it is not load the definition in libEvent.so; if (!TClassTable::GetDict(""Event"")) {; gSystem->Load(""$ROOTSYS/test/libEvent.so"");; }; // create a Tree file tree4.root; TFile f(""tree4.root"",""RECREATE"");; // create a ROOT Tree; TTree t4(""t4"",""A Tree with Events"");; // create a pointer to an Event object; Event *event = new Event();; // create two branches, split one; t4.Branch(""event_branch"", ""Event"", &event,16000,2);; t4.Branch(""event_not_split"", ""Event"", &event,16000,0);. // a local variable for the event type; char etype[20];. // fill the tree; for (Int_t ev = 0; ev <100; ev++) {; Float_t sigmat, sigmas;; gRandom->Rannor(sigmat,sigmas);; Int_t ntrack = Int_t(600 + 600 *sigmat/120.);; Float_t random = gRandom->Rndm(1);; sprintf(etype,""type%d"",ev%5);; event->SetType(etype);; event->SetHeader(ev, 200, 960312, random);; event->SetNseg(Int_t(10*ntrack+20*sigmas));; event->SetNvertex(Int_t(1+20*gRandom->Rndm()));; event->SetFlag(UInt_t(random+0.5));; event->SetTemperatu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:62339,load,load,62339,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['load'],['load']
Performance,"t from hadd a better way to invoke Merge for; generic objects; add option to merge histograms in one go, instead of; one-by-one as for generic objects (this option is not yet supported by; hadd). TProofOutputFile. Add support for the placeholder <file>; the definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround for the wrong TTreeCache initialization at the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; TChain's; in multi-master mode. The Mass Storage Domain must be specified as; option in the URL.              ; chain.AddFile(""root:// .....?msd=CERN"").  and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of the processing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/act",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:4614,perform,performance,4614,proof/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html,1,['perform'],['performance']
Performance,"t from significantly faster times for fitting by calling `fitTo()` and providing a `BatchMode(""cpu"")` or a `BatchMode(""cuda"")` option.; ``` {.cpp}; // fit using the most efficient library that the computer's CPU can support; RooMyPDF.fitTo(data, BatchMode(""cpu""));. // fit using the CUDA library along with the most efficient library that the computer's CPU can support; RooMyPDF.fitTo(data, BatchMode(""cuda""));; ```; **Note: In case the system does not support vector instructions, the `RooBatchCompute::Cpu` option is guaranteed to work properly by using a generic CPU library. In contrast, users must first make sure that their system supports CUDA in order to use the `RooBatchCompute::Cuda` option. If this is not the case, an exception will be thrown.**. If `""cuda""` is selected, RooFit will launch CUDA kernels for computing likelihoods and potentially other intense computations. At the same time, the most efficient CPU library loaded will also handle parts of the computations in parallel with the GPU (or potentially, if it's faster, all of them), thus gaining full advantage of the available hardware. For this purpose `RooFitDriver`, a newly created RooFit class (in roofitcore) takes over the task of analyzing the computations and assigning each to the correct piece of hardware, taking into consideration the performance boost or penalty that may arise with every method of computing. #### Multithread computations; The CPU instance of the computing library can furthermore execute multithread computations. This also applies for computations handled by the CPU in the `""cuda""` mode. To use them, one needs to set the desired number of parallel tasks before calling `fitTo()` as shown below:; ``` {.cpp}; ROOT::EnableImplicitMT(nThreads);; RooMyPDF.fitTo(data, BatchMode(""cuda"")); // can also use ""cuda""; ```. ### User-made PDFs; The easiest and most efficient way of accelerating your PDFs is to request their addition to the official RooFit by submitting a ticket [here](https://git",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md:2670,load,loaded,2670,roofit/doc/developers/batchcompute.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md,1,['load'],['loaded']
Performance,"t guarantees that a total; ordering exists between all SequentiallyConsistent operations. Relevant standard; This corresponds to the C++/C ``memory_order_seq_cst``, Java volatile, and; the gcc-compatible ``__sync_*`` builtins which do not specify otherwise. Notes for frontends; If a frontend is exposing atomic operations, these are much easier to reason; about for the programmer than other kinds of operations, and using them is; generally a practical performance tradeoff. Notes for optimizers; Optimizers not aware of atomics can treat this like a nothrow call. For; SequentiallyConsistent loads and stores, the same reorderings are allowed as; for Acquire loads and Release stores, except that SequentiallyConsistent; operations may not be reordered. Notes for code generation; SequentiallyConsistent loads minimally require the same barriers as Acquire; operations and SequentiallyConsistent stores require Release; barriers. Additionally, the code generator must enforce ordering between; SequentiallyConsistent stores followed by SequentiallyConsistent loads. This; is usually done by emitting either a full fence before the loads or a full; fence after the stores; which is preferred varies by architecture. Atomics and IR optimization; ===========================. Predicates for optimizer writers to query:. * ``isSimple()``: A load or store which is not volatile or atomic. This is; what, for example, memcpyopt would check for operations it might transform. * ``isUnordered()``: A load or store which is not volatile and at most; Unordered. This would be checked, for example, by LICM before hoisting an; operation. * ``mayReadFromMemory()``/``mayWriteToMemory()``: Existing predicate, but note; that they return true for any operation which is volatile or at least; Monotonic. * ``isStrongerThan`` / ``isAtLeastOrStrongerThan``: These are predicates on; orderings. They can be useful for passes that are aware of atomics, for; example to do DSE across a single atomic access, but not a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:15614,load,loads,15614,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['load'],['loads']
Performance,"t happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:259263,load,load,259263,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"t have an address available. When; the function returns (either with the ``ret`` or ``resume`` instructions),; the memory is reclaimed. Allocating zero bytes is legal, but the returned; pointer may not be unique. The order in which memory is allocated (ie.,; which way the stack grows) is not specified. Note that '``alloca``' outside of the alloca address space from the; :ref:`datalayout string<langref_datalayout>` is meaningful only if the; target has assigned it a semantics. If the returned pointer is used by :ref:`llvm.lifetime.start <int_lifestart>`,; the returned object is initially dead.; See :ref:`llvm.lifetime.start <int_lifestart>` and; :ref:`llvm.lifetime.end <int_lifeend>` for the precise semantics of; lifetime-manipulating intrinsics. Example:; """""""""""""""". .. code-block:: llvm. %ptr = alloca i32 ; yields ptr; %ptr = alloca i32, i32 4 ; yields ptr; %ptr = alloca i32, i32 4, align 1024 ; yields ptr; %ptr = alloca i32, align 1024 ; yields ptr. .. _i_load:. '``load``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = load [volatile] <ty>, ptr <pointer>[, align <alignment>][, !nontemporal !<nontemp_node>][, !invariant.load !<empty_node>][, !invariant.group !<empty_node>][, !nonnull !<empty_node>][, !dereferenceable !<deref_bytes_node>][, !dereferenceable_or_null !<deref_bytes_node>][, !align !<align_node>][, !noundef !<empty_node>]; <result> = load atomic [volatile] <ty>, ptr <pointer> [syncscope(""<target-scope>"")] <ordering>, align <alignment> [, !invariant.group !<empty_node>]; !<nontemp_node> = !{ i32 1 }; !<empty_node> = !{}; !<deref_bytes_node> = !{ i64 <dereferenceable_bytes> }; !<align_node> = !{ i64 <value_alignment> }. Overview:; """""""""""""""""". The '``load``' instruction is used to read from memory. Arguments:; """""""""""""""""""". The argument to the ``load`` instruction specifies the memory address from which; to load. The type specified must be a :ref:`first class <t_firstclass>` type of; known size (i.e. not containing an :ref:`opaque structu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:411826,load,load,411826,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"t helps streamline `RDataFrame` workflows in a distributed environment. Currently only a subset of `RDataFrame` actions have their corresponding mergeable class, but in the future it will be possible to extend it to any action through the creation of a new `RMergeableValue` derived class. ### Behavior changes. - `Snapshot` now respects the basket size and split level of the original branch when copying branches to a new `TTree`.; - `Snapshot` now writes branches coming from friend `TTree`s even if they have the same name as branches in the main tree (`friendname_` is prepended to the name of the output branches). More details at [#7181](https://github.com/root-project/root/issues/7181).; - Just-in-time compilation of string expressions passed to `Filter` and `Define` now generates functions that take fundamental types by const value (rather than by non-const reference as before). This will break code that was assigning to column values in string expressions: this is an intended side effect as we want to prevent non-expert users from performing assignments (`=`) rather than comparisons (`==`). Expert users can resort to compiled callables if they absolutely have to assign to column values (not recommended). See [ROOT-11009](https://sft.its.cern.ch/jira/browse/ROOT-11009) for further discussion.; - For some `TTrees`, `RDataFrame::GetColumnNames` might now returns multiple valid spellings for a given column. For example, leaf `""l""` under branch `""b""` might now be mentioned as `""l""` as well as `""b.l""`, while only one of the two spellings might have been recognized before.; - Certain RDF-related types in the `ROOT::Detail` and `ROOT::Internal` namespaces have been renamed, most notably `RCustomColumn` is now `RDefine`. This does not impact code that only makes use of entities in the public ROOT namespace, and should not impact downstream code unless it was patching or reusing internal `RDataFrame` types. ### Notable bug fixes and improvements. - A critical issue has been ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:8448,perform,performing,8448,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['perform'],['performing']
Performance,"t i32 %added, %bar.0, !dbg !5; br i1 %cond, label %bb1, label %bb2, !dbg !5. bb2: ; preds = %bb1; ret i32 0, !dbg !5; }. If one compiles this IR with ``llc -o - -start-after=codegen-prepare -stop-after=expand-isel-pseudos -mtriple=x86_64--``, the following MIR is produced:. .. code-block:: text. bb.0.entry:; successors: %bb.1(0x80000000); liveins: $rdi. %2:gr64 = COPY $rdi; %3:gr32 = MOV32r0 implicit-def dead $eflags; DBG_VALUE 0, $noreg, !3, !DIExpression(), debug-location !5. bb.1.bb1:; successors: %bb.1(0x7c000000), %bb.2(0x04000000). %0:gr32 = PHI %3, %bb.0, %1, %bb.1; DBG_VALUE %0, $noreg, !3, !DIExpression(), debug-location !5; DBG_VALUE %2, $noreg, !3, !DIExpression(DW_OP_plus_uconst, 4, DW_OP_stack_value), debug-location !5; %4:gr32 = MOV32rm %2, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); %5:gr64_nosp = MOVSX64rr32 %0, debug-location !5; DBG_VALUE $noreg, $noreg, !3, !DIExpression(), debug-location !5; %1:gr32 = INC32r %0, implicit-def dead $eflags, debug-location !5; DBG_VALUE %1, $noreg, !3, !DIExpression(), debug-location !5; %6:gr32 = ADD32rm %4, %2, 4, killed %5, 0, $noreg, implicit-def dead $eflags :: (load 4 from %ir.addr2); %7:gr32 = SUB32rr %6, %0, implicit-def $eflags, debug-location !5; JB_1 %bb.1, implicit $eflags, debug-location !5; JMP_1 %bb.2, debug-location !5. bb.2.bb2:; %8:gr32 = MOV32r0 implicit-def dead $eflags; $eax = COPY %8, debug-location !5; RET 0, $eax, debug-location !5. Observe first that there is a DBG_VALUE instruction for every ``llvm.dbg.value``; intrinsic in the source IR, ensuring no source level assignments go missing.; Then consider the different ways in which variable locations have been recorded:. * For the first dbg.value an immediate operand is used to record a zero value.; * The dbg.value of the PHI instruction leads to a DBG_VALUE of virtual register; ``%0``.; * The first GEP has its effect folded into the first load instruction; (as a 4-byte offset), but the variable location is salvaged by ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:31463,load,load,31463,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['load'],['load']
Performance,"t identify itself as Windows, and thus gets path::Style::posix; # as native path style, regardless of what this is set to.; set(WINDOWS_PREFER_FORWARD_SLASH_DEFAULT ON); endif(); option(LLVM_WINDOWS_PREFER_FORWARD_SLASH ""Prefer path names with forward slashes on Windows."" ${WINDOWS_PREFER_FORWARD_SLASH_DEFAULT}). option(LLVM_ENABLE_FFI ""Use libffi to call external functions from the interpreter"" OFF); set(FFI_LIBRARY_DIR """" CACHE PATH ""Additional directory, where CMake should search for libffi.so""); set(FFI_INCLUDE_DIR """" CACHE PATH ""Additional directory, where CMake should search for ffi.h or ffi/ffi.h""). set(LLVM_TARGET_ARCH ""host""; CACHE STRING ""Set target to use for LLVM JIT or use \""host\"" for automatic detection.""). option(LLVM_ENABLE_TERMINFO ""Use terminfo database if available."" ON). set(LLVM_ENABLE_LIBXML2 ""ON"" CACHE STRING ""Use libxml2 if available. Can be ON, OFF, or FORCE_ON""). option(LLVM_ENABLE_LIBEDIT ""Use libedit if available."" ON). option(LLVM_ENABLE_LIBPFM ""Use libpfm for performance counters if available."" ON). # On z/OS, threads cannot be used because TLS is not supported.; if (CMAKE_SYSTEM_NAME MATCHES ""OS390""); option(LLVM_ENABLE_THREADS ""Use threads if available."" OFF); else(); option(LLVM_ENABLE_THREADS ""Use threads if available."" ON); endif(). set(LLVM_ENABLE_ZLIB ""ON"" CACHE STRING ""Use zlib for compression/decompression if available. Can be ON, OFF, or FORCE_ON""). set(LLVM_ENABLE_ZSTD ""ON"" CACHE STRING ""Use zstd for compression/decompression if available. Can be ON, OFF, or FORCE_ON""). set(LLVM_USE_STATIC_ZSTD FALSE CACHE BOOL ""Use static version of zstd. Can be TRUE, FALSE""). set(LLVM_ENABLE_CURL ""OFF"" CACHE STRING ""Use libcurl for the HTTP client if available. Can be ON, OFF, or FORCE_ON""). set(LLVM_ENABLE_HTTPLIB ""OFF"" CACHE STRING ""Use cpp-httplib HTTP server library if available. Can be ON, OFF, or FORCE_ON""). set(LLVM_Z3_INSTALL_DIR """" CACHE STRING ""Install directory of the Z3 solver.""). option(LLVM_ENABLE_Z3_SOLVER; ""Enable Support fo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:22176,perform,performance,22176,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['perform'],['performance']
Performance,"t in memory when reading or writing.; When reading this write basket was always present in memory even if the branch was never accessed. Starting in v5.20/00, TTree::Write closes out, compresses (when requested) and writes to disk in their own file record the write baskets of all the branches.; (This is implemented via the new function TTree::FlushBaskets, TBranch::FlushBaskets, TBranch::FlushOneBaskets). TTree::AutoSave supports a new option ""FlushBaskets"" which will call FlushBaskets before saving the TTree object. Benefits. Flushing the write baskets has several advantages:. Reduce the file size of the TTree object (it not longer contains the last basket), improving read time of the TTree object; Reduce memory footprint of the TTree object.; In a TTree which ""flushed"" buffer, there is now usually only zero or one buffer in memory.; Previously each branch always had at least one basket in memory and usually 2 (the write basket and one read basket).; Now only the basket of the branches actually read are loaded in memory. allow for the basket to be compressed and stored separated, increasing the compression factor. Note: Calling FlushBaskets too often (either directly of via AutoSave(""FlushBaskets"")) can lead to unnecessary fragmentation of the ROOT file,; since it write the baskets to disk (and a new basket will be started at the next fill) whether or not the content was close to filling the basket or not. Others. The fast tree cloning (TTreeCloner) was enhanced to support copying in-memory TTrees (that have been save as a single key on file). This issue was preventing hadd to fast clone files containing any 'in-memory' tree. Re-enabled the splitting of TVector3 and of any classes starting by TVector; that is not a TVectorT.; Fix the list of StreamerInfo stored in the TFile in the case of a slow; CloneTree, previously some of the classes whose named contained '::' and any; of the STL container names was inadvertently omitted (in case of classes; that are part of the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:6991,load,loaded,6991,tree/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html,1,['load'],['loaded']
Performance,"t is that it evaluates ""``BB->end()``"" every time; through the loop. Instead of writing the loop like this, we strongly prefer; loops to be written so that they evaluate it once before the loop starts. A; convenient way to do this is like so:. .. code-block:: c++. BasicBlock *BB = ...; for (auto I = BB->begin(), E = BB->end(); I != E; ++I); ... use I ... The observant may quickly point out that these two loops may have different; semantics: if the container (a basic block in this case) is being mutated, then; ""``BB->end()``"" may change its value every time through the loop and the second; loop may not in fact be correct. If you actually do depend on this behavior,; please write the loop in the first form and add a comment indicating that you; did it intentionally. Why do we prefer the second form (when correct)? Writing the loop in the first; form has two problems. First it may be less efficient than evaluating it at the; start of the loop. In this case, the cost is probably minor --- a few extra; loads every time through the loop. However, if the base expression is more; complex, then the cost can rise quickly. I've seen loops where the end; expression was actually something like: ""``SomeMap[X]->end()``"" and map lookups; really aren't cheap. By writing it in the second form consistently, you; eliminate the issue entirely and don't even have to think about it. The second (even bigger) issue is that writing the loop in the first form hints; to the reader that the loop is mutating the container (a fact that a comment; would handily confirm!). If you write the loop in the second form, it is; immediately obvious without even looking at the body of the loop that the; container isn't being modified, which makes it easier to read the code and; understand what it does. While the second form of the loop is a few extra keystrokes, we do strongly; prefer it. ``#include <iostream>`` is Forbidden; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The use of ``#include <iostream>`` in library",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:54092,load,loads,54092,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['load'],['loads']
Performance,"t is; currently assumed that the operation is of pointer size and the alignment is; assumed to be the target machine's default alignment. Write barrier: ``llvm.gcwrite``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.gcwrite(i8* %value, i8* %object, i8** %derived). For write barriers, LLVM provides the ``llvm.gcwrite`` intrinsic function. It; has exactly the same semantics as a non-volatile ``store`` to the derived; pointer (the third argument). The exact code generated is specified by the; Function's selected :ref:`GC strategy <plugin>`. Many important algorithms require write barriers, including generational and; concurrent collectors. Additionally, write barriers could be used to implement; reference counting. Read barrier: ``llvm.gcread``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. i8* @llvm.gcread(i8* %object, i8** %derived). For read barriers, LLVM provides the ``llvm.gcread`` intrinsic function. It has; exactly the same semantics as a non-volatile ``load`` from the derived pointer; (the second argument). The exact code generated is specified by the Function's; selected :ref:`GC strategy <plugin>`. Read barriers are needed by fewer algorithms than write barriers, and may have a; greater performance impact since pointer reads are more frequent than writes. .. _plugin:. .. _builtin-gc-strategies:. Built In GC Strategies; ======================. LLVM includes built in support for several varieties of garbage collectors. The Shadow Stack GC; ----------------------. To use this collector strategy, mark your functions with:. .. code-block:: c++. F.setGC(""shadow-stack"");. Unlike many GC algorithms which rely on a cooperative code generator to compile; stack maps, this algorithm carefully maintains a linked list of stack roots; [:ref:`Henderson2002 <henderson02>`]. This so-called ""shadow stack"" mirrors the; machine stack. Maintaining this data structure is slower than using a stack map; compiled into the executable as constant data, but ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:15496,load,load,15496,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['load'],['load']
Performance,"t it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to :ref:`register your pass; <writing-an-llvm-pass-registration>`). Because the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -load lib/LLVMHello.so -help; OVERVIEW: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] [options] <input bitcode file>. OPTIONS:; Optimizations available:; ...; -guard-widening - Widen guards; -gvn - Global Value Numbering; -gvn-hoist - Early GVN Hoisting of Expressions; -hello - Hello World Pass; -indvars - Induction Variable Simplification; -inferattrs - Infer set function attributes; ... The pass name gets added as the information string for your pass, giving some; documentation to users of :program:`opt`. Now that you have a working pass,; you would go ahead and make it do the cool transformations you want. Once you; get it all working and tested, it may become useful to find out how fast your; pass is. The :ref:`PassManager <writing-an-llvm-pass-passmanager>` provides a; nice command line option (:option:`-time-passes`) that allows you to get; information about the execution time of your pass along with the other passes; you queue up. For example:. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello -time-passes ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:8967,optimiz,optimizer,8967,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['optimiz'],['optimizer']
Performance,"t it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representing the core idea of a; predicate guarding potentially invalid loads:; ```; void leak(int data);; void example(int* pointer1, int* pointer2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : pred",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:3064,load,loads,3064,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loads']
Performance,"t node or path has not; been changed by the user. \anchor GP02ga; #### Finding If Current State Is Changed For a New Point. One can find fast if a point different from the current one has or not; the same location inside the geometry tree. To do that, the new point; should not be introduced by using TGeoManager::SetCurrentPoint(); method, but rather by calling the specific method:. ~~~{.cpp}; Bool_t TGeoManager::IsSameLocation(Double_t x,Double_t y,; Double_t z,Bool_t change=kFALSE);; ~~~. In the prototype above, `x, y` and `z` are the coordinates of the new; point. The modeller will check whether the current volume still contains; the new point or its location has changed in the geometry hierarchy. If; the new location is different, two actions are possible according to the; value of `change`:. - `change = kFALSE` (default) - the modeller does not change the; current state but just inform the caller about this change.; - `change = kTRUE` - the modeller will actually perform a new; `‘Where am I?' `search after finding out that the location has; changed. The current state will be actualized accordingly. Note that even when performing a normal search on the current state; after changing the current point coordinates (e.g.; `gGeoManager->FindNode(newX,newY,newZ)`), users can always query if the; previous state has changed by using a method having the same name but; without parameters:. ~~~{.cpp}; Bool_t TGeoManager::IsSameLocation();; ~~~. \anchor GP02gb; #### Finding the Distance to the Next Boundary. All tracking engines need to compare the currently proposed physical; step with the maximum allowed distance in the current material. The; modeller provides this information by computing the distance to the; first boundary starting from the current point along a straight line.; The starting point and direction for this procedure are the ones; corresponding to the current state. The boundary search is initialized; inside the current volume and the crossed boundary can belo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:75418,perform,perform,75418,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['perform']
Performance,"t of an erroneous operation.; In order to facilitate speculative execution, many instructions do not; invoke immediate undefined behavior when provided with illegal operands,; and return a poison value instead.; The string '``poison``' can be used anywhere a constant is expected, and; operations such as :ref:`add <i_add>` with the ``nsw`` flag can produce; a poison value. Most instructions return '``poison``' when one of their arguments is; '``poison``'. A notable exception is the :ref:`select instruction <i_select>`.; Propagation of poison can be stopped with the; :ref:`freeze instruction <i_freeze>`. It is correct to replace a poison value with an; :ref:`undef value <undefvalues>` or any value of the type. This means that immediate undefined behavior occurs if a poison value is; used as an instruction operand that has any values that trigger undefined; behavior. Notably this includes (but is not limited to):. - The pointer operand of a :ref:`load <i_load>`, :ref:`store <i_store>` or; any other pointer dereferencing instruction (independent of address; space).; - The divisor operand of a ``udiv``, ``sdiv``, ``urem`` or ``srem``; instruction.; - The condition operand of a :ref:`br <i_br>` instruction.; - The callee operand of a :ref:`call <i_call>` or :ref:`invoke <i_invoke>`; instruction.; - The parameter operand of a :ref:`call <i_call>` or :ref:`invoke <i_invoke>`; instruction, when the function or invoking call site has a ``noundef``; attribute in the corresponding position.; - The operand of a :ref:`ret <i_ret>` instruction if the function or invoking; call site has a `noundef` attribute in the return value position. Here are some examples:. .. code-block:: llvm. entry:; %poison = sub nuw i32 0, 1 ; Results in a poison value.; %poison2 = sub i32 poison, 1 ; Also results in a poison value.; %still_poison = and i32 %poison, 0 ; 0, but also poison.; %poison_yet_again = getelementptr i32, ptr @h, i32 %still_poison; store i32 0, ptr %poison_yet_again ; Undefined beha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:197721,load,load,197721,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"t of known class methods. It can be extended by users.; 12. Use of cached methods improves binary I/O performance by 20%; 13. Support TGaxis; 14. Project now can be obtained via 'bower install jsroot'; 15. Support 'scat' and 'text' draw options for TH2; 16. Support in binary I/O zipped buffer bigger than 16M; 17. Correctly handle in binary I/O pointer on TArray object (like in THnSparseArrayChunk). ## Changes in 4.3; 1. Implement TGeoCtub, TGeoParaboloid and TGeoHype shapes; 2. Support TGeoTube with Rmin==0; 3. Exclude empty faces in TGeoArb8; 4. Improve TGeoSphere creation - handle all parameters combinations; 5. Introduce JSROOT.cleanup() function to safely clear all drawn objects; 6. Fix wrong resize method in 'tabs' and 'collapsible' layouts; 7. Fix canvas resize problem (issue #27); 8. Fix zero-height canvas when draw TGeo in collapsible layout; 9. Fix problem of simultaneous move TGeo drawings and canvas in flexible layout. ## Changes in 4.2; 1. Significant performance improvements in 3D drawings - TGeo/TH2/TH3; 2. Implement TGeoPara, TGeoGtra, TGeoXtru and TGeoEltu shapes; 3. Optimize (reduce vertices number) for others TGeo shapes; 4. Correct rotation/translation/scaling of TGeo nodes; 5. Workaround for axis reflection (not directly supported in three.js); 6. Support array of objects in I/O (like in TAxis3D); 7. Correct reading of multi-dim arrays like Double_t fXY[8][2];; 8. Provide canvas toolbar for actions like savepng or unzoom; 9. Implement JSROOT.resize() function to let resize drawing after changes in page layout; 10. Fix error with title display/update. ## Changes in 4.1; 1. Introduce object inspector - one could browse object members of any class; 2. Let draw sub-items from TCanvas list of primitives like sub-pad or TLatex; 3. Provide possibility to save drawn SVG canvas as PNG; 4. TGraph drawing optimization - limit number of drawn points; 5. Implement painter for TPolyMarker3D; 6. Improve drawing and update of TMultiGraph; 7. Reorganize 3D drawing",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:58236,perform,performance,58236,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['perform'],['performance']
Performance,"t one has or not; the same location inside the geometry tree. To do that, the new point; should not be introduced by using TGeoManager::SetCurrentPoint(); method, but rather by calling the specific method:. ~~~{.cpp}; Bool_t TGeoManager::IsSameLocation(Double_t x,Double_t y,; Double_t z,Bool_t change=kFALSE);; ~~~. In the prototype above, `x, y` and `z` are the coordinates of the new; point. The modeller will check whether the current volume still contains; the new point or its location has changed in the geometry hierarchy. If; the new location is different, two actions are possible according to the; value of `change`:. - `change = kFALSE` (default) - the modeller does not change the; current state but just inform the caller about this change.; - `change = kTRUE` - the modeller will actually perform a new; `‘Where am I?' `search after finding out that the location has; changed. The current state will be actualized accordingly. Note that even when performing a normal search on the current state; after changing the current point coordinates (e.g.; `gGeoManager->FindNode(newX,newY,newZ)`), users can always query if the; previous state has changed by using a method having the same name but; without parameters:. ~~~{.cpp}; Bool_t TGeoManager::IsSameLocation();; ~~~. \anchor GP02gb; #### Finding the Distance to the Next Boundary. All tracking engines need to compare the currently proposed physical; step with the maximum allowed distance in the current material. The; modeller provides this information by computing the distance to the; first boundary starting from the current point along a straight line.; The starting point and direction for this procedure are the ones; corresponding to the current state. The boundary search is initialized; inside the current volume and the crossed boundary can belong either to; the current node or to one of its daughters. The full prototype of the; method is:. ~~~{.cpp}; TGeoNode *TGeoManager::FindNextBoundary(Double_t step=kBig);; ~~~. I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:75576,perform,performing,75576,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performing']
Performance,"t operates within the same; address space as other independent flows of controls within a process.; In most UNIX systems, thread and process characteristics are grouped; into a single entity called a process. Sometimes, threads are called; ""lightweight processes''. Note: This introduction is adapted from the AIX 4.3 Programmer's Manual. ## Threads and Processes. In traditional single-threaded process systems, a process has a set of; properties. In multi-threaded systems, these properties are divided; between processes and threads. ### Process Properties. A process in a multi-threaded system is the changeable entity. It must; be considered as an execution frame. It has all traditional process; attributes, such as:. - Process ID, process group ID, user ID, and group ID. - Environment. - Working directory. A process also provides a common address space and common system; resources:. - File descriptors. - Signal actions. - Shared libraries. - Inter-process communication tools (such as message queues, pipes,; semaphores, or shared memory). ### Thread Properties. A thread is the schedulable entity. It has only those properties that; are required to ensure its independent flow of control. These include; the following properties:. - Stack. - Scheduling properties (such as policy or priority). - Set of pending and blocked signals. - Some thread-specific data (TSD). An example of thread-specific data is the error indicator, `errno`. In; multi-threaded systems, `errno` is no longer a global variable, but; usually a subroutine returning a thread-specific `errno` value. Some; other systems may provide other implementations of `errno`. With respect; to ROOT, a thread specific data is for example the ***`gPad`*** pointer,; which is treated in a different way, whether it is accessed from any; thread or the main thread. Threads within a process must not be considered as a group of processes; (even though in Linux each thread receives an own process id, so that it; can be scheduled b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:1061,queue,queues,1061,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['queue'],['queues']
Performance,"t optimizations in the middle-end. Rematerialization; of hoisted instructions to reduce register pressure is the responsibility of; the back-end, which has more accurate information about register pressure and; also handles other optimizations than LICM that increase live-ranges. This pass uses alias analysis for two purposes:. #. Moving loop invariant loads and calls out of loops. If we can determine; that a load or call inside of a loop never aliases anything stored to, we; can hoist it or sink it like any other instruction. #. Scalar Promotion of Memory. If there is a store instruction inside of the; loop, we try to move the store to happen AFTER the loop instead of inside of; the loop. This can only happen if a few conditions are true:. #. The pointer stored through is loop invariant.; #. There are no stores or loads in the loop which *may* alias the pointer.; There are no calls in the loop which mod/ref the pointer. If these conditions are true, we can promote the loads and stores in the; loop of the pointer to use a temporary alloca'd variable. We then use the; :ref:`mem2reg <passes-mem2reg>` functionality to construct the appropriate; SSA form for the variable. ``loop-deletion``: Delete dead loops; ------------------------------------. This file implements the Dead Loop Deletion Pass. This pass is responsible for; eliminating loops with non-infinite computable trip counts that have no side; effects or volatile instructions, and do not contribute to the computation of; the function's return value. .. _passes-loop-extract:. ``loop-extract``: Extract loops into new functions; --------------------------------------------------. A pass wrapper around the ``ExtractLoop()`` scalar transformation to extract; each top-level loop into its own new function. If the loop is the *only* loop; in a given function, it is not touched. This is a pass most useful for; debugging via bugpoint. ``loop-reduce``: Loop Strength Reduction; ----------------------------------------. This",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:24959,load,loads,24959,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['load'],['loads']
Performance,"t possible to specify that a particular one of the input; location descriptions is undefined. See the ``DW_OP_LLVM_undefined`` operation in; :ref:`amdgpu-dwarf-undefined-location-description-operations`. 2.6 Generalize Creation of Composite Location Descriptions; ----------------------------------------------------------. To allow composition of composite location descriptions, an explicit operation; that indicates the end of the definition of a composite location description is; required. This can be implied if the end of a DWARF expression is reached,; allowing current DWARF expressions to remain legal. See ``DW_OP_LLVM_piece_end`` in; :ref:`amdgpu-dwarf-composite-location-description-operations`. 2.7 Generalize DWARF Base Objects to Allow Any Location Description Kind; ------------------------------------------------------------------------. The number of registers and the cost of memory operations is much higher for; AMDGPU than a typical CPU. The compiler attempts to optimize whole variables and; arrays into registers. Currently DWARF only allows ``DW_OP_push_object_address`` and related operations; to work with a global memory location. To support AMDGPU optimized code it is; required to generalize DWARF to allow any location description to be used. This; allows registers, or composite location descriptions that may be a mixture of; memory, registers, or even implicit values. See ``DW_OP_push_object_address`` in; :ref:`amdgpu-dwarf-general-location-description-operations`. 2.8 General Support for Address Spaces; --------------------------------------. AMDGPU needs to be able to describe addresses that are in different kinds of; memory. Optimized code may need to describe a variable that resides in pieces; that are in different kinds of storage which may include parts of registers,; memory that is in a mixture of memory kinds, implicit values, or be undefined. DWARF has the concept of segment addresses. However, the segment cannot be; specified within a DWARF e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:16262,optimiz,optimize,16262,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['optimiz'],['optimize']
Performance,"t present) does steps 6/7/8 for you. Common Problems; ===============. If you are having problems building or using LLVM, or if you have any other; general questions about LLVM, please consult the `Frequently Asked; Questions <FAQ.html>`_ page. If you are having problems with limited memory and build time, please try; building with ninja instead of make. Please consider configuring the; following options with cmake:. * -G Ninja; Setting this option will allow you to build with ninja instead of make.; Building with ninja significantly improves your build time, especially with; incremental builds, and improves your memory usage. * -DLLVM_USE_LINKER; Setting this option to lld will significantly reduce linking time for LLVM; executables on ELF-based platforms, such as Linux. If you are building LLVM; for the first time and lld is not available to you as a binary package, then; you may want to use the gold linker as a faster alternative to GNU ld. * -DCMAKE_BUILD_TYPE; Controls optimization level and debug information of the build. This setting; can affect RAM and disk usage, see :ref:`CMAKE_BUILD_TYPE <cmake_build_type>`; for more information. * -DLLVM_ENABLE_ASSERTIONS; This option defaults to ON for Debug builds and defaults to OFF for Release; builds. As mentioned in the previous option, using the Release build type and; enabling assertions may be a good alternative to using the Debug build type. * -DLLVM_PARALLEL_LINK_JOBS; Set this equal to number of jobs you wish to run simultaneously. This is; similar to the -j option used with make, but only for link jobs. This option; can only be used with ninja. You may wish to use a very low number of jobs,; as this will greatly reduce the amount of memory used during the build; process. If you have limited memory, you may wish to set this to 1. * -DLLVM_TARGETS_TO_BUILD; Set this equal to the target you wish to build. You may wish to set this to; X86; however, you will find a full list of targets within the; llvm-project/ll",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:44764,optimiz,optimization,44764,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['optimiz'],['optimization']
Performance,"t require a definition.; root [] foo::bar *baz1; // #2: does not require a definition.; root [] foo::bar baz2; // #3: requires a definition.; root [] TCanvas* c = new TCanvas(); // #4 requires a definition; ```. The implementation avoids recursive actions and relies on a well-defined (by; the C++ standard) behavior. Currently, this comes with a constant performance; overhead which we go in details bellow. ROOT uses the global module index (GMI) to avoid the performance overhead. ROOT; only preloads the set of C++ modules which are not present in the GMI. The; example becomes equivalent to:. ```cpp; // ROOT prompt; root [] import Foo.*; // Preload Foo if it is not in the GMI.; root [] S *s; // #1: does not require a definition.; root [] foo::bar *baz1; // #2: does not require a definition.; root [] foo::bar baz2; // #3: requires a definition.; root [] TCanvas* c = new TCanvas(); // #4 requires a definition; ```. Line #4 forces cling to send ROOT a callback that TCanvas in unknown but; the GMI resolves it to module Gpad, loads it and returns the control to cling. ### Performance; This section compares ROOT PCH technology with C++ Modules which is important but; unfair comparison. As we noted earlier, PCH is very efficient, it cannot be; extended to the experiments’ software stacks because of its design constraints.; On the contrary, the C++ Modules can be used in third-party code where the PCH; is not available. The comparisons are to give a good metric when we are ready to switch ROOT to use; C++ Modules by default. However, since it is essentially the same technology,; optimizations of C++ Modules also affect the PCH. We have a few tricks up in; the sleeves to but they come with given trade-offs. #### Preloading of C++ Modules. The main focus for the technology preview was not in performance until recently.; We have invested some resources in optimizations and we would like to show you; (probably outdated) performance results:. * Memory footprint -- mostly due to imp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:17249,load,loads,17249,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['load'],['loads']
Performance,"t sampling windows of 'resolution model' p.d.f. centered around zero, even if fit range of convolution observable does not bracket zero. Improve internal efficiency; RooAbsData - Add ability to plot efficiency distribution with correct binomial errors given a RooRealVar and a RooCategory category observable encoding distribution and accept/reject state respectively. See rf701_efficiencyfit.C for details ; RooAbsPdf - Included extended ML term by default in fit if p.d.f is extendable. You can still use Extended() to override default behavior. Do not run MINOS by default anymore if no fit options are provided.; RooProfileLL - Add option to always start minimization from global minimimum (takes more time, but improves reproducibility). Can now profile multi-core paralellized likelihoods as well.; RooRealSumPdf - Enable plotting of component p.d.f.s using same scheme as RooAddPdf, i.e. just use the Components() specified in plotOn().; RooExpensiveObjectCache - New cache manager for sharing and storing of expensive components cached by operator p.d.f.s ; RooMCStudy - Add Silence() argument to constructor to request minimal verbosity during running; RooMinuit - Improve contour() method to return RooPlots rather than drawing TGraphs straight on a canvas; RooWorkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:8778,cache,cache,8778,roofit/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html,2,['cache'],"['cache', 'cached']"
Performance,"t search for module map files named ``module.modulemap`` and similar. This option is implied by ``-fmodules``. If this is disabled with ``-fno-implicit-module-maps``, module map files will only be loaded if they are explicitly specified via ``-fmodule-map-file`` or transitively used by another module map file. ``-fmodules-cache-path=<directory>``; Specify the path to the modules cache. If not provided, Clang will select a system-appropriate default. ``-fno-autolink``; Disable automatic linking against the libraries associated with imported modules. ``-fmodules-ignore-macro=macroname``; Instruct modules to ignore the named macro when selecting an appropriate module variant. Use this for macros defined on the command line that don't affect how modules are built, to improve sharing of compiled module files. ``-fmodules-prune-interval=seconds``; Specify the minimum delay (in seconds) between attempts to prune the module cache. Module cache pruning attempts to clear out old, unused module files so that the module cache itself does not grow without bound. The default delay is large (604,800 seconds, or 7 days) because this is an expensive operation. Set this value to 0 to turn off pruning. ``-fmodules-prune-after=seconds``; Specify the minimum time (in seconds) for which a file in the module cache must be unused (according to access time) before module pruning will remove it. The default delay is large (2,678,400 seconds, or 31 days) to avoid excessive module rebuilding. ``-module-file-info <module file name>``; Debugging aid that prints information about a given module file (with a ``.pcm`` extension), including the language and preprocessor options that particular module variant was built with. ``-fmodules-decluse``; Enable checking of module ``use`` declarations. ``-fmodule-name=module-id``; Consider a source file as a part of the given module. ``-fmodule-map-file=<file>``; Load the given module map file if a header from its directory or one of its subdirectories is loa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:15551,cache,cache,15551,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,2,['cache'],['cache']
Performance,"t shooting for the; ultimate optimization experience in this setting, but we also want to; catch the easy and quick stuff where possible. As such, we will choose; to run a few per-function optimizations as the user types the function; in. If we wanted to make a ""static Kaleidoscope compiler"", we would use; exactly the code we have now, except that we would defer running the; optimizer until the entire file has been parsed. In addition to the distinction between function and module passes, passes can be; divided into transform and analysis passes. Transform passes mutate the IR, and; analysis passes compute information that other passes can use. In order to add; a transform pass, all analysis passes it depends upon must be registered in; advance. In order to get per-function optimizations going, we need to set up a; `FunctionPassManager <../../WritingAnLLVMPass.html#what-passmanager-doesr>`_ to hold; and organize the LLVM optimizations that we want to run. Once we have; that, we can add a set of optimizations to run. We'll need a new; FunctionPassManager for each module that we want to optimize, so we'll; add to a function created in the previous chapter (``InitializeModule()``):. .. code-block:: c++. void InitializeModuleAndManagers(void) {; // Open a new context and module.; TheContext = std::make_unique<LLVMContext>();; TheModule = std::make_unique<Module>(""KaleidoscopeJIT"", *TheContext);; TheModule->setDataLayout(TheJIT->getDataLayout());. // Create a new builder for the module.; Builder = std::make_unique<IRBuilder<>>(*TheContext);. // Create new pass and analysis managers.; TheFPM = std::make_unique<FunctionPassManager>();; TheLAM = std::make_unique<LoopAnalysisManager>();; TheFAM = std::make_unique<FunctionAnalysisManager>();; TheCGAM = std::make_unique<CGSCCAnalysisManager>();; TheMAM = std::make_unique<ModuleAnalysisManager>();; ThePIC = std::make_unique<PassInstrumentationCallbacks>();; TheSI = std::make_unique<StandardInstrumentations>(*TheContext,; /*Debu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:5403,optimiz,optimizations,5403,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['optimiz'],['optimizations']
Performance,"t syntax tree (AST);; .dynamicExtensions - Turns on cling's dynamic extensions. This in turn enables the dynamic lookup and the late resolving of the identifier. With that option cling tries to heal the compile-time failed lookups at runtime;. Details; Command line. The interactive prompt supports an emacs-like command line editor, just like bash terminal, which makes it easy to integrate and use. Cling uses TextInput and doesn't depend on ncurses.; . Autocompletion should be coming soon!; ; #Include Declarations. Cling allows #include-s to be not only before the declarations. The includes could be mixed with other declarations. For example:; [cling]$ #include ""math.h""; [cling]$ sin(1); (double const) 8.414710e-01; [cling]$ #include ""stdio.h""; [cling]$ printf(""%f\n"", sin(1));; 0.841471. More statements could be combined using semicolon (;). This doesn't stay when the command is #include; The following example is invalid:[cling]$ #include ""math.h""; sin(1). The same rules are applicable for the other preprocessor directives (commands starting with # - such as #define); ; Variable Declarations. Cling allows statements to be entered onto the global scope. In order to be compiled and executed by the compiler these statements need to be wrapped into functions, which body contains the statement and afterwards to run the function. The semantics of the statements that declare variables is that variables should be accessed by other statements. If the statement that declare variable is wrapped into function the variables won't be accessible from outside anymore. In this case variables are extracted onto the global scope.; ; TODO: There should be dedicated entry for that in the docs; Builtins; Cling starts with very few builtins loaded. Users could extend the available builtins via extending the RuntimeUniverse.h, which is loaded at cling's startup.; . Copyright © Cling Team; . The ROOT Framework |; LLVM |; Clang |; Web Design. Page was modified on $Date$ in $Rev$ by $Author$. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/old/index.html:4226,load,loaded,4226,interpreter/cling/www/old/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/old/index.html,2,['load'],['loaded']
Performance,"t the shared library defining the classes theand avoid splicing if the data is copied. TStreamerInfo::New inserts the address of the creating TStreamerInfo into; the object. This address is inserted in each emulated that does not inherit; from an emulated class and is positioned after all the base classes (which; are compiled classes). A derived class will set this value inside each; of its emulated base class.; TStreamerInfo::Destruct and the new method TStreamerInfo::GetActualClass; use this information to detect the TStreamerInfo actually used to create; the object and hence run the proper emulated destructor. Add a new function GenerateDictionary to TInterpreter which allows for the quick and easy creation of a dictionary; given one (or more) class name(s) and the name(s) of its header files. gInterpreter->GenerateDictionary(""vector<vector<float> >;list<vector<float> >"",""list;vector"");; gInterpreter->GenerateDictionary(""myclass"",""myclass.h;myhelper.h"");; This replaces the recommendation of creating a small 'loader.C' script to create the dictionaries. Implement a ShowMembers function for interpreted classes, by querying the interpreter for the data member; information.; In order to fix possible buffer overflow of parent string buffer in TMemberInspector,; the signature of ShowMember() was changed to no longer require (nor request) the; caller to provide a buffer (of length unknown to the callee.); Improve the uniqueness of globally visible symbols to allow for the mixing of; dictionaries with very similar layout. Cont. New functions for TClonesArray:. AbsorbObjects(TClonesArray* otherTCA):; Allows one to directly move the object pointers from otherTCA to the calling; TCA without cloning (copying). The calling TCA takes over ownership of all of; the moved objects. otherTCA is left empty upon return. MultiSort(Int_t nTCs, TClonesArray** tcs):; Sorts multiple TClonesArrays simultaneously using the calling TCA's objects; as the sorting key. New function for TSeqColle",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v528/index.html:3566,load,loader,3566,core/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v528/index.html,1,['load'],['loader']
Performance,"t the top level in a file, in which case they cover all subsequent function; bodies until they're turned off. Note that it is undefined behavior to enter; code that is *not* covered by one of these pragmas from code that *is* covered; by one of these pragmas unless the floating point environment has been restored; to its default state. See the C standard for more information about these pragmas. The command line option ``-frounding-math`` behaves as if the translation unit; began with ``#pragma STDC FENV_ROUND FE_DYNAMIC``. The command line option; ``-ffp-model=strict`` behaves as if the translation unit began with ``#pragma STDC FENV_ACCESS ON``. Code that just wants to use a specific rounding mode for specific floating point; operations can avoid most of the hazards of the dynamic floating point environment; by using ``#pragma STDC FENV_ROUND`` with a value other than ``FE_DYNAMIC``. .. _crtfastmath.o:. A note about ``crtfastmath.o``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ``-ffast-math`` and ``-funsafe-math-optimizations`` cause ``crtfastmath.o`` to be; automatically linked, which adds a static constructor that sets the FTZ/DAZ; bits in MXCSR, affecting not only the current compilation unit but all static; and shared libraries included in the program. .. _FLT_EVAL_METHOD:. A note about ``__FLT_EVAL_METHOD__``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``__FLT_EVAL_METHOD__`` is not defined as a traditional macro, and so it; will not appear when dumping preprocessor macros. Instead, the value; ``__FLT_EVAL_METHOD__`` expands to is determined at the point of expansion; either from the value set by the ``-ffp-eval-method`` command line option or; from the target. This is because the ``__FLT_EVAL_METHOD__`` macro; cannot expand to the correct evaluation method in the presence of a ``#pragma``; which alters the evaluation method. An error is issued if; ``__FLT_EVAL_METHOD__`` is expanded inside a scope modified by; ``#pragma clang fp eval_method``. .. _fp-constant-eval:. A no",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:71698,optimiz,optimizations,71698,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance,"t the; output to an area specific to the logged user.; Addition of a new class TProofProgressStatus, which is used to keep; the query progress stauts in all the TProofPlayer objects and in the; TPacketizerAdaptive. It is also send in kPROOF_GETPACKET and; kPROOF_STOPPROCESS messages. ; The class TPacketizerProgressive is removed. . Fixes. Enable; the max number of sessions ('mxsess' parameter in the xpd.schedparam; directive); users are just refused to start a session if this limit is; reached.Make sure to collect consistently input messages when running in asynchronous modeFix; a few problems with TProof::SendFile (used by UploadPackage, Load); appearing when a rapid sequence of these commands was submitted Invalidate the TProofMgr when the physical connection is; closed; avoids; crashing when trying to get the logs after a failure. ; Fix a memory leak in log retrieval (the TProofLog object; was never; deleted); Add protections for the cases the manager cannot be; initialized; Fix a race condition possibly affecting the handling of; workers death; Avoid duplicating worker logs in the master log file; unless; when explicitly needed by the request (Exec(...), Print(...)) or when; an error occuredFix; problem with the determination and transmission of the name of the; object to be processed. The problem appeared when processing files; containing >1 trees in changing order.Fix problem with TProof::Load loading the macro to one worker only per machineFix wrong return code preventing the correct propagation of the full ClearPackage to workersFix a problem causing the whole query to stop even in the case a worker was terminated gently with SIGTERM.; Fix a problem triggering full re-build of a package upon change of a; single file; the version info file was wrongly reset; this should; happen only after a re-build.Make sure that in case multiple TProofOutputFile are present, each get merged correctlyFix problem in TProofServLogHandler::Notify due to bad usage of Form(...). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:6597,race condition,race condition,6597,proof/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html,2,"['load', 'race condition']","['loading', 'race condition']"
Performance,"t their own personal PROOF cluster,; separated from the others: a problem occurring on one personal; cluster does not affect the workflow of other users. - **Easier administration and self-servicing.** A user can restart their; personal PROOF cluster in case of troubles without waiting for a; system administrator's intervention. - **Efficient multiuser scheduling.** PROOF on Demand makes PROOF run on; top of an existing resource management system, moving the problem of; scheduling many concurrent users outside of PROOF. This guide particularly refers to the setup of a static PROOF cluster; running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal/filesystem/techinformation). A brief step-by-step procedure to install CernVM-FS is hereby described. - Download and install the latest stable version from; [here](http://cernvm.cern.ch/portal/filesystem): pick one which is; appropriate to you",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:1420,queue,queue,1420,proof/doc/confman/ConfigProofPoD.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md,1,['queue'],['queue']
Performance,"t those elements actually used). .. _dss_tinyptrvector:. llvm/ADT/TinyPtrVector.h; ^^^^^^^^^^^^^^^^^^^^^^^^. ``TinyPtrVector<Type>`` is a highly specialized collection class that is; optimized to avoid allocation in the case when a vector has zero or one; elements. It has two major restrictions: 1) it can only hold values of pointer; type, and 2) it cannot hold a null pointer. Since this container is highly specialized, it is rarely used. .. _dss_smallvector:. llvm/ADT/SmallVector.h; ^^^^^^^^^^^^^^^^^^^^^^. ``SmallVector<Type, N>`` is a simple class that looks and smells just like; ``vector<Type>``: it supports efficient iteration, lays out elements in memory; order (so you can do pointer arithmetic between elements), supports efficient; push_back/pop_back operations, supports efficient random access to its elements,; etc. The main advantage of SmallVector is that it allocates space for some number of; elements (N) **in the object itself**. Because of this, if the SmallVector is; dynamically smaller than N, no malloc is performed. This can be a big win in; cases where the malloc/free call is far more expensive than the code that; fiddles around with the elements. This is good for vectors that are ""usually small"" (e.g. the number of; predecessors/successors of a block is usually less than 8). On the other hand,; this makes the size of the SmallVector itself large, so you don't want to; allocate lots of them (doing so will waste a lot of space). As such,; SmallVectors are most useful when on the stack. In the absence of a well-motivated choice for the number of; inlined elements ``N``, it is recommended to use ``SmallVector<T>`` (that is,; omitting the ``N``). This will choose a default number of; inlined elements reasonable for allocation on the stack (for example, trying; to keep ``sizeof(SmallVector<T>)`` around 64 bytes). SmallVector also provides a nice portable and efficient replacement for; ``alloca``. SmallVector has grown a few other minor advantages over std",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:59943,perform,performed,59943,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['perform'],['performed']
Performance,"t uses a local PassManager; instance and creates a new ObjectBufferStream instance, both of which it; passes to TargetMachine::addPassesToEmitMC before calling PassManager::run; on the Module with which it was created. .. image:: MCJIT-load.png. The PassManager::run call causes the MC code generation mechanisms to emit; a complete relocatable binary object image (either in either ELF or MachO; format, depending on the target) into the ObjectBufferStream object, which; is flushed to complete the process. If an ObjectCache is being used, the; image will be passed to the ObjectCache here. At this point, the ObjectBufferStream contains the raw object image.; Before the code can be executed, the code and data sections from this; image must be loaded into suitable memory, relocations must be applied and; memory permission and code cache invalidation (if required) must be completed. Object Loading; ==============. Once an object image has been obtained, either through code generation or; having been retrieved from an ObjectCache, it is passed to RuntimeDyld to; be loaded. The RuntimeDyld wrapper class examines the object to determine; its file format and creates an instance of either RuntimeDyldELF or; RuntimeDyldMachO (both of which derive from the RuntimeDyldImpl base; class) and calls the RuntimeDyldImpl::loadObject method to perform that; actual loading. .. image:: MCJIT-dyld-load.png. RuntimeDyldImpl::loadObject begins by creating an ObjectImage instance; from the ObjectBuffer it received. ObjectImage, which wraps the; ObjectFile class, is a helper class which parses the binary object image; and provides access to the information contained in the format-specific; headers, including section, symbol and relocation information. RuntimeDyldImpl::loadObject then iterates through the symbols in the; image. Information about common symbols is collected for later use. For; each function or data symbol, the associated section is loaded into memory; and the symbol is stored in a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst:3672,load,loaded,3672,interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,1,['load'],['loaded']
Performance,"t using a just-in-time compiler or an; interpreter. :program:`lli` is *not* an emulator. It will not execute IR of different architectures; and it can only interpret (or JIT-compile) for the host architecture. The JIT compiler takes the same arguments as other tools, like :program:`llc`,; but they don't necessarily work for the interpreter. If `filename` is not specified, then :program:`lli` reads the LLVM bitcode for the; program from standard input. The optional *args* specified on the command line are passed to the program as; arguments. GENERAL OPTIONS; ---------------. .. option:: -fake-argv0=executable. Override the ``argv[0]`` value passed into the executing program. .. option:: -force-interpreter={false,true}. If set to true, use the interpreter even if a just-in-time compiler is available; for this architecture. Defaults to false. .. option:: -help. Print a summary of command line options. .. option:: -load=pluginfilename. Causes :program:`lli` to load the plugin (shared object) named *pluginfilename* and use; it for optimization. .. option:: -stats. Print statistics from the code-generation passes. This is only meaningful for; the just-in-time compiler, at present. .. option:: -time-passes. Record the amount of time needed for each code-generation pass and print it to; standard error. .. option:: -version. Print out the version of :program:`lli` and exit without doing anything else. TARGET OPTIONS; --------------. .. option:: -mtriple=target triple. Override the target triple specified in the input bitcode file with the; specified string. This may result in a crash if you pick an; architecture which is not compatible with the current system. .. option:: -march=arch. Specify the architecture for which to generate assembly, overriding the target; encoded in the bitcode file. See the output of **llc -help** for a list of; valid architectures. By default this is inferred from the target triple or; autodetected to the current architecture. .. option:: -mcpu=cpu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst:1318,load,load,1318,interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,2,"['load', 'optimiz']","['load', 'optimization']"
Performance,"t which denormal numbers the code is permitted to require. Valid values are:. * ``ieee`` - IEEE 754 denormal numbers; * ``preserve-sign`` - the sign of a flushed-to-zero number is preserved in the sign of 0; * ``positive-zero`` - denormals are flushed to positive zero. The default value depends on the target. For most targets, defaults to; ``ieee``. .. option:: -f[no-]strict-float-cast-overflow. When a floating-point value is not representable in a destination integer; type, the code has undefined behavior according to the language standard.; By default, Clang will not guarantee any particular result in that case.; With the 'no-strict' option, Clang will saturate towards the smallest and; largest representable integer values instead. NaNs will be converted to zero.; Defaults to ``-fstrict-float-cast-overflow``. .. option:: -f[no-]math-errno. Require math functions to indicate errors by setting errno.; The default varies by ToolChain. ``-fno-math-errno`` allows optimizations; that might cause standard C math functions to not set ``errno``.; For example, on some systems, the math function ``sqrt`` is specified; as setting ``errno`` to ``EDOM`` when the input is negative. On these; systems, the compiler cannot normally optimize a call to ``sqrt`` to use; inline code (e.g. the x86 ``sqrtsd`` instruction) without additional; checking to ensure that ``errno`` is set appropriately.; ``-fno-math-errno`` permits these transformations. On some targets, math library functions never set ``errno``, and so; ``-fno-math-errno`` is the default. This includes most BSD-derived; systems, including Darwin. .. option:: -f[no-]trapping-math. Control floating point exception behavior. ``-fno-trapping-math`` allows optimizations that assume that floating point operations cannot generate traps such as divide-by-zero, overflow and underflow. - The option ``-ftrapping-math`` behaves identically to ``-ffp-exception-behavior=strict``.; - The option ``-fno-trapping-math`` behaves identically to `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:55612,optimiz,optimizations,55612,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance,"t which will be used to; discover and run tests in the test suite. Generally this will be a builtin test; format available from the *lit.formats* module. **test_source_root** The filesystem path to the test suite root. For out-of-dir; builds this is the directory that will be scanned for tests. **test_exec_root** For out-of-dir builds, the path to the test suite root inside; the object directory. This is where tests will be run and temporary output files; placed. **environment** A dictionary representing the environment to use when executing; tests in the suite. **standalone_tests** When true, mark a directory with tests expected to be run; standalone. Test discovery is disabled for that directory. *lit.suffixes* and; *lit.excludes* must be empty when this variable is true. **suffixes** For **lit** test formats which scan directories for tests, this; variable is a list of suffixes to identify test files. Used by: *ShTest*. **substitutions** For **lit** test formats which substitute variables into a test; script, the list of substitutions to perform. Used by: *ShTest*. **unsupported** Mark an unsupported directory, all tests within it will be; reported as unsupported. Used by: *ShTest*. **parent** The parent configuration, this is the config object for the directory; containing the test suite, or None. **root** The root configuration. This is the top-most :program:`lit` configuration in; the project. **pipefail** Normally a test using a shell pipe fails if any of the commands; on the pipe fail. If this is not desired, setting this variable to false; makes the test fail only if the last command in the pipe fails. **available_features** A set of features that can be used in `XFAIL`,; `REQUIRES`, and `UNSUPPORTED` directives. TEST DISCOVERY; ~~~~~~~~~~~~~~. Once test suites are located, :program:`lit` recursively traverses the source; directory (following *test_source_root*) looking for tests. When :program:`lit`; enters a sub-directory, it first checks to see if a neste",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:16692,perform,perform,16692,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['perform'],['perform']
Performance,"t within the range of; the fixed point type. Examples; """""""""""""""""". .. code-block:: llvm. %res = call i4 @llvm.umul.fix.i4(i4 3, i4 2, i32 0) ; %res = 6 (2 x 3 = 6); %res = call i4 @llvm.umul.fix.i4(i4 3, i4 2, i32 1) ; %res = 3 (1.5 x 1 = 1.5). ; The result in the following could be rounded down to 3.5 or up to 4; %res = call i4 @llvm.umul.fix.i4(i4 15, i4 1, i32 1) ; %res = 7 (or 8) (7.5 x 0.5 = 3.75). '``llvm.smul.fix.sat.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.smul.fix.sat``; on any integer bit width or vectors of integers. ::. declare i16 @llvm.smul.fix.sat.i16(i16 %a, i16 %b, i32 %scale); declare i32 @llvm.smul.fix.sat.i32(i32 %a, i32 %b, i32 %scale); declare i64 @llvm.smul.fix.sat.i64(i64 %a, i64 %b, i32 %scale); declare <4 x i32> @llvm.smul.fix.sat.v4i32(<4 x i32> %a, <4 x i32> %b, i32 %scale). Overview; """""""""""""""""". The '``llvm.smul.fix.sat``' family of intrinsic functions perform signed; fixed point saturating multiplication on 2 arguments of the same scale. Arguments; """""""""""""""""""". The arguments (%a and %b) and the result may be of integer types of any bit; width, but they must have the same bit width. ``%a`` and ``%b`` are the two; values that will undergo signed fixed point multiplication. The argument; ``%scale`` represents the scale of both operands, and must be a constant; integer. Semantics:; """""""""""""""""""". This operation performs fixed point multiplication on the 2 arguments of a; specified scale. The result will also be returned in the same scale specified; in the third argument. If the result value cannot be precisely represented in the given scale, the; value is rounded up or down to the closest representable value. The rounding; direction is unspecified. The maximum value this operation can clamp to is the largest signed value; representable by the bit width of the first 2 arguments. The minimum value is the; smallest signed value representable by this bit width. Example",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:625524,perform,perform,625524,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"t work for your use case without; requiring a custom build. Collector Requirements; ----------------------. You should be able to leverage any existing collector library that includes the following elements:. #. A memory allocator which exposes an allocation function your compiled; code can call. #. A binary format for the stack map. A stack map describes the location; of references at a safepoint and is used by precise collectors to identify; references within a stack frame on the machine stack. Note that collectors; which conservatively scan the stack don't require such a structure. #. A stack crawler to discover functions on the call stack, and enumerate the; references listed in the stack map for each call site. #. A mechanism for identifying references in global locations (e.g. global; variables). #. If you collector requires them, an LLVM IR implementation of your collectors; load and store barriers. Note that since many collectors don't require; barriers at all, LLVM defaults to lowering such barriers to normal loads; and stores unless you arrange otherwise. Implementing a collector plugin; -------------------------------. User code specifies which GC code generation to use with the ``gc`` function; attribute or, equivalently, with the ``setGC`` method of ``Function``. To implement a GC plugin, it is necessary to subclass ``llvm::GCStrategy``,; which can be accomplished in a few lines of boilerplate code. LLVM's; infrastructure provides access to several important algorithms. For an; uncontroversial collector, all that remains may be to compile LLVM's computed; stack map to assembly code (using the binary representation expected by the; runtime library). This can be accomplished in about 100 lines of code. This is not the appropriate place to implement a garbage collected heap or a; garbage collector itself. That code should exist in the language's runtime; library. The compiler plugin is responsible for generating code which conforms; to the binary interface",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:23310,load,loads,23310,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['load'],['loads']
Performance,"t {; int data;; struct LinkedList *next;; };. struct LinkedList * _Nullable getNext(struct LinkedList *l);. void updateNextData(struct LinkedList *list, int newData) {; struct LinkedList *next = getNext(list);; // Warning: Nullable pointer is dereferenced; next->data = 7;; }. .. _nullability-NullablePassedToNonnull:. nullability.NullablePassedToNonnull (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warns when a nullable pointer is passed to a pointer which has a _Nonnull type. .. code-block:: objc. typedef struct Dummy { int val; } Dummy;; Dummy *_Nullable returnsNullable();; void takesNonnull(Dummy *_Nonnull);. void test() {; Dummy *p = returnsNullable();; takesNonnull(p); // warn; }. .. _nullability-NullableReturnedFromNonnull:. nullability.NullableReturnedFromNonnull (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warns when a nullable pointer is returned from a function that has _Nonnull return type. .. _optin-checkers:. optin; ^^^^^. Checkers for portability, performance or coding style specific rules. .. _optin-core-EnumCastOutOfRange:. optin.core.EnumCastOutOfRange (C, C++); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for integer to enumeration casts that would produce a value with no; corresponding enumerator. This is not necessarily undefined behavior, but can; lead to nasty surprises, so projects may decide to use a coding standard that; disallows these ""unusual"" conversions. Note that no warnings are produced when the enum type (e.g. `std::byte`) has no; enumerators at all. .. code-block:: cpp. enum WidgetKind { A=1, B, C, X=99 };. void foo() {; WidgetKind c = static_cast<WidgetKind>(3); // OK; WidgetKind x = static_cast<WidgetKind>(99); // OK; WidgetKind d = static_cast<WidgetKind>(4); // warn; }. **Limitations**. This checker does not accept the coding pattern where an enum type is used to; store combinations of flag values:. .. code-block:: cpp. enum AnimalFlags; {; HasClaws = 1,; CanFly = 2,; EatsFish = 4,; Endangered = 8; };. AnimalFla",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:12852,perform,performance,12852,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['perform'],['performance']
Performance,"t's all together, compile the file with a simple ""``gmake``"" command; from the top level of your build directory and you should get a new file; ""``lib/LLVMHello.so``"". Note that everything in this file is; contained in an anonymous namespace --- this reflects the fact that passes; are self contained units that do not need external interfaces (although they; can have them) to be useful. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny shared object file, we can use the; :program:`opt` command to run an LLVM program through your pass. Because you; registered your pass with ``RegisterPass``, you will be able to use the; :program:`opt` tool to access it, once loaded. To test it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to :ref:`register your pass; <writing-an-llvm-pass-registration>`). Because the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -load lib/LLVMHello.so -help; OVERVIEW: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] [options] <input bitcode file>. OPTIONS:; Optimizations available:; ...; -guard-widening - Widen guards; -gvn - Global Value Numbering; -gvn-hoist - Early GVN Hoisting of Expressions; -hello - Hello World Pass; -indvars - Induction ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:8249,load,load,8249,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['load'],['load']
Performance,"t(0) &; - system - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:282934,load,load,282934,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"t(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; sc1=1; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acq_rel - agent - generic 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; bein",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:322003,load,loads,322003,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"t(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. flat_atomic sc1=1; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; addre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:324133,load,load,324133,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"t, it will emit globals to the section specified.; Additionally, the global can placed in a comdat if the target has the necessary; support. External declarations may have an explicit section specified. Section; information is retained in LLVM IR for targets that make use of this; information. Attaching section information to an external declaration is an; assertion that its definition is located in the specified section. If the; definition is located in a different section, the behavior is undefined. LLVM allows an explicit code model to be specified for globals. If the; target supports it, it will emit globals in the code model specified,; overriding the code model used to compile the translation unit.; The allowed values are ""tiny"", ""small"", ""kernel"", ""medium"", ""large"".; This may be extended in the future to specify global data layout that; doesn't cleanly fit into a specific code model. By default, global initializers are optimized by assuming that global; variables defined within the module are not modified from their; initial values before the start of the global initializer. This is; true even for variables potentially accessible from outside the; module, including those with external linkage or appearing in; ``@llvm.used`` or dllexported variables. This assumption may be suppressed; by marking the variable with ``externally_initialized``. An explicit alignment may be specified for a global, which must be a; power of 2. If not present, or if the alignment is set to zero, the; alignment of the global is set by the target to whatever it feels; convenient. If an explicit alignment is specified, the global is forced; to have exactly that alignment. Targets and optimizers are not allowed; to over-align the global if the global has an assigned section. In this; case, the extra alignment could be observable: for example, code could; assume that the globals are densely packed in their section and try to; iterate over them as an array, alignment padding would break thi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:33955,optimiz,optimized,33955,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimized']
Performance,"t. The Darwin and Linux implementation; relies on padding and the ability to map a file over the existing memory; mapping which is generally only available on POSIX systems and isn't suitable; for other platforms. On Fuchsia, we rely on the ability to relocate counters at runtime using a; level of indirection. On every counter access, we add a bias to the counter; address. This bias is stored in ``__llvm_profile_counter_bias`` symbol that's; provided by the profile runtime and is initially set to zero, meaning no; relocation. The runtime can map the profile into memory at arbitrary locations,; and set bias to the offset between the original and the new counter location,; at which point every subsequent counter access will be to the new location,; which allows updating profile directly akin to the continuous mode. The advantage of this approach is that doesn't require any special OS support.; The disadvantage is the extra overhead due to additional instructions required; for each counter access (overhead both in terms of binary size and performance); plus duplication of counters (i.e. one copy in the binary itself and another; copy that's mapped into memory). This implementation can be also enabled for; other platforms by passing the ``-runtime-counter-relocation`` option to the; backend during compilation. For a program such as the `Lit <https://llvm.org/docs/CommandGuide/lit.html>`_; testing tool which invokes other programs, it may be necessary to set; ``LLVM_PROFILE_FILE`` for each invocation. The pattern strings ""%p"" or ""%Nm""; may help to avoid corruption due to concurrency. Note that ""%p"" is also a Lit; token and needs to be escaped as ""%%p"". .. code-block:: console. % clang++ -fprofile-instr-generate -fcoverage-mapping -mllvm -runtime-counter-relocation foo.cc -o foo. Creating coverage reports; =========================. Raw profiles have to be **indexed** before they can be used to generate; coverage reports. This is done using the ""merge"" tool in ``llvm-profd",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:5094,perform,performance,5094,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['perform'],['performance']
Performance,"t. Therefore, the; vector and scalar memory operations performed by different wavefronts, whether; executing in the same or different work-groups (which may be executing on; different CUs accessing different L0s), can be reordered relative to each; other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is required to ensure; synchronization between vector memory operations of different wavefronts. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L1 caches use an L2 cache shared by all SAs on the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each L1 quadrant of a single SA accesses a different L2 channel. Each L1; quadrant has a separate request queue per L2 channel. Therefore, the vector; and scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different SAs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is; required to ensure synchronization between vector memory operations of; different SAs. It ensures a previous vector memory operation has completed; before executing a subsequent vector memory and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence.; * On GFX10.3 and GFX11 a memory attached last level (MALL) cache exists for GPU memory.; The MALL cache is fully coherent with GPU memory and has no impact on system; coherence. All agents (GPU and CPU) access GPU memory through the MALL cache. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address sp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:339079,perform,performed,339079,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performed']
Performance,"t.*. 1. The ``DW_AT_data_location`` attribute may be used with any type that; provides one or more levels of hidden indirection and/or run-time parameters; in its representation. Its value is a DWARF operation expression E which; computes the location description of the data for an object. When this; attribute is omitted, the location description of the data is the same as; the location description of the object. The result of the attribute is obtained by evaluating E with a context that; has a result kind of a location description, an object that is the location; description of the data descriptor, the compilation unit that contains E, an; empty initial stack, and other context elements corresponding to the source; language thread of execution upon which the user is focused, if any. The; result of the evaluation is the location description of the base of the; member entry. *E will typically involve an operation expression that begins with a*; ``DW_OP_push_object_address`` *operation which loads the location; description of the object which can then serve as a descriptor in subsequent; calculation.*. .. note::. Since ``DW_AT_data_member_location``, ``DW_AT_use_location``, and; ``DW_AT_vtable_elem_location`` allow both operation expressions and; location list expressions, why does ``DW_AT_data_location`` not allow; both? In all cases they apply to data objects so less likely that; optimization would cause different operation expressions for different; program location ranges. But if supporting for some then should be for; all. It seems odd this attribute is not the same as; ``DW_AT_data_member_location`` in having an initial stack with the; location description of the object since the expression has to need it. A.6 Other Debugging Information; -------------------------------. .. note::. This section provides changes to existing debugger information entry; attributes. These would be incorporated into the corresponding DWARF Version 5; chapter 6 sections. A.6.1 Accelera",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:184732,load,loads,184732,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['load'],['loads']
Performance,"t...\n"");. int main(int argc, const char **argv) {; auto ExpectedParser = CommonOptionsParser::create(argc, argv, MyToolCategory);; if (!ExpectedParser) {; // Fail gracefully for unsupported options.; llvm::errs() << ExpectedParser.takeError();; return 1;; }; CommonOptionsParser& OptionsParser = ExpectedParser.get();; ClangTool Tool(OptionsParser.getCompilations(),; OptionsParser.getSourcePathList());; return Tool.run(newFrontendActionFactory<clang::SyntaxOnlyAction>().get());; }. And that's it! You can compile our new tool by running ninja from the; ``build`` directory. .. code-block:: console. cd ~/clang-llvm/build; ninja. You should now be able to run the syntax checker, which is located in; ``~/clang-llvm/build/bin``, on any source file. Try it!. .. code-block:: console. echo ""int main() { return 0; }"" > test.cpp; bin/loop-convert test.cpp --. Note the two dashes after we specify the source file. The additional; options for the compiler are passed after the dashes rather than loading; them from a compilation database - there just aren't any options needed; right now. Intermezzo: Learn AST matcher basics; ====================================. Clang recently introduced the :doc:`ASTMatcher; library <LibASTMatchers>` to provide a simple, powerful, and; concise way to describe specific patterns in the AST. Implemented as a; DSL powered by macros and templates (see; `ASTMatchers.h <../doxygen/ASTMatchers_8h_source.html>`_ if you're; curious), matchers offer the feel of algebraic data types common to; functional programming languages. For example, suppose you wanted to examine only binary operators. There; is a matcher to do exactly that, conveniently named ``binaryOperator``.; I'll give you one guess what this matcher does:. .. code-block:: c++. binaryOperator(hasOperatorName(""+""), hasLHS(integerLiteral(equals(0)))). Shockingly, it will match against addition expressions whose left hand; side is exactly the literal 0. It will not match against other forms of; 0, such",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst:5536,load,loading,5536,interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,1,['load'],['loading']
Performance,t/NonTrivialTypesLibcMemoryCallsCheck.cpp; clang-tools-extra/clang-tidy/cert/NonTrivialTypesLibcMemoryCallsCheck.h; clang-tools-extra/clang-tidy/cert/PostfixOperatorCheck.cpp; clang-tools-extra/clang-tidy/cert/PostfixOperatorCheck.h; clang-tools-extra/clang-tidy/cert/ProperlySeededRandomGeneratorCheck.cpp; clang-tools-extra/clang-tidy/cert/ProperlySeededRandomGeneratorCheck.h; clang-tools-extra/clang-tidy/cert/SetLongJmpCheck.cpp; clang-tools-extra/clang-tidy/cert/SetLongJmpCheck.h; clang-tools-extra/clang-tidy/cert/StaticObjectExceptionCheck.cpp; clang-tools-extra/clang-tidy/cert/StaticObjectExceptionCheck.h; clang-tools-extra/clang-tidy/cert/StrToNumCheck.cpp; clang-tools-extra/clang-tidy/cert/StrToNumCheck.h; clang-tools-extra/clang-tidy/cert/ThrownExceptionTypeCheck.cpp; clang-tools-extra/clang-tidy/cert/ThrownExceptionTypeCheck.h; clang-tools-extra/clang-tidy/cert/VariadicFunctionDefCheck.cpp; clang-tools-extra/clang-tidy/cert/VariadicFunctionDefCheck.h; clang-tools-extra/clang-tidy/concurrency/MtUnsafeCheck.cpp; clang-tools-extra/clang-tidy/concurrency/MtUnsafeCheck.h; clang-tools-extra/clang-tidy/concurrency/ThreadCanceltypeAsynchronousCheck.cpp; clang-tools-extra/clang-tidy/concurrency/ThreadCanceltypeAsynchronousCheck.h; clang-tools-extra/clang-tidy/cppcoreguidelines/AvoidGotoCheck.cpp; clang-tools-extra/clang-tidy/cppcoreguidelines/AvoidGotoCheck.h; clang-tools-extra/clang-tidy/cppcoreguidelines/AvoidNonConstGlobalVariablesCheck.cpp; clang-tools-extra/clang-tidy/cppcoreguidelines/AvoidNonConstGlobalVariablesCheck.h; clang-tools-extra/clang-tidy/cppcoreguidelines/CppCoreGuidelinesTidyModule.cpp; clang-tools-extra/clang-tidy/cppcoreguidelines/InitVariablesCheck.cpp; clang-tools-extra/clang-tidy/cppcoreguidelines/InitVariablesCheck.h; clang-tools-extra/clang-tidy/cppcoreguidelines/InterfacesGlobalInitCheck.cpp; clang-tools-extra/clang-tidy/cppcoreguidelines/InterfacesGlobalInitCheck.h; clang-tools-extra/clang-tidy/cppcoreguidelines/MacroUsageCheck.cpp; clang-,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:51205,concurren,concurrency,51205,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['concurren'],['concurrency']
Performance,"t2"");; root[] list2->SetTree(""tree2"", ""file2"");; root[] list2->Enter(0);; root[] list2->Enter(3);; root[] list1->Add(list2);; root[] list1->Print(""all""); tree1 file1; 0; 2; tree2 file2; 0; 3; ```. The result is a **`TEntryList`** for a **`TChain`** of `tree1` and; `tree2`. If the second list was for the same **`TTree`** in the same; file as the first list, the result would be as follows:. ``` {.cpp}; root[] TEntryList *list2_2 = new TEntryList(""list2_2"", ""list2_2"");; root[] list2_2->SetTree(""tree2"", ""file2"");; root[] list2_2->Enter(1);; root[] list2_2->Enter(2);; root[] list2->Add(list2_2);; root[] list2->Print(""all""); tree2 file2; 0; 1; 2; 3; ```. #### TEntryListFromFile. This is a special kind of **`TEntryList`**, used only when processing; **`TChain`** objects (see the method `TChain::SetEntryListFile()`). It; is used in the case, when the entry lists, corresponding to the trees of; this chain, are stored in separate files. It allows to load the entry; lists in memory one by one, keeping only the list for the currently; processed tree loaded. For more details on entry lists, see **`TEntryList`**,; **`TEntryListBlock`** and **`TEntryListFromFile`** class descriptions,; functions **`TChain`**`::SetEntryList()`, `TChain::SetEntryListFile()`,; and the macro `$ROOTSYS/test/stressEntryList.C`. ### Filling a Histogram. The `TTree::Draw` method can also be used to fill a specific histogram.; The syntax is:. ``` {.cpp}; root[] TFile *f = new TFile(""Event.root""); root[] T->Draw(""fNtrack >> myHisto""); root[] myHisto->Print(); TH1.Print Name= myHisto, Entries= 100, Total sum= 100; ```. As we can see, this created a **`TH1`**, called `myHisto`. If you want; to append more entries to the histogram, you can use this syntax:. ``` {.cpp}; root[] T->Draw(""fNtrack >>+ myHisto""); ```. If you do not create a histogram ahead of time, ROOT will create one at; the time of the Draw command (as is the case above). If you would like; to draw the variable into a specific histogram where you,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:114677,load,load,114677,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,2,['load'],"['load', 'loaded']"
Performance,"t; address, and a new value to place at that address if the compared values; are equal. The type of '<cmp>' must be an integer or pointer type whose; bit width is a power of two greater than or equal to eight and less; than or equal to a target-specific size limit. '<cmp>' and '<new>' must; have the same type, and the type of '<pointer>' must be a pointer to; that type. If the ``cmpxchg`` is marked as ``volatile``, then the; optimizer is not allowed to modify the number or order of execution of; this ``cmpxchg`` with other :ref:`volatile operations <volatile>`. The success and failure :ref:`ordering <ordering>` arguments specify how this; ``cmpxchg`` synchronizes with other atomic operations. Both ordering parameters; must be at least ``monotonic``, the failure ordering cannot be either; ``release`` or ``acq_rel``. A ``cmpxchg`` instruction can also take an optional; "":ref:`syncscope <syncscope>`"" argument. Note: if the alignment is not greater or equal to the size of the `<value>`; type, the atomic operation is likely to require a lock and have poor; performance. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present. If unspecified, the alignment is assumed to be equal to the; size of the '<value>' type. Note that this default alignment assumption is; different from the alignment used for the load/store instructions when align; isn't specified. The pointer passed into cmpxchg must have alignment greater than or; equal to the size in memory of the operand. Semantics:; """""""""""""""""""". The contents of memory at the location specified by the '``<pointer>``' operand; is read and compared to '``<cmp>``'; if the values are equal, '``<new>``' is; written to the location. The original value at the location is returned,; together with a flag indicating success (true) or failure (false). If the cmpxchg operation is marked as ``weak`` then a spurious failure is; permitted: the operation may not write ``<new>`` even if the comparison; match",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:427229,perform,performance,427229,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performance']
Performance,"t; value as an i16, then convert it to float with; :ref:`llvm.convert.from.fp16 <int_convert_from_fp16>`. Computation can; then be performed on the float value (including extending to double; etc). To store the value back to memory, it is first converted to float; if needed, then converted to i16 with; :ref:`llvm.convert.to.fp16 <int_convert_to_fp16>`, then storing as an; i16 value. .. _int_convert_to_fp16:. '``llvm.convert.to.fp16``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i16 @llvm.convert.to.fp16.f32(float %a); declare i16 @llvm.convert.to.fp16.f64(double %a). Overview:; """""""""""""""""". The '``llvm.convert.to.fp16``' intrinsic function performs a conversion from a; conventional floating-point type to half precision floating-point format. Arguments:; """""""""""""""""""". The intrinsic function contains single argument - the value to be; converted. Semantics:; """""""""""""""""""". The '``llvm.convert.to.fp16``' intrinsic function performs a conversion from a; conventional floating-point format to half precision floating-point format. The; return value is an ``i16`` which contains the converted number. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call i16 @llvm.convert.to.fp16.f32(float %a); store i16 %res, i16* @x, align 2. .. _int_convert_from_fp16:. '``llvm.convert.from.fp16``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.convert.from.fp16.f32(i16 %a); declare double @llvm.convert.from.fp16.f64(i16 %a). Overview:; """""""""""""""""". The '``llvm.convert.from.fp16``' intrinsic function performs a; conversion from half precision floating-point format to single precision; floating-point format. Arguments:; """""""""""""""""""". The intrinsic function contains single argument - the value to be; converted. Semantics:; """""""""""""""""""". The '``llvm.convert.from.fp16``' intrinsic function performs a; conversion from half single precision floating-point format to single; precision floating-point format. The input half-float va",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:682024,perform,performs,682024,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"t> = icmp eq i32 4, 5 ; yields: result=false; <result> = icmp ne ptr %X, %X ; yields: result=false; <result> = icmp ult i16 4, 5 ; yields: result=true; <result> = icmp sgt i16 4, 5 ; yields: result=false; <result> = icmp ule i16 -4, 5 ; yields: result=false; <result> = icmp sge i16 4, 5 ; yields: result=false. .. _i_fcmp:. '``fcmp``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = fcmp [fast-math flags]* <cond> <ty> <op1>, <op2> ; yields i1 or <N x i1>:result. Overview:; """""""""""""""""". The '``fcmp``' instruction returns a boolean value or vector of boolean; values based on comparison of its operands. If the operands are floating-point scalars, then the result type is a; boolean (:ref:`i1 <t_integer>`). If the operands are floating-point vectors, then the result type is a; vector of boolean with the same number of elements as the operands being; compared. Arguments:; """""""""""""""""""". The '``fcmp``' instruction takes three operands. The first operand is; the condition code indicating the kind of comparison to perform. It is; not a value, just a keyword. The possible condition codes are:. #. ``false``: no comparison, always returns false; #. ``oeq``: ordered and equal; #. ``ogt``: ordered and greater than; #. ``oge``: ordered and greater than or equal; #. ``olt``: ordered and less than; #. ``ole``: ordered and less than or equal; #. ``one``: ordered and not equal; #. ``ord``: ordered (no nans); #. ``ueq``: unordered or equal; #. ``ugt``: unordered or greater than; #. ``uge``: unordered or greater than or equal; #. ``ult``: unordered or less than; #. ``ule``: unordered or less than or equal; #. ``une``: unordered or not equal; #. ``uno``: unordered (either nans); #. ``true``: no comparison, always returns true. *Ordered* means that neither operand is a QNAN while *unordered* means; that either operand may be a QNAN. Each of ``val1`` and ``val2`` arguments must be either a :ref:`floating-point; <t_floating>` type or a :ref:`vector <t_vector>` of floating-poin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:463399,perform,perform,463399,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,tEquals.cpp; clang-tools-extra/clang-tidy/objc/AssertEquals.h; clang-tools-extra/clang-tidy/objc/DeallocInCategoryCheck.cpp; clang-tools-extra/clang-tidy/objc/DeallocInCategoryCheck.h; clang-tools-extra/clang-tidy/objc/ForbiddenSubclassingCheck.h; clang-tools-extra/clang-tidy/objc/MissingHashCheck.cpp; clang-tools-extra/clang-tidy/objc/MissingHashCheck.h; clang-tools-extra/clang-tidy/objc/NSInvocationArgumentLifetimeCheck.cpp; clang-tools-extra/clang-tidy/objc/NSInvocationArgumentLifetimeCheck.h; clang-tools-extra/clang-tidy/objc/PropertyDeclarationCheck.h; clang-tools-extra/clang-tidy/objc/SuperSelfCheck.cpp; clang-tools-extra/clang-tidy/objc/SuperSelfCheck.h; clang-tools-extra/clang-tidy/openmp/ExceptionEscapeCheck.cpp; clang-tools-extra/clang-tidy/openmp/ExceptionEscapeCheck.h; clang-tools-extra/clang-tidy/openmp/OpenMPTidyModule.cpp; clang-tools-extra/clang-tidy/openmp/UseDefaultNoneCheck.cpp; clang-tools-extra/clang-tidy/openmp/UseDefaultNoneCheck.h; clang-tools-extra/clang-tidy/performance/FasterStringFindCheck.cpp; clang-tools-extra/clang-tidy/performance/ForRangeCopyCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.h; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.h; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.cpp; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.h; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.cpp; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.h; clang-tools-extra/clang-tidy/performance/NoIntTo,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:64705,perform,performance,64705,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['perform'],['performance']
Performance,"tGenerateBinned).; An estimated of the error in the obtained p values is now computed in the HybridResult class thanks to Matthias Wolf. The errors can be obtained with HybridResult::CLbError(), HybridResult::CLsplusbError() or HybridResult::CLsError().; A new tutorial has been added for showing the usage of the hybrid calculator: rs505_HybridCalculator_significance.C. new class HypoTestInverter. New class for performing an hypothesis test inversion by scanning; the hypothesis test results of the HybridCalculator for; various values of the parameter of interest. An upper (or lower) limit can be derived by looking at the; confidence level curve of the result as function of the parameter of; interest, where it intersects the desired confidence level. The class implements the IntervalCalculator interface and returns an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find optimally the curve and it will stop when the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method retu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:15176,perform,performing,15176,roofit/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html,1,['perform'],['performing']
Performance,"tLevel::None and passes which are required for register; allocation. The -opt-bisect-limit option can be used with any tool, including front ends; such as clang, that uses the core LLVM library for optimization and code; generation. The exact syntax for invoking the option is discussed below. This feature is not intended to replace other debugging tools such as bugpoint.; Rather it provides an alternate course of action when reproducing the problem; requires a complex build infrastructure that would make using bugpoint; impractical or when reproducing the failure requires a sequence of; transformations that is difficult to replicate with tools like opt and llc. Getting Started; ===============. The -opt-bisect-limit command line option can be passed directly to tools such; as opt, llc and lli. The syntax is as follows:. ::. <tool name> [other options] -opt-bisect-limit=<limit>. If a value of -1 is used the tool will perform all optimizations but a message; will be printed to stderr for each optimization that could be skipped; indicating the index value that is associated with that optimization. To skip; optimizations, pass the value of the last optimization to be performed as the; opt-bisect-limit. All optimizations with a higher index value will be skipped. In order to use the -opt-bisect-limit option with a driver that provides a; wrapper around the LLVM core library, an additional prefix option may be; required, as defined by the driver. For example, to use this option with; clang, the ""-mllvm"" prefix must be used. A typical clang invocation would look; like this:. ::. clang -O2 -mllvm -opt-bisect-limit=256 my_file.c. The -opt-bisect-limit option may also be applied to link-time optimizations by; using a prefix to indicate that this is a plug-in option for the linker. The; following syntax will set a bisect limit for LTO transformations:. ::. # When using lld, or ld64 (macOS); clang -flto -Wl,-mllvm,-opt-bisect-limit=256 my_file.o my_other_file.o; # When using Gol",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst:1887,perform,perform,1887,interpreter/llvm-project/llvm/docs/OptBisect.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst,4,"['optimiz', 'perform']","['optimization', 'optimizations', 'perform']"
Performance,"t`** is used and the default ROOT interrupt handler is not; desired, you should use `GetSignalHandler()` of **`TApplication`** to; get the interrupt handler and to remove it by `RemoveSignalHandler()`of; **`TSystem`** . ## Glossary. The following glossary is adapted from the description of the Rogue Wave; `Threads.h`++ package. A **`process`** is a program that is loaded into memory and prepared for; execution. Each process has a private address space. Processes begin; with a single thread. A **`thread`** is a sequence of instructions being executed in a; program. A thread has a program counter and a private stack to keep; track of local variables and return addresses. A multithreaded process; is associated with one or more threads. Threads execute independently.; All threads in a given process share the private address space of that; process. **`Concurrency`** exists when at least two threads are in progress at; the same time. A system with only a single processor can support; concurrency by switching execution contexts among multiple threads. **`Parallelism`** arises when at least two threads are executing; simultaneously. This requires a system with multiple processors.; Parallelism implies concurrency, but not vice-versa. A function is **`reentrant`** if it will behave correctly even if a; thread of execution enters the function while one or more threads are; already executing within the function. These could be the same thread,; in the case of recursion, or different threads, in the case of; concurrency. **`Thread-specific data`** (**`TSD`**) is also known as thread-local; storage (TLS). Normally, any data that has lifetime beyond the local; variables on the thread's private stack are shared among all threads; within the process. Thread-specific data is a form of static or global; data that is maintained on a per-thread basis. That is, each thread gets; its own private copy of the data. Left to their own devices, threads execute independently.; **`Synchronizatio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:20304,concurren,concurrency,20304,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['concurren'],['concurrency']
Performance,"ta read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:268868,load,load,268868,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"table entries, so that addresses taken outside the module will pass; any verification done inside the module. In more concrete terms, suppose we have three functions ``f``, ``g``,; ``h`` which are all of the same type, and a function foo that returns their; addresses:. .. code-block:: none. f:; mov 0, %eax; ret. g:; mov 1, %eax; ret. h:; mov 2, %eax; ret. foo:; mov f, %eax; mov g, %edx; mov h, %ecx; ret. Our jump table will (conceptually) look like this:. .. code-block:: none. f:; jmp .Ltmp0 ; 5 bytes; int3 ; 1 byte; int3 ; 1 byte; int3 ; 1 byte. g:; jmp .Ltmp1 ; 5 bytes; int3 ; 1 byte; int3 ; 1 byte; int3 ; 1 byte. h:; jmp .Ltmp2 ; 5 bytes; int3 ; 1 byte; int3 ; 1 byte; int3 ; 1 byte. .Ltmp0:; mov 0, %eax; ret. .Ltmp1:; mov 1, %eax; ret. .Ltmp2:; mov 2, %eax; ret. foo:; mov f, %eax; mov g, %edx; mov h, %ecx; ret. Because the addresses of ``f``, ``g``, ``h`` are evenly spaced at a power of; 2, and function types do not overlap (unlike class types with base classes),; we can normally apply the `Alignment`_ and `Eliminating Bit Vector Checks; for All-Ones Bit Vectors`_ optimizations thus simplifying the check at each; call site to a range and alignment check. Shared library support; ======================. **EXPERIMENTAL**. The basic CFI mode described above assumes that the application is a; monolithic binary; at least that all possible virtual/indirect call; targets and the entire class hierarchy are known at link time. The; cross-DSO mode, enabled with **-f[no-]sanitize-cfi-cross-dso** relaxes; this requirement by allowing virtual and indirect calls to cross the; DSO boundary. Assuming the following setup: the binary consists of several; instrumented and several uninstrumented DSOs. Some of them may be; dlopen-ed/dlclose-d periodically, even frequently. - Calls made from uninstrumented DSOs are not checked and just work.; - Calls inside any instrumented DSO are fully protected.; - Calls between different instrumented DSOs are also protected, with; a performance pen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:18519,optimiz,optimizations,18519,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['optimiz'],['optimizations']
Performance,"table is constructed for the; equivalence class of functions instead of a single function. Cross-DSO calls; ---------------; Consider two instrumented DSOs, `A` and `B`. `A` defines `f()` and `B` calls it. This case will be handled similarly to the cross-DSO scheme using the slow path callback. Non-goals; ---------. RCFI does not protect `RET` instructions:; * in non-instrumented DSOs,; * in instrumented DSOs for functions that are called from non-instrumented DSOs,; * embedded into other instructions (e.g. `0f4fc3 cmovg %ebx,%eax`). .. _SafeStack: https://clang.llvm.org/docs/SafeStack.html; .. _RFG: https://xlab.tencent.com/en/2016/11/02/return-flow-guard; .. _Intel CET: https://software.intel.com/en-us/blogs/2016/06/09/intel-release-new-technology-specifications-protect-rop-attacks. Hardware support; ================. We believe that the above design can be efficiently implemented in hardware.; A single new instruction added to an ISA would allow to perform the forward-edge CFI check; with fewer bytes per check (smaller code size overhead) and potentially more; efficiently. The current software-only instrumentation requires at least; 32-bytes per check (on x86_64).; A hardware instruction may probably be less than ~ 12 bytes.; Such instruction would check that the argument pointer is in-bounds,; and is properly aligned, and if the checks fail it will either trap (in monolithic scheme); or call the slow path function (cross-DSO scheme).; The bit vector lookup is probably too complex for a hardware implementation. .. code-block:: none. // This instruction checks that 'Ptr'; // * is aligned by (1 << kAlignment) and; // * is inside [kRangeBeg, kRangeBeg+(kRangeSize<<kAlignment)); // and if the check fails it jumps to the given target (slow path).; //; // 'Ptr' is a register, pointing to the virtual function table; // or to the function which we need to check. We may require an explicit; // fixed register to be used.; // 'kAlignment' is a 4-bit constant.; // 'kRangeSiz",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:27972,perform,perform,27972,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['perform'],['perform']
Performance,"tadata may be attached to; ``load``/``store`` instructions referencing a single metadata with no entries.; The existence of the ``invariant.group`` metadata on the instruction tells; the optimizer that every ``load`` and ``store`` to the same pointer operand; can be assumed to load or store the same; value (but see the ``llvm.launder.invariant.group`` intrinsic which affects; when two pointers are considered the same). Pointers returned by bitcast or; getelementptr with only zero indices are considered the same. Examples:. .. code-block:: llvm. @unknownPtr = external global i8; ...; %ptr = alloca i8; store i8 42, ptr %ptr, !invariant.group !0; call void @foo(ptr %ptr). %a = load i8, ptr %ptr, !invariant.group !0 ; Can assume that value under %ptr didn't change; call void @foo(ptr %ptr). %newPtr = call ptr @getPointer(ptr %ptr); %c = load i8, ptr %newPtr, !invariant.group !0 ; Can't assume anything, because we only have information about %ptr. %unknownValue = load i8, ptr @unknownPtr; store i8 %unknownValue, ptr %ptr, !invariant.group !0 ; Can assume that %unknownValue == 42. call void @foo(ptr %ptr); %newPtr2 = call ptr @llvm.launder.invariant.group.p0(ptr %ptr); %d = load i8, ptr %newPtr2, !invariant.group !0 ; Can't step through launder.invariant.group to get value of %ptr. ...; declare void @foo(ptr); declare ptr @getPointer(ptr); declare ptr @llvm.launder.invariant.group.p0(ptr). !0 = !{}. The invariant.group metadata must be dropped when replacing one pointer by; another based on aliasing information. This is because invariant.group is tied; to the SSA value of the pointer operand. .. code-block:: llvm. %v = load i8, ptr %x, !invariant.group !0; ; if %x mustalias %y then we can replace the above instruction with; %v = load i8, ptr %y. Note that this is an experimental feature, which means that its semantics might; change in the future. '``type``' Metadata; ^^^^^^^^^^^^^^^^^^^. See :doc:`TypeMetadata`. '``associated``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^. The ``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:316921,load,load,316921,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"tainer volume, then positioning the; container itself. However, there are many practical cases when defining; such a container is not straightforward or even possible without; generating overlaps with the rest of the geometry. There are few ways; out of this:. - Defining the container for the structure as ""overlapping"" (see also; ""Overlapping Volumes""); - Representing the container as a composite shape - the Boolean union; of all components (see also ""Composite Shapes""); - Using an assembly volume - this will be described in the following. The first two approaches have the disadvantage of penalizing the; navigation performance with a factor increasing more than linear of the; number of components in the structure. The best solution is the third; one because it uses all volume-related navigation optimizations. The; class TGeoVolumeAssembly represents an assembly volume. Its shape; is represented by TGeoShapeAssembly class that is the union of all; components. It uses volume voxelization to perform navigation tasks. An assembly volume creates a hierarchical level and it geometrically; insulates the structure from the rest (as a normal volume). Physically,; a point that is INSIDE a TGeoShapeAssembly is always inside one of; the components, so a TGeoVolumeAssembly does not need to have a; medium. Due to the self-containment of assemblies, they are very; practical to use when a container is hard to define due to possible; overlaps during positioning. For instance, it is very easy creating; honeycomb structures. A very useful example for creating and using; assemblies can be found at: assembly.C. Creation of an assembly is very easy: one has just to create a; TGeoVolumeAssembly object and position the components inside as; for any volume:. ~~~{.cpp}; TGeoVolume *vol = new TGeoVolumeAssembly(name);; vol->AddNode(vdaughter1, cpy1, matrix1);; vol->AddNode(vdaughter2, cpy2, matrix2);; ~~~. Note that components cannot be declared as ""overlapping"" and that a; component can be an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:49801,perform,perform,49801,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['perform']
Performance,"taken from the fit result; Corr(a,a') = the correlation matrix from the fit result; Z = requested significance 'Z sigma band'. The linear method is fast (requires 2*N evaluations of the curve,; where N is the number of parameters), but may not be accurate in the; presence of strong correlations (~>0.9) and at Z>2 due to linear and; Gaussian approximations made. Alternatively, errors can be visualized using a sampling method. In; this method a number of curves is calculated with variations of the; parameter values, as sampled from a multi-variate Gaussian p.d.f. that; is constructed from the fit results covariance matrix. The error(x); is determined by calculating a central interval that capture N% of the; variations for each value of x, where N% is controlled by Z (i.e. Z=1; gives N=68%). The number of sampling curves is chosen to be such that; at least 100 curves are expected to be outside the N% interval. Intervals from; the sampling method can be asymmetric, and may perform better in the; presence of strong correlations, but may take (much) longer to; calculate. The sampling method also assumes that the uncertainty on the; parameters can modeled by a multi-variate Gaussian distribution. A complete example is provided in a new tutorial macro rf610_visualerror.C,; the output of which is shown below. It is also possible to visualize partial errors (from a subset of the parameters),; as shown above. Binned dataset generation. A new method RooAbsPdf::generateBinned() has been implemented; that samples binned datasets (RooDataHist) from any; p.d.f. RooDataHist* data = pdf.generateBinned(x,10000) ;. This binned generation interface samples the p.d.f. at each bin; center and applies a Poisson fluctuation to each sampled value.; The binning of the returned RooDataHist is controlled by the default; binning associated with the observables generated. To set the number; of bins in x to 200, do e.g. x.setBins(200) prior to the call; to generateBinned(). The binned dataset gener",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:1940,perform,perform,1940,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,1,['perform'],['perform']
Performance,"tance and; class methods, respectively). As with identifiers, selectors are represented by numeric values within the AST; file. A separate index maps these numeric selector values to the offset of the; selector within the on-disk hash table, and will be used when de-serializing an; Objective-C method declaration (or other Objective-C construct) that refers to; the selector. AST Reader Integration Points; -----------------------------. The ""lazy"" deserialization behavior of AST files requires their integration; into several completely different submodules of Clang. For example, lazily; deserializing the declarations during name lookup requires that the name-lookup; routines be able to query the AST file to find entities stored there. For each Clang data structure that requires direct interaction with the AST; reader logic, there is an abstract class that provides the interface between; the two modules. The ``ASTReader`` class, which handles the loading of an AST; file, inherits from all of these abstract classes to provide lazy; deserialization of Clang's data structures. ``ASTReader`` implements the; following abstract classes:. ``ExternalSLocEntrySource``; This abstract interface is associated with the ``SourceManager`` class, and; is used whenever the :ref:`source manager <pchinternals-sourcemgr>` needs to; load the details of a file, buffer, or macro instantiation. ``IdentifierInfoLookup``; This abstract interface is associated with the ``IdentifierTable`` class, and; is used whenever the program source refers to an identifier that has not yet; been seen. In this case, the AST reader searches for this identifier within; its :ref:`identifier table <pchinternals-ident-table>` to load any top-level; declarations or macros associated with that identifier. ``ExternalASTSource``; This abstract interface is associated with the ``ASTContext`` class, and is; used whenever the abstract syntax tree nodes need to loaded from the AST; file. It provides the ability to de-serial",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:22021,load,loading,22021,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['load'],['loading']
Performance,"tance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2577,load,loaded,2577,proof/doc/confman/UsingVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md,1,['load'],['loaded']
Performance,"tarted in a file must end in that file; that is, must have its; ``#endif`` in the same file. A :token:`MacroName` may be defined externally using the ``-D`` option on the; ``*-tblgen`` command line::. llvm-tblgen self-reference.td -Dmacro1 -Dmacro3. Appendix A: Bang Operators; ==========================. Bang operators act as functions in value expressions. A bang operator takes; one or more arguments, operates on them, and produces a result. If the; operator produces a boolean result, the result value will be 1 for true or 0; for false. When an operator tests a boolean argument, it interprets 0 as false; and non-0 as true. .. warning::; The ``!getop`` and ``!setop`` bang operators are deprecated in favor of; ``!getdagop`` and ``!setdagop``. ``!add(``\ *a*\ ``,`` *b*\ ``, ...)``; This operator adds *a*, *b*, etc., and produces the sum. ``!and(``\ *a*\ ``,`` *b*\ ``, ...)``; This operator does a bitwise AND on *a*, *b*, etc., and produces the; result. A logical AND can be performed if all the arguments are either; 0 or 1. ``!cast<``\ *type*\ ``>(``\ *a*\ ``)``; This operator performs a cast on *a* and produces the result.; If *a* is not a string, then a straightforward cast is performed, say; between an ``int`` and a ``bit``, or between record types. This allows; casting a record to a class. If a record is cast to ``string``, the; record's name is produced. If *a* is a string, then it is treated as a record name and looked up in; the list of all defined records. The resulting record is expected to be of; the specified *type*. For example, if ``!cast<``\ *type*\ ``>(``\ *name*\ ``)``; appears in a multiclass definition, or in a; class instantiated inside a multiclass definition, and the *name* does not; reference any template arguments of the multiclass, then a record by; that name must have been instantiated earlier; in the source file. If *name* does reference; a template argument, then the lookup is delayed until ``defm`` statements; instantiating the multiclass (o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:59490,perform,performed,59490,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['perform'],['performed']
Performance,"tary stages of compilation. We feel that ; providing a solution to these two goals will yield an excellent solution ; to the performance problem faced by modern architectures and programming ; languages. A key insight into current compiler and runtime systems is that a ; compiler may fall in anywhere in a ""continuum of compilation"" to do its ; job. On one side, scripting languages statically compile nothing and ; dynamically compile (or equivalently, interpret) everything. On the far ; other side, traditional static compilers process everything statically and ; nothing dynamically. These approaches have typically been seen as a ; tradeoff between performance and portability. On a deeper level, however, ; there are two reasons that optimal system performance may be obtained by a; system somewhere in between these two extremes: Dynamic application ; behavior and social constraints. From a technical perspective, pure static compilation cannot ever give ; optimal performance in all cases, because applications have varying dynamic; behavior that the static compiler cannot take into consideration. Even ; compilers that support profile guided optimization generate poor code in ; the real world, because using such optimization tunes that application ; to one particular usage pattern, whereas real programs (as opposed to ; benchmarks) often have several different usage patterns. On a social level, static compilation is a very shortsighted solution to ; the performance problem. Instruction set architectures (ISAs) continuously ; evolve, and each implementation of an ISA (a processor) must choose a set ; of tradeoffs that make sense in the market context that it is designed for. ; With every new processor introduced, the vendor faces two fundamental ; problems: First, there is a lag time between when a processor is introduced ; to when compilers generate quality code for the architecture. Secondly, ; even when compilers catch up to the new architecture there is often a large ;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt:1227,perform,performance,1227,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt,1,['perform'],['performance']
Performance,"tates-1. The mapping from a given logical; node to a state number is generally not possible, as for the node; B\_1 that appears as current node for 2 different states. The; numbering order of states is therefore not important, but it can be; used as in the following lines:. ~~~{.cpp}; gGeoManager->InitTrack(pt,dir); // anything to initialize a state; Int_t istate = gGeoManager->GetCurrentNodeId(); // in fact state Id; {; //... code changing the current state; }; gGeoManager->CdNode(istate); // forces state's re-initialization; ~~~. - Current `global transformation`. This represents the transformation; from `MARS` to the local reference of the current node, being the; product of all local mother-daughter transformations in the branch.; The global transformation can be referenced or copied:. ~~~{.cpp}; const TGeoHMatrix *global = gGeoManager->GetCurrentMatrix();; TGeoHMatrix *copy = new TGeoHMatrix(*global);; ~~~. - One often needs to perform `master-to-local` and `local-to-master`; point and vector conversions to get from `MARS` to the local node; coordinates. This can be done by using the global transformation or; directly the **`TGeoManager`** corresponding interfaces:. ~~~{.cpp}; Double_t *glob_pt = gGeoManager->GetCurrentPoint();; Double_t *glob_dir = gGeoManager->GetCurrentDirection();; Double_t loc_pt[3], loc_dir[3];; // Go from MARS to local coordinates:; gGeoManager->MasterToLocal(glob_pt,loc_pt); // or:; global->MasterToLocal(glob_pt,loc_pt); // will be omitted from now; ~~~. \anchor GP02f; ### Saving and Restoring the Current State. As we already described, saving and restoring modeller states can be; quite useful during tracking and is a feature extensively used by; external tracking engines. We will call this navigation history; management, which in most of the cases can be performed by handling the; state identifiers. For quite big geometries, state indexing is not; possible anymore and will be automatically disabled by the modeller.; Fortunately there i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:72115,perform,perform,72115,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['perform']
Performance,"tation remains however the same.; A new method TF1::operator()(double x, double y=0, double z) which is equivalent to TF1::Eval has been added for using TF1 as a callable object.; New templated methods TF1::SetFunction for generic C++ callable objects or for class member functions. TH1. Fixed a bug in the TH1::KolmogorovTest function in the case of scaled or weighted histograms. The routine has been improved and; now could also be used for comparing an histogram with a function if it is represented as an histogram with zero errors (equivalent to the case of options ""F1"" or ""F2"" in the original HDIFF routine of HBOOK). The bug has been fixed also for the TH2 and TH3 corresponding method. In addition in the case of TH3 use now all 6 axis combinations for estimating the maximum deviation. This is consistent with what is done in the 2D case.; Improved the TH1::Chi2Test for the treatment of empty bins in the histograms. If both histograms have one empty bin, the number of degree of freedom is decreased by one but the test is performed without reporting an error. If only one histogram is having an empty bin it is considered in the comparison. Fixed a bug in preserving the global statistic information after scaling, adding or rebinning the histogram. TH2. Improve TH2::FitFitSliceX and TH2::FitFitSliceY by adding the possibility to return the generated histograms in a TObjArray when the passed pointer is not null. Support also variable bin size histograms. Improve histogram projections. The implementation of TH2::ProjectionX and TH2::ProjectionY has been combined in a single private method. TH3. Fixed a couple of bugs in TH3::Project3DProfile. TProfile and TProfile2D. Add a new option ""W"" in TProfile::ProjectionX and TProfile::ProjectionXY to be able to return the equivalent weighted filled histogram. Its bin content is equal to the profile bin content multiplied by the bin entries. Implement in the TProfile a new option, ""G"" for the bin error. This option can be used, bin b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v520/index.html:1414,perform,performed,1414,hist/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v520/index.html,1,['perform'],['performed']
Performance,"tatistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Updated class structure: ToyMCSampler is a particular implementation of a TestStatSampler and runs with any TestStatistic. It returns the result in an instance of SamplingDistribution.; Supports Importance Sampling: Improves sampling the tails of a distribution by generating toys from a user supplied importance density and a reweighing procedure of the result.; Supports Adaptive Sampling: extends the run until a given number of toys is reached in the tail(s).; Parallelization using PROOF(-Lite) is supported. It is enabled by supplying a ProofConfig instance. BayesianCalculator. Improve the way the class performs the numerical integration to; find the interval and/or the posterior function.; In case of complex; numerical calculation add the method SetScanOfPosterior(nbins) for; scanning the posterior function in a givn number of nbins; Add possibility to compute lower/upper limits using the method; SetLeftSideTailFraction(fraction); Add possibility to compute shortest interval using; SetShortestInterval. MCMCCalculator. Various improvements including possibility to compute; lower/central/upper limits using; SetLeftSideTailFraction(fraction). New Tutorials. New Demos that take name for file, workspace, modelconfig, and data, then use the corresponding calculator tool. If the file is not specified it will read an file produced from running the HistFactory tutorial example. StandardProfileLikelihoodDemo.C: ; StandardFeldmanCousinsDemo.C: ; StandardBayesianMCMCDemo.C: ; StandardBayesianNumericalDemo.C: ; StandardProfileInspectorDemo.C: . Demonstrate some new PDFs. TestNonCentral.C: demonstrates non central chi-square; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:8077,perform,performs,8077,roofit/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html,1,['perform'],['performs']
Performance,"tax:; """""""""""""". ::. declare i1 @llvm.type.test(ptr %ptr, metadata %type) nounwind memory(none). Arguments:; """""""""""""""""""". The first argument is a pointer to be tested. The second argument is a; metadata object representing a :doc:`type identifier <TypeMetadata>`. Overview:; """""""""""""""""". The ``llvm.type.test`` intrinsic tests whether the given pointer is associated; with the given type identifier. .. _type.checked.load:. '``llvm.type.checked.load``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare {ptr, i1} @llvm.type.checked.load(ptr %ptr, i32 %offset, metadata %type) nounwind memory(argmem: read). Arguments:; """""""""""""""""""". The first argument is a pointer from which to load a function pointer. The; second argument is the byte offset from which to load the function pointer. The; third argument is a metadata object representing a :doc:`type identifier; <TypeMetadata>`. Overview:; """""""""""""""""". The ``llvm.type.checked.load`` intrinsic safely loads a function pointer from a; virtual table pointer using type metadata. This intrinsic is used to implement; control flow integrity in conjunction with virtual call optimization. The; virtual call optimization pass will optimize away ``llvm.type.checked.load``; intrinsics associated with devirtualized calls, thereby removing the type; check in cases where it is not needed to enforce the control flow integrity; constraint. If the given pointer is associated with a type metadata identifier, this; function returns true as the second element of its return value. (Note that; the function may also return true if the given pointer is not associated; with a type metadata identifier.) If the function's return value's second; element is true, the following rules apply to the first element:. - If the given pointer is associated with the given type metadata identifier,; it is the function pointer loaded from the given byte offset from the given; pointer. - If the given pointer is not associated with the given type meta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:938218,load,load,938218,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['load'],"['load', 'loads']"
Performance,"tchCompute` backend now also supports ROOT's implicit multithreading (similar to RDataFrame), which can be enabled as follows:; ```C++; ROOT::EnableImplicitMT(nThreads);; ```. For more information, please have a look at this [contribution to the ACAT 2021 conference](https://indico.cern.ch/event/855454/contributions/4596763/) or consult the [RooBatchComupte README](https://github.com/root-project/root/tree/v6-26-00-patches/roofit/batchcompute).; The README also describes how to enable BatchMode support for your own PDFs. ### Parallel calculation of likelihood gradients during fitting; This release features two new optional RooFit libraries: `RooFit::MultiProcess` and `RooFit::TestStatistics`.; To activate both, build with `-Droofit_multiprocess=ON`. The `RooFit::TestStatistics` namespace contains a major refactoring of the `RooAbsTestStatistic`-`RooAbsOptTestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;; 2. calculation/evaluation/optimization based classes on the other hand. The main selling point of using `RooFit::TestStatistics` from a performance point of view is the implementation of the `RooFit::MultiProcess` based `LikelihoodGradientJob` calculator class.; To use it to perform a ""migrad"" fit (using Minuit2), one should create a `RooMinimizer` using a new constructor with a `RooAbsL` likelihood parameter as follows:. ```c++; using RooFit::TestStatistics::RooAbsL;; using RooFit::TestStatistics::buildLikelihood;. RooAbsPdf* pdf = ...; // build a pdf; RooAbsData* data = ...; // get some data. std::shared_ptr<RooAbsL> likelihood = buildLikelihood(pdf, data, [OPTIONAL ARGUMENTS]);. RooMinimizer m(likelihood);; m.migrad();; ```. The `RooMinimizer` object behaves as usual, except that behind the scenes it will now calculate each partial derivative on a separate process, ideally running on a separate CPU core.; This can be used to speed up fits with many parameters (at least as many as there are cores to parallelize over), s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:16899,optimiz,optimization,16899,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['optimiz'],['optimization']
Performance,"tcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note tha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:238319,cache,cached,238319,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cached']
Performance,"tcnt`` instructions when there are; no intervening memory instructions which access the corresponding address; space. The code sequences in the table indicate what can be omitted for the; OpenCL memory. The target triple environment is used to determine if the; source language is OpenCL (see :ref:`amdgpu-opencl`). ``ds/flat_load/store/atomic`` instructions to local memory are termed LDS; operations. ``buffer/global/flat_load/store/atomic`` instructions to global memory are; termed vector memory operations. Private address space uses ``buffer_load/store`` using the scratch V#; (GFX6-GFX8), or ``scratch_load/store`` (GFX9-GFX11). Since only a single thread; is accessing the memory, atomic memory orderings are not meaningful, and all; accesses are treated as non-atomic. Constant address space uses ``buffer/global_load`` instructions (or equivalent; scalar memory instructions). Since the constant address space contents do not; change during the execution of a kernel dispatch it is not legal to perform; stores, and atomic memory orderings are not meaningful, and all accesses are; treated as non-atomic. A memory synchronization scope wider than work-group is not meaningful for the; group (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-ta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:203501,perform,perform,203501,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['perform']
Performance,"tcode format. It takes a program; in LLVM bitcode format and executes it using a just-in-time compiler or an; interpreter. :program:`lli` is *not* an emulator. It will not execute IR of different architectures; and it can only interpret (or JIT-compile) for the host architecture. The JIT compiler takes the same arguments as other tools, like :program:`llc`,; but they don't necessarily work for the interpreter. If `filename` is not specified, then :program:`lli` reads the LLVM bitcode for the; program from standard input. The optional *args* specified on the command line are passed to the program as; arguments. GENERAL OPTIONS; ---------------. .. option:: -fake-argv0=executable. Override the ``argv[0]`` value passed into the executing program. .. option:: -force-interpreter={false,true}. If set to true, use the interpreter even if a just-in-time compiler is available; for this architecture. Defaults to false. .. option:: -help. Print a summary of command line options. .. option:: -load=pluginfilename. Causes :program:`lli` to load the plugin (shared object) named *pluginfilename* and use; it for optimization. .. option:: -stats. Print statistics from the code-generation passes. This is only meaningful for; the just-in-time compiler, at present. .. option:: -time-passes. Record the amount of time needed for each code-generation pass and print it to; standard error. .. option:: -version. Print out the version of :program:`lli` and exit without doing anything else. TARGET OPTIONS; --------------. .. option:: -mtriple=target triple. Override the target triple specified in the input bitcode file with the; specified string. This may result in a crash if you pick an; architecture which is not compatible with the current system. .. option:: -march=arch. Specify the architecture for which to generate assembly, overriding the target; encoded in the bitcode file. See the output of **llc -help** for a list of; valid architectures. By default this is inferred from the target trip",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst:1272,load,load,1272,interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,1,['load'],['load']
Performance,"te make no assumptions about the value of `vscale`.; ``""nooutline""``; This attribute indicates that outlining passes should not modify the; function. Call Site Attributes; ----------------------. In addition to function attributes the following call site only; attributes are supported:. ``vector-function-abi-variant``; This attribute can be attached to a :ref:`call <i_call>` to list; the vector functions associated to the function. Notice that the; attribute cannot be attached to a :ref:`invoke <i_invoke>` or a; :ref:`callbr <i_callbr>` instruction. The attribute consists of a; comma separated list of mangled names. The order of the list does; not imply preference (it is logically a set). The compiler is free; to pick any listed vector function of its choosing. The syntax for the mangled names is as follows:::. _ZGV<isa><mask><vlen><parameters>_<scalar_name>[(<vector_redirection>)]. When present, the attribute informs the compiler that the function; ``<scalar_name>`` has a corresponding vector variant that can be; used to perform the concurrent invocation of ``<scalar_name>`` on; vectors. The shape of the vector function is described by the; tokens between the prefix ``_ZGV`` and the ``<scalar_name>``; token. The standard name of the vector function is; ``_ZGV<isa><mask><vlen><parameters>_<scalar_name>``. When present,; the optional token ``(<vector_redirection>)`` informs the compiler; that a custom name is provided in addition to the standard one; (custom names can be provided for example via the use of ``declare; variant`` in OpenMP 5.0). The declaration of the variant must be; present in the IR Module. The signature of the vector variant is; determined by the rules of the Vector Function ABI (VFABI); specifications of the target. For Arm and X86, the VFABI can be; found at https://github.com/ARM-software/abi-aa and; https://software.intel.com/content/www/us/en/develop/download/vector-simd-function-abi.html,; respectively. For X86 and Arm targets, the values of t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:112472,perform,perform,112472,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['concurren', 'perform']","['concurrent', 'perform']"
Performance,"te many branches. Each branch has; its own buffer in memory. In case of many branches (say more than 100),; you should adjust the buffer size accordingly. A recommended buffer size; is 32000 bytes if you have less than 50 branches. Around 16000 bytes if; you have less than 100 branches and 4000 bytes if you have more than 500; branches. These numbers are recommended for computers with memory size; ranging from 32MB to 256MB. If you have more memory, you should specify; larger buffer sizes. However, in this case, do not forget that your file; might be used on another machine with a smaller memory configuration. #### Performance Considerations when Splitting a Branch. A split branch is faster to read, but slightly slower to write. The; reading is quicker because variables of the same type are stored; consecutively and the type does not have to be read each time. It is; slower to write because of the large number of buffers as described; above. See "". Performance Benchmarks"" for performance impact of split and non-split; mode. #### Rules for Splitting. When splitting a branch, variables of different types are handled; differently. Here are the rules that apply when splitting a branch. - If a data member is a basic type, it becomes one branch of class; **`TBranchElement`**. - A data member can be an array of basic types. In this case, one; single branch is created for the array. - A data member can be a pointer to an array of basic types. The; length can vary, and must be specified in the comment field of the; data member in the class definition. See ""Input/Output"". - Pointer data member are not split, except for pointers to a; **`TClonesArray`**. The **`TClonesArray`** (pointed to) is split if; the split level is greater than two. When the split level is one,; the **`TClonesArray`** is not split. - If a data member is a pointer to an object, a special branch is; created. The branch will be filled by calling the class `Streamer`; function to serialize the object into the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:26777,perform,performance,26777,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['perform'],['performance']
Performance,"te request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:209592,cache,cache,209592,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['cache'],"['cache', 'caches']"
Performance,"te-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. Tha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39625,load,load,39625,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['load', 'queue']","['load', 'queues']"
Performance,"te: xxspltib; . Similar to XXSPLTW:; def XXSPLTW : XX2Form_2<60, 164,; (outs vsrc:$XT), (ins vsrc:$XB, u2imm:$UIM),; ""xxspltw $XT, $XB, $UIM"", IIC_VecPerm, []>;. . No SDAG, intrinsic, builtin are required?. - Load/Store Vector: lxv stxv; . Has likely SDAG match:; (set v?:$XT, (load ix16addr:$src)); (set v?:$XT, (store ix16addr:$dst)). . Need define ix16addr in PPCInstrInfo.td; ix16addr: 16-byte aligned, see ""def memrix16"" in PPCInstrInfo.td. - Load/Store Vector Indexed: lxvx stxvx; . Has likely SDAG match:; (set v?:$XT, (load xoaddr:$src)); (set v?:$XT, (store xoaddr:$dst)). - Load/Store DWord: lxsd stxsd; . Similar to lxsdx/stxsdx:; def LXSDX : XX1Form<31, 588,; (outs vsfrc:$XT), (ins memrr:$src),; ""lxsdx $XT, $src"", IIC_LdStLFD,; [(set f64:$XT, (load xoaddr:$src))]>;. . (set f64:$XT, (load iaddrX4:$src)); (set f64:$XT, (store iaddrX4:$dst)). - Load/Store SP, with conversion from/to DP: lxssp stxssp; . Similar to lxsspx/stxsspx:; def LXSSPX : XX1Form<31, 524, (outs vssrc:$XT), (ins memrr:$src),; ""lxsspx $XT, $src"", IIC_LdStLFD,; [(set f32:$XT, (load xoaddr:$src))]>;. . (set f32:$XT, (load iaddrX4:$src)); (set f32:$XT, (store iaddrX4:$dst)). - Load as Integer Byte/Halfword & Zero Indexed: lxsibzx lxsihzx; . Similar to lxsiwzx:; def LXSIWZX : XX1Form<31, 12, (outs vsfrc:$XT), (ins memrr:$src),; ""lxsiwzx $XT, $src"", IIC_LdStLFD,; [(set f64:$XT, (PPClfiwzx xoaddr:$src))]>;. . (set f64:$XT, (PPClfiwzx xoaddr:$src)). - Store as Integer Byte/Halfword Indexed: stxsibx stxsihx; . Similar to stxsiwx:; def STXSIWX : XX1Form<31, 140, (outs), (ins vsfrc:$XT, memrr:$dst),; ""stxsiwx $XT, $dst"", IIC_LdStSTFD,; [(PPCstfiwx f64:$XT, xoaddr:$dst)]>;. . (PPCstfiwx f64:$XT, xoaddr:$dst). - Load Vector Halfword*8/Byte*16 Indexed: lxvh8x lxvb16x; . Similar to lxvd2x/lxvw4x:; def LXVD2X : XX1Form<31, 844,; (outs vsrc:$XT), (ins memrr:$src),; ""lxvd2x $XT, $src"", IIC_LdStLFD,; [(set v2f64:$XT, (int_ppc_vsx_lxvd2x xoaddr:$src))]>;. . (set v8i16:$XT, (int_ppc_vsx_lxvh8x xoaddr:$src)); (set v1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt:18149,load,load,18149,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,1,['load'],['load']
Performance,"tead a real binary. There are 4 potential solutions to the problem:. * (1) End users can resolve the issue by pointing the specified compiler executable to; the real binary instead of the symlink.; * (2) End users can invoke ``<path-to-compiler-executable>/clang++ -print-resource-dir``; to get the corresponding resource directory for your compiler and add that directory; to the include search paths manually in the build scripts.; * (3) Build systems that use a compilation database as the input for clang-scan-deps; scanner, the build system can add the flag ``--resource-dir-recipe invoke-compiler`` to; the clang-scan-deps scanner to calculate the resources directory dynamically.; The calculation happens only once for a unique ``<path-to-compiler-executable>/clang++``.; * (4) For build systems that invokes the clang-scan-deps scanner per file, repeatedly; calculating the resource directory may be inefficient. In such cases, the build; system can cache the resource directory by itself and pass ``-resource-dir <resource-dir>``; explicitly in the command line options:. .. code-block:: console. $ clang-scan-deps -format=p1689 -- <path-to-compiler-executable>/clang++ -std=c++20 -resource-dir <resource-dir> mod.cppm -c -o mod.o. Possible Questions; ==================. How modules speed up compilation; --------------------------------. A classic theory for the reason why modules speed up the compilation is:; if there are ``n`` headers and ``m`` source files and each header is included by each source file,; then the complexity of the compilation is ``O(n*m)``;; But if there are ``n`` module interfaces and ``m`` source files, the complexity of the compilation is; ``O(n+m)``. So, using modules would be a big win when scaling.; In a simpler word, we could get rid of many redundant compilations by using modules. Roughly, this theory is correct. But the problem is that it is too rough.; The behavior depends on the optimization level, as we will illustrate below. First is ``O0``. T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst:39243,cache,cache,39243,interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,1,['cache'],['cache']
Performance,"tead of falling back to the complex; omnipotent API. I'm thinking of AST matchers vs. AST visitors as a roughly; similar situation: matchers are not omnipotent, but they're so nice. * Separation between core and checkers is usually quite strange. Once we have; shared state traits, i generally wouldn't mind having region store or range; constraint manager as checkers (though it's probably not worth it to transform; them - just a mood). The main thing to avoid here would be the situation when; the checker overwrites stuff written by the core because it thinks it has a; better idea what's going on, so the core should provide a good default behavior. * Yeah, i totally care about performance as well, and if i try to implement; approach, i'd make sure it's good. **Artem:**. > Approach (2): We could teach the Store to scan itself for bindings to; > metadata-symbolic-based regions during scanReachableSymbols() whenever; > a region turns out to be reachable. This requires no work on checker side,; > but it sounds performance-heavy. Nope, this approach is wrong. Metadata symbols may become out-of-date: when the; object changes, metadata symbols attached to it aren't changing (because symbols; simply don't change). The same metadata may have different symbols to denote its; value in different moments of time, but at most one of them represents the; actual metadata value. So we'd be escaping more stuff than necessary. If only we had ""ghost fields""; (https://lists.llvm.org/pipermail/cfe-dev/2016-May/049000.html), it would have; been much easier, because the ghost field would only contain the actual; metadata, and the Store would always know about it. This example adds to my; belief that ghost fields are exactly what we need for most C++ checkers. **Devin:**. In this case, I would be fine with some sort of; AbstractStorageMemoryRegion that meant ""here is a memory region and somewhere; reachable from here exists another region of type T"". Or even multiple regions; with different id",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst:7597,perform,performance-heavy,7597,interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,1,['perform'],['performance-heavy']
Performance,"tect against an otherwise serious risk of mis-inferring an; ""array"" argument as an out-parameter. Second, it makes it much less likely; that the user will see confusing aliasing problems due to the implementation,; below, where their store to the writeback temporary is not immediately seen; in the original argument variable. A pass-by-writeback is evaluated as follows:. #. The argument is evaluated to yield a pointer ``p`` of type ``U oq *``.; #. If ``p`` is a null pointer, then a null pointer is passed as the argument,; and no further work is required for the pass-by-writeback.; #. Otherwise, a temporary of type ``T __autoreleasing`` is created and; initialized to a null pointer.; #. If the parameter is not an Objective-C method parameter marked ``out``,; then ``*p`` is read, and the result is written into the temporary with; primitive semantics.; #. The address of the temporary is passed as the argument to the actual call.; #. After the call completes, the temporary is loaded with primitive; semantics, and that value is assigned into ``*p``. .. admonition:: Rationale. This is all admittedly convoluted. In an ideal world, we would see that a; local variable is being passed to an out-parameter and retroactively modify; its type to be ``__autoreleasing`` rather than ``__strong``. This would be; remarkably difficult and not always well-founded under the C type system.; However, it was judged unacceptably invasive to require programmers to write; ``__autoreleasing`` on all the variables they intend to use for; out-parameters. This was the least bad solution. .. _arc.ownership.restrictions.records:. Ownership-qualified fields of structs and unions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A member of a struct or union may be declared to have ownership-qualified; type. If the type is qualified with ``__unsafe_unretained``, the semantics; of the containing aggregate are unchanged from the semantics of an unqualified type in a non-ARC mode. If the type is qualified",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:50573,load,loaded,50573,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['load'],['loaded']
Performance,"tecture. .. option:: -mcpu=cpuname. Specify a specific chip in the current architecture to generate code for.; By default this is inferred from the target triple and autodetected to; the current architecture. For a list of available CPUs, use:; **llvm-as < /dev/null | llc -march=xyz -mcpu=help**. .. option:: -mattr=a1,+a2,-a3,... Override or control specific attributes of the target, such as whether SIMD; operations are enabled or not. The default set of attributes is set by the; current CPU. For a list of available attributes, use:; **llvm-as < /dev/null | llc -march=xyz -mattr=help**. FLOATING POINT OPTIONS; ----------------------. .. option:: -disable-excess-fp-precision. Disable optimizations that may increase floating point precision. .. option:: -enable-no-infs-fp-math. Enable optimizations that assume no Inf values. .. option:: -enable-no-nans-fp-math. Enable optimizations that assume no NAN values. .. option:: -enable-unsafe-fp-math. Causes :program:`lli` to enable optimizations that may decrease floating point; precision. .. option:: -soft-float. Causes :program:`lli` to generate software floating point library calls instead of; equivalent hardware instructions. CODE GENERATION OPTIONS; -----------------------. .. option:: -code-model=model. Choose the code model from:. .. code-block:: text. default: Target default code model; tiny: Tiny code model; small: Small code model; kernel: Kernel code model; medium: Medium code model; large: Large code model. .. option:: -disable-post-RA-scheduler. Disable scheduling after register allocation. .. option:: -disable-spill-fusing. Disable fusing of spill code into instructions. .. option:: -jit-enable-eh. Exception handling should be enabled in the just-in-time compiler. .. option:: -join-liveintervals. Coalesce copies (default=true). .. option:: -nozero-initialized-in-bss. Don't place zero-initialized symbols into the BSS section. .. option:: -pre-RA-sched=scheduler. Instruction schedulers available (before register a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst:3305,optimiz,optimizations,3305,interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,1,['optimiz'],['optimizations']
Performance,"ted compiler to; generate profdata based on the training files in clang/utils/perf-training. **stage2**; Depends on stage2-instrumented-generate-profdata and will use the stage1; compiler with the stage2 profdata to build a PGO-optimized compiler. **stage2-check-llvm**; Depends on stage2 and runs check-llvm using the stage2 compiler. **stage2-check-clang**; Depends on stage2 and runs check-clang using the stage2 compiler. **stage2-check-all**; Depends on stage2 and runs check-all using the stage2 compiler. **stage2-test-suite**; Depends on stage2 and runs the test-suite using the stage2 compiler (requires; in-tree test-suite). BOLT; ====. `BOLT <https://github.com/llvm/llvm-project/blob/main/bolt/README.md>`_; (Binary Optimization and Layout Tool) is a tool that optimizes binaries; post-link by profiling them at runtime and then using that information to; optimize the layout of the final binary among other optimizations performed; at the binary level. There are also CMake caches available to build; LLVM/Clang with BOLT. To configure a single-stage build that builds LLVM/Clang and then optimizes; it with BOLT, use the following CMake configuration:. .. code-block:: console. $ cmake <path to source>/llvm -C <path to source>/clang/cmake/caches/BOLT.cmake. Then, build the BOLT-optimized binary by running the following ninja command:. .. code-block:: console. $ ninja clang-bolt. If you're seeing errors in the build process, try building with a recent; version of Clang/LLVM by setting the CMAKE_C_COMPILER and; CMAKE_CXX_COMPILER flags to the appropriate values. It is also possible to use BOLT on top of PGO and (Thin)LTO for an even more; significant runtime speedup. To configure a three stage PGO build with ThinLTO; that optimizes the resulting binary with BOLT, use the following CMake; configuration command:. .. code-block:: console. $ cmake -G Ninja <path to source>/llvm \; -C <path to source>/clang/cmake/caches/BOLT-PGO.cmake \; -DBOOTSTRAP_LLVM_ENABLE_LLD=ON \; -DBOOT",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:10163,cache,caches,10163,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,1,['cache'],['caches']
Performance,"ted projects. > 2. Design issues to consider (an initial list that we should continue; > to modify). Note that I'm not trying to suggest actual solutions here,; > but just various directions we can pursue:. Understood. :). > a. A single-assignment VM, which we've both already been thinking; > about. Yup, I think that this makes a lot of sense. I am still intrigued,; however, by the prospect of a minimally allocated VM representation... I; think that it could have definite advantages for certain applications; (think very small machines, like PDAs). I don't, however, think that our; initial implementations should focus on this. :). Here are some other auxiliary goals that I think we should consider:. 1. Primary goal: Support a high performance dynamic compilation; system. This means that we have an ""ideal"" division of labor between; the runtime and static compilers. Of course, the other goals of the; system somewhat reduce the importance of this point (f.e. portability; reduces performance, but hopefully not much); 2. Portability to different processors. Since we are most familiar with; x86 and solaris, I think that these two are excellent candidates when; we get that far...; 3. Support for all languages & styles of programming (general purpose; VM). This is the point that disallows java style bytecodes, where all; array refs are checked for bounds, etc...; 4. Support linking between different language families. For example, call; C functions directly from Java without using the nasty/slow/gross JNI; layer. This involves several subpoints:; A. Support for languages that require garbage collectors and integration; with languages that don't. As a base point, we could insist on; always using a conservative GC, but implement free as a noop, f.e. > b. A strongly-typed VM. One question is do we need the types to be; > explicitly declared or should they be inferred by the dynamic; > compiler?. B. This is kind of similar to another idea that I have: make OOP; constructs (virt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:3472,perform,performance,3472,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['perform'],['performance']
Performance,"ted with a file ID is loaded only when; required by the front end, e.g., to emit a diagnostic that includes a macro; instantiation history inside the header itself. The source manager block also contains information about all of the headers; that were included when building the AST file. This includes information about; the controlling macro for the header (e.g., when the preprocessor identified; that the contents of the header dependent on a macro like; ``LLVM_CLANG_SOURCEMANAGER_H``). .. _pchinternals-preprocessor:. Preprocessor Block; ^^^^^^^^^^^^^^^^^^. The preprocessor block contains the serialized representation of the; preprocessor. Specifically, it contains all of the macros that have been; defined by the end of the header used to build the AST file, along with the; token sequences that comprise each macro. The macro definitions are only read; from the AST file when the name of the macro first occurs in the program. This; lazy loading of macro definitions is triggered by lookups into the; :ref:`identifier table <pchinternals-ident-table>`. .. _pchinternals-types:. Types Block; ^^^^^^^^^^^. The types block contains the serialized representation of all of the types; referenced in the translation unit. Each Clang type node (``PointerType``,; ``FunctionProtoType``, etc.) has a corresponding record type in the AST file.; When types are deserialized from the AST file, the data within the record is; used to reconstruct the appropriate type node using the AST context. Each type has a unique type ID, which is an integer that uniquely identifies; that type. Type ID 0 represents the NULL type, type IDs less than; ``NUM_PREDEF_TYPE_IDS`` represent predefined types (``void``, ``float``, etc.),; while other ""user-defined"" type IDs are assigned consecutively from; ``NUM_PREDEF_TYPE_IDS`` upward as the types are encountered. The AST file has; an associated mapping from the user-defined types block to the location within; the types block where the serialized representation o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:11643,load,loading,11643,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['load'],['loading']
Performance,"tegy`` and register it with the compiler:. .. code-block:: c++. // lib/MyGC/MyGC.cpp - Example LLVM GC plugin. #include ""llvm/CodeGen/GCStrategy.h""; #include ""llvm/CodeGen/GCMetadata.h""; #include ""llvm/Support/Compiler.h"". using namespace llvm;. namespace {; class LLVM_LIBRARY_VISIBILITY MyGC : public GCStrategy {; public:; MyGC() {}; };. GCRegistry::Add<MyGC>; X(""mygc"", ""My bespoke garbage collector."");; }. This boilerplate collector does nothing. More specifically:. * ``llvm.gcread`` calls are replaced with the corresponding ``load``; instruction. * ``llvm.gcwrite`` calls are replaced with the corresponding ``store``; instruction. * No safe points are added to the code. * The stack map is not compiled into the executable. Using the LLVM makefiles, this code; can be compiled as a plugin using a simple makefile:. .. code-block:: make. # lib/MyGC/Makefile. LEVEL := ../..; LIBRARYNAME = MyGC; LOADABLE_MODULE = 1. include $(LEVEL)/Makefile.common. Once the plugin is compiled, code using it may be compiled using ``llc; -load=MyGC.so`` (though MyGC.so may have some other platform-specific; extension):. ::. $ cat sample.ll; define void @f() gc ""mygc"" {; entry:; ret void; }; $ llvm-as < sample.ll | llc -load=MyGC.so. It is also possible to statically link the collector plugin into tools, such as; a language-specific compiler front-end. .. _collector-algos:. Overview of available features; ------------------------------. ``GCStrategy`` provides a range of features through which a plugin may do useful; work. Some of these are callbacks, some are algorithms that can be enabled,; disabled, or customized. This matrix summarizes the supported (and planned); features and correlates them with the collection techniques which typically; require them. .. |v| unicode:: 0x2714; :trim:. .. |x| unicode:: 0x2718; :trim:. +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | Algorithm | Done | Shadow | refcount | mark- | copying | incremental ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:25407,load,load,25407,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['load'],['load']
Performance,"tely after the link stage. The ``internalize`` pass is also; recommended to remove unused math functions from the resulting PTX. For an; input IR module ``module.bc``, the following compilation flow is recommended:. 1. Save list of external functions in ``module.bc``; 2. Link ``module.bc`` with ``libdevice.compute_XX.YY.bc``; 3. Internalize all functions not in list from (1); 4. Eliminate all unused internal functions; 5. Run ``NVVMReflect`` pass; 6. Run standard optimization pipeline. .. note::. ``linkonce`` and ``linkonce_odr`` linkage types are not suitable for the; libdevice functions. It is possible to link two IR modules that have been; linked against libdevice using different reflection variables. Since the ``NVVMReflect`` pass replaces conditionals with constants, it will; often leave behind dead code of the form:. .. code-block:: llvm. entry:; ..; br i1 true, label %foo, label %bar; foo:; ..; bar:; ; Dead code; .. Therefore, it is recommended that ``NVVMReflect`` is executed early in the; optimization pipeline before dead-code elimination. The NVPTX TargetMachine knows how to schedule ``NVVMReflect`` at the beginning; of your pass manager; just use the following code when setting up your pass; manager and the PassBuilder will use ``registerPassBuilderCallbacks`` to let; NVPTXTargetMachine::registerPassBuilderCallbacks add the pass to the; pass manager:. .. code-block:: c++. std::unique_ptr<TargetMachine> TM = ...;; PassBuilder PB(TM);; ModulePassManager MPM;; PB.parsePassPipeline(MPM, ...);. Reflection Parameters; ---------------------. The libdevice library currently uses the following reflection parameters to; control code generation:. ==================== ======================================================; Flag Description; ==================== ======================================================; ``__CUDA_FTZ=[0,1]`` Use optimized code paths that flush subnormals to zero; ==================== ======================================================.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst:9838,optimiz,optimization,9838,interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,1,['optimiz'],['optimization']
Performance,"tem with other draw options (before one should clear drawings); 11. Several improvements in THttpServer user interface - repair hierarchy reload,; hide unsupported context menu entries, status line update. ## Changes in 3.4; 1. Support usage of minimized versions of .js and .css files.; Minimized scripts used by default on web servers.; 2. Implement JSROOT.extend instead of jQuery.extend, reduce; usage of jquery.js in core JSROOT classes; 3. Implement main graphics without jquery at all,; such mode used in `nobrowser` mode.; 4. Provide optional latex drawing with MathJax SVG.; TMathText always drawn with MathJax,; other classes require `mathjax` option in URL; 5. Improve drawing of different text classes, correctly handle; their alignment and scaling, special handling for IE; 6. Fix error with time axes - time offset was not correctly interpreted. ## Changes in 3.3; 1. Use d3.time.scale for display of time scales; 2. Within JSRootCore.js script URL one could specify JSROOT; functionality to be loaded: '2d', '3d', 'io', 'load', 'onload'.; Old method with JSROOT.AssertPrerequisites will also work.; 3. With THttpServer JSROOT now provides simple control functionality.; One could publish commands and execute them from the browser; 4. One could open several ROOT files simultaneously; 5. Add 'simple' layout - drawing uses full space on the right side; 6. Allow to open ROOT files in online session (via url parameter); 7. One could monitor simultaneously objects from server and root files; 8. Implement 'autocol' draw option - when superimposing histograms,; their line colors will be automatically assigned; 9. Implement 'nostat' draw option - disabled stat drawing; 10. Using '_same_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:67070,load,loaded,67070,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,2,['load'],"['load', 'loaded']"
Performance,"template pattern parameterized over the load upper immediate; instruction, add operation, the zero register, and register class.; Here the instantiation of MipsHiLoRelocs in MipsInstrInfo.td is used; to MIPS32 to compute addresses for the static relocation model. // lib/Target/Mips/MipsInstrInfo.td; multiclass MipsHiLoRelocs<Instruction Lui, Instruction Addiu,; Register ZeroReg, RegisterOperand GPROpnd> {; def : MipsPat<(MipsHi tglobaladdr:$in), (Lui tglobaladdr:$in)>;; ...; def : MipsPat<(MipsLo tglobaladdr:$in), (Addiu ZeroReg, tglobaladdr:$in)>;; ...; def : MipsPat<(add GPROpnd:$hi, (MipsLo tglobaladdr:$lo)),; (Addiu GPROpnd:$hi, tglobaladdr:$lo)>;; ...; }; defm : MipsHiLoRelocs<LUi, ADDiu, ZERO, GPR32Opnd>;. // lib/Target/Mips/Mips64InstrInfo.td; defm : MipsHiLoRelocs<LUi64, DADDiu, ZERO_64, GPR64Opnd>, SYM_32;. The instantiation in Mips64InstrInfo.td is used for MIPS64 in ILP32; mode, as guarded by the predicate ""SYM_32"" and also for a submode of; LP64 where symbols are assumed to be 32 bits wide. More details on how multiclasses in TableGen work can be found in the; section ""Multiclass definitions and instances"" in the document; ""TableGen Language Introduction"". 4. Instruction definitions are multiply defined to cover the different; register classes. In some cases, such as LW/LW64, this also accounts; for the difference in the results of instruction execution. On MIPS32,; ""lw"" loads a 32 bit value from memory. On MIPS64, ""lw"" loads a 32 bit; value from memory and sign extends the value to 64 bits. // lib/Target/Mips/MipsInstrInfo.td; def LUi : MMRel, LoadUpper<""lui"", GPR32Opnd, uimm16_relaxed>, LUI_FM;; // lib/Target/Mips/Mips64InstrInfo.td; def LUi64 : LoadUpper<""lui"", GPR64Opnd, uimm16_64_relaxed>, LUI_FM;. defines two names ""LUi"" and ""LUi64"" with two different register; classes, but with the same encoding---""LUI_FM"". These instructions load a; 16-bit immediate into bits 31-16 and clear the lower 15 bits. On MIPS64,; the result is sign-extended to 64 bits.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt:3293,load,loads,3293,interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt,3,['load'],"['load', 'loads']"
Performance,"tempting to; reduce test programs. If you're trying to find a bug in one of these passes,; **bugpoint** may crash. **--enable-valgrind**. Use valgrind to find faults in the optimization phase. This will allow; bugpoint to find otherwise asymptomatic problems caused by memory; mis-management. **-find-bugs**. Continually randomize the specified passes and run them on the test program; until a bug is found or the user kills **bugpoint**. **-help**. Print a summary of command line options. **--input** *filename*. Open *filename* and redirect the standard input of the test program, whenever; it runs, to come from that file. **--load** *plugin*. Load the dynamic object *plugin* into **bugpoint** itself. This object should; register new optimization passes. Once loaded, the object will add new command; line options to enable various optimizations. To see the new complete list of; optimizations, use the **-help** and **--load** options together; for example:. .. code-block:: bash. bugpoint --load myNewPass.so -help. **--mlimit** *megabytes*. Specifies an upper limit on memory usage of the optimization and codegen. Set; to zero to disable the limit. **--output** *filename*. Whenever the test program produces output on its standard output stream, it; should match the contents of *filename* (the ""reference output""). If you; do not use this option, **bugpoint** will attempt to generate a reference output; by compiling the program with the ""safe"" backend and running it. **--run-{int,jit,llc,custom}**. Whenever the test program is compiled, **bugpoint** should generate code for it; using the specified code generator. These options allow you to choose the; interpreter, the JIT compiler, the static native code compiler, or a; custom command (see **--exec-command**) respectively. **--safe-{llc,custom}**. When debugging a code generator, **bugpoint** should use the specified code; generator as the ""safe"" code generator. This is a known-good code generator; used to generate the ""refere",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst:3664,load,load,3664,interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,1,['load'],['load']
Performance,"ten in the previous format anymore.**; - Support has been added for several new field types: `std::unordered_set<T>`, `std::map<K,V>`, `std::unordered_map<K,V>`; - Support has been added for on-disk half-precision (IEEE 754-2008 16-bit) float fields. This can be enabled through `RField<float>::SetHalfPrecision()`. On reading, values of such fields are represented as regular, 32-bit floats.; - A new `RNTupleInspector` utility class has been added, to provide information about the on-disk metadata of an RNTuple.; - A new `RNTupleParallelWriter` class has been added, providing (initial) support for parallel writing of RNTuples.; - A new static method `RFieldBase::Check()` has been added, which produces a support status report of a type with regards to RNTuple I/O.; - A new internal `RNTupleMerger` class has been added, enabling the merging of different page sources into one page sink. This also means that RNTuples can be merged through `hadd`.; - Zero-copy bulk reading has been added, with extra optimizations for `ROOT::RVec` fields.; - It is now possible to use the `RNTupleView` with an external address with type erasure, e.g.:; ```cpp; std::shared_ptr<void> data{new float()};; auto view = reader->GetView(""pt"", data);; ```; This enables use cases such as reading one specific entry of one specific field into a previously allocated memory location.; - Further integration with [RDataFrame](#rdataframe): it is now possible to create RDataFrame for chains of RNTuples. This addition also comes with improvements to the multi-threaded work scheduling.; - Many additional bug fixes and improvements. Please, report any issues regarding the above mentioned features should you encounter them. RNTuple is still in pre-production. The on-disk format is scheduled to be finalized by the end of 2024. Thus, we appreciate feedback and suggestions for improvement. ## Histogram Libraries. - Implement the FLT_MAX mechanism for `THStack::GetMaximum()` and `THStack::GetMiniumum()`.; - Print a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:5734,optimiz,optimizations,5734,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['optimiz'],['optimizations']
Performance,"tentative scratch V#, then its register numbers; are shifted to the first four-aligned SGPR index after the highest one; allocated by the register allocator, and all uses are updated. The; register count includes them in the shifted location.; - In either case, if the processor has the SGPR allocation bug, the; tentative allocation is not shifted or unreserved in order to ensure; the register count is higher to workaround the bug. .. note::. This approach of using a tentative scratch V# and shifting the register; numbers if used avoids having to perform register allocation a second; time if the tentative V# is eliminated. This is more efficient and; avoids the problem that the second register allocation may perform; spilling which will fail as there is no longer a scratch V#. When the kernel prolog code is being emitted it is known whether the scratch V#; described above is actually used. If it is, the prolog code must set it up by; copying the Private Segment Buffer to the scratch V# registers and then adding; the Private Segment Wavefront Offset to the queue base address in the V#. The; result is a V# with a base address pointing to the beginning of the wavefront; scratch backing memory. The Private Segment Buffer is always requested, but the Private Segment; Wavefront Offset is only requested if it is used (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). .. _amdgpu-amdhsa-memory-model:. Memory Model; ~~~~~~~~~~~~. This section describes the mapping of the LLVM memory model onto AMDGPU machine; code (see :ref:`memmodel`). The AMDGPU backend supports the memory synchronization scopes specified in; :ref:`amdgpu-memory-scopes`. The code sequences used to implement the memory model specify the order of; instructions that a single thread must execute. The ``s_waitcnt`` and cache; management instructions such as ``buffer_wbinvl1_vol`` are defined with respect; to other memory instructions executed by the same thread. This allows them to be; moved earlier or la",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:200437,queue,queue,200437,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance,"ter value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collected values, transforming the IR to expose a pointer giving the; base object for every such live pointer, and inserting all the; intrinsics correctly is explicitly out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of; intrinsic calls known collectively as a ""statepoint relocation sequence"". Let's consider a simple call in LLVM IR:. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:6993,optimiz,optimizer,6993,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,3,"['optimiz', 'perform']","['optimizations', 'optimizer', 'performing']"
Performance,"teration through the elements in sorted order.; Set-like containers are more expensive than sequential containers. * a :ref:`sequential <ds_sequential>` container provides the most efficient way; to add elements and keeps track of the order they are added to the collection.; They permit duplicates and support efficient iteration, but do not support; efficient look-up based on a key. * a :ref:`string <ds_string>` container is a specialized sequential container or; reference structure that is used for character or byte arrays. * a :ref:`bit <ds_bit>` container provides an efficient way to store and; perform set operations on sets of numeric id's, while automatically; eliminating duplicates. Bit containers require a maximum of 1 bit for each; identifier you want to store. Once the proper category of container is determined, you can fine tune the; memory use, constant factors, and cache behaviors of access by intelligently; picking a member of the category. Note that constant factors and cache behavior; can be a big deal. If you have a vector that usually only contains a few; elements (but could contain many), for example, it's much better to use; :ref:`SmallVector <dss_smallvector>` than :ref:`vector <dss_vector>`. Doing so; avoids (relatively) expensive malloc/free calls, which dwarf the cost of adding; the elements to the container. .. _ds_sequential:. Sequential Containers (std::vector, std::list, etc); ---------------------------------------------------. There are a variety of sequential containers available for you, based on your; needs. Pick the first in this section that will do what you want. .. _dss_arrayref:. llvm/ADT/ArrayRef.h; ^^^^^^^^^^^^^^^^^^^. The ``llvm::ArrayRef`` class is the preferred class to use in an interface that; accepts a sequential list of elements in memory and just reads from them. By; taking an ``ArrayRef``, the API can be passed a fixed size array, an; ``std::vector``, an ``llvm::SmallVector`` and anything else that is contiguous; in me",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:57044,cache,cache,57044,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['cache'],['cache']
Performance,"termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219428,perform,performing,219428,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"ternal global i32; ...; %idx1 = getelementptr i32, ptr @MyVar, i64 0; %idx2 = getelementptr i32, ptr @MyVar, i64 1; %idx3 = getelementptr i32, ptr @MyVar, i64 2. These GEP instructions are simply making address computations from the base; address of ``MyVar``. They compute, as follows (using C syntax):. .. code-block:: c++. idx1 = (char*) &MyVar + 0; idx2 = (char*) &MyVar + 4; idx3 = (char*) &MyVar + 8. Since the type ``i32`` is known to be four bytes long, the indices 0, 1 and 2; translate into memory offsets of 0, 4, and 8, respectively. No memory is; accessed to make these computations because the address of ``@MyVar`` is passed; directly to the GEP instructions. The obtuse part of this example is in the cases of ``%idx2`` and ``%idx3``. They; result in the computation of addresses that point to memory past the end of the; ``@MyVar`` global, which is only one ``i32`` long, not three ``i32``\s long.; While this is legal in LLVM, it is inadvisable because any load or store with; the pointer that results from these GEP instructions would trigger undefined; behavior (UB). Why is the extra 0 index required?; ----------------------------------. Quick answer: there are no superfluous indices. This question arises most often when the GEP instruction is applied to a global; variable which is always a pointer type. For example, consider this:. .. code-block:: text. %MyStruct = external global { ptr, i32 }; ...; %idx = getelementptr { ptr, i32 }, ptr %MyStruct, i64 0, i32 1. The GEP above yields a ``ptr`` by indexing the ``i32`` typed field of the; structure ``%MyStruct``. When people first look at it, they wonder why the ``i64; 0`` index is needed. However, a closer inspection of how globals and GEPs work; reveals the need. Becoming aware of the following facts will dispel the; confusion:. #. The type of ``%MyStruct`` is *not* ``{ ptr, i32 }`` but rather ``ptr``.; That is, ``%MyStruct`` is a pointer (to a structure), not a structure itself. #. Point #1 is evidenced by notic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:4760,load,load,4760,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['load'],['load']
Performance,"ters. The main design goals for the; PROOF system are:. *Transparency* : there should be as little difference as possible; between a local ROOT based analysis session and a remote parallel PROOF; session, both being interactive and giving the same results. *Scalability* : the basic architecture should not put any implicit; limitations on the number of computers that can be used in parallel. *Adaptability* : the system should be able to adapt itself to variations; in the remote environment (changing load on the cluster nodes, network; interruptions, etc.). Being an extension of the ROOT system, PROOF is designed to work on; objects in ROOT data stores, though, for the time being, it mainly; addresses the case of **`TTree`** based object collections. PROOF is primarily meant as an interactive alternative to batch systems; for Central Analysis Facilities and departmental workgroups (Tier-2's).; However, thanks to a multi-tier architecture allowing multiple levels of; masters, it can be easily adapted to wide range virtual clusters; distributed over geographically separated domains and heterogeneous; machines (GRIDs). While pure interactivity might not always be possible when performing a; complicated analysis on a very large data set, PROOF still tries to give; the user the interactive experience with something we call ""interactive; batch"". With ""interactive batch"" the user can start very long running; queries, disconnect the client and at any time, any location and from; any computer reconnect to the query to monitor its progress or retrieve; the results. This feature gives it a distinct advantage over purely; batch based solutions, that only provide an answer once all sub-jobs; have been finished. ![The Multi-tier structure of a PROOF cluster](pictures/03000200.png). Details about the PROOF system and the way to use it can be found at; <PROOFWiki> [^1]. The PROOF development is a joint effort between CERN and MIT. [^1]: http://root.cern.ch/twiki/bin/view/ROOT/PROOF; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PROOF.md:1443,perform,performing,1443,documentation/users-guide/PROOF.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PROOF.md,1,['perform'],['performing']
Performance,"tes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also; causes it to be treated as non-volatile and so is not invalidated by; ``*_vol``.; * On APU the kernarg backing memory it is accessed as MTYPE CC (cache coherent); and so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory Model Code Sequences GFX6-GFX9; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX6-GFX9; Space; ============ ============ ============== ========== =",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:210874,cache,cache,210874,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['cache'],['cache']
Performance,"tes, such as sret, byval, inreg,; returned, and inalloca, must match.; - The caller and callee prototypes must match. Pointer types of parameters; or return types may differ in pointee type, but not in address space. On the other hand, if the calling convention is `swifttailcc` or `swiftcc`:. - Only these ABI-impacting attributes attributes are allowed: sret, byval,; swiftself, and swiftasync.; - Prototypes are not required to match. Tail call optimization for calls marked ``tail`` is guaranteed to occur if; the following conditions are met:. - Caller and callee both have the calling convention ``fastcc`` or ``tailcc``.; - The call is in tail position (ret immediately follows call and ret; uses value of call or is void).; - Option ``-tailcallopt`` is enabled,; ``llvm::GuaranteedTailCallOpt`` is ``true``, or the calling convention; is ``tailcc``; - `Platform-specific constraints are; met. <CodeGenerator.html#tailcallopt>`_. #. The optional ``notail`` marker indicates that the optimizers should not add; ``tail`` or ``musttail`` markers to the call. It is used to prevent tail; call optimization from being performed on the call. #. The optional ``fast-math flags`` marker indicates that the call has one or more; :ref:`fast-math flags <fastmath>`, which are optimization hints to enable; otherwise unsafe floating-point optimizations. Fast-math flags are only valid; for calls that return a floating-point scalar or vector type, or an array; (nested to any depth) of floating-point scalar or vector types. #. The optional ""cconv"" marker indicates which :ref:`calling; convention <callingconv>` the call should use. If none is; specified, the call defaults to using C calling conventions. The; calling convention of the call must match the calling convention of; the target function, or else the behavior is undefined.; #. The optional :ref:`Parameter Attributes <paramattrs>` list for return; values. Only '``zeroext``', '``signext``', and '``inreg``' attributes; are valid here.; #. The",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:475484,optimiz,optimizers,475484,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizers']
Performance,"tes-1. The mapping from a given logical; node to a state number is generally not possible, as for the node; B\_1 that appears as current node for 2 different states. The; numbering order of states is therefore not important, but it can be; used as in the following lines:. ``` {.cpp}; gGeoManager->InitTrack(pt,dir); // anything to initialize a state; Int_t istate = gGeoManager->GetCurrentNodeId(); // in fact state Id; {; //... code changing the current state; }; gGeoManager->CdNode(istate); // forces state's re-initialization; ```. - Current `global transformation`. This represents the transformation; from `MARS` to the local reference of the current node, being the; product of all local mother-daughter transformations in the branch.; The global transformation can be referenced or copied:. ``` {.cpp}; const TGeoHMatrix *global = gGeoManager->GetCurrentMatrix();; TGeoHMatrix *copy = new TGeoHMatrix(*global);; ```. - One often needs to perform `master-to-local` and `local-to-master`; point and vector conversions to get from `MARS` to the local node; coordinates. This can be done by using the global transformation or; directly the **`TGeoManager`** corresponding interfaces:. ``` {.cpp}; Double_t *glob_pt = gGeoManager->GetCurrentPoint();; Double_t *glob_dir = gGeoManager->GetCurrentDirection();; Double_t loc_pt[3], loc_dir[3];; // Go from MARS to local coordinates:; gGeoManager->MasterToLocal(glob_pt,loc_pt); // or:; global->MasterToLocal(glob_pt,loc_pt); // will be omitted from now; ```. ### Saving and Restoring the Current State. As we already described, saving and restoring modeller states can be; quite useful during tracking and is a feature extensively used by; external tracking engines. We will call this navigation history; management, which in most of the cases can be performed by handling the; state identifiers. For quite big geometries, state indexing is not; possible anymore and will be automatically disabled by the modeller.; Fortunately there is a backup sol",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:111714,perform,perform,111714,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['perform']
Performance,"teseer.ist.psu.edu/debus04linktime.html. //===---------------------------------------------------------------------===//. gcc generates smaller code for this function at -O2 or -Os:. void foo(signed char* p) {; if (*p == 3); bar();; else if (*p == 4); baz();; else if (*p == 5); quux();; }. llvm decides it's a good idea to turn the repeated if...else into a; binary tree, as if it were a switch; the resulting code requires -1; compare-and-branches when *p<=2 or *p==5, the same number if *p==4; or *p>6, and +1 if *p==3. So it should be a speed win; (on balance). However, the revised code is larger, with 4 conditional; branches instead of 3. More seriously, there is a byte->word extend before; each comparison, where there should be only one, and the condition codes; are not remembered when the same two values are compared twice. //===---------------------------------------------------------------------===//. More LSR enhancements possible:. 1. Teach LSR about pre- and post- indexed ops to allow iv increment be merged; in a load / store.; 2. Allow iv reuse even when a type conversion is required. For example, i8; and i32 load / store addressing modes are identical. //===---------------------------------------------------------------------===//. This:. int foo(int a, int b, int c, int d) {; long long acc = (long long)a * (long long)b;; acc += (long long)c * (long long)d;; return (int)(acc >> 32);; }. Should compile to use SMLAL (Signed Multiply Accumulate Long) which multiplies; two signed 32-bit values to produce a 64-bit value, and accumulates this with; a 64-bit value. We currently get this with both v4 and v6:. _foo:; smull r1, r0, r1, r0; smull r3, r2, r3, r2; adds r3, r3, r1; adc r0, r2, r0; bx lr. //===---------------------------------------------------------------------===//. This:; #include <algorithm>; std::pair<unsigned, bool> full_add(unsigned a, unsigned b); { return std::make_pair(a + b, a + b < a); }; bool no_overflow(unsigned a, unsigned b); { return !full_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:12524,load,load,12524,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,1,['load'],['load']
Performance,"test {; NSString *string = NSLocalizedString(@""LocalizedString"", nil); // warn; NSString *string2 = NSLocalizedString(@""LocalizedString"", @"" ""); // warn; NSString *string3 = NSLocalizedStringWithDefaultValue(; @""LocalizedString"", nil, [[NSBundle alloc] init], nil,@""""); // warn; }. .. _optin-osx-cocoa-localizability-NonLocalizedStringChecker:. optin.osx.cocoa.localizability.NonLocalizedStringChecker (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warns about uses of non-localized NSStrings passed to UI methods expecting localized NSStrings. .. code-block:: objc. NSString *alarmText =; NSLocalizedString(@""Enabled"", @""Indicates alarm is turned on"");; if (!isEnabled) {; alarmText = @""Disabled"";; }; UILabel *alarmStateLabel = [[UILabel alloc] init];. // Warning: User-facing text should use localized string macro; [alarmStateLabel setText:alarmText];. .. _optin-performance-GCDAntipattern:. optin.performance.GCDAntipattern; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for performance anti-patterns when using Grand Central Dispatch. .. _optin-performance-Padding:. optin.performance.Padding; """"""""""""""""""""""""""""""""""""""""""""""""""; Check for excessively padded structs. .. _optin-portability-UnixAPI:. optin.portability.UnixAPI; """"""""""""""""""""""""""""""""""""""""""""""""""; Finds implementation-defined behavior in UNIX/Posix functions. .. _security-checkers:. security; ^^^^^^^^. Security related checkers. .. _security-cert-env-InvalidPtr:. security.cert.env.InvalidPtr; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Corresponds to SEI CERT Rules `ENV31-C <https://wiki.sei.cmu.edu/confluence/display/c/ENV31-C.+Do+not+rely+on+an+environment+pointer+following+an+operation+that+may+invalidate+it>`_ and `ENV34-C <https://wiki.sei.cmu.edu/confluence/display/c/ENV34-C.+Do+not+store+pointers+returned+by+certain+functions>`_. * **ENV31-C**:; Rule is about the possible problem with ``main`` function's third argument, environment pointer,; ""envp"". When environment array is modified using some modification functi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:19413,perform,performance,19413,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['perform'],['performance']
Performance,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:761,cache,cache,761,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,2,['cache'],"['cache', 'caches']"
Performance,"tforward. Precompiled header; ------------------. For performance reasons (reduced memory and CPU usage), a precompiled header; (PCH) of the system and compiler header files will be installed or, failing; that, generated on startup.; Obviously, this PCH is not portable and should not be part of any wheel. Some compiler features, such as AVX, OpenMP, fast math, etc. need to be; active during compilation of the PCH, as they depend both on compiler flags; and system headers (for intrinsics, or API calls).; You can control compiler flags through the ``EXTRA_CLING_ARGS`` envar and thus; what is active in the PCH.; In principle, you can also change the C++ language standard by setting the; appropriate flag on ``EXTRA_CLING_ARGS`` and rebuilding the PCH.; However, if done at this stage, that disables some automatic conversion for; C++ types that were introduced after C++11 (such as ``string_view`` and; ``optional``). If you want multiple PCHs living side-by-side, you can generate them; yourself (note that the given path must be absolute)::. >>> import cppyy_backend.loader as l; >>> l.set_cling_compile_options(True) # adds defaults to EXTRA_CLING_ARGS; >>> install_path = '/full/path/to/target/location/for/PCH'; >>> l.ensure_precompiled_header(install_path). You can then select the appropriate PCH with the ``CLING_STANDARD_PCH`` envar::. $ export CLING_STANDARD_PCH=/full/path/to/target/location/for/PCH/allDict.cxx.pch. Or disable it completely by setting that envar to ""none"". .. note::. Without the PCH, the default C++ standard will be the one with which; ``cppyy-cling`` was built. .. _`conda-forge`: https://anaconda.org/conda-forge/cppyy; .. _`Anaconda`: https://www.anaconda.com/distribution/; .. _`miniconda`: https://docs.conda.io/en/latest/miniconda.html; .. _`PyPI`: https://pypi.python.org/pypi/cppyy/; .. _`virtualenv`: https://pypi.python.org/pypi/virtualenv; .. _`venv`: https://docs.python.org/3/library/venv.html; .. _`Reflex`: https://root.cern.ch/how/how-use-reflex; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:8541,load,loader,8541,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,1,['load'],['loader']
Performance,"th a Release; operation, and vice versa. Notes for optimizers; In general, optimizers should treat this like a nothrow call; the possible; optimizations are usually not interesting. Notes for code generation; This operation has Acquire and Release semantics; see the sections on Acquire; and Release. SequentiallyConsistent; ----------------------. SequentiallyConsistent (``seq_cst`` in IR) provides Acquire semantics for loads; and Release semantics for stores. Additionally, it guarantees that a total; ordering exists between all SequentiallyConsistent operations. Relevant standard; This corresponds to the C++/C ``memory_order_seq_cst``, Java volatile, and; the gcc-compatible ``__sync_*`` builtins which do not specify otherwise. Notes for frontends; If a frontend is exposing atomic operations, these are much easier to reason; about for the programmer than other kinds of operations, and using them is; generally a practical performance tradeoff. Notes for optimizers; Optimizers not aware of atomics can treat this like a nothrow call. For; SequentiallyConsistent loads and stores, the same reorderings are allowed as; for Acquire loads and Release stores, except that SequentiallyConsistent; operations may not be reordered. Notes for code generation; SequentiallyConsistent loads minimally require the same barriers as Acquire; operations and SequentiallyConsistent stores require Release; barriers. Additionally, the code generator must enforce ordering between; SequentiallyConsistent stores followed by SequentiallyConsistent loads. This; is usually done by emitting either a full fence before the loads or a full; fence after the stores; which is preferred varies by architecture. Atomics and IR optimization; ===========================. Predicates for optimizer writers to query:. * ``isSimple()``: A load or store which is not volatile or atomic. This is; what, for example, memcpyopt would check for operations it might transform. * ``isUnordered()``: A load or store which is not",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:15039,optimiz,optimizers,15039,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['optimiz'],['optimizers']
Performance,"th access groups; in its ``llvm.loop.parallel_accesses`` metadata, then the compiler can; assume that there is no dependency between ``m1`` and ``m2`` carried by; this loop. Instructions that belong to multiple access groups are; considered having this property if at least one of the access groups; matches the ``llvm.loop.parallel_accesses`` list. If all memory-accessing instructions in a loop have; ``llvm.access.group`` metadata that each refer to one of the access; groups of a loop's ``llvm.loop.parallel_accesses`` metadata, then the; loop has no loop carried memory dependences and is considered to be a; parallel loop. Note that if not all memory access instructions belong to an access; group referred to by ``llvm.loop.parallel_accesses``, then the loop must; not be considered trivially parallel. Additional; memory dependence analysis is required to make that determination. As a fail; safe mechanism, this causes loops that were originally parallel to be considered; sequential (if optimization passes that are unaware of the parallel semantics; insert new memory instructions into the loop body). Example of a loop that is considered parallel due to its correct use of; both ``llvm.access.group`` and ``llvm.loop.parallel_accesses``; metadata types. .. code-block:: llvm. for.body:; ...; %val0 = load i32, ptr %arrayidx, !llvm.access.group !1; ...; store i32 %val0, ptr %arrayidx1, !llvm.access.group !1; ...; br i1 %exitcond, label %for.end, label %for.body, !llvm.loop !0. for.end:; ...; !0 = distinct !{!0, !{!""llvm.loop.parallel_accesses"", !1}}; !1 = distinct !{}. It is also possible to have nested parallel loops:. .. code-block:: llvm. outer.for.body:; ...; %val1 = load i32, ptr %arrayidx3, !llvm.access.group !4; ...; br label %inner.for.body. inner.for.body:; ...; %val0 = load i32, ptr %arrayidx1, !llvm.access.group !3; ...; store i32 %val0, ptr %arrayidx2, !llvm.access.group !3; ...; br i1 %exitcond, label %inner.for.end, label %inner.for.body, !llvm.loop !1. inner.for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:312879,optimiz,optimization,312879,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance,"th are optional. The ""selection of target"" behavior is defined as follows:. (1) If the user does not specify -triple, we default to the host triple.; (2) If the user specifies a -arch, that overrides the arch in the host or; specified triple. //===---------------------------------------------------------------------===//. verifyInputConstraint and verifyOutputConstraint should not return bool. Instead we should return something like:. enum VerifyConstraintResult {; Valid,. // Output only; OutputOperandConstraintLacksEqualsCharacter,; MatchingConstraintNotValidInOutputOperand,. // Input only; InputOperandConstraintContainsEqualsCharacter,; MatchingConstraintReferencesInvalidOperandNumber,. // Both; PercentConstraintUsedWithLastOperand; };. //===---------------------------------------------------------------------===//. Blocks should not capture variables that are only used in dead code. The rule that we came up with is that blocks are required to capture; variables if they're referenced in evaluated code, even if that code; doesn't actually rely on the value of the captured variable. For example, this requires a capture:; (void) var;; But this does not:; if (false) puts(var);. Summary of <rdar://problem/9851835>: if we implement this, we should; warn about non-POD variables that are referenced but not captured, but; only if the non-reachability is not due to macro or template; metaprogramming. //===---------------------------------------------------------------------===//. We can still apply a modified version of the constructor/destructor; delegation optimization in cases of virtual inheritance where:; - there is no function-try-block,; - the constructor signature is not variadic, and; - the parameter variables can safely be copied and repassed; to the base constructor because either; - they have not had their addresses taken by the vbase initializers or; - they were passed indirectly. //===---------------------------------------------------------------------===//; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/NOTES.txt:3576,optimiz,optimization,3576,interpreter/llvm-project/clang/NOTES.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/NOTES.txt,1,['optimiz'],['optimization']
Performance,"th caution. The; guarantees in terms of synchronization are very weak, so make sure these are; only used in a pattern which you know is correct. Generally, these would; either be used for atomic operations which do not protect other memory (like; an atomic counter), or along with a ``fence``. Notes for optimizers; In terms of the optimizer, this can be treated as a read+write on the relevant; memory location (and alias analysis will take advantage of that). In addition,; it is legal to reorder non-atomic and Unordered loads around Monotonic; loads. CSE/DSE and a few other optimizations are allowed, but Monotonic; operations are unlikely to be used in ways which would make those; optimizations useful. Notes for code generation; Code generation is essentially the same as that for unordered for loads and; stores. No fences are required. ``cmpxchg`` and ``atomicrmw`` are required; to appear as a single operation. Acquire; -------. Acquire provides a barrier of the sort necessary to acquire a lock to access; other memory with normal loads and stores. Relevant standard; This corresponds to the C++/C ``memory_order_acquire``. It should also be; used for C++/C ``memory_order_consume``. Notes for frontends; If you are writing a frontend which uses this directly, use with caution.; Acquire only provides a semantic guarantee when paired with a Release; operation. Notes for optimizers; Optimizers not aware of atomics can treat this like a nothrow call. It is; also possible to move stores from before an Acquire load or read-modify-write; operation to after it, and move non-Acquire loads from before an Acquire; operation to after it. Notes for code generation; Architectures with weak memory ordering (essentially everything relevant today; except x86 and SPARC) require some sort of fence to maintain the Acquire; semantics. The precise fences required varies widely by architecture, but for; a simple implementation, most architectures provide a barrier which is strong; enough for eve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:11573,load,loads,11573,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['load'],['loads']
Performance,"th optimization remarks (see; :ref:`Options to Emit Optimization Reports <rpass>`). The hotness information; allows users to focus on the hot optimization remarks that are likely to be; more relevant for run-time performance. For example, in this output, the block containing the callsite of `foo` was; executed 3000 times according to the profile data:. ::. s.c:7:10: remark: foo inlined into bar (hotness: 3000) [-Rpass-analysis=inline]; sum += foo(x, x - 2);; ^. This option is implied when; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>` is used.; Otherwise, it defaults to off. .. option:: -fdiagnostics-hotness-threshold. Prevent optimization remarks from being output if they do not have at least; this hotness value. This option, which defaults to zero, controls the minimum hotness an; optimization remark would need in order to be output by Clang. This is; currently supported with optimization remarks (see :ref:`Options to Emit; Optimization Reports <rpass>`) when profile hotness information in; diagnostics is enabled (see; :ref:`-fdiagnostics-show-hotness <opt_fdiagnostics-show-hotness>`). .. _opt_fdiagnostics-fixit-info:. .. option:: -f[no-]diagnostics-fixit-info. Enable ""FixIt"" information in the diagnostics output. This option, which defaults to on, controls whether or not Clang; prints the information on how to fix a specific diagnostic; underneath it when it knows. For example, in this output:. ::. test.c:28:8: warning: extra tokens at end of #endif directive [-Wextra-tokens]; #endif bad; ^; //. Passing **-fno-diagnostics-fixit-info** will prevent Clang from; printing the ""//"" line at the end of the message. This information; is useful for users who may not understand what is wrong, but can be; confusing for machine parsing. .. _opt_fdiagnostics-print-source-range-info:. .. option:: -fdiagnostics-print-source-range-info. Print machine parsable information about source ranges.; This option makes Clang print information about source ranges in a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:14960,optimiz,optimization,14960,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance,"th should combine to ((a|b) & (c-1)) != 0. Currently not optimized with; ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. From GCC Bug 20192:; #define PMD_MASK (~((1UL << 23) - 1)); void clear_pmd_range(unsigned long start, unsigned long end); {; if (!(start & ~PMD_MASK) && !(end & ~PMD_MASK)); f();; }; The expression should optimize to something like; ""!((start|end)&~PMD_MASK). Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned int f(unsigned int i, unsigned int n) {++i; if (i == n) ++i; return; i;}; unsigned int f2(unsigned int i, unsigned int n) {++i; i += i == n; return i;}; These should combine to the same thing. Currently, the first function; produces better code on X86. //===---------------------------------------------------------------------===//. From GCC Bug 15784:; #define abs(x) x>0?x:-x; int f(int x, int y); {; return (abs(x)) >= 0;; }; This should optimize to x == INT_MIN. (With -fwrapv.) Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. From GCC Bug 14753:; void; rotate_cst (unsigned int a); {; a = (a << 10) | (a >> 22);; if (a == 123); bar ();; }; void; minus_cst (unsigned int a); {; unsigned int tem;. tem = 20 - a;; if (tem == 5); bar ();; }; void; mask_gt (unsigned int a); {; /* This is equivalent to a > 15. */; if ((a & ~7) > 8); bar ();; }; void; rshift_gt (unsigned int a); {; /* This is equivalent to a > 23. */; if ((a >> 2) > 5); bar ();; }. All should simplify to a single comparison. All of these are; currently not optimized with ""clang -emit-llvm-bc | opt; -O3"". //===---------------------------------------------------------------------===//. From GCC Bug 32605:; int c(int* x) {return (char*)x+2 == (char*)x;}; Should combine to 0. Currently not optimized with ""clang; -emit-llvm-bc | opt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:22566,optimiz,optimize,22566,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['optimiz'],['optimize']
Performance,"th the static superclass instead of the dynamic class. The actual methods; dynamically found in a class are not those declared in the ``@interface``, but; those defined in a separate ``@implementation`` declaration; however, when; compiling a call, typechecking is done based on the methods declared in the; ``@interface``. Method declarations may also be grouped into :arc-term:`protocols`, which are not; inherently associated with any class, but which classes may claim to follow.; Object pointer types may be qualified with additional protocols that the object; is known to support. :arc-term:`Class extensions` are collections of ivars and methods, designed to; allow a class's ``@interface`` to be split across multiple files; however,; there is still a primary implementation file which must see the; ``@interface``\ s of all class extensions. :arc-term:`Categories` allow; methods (but not ivars) to be declared *post hoc* on an arbitrary class; the; methods in the category's ``@implementation`` will be dynamically added to that; class's method tables which the category is loaded at runtime, replacing those; methods in case of a collision. In the standard environment, objects are allocated on the heap, and their; lifetime is manually managed using a reference count. This is done using two; instance methods which all classes are expected to implement: ``retain``; increases the object's reference count by 1, whereas ``release`` decreases it; by 1 and calls the instance method ``dealloc`` if the count reaches 0. To; simplify certain operations, there is also an :arc-term:`autorelease pool`, a; thread-local list of objects to call ``release`` on later; an object can be; added to this pool by calling ``autorelease`` on it. Block pointers may be converted to type ``id``; block objects are laid out in a; way that makes them compatible with Objective-C objects. There is a builtin; class that all block objects are considered to be objects of; this class; implements ``retain`` by ad",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:6525,load,loaded,6525,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['load'],['loaded']
Performance,"th this type metadata, we can now use the ``llvm.type.test`` intrinsic to; test whether a given pointer is compatible with a type identifier. Working; backwards, if ``llvm.type.test`` returns true for a particular pointer,; we can also statically determine the identities of the virtual functions; that a particular virtual call may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:5073,optimiz,optimization,5073,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,"th very short (often purely numeric) names. What to do when bugpoint isn't enough; =====================================; 	; Sometimes, ``bugpoint`` is not enough. In particular, InstCombine and; TargetLowering both have visitor structured code with lots of potential; transformations. If the process of using bugpoint has left you with still too; much code to figure out and the problem seems to be in instcombine, the; following steps may help. These same techniques are useful with TargetLowering; as well. Turn on ``-debug-only=instcombine`` and see which transformations within; instcombine are firing by selecting out lines with ""``IC``"" in them. At this point, you have a decision to make. Is the number of transformations; small enough to step through them using a debugger? If so, then try that. If there are too many transformations, then a source modification approach may; be helpful. In this approach, you can modify the source code of instcombine to; disable just those transformations that are being performed on your test input; and perform a binary search over the set of transformations. One set of places; to modify are the ""``visit*``"" methods of ``InstCombiner`` (*e.g.*; ``visitICmpInst``) by adding a ""``return false``"" as the first line of the; method. If that still doesn't remove enough, then change the caller of; ``InstCombiner::DoOneIteration``, ``InstCombiner::runOnFunction`` to limit the; number of iterations. You may also find it useful to use ""``-stats``"" now to see what parts of; instcombine are firing. This can guide where to put additional reporting code. At this point, if the amount of transformations is still too large, then; inserting code to limit whether or not to execute the body of the code in the; visit function can be helpful. Add a static counter which is incremented on; every invocation of the function. Then add code which simply returns false on; desired ranges. For example:. .. code-block:: c++. static int calledCount = 0;; calledCount++;; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:9149,perform,performed,9149,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,2,['perform'],"['perform', 'performed']"
Performance,"th, clang-format will format up to the end; of the file.; Can only be used with one input file.; --lines=<string> - <start line>:<end line> - format a range of; lines (both 1-based).; Multiple ranges can be formatted by specifying; several -lines arguments.; Can't be used with -offset and -length.; Can only be used with one input file.; -n - Alias for --dry-run; --offset=<uint> - Format a range starting at this byte offset.; Multiple ranges can be formatted by specifying; several -offset and -length pairs.; Can only be used with one input file.; --output-replacements-xml - Output replacements as XML.; --qualifier-alignment=<string> - If set, overrides the qualifier alignment style; determined by the QualifierAlignment style flag; --sort-includes - If set, overrides the include sorting behavior; determined by the SortIncludes style flag; --style=<string> - Set coding style. <string> can be:; 1. A preset: LLVM, GNU, Google, Chromium, Microsoft,; Mozilla, WebKit.; 2. 'file' to load style configuration from a; .clang-format file in one of the parent directories; of the source file (for stdin, see --assume-filename).; If no .clang-format file is found, falls back to; --fallback-style.; --style=file is the default.; 3. 'file:<format_file_path>' to explicitly specify; the configuration file.; 4. ""{key: value, ...}"" to set specific parameters, e.g.:; --style=""{BasedOnStyle: llvm, IndentWidth: 8}""; --verbose - If set, shows the list of processed files. Generic Options:. --help - Display available options (--help-hidden for more); --help-list - Display list of available options (--help-list-hidden for more); --version - Display the version of this program. .. END_FORMAT_HELP. When the desired code formatting style is different from the available options,; the style can be customized using the ``-style=""{key: value, ...}""`` option or; by putting your style configuration in the ``.clang-format`` or ``_clang-format``; file in your project's directory and using ``clang-format -sty",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst:3859,load,load,3859,interpreter/llvm-project/clang/docs/ClangFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst,1,['load'],['load']
Performance,"than 100 bins per axis) that are; not sparse, the COL2 option will provide up to 20 times performance improvements.; For example, a 1000x1000 bin TH2 that is not sparse will render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23164,perform,performance,23164,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['perform'],['performance']
Performance,"than one node in it. All of the virtual methods; described below should return ``true`` if they modified the program, or; ``false`` if they didn't. The ``doInitialization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(CallGraph &CG);. The ``doInitialization`` method is allowed to do most of the things that; ``CallGraphSCCPass``\ es are not allowed to do. They can add and remove; functions, get pointers to functions, etc. The ``doInitialization`` method is; designed to do simple initialization type of stuff that does not depend on the; SCCs being processed. The ``doInitialization`` method call is not scheduled to; overlap with any other pass executions (thus it should be very fast). .. _writing-an-llvm-pass-runOnSCC:. The ``runOnSCC`` method; ^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnSCC(CallGraphSCC &SCC) = 0;. The ``runOnSCC`` method performs the interesting work of the pass, and should; return ``true`` if the module was modified by the transformation, ``false``; otherwise. The ``doFinalization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization(CallGraph &CG);. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` for every SCC in the program being compiled. .. _writing-an-llvm-pass-FunctionPass:. The ``FunctionPass`` class; --------------------------. In contrast to ``ModulePass`` subclasses, `FunctionPass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ subclasses do have a; predictable, local behavior that can be expected by the system. All; ``FunctionPass`` execute on each function in the program independent of all of; the other functions in the program. ``FunctionPass``\ es do not require that; they are executed in a particular order, and ``FunctionPass``\ es do not modify; external fu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:16516,perform,performs,16516,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['perform'],['performs']
Performance,"that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; sc1=1; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acq_rel - agent - generic 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:321329,load,load,321329,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"that partitions values computed by a; function into congruence classes. Values ending up in the same congruence; class are guaranteed to be the same for every execution of the program.; In that respect, congruency is a compile-time approximation of equivalence; of values at runtime. H; -. .. _heap:. **Heap**; In garbage collection, the region of memory which is managed using; reachability analysis. I; -. **ICE**; Internal Compiler Error. This abbreviation is used to describe errors; that occur in LLVM or Clang as they are compiling source code. For example,; if a valid C++ source program were to trigger an assert in Clang when; compiled, that could be referred to as an ""ICE"". **ICF**; Identical Code Folding. **ICP**; Indirect Call Promotion. **IPA**; Inter-Procedural Analysis. Refers to any variety of code analysis that; occurs between procedures, functions or compilation units (modules). **IPO**; Inter-Procedural Optimization. Refers to any variety of code optimization; that occurs between procedures, functions or compilation units (modules). **ISel**; Instruction Selection. L; -. **LCSSA**; Loop-Closed Static Single Assignment Form. **LGTM**; ""Looks Good To Me"". In a review thread, this indicates that the; reviewer thinks that the patch is okay to commit. **LICM**; Loop Invariant Code Motion. **LSDA**; Language Specific Data Area. C++ ""zero cost"" unwinding is built on top a; generic unwinding mechanism. As the unwinder walks each frame, it calls; a ""personality"" function to do language specific analysis. Each function's; FDE points to an optional LSDA which is passed to the personality function.; For C++, the LSDA contain info about the type and location of catch; statements in that function. **Load-VN**; Load Value Numbering. **LTO**; Link-Time Optimization. M; -. **MC**; Machine Code. N; -; .. _nfc:. **NFC**; ""No functional change"". Used in a commit message to indicate that a patch; is a pure refactoring/cleanup.; Usually used in the first line, so it is visible",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Lexicon.rst:4849,optimiz,optimization,4849,interpreter/llvm-project/llvm/docs/Lexicon.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Lexicon.rst,1,['optimiz'],['optimization']
Performance,"that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231601,load,load,231601,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"that the set of threads is the same for all the; operations within the sequence. (If a subset of the convergent operations in the; sequence have additional, non-uniform control dependencies, then this is not; possible. However, the code may still require that the sets of threads are; logically consistent with the conditions of those control dependencies.) In this; case, :ref:`llvm.experimental.convergence.anchor; <llvm.experimental.convergence.anchor>` can be used to express the desired; semantics. The following example function could be part of a hypothetical ""append buffer""; implementation, where threads conditionally write fixed-sized records; contiguously into a global buffer. The function ``@reserveSpaceInBuffer``; returns the index into the buffer at which the calling thread should store its; data. This could be achieved by using a simple atomic operation in every thread to; bump an allocation counter. However, the following implementation can be more performant on some hardware,; because it uses only a single atomic operation for an entire group of threads.; To do this, it first determines the total size of the group, which will be the; operand to the atomic operation, and then later broadcasts the result of the; atomic operation to all threads of the group, so that each thread can compute; its individual position in the buffer:. .. code-block:: llvm. define i32 @reserveSpaceInBuffer() { ; NOTE: _not_ a convergent function!; entry:; %anchor = call token @llvm.experimental.convergence.anchor(). %ballot = call i64 @subgroupBallot(i1 true) [ ""convergencectrl""(token %anchor) ]; %numThreads.p = call i64 @llvm.ctpop.i64(i64 %ballot); %numThreads = trunc i64 %numThreads.p to i32. %absoluteThreadIdx = call i32 @getSubgroupLocalInvocationId(); %absoluteThreadIdx.ext = zext i32 %absoluteThreadIdx to i64; %mask.p = shl i64 1, %absoluteThreadIdx.ext; %mask = sub i64 %mask.p, 1. %maskedBallot = and i64 %ballot, %mask; %relativeThreadIdx.p = call i64 @llvm.ctpop.i64(i64 %ma",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:12567,perform,performant,12567,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,1,['perform'],['performant']
Performance,"that the symbolizing filter processes a coherent stream of; log lines from a single process address space context. If a logging stream; interleaves log lines from more than one process, these must be collated into; separate per-process log streams and each stream processed by a separate; instance of the symbolizing filter. Because the kernel and user processes use; disjoint address regions in most operating systems, a single user process; address space plus the kernel address space can be treated as a single address; space for symbolization purposes if desired. Dependence on Build IDs; =======================. The symbolizer markup scheme relies on contextual information about runtime; memory address layout to make it possible to convert markup elements into useful; symbolic form. This relies on having an unmistakable identification of which; binary was loaded at each address. An ELF Build ID is the payload of an ELF note with name ``""GNU""`` and type; ``NT_GNU_BUILD_ID``, a unique byte sequence that identifies a particular binary; (executable, shared library, loadable module, or driver module). The linker; generates this automatically based on a hash that includes the complete symbol; table and debugging information, even if this is later stripped from the binary. This specification uses the ELF Build ID as the sole means of identifying; binaries. Each binary relevant to the log must have been linked with a unique; Build ID. The symbolizing filter must have some means of mapping a Build ID back; to the original ELF binary (either the whole unstripped binary, or a stripped; binary paired with a separate debug file). Colorization; ============. The markup format supports a restricted subset of ANSI X3.64 SGR (Select Graphic; Rendition) control sequences. These are unlike other markup elements:. * They specify presentation details (bold or colors) rather than semantic; information. The association of semantic meaning with color (e.g. red for; errors) is chosen by the c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:3986,load,loadable,3986,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,1,['load'],['loadable']
Performance,"that values are dead until proven otherwise. This; is similar to :ref:`SCCP <passes-sccp>`, except applied to the liveness of; values. ``always-inline``: Inliner for ``always_inline`` functions; ----------------------------------------------------------. A custom inliner that handles only functions that are marked as ""always; inline"". ``argpromotion``: Promote 'by reference' arguments to scalars; -------------------------------------------------------------. This pass promotes ""by reference"" arguments to be ""by value"" arguments. In; practice, this means looking for internal functions that have pointer; arguments. If it can prove, through the use of alias analysis, that an; argument is *only* loaded, then it can pass the value into the function instead; of the address of the value. This can cause recursive simplification of code; and lead to the elimination of allocas (especially in C++ template code like; the STL). This pass also handles aggregate arguments that are passed into a function,; scalarizing them if the elements of the aggregate are only loaded. Note that; it refuses to scalarize aggregates which would require passing in more than; three operands to the function, because passing thousands of operands for a; large array or structure is unprofitable!. Note that this transformation could also be done for arguments that are only; stored to (returning the value instead), but does not currently. This case; would be best handled when and if LLVM starts supporting multiple return values; from functions. ``block-placement``: Profile Guided Basic Block Placement; ---------------------------------------------------------. This pass is a very simple profile guided basic block placement algorithm. The; idea is to put frequently executed blocks together at the start of the function; and hopefully increase the number of fall-through conditional branches. If; there is no profile information for a particular function, this pass basically; orders blocks in depth-first orde",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:13053,load,loaded,13053,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['load'],['loaded']
Performance,"that we'll have a source file; with a simple program written in Kaleidoscope rather than the; interactive JIT. It does involve a limitation that we can only; have one ""top level"" command at a time to reduce the number of; changes necessary. Here's the sample program we'll be compiling:. .. code-block:: python. def fib(x); if x < 3 then; 1; else; fib(x-1)+fib(x-2);. fib(10). Why is this a hard problem?; ===========================. Debug information is a hard problem for a few different reasons - mostly; centered around optimized code. First, optimization makes keeping source; locations more difficult. In LLVM IR we keep the original source location; for each IR level instruction on the instruction. Optimization passes; should keep the source locations for newly created instructions, but merged; instructions only get to keep a single location - this can cause jumping; around when stepping through optimized programs. Secondly, optimization; can move variables in ways that are either optimized out, shared in memory; with other variables, or difficult to track. For the purposes of this; tutorial we're going to avoid optimization (as you'll see with one of the; next sets of patches). Ahead-of-Time Compilation Mode; ==============================. To highlight only the aspects of adding debug information to a source; language without needing to worry about the complexities of JIT debugging; we're going to make a few changes to Kaleidoscope to support compiling; the IR emitted by the front end into a simple standalone program that; you can execute, debug, and see results. First we make our anonymous function that contains our top level; statement be our ""main"":. .. code-block:: udiff. - auto Proto = std::make_unique<PrototypeAST>("""", std::vector<std::string>());; + auto Proto = std::make_unique<PrototypeAST>(""main"", std::vector<std::string>());. just with the simple change of giving it a name. Then we're going to remove the command line code wherever it exists:. .. code-blo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst:2166,optimiz,optimization,2166,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,2,['optimiz'],"['optimization', 'optimized']"
Performance,"the ""t.c"" input into an object file, two to assemble the; ""t.s"" input, and one to link them together. A rather different compilation pipeline is shown here; in this; example there are two top level actions to compile the input files; into two separate object files, where each object file is built using; ``lipo`` to merge results built for two separate architectures. .. code-block:: console. $ clang -ccc-print-phases -c -arch i386 -arch x86_64 t0.c t1.c; 0: input, ""t0.c"", c; 1: preprocessor, {0}, cpp-output; 2: compiler, {1}, assembler; 3: assembler, {2}, object; 4: bind-arch, ""i386"", {3}, object; 5: bind-arch, ""x86_64"", {3}, object; 6: lipo, {4, 5}, object; 7: input, ""t1.c"", c; 8: preprocessor, {7}, cpp-output; 9: compiler, {8}, assembler; 10: assembler, {9}, object; 11: bind-arch, ""i386"", {10}, object; 12: bind-arch, ""x86_64"", {10}, object; 13: lipo, {11, 12}, object. After this stage is complete the compilation process is divided into; a simple set of actions which need to be performed to produce; intermediate or final outputs (in some cases, like ``-fsyntax-only``,; there is no ""real"" final output). Phases are well known compilation; steps, such as ""preprocess"", ""compile"", ""assemble"", ""link"", etc. #. **Bind: Tool & Filename Selection**. This stage (in conjunction with the Translate stage) turns the tree; of Actions into a list of actual subprocess to run. Conceptually, the; driver performs a top down matching to assign Action(s) to Tools. The; ToolChain is responsible for selecting the tool to perform a; particular action; once selected the driver interacts with the tool; to see if it can match additional actions (for example, by having an; integrated preprocessor). Once Tools have been selected for all actions, the driver determines; how the tools should be connected (for example, using an inprocess; module, pipes, temporary files, or user provided filenames). If an; output file is required, the driver also computes the appropriate; file name (the suffix and fil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst:8258,perform,performed,8258,interpreter/llvm-project/clang/docs/DriverInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst,1,['perform'],['performed']
Performance,"the 200m long detector in a meaningful way. Several generalizations of the projection infrastructure were; required:; TEveProjectable::ProjectedClass() takes an argument:; virtual TClass* ProjectedClass(const TEveProjection* p) const = 0;; thus allowing different projected classes for different projections.; All TEveProjection::ProjectPoint/Vector(...) functions have an; additional ""depth"" argument thus allowing the projected classes to; skip explicit setting of depth after the point has been projected; -- this could damage the 3rd component. Pre-scaling now supports 3 dimensions.; Abstract TEveProjected::SetDepth() has been split into two parts:; ; It has been implemented in the base class where it checks for; the projection type (2d) before calling the local function;; Abstract SetDepthLocal() has been added to provide the same; functionality. This allows for the 2d/3d check to be done in place only.; New projection class has been introduced: TEve3DProjection.; It performs pre-scaling and offsets the center.; To simplify the projection of lists TEveElementList has been made; projectable and corresponding TEveElementListProjected class; introduced. This also fixed the problem with render-state not being; propagated to projected classes. The check whether to project a sub-tree of elements is still performed.; TEveGeoShapeProjected has been introduced to represent the 3D; projection of a TEveGeoShape (2D projection is handled by; TEvePolygonSetProjected). Points, lines and tracks use the same projected class for both 2D; and 3D projections. An example showing this functionality has been added as a new tab in; projection_prescale.C.; TEveManager now allows simultaneous usage of several objects; editors. Simply click on the top name-button in object editor to; create a standalone editor for this object in a separate window. This; facilitates operation when several objects need to be modifed in; parallel.; New tutorial alice_vsd.C has been added. It shows; how to read Vi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v526/index.html:2529,perform,performs,2529,graf3d/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v526/index.html,1,['perform'],['performs']
Performance,"the Chirp filesystem. To configure and build, chirp 3.2.2 must be installed.; When a TFile object is deleted, make sure that CINT also 'removes' any global variables that might point to it.; Fix support for the automatic addition to the current directory (for TTree and TH1 for example) in TKey::Read(TObject*).; In TKey, properly handle error in the I/O routines.; Explicitly check the validity of the zipped buffer before calling R__unzip, this allow for better error recovery.; When double checking whether a checksum difference is sustantial, ignore the std namespace. Use CompareContent also in the case of where; the class is versioned but the 'current' streamerInfo has not yet been built.; Prevent the I/O engine from mistakenly applying schema evolution to the TObject::fBits.; Make sure that when a streamer info of a base class is used to stream memberwise that is always not-optimized. If the StreamerInfo on file; has the same version as the StreamerInfo in memory but the one on file need to be 'not optimized' while the one in memory is not yet built, make; sure it will not be optimized.; Fix the reading of empty collection of object when reading without the library.; If the sequence of actions for streaming member-wise is not created correctly (i.e. where fReadMemberWise was null previously),; we now explicitly issue a Fatal error:. Fatal in <ReadSequence>: The sequence of actions to read AliESDVertex:7 member-wise was not initialized.; aborting. Add new optional parameter maxbuf to TXMLEngine::ParseFile() allowing the specification of the XML file size to be parsed. This fixes issue #78864.; Add function TBuffer::AutoExpand to centralize the automatic buffer extension policy. This enable the ability to tweak it later (for example instead of always doubling the size, increasing by only at most 2Mb or take hints from the number of entries already; in a TBasket).; Migrate the class TFileMerger from the proofplayer library to ROOT I/O library and update hadd to rely on",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v530/index.html:1037,optimiz,optimized,1037,io/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v530/index.html,2,['optimiz'],['optimized']
Performance,"the DWARF is part of a code object, then A may need to be relocated. For; example, in the ELF code object format, A must be adjusted by the difference; between the ELF segment virtual address and the virtual address at which the; segment is loaded.*. 2. ``DW_OP_addrx``. ``DW_OP_addrx`` has a single unsigned LEB128 integer operand that represents; a zero-based index into the ``.debug_addr`` section relative to the value of; the ``DW_AT_addr_base`` attribute of the associated compilation unit. The; address value A in the ``.debug_addr`` section has the size of the generic; type. It pushes a location description L with one memory location description SL; on the stack. SL specifies the memory location storage corresponding to the; target architecture default address space with a bit offset equal to A; scaled by 8 (the byte size). *If the DWARF is part of a code object, then A may need to be relocated. For; example, in the ELF code object format, A must be adjusted by the difference; between the ELF segment virtual address and the virtual address at which the; segment is loaded.*. 3. ``DW_OP_LLVM_form_aspace_address`` *New*. ``DW_OP_LLVM_form_aspace_address`` pops top two stack entries. The first; must be an integral type value that represents a target architecture; specific address space identifier AS. The second must be an integral type; value that represents an address A. The address size S is defined as the address bit size of the target; architecture specific address space that corresponds to AS. A is adjusted to S bits by zero extending if necessary, and then treating; the least significant S bits as an unsigned value A'. It pushes a location description L with one memory location description SL; on the stack. SL specifies the memory location storage LS that corresponds; to AS with a bit offset equal to A' scaled by 8 (the byte size). If AS is an address space that is specific to context elements, then LS; corresponds to the location storage associated with the cur",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:110210,load,loaded,110210,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['load'],['loaded']
Performance,"the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); 5. An AQL kernel dispatch packet is created on the AQL queue. The HSA compatible; runtime api uses 64-bit atomic operations to reserve space in the AQL queue; for the packet. The packet must be set up, and the final write must use an; atomic store release to set the packet kind to ensure the packet contents are; visible to the kernel agent. AQL defines a doorbell signal mechanism to; notify the kernel agent that the AQL queue has been updated. These rules, and; the layout of the AQL queue and kernel dispatch packet is defined in the *HSA; System Architecture Specification* [HSA]_.; 6. A kernel dispatch packet includes information about the actual dispatch,; such as grid and work-group size, together with information from the code; object about the kernel, such as segment sizes. The HSA compatible runtime; queries on the kernel symbol can be used to obtain the code object values; which are recorded in the :ref:`amdgpu-amdhsa-code-object-metadata`.; 7. CP executes micro-code and is responsible for detecting and setting up the; GPU to execute the wavefronts of a kernel dispatch.; 8. CP ensures that when the a wavefront starts executing the kernel machine; code, the scalar general purpose registers (SGPR) and vector general purpose; registers (VGPR) are set up as required by the machine code. The required; setup is defined in the :ref:`amdgpu-amdhsa-kernel-descriptor`. The ini",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:151393,queue,queue,151393,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance,"the Poisson log likelihood function; Improve calculation of derivative in x for fitted function. This fixes some problem observed when fitting using the error on the coordinates.; Fitter class: add new methods for calculating the error matrix after minimization, Fitter::CalculateHessErrors() and for calculating the Minos errors Fitter::CalculateMinosErrors; FitConfig: add in the configuration the possibility to select a sub-set of the parameters for calculating the Minos errors by using the method FitConfig::SetMinosErrors( listOfParameters ). If no list is passed, by default the Minos error will be computed on all parameters.; UnBinData class: add new constructor for creating a unbin data set passing a range to select the data and copy in the internal array; FitResult: the class now stores a map of the Minos error using as key the parameter index. If the Minos error has not been calculated for the parameter, FitResult::LowerError(i) and FitResult::UpperError(i) returns the parabolic error; ; Add a new class, MinimTransformFunction to perform a transformation of the function object to deal with limited and fixed variables.; This class uses the same transformation which are also used inside Minuit, a sin transformation for double bounded variables and a sqrt transformation for single bound variable defined in the class MinimizerVariableTransformation.; These classes can be used by minimizer which do not support internally the bounds (like the GSL minimizers).; . Add two new method in ROOT::Math::Minimizer class:; ; int Minimizer::CovMatrixStatus() : returning the status of the covariance matrix. Implemented by Minuit and Minuit2 and follows original Minuit code meaning: code = 0 (not calculated), 1 (approximated), 2 (matrix was made pos def) , 3 (accurate); ; bool Hesse(): to perform a full calculation of the Hessian matrix; . TMath. Fix a numerical problem in TMath::ErfcInverse for small input values. Now the normal quantile function is used for implementing it.; . ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v524/index.html:1665,perform,perform,1665,math/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v524/index.html,1,['perform'],['perform']
Performance,"the SparseBitVector is that setting and testing of random bits is; O(N), and on large SparseBitVectors, this can be slower than BitVector. In our; implementation, setting or testing bits in sorted order (either forwards or; reverse) is O(1) worst case. Testing and setting bits within 128 bits (depends; on size) of the current bit is also O(1). As a general statement,; testing/setting bits in a SparseBitVector is O(distance away from last set bit). .. _dss_coalescingbitvector:. CoalescingBitVector; ^^^^^^^^^^^^^^^^^^^. The CoalescingBitVector container is similar in principle to a SparseBitVector,; but is optimized to represent large contiguous ranges of set bits compactly. It; does this by coalescing contiguous ranges of set bits into intervals. Searching; for a bit in a CoalescingBitVector is O(log(gaps between contiguous ranges)). CoalescingBitVector is a better choice than BitVector when gaps between ranges; of set bits are large. It's a better choice than SparseBitVector when find(); operations must have fast, predictable performance. However, it's not a good; choice for representing sets which have lots of very short ranges. E.g. the set; `{2*x : x \in [0, n)}` would be a pathological input. .. _utility_functions:. Useful Utility Functions; ========================. LLVM implements a number of general utility functions used across the; codebase. You can find the most common ones in ``STLExtras.h``; (`doxygen <https://llvm.org/doxygen/STLExtras_8h.html>`__). Some of these wrap; well-known C++ standard library functions, while others are unique to LLVM. .. _uf_iteration:. Iterating over ranges; ---------------------. Sometimes you may want to iterate over more than range at a time or know the; index of the index. LLVM provides custom utility functions to make that easier,; without having to manually manage all iterators and/or indices:. .. _uf_zip:. The ``zip``\ * functions; ^^^^^^^^^^^^^^^^^^^^^^^^. ``zip``\ * functions allow for iterating over elements from two ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:99350,perform,performance,99350,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['perform'],['performance']
Performance,"the class,; the method `Delete` is called for the owning collection to delete; correctly its entire track objects. To delete the objects in the; container use `fTrack->Delete()`. To delete the container itself, do; '`delete fTracks'.`. ``` {.cpp}; class TEvent : public TObject {; private:; TList *fTracks; //list of all tracks; TList *fVertex1; //subset of tracks part of vertex1; TList *fVertex2; //subset of tracks part of vertex2; };; TEvent::~TEvent(); {; fTracks->Delete();; delete fTracks;; delete fVertex1;; delete fVertex2;; }; ```. The **`TIterator`** class defines the minimum set of member functions; that all iterators must support. These include:. - `Next`; `Returns the next member of the collection or 0 if no more members.`. - `Reset` `Resets the iterator so that ` `Next`; ` returns the first object.`. ## A Collectable Class. By default, all objects of **`TObject`** derived classes can be stored; in ROOT containers. However, the **`TObject`** class provides some; member functions that allow you to tune the behavior of objects in; containers. For example, by default two objects are considered equal if; their pointers point to the same address. This might be too strict for; some classes where equality is already achieved if some or all of the; data members are equal. By overriding the following **`TObject`** member; functions, you can change the behavior of objects in collections:. - `IsEqual()`is used by the `FindObject() `collection method. By; default, `IsEqual()` compares the two object pointers. - `Compare()`returns -1, 0 or 1 depending if the object is smaller,; equal or larger than the other object. By default, a **`TObject`**; has not a valid `Compare()` method. - `IsSortable() `returns true if the class is sort able (i.e. if it; has a valid `Compare(`) method). By default, a **`TObject`** is not; sort able. - `Hash() `returns a hash value. It needs to be implemented if an; object has to be stored in a collection using a hashing technique,; like **`THas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/CollectionClasses.md:8483,tune,tune,8483,documentation/users-guide/CollectionClasses.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/CollectionClasses.md,1,['tune'],['tune']
Performance,"the code and has some runtime; overhead during the profiling, but it provides more detailed results than a; sampling profiler. It also provides reproducible results, at least to the; extent that the code behaves consistently across runs. Clang supports two types of instrumentation: frontend-based and IR-based.; Frontend-based instrumentation can be enabled with the option ``-fprofile-instr-generate``,; and IR-based instrumentation can be enabled with the option ``-fprofile-generate``.; For best performance with PGO, IR-based instrumentation should be used. It has; the benefits of lower instrumentation overhead, smaller raw profile size, and; better runtime performance. Frontend-based instrumentation, on the other hand,; has better source correlation, so it should be used with source line-based; coverage testing. The flag ``-fcs-profile-generate`` also instruments programs using the same; instrumentation method as ``-fprofile-generate``. However, it performs a; post-inline late instrumentation and can produce context-sensitive profiles. Here are the steps for using profile guided optimization with; instrumentation:. 1. Build an instrumented version of the code by compiling and linking with the; ``-fprofile-generate`` or ``-fprofile-instr-generate`` option. .. code-block:: console. $ clang++ -O2 -fprofile-instr-generate code.cc -o code. 2. Run the instrumented executable with inputs that reflect the typical usage.; By default, the profile data will be written to a ``default.profraw`` file; in the current directory. You can override that default by using option; ``-fprofile-instr-generate=`` or by setting the ``LLVM_PROFILE_FILE``; environment variable to specify an alternate file. If non-default file name; is specified by both the environment variable and the command line option,; the environment variable takes precedence. The file name pattern specified; can include different modifiers: ``%p``, ``%h``, ``%m``, ``%t``, and ``%c``. Any instance of ``%p`` in that file na",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:103236,perform,performs,103236,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['perform'],['performs']
Performance,"the compiler that; the program is well defined no matter what value is used. This gives the; compiler more freedom to optimize. Here are some examples of; (potentially surprising) transformations that are valid (in pseudo IR):. .. code-block:: llvm. %A = add %X, undef; %B = sub %X, undef; %C = xor %X, undef; Safe:; %A = undef; %B = undef; %C = undef. This is safe because all of the output bits are affected by the undef; bits. Any output bit can have a zero or one depending on the input bits. .. code-block:: llvm. %A = or %X, undef; %B = and %X, undef; Safe:; %A = -1; %B = 0; Safe:; %A = %X ;; By choosing undef as 0; %B = %X ;; By choosing undef as -1; Unsafe:; %A = undef; %B = undef. These logical operations have bits that are not always affected by the; input. For example, if ``%X`` has a zero bit, then the output of the; '``and``' operation will always be a zero for that bit, no matter what; the corresponding bit from the '``undef``' is. As such, it is unsafe to; optimize or assume that the result of the '``and``' is '``undef``'.; However, it is safe to assume that all bits of the '``undef``' could be; 0, and optimize the '``and``' to 0. Likewise, it is safe to assume that; all the bits of the '``undef``' operand to the '``or``' could be set,; allowing the '``or``' to be folded to -1. .. code-block:: llvm. %A = select undef, %X, %Y; %B = select undef, 42, %Y; %C = select %X, %Y, undef; Safe:; %A = %X (or %Y); %B = 42 (or %Y); %C = %Y (if %Y is provably not poison; unsafe otherwise); Unsafe:; %A = undef; %B = undef; %C = undef. This set of examples shows that undefined '``select``' (and conditional; branch) conditions can go *either way*, but they have to come from one; of the two operands. In the ``%A`` example, if ``%X`` and ``%Y`` were; both known to have a clear low bit, then ``%A`` would have to have a; cleared low bit. However, in the ``%C`` example, the optimizer is; allowed to assume that the '``undef``' operand could be the same as; ``%Y`` if ``%Y`` is pro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:192338,optimiz,optimize,192338,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimize']
Performance,"the constructor, `fChain` will point to the tree named in; the parameter. Next is `fCurrent`, which is also a pointer to the; current tree/chain. Its role is only relevant when we have multiple; trees chained together in a **`TChain`**. The class definition shows us; that this tree has one branch and one leaf per data member. The methods; of `MyClass` are:. - `MyClass(TTree *tree=0) -` this constructor has an optional tree; for a parameter. If you pass a tree, `MyClass` will use it rather; than the tree from which it was created. - `void Init(TTree *tree) -` it is called by the constructor to; initialize the tree for reading. It associates each branch with the; corresponding leaf data member. - `~MyClass() - `the destructor, nothing special. - `Int_t GetEntry(Int_t entry) -` it loads the class with the entry; specified. Once you have executed `GetEntry`, the leaf data members; in `MyClass` are set to the values of the entry. For example,; `GetEntry(12)` loads the 13th event into the event data member of; `MyClass` (note that the first entry is 0). `GetEntry` returns the; number of bytes read from the file. In case the same entry is read; twice, ROOT does not have to do any I/O. In this case `GetEntry`; returns 1. It does not return 0, because many people assume a return; of 0 means an error has occurred while reading. - `Int_t LoadTree(Int_t entry)` and `void Notify()` - these two; methods are related to chains. `LoadTree` will load the tree; containing the specified entry from a chain of trees. Notify is; called by `LoadTree` to adjust the branch addresses. - `void Loop()` - it is the skeleton method that loops through each; entry of the tree. This is interesting to us, because we will need; to customize it for our analysis. ### MyClass.C. `MyClass::Loop` consists of a for-loop calling `GetEntry` for each; entry. In the template, the numbers of bytes are added up, but it does; nothing else. If we were to execute it now, there would be no output. ``` {.cpp}; void MyC",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:127240,load,loads,127240,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['load'],['loads']
Performance,"the false side of the second if. .. _passes-lcssa:. ``lcssa``: Loop-Closed SSA Form Pass; ------------------------------------. This pass transforms loops by placing phi nodes at the end of the loops for all; values that are live across the loop boundary. For example, it turns the left; into the right code:. .. code-block:: c++. for (...) for (...); if (c) if (c); X1 = ... X1 = ...; else else; X2 = ... X2 = ...; X3 = phi(X1, X2) X3 = phi(X1, X2); ... = X3 + 4 X4 = phi(X3); ... = X4 + 4. This is still valid LLVM; the extra phi nodes are purely redundant, and will be; trivially eliminated by ``InstCombine``. The major benefit of this; transformation is that it makes many other loop optimizations, such as; ``LoopUnswitch``\ ing, simpler. You can read more in the; :ref:`loop terminology section for the LCSSA form <loop-terminology-lcssa>`. .. _passes-licm:. ``licm``: Loop Invariant Code Motion; ------------------------------------. This pass performs loop invariant code motion, attempting to remove as much; code from the body of a loop as possible. It does this by either hoisting code; into the preheader block, or by sinking code to the exit blocks if it is safe.; This pass also promotes must-aliased memory locations in the loop to live in; registers, thus hoisting and sinking ""invariant"" loads and stores. Hoisting operations out of loops is a canonicalization transform. It enables; and simplifies subsequent optimizations in the middle-end. Rematerialization; of hoisted instructions to reduce register pressure is the responsibility of; the back-end, which has more accurate information about register pressure and; also handles other optimizations than LICM that increase live-ranges. This pass uses alias analysis for two purposes:. #. Moving loop invariant loads and calls out of loops. If we can determine; that a load or call inside of a loop never aliases anything stored to, we; can hoist it or sink it like any other instruction. #. Scalar Promotion of Memory. If there is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:23501,perform,performs,23501,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['perform'],['performs']
Performance,"the following code; (from http://gcc.gnu.org/bugzilla/show_bug.cgi?id=34653):; extern unsigned long table[];; unsigned long foo(unsigned char *p) {; unsigned long tag = *p;; return table[tag >> 4] + table[tag & 0xf];; }. Current code generated:; 	movzbl	(%rdi), %eax; 	movq	%rax, %rcx; 	andq	$240, %rcx; 	shrq	%rcx; 	andq	$15, %rax; 	movq	table(,%rax,8), %rax; 	addq	table(%rcx), %rax; 	ret. Issues:; 1. First movq should be movl; saves a byte.; 2. Both andq's should be andl; saves another two bytes. I think this was; implemented at one point, but subsequently regressed.; 3. shrq should be shrl; saves another byte.; 4. The first andq can be completely eliminated by using a slightly more; expensive addressing mode. //===---------------------------------------------------------------------===//. Consider the following (contrived testcase, but contains common factors):. #include <stdarg.h>; int test(int x, ...) {; int sum, i;; va_list l;; va_start(l, x);; for (i = 0; i < x; i++); sum += va_arg(l, int);; va_end(l);; return sum;; }. Testcase given in C because fixing it will likely involve changing the IR; generated for it. The primary issue with the result is that it doesn't do any; of the optimizations which are possible if we know the address of a va_list; in the current function is never taken:; 1. We shouldn't spill the XMM registers because we only call va_arg with ""int"".; 2. It would be nice if we could sroa the va_list.; 3. Probably overkill, but it'd be cool if we could peel off the first five; iterations of the loop. Other optimizations involving functions which use va_arg on floats which don't; have the address of a va_list taken:; 1. Conversely to the above, we shouldn't spill general registers if we only; call va_arg on ""double"".; 2. If we know nothing more than 64 bits wide is read from the XMM registers,; we can change the spilling code to reduce the amount of stack used by half. //===---------------------------------------------------------------------===//; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt:5311,optimiz,optimizations,5311,interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt,2,['optimiz'],['optimizations']
Performance,"the instructions here to fit your own local situation. Prerequisites; =============. In this use case we'll be using cmake on a Debian-based Linux system,; cross-compiling from an x86_64 host to a hard-float Armv7-A target. We'll be; using as many of the LLVM tools as we can, but it is possible to use GNU; equivalents. * ``A build of LLVM/clang for the llvm-tools and llvm-config``; * ``A clang executable with support for the ARM target``; * ``compiler-rt sources``; * ``The qemu-arm user mode emulator``; * ``An arm-linux-gnueabihf sysroot``. In this example we will be using ninja. See https://compiler-rt.llvm.org/ for more information about the dependencies; on clang and LLVM. See https://llvm.org/docs/GettingStarted.html for information about obtaining; the source for LLVM and compiler-rt. Note that the getting started guide; places compiler-rt in the projects subdirectory, but this is not essential and; if you are using the BaremetalARM.cmake cache for v6-M, v7-M and v7-EM then; compiler-rt must be placed in the runtimes directory. ``qemu-arm`` should be available as a package for your Linux distribution. The most complicated of the prerequisites to satisfy is the arm-linux-gnueabihf; sysroot. In theory it is possible to use the Linux distributions multiarch; support to fulfill the dependencies for building but unfortunately due to; /usr/local/include being added some host includes are selected. The easiest way; to supply a sysroot is to download the arm-linux-gnueabihf toolchain. This can; be found at:; * https://developer.arm.com/open-source/gnu-toolchain/gnu-a/downloads for gcc 8 and above; * https://releases.linaro.org/components/toolchain/binaries/ for gcc 4.9 to 7.3. Building compiler-rt builtins for Arm; =====================================; We will be doing a standalone build of compiler-rt using the following cmake; options. * ``path/to/compiler-rt``; * ``-G Ninja``; * ``-DCMAKE_AR=/path/to/llvm-ar``; * ``-DCMAKE_ASM_COMPILER_TARGET=""arm-linux-gnueabihf""`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToCrossCompileBuiltinsOnArm.rst:1680,cache,cache,1680,interpreter/llvm-project/llvm/docs/HowToCrossCompileBuiltinsOnArm.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToCrossCompileBuiltinsOnArm.rst,1,['cache'],['cache']
Performance,"the locality of frequently accessed values on the stack, such; as register spills, return addresses, and small local variables. Compatibility; -------------. Most programs, static libraries, or individual files can be compiled; with SafeStack as is. SafeStack requires basic runtime support, which, on most; platforms, is implemented as a compiler-rt library that is automatically linked; in when the program is compiled with SafeStack. Linking a DSO with SafeStack is not currently supported. Known compatibility limitations; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Certain code that relies on low-level stack manipulations requires adaption to; work with SafeStack. One example is mark-and-sweep garbage collection; implementations for C/C++ (e.g., Oilpan in chromium/blink), which must be; changed to look for the live pointers on both safe and unsafe stacks. SafeStack supports linking statically modules that are compiled with and; without SafeStack. An executable compiled with SafeStack can load dynamic; libraries that are not compiled with SafeStack. At the moment, compiling; dynamic libraries with SafeStack is not supported. Signal handlers that use ``sigaltstack()`` must not use the unsafe stack (see; ``__attribute__((no_sanitize(""safe-stack"")))`` below). Programs that use APIs from ``ucontext.h`` are not supported yet. Security; --------. SafeStack protects return addresses, spilled registers and local variables that; are always accessed in a safe way by separating them in a dedicated safe stack; region. The safe stack is automatically protected against stack-based buffer; overflows, since it is disjoint from the unsafe stack in memory, and it itself; is always accessed in a safe way. In the current implementation, the safe stack; is protected against arbitrary memory write vulnerabilities though; randomization and information hiding: the safe stack is allocated at a random; address and the instrumentation ensures that no pointers to the safe stack are; ever stored outside of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst:2515,load,load,2515,interpreter/llvm-project/clang/docs/SafeStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst,1,['load'],['load']
Performance,"the mask is taken from the; combination of the '``mask``' and '``evl``' operands in the usual VP way. The; alignment of the operation (corresponding to the '``alignment``' operand of; '``llvm.masked.store``') is specified by the ``align`` parameter attribute (see; above). If it is not provided then the ABI alignment of the type of the; '``value``' operand as specified by the :ref:`datalayout; string<langref_datalayout>` is used instead. Examples:; """""""""""""""""". .. code-block:: text. call void @llvm.vp.store.v8i8.p0(<8 x i8> %val, ptr align 4 %ptr, <8 x i1> %mask, i32 %evl); ;; For all lanes below %evl, the call above is lane-wise equivalent to the call below. call void @llvm.masked.store.v8i8.p0(<8 x i8> %val, ptr %ptr, i32 4, <8 x i1> %mask). .. _int_experimental_vp_strided_load:. '``llvm.experimental.vp.strided.load``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <4 x float> @llvm.experimental.vp.strided.load.v4f32.i64(ptr %ptr, i64 %stride, <4 x i1> %mask, i32 %evl); declare <vscale x 2 x i16> @llvm.experimental.vp.strided.load.nxv2i16.i64(ptr %ptr, i64 %stride, <vscale x 2 x i1> %mask, i32 %evl). Overview:; """""""""""""""""". The '``llvm.experimental.vp.strided.load``' intrinsic loads, into a vector, scalar values from; memory locations evenly spaced apart by '``stride``' number of bytes, starting from '``ptr``'. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is the stride; value expressed in bytes. The third operand is a vector of boolean values; with the same number of elements as the return type. The fourth is the explicit; vector length of the operation. The base pointer underlying type matches the type of the scalar; elements of the return operand. The :ref:`align <attr_align>` parameter attribute can be provided for the first; operand. Semantics:; """""""""""""""""""". The '``llvm.experimental.vp.strided.load``' intrinsic loads, into a vector, multipl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:787244,load,load,787244,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"the new API ``ensureOptimizedUses()`` to keep the previous behavior and do a; one-time optimization of ``MemoryUse``\ s, if this was not done before.; New pass users are recommended to call ``ensureOptimizedUses()``. Initially it was not possible to optimize ``MemoryDef``\ s in the same way, as we; restricted ``MemorySSA`` to one operand per access.; This was changed and ``MemoryDef``\ s now keep two operands.; The first one, the defining access, is; always the previous ``MemoryDef`` or ``MemoryPhi`` in the same basic block, or; the last one in a dominating predecessor if the current block doesn't have any; other accesses writing to memory. This is needed for walking Def chains.; The second operand is the optimized access, if there was a previous call on the; walker's ``getClobberingMemoryAccess(MA)``. This API will cache information; as part of ``MA``.; Optimizing all ``MemoryDef``\ s has quadratic time complexity and is not done; by default. A walk of the uses for any MemoryDef can find the accesses that were optimized; to it.; A code snippet for such a walk looks like this:. .. code-block:: c++. MemoryDef *Def; // find who's optimized or defining for this MemoryDef; for (auto& U : Def->uses()) {; MemoryAccess *MA = cast<MemoryAccess>(Use.getUser());; if (auto *DefUser = cast_of_null<MemoryDef>MA); if (DefUser->isOptimized() && DefUser->getOptimized() == Def) {; // User who is optimized to Def; } else {; // User who's defining access is Def; optimized to something else or not optimized.; }; }. When ``MemoryUse``\ s are optimized, for a given store, you can find all loads; clobbered by that store by walking the immediate and transitive uses of; the store. .. code-block:: c++. checkUses(MemoryAccess *Def) { // Def can be a MemoryDef or a MemoryPhi.; for (auto& U : Def->uses()) {; MemoryAccess *MA = cast<MemoryAccess>(Use.getUser());; if (auto *MU = cast_of_null<MemoryUse>MA) {; // Process MemoryUse as needed.; }; else {; // Process MemoryDef or MemoryPhi as needed. /",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:12793,optimiz,optimized,12793,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimized']
Performance,"the object editor; should be the object class name concatenated with the word `‘Editor'`. (c) Provide a default constructor. (d) Use the signals/slots communication mechanism for event processing. (e) Implement the virtual method `SetModel(TObject *obj)` where all; widgets are set with the current object's attributes. This method is; called when the editor receives a signal from the canvas saying that an; object is the selected. (f) Implement all necessary slots and connect them to appropriate; signals that GUI widgets send out. The GUI classes in ROOT are developed; to emit signals whenever they change a state that others might be; interested. As we noted already, the signals/slots communication; mechanism allows total independence of the interacting classes. #### Creation and Destruction. GED-frames are constructed during traversal of class hierarchy of the; selected object, executed from method **`TGedEditor::SetModel()`**.; When a new object of a different class is selected, the unneeded; GED-frames are cached in memory for potential reuse. The frames are; deleted automatically when the editor is closed. Note: A deep cleanup is assumed for all frames put into the editor. This; implies:. - do not share the layout-hints among GUI components;. - do not delete child widgets in the destructor as this is done; automatically. #### Using Several Tabs. Sometimes you might need to use several tabs to organize properly your; class-editor. Each editor tab is a resource shared among all the; class-editors. Tabs must be created from the constructor of your; editor-class by using the method:. ``` {.cpp}; TGVerticalFrame* TGedFrame::CreateEditorTabSubFrame(const Text_t *name),; ```. It returns a pointer to a new tab container frame ready for use in your; class. If you need to hide/show this frame depending on the object's; status, you should store it in a data member. See for examples:; **`TH1Editor`**, **`TH2Editor`**. #### Base-Class Editors Control. Full control over base-cl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:4716,cache,cached,4716,gui/ged/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md,1,['cache'],['cached']
Performance,"the overloaded function:. // lib/Target/Mips/MipsISelLowering.h; SDValue getTargetNode(JumpTableSDNode *N, EVT Ty, SelectionDAG &DAG,; unsigned Flag) const;. 2. Generic address nodes are lowered to some combination of target; independent and machine specific SDNodes (for example:; MipsISD::{Highest, Higher, Hi, Lo}) depending upon relocation model,; ABI, and compilation options. The choice of specific instructions that are to be used is delegated; to ISel which in turn relies on TableGen patterns to choose subtarget; specific instructions. For example, in getAddrLocal, the pseudo-code; generated is:. (add (load (wrapper $gp, %got(sym)), %lo(sym)). where ""%lo"" represents an instance of an SDNode with opcode; ""MipsISD::Lo"", ""wrapper"" indicates one with opcode ""MipsISD::Wrapper"",; and ""%got"" the global table pointer ""getGlobalReg(...)"". The ""add"" is; ""ISD::ADD"", not a target dependent one. 3. A TableGen multiclass pattern ""MipsHiLoRelocs"" is used to define a; template pattern parameterized over the load upper immediate; instruction, add operation, the zero register, and register class.; Here the instantiation of MipsHiLoRelocs in MipsInstrInfo.td is used; to MIPS32 to compute addresses for the static relocation model. // lib/Target/Mips/MipsInstrInfo.td; multiclass MipsHiLoRelocs<Instruction Lui, Instruction Addiu,; Register ZeroReg, RegisterOperand GPROpnd> {; def : MipsPat<(MipsHi tglobaladdr:$in), (Lui tglobaladdr:$in)>;; ...; def : MipsPat<(MipsLo tglobaladdr:$in), (Addiu ZeroReg, tglobaladdr:$in)>;; ...; def : MipsPat<(add GPROpnd:$hi, (MipsLo tglobaladdr:$lo)),; (Addiu GPROpnd:$hi, tglobaladdr:$lo)>;; ...; }; defm : MipsHiLoRelocs<LUi, ADDiu, ZERO, GPR32Opnd>;. // lib/Target/Mips/Mips64InstrInfo.td; defm : MipsHiLoRelocs<LUi64, DADDiu, ZERO_64, GPR64Opnd>, SYM_32;. The instantiation in Mips64InstrInfo.td is used for MIPS64 in ILP32; mode, as guarded by the predicate ""SYM_32"" and also for a submode of; LP64 where symbols are assumed to be 32 bits wide. More details",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt:1927,load,load,1927,interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt,1,['load'],['load']
Performance,"the pointee must be an integer, pointer, or; floating-point type whose bit width is a power of two greater than or equal to; eight and less than or equal to a target-specific size limit. ``align`` must be; explicitly specified on atomic loads. Note: if the alignment is not greater or; equal to the size of the `<value>` type, the atomic operation is likely to; require a lock and have poor performance. ``!nontemporal`` does not have any; defined semantics for atomic loads. The optional constant ``align`` argument specifies the alignment of the; operation (that is, the alignment of the memory address). It is the; responsibility of the code emitter to ensure that the alignment information is; correct. Overestimating the alignment results in undefined behavior.; Underestimating the alignment may produce less efficient code. An alignment of; 1 is always safe. The maximum possible alignment is ``1 << 32``. An alignment; value higher than the size of the loaded type implies memory up to the; alignment value bytes can be safely loaded without trapping in the default; address space. Access of the high bytes can interfere with debugging tools, so; should not be accessed if the function has the ``sanitize_thread`` or; ``sanitize_address`` attributes. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present. An omitted ``align`` argument means that the operation has the; ABI alignment for the target. The optional ``!nontemporal`` metadata must reference a single; metadata name ``<nontemp_node>`` corresponding to a metadata node with one; ``i32`` entry of value 1. The existence of the ``!nontemporal``; metadata on the instruction tells the optimizer and code generator; that this load is not expected to be reused in the cache. The code; generator may select special instructions to save cache bandwidth, such; as the ``MOVNT`` instruction on x86. The optional ``!invariant.load`` metadata must reference a single; metadata name ``<empty_node>`` co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:414356,load,loaded,414356,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['load'],['loaded']
Performance,"the size of the test; program. By default, **bugpoint** uses these passes internally when attempting to; reduce test programs. If you're trying to find a bug in one of these passes,; **bugpoint** may crash. **--enable-valgrind**. Use valgrind to find faults in the optimization phase. This will allow; bugpoint to find otherwise asymptomatic problems caused by memory; mis-management. **-find-bugs**. Continually randomize the specified passes and run them on the test program; until a bug is found or the user kills **bugpoint**. **-help**. Print a summary of command line options. **--input** *filename*. Open *filename* and redirect the standard input of the test program, whenever; it runs, to come from that file. **--load** *plugin*. Load the dynamic object *plugin* into **bugpoint** itself. This object should; register new optimization passes. Once loaded, the object will add new command; line options to enable various optimizations. To see the new complete list of; optimizations, use the **-help** and **--load** options together; for example:. .. code-block:: bash. bugpoint --load myNewPass.so -help. **--mlimit** *megabytes*. Specifies an upper limit on memory usage of the optimization and codegen. Set; to zero to disable the limit. **--output** *filename*. Whenever the test program produces output on its standard output stream, it; should match the contents of *filename* (the ""reference output""). If you; do not use this option, **bugpoint** will attempt to generate a reference output; by compiling the program with the ""safe"" backend and running it. **--run-{int,jit,llc,custom}**. Whenever the test program is compiled, **bugpoint** should generate code for it; using the specified code generator. These options allow you to choose the; interpreter, the JIT compiler, the static native code compiler, or a; custom command (see **--exec-command**) respectively. **--safe-{llc,custom}**. When debugging a code generator, **bugpoint** should use the specified code; generator as ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst:3551,optimiz,optimizations,3551,interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,2,"['load', 'optimiz']","['load', 'optimizations']"
Performance,"the tdf, skipped otherwise.; - The TLazyDS data source has been added. It allows to create a source starting from ResultProxies to vectors.; - `TDataFrameInterface<T>::Report` returns a `TCutflowReport` object which can be inspected programmatically.; - Add `Aggregate` action and implement `Reduce` in terms of it.; - Add support for a more general leafname syntax that includes pathnames with multiple dots, such as ""myBranch.mySubBranch.myLeaf"". This is available both for jitted expressions and for lists of column names.; - The CSV data source (TCsvDS) can now be constructed with a chunk size parameter, and as a result the CSV file will be read progressively, in chunks of the specified size. This can be used to prevent the whole CSV file from being read into memory at once, thus reducing the memory footprint of this data source.; - Add the `ROOT::Experimental::TAdoptAllocator<T>`, an allocator which allows to adopt existing memory. If memory is adopted, upon allocation a copy is performed in the new, potentially more extended, memory region.; - Add `ROOT::Experimental::VecOps::TVec<T>` a class which represents a contiguous array, inspired by Numpy arrays. `TVec` offer a convenient interface, almost identical to the one of `std::vector`. It can own or adopt its memory. As well as a set of tools which make analysis of collections easier, avoiding to loop over the individual elements of the collections. Basic arithmetic operations such as +,-,*,/,% between TVecs and scalars and TVecs are supported. Most popular math functions which act on TVecs are provided. Helpers to calculate basic quantities such as sum, mean, variance or standard deviation of TVecs are provided.; A powerful and concise syntax for expressing cuts is available:; ```; // mu_pts_tvec and mu_etas_tvec are two equally sized TVecs holding kinematic properties of muons; // a filter on muons pseudorapidities is applied considering a range in pseudo rapidity.; filtered_mu_pts_tvec = mu_pts_tvec[abs(mu_etas_t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:8355,perform,performed,8355,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['perform'],['performed']
Performance,"the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and the same L2 cache can be reordered; relative to each other.; * A ``s_waitcnt vmcnt(0)`` is required to ensure synchronization between; vector memory operations of different CUs. It ensures a previous vector; memory operation has completed before executing a subsequent vector memory; or LDS operation and so can be used to meet the requirements of acquire and; release.; * An L2 cache can be kept coherent with other L2 caches by using the MTYPE RW; (read-write) for memory local to the L2, and MTYPE NC (non-coherent) with; the PTE C-bit set for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by the PTE C-bit.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure coherence of local memory writes of CUs with different L1 caches; in the same agent a ``buffer_wbl2`` is required. It does nothing if the; agent is configured to have a single L2, or will writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory writes of CUs in different agents a; ``buffer_wbl2 sc1`` is required. It will writeback dirty L2 cache lines.; * To ensure coherence of local memory reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To ensure coherence of local memory reads of CUs in different agents a; ``buffer_inv sc0 sc1`` is required. It will invalidate non-local L2 cache; lines if configured to have multiple L2 caches. * PCIe access from the GPU to the CP",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:288738,cache,cache,288738,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. That is because the FP multiplier JFPM is only available; from pipeline JFPU1. Instruction encodings are displayed within the instruction info view when flag; `-show-encoding` is specified. Below is an example of `-show-encoding` output for the dot-product kernel:. .. code-block:: none. Instruction Info:; [1]: #uOps; [2]: Latency; [3]: RThroughput; [4]: MayLoad; [5]: MayStore; [6]: HasSideEffects (U); [7]: Encoding Size. [1] [2] [3] [4] [5] [6] [7] Encodings: Instructions:; 1 2 1.00 4 c5 f0 59 d0 vmulps	%xmm0, %xmm1, %xmm2; 1 4 1.00 4 c5 eb 7c da vhaddps	%xmm2, %xmm2, %xmm3; 1 4 1.00 4 c5 e3 7c e3 vhaddps	%xmm3, %xmm3, %xmm4. The `Encoding Size` column shows the size in bytes of instructions. The; `Encod",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:18870,throughput,throughput,18870,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['throughput'],['throughput']
Performance,"the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:362463,load,load,362463,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"ther RuntimeDyldELF or; RuntimeDyldMachO (both of which derive from the RuntimeDyldImpl base; class) and calls the RuntimeDyldImpl::loadObject method to perform that; actual loading. .. image:: MCJIT-dyld-load.png. RuntimeDyldImpl::loadObject begins by creating an ObjectImage instance; from the ObjectBuffer it received. ObjectImage, which wraps the; ObjectFile class, is a helper class which parses the binary object image; and provides access to the information contained in the format-specific; headers, including section, symbol and relocation information. RuntimeDyldImpl::loadObject then iterates through the symbols in the; image. Information about common symbols is collected for later use. For; each function or data symbol, the associated section is loaded into memory; and the symbol is stored in a symbol table map data structure. When the; iteration is complete, a section is emitted for the common symbols. Next, RuntimeDyldImpl::loadObject iterates through the sections in the; object image and for each section iterates through the relocations for; that sections. For each relocation, it calls the format-specific; processRelocationRef method, which will examine the relocation and store; it in one of two data structures, a section-based relocation list map and; an external symbol relocation map. .. image:: MCJIT-load-object.png. When RuntimeDyldImpl::loadObject returns, all of the code and data; sections for the object will have been loaded into memory allocated by the; memory manager and relocation information will have been prepared, but the; relocations have not yet been applied and the generated code is still not; ready to be executed. [Currently (as of August 2013) the MCJIT engine will immediately apply; relocations when loadObject completes. However, this shouldn't be; happening. Because the code may have been generated for a remote target,; the client should be given a chance to re-map the section addresses before; relocations are applied. It is possible to ap",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst:4734,load,loadObject,4734,interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,1,['load'],['loadObject']
Performance,"ther SIMD; operations are enabled or not. The default set of attributes is set by the; current CPU. For a list of available attributes, use:. .. code-block:: none. llvm-as < /dev/null | llc -march=xyz -mattr=help. .. option:: --frame-pointer. Specify effect of frame pointer elimination optimization (all,non-leaf,none). .. option:: --disable-excess-fp-precision. Disable optimizations that may produce excess precision for floating point.; Note that this option can dramatically slow down code on some systems; (e.g. X86). .. option:: --enable-no-infs-fp-math. Enable optimizations that assume no Inf values. .. option:: --enable-no-nans-fp-math. Enable optimizations that assume no NAN values. .. option:: --enable-no-signed-zeros-fp-math. Enable FP math optimizations that assume the sign of 0 is insignificant. .. option:: --enable-no-trapping-fp-math. Enable setting the FP exceptions build attribute not to use exceptions. .. option:: --enable-unsafe-fp-math. Enable optimizations that make unsafe assumptions about IEEE math (e.g. that; addition is associative) or may not work for all input ranges. These; optimizations allow the code generator to make use of some instructions which; would otherwise not be usable (such as ``fsin`` on X86). .. option:: --stats. Print statistics recorded by code-generation passes. .. option:: --time-passes. Record the amount of time needed for each pass and print a report to standard; error. .. option:: --load=<dso_path>. Dynamically load ``dso_path`` (a path to a dynamically shared object) that; implements an LLVM target. This will permit the target name to be used with; the :option:`-march` option so that code can be generated for that target. .. option:: -meabi=[default|gnu|4|5]. Specify which EABI version should conform to. Valid EABI versions are *gnu*,; *4* and *5*. Default value (*default*) depends on the triple. .. option:: -stack-size-section. Emit the .stack_sizes section which contains stack size metadata. The section; contains an ar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst:3840,optimiz,optimizations,3840,interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,1,['optimiz'],['optimizations']
Performance,"ther with coverage mapping for; `source-based code coverage`_. The `coverage mapping format`_ is different from; profile format. .. _`source-based code coverage`: https://clang.llvm.org/docs/SourceBasedCodeCoverage.html; .. _`coverage mapping format`: https://llvm.org/docs/CoverageMappingFormat.html. Raw Profile Format; ===================. The raw profile is generated by running the instrumented binary. The raw profile; data from an executable or a shared library [3]_ consists of a header and; multiple sections, with each section as a memory dump. The raw profile data needs; to be reasonably compact and fast to generate. There are no backward or forward version compatiblity guarantees for the raw profile; format. That is, compilers and tools `require`_ a specific raw profile version; to parse the profiles. .. _`require`: https://github.com/llvm/llvm-project/blob/bffdde8b8e5d9a76a47949cd0f574f3ce656e181/llvm/lib/ProfileData/InstrProfReader.cpp#L551-L558. To feed profiles back into compilers for an optimized build (e.g., via; ``-fprofile-use`` for IR instrumentation), a raw profile must to be converted into; indexed format. General Storage Layout; -----------------------. The storage layout of raw profile data format is illustrated below. Basically,; when the raw profile is read into an memory buffer, the actual byte offset of a; section is inferred from the section's order in the layout and size information; of all the sections ahead of it. ::. +----+-----------------------+; | | Magic |; | +-----------------------+; | | Version |; | +-----------------------+; H | Size Info for |; E | Section 1 |; A +-----------------------+; D | Size Info for |; E | Section 2 |; R +-----------------------+; | | ... |; | +-----------------------+; | | Size Info for |; | | Section N |; +----+-----------------------+; P | Section 1 |; A +-----------------------+; Y | Section 2 |; L +-----------------------+; O | ... |; A +-----------------------+; D | Section N |; +----+--------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst:1677,optimiz,optimized,1677,interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,1,['optimiz'],['optimized']
Performance,"they are never allowed to be selected to generate vector loads and stores. The exception is one-lane vectors [1]_ - these by definition cannot have lane ordering problems so are fine to use ``LDR``/``STR``. 2. Create code generation patterns for bitconverts that create ``REV`` instructions. 3. Make sure appropriate bitconverts are created so that vector values get passed over call boundaries as 1-element vectors (which is the same as if they were loaded with ``LDR``). Bitconverts; -----------. .. image:: ARM-BE-bitcastfail.png; :align: right. The main problem with the ``LD1`` solution is dealing with bitconverts (or bitcasts, or reinterpret casts). These are pseudo instructions that only change the compiler's interpretation of data, not the underlying data itself. A requirement is that if data is loaded and then saved again (called a ""round trip""), the memory contents should be the same after the store as before the load. If a vector is loaded and is then bitconverted to a different vector type before storing, the round trip will currently be broken. Take for example this code sequence::. %0 = load <4 x i32> %x; %1 = bitcast <4 x i32> %0 to <2 x i64>; store <2 x i64> %1, <2 x i64>* %y. This would produce a code sequence such as that in the figure on the right. The mismatched ``LD1`` and ``ST1`` cause the stored data to differ from the loaded data. .. container:: clearer. When we see a bitcast from type ``X`` to type ``Y``, what we need to do is to change the in-register representation of the data to be *as if* it had just been loaded by a ``LD1`` of type ``Y``. .. image:: ARM-BE-bitcastsuccess.png; :align: right. Conceptually this is simple - we can insert a ``REV`` undoing the ``LD1`` of type ``X`` (converting the in-register representation to the same as if it had been loaded by ``LDR``) and then insert another ``REV`` to change the representation to be as if it had been loaded by an ``LD1`` of type ``Y``. For the previous example, this would be::. LD1 v0.4s, [x]. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:10233,load,loaded,10233,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,1,['load'],['loaded']
Performance,"this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_inv.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_inv sc1=1. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - system *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; add",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:304313,load,load,304313,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wonde",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36094,load,load,36094,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,2,['load'],['load']
Performance,"this simple; case, it seems to be pretty clear that `__int_32_0` represents `a`. However, it; is not true. An important note with optimization is that the value of a variable may not; properly express the intended value in the source code. For example:. .. code-block:: c++. static task coro_task(int v) {; int a = v;; co_await await_counter{};; a++; // __int_32_0 is 43 here; std::cout << a << ""\n"";; a++; // __int_32_0 is still 43 here; std::cout << a << ""\n"";; a++; // __int_32_0 is still 43 here!; std::cout << a << ""\n"";; co_await await_counter{};; a++; // __int_32_0 is still 43 here!!; std::cout << a << ""\n"";; a++; // Why is __int_32_0 still 43 here?; std::cout << a << ""\n"";; }. When debugging step-by-step, the value of `__int_32_0` seemingly does not; change, despite being frequently incremented, and instead is always `43`.; While this might be surprising, this is a result of the optimizer recognizing; that it can eliminate most of the load/store operations. The above code gets; optimized to the equivalent of:. .. code-block:: c++. static task coro_task(int v) {; store v to __int_32_0 in the frame; co_await await_counter{};; a = load __int_32_0; std::cout << a+1 << ""\n"";; std::cout << a+2 << ""\n"";; std::cout << a+3 << ""\n"";; co_await await_counter{};; a = load __int_32_0; std::cout << a+4 << ""\n"";; std::cout << a+5 << ""\n"";; }. It should now be obvious why the value of `__int_32_0` remains unchanged; throughout the function. It is important to recognize that `__int_32_0`; does not directly correspond to `a`, but is instead a variable generated; to assist the compiler in code generation. The variables in an optimized; coroutine frame should not be thought of as directly representing the; variables in the C++ source. Get the suspended points; ========================. An important requirement for debugging coroutines is to understand suspended; points, which are where the coroutine is currently suspended and awaiting. For simple cases like the above, inspecting the v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst:9700,optimiz,optimized,9700,interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,1,['optimiz'],['optimized']
Performance,"this; function returns to its caller. If the address space is not explicitly; specified, the object is allocated in the alloca address space from the; :ref:`datalayout string<langref_datalayout>`. Arguments:; """""""""""""""""""". The '``alloca``' instruction allocates ``sizeof(<type>)*NumElements``; bytes of memory on the runtime stack, returning a pointer of the; appropriate type to the program. If ""NumElements"" is specified, it is; the number of elements allocated, otherwise ""NumElements"" is defaulted; to be one. If a constant alignment is specified, the value result of the; allocation is guaranteed to be aligned to at least that boundary. The; alignment may not be greater than ``1 << 32``. The alignment is only optional when parsing textual IR; for in-memory IR,; it is always present. If not specified, the target can choose to align the; allocation on any convenient boundary compatible with the type. '``type``' may be any sized type. Structs containing scalable vectors cannot be used in allocas unless all; fields are the same scalable vector type (e.g. ``{<vscale x 2 x i32>,; <vscale x 2 x i32>}`` contains the same type while ``{<vscale x 2 x i32>,; <vscale x 2 x i64>}`` doesn't). Semantics:; """""""""""""""""""". Memory is allocated; a pointer is returned. The allocated memory is; uninitialized, and loading from uninitialized memory produces an undefined; value. The operation itself is undefined if there is insufficient stack; space for the allocation.'``alloca``'d memory is automatically released; when the function returns. The '``alloca``' instruction is commonly used; to represent automatic variables that must have an address available. When; the function returns (either with the ``ret`` or ``resume`` instructions),; the memory is reclaimed. Allocating zero bytes is legal, but the returned; pointer may not be unique. The order in which memory is allocated (ie.,; which way the stack grows) is not specified. Note that '``alloca``' outside of the alloca address space from the; :ref",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:410183,scalab,scalable,410183,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['scalab'],['scalable']
Performance,"thmetic using ``float``, Clang; does not truncate intermediate operands back to their true type unless the; operand is the result of an explicit cast or assignment. This is generally; much faster but can generate different results from strict operation-by-operation; emulation. Usually the results are more precise. This is permitted by the; C and C++ standards under the rules for excess precision in intermediate operands;; see the discussion of evaluation formats in the C standard and [expr.pre] in; the C++ standard. The use of excess precision can be independently controlled for these two; types with the ``-ffloat16-excess-precision=`` and; ``-fbfloat16-excess-precision=`` options. Valid values include:. * ``none``: meaning to perform strict operation-by-operation emulation; * ``standard``: meaning that excess precision is permitted under the rules; described in the standard, i.e. never across explicit casts or statements; * ``fast``: meaning that excess precision is permitted whenever the; optimizer sees an opportunity to avoid truncations; currently this has no; effect beyond ``standard``. The ``_Float16`` type is an interchange floating type specified in; ISO/IEC TS 18661-3:2015 (""Floating-point extensions for C""). It will; be supported on more targets as they define ABIs for it. The ``__bf16`` type is a non-standard extension, but it generally follows; the rules for arithmetic interchange floating types from ISO/IEC TS; 18661-3:2015. In previous versions of Clang, it was a storage-only type; that forbade arithmetic operations. It will be supported on more targets; as they define ABIs for it. The ``__fp16`` type was originally an ARM extension and is specified; by the `ARM C Language Extensions <https://github.com/ARM-software/acle/releases>`_.; Clang uses the ``binary16`` format from IEEE 754-2008 for ``__fp16``,; not the ARM alternative format. Operators that expect arithmetic operands; immediately promote ``__fp16`` operands to ``float``. It is recommended that",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:33635,optimiz,optimizer,33635,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimizer']
Performance,"thon, for example.; Obvious, but completely wrong, however.; In fact, when it comes to Python, it is even the `wrong question.`. Everything in Python is run-time: modules, classes, functions, etc. are all; run-time constructs.; A Python module that defines a class is a set of instructions to the Python; interpreter that lead to the construction of the desired class object.; A C/C++ extension module that defines a class does the same thing by calling; a succession of Python interpreter Application Programming Interfaces (APIs;; the exact same that Python uses itself internally).; If you use a compile-time binder such as `SWIG`_ or `pybind11`_ to bind a C++; class, then what gets compiled is the series of API calls necessary to; construct a Python-side equivalent at `run-time` (when the module gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed arguments; offset calculations; and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:1754,perform,performance,1754,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,1,['perform'],['performance']
Performance,"though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float -0.0, float -0.0, float -0.0, float -0.0>; %also.r = call float @llvm.vector.reduce.fadd.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_mul:. '``llvm.vp.reduce.mul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.mul.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.mul.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``MUL`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.mul``' intrinsic performs the integer ``MUL`` reduction; (:ref:`llvm.vector.reduce.mul <int_vector_reduce_mul>`) of the vector operand ``val``; on each enabled lane, multiplying it by the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``1`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is the; start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.mul.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:753182,perform,performed,753182,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"tic C++ uses smart pointers to express memory ownership, however in; pre-C++11 code one can often find raw pointers that own heap memory blocks. Imagine that we would like to refactor raw pointers that own memory to; `unique_ptr`. There are multiple ways to design a data flow analysis for this; problem; let's look at one way to do it. For example, we would like to refactor the following code that uses raw; pointers:. ```c++; void UniqueOwnership1() {; int *pi = new int;; if (...) {; Borrow(pi);; delete pi;; } else {; TakeOwnership(pi);; }; }; ```. into code that uses `unique_ptr`:. ```c++; void UniqueOwnership1() {; auto pi = std::make_unique<int>();; if (...) {; Borrow(pi.get());; } else {; TakeOwnership(pi.release());; }; }; ```. This problem can be solved with a lattice in form of map from value declarations; to pointer states:. ![Lattice that identifies candidates for unique_ptr refactoring](DataFlowAnalysisIntroImages/UniquePtrLattice.svg). We can perform the refactoring if at the exit of a function `pi` is; `Compatible`. ```c++; void UniqueOwnership1() {; int *pi; // pi is Compatible; pi = new int; // pi is Defined; if (...) {; Borrow(pi); // pi is Defined; delete pi; // pi is Compatible; } else {; TakeOwnership(pi); // pi is Compatible; }; // pi is Compatible; }; ```. Let's look at an example where the raw pointer owns two different memory blocks:. ```c++; void UniqueOwnership2() {; int *pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; if (smth) {; pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; }; // pi is Compatible; }; ```. It can be refactored to use `unique_ptr` like this:. ```c++; void UniqueOwnership2() {; auto pi = make_unique<int>();; Borrow(pi);; if (smth) {; pi = make_unique<int>();; Borrow(pi);; }; }; ```. In the following example, the raw pointer is used to access the heap object; after the ownership has been transferred. ```c++; void UniqueOwnership3() {; int *pi = new int; // pi is Defined",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:22457,perform,perform,22457,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['perform'],['perform']
Performance,"tice. * When `x` is assigned a concrete value, its possible set of values contains; just that specific value. * When `x` is assigned some unknown value, it can have any value. We represent; this fact as `⊤`. * When two control flow paths join, we compute the set union of incoming; values (limiting the number of elements to 3, representing larger sets as; `⊤`). The sets of possible values are influenced by:. * Statements, for example, assignments. * Joins in control flow, for example, ones that appear at the end of ""if""; statements. **Effects of statements** are modeled by what is formally known as a transfer; function. A transfer function takes two arguments: the statement, and the state; of `x` at the previous program point. It produces the state of `x` at the next; program point. For example, the transfer function for assignment ignores the; state at the previous program point:. ```c++; // GIVEN: x is {42; 44}; x = 0;; // CONCLUSION: x is {0}; ```. The transfer function for `+` performs arithmetic on every set member:. ```c++; // GIVEN: x is {42, 44}; x = x + 100;; // CONCLUSION: x is {142, 144}; ```. **Effects of control flow** are modeled by joining the knowledge from all; possible previous program points. ```c++; if (...) {; ...; // GIVEN: x is {42}; } else {; ...; // GIVEN: x is {44}; }; // CONCLUSION: x is {42; 44}; ```. ```c++; // GIVEN: x is {42}; while (...) {; ...; // GIVEN: x is {44}; }; // CONCLUSION: {42; 44}; ```. The predicate that we marked ""given"" is usually called a precondition, and the; conclusion is called a postcondition. In terms of the CFG, we join the information from all predecessor basic blocks. ![Modeling the effects of a CFG basic block](DataFlowAnalysisIntroImages/CFGJoinRule.svg). Putting it all together, to model the effects of a basic block we compute:. ```; out = transfer(basic_block, join(in_1, in_2, ..., in_n)); ```. (Note that there are other ways to write this equation that produce higher; precision analysis results. The trick ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:8890,perform,performs,8890,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['perform'],['performs']
Performance,"tient of the two operands.; This instruction is assumed to execute in the default :ref:`floating-point; environment <floatenv>`.; This instruction can also take any number of :ref:`fast-math; flags <fastmath>`, which are optimization hints to enable otherwise; unsafe floating-point optimizations:. Example:; """""""""""""""". .. code-block:: text. <result> = fdiv float 4.0, %var ; yields float:result = 4.0 / %var. .. _i_urem:. '``urem``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = urem <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``urem``' instruction returns the remainder from the unsigned; division of its two arguments. Arguments:; """""""""""""""""""". The two arguments to the '``urem``' instruction must be; :ref:`integer <t_integer>` or :ref:`vector <t_vector>` of integer values. Both; arguments must have identical types. Semantics:; """""""""""""""""""". This instruction returns the unsigned integer *remainder* of a division.; This instruction always performs an unsigned division to get the; remainder. Note that unsigned integer remainder and signed integer remainder are; distinct operations; for signed integer remainder, use '``srem``'. Taking the remainder of a division by zero is undefined behavior.; For vectors, if any element of the divisor is zero, the operation has; undefined behavior. Example:; """""""""""""""". .. code-block:: text. <result> = urem i32 4, %var ; yields i32:result = 4 % %var. .. _i_srem:. '``srem``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = srem <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``srem``' instruction returns the remainder from the signed; division of its two operands. This instruction can also take; :ref:`vector <t_vector>` versions of the values in which case the elements; must be integers. Arguments:; """""""""""""""""""". The two arguments to the '``srem``' instruction must be; :ref:`integer <t_integer>` or :ref:`vector <t_vector>` of integer values. Both; arguments must have ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:388338,perform,performs,388338,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"time functions; that have a hot path and a cold path. The hot path is usually a small piece; of code that doesn't use many registers. The cold path might need to call out to; another function and therefore only needs to preserve the caller-saved; registers, which haven't already been saved by the caller. The; `PreserveMost` calling convention is very similar to the `cold` calling; convention in terms of caller/callee-saved registers, but they are used for; different types of function calls. `coldcc` is for function calls that are; rarely executed, whereas `preserve_mostcc` function calls are intended to be; on the hot path and definitely executed a lot. Furthermore `preserve_mostcc`; doesn't prevent the inliner from inlining the function call. This calling convention will be used by a future version of the ObjectiveC; runtime and should therefore still be considered experimental at this time.; Although this convention was created to optimize certain runtime calls to; the ObjectiveC runtime, it is not limited to this runtime and might be used; by other runtimes in the future too. The current implementation only; supports X86-64, but the intention is to support more architectures in the; future.; ""``preserve_allcc``"" - The `PreserveAll` calling convention; This calling convention attempts to make the code in the caller even less; intrusive than the `PreserveMost` calling convention. This calling; convention also behaves identical to the `C` calling convention on how; arguments and return values are passed, but it uses a different set of; caller/callee-saved registers. This removes the burden of saving and; recovering a large register set before and after the call in the caller. If; the arguments are passed in callee-saved registers, then they will be; preserved by the callee across the call. This doesn't apply for values; returned in callee-saved registers. - On X86-64 the callee preserves all general purpose registers, except for; R11. R11 can be used as a scratch re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:18256,optimiz,optimize,18256,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimize']
Performance,"time, ROOT inspects the CPU capabilities, and loads the fastest supported version of this computation library.; This means that RooFit can now use vector extensions such as AVX2 without being recompiled, which enables a speed up of up to 4x for certain computations.; Combined with better data access patterns (~3x speed up, ROOT 6.20), computations with optimised PDFs speed up between 4x and 16x. The fast `BatchMode` now also works in combination with multi processing (`NumCPU`) and with binned data (`RooDataHist`). See [Demo notebook in SWAN](https://github.com/hageboeck/rootNotebooks),; [EPJ Web Conf. 245 (2020) 06007](https://www.epj-conferences.org/articles/epjconf/abs/2020/21/epjconf_chep2020_06007/epjconf_chep2020_06007.html),; [arxiv:2012.02746](https://arxiv.org/abs/2012.02746). #### RooBatchCompute Library. The library that contains the optimised computation functions is called `RooBatchCompute`. The PDFs contained in this library are highly optimized, and there is currently work in progress for further optimization using CUDA and multi-threaded computations. If you use PDFs that are not part of the official RooFit, you are very well invited to add them to RooFit by [submitting a ticket](https://github.com/root-project/root/issues/new) or a [pull request](https://github.com/root-project/root/pulls). #### Benefiting from batch computations by overriding `evaluateSpan()`. For PDFs that are not part of RooFit, it is possible to benefit from batch computations without vector extensions. To do so, consult the [RooBatchCompute readme](https://github.com/root-project/root/tree/v6-24-00-patches/roofit/batchcompute). #### Migrating PDFs that override the deprecated `evaluateBatch()`. In case you have created a custom PDF which overrides `evaluateBatch()`, please follow these steps to update your code to the newest version:. 1. Change the signature of the function both in the source and header file:; ```diff; - RooSpan<double> RooGaussian::evaluateBatch(std::size_t be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:16418,optimiz,optimized,16418,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,3,"['multi-thread', 'optimiz']","['multi-threaded', 'optimization', 'optimized']"
Performance,"times (see :ref:`amdgpu-os`), the runtime installs a trap handler that; supports the ``s_trap`` instruction. For usage see:. - :ref:`amdgpu-trap-handler-for-amdhsa-os-v2-table`; - :ref:`amdgpu-trap-handler-for-amdhsa-os-v3-table`; - :ref:`amdgpu-trap-handler-for-amdhsa-os-v4-onwards-table`. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V2; :name: amdgpu-trap-handler-for-amdhsa-os-v2-table. =================== =============== =============== =======================================; Usage Code Sequence Trap Handler Description; Inputs; =================== =============== =============== =======================================; reserved ``s_trap 0x00`` Reserved by hardware.; ``debugtrap(arg)`` ``s_trap 0x01`` ``SGPR0-1``: Reserved for Finalizer HSA ``debugtrap``; ``queue_ptr`` intrinsic (not implemented).; ``VGPR0``:; ``arg``; ``llvm.trap`` ``s_trap 0x02`` ``SGPR0-1``: Causes wave to be halted with the PC at; ``queue_ptr`` the trap instruction. The associated; queue is signalled to put it into the; error state. When the queue is put in; the error state, the waves executing; dispatches on the queue will be; terminated.; ``llvm.debugtrap`` ``s_trap 0x03`` *none* - If debugger not enabled then behaves; as a no-operation. The trap handler; is entered and immediately returns to; continue execution of the wavefront.; - If the debugger is enabled, causes; the debug trap to be reported by the; debugger and the wavefront is put in; the halt state with the PC at the; instruction. The debugger must; increment the PC and resume the wave.; reserved ``s_trap 0x04`` Reserved.; reserved ``s_trap 0x05`` Reserved.; reserved ``s_trap 0x06`` Reserved.; reserved ``s_trap 0x07`` Reserved.; reserved ``s_trap 0x08`` Reserved.; reserved ``s_trap 0xfe`` Reserved.; reserved ``s_trap 0xff`` Reserved.; =================== =============== =============== =======================================. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V3; :name: amdgpu-trap-handler-for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:381326,queue,queue,381326,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance,"times and memory usage; during linking significantly. With a build machine with sufficient; parallelism, link times tend to dominate critical path of the build, and are; thus worth optimizing. Use CCache and NOT incremental builds; Using ccache materially improves average build times. Incremental builds; can be slightly faster, but introduce the risk of build corruption due to; e.g. state changes, etc... At this point, the recommendation is not to; use incremental builds and instead use ccache as the latter captures the; majority of the benefit with less risk of false positives. One of the non-obvious benefits of using ccache is that it makes the; builder less sensitive to which projects are being monitored vs built.; If a change triggers a build request, but doesn't change the build output; (e.g. doc changes, python utility changes, etc..), the build will entirely; hit in cache and the build request will complete in just the testing time. With multiple workers, it is tempting to try to configure a shared cache; between the workers. Experience to date indicates this is difficult to; well, and that having local per-worker caches gets most of the benefit; anyways. We don't currently recommend shared caches. CCache does depend on the builder hardware having sufficient IO to access; the cache with reasonable access times - i.e. a fast disk, or enough memory; for a RAM cache, etc.. For builders without, incremental may be your best; option, but is likely to require higher ongoing involvement from the; sponsor. Enable batch builds; As a last resort, you can configure your builder to batch build requests.; This makes the build failure notifications markedly less actionable, and; should only be done once all other reasonable measures have been taken. Leave it on the staging buildmaster; While most of this section has been biased towards builders intended for; the main buildmaster, it is worth highlighting that builders can run; indefinitely on the staging buildmaster. Such a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:11874,cache,cache,11874,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['cache'],['cache']
Performance,"timizes; it with BOLT, use the following CMake configuration:. .. code-block:: console. $ cmake <path to source>/llvm -C <path to source>/clang/cmake/caches/BOLT.cmake. Then, build the BOLT-optimized binary by running the following ninja command:. .. code-block:: console. $ ninja clang-bolt. If you're seeing errors in the build process, try building with a recent; version of Clang/LLVM by setting the CMAKE_C_COMPILER and; CMAKE_CXX_COMPILER flags to the appropriate values. It is also possible to use BOLT on top of PGO and (Thin)LTO for an even more; significant runtime speedup. To configure a three stage PGO build with ThinLTO; that optimizes the resulting binary with BOLT, use the following CMake; configuration command:. .. code-block:: console. $ cmake -G Ninja <path to source>/llvm \; -C <path to source>/clang/cmake/caches/BOLT-PGO.cmake \; -DBOOTSTRAP_LLVM_ENABLE_LLD=ON \; -DBOOTSTRAP_BOOTSTRAP_LLVM_ENABLE_LLD=ON \; -DPGO_INSTRUMENT_LTO=Thin. Then, to build the final optimized binary, build the stage2-clang-bolt target:. .. code-block:: console. $ ninja stage2-clang-bolt. 3-Stage Non-Determinism; =======================. In the ancient lore of compilers non-determinism is like the multi-headed hydra.; Whenever its head pops up, terror and chaos ensue. Historically one of the tests to verify that a compiler was deterministic would; be a three stage build. The idea of a three stage build is you take your sources; and build a compiler (stage1), then use that compiler to rebuild the sources; (stage2), then you use that compiler to rebuild the sources a third time; (stage3) with an identical configuration to the stage2 build. At the end of; this, you have a stage2 and stage3 compiler that should be bit-for-bit; identical. You can perform one of these 3-stage builds with LLVM and clang using the; following commands:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/3-stage.cmake <path to source>/llvm; $ ninja stage3. After the build you",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:11266,optimiz,optimized,11266,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,1,['optimiz'],['optimized']
Performance,"tin_isnormal``; * ``__builtin_nan``; * ``__builtin_nans``; * ``__builtin_parity``; * ``__builtin_parityl``; * ``__builtin_parityll``; * ``__builtin_popcount``; * ``__builtin_popcountl``; * ``__builtin_popcountll``; * ``__builtin_rotateleft8``; * ``__builtin_rotateleft16``; * ``__builtin_rotateleft32``; * ``__builtin_rotateleft64``; * ``__builtin_rotateright8``; * ``__builtin_rotateright16``; * ``__builtin_rotateright32``; * ``__builtin_rotateright64``. The following x86-specific intrinsics can be used in constant expressions:. * ``_bit_scan_forward``; * ``_bit_scan_reverse``; * ``__bsfd``; * ``__bsfq``; * ``__bsrd``; * ``__bsrq``; * ``__bswap``; * ``__bswapd``; * ``__bswap64``; * ``__bswapq``; * ``_castf32_u32``; * ``_castf64_u64``; * ``_castu32_f32``; * ``_castu64_f64``; * ``__lzcnt16``; * ``__lzcnt``; * ``__lzcnt64``; * ``_mm_popcnt_u32``; * ``_mm_popcnt_u64``; * ``_popcnt32``; * ``_popcnt64``; * ``__popcntd``; * ``__popcntq``; * ``__popcnt16``; * ``__popcnt``; * ``__popcnt64``; * ``__rolb``; * ``__rolw``; * ``__rold``; * ``__rolq``; * ``__rorb``; * ``__rorw``; * ``__rord``; * ``__rorq``; * ``_rotl``; * ``_rotr``; * ``_rotwl``; * ``_rotwr``; * ``_lrotl``; * ``_lrotr``. Debugging the Compiler; ======================. Clang supports a number of pragma directives that help debugging the compiler itself.; Syntax is the following: `#pragma clang __debug <command> <arguments>`.; Note, all of debugging pragmas are subject to change. `dump`; ------; Accepts either a single identifier or an expression. When a single identifier is passed,; the lookup results for the identifier are printed to `stderr`. When an expression is passed,; the AST for the expression is printed to `stderr`. The expression is an unevaluated operand,; so things like overload resolution and template instantiations are performed,; but the expression has no runtime effects.; Type- and value-dependent expressions are not supported yet. This facility is designed to aid with testing name lookup machinery.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:196465,perform,performed,196465,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['perform'],['performed']
Performance,"ting it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3290,optimiz,optimizer,3290,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,1,['optimiz'],['optimizer']
Performance,"ting-point; semantics and floating-point exception behavior to be specified; for a section of the source code. This pragma can only appear at file or; namespace scope, within a language linkage specification or at the start of a; compound statement (excluding comments). When used within a compound statement,; the pragma is active within the scope of the compound statement. This pragma; is modeled after a Microsoft pragma with the same spelling and syntax. For; pragmas specified at file or namespace scope, or within a language linkage; specification, a stack is supported so that the ``pragma float_control``; settings can be pushed or popped. When ``pragma float_control(precise, on)`` is enabled, the section of code; governed by the pragma uses precise floating point semantics, effectively; ``-ffast-math`` is disabled and ``-ffp-contract=on``; (fused multiply add) is enabled. This pragma enables ``-fmath-errno``. When ``pragma float_control(precise, off)`` is enabled, unsafe-floating point; optimizations are enabled in the section of code governed by the pragma.; Effectively ``-ffast-math`` is enabled and ``-ffp-contract=fast``. This pragma; disables ``-fmath-errno``. When ``pragma float_control(except, on)`` is enabled, the section of code; governed by the pragma behaves as though the command-line option; ``-ffp-exception-behavior=strict`` is enabled,; when ``pragma float_control(except, off)`` is enabled, the section of code; governed by the pragma behaves as though the command-line option; ``-ffp-exception-behavior=ignore`` is enabled. The full syntax this pragma supports is; ``float_control(except|precise, on|off [, push])`` and; ``float_control(push|pop)``.; The ``push`` and ``pop`` forms, including using ``push`` as the optional; third argument, can only occur at file scope. .. code-block:: c++. for(...) {; // This block will be compiled with -fno-fast-math and -ffp-contract=on; #pragma float_control(precise, on); a = b[i] * c[i] + e;; }. Specifying an attribute",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:175918,optimiz,optimizations,175918,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimizations']
Performance,"tion (LoopVectorize/SLP); entirely when the a function has either of the ``aarch64_pstate_sm_enabled``,; ``aarch64_pstate_sm_body`` or ``aarch64_pstate_sm_compatible`` attributes,; in order to avoid the use of vector instructions. Later on we'll aim to relax these restrictions to enable scalable; auto-vectorization with a subset of streaming-compatible instructions, but that; requires changes to the CostModel, Legalization and SelectionDAG lowering. We will also emit diagnostics in Clang to prevent the use of; non-streaming(-compatible) operations, e.g. through ACLE intrinsics, when a; function is decorated with the streaming mode attributes. Other things to consider; ------------------------. * Inlining must be disabled when the call-site needs to toggle PSTATE.SM or; when the callee's function body is executed in a different streaming mode than; its caller. This is needed because function calls are the boundaries for; streaming mode changes. * Tail call optimization must be disabled when the call-site needs to toggle; PSTATE.SM, such that the caller can restore the original value of PSTATE.SM. 3. Handling PSTATE.ZA; =====================. In contrast to PSTATE.SM, enabling PSTATE.ZA does not affect the SVE vector; length and also doesn't clobber FP/AdvSIMD/SVE registers. This means it is safe; to toggle PSTATE.ZA using intrinsics. This also makes it simpler to setup a; lazy-save mechanism for calls to private-ZA functions (i.e. functions that may; either directly or indirectly clobber ZA state). For the purpose of handling functions marked with ``aarch64_pstate_za_new``,; we have introduced a new LLVM IR pass (SMEABIPass) that is run just before; SelectionDAG. Any such functions dealt with by this pass are marked with; ``aarch64_expanded_pstate_za``. Setting up a lazy-save; ----------------------. Committing a lazy-save; ----------------------. Exception handling and ZA; -------------------------. 4. Types; ========. AArch64 Predicate-as-Counter Type; ------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst:16644,optimiz,optimization,16644,interpreter/llvm-project/llvm/docs/AArch64SME.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst,1,['optimiz'],['optimization']
Performance,"tion can then be used to speed-up fitting. It is not enabled by default, but it can be enabled by callig `TF1::SetVectorized(true)` or using the `""VEC""` option in the; constructor of TF1, when ROOT has been built with VecCore and one vectorization library such as Vc. ; - Added new auto-binning algorithm, referred to as `power-2`, which uses power of 2 bin widths to create bins; that are mergeable. The target use-case is support for auto-binning in multi-process or multi-thread execution,; e.g. `TDataFrame`, without the need of a synchronization point.; The new `power-2` algorithm is activated by setting the new `TH1::kAutoBinPTwo` status bit on the histogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats classes have been updated to include the `GlobalObservables` option.; - Remove the `Roo1DMomentMorphFunction` and replace it with `RooMomentMorphFunction` and `RooMomentMorphFunctionND`. ## TMVA Library. - Improvement and fixes in ROCCurve class.; - Add support for event weights in the DNN; - Add in the DNN the option to use a validation data set independent of the training/test set used for training the DNN.; - Add option to suppress correlation outputs; - Improvements in the support for multi-class classification.; - Improvements in the Gradient Boostig Trees; - Deprecate the TMVA DNN Reference Implementation. Support now only CPU and GPU implementations. . ## 2",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:18355,load,loading,18355,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['load'],['loading']
Performance,"tion has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42841,load,load,42841,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['load'],['load']
Performance,"tion in this model is divided into the following stages:. 1. `Instruction Selection`_ --- This phase determines an efficient way to; express the input LLVM code in the target instruction set. This stage; produces the initial code for the program in the target instruction set, then; makes use of virtual registers in SSA form and physical registers that; represent any required register assignments due to target constraints or; calling conventions. This step turns the LLVM code into a DAG of target; instructions. 2. `Scheduling and Formation`_ --- This phase takes the DAG of target; instructions produced by the instruction selection phase, determines an; ordering of the instructions, then emits the instructions as :raw-html:`<tt>`; `MachineInstr`_\s :raw-html:`</tt>` with that ordering. Note that we; describe this in the `instruction selection section`_ because it operates on; a `SelectionDAG`_. 3. `SSA-based Machine Code Optimizations`_ --- This optional stage consists of a; series of machine-code optimizations that operate on the SSA-form produced by; the instruction selector. Optimizations like modulo-scheduling or peephole; optimization work here. 4. `Register Allocation`_ --- The target code is transformed from an infinite; virtual register file in SSA form to the concrete register file used by the; target. This phase introduces spill code and eliminates all virtual register; references from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:6121,optimiz,optimizations,6121,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['optimiz'],['optimizations']
Performance,"tion of each member function; and most data members. An update to the users manual is foreseen shortly after the 5.20; release. RooWorkspace. A new feature has been added that allows to persist source code of RooFit classes that; are not in ROOT distribution inside a RooWorkspace to facilitate sharing; of custom code with others. To import code of custom classes call. RooWorkspace::importClassCode(). after importing the objects themselves into the workspace. For all classes; that are compiled with ACliC RooWorkspace can automatically find the source; code using the ROOT TClass interface. For custom classes that are compiled; externally and loaded into ROOT as shared library it might be necessary to; provide the location of the source files manually using the static RooWorkspace; member functions addClassDeclImportDir() and addClassImplImportDir().; ; When a TFile with a RooWorkspace containing source code is opened in a ROOT; session that does not have the class code already loaded for the classes; contained in the workspace, the code in the workspace is written to file,; compiled and loaded into the ROOT session on the fly. The code repository of RooWorkspace is designed to handle classes that; have either their own implementation and header file, or are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct ranges that vary as function of another variable. For example. RooRealVar x(""x"",""x"",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:2555,load,loaded,2555,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,2,['load'],['loaded']
Performance,"tion of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:45384,perform,performance,45384,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['perform'],['performance']
Performance,"tion that we can only; have one ""top level"" command at a time to reduce the number of; changes necessary. Here's the sample program we'll be compiling:. .. code-block:: python. def fib(x); if x < 3 then; 1; else; fib(x-1)+fib(x-2);. fib(10). Why is this a hard problem?; ===========================. Debug information is a hard problem for a few different reasons - mostly; centered around optimized code. First, optimization makes keeping source; locations more difficult. In LLVM IR we keep the original source location; for each IR level instruction on the instruction. Optimization passes; should keep the source locations for newly created instructions, but merged; instructions only get to keep a single location - this can cause jumping; around when stepping through optimized programs. Secondly, optimization; can move variables in ways that are either optimized out, shared in memory; with other variables, or difficult to track. For the purposes of this; tutorial we're going to avoid optimization (as you'll see with one of the; next sets of patches). Ahead-of-Time Compilation Mode; ==============================. To highlight only the aspects of adding debug information to a source; language without needing to worry about the complexities of JIT debugging; we're going to make a few changes to Kaleidoscope to support compiling; the IR emitted by the front end into a simple standalone program that; you can execute, debug, and see results. First we make our anonymous function that contains our top level; statement be our ""main"":. .. code-block:: udiff. - auto Proto = std::make_unique<PrototypeAST>("""", std::vector<std::string>());; + auto Proto = std::make_unique<PrototypeAST>(""main"", std::vector<std::string>());. just with the simple change of giving it a name. Then we're going to remove the command line code wherever it exists:. .. code-block:: udiff. @@ -1129,7 +1129,6 @@ static void HandleTopLevelExpression() {; /// top ::= definition | external | expression | ';'; stat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst:2357,optimiz,optimization,2357,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,1,['optimiz'],['optimization']
Performance,"tion, and; motion of ``Instructions``. The update API is being made on an as-needed basis.; If you'd like examples, ``GVNHoist`` and ``LICM`` are users of ``MemorySSA``\ s; update API.; Note that adding new ``MemoryDef``\ s (by calling ``insertDef``) can be a; time-consuming update, if the new access triggers many ``MemoryPhi`` insertions and; renaming (optimization invalidation) of many ``MemoryAccesses``\ es. Phi placement; ^^^^^^^^^^^^^. ``MemorySSA`` only places ``MemoryPhi``\ s where they're actually; needed. That is, it is a pruned SSA form, like LLVM's SSA form. For; example, consider:. .. code-block:: llvm. define void @foo() {; entry:; %p1 = alloca i8; %p2 = alloca i8; %p3 = alloca i8; ; 1 = MemoryDef(liveOnEntry); store i8 0, ptr %p3; br label %while.cond. while.cond:; ; 3 = MemoryPhi({%0,1},{if.end,2}); br i1 undef, label %if.then, label %if.else. if.then:; br label %if.end. if.else:; br label %if.end. if.end:; ; MemoryUse(1); %1 = load i8, ptr %p1; ; 2 = MemoryDef(3); store i8 2, ptr %p2; ; MemoryUse(1); %2 = load i8, ptr %p3; br label %while.cond; }. Because we removed the stores from ``if.then`` and ``if.else``, a ``MemoryPhi``; for ``if.end`` would be pointless, so we don't place one. So, if you need to; place a ``MemoryDef`` in ``if.then`` or ``if.else``, you'll need to also create; a ``MemoryPhi`` for ``if.end``. If it turns out that this is a large burden, we can just place ``MemoryPhi``\ s; everywhere. Because we have Walkers that are capable of optimizing above said; phis, doing so shouldn't prohibit optimizations. Non-Goals; ---------. ``MemorySSA`` is meant to reason about the relation between memory; operations, and enable quicker querying.; It isn't meant to be the single source of truth for all potential memory-related; optimizations. Specifically, care must be taken when trying to use ``MemorySSA``; to reason about atomic or volatile operations, as in:. .. code-block:: llvm. define i8 @foo(ptr %a) {; entry:; br i1 undef, label %if.then, labe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:15214,load,load,15214,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,2,['load'],['load']
Performance,"tion. MemorySanitizer may still instrument such functions to; avoid false positives. This attribute may not be supported by other compilers,; so we suggest to use it together with ``__has_feature(memory_sanitizer)``. ``__attribute__((disable_sanitizer_instrumentation))``; --------------------------------------------------------. The ``disable_sanitizer_instrumentation`` attribute can be applied to functions; to prevent all kinds of instrumentation. As a result, it may introduce false; positives and therefore should be used with care, and only if absolutely; required; for example for certain code that cannot tolerate any instrumentation; and resulting side-effects. This attribute overrides ``no_sanitize(""memory"")``. Ignorelist; ----------. MemorySanitizer supports ``src`` and ``fun`` entity types in; :doc:`SanitizerSpecialCaseList`, that can be used to relax MemorySanitizer; checks for certain source files and functions. All ""Use of uninitialized value""; warnings will be suppressed and all values loaded from memory will be; considered fully initialized. Report symbolization; ====================. MemorySanitizer uses an external symbolizer to print files and line numbers in; reports. Make sure that ``llvm-symbolizer`` binary is in ``PATH``,; or set environment variable ``MSAN_SYMBOLIZER_PATH`` to point to it. .. _msan-origins:. Origin Tracking; ===============. MemorySanitizer can track origins of uninitialized values, similar to; Valgrind's --track-origins option. This feature is enabled by; ``-fsanitize-memory-track-origins=2`` (or simply; ``-fsanitize-memory-track-origins``) Clang option. With the code from; the example above,. .. code-block:: console. % cat umr2.cc; #include <stdio.h>. int main(int argc, char** argv) {; int* a = new int[10];; a[5] = 0;; volatile int b = a[argc];; if (b); printf(""xx\n"");; return 0;; }. % clang -fsanitize=memory -fsanitize-memory-track-origins=2 -fno-omit-frame-pointer -g -O2 umr2.cc; % ./a.out; WARNING: MemorySanitizer: use-of-unin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MemorySanitizer.rst:3447,load,loaded,3447,interpreter/llvm-project/clang/docs/MemorySanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MemorySanitizer.rst,1,['load'],['loaded']
Performance,"tion:: -all-views. Enable all the view. .. option:: -instruction-tables. Prints resource pressure information based on the static information; available from the processor model. This differs from the resource pressure; view because it doesn't require that the code is simulated. It instead prints; the theoretical uniform distribution of resource pressure for every; instruction in sequence. .. option:: -bottleneck-analysis. Print information about bottlenecks that affect the throughput. This analysis; can be expensive, and it is disabled by default. Bottlenecks are highlighted; in the summary view. Bottleneck analysis is currently not supported for; processors with an in-order backend. .. option:: -json. Print the requested views in valid JSON format. The instructions and the; processor resources are printed as members of special top level JSON objects.; The individual views refer to them by index. However, not all views are; currently supported. For example, the report from the bottleneck analysis is; not printed out in JSON. All the default views are currently supported. .. option:: -disable-cb. Force usage of the generic CustomBehaviour and InstrPostProcess classes rather; than using the target specific implementation. The generic classes never; detect any custom hazards or make any post processing modifications to; instructions. .. option:: -disable-im. Force usage of the generic InstrumentManager rather than using the target; specific implementation. The generic class creates Instruments that provide; no extra information, and InstrumentManager never overrides the default; schedule class for a given instruction. EXIT STATUS; -----------. :program:`llvm-mca` returns 0 on success. Otherwise, an error message is printed; to standard error, and the tool returns 1. USING MARKERS TO ANALYZE SPECIFIC CODE BLOCKS; ---------------------------------------------; :program:`llvm-mca` allows for the optional usage of special code comments to; mark regions of the assembly cod",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:7281,bottleneck,bottleneck,7281,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['bottleneck'],['bottleneck']
Performance,"tion; of the pull values for each parameter has been modified accordingly. Alternatively, it is possible to specify constraints to both RooAbsPdf::fitTo() and the RooMCStudy constructor; using the ExternalConstraint() named argument to supply constraint p.d.f.s that are not part of the 'master'; p.d.f but rather an ad-hoc supplied external constraint. The argument supplied to ExternalConstraint() should; be (a set of) constraint p.d.f(s), rather than (a set of) parameters for which internal constraint p.d.f.s should; be picked up. New operator class RooLinearMorph. A new numeric operator class RooLinearMorph has been added that provides a continuous; transformation between two p.d.f.s shapes in terms of a linear parameter alpha. The algorithm ; for histograms is described in the paper by Alex Read in NUM A 425 (1999) 357-369 ; 'Linear interpolation of histograms'. The implementation in RooLinearMorph is for; continuous functions. . // Observable and sampling binning to be used by RooLinearMorph (""cache""); RooRealVar x(""x"",""x"",-20,20) ;; x.setBins(1000,""cache"") ;. // End point shapes : a gaussian on one end, a polynomial on the other; RooGaussian f1(""f1"",""f1"",x,RooConst(-10),RooConst(2)) ;; RooPolynomial f2(""f2"",""f2"",x,RooArgSet(RooConst(-0.03),RooConst(-0.001))) ;. // Interpolation parameter: rlm=f1 at alpha=0, rlm=f2 at alpha=1; RooRealVar alpha(""alpha"",""alpha"",0,1.0) ;; RooLinearMorph rlm(""rlm"",""rlm"",g1,g2,x,alpha) ;. // Plot halfway shape; alpha=0.5; RooPlot* frame = x.frame() ;; rlm.plotOn(frame) ;. In short the algorithm works as follows: for both f1(x) and f2(x), the cumulative distribution; functions F1(x) and F2(x) are calculated. One finds takes a value 'y' of both c.d.fs and ; determines the corresponding x values x1,x2 at which F1(x1)=F2(x2)=y. The value of the interpolated ; p.d.f fbar(x) is then calculated as fbar(alpha*x1+(1-alpha)*x2) = f1(x1)*f2(x2) / ( alpha*f2(x2) + ; (1-alpha)*f1(x1) ). Given that it is not easily possible to calculate the value o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:10180,cache,cache,10180,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,1,['cache'],['cache']
Performance,"tional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained; (the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory).; - Added ```TBranchProxy::GetEntries``` to support leaflist variable size array and added ```TBranchProxy::GetArrayLength```.; - In ```TBranch::Streamer``` insured that we never steam already basket already written to disk. ### TDataFrame. #### New features; - Add `Alias`, a facility to specify an alternative name for a given column: `auto histo = mytdf.Alias(""myAlias"", ""myColumn"").Histo1D(""myAlias"");`. Especially useful for pyROOT users to deal with column names that are not valid C++ identifiers (e.g. `Filter(""1branch > 0"") --> Alias(""1branch"", ""branch1"").Filter(""branch1 > 0"")`.; - Add `Cache`, a facility to cache `TDataFrame`s in memory. All or some columns can be cached. Two versions of the method are proposed: one which allows to explicitly list the types of the columns and another one allowing to let the system infer them (the same mechanism of the `Snapshot` method). Only columns containing instances of classes which have a copy constructor can be cached.; - Add `DefineSlot`, a `Define` transformation that is aware of the multi-threading slot where the workload is executed; - Add `DefineSlotEntry`, a `Define` transformation that is aware of the multi-threading slot and of the current entry number; - Add `GetColumnsNames`: users can now get the names of the available columns coming from trees, data sources or `Define`d columns; - Add `OnPartialResult` and `OnPartialResultSlot`: users can now register one or more functions to be executed on partial results of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:10978,cache,cache,10978,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['cache'],['cache']
Performance,"tions (:ref:`fneg <i_fneg>`, :ref:`fadd <i_fadd>`,; :ref:`fsub <i_fsub>`, :ref:`fmul <i_fmul>`, :ref:`fdiv <i_fdiv>`,; :ref:`frem <i_frem>`, :ref:`fcmp <i_fcmp>`), :ref:`phi <i_phi>`,; :ref:`select <i_select>` and :ref:`call <i_call>`; may use the following flags to enable otherwise unsafe; floating-point transformations. ``nnan``; No NaNs - Allow optimizations to assume the arguments and result are not; NaN. If an argument is a nan, or the result would be a nan, it produces; a :ref:`poison value <poisonvalues>` instead. ``ninf``; No Infs - Allow optimizations to assume the arguments and result are not; +/-Inf. If an argument is +/-Inf, or the result would be +/-Inf, it; produces a :ref:`poison value <poisonvalues>` instead. ``nsz``; No Signed Zeros - Allow optimizations to treat the sign of a zero; argument or zero result as insignificant. This does not imply that -0.0; is poison and/or guaranteed to not exist in the operation. ``arcp``; Allow Reciprocal - Allow optimizations to use the reciprocal of an; argument rather than perform division. ``contract``; Allow floating-point contraction (e.g. fusing a multiply followed by an; addition into a fused multiply-and-add). This does not enable reassociating; to form arbitrary contractions. For example, ``(a*b) + (c*d) + e`` can not; be transformed into ``(a*b) + ((c*d) + e)`` to create two fma operations. .. _fastmath_afn:. ``afn``; Approximate functions - Allow substitution of approximate calculations for; functions (sin, log, sqrt, etc). See floating-point intrinsic definitions; for places where this can apply to LLVM's intrinsic math functions. ``reassoc``; Allow reassociation transformations for floating-point instructions.; This may dramatically change results in floating-point. ``fast``; This flag implies all of the others. .. _uselistorder:. Use-list Order Directives; -------------------------. Use-list directives encode the in-memory order of each use-list, allowing the; order to be recreated. ``<order-indexes>``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:162476,optimiz,optimizations,162476,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['optimiz', 'perform']","['optimizations', 'perform']"
Performance,"tions have been performed. Additionally, on targets; where it is profitable, the loop could be transformed to count down to zero; (the ""do loop"" optimization). ``inline``: Function Integration/Inlining; -----------------------------------------. Bottom-up inlining of functions into callees. .. _passes-instcombine:. ``instcombine``: Combine redundant instructions; -----------------------------------------------. Combine instructions to form fewer, simple instructions. This pass does not; modify the CFG. This pass is where algebraic simplification happens. This pass combines things like:. .. code-block:: llvm. %Y = add i32 %X, 1; %Z = add i32 %Y, 1. into:. .. code-block:: llvm. %Z = add i32 %X, 2. This is a simple worklist driven algorithm. This pass guarantees that the following canonicalizations are performed on the; program:. #. If a binary operator has a constant operand, it is moved to the right-hand; side.; #. Bitwise operators with constant operands are always grouped so that shifts; are performed first, then ``or``\ s, then ``and``\ s, then ``xor``\ s.; #. Compare instructions are converted from ``<``, ``>``, ``≤``, or ``≥`` to; ``=`` or ``≠`` if possible.; #. All ``cmp`` instructions on boolean values are replaced with logical; operations.; #. ``add X, X`` is represented as ``mul X, 2`` ⇒ ``shl X, 1``; #. Multiplies with a constant power-of-two argument are transformed into; shifts.; #. … etc. This pass can also simplify calls to specific well-known function calls (e.g.; runtime library functions). For example, a call ``exit(3)`` that occurs within; the ``main()`` function can be transformed into simply ``return 3``. Whether or; not library calls are simplified is controlled by the; :ref:`-function-attrs <passes-function-attrs>` pass and LLVM's knowledge of; library calls on different targets. .. _passes-aggressive-instcombine:. ``aggressive-instcombine``: Combine expression patterns; --------------------------------------------------------. Combine expression",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:19983,perform,performed,19983,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['perform'],['performed']
Performance,"tions. 5. ``DW_OP_xderef`` *Deprecated*. ``DW_OP_xderef`` pops two stack entries. The first must be an integral type; value that represents an address A. The second must be an integral type; value that represents a target architecture specific address space; identifier AS. The operation is equivalent to performing ``DW_OP_swap;; DW_OP_LLVM_form_aspace_address; DW_OP_deref``. The value V retrieved is left; on the stack with the generic type. *This operation is deprecated as the* ``DW_OP_LLVM_form_aspace_address``; *operation can be used and provides greater expressiveness.*. 6. ``DW_OP_xderef_size`` *Deprecated*. ``DW_OP_xderef_size`` has a single 1-byte unsigned integral constant that; represents a byte result size S. It pops two stack entries. The first must be an integral type value that; represents an address A. The second must be an integral type value that; represents a target architecture specific address space identifier AS. The operation is equivalent to performing ``DW_OP_swap;; DW_OP_LLVM_form_aspace_address; DW_OP_deref_size S``. The zero-extended; value V retrieved is left on the stack with the generic type. *This operation is deprecated as the* ``DW_OP_LLVM_form_aspace_address``; *operation can be used and provides greater expressiveness.*. 7. ``DW_OP_xderef_type`` *Deprecated*. ``DW_OP_xderef_type`` has two operands. The first is a 1-byte unsigned; integral constant S. The second operand is an unsigned LEB128 integer DR; that represents the byte offset of a debugging information entry D relative; to the beginning of the current compilation unit, that provides the type T; of the result value. It pops two stack entries. The first must be an integral type value that; represents an address A. The second must be an integral type value that; represents a target architecture specific address space identifier AS. The operation is equivalent to performing ``DW_OP_swap;; DW_OP_LLVM_form_aspace_address; DW_OP_deref_type S DR``. The value V; retrieved is left on th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:94148,perform,performing,94148,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['perform'],['performing']
Performance,"tions. ``-fmodule-name=module-id``; Consider a source file as a part of the given module. ``-fmodule-map-file=<file>``; Load the given module map file if a header from its directory or one of its subdirectories is loaded. ``-fmodules-search-all``; If a symbol is not found, search modules referenced in the current module maps but not imported for symbols, so the error message can reference the module by name. Note that if the global module index has not been built before, this might take some time as it needs to build all the modules. Note that this option doesn't apply in module builds, to avoid the recursion. ``-fno-implicit-modules``; All modules used by the build must be specified with ``-fmodule-file``. ``-fmodule-file=[<name>=]<file>``; Specify the mapping of module names to precompiled module files. If the; name is omitted, then the module file is loaded whether actually required; or not. If the name is specified, then the mapping is treated as another; prebuilt module search mechanism (in addition to ``-fprebuilt-module-path``); and the module is only loaded if required. Note that in this case the; specified file also overrides this module's paths that might be embedded; in other precompiled module files. ``-fprebuilt-module-path=<directory>``; Specify the path to the prebuilt modules. If specified, we will look for modules in this directory for a given top-level module name. We don't need a module map for loading prebuilt modules in this directory and the compiler will not try to rebuild these modules. This can be specified multiple times. ``-fprebuilt-implicit-modules``; Enable prebuilt implicit modules. If a prebuilt module is not found in the; prebuilt modules paths (specified via ``-fprebuilt-module-path``), we will; look for a matching implicit module in the prebuilt modules paths. -cc1 Options; ~~~~~~~~~~~~. ``-fmodules-strict-context-hash``; Enables hashing of all compiler options that could impact the semantics of a; module in an implicit build. This ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:17466,load,loaded,17466,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['load'],['loaded']
Performance,"tiple ; function calls could be made from the try block. In this case, trivial ; optimization could merge the two basic blocks. TryHandler is the code ; that actually determines the type of exception, based on the Exception object; itself. For this discussion, assume that the exception object contains *at; least*:. 1. A pointer to the RTTI info for the contained object; 2. A pointer to the dtor for the contained object; 3. The contained object itself. Note that it is necessary to maintain #1 & #2 in the exception object itself; because objects without virtual function tables may be thrown (as in this ; example). Assuming this, TryHandler would look something like this:. TryHandler: ; Exception *E = getThreadLocalException();; switch (E->RTTIType) {; case IntRTTIInfo:; ...int Stuff... // The action to perform from the catch block; break;; case DoubleRTTIInfo:; ...double Stuff... // The action to perform from the catch block; goto TryCleanup // This catch block rethrows the exception; break; // Redundant, eliminated by the optimizer; default:; goto TryCleanup // Exception not caught, rethrow; }. // Exception was consumed; if (E->dtor); E->dtor(E->object) // Invoke the dtor on the object if it exists; goto EndTry // Continue mainline code... And that is all there is to it. The throw(E) function would then be implemented like this (which may be ; inlined into the caller through standard optimization):. function throw(Exception *E) {; // Get the start of the stack trace...; %frame %f = call getStackCurrentFrame(). // Get the label information that corresponds to it; label * %L = call getFrameLabel(%f); while (%L == 0 && !isFirstFrame(%f)) {; // Loop until a cleanup handler is found; %f = call getNextFrame(%f); %L = call getFrameLabel(%f); }. if (%L != 0) {; call setThreadLocalException(E) // Allow handlers access to this...; call doNonLocalBranch(%L); }; // No handler found!; call BlowUp() // Ends up calling the terminate() method in use; }. That's a brief rundown of how",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-05-18-ExceptionHandling.txt:6009,perform,perform,6009,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-05-18-ExceptionHandling.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-05-18-ExceptionHandling.txt,2,"['optimiz', 'perform']","['optimizer', 'perform']"
Performance,"tity. Name lookup; When writing a chained precompiled header, Clang attempts to write only; information that has changed from the precompiled header on which it is; based. This changes the lookup algorithm for the various tables, such as the; :ref:`identifier table <pchinternals-ident-table>`: the search starts at the; most-recent precompiled header. If no entry is found, lookup then proceeds; to the identifier table in the precompiled header it depends on, and so one.; Once a lookup succeeds, that result is considered definitive, overriding any; results from earlier precompiled headers. Update records; There are various ways in which a later precompiled header can modify the; entities described in an earlier precompiled header. For example, later; precompiled headers can add entries into the various name-lookup tables for; the translation unit or namespaces, or add new categories to an Objective-C; class. Each of these updates is captured in an ""update record"" that is; stored in the chained precompiled header file and will be loaded along with; the original entity. .. _pchinternals-modules:. Modules; -------. Modules generalize the chained precompiled header model yet further, from a; linear chain of precompiled headers to an arbitrary directed acyclic graph; (DAG) of AST files. All of the same techniques used to make chained; precompiled headers work --- ID number, name lookup, update records --- are; shared with modules. However, the DAG nature of modules introduce a number of; additional complications to the model:. Numbering of IDs; The simple, linear numbering scheme used in chained precompiled headers falls; apart with the module DAG, because different modules may end up with; different numbering schemes for entities they imported from common shared; modules. To account for this, each module file provides information about; which modules it depends on and which ID numbers it assigned to the entities; in those modules, as well as which ID numbers it took for it",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:27029,load,loaded,27029,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['load'],['loaded']
Performance,"tive in a file. The ""CHECK-EMPTY:"" directive; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~. If you need to check that the next line has nothing on it, not even whitespace,; you can use the ""``CHECK-EMPTY:``"" directive. .. code-block:: llvm. declare void @foo(). declare void @bar(); ; CHECK: foo; ; CHECK-EMPTY:; ; CHECK-NEXT: bar. Just like ""``CHECK-NEXT:``"" the directive will fail if there is more than one; newline before it finds the next blank line, and it cannot be the first; directive in a file. The ""CHECK-NOT:"" directive; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ""``CHECK-NOT:``"" directive is used to verify that a string doesn't occur; between two matches (or before the first match, or after the last match). For; example, to verify that a load is removed by a transformation, a test like this; can be used:. .. code-block:: llvm. define i8 @coerce_offset0(i32 %V, i32* %P) {; store i32 %V, i32* %P. %P2 = bitcast i32* %P to i8*; %P3 = getelementptr i8* %P2, i32 2. %A = load i8* %P3; ret i8 %A; ; CHECK: @coerce_offset0; ; CHECK-NOT: load; ; CHECK: ret i8; }. The ""CHECK-COUNT:"" directive; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~. If you need to match multiple lines with the same pattern over and over again; you can repeat a plain ``CHECK:`` as many times as needed. If that looks too; boring you can instead use a counted check ""``CHECK-COUNT-<num>:``"", where; ``<num>`` is a positive decimal number. It will match the pattern exactly; ``<num>`` times, no more and no less. If you specified a custom check prefix,; just use ""``<PREFIX>-COUNT-<num>:``"" for the same effect.; Here is a simple example:. .. code-block:: text. Loop at depth 1; Loop at depth 1; Loop at depth 1; Loop at depth 1; Loop at depth 2; Loop at depth 3. ; CHECK-COUNT-6: Loop at depth {{[0-9]+}}; ; CHECK-NOT: Loop at depth {{[0-9]+}}. The ""CHECK-DAG:"" directive; ~~~~~~~~~~~~~~~~~~~~~~~~~~. If it's necessary to match strings that don't occur in a strictly sequential; order, ""``CHECK-DAG:``"" could be used to verify them between two matches (or; b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:17037,load,load,17037,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,2,['load'],['load']
Performance,"tl;libcxx;compiler-rt;openmp;llvm-libgcc""); set(LLVM_ENABLE_RUNTIMES """" CACHE STRING; ""Semicolon-separated list of runtimes to build, or \""all\"" (${LLVM_DEFAULT_RUNTIMES}). Supported runtimes are ${LLVM_SUPPORTED_RUNTIMES}.""); if(LLVM_ENABLE_RUNTIMES STREQUAL ""all""); set(LLVM_ENABLE_RUNTIMES ${LLVM_DEFAULT_RUNTIMES}); endif(); foreach(proj IN LISTS LLVM_ENABLE_RUNTIMES); if (NOT ""${proj}"" IN_LIST LLVM_SUPPORTED_RUNTIMES); message(FATAL_ERROR ""Runtime \""${proj}\"" is not a supported runtime. Supported runtimes are: ${LLVM_SUPPORTED_RUNTIMES}""); endif(); endforeach(). if (""libc"" IN_LIST LLVM_ENABLE_RUNTIMES); # To build the libc runtime, we need to be able to build few libc build; # tools from the ""libc"" project. So, we add it to the list of enabled; # projects.; if (NOT ""libc"" IN_LIST LLVM_ENABLE_PROJECTS); message(STATUS ""Enabling libc project to build libc build tools""); list(APPEND LLVM_ENABLE_PROJECTS ""libc""); endif(); endif(). # LLVM_ENABLE_PROJECTS_USED is `ON` if the user has ever used the; # `LLVM_ENABLE_PROJECTS` CMake cache variable. This exists for; # several reasons:; #; # * As an indicator that the `LLVM_ENABLE_PROJECTS` list is now the single; # source of truth for which projects to build. This means we will ignore user; # supplied `LLVM_TOOL_<project>_BUILD` CMake cache variables and overwrite; # them.; #; # * The case where the user previously had `LLVM_ENABLE_PROJECTS` set to a; # non-empty list but now the user wishes to disable building all other projects; # by setting `LLVM_ENABLE_PROJECTS` to an empty string. In that case we still; # need to set the `LLVM_TOOL_${upper_proj}_BUILD` variables so that we disable; # building all the projects that were previously enabled.; set(LLVM_ENABLE_PROJECTS_USED OFF CACHE BOOL """"); mark_as_advanced(LLVM_ENABLE_PROJECTS_USED). if (LLVM_ENABLE_PROJECTS_USED OR NOT LLVM_ENABLE_PROJECTS STREQUAL """"); set(LLVM_ENABLE_PROJECTS_USED ON CACHE BOOL """" FORCE); foreach(proj ${LLVM_KNOWN_PROJECTS} ${LLVM_EXTERNAL_PROJECTS})",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:7939,cache,cache,7939,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['cache'],['cache']
Performance,"tmia. I think option 2 is better but the current register; allocator cannot allocate a chunk of registers at a time. A feasible temporary solution is to use specific physical registers at the; lowering time for small (<= 4 words?) transfer size. * ARM CSRet calling convention requires the hidden argument to be returned by; the callee. //===---------------------------------------------------------------------===//. We can definitely do a better job on BB placements to eliminate some branches.; It's very common to see llvm generated assembly code that looks like this:. LBB3:; ...; LBB4:; ...; beq LBB3; b LBB2. If BB4 is the only predecessor of BB3, then we can emit BB3 after BB4. We can; then eliminate beq and turn the unconditional branch to LBB2 to a bne. See McCat/18-imp/ComputeBoundingBoxes for an example. //===---------------------------------------------------------------------===//. Pre-/post- indexed load / stores:. 1) We should not make the pre/post- indexed load/store transform if the base ptr; is guaranteed to be live beyond the load/store. This can happen if the base; ptr is live out of the block we are performing the optimization. e.g. mov r1, r2; ldr r3, [r1], #4; ... vs. ldr r3, [r2]; add r1, r2, #4; ... In most cases, this is just a wasted optimization. However, sometimes it can; negatively impact the performance because two-address code is more restrictive; when it comes to scheduling. Unfortunately, liveout information is currently unavailable during DAG combine; time. 2) Consider spliting a indexed load / store into a pair of add/sub + load/store; to solve #1 (in TwoAddressInstructionPass.cpp). 3) Enhance LSR to generate more opportunities for indexed ops. 4) Once we added support for multiple result patterns, write indexed loads; patterns instead of C++ instruction selection code. 5) Use VLDM / VSTM to emulate indexed FP load / store. //===---------------------------------------------------------------------===//. Implement support for some more tr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:8272,load,load,8272,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['load'],['load']
Performance,"tml#aec50335293c45a507d347c604bf9651f); ### Uniquely identifying RooArgSet and RooDataSet objects. Before v6.28, it was ensured that no `RooArgSet` and `RooDataSet` objects on the heap were located at an address that had already been used for an instance of the same class before.; With v6.28, this is not guaranteed anymore.; Hence, if your code uses pointer comparisons to uniquely identify RooArgSet or RooDataSet instances, please consider using the new `RooArgSet::uniqueId()` or `RooAbsData::uniqueId()`. ### Introducing binned likelihood fit optimization in HistFactory. In a binned likelihood fit, it is possible to skip the PDF normalization when; the unnormalized binned PDF can be interpreted directly in terms of event; yields. This is now done by default for HistFactory models, which; results in great speedups for binned fits with many channels. Some RooFit users; like ATLAS were already using this for a long time. To disable this optimization when using the `hist2workspace` executable, add the `-disable_binned_fit_optimization` command line argument.; Directly in C++, you can also set the `binnedFitOptimization` to `false` in the; HistFactory configuration as follows:; ```C++; RooStats::HistFactory::MakeModelAndMeasurementFast(measurement, {.binnedFitOptimization=false});; ```; If your compiler doesn't support aggregate initialization with designators, you; need to create and edit the configuration struct explicitely:; ```C++; RooStats::HistFactory::HistoToWorkspaceFactoryFast::Configuration hfCfg;; hfCfg.binnedFitOptimization = false;; RooStats::HistFactory::MakeModelAndMeasurementFast(measurement, hfCfg);; ```. ### Disable copy assignment for RooAbsArg and derived types. Copy assignment for RooAbsArgs was implemented in an unexpected and; inconsistent way. While one would expect that the copy assignment is copying; the object, it said in the documentation of `RooAbsArg::operator=` that it will; ""assign all boolean and string properties of the original bject. Tr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:20521,optimiz,optimization,20521,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,1,['optimiz'],['optimization']
Performance,"tml:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_21</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 2.1</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_30</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 3.0</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_35</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 3.5</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>ptx30</td>`; :raw-html:`<td align=""left"">Target PTX 3.0</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>ptx31</td>`; :raw-html:`<td align=""left"">Target PTX 3.1</td>`; :raw-html:`</tr>`; :raw-html:`</table>`. The extended Berkeley Packet Filter (eBPF) backend; --------------------------------------------------. Extended BPF (or eBPF) is similar to the original (""classic"") BPF (cBPF) used; to filter network packets. The; `bpf() system call <http://man7.org/linux/man-pages/man2/bpf.2.html>`_; performs a range of operations related to eBPF. For both cBPF and eBPF; programs, the Linux kernel statically analyzes the programs before loading; them, in order to ensure that they cannot harm the running system. eBPF is; a 64-bit RISC instruction set designed for one to one mapping to 64-bit CPUs.; Opcodes are 8-bit encoded, and 87 instructions are defined. There are 10; registers, grouped by function as outlined below. ::. R0 return value from in-kernel functions; exit value for eBPF program; R1 - R5 function call arguments to in-kernel functions; R6 - R9 callee-saved registers preserved by in-kernel functions; R10 stack frame pointer (read only). Instruction encoding (arithmetic and jump); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; eBPF is reusing most of the opcode encoding from classic to simplify conversion; of classic BPF to eBPF. For arithmetic and jump instructions the 8-bit 'code'; field is divided into three parts:. ::. +----------------+--------+--------------------+; | 4 bits | 1 bit | 3 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:102752,perform,performs,102752,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['perform'],['performs']
Performance,"to 'CPU Time / number of threads' AND 'Compressed Throughput' is lower than expected; for your storage medium: this would imply that your CPU threads aren't decompressing data as fast as your storage; medium can provide it, and so decompression is the bottleneck.; The best way to decrease your runtime would be to utilise a system with a faster CPU, or make use; use of more threads when running, or use a compression algorithm with a higher decompression rate such as LZ4,; possibly at the cost of some extra file size. ### A note on caching. If your data is stored on a local disk, the system may cache some/all of the file in memory after it is; first read. If this is realistic of how your analysis will run - then there is no concern. However, if; you expect to only read files once in a while - and as such the files are unlikely to be in the cache -; consider clearing the cache before running rootreadspeed.; On Linux this can be done by running 'echo 3 > /proc/sys/vm/drop_caches' as a superuser,; or a specific file can be dropped from the cache with; `dd of=<FILENAME> oflag=nocache conv=notrunc,fdatasync count=0 > /dev/null 2>&1`. ### Known overhead of TTreeReader, RDataFrame. `rootreadspeed` is designed to read all data present in the specified branches, trees and files at the highest; possible speed. When the application bottleneck is not in the computations performed by analysis logic,; higher-level interfaces built on top of TTree such as TTreeReader and RDataFrame are known to add a significant; runtime overhead with respect to the runtimes reported by `rootreadspeed` (up to a factor 2). In realistic analysis; applications it has been observed that a large part of that overhead is compensated by the ability of TTreeReader and; RDataFrame to read branch values selectively, based on event cuts, and this overhead will be reduced significantly; when using RDataFrame in conjunction with RNTuple.; See also [this talk](https://indico.cern.ch/e/PPP138) (slides 16 to 19).; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md:3921,cache,cache,3921,tree/readspeed/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md,3,"['bottleneck', 'cache', 'perform']","['bottleneck', 'cache', 'performed']"
Performance,"to Quagliani, LPNHE, CNRS/IN2P3, Sorbonne Université,\; Fons Rademakers, CERN/SFT,\; Oksana Shadura, Nebraska,\; Enric Tejedor Saavedra, CERN/SFT,\; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas,\; Stefan Wunsch, CERN/SFT. ## Deprecation and Removal. - `ROOT::GetImplicitMTPoolSize` has been deprecated in favor of the newly added `ROOT::GetThreadPoolSize` and; will be removed in v6.24.; - Manually setting `TThreadedObject::fgMaxSlots` is deprecated: TThreadedObject now increases the number of slots; on-demand rather than running out and throwing an exception. ## Core Libraries. - ROOT comes with C++ Modules enabled. More details about the technology found [here](../../README.CXXMODULES.md).; - The `ACLiC` can be configured to pass options to the `rootcling` invocation by enabling in the `.rootrc` the `ACLiC.ExtraRootclingFlags [-opts]` line.; - A call to `ROOT::EnableThreadSafety` is not required before using `TThreadExecutor` or `TTreeProcessorMT` anymore; - `TTreeProcessorMT` does not silently activate implicit multi-threading features anymore. An explicit call to; `ROOT::EnableImplicitMT` is required instead; - `TTreeProcessorMT` now has a constructor argument to set the number of threads for its thread-pool. ## I/O Libraries. ## TTree Libraries. - A new status bit was added to `TTree`: `kEntriesReshuffled`, which indicates a `TTree` that is the output of the; processing of another tree during which its entry order has been changed (this can happen, for instance, when; processing a tree in a multi-thread application). To avoid silent entry number mismatches, trees with this bit set; cannot add friend trees nor can be added as friends, unless the friend `TTree` has an appropriate `TTreeIndex`. ## Histogram Libraries. ## Math Libraries. ## RooFit Libraries. ### RooWorkspace::Import() for Python; `RooWorkspace.import()` cannot be used in Python, since it is a reserved keyword. Users therefore had to resort; to; getattr(works",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md:1863,multi-thread,multi-threading,1863,README/ReleaseNotes/v622/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md,1,['multi-thread'],['multi-threading']
Performance,"to RDTSC. On Alpha, it; should map to RPCC. As the backing counters overflow quickly (on the; order of 9 seconds on alpha), this should only be used for small; timings. Semantics:; """""""""""""""""""". When directly supported, reading the cycle counter should not modify any; memory. Implementations are allowed to either return an application; specific value or a system wide value. On backends without support, this; is lowered to a constant 0. Note that runtime support may be conditional on the privilege-level code is; running at and the host platform. '``llvm.clear_cache``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.clear_cache(ptr, ptr). Overview:; """""""""""""""""". The '``llvm.clear_cache``' intrinsic ensures visibility of modifications; in the specified range to the execution unit of the processor. On; targets with non-unified instruction and data cache, the implementation; flushes the instruction cache. Semantics:; """""""""""""""""""". On platforms with coherent instruction and data caches (e.g. x86), this; intrinsic is a nop. On platforms with non-coherent instruction and data; cache (e.g. ARM, MIPS), the intrinsic is lowered either to appropriate; instructions or a system call, if cache flushing requires special; privileges. The default behavior is to emit a call to ``__clear_cache`` from the run; time library. This intrinsic does *not* empty the instruction pipeline. Modifications; of the current function are outside the scope of the intrinsic. '``llvm.instrprof.increment``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.instrprof.increment(ptr <name>, i64 <hash>,; i32 <num-counters>, i32 <index>). Overview:; """""""""""""""""". The '``llvm.instrprof.increment``' intrinsic can be emitted by a; frontend for use with instrumentation based profiling. These will be; lowered by the ``-instrprof`` pass to generate execution counts of a; program at runtime. Arguments:; """""""""""""""""""". The first argument is a pointer",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:526312,cache,caches,526312,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['cache'],['caches']
Performance,"to TS3WebFile by allowing the security token to be given.; * Resolve an issue when space is freed in a large `ROOT` file and a TDirectory is updated and stored the lower (less than 2GB) freed portion of the file [ROOT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually call",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9328,optimiz,optimization,9328,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['optimiz'],['optimization']
Performance,"to ``-fsigned-zeros``. .. option:: -f[no-]associative-math. Allow floating point operations to be reassociated.; Defaults to ``-fno-associative-math``. .. option:: -f[no-]reciprocal-math. Allow division operations to be transformed into multiplication by a; reciprocal. This can be significantly faster than an ordinary division; but can also have significantly less precision. Defaults to; ``-fno-reciprocal-math``. .. option:: -f[no-]unsafe-math-optimizations. Allow unsafe floating-point optimizations.; ``-funsafe-math-optimizations`` also implies:. * ``-fapprox-func``; * ``-fassociative-math``; * ``-freciprocal-math``; * ``-fno-signed-zeros``; * ``-fno-trapping-math``; * ``-ffp-contract=fast``. ``-fno-unsafe-math-optimizations`` implies:. * ``-fno-approx-func``; * ``-fno-associative-math``; * ``-fno-reciprocal-math``; * ``-fsigned-zeros``; * ``-ftrapping-math``; * ``-ffp-contract=on``; * ``-fdenormal-fp-math=ieee``. There is ambiguity about how ``-ffp-contract``,; ``-funsafe-math-optimizations``, and ``-fno-unsafe-math-optimizations``; behave when combined. Explanation in :option:`-fno-fast-math` also applies; to these options. Defaults to ``-fno-unsafe-math-optimizations``. .. option:: -f[no-]finite-math-only. Allow floating-point optimizations that assume arguments and results are; not NaNs or +-Inf. ``-ffinite-math-only`` defines the; ``__FINITE_MATH_ONLY__`` preprocessor macro.; ``-ffinite-math-only`` implies:. * ``-fno-honor-infinities``; * ``-fno-honor-nans``. ``-ffno-inite-math-only`` implies:. * ``-fhonor-infinities``; * ``-fhonor-nans``. Defaults to ``-fno-finite-math-only``. .. option:: -f[no-]rounding-math. Force floating-point operations to honor the dynamically-set rounding mode by default. The result of a floating-point operation often cannot be exactly represented in the result type and therefore must be rounded. IEEE 754 describes different rounding modes that control how to perform this rounding, not all of which are supported by all implementations.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:59775,optimiz,optimizations,59775,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,['optimiz'],['optimizations']
Performance,"to ``On`` if you want to; enforce a target appearing in only one distribution and umbrella distributions; being consistent with target distributions. We strongly encourage looking at ``clang/cmake/caches/MultiDistributionExample.cmake``; as an example of configuring multiple distributions. Special Notes for Library-only Distributions; --------------------------------------------. One of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to perform and the; stage-1 compiler is thrown away. All of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. The first and simplest to use is the compiler optimization level by setting the; *CMAKE_BUILD_TYPE* option. The main values of interest are ``Release`` or; ``RelWithDebInfo``. By default the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebInfo`` uses ``-O2``. If you want to generate; debug information and use ``-O3`` you can override the; *CMAKE_<LANG>_FLAGS_RELWITHDEBINFO* option for C and CXX.; DistributionExample.cmake does this. Another easy to use option is Link-Time-Optimization. You can set the; *LL",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:7560,optimiz,optimizations,7560,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['optimiz'],['optimizations']
Performance,"to a property not of retainable object; pointer type has the same behavior it does outside of ARC: it requires the; property type to be some sort of pointer and permits the use of modifiers other; than ``assign``. These modifiers only affect the synthesized getter and; setter; direct accesses to the ivar (even if synthesized) still have primitive; semantics, and the value in the ivar will not be automatically released during; deallocation. .. _arc.ownership.semantics:. Semantics; ---------. There are five :arc-term:`managed operations` which may be performed on an; object of retainable object pointer type. Each qualifier specifies different; semantics for each of these operations. It is still undefined behavior to; access an object outside of its lifetime. A load or store with ""primitive semantics"" has the same semantics as the; respective operation would have on an ``void*`` lvalue with the same alignment; and non-ownership qualification. :arc-term:`Reading` occurs when performing a lvalue-to-rvalue conversion on an; object lvalue. * For ``__weak`` objects, the current pointee is retained and then released at; the end of the current full-expression. In particular, messaging a ``__weak``; object keeps the object retained until the end of the full expression. .. code-block:: objc. __weak MyObject *weakObj;. void foo() {; // weakObj is retained before the message send and released at the end of; // the full expression.; [weakObj m];; }. This must execute atomically with respect to assignments and to the final; release of the pointee.; * For all other objects, the lvalue is loaded with primitive semantics. :arc-term:`Assignment` occurs when evaluating an assignment operator. The; semantics vary based on the qualification:. * For ``__strong`` objects, the new pointee is first retained; second, the; lvalue is loaded with primitive semantics; third, the new pointee is stored; into the lvalue with primitive semantics; and finally, the old pointee is; released. This is not p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:37887,perform,performing,37887,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['perform'],['performing']
Performance,"to a valid; object. Performs the complete sequence for assigning to a ``__strong`` object of; non-block type [*]_. Equivalent to the following code:. .. code-block:: objc. void objc_storeStrong(id *object, id value) {; id oldValue = *object;; value = [value retain];; *object = value;; [oldValue release];; }. .. [*] This does not imply that a ``__strong`` object of block type is an; invalid argument to this function. Rather it implies that an ``objc_retain``; and not an ``objc_retainBlock`` operation will be emitted if the argument is; a block. .. _arc.runtime.objc_storeWeak:. ``id objc_storeWeak(id *object, id value);``; --------------------------------------------. *Precondition:* ``object`` is a valid pointer which either contains a null; pointer or has been registered as a ``__weak`` object. ``value`` is null or a; pointer to a valid object. If ``value`` is a null pointer or the object to which it points has begun; deallocation, ``object`` is assigned null and unregistered as a ``__weak``; object. Otherwise, ``object`` is registered as a ``__weak`` object or has its; registration updated to point to ``value``. Returns the value of ``object`` after the call. .. _arc.runtime.objc_unsafeClaimAutoreleasedReturnValue:. ``id objc_unsafeClaimAutoreleasedReturnValue(id value);``; ---------------------------------------------------------. *Precondition:* ``value`` is null or a pointer to a valid object. If ``value`` is null, this call has no effect. Otherwise, it attempts to; accept a hand off of a retain count from a call to; :ref:`objc_autoreleaseReturnValue <arc.runtime.objc_autoreleaseReturnValue>` on; ``value`` in a recently-called function or something it tail-calls (in a manner; similar to :ref:`objc_retainAutoreleasedReturnValue; <arc.runtime.objc_retainAutoreleasedReturnValue>`). If that succeeds,; it performs a release operation exactly like :ref:`objc_release; <arc.runtime.objc_release>`. If the handoff fails, this call has no effect. Always returns ``value``. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:118077,perform,performs,118077,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['perform'],['performs']
Performance,"to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:8319,throughput,throughput,8319,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['throughput'],['throughput']
Performance,"to be duplicated as well. For example, when the intrinsic is used inside a loop body, and that loop is; unrolled, the associated noalias scope must also be duplicated. Otherwise, the; noalias property it signifies would spill across loop iterations, whereas it; was only valid within a single iteration. .. code-block:: llvm. ; This examples shows two possible positions for noalias.decl and how they impact the semantics:; ; If it is outside the loop (Version 1), then %a and %b are noalias across *all* iterations.; ; If it is inside the loop (Version 2), then %a and %b are noalias only within *one* iteration.; declare void @decl_in_loop(ptr %a.base, ptr %b.base) {; entry:; ; call void @llvm.experimental.noalias.scope.decl(metadata !2) ; Version 1: noalias decl outside loop; br label %loop. loop:; %a = phi ptr [ %a.base, %entry ], [ %a.inc, %loop ]; %b = phi ptr [ %b.base, %entry ], [ %b.inc, %loop ]; ; call void @llvm.experimental.noalias.scope.decl(metadata !2) ; Version 2: noalias decl inside loop; %val = load i8, ptr %a, !alias.scope !2; store i8 %val, ptr %b, !noalias !2; %a.inc = getelementptr inbounds i8, ptr %a, i64 1; %b.inc = getelementptr inbounds i8, ptr %b, i64 1; %cond = call i1 @cond(); br i1 %cond, label %loop, label %exit. exit:; ret void; }. !0 = !{!0} ; domain; !1 = !{!1, !0} ; scope; !2 = !{!1} ; scope list. Multiple calls to `@llvm.experimental.noalias.scope.decl` for the same scope; are possible, but one should never dominate another. Violations are pointed out; by the verifier as they indicate a problem in either a transformation pass or; the input. Floating Point Environment Manipulation intrinsics; --------------------------------------------------. These functions read or write floating point environment, such as rounding; mode or state of floating point exceptions. Altering the floating point; environment requires special care. See :ref:`Floating Point Environment <floatenv>`. .. _int_get_rounding:. '``llvm.get.rounding``' Intrinsic; ^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:915090,load,load,915090,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"to be effectively optimized. It; can often be useful to write a quick C program with the semantics you're trying; to model and see what decisions Clang's IRGen makes about what IR to emit.; Studying Clang's CodeGen directory can also be a good source of ideas. Note; that Clang and LLVM are explicitly version locked so you'll need to make sure; you're using a Clang built from the same git revision or release as the LLVM; library you're using. As always, it's *strongly* recommended that you track; tip of tree development, particularly during bring up of a new project. The Basics; ^^^^^^^^^^^. #. Make sure that your Modules contain both a data layout specification and; target triple. Without these pieces, non of the target specific optimization; will be enabled. This can have a major effect on the generated code quality. #. For each function or global emitted, use the most private linkage type; possible (private, internal or linkonce_odr preferably). Doing so will; make LLVM's inter-procedural optimizations much more effective. #. Avoid high in-degree basic blocks (e.g. basic blocks with dozens or hundreds; of predecessors). Among other issues, the register allocator is known to; perform badly with confronted with such structures. The only exception to; this guidance is that a unified return block with high in-degree is fine. Use of allocas; ^^^^^^^^^^^^^^. An alloca instruction can be used to represent a function scoped stack slot,; but can also represent dynamic frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instruction",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:1773,optimiz,optimizations,1773,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['optimiz'],['optimizations']
Performance,"to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:1713,load,loaded,1713,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,1,['load'],['loaded']
Performance,"to evolve through collaboration with many individuals and; active prototyping within the GDB debugger and LLVM compiler. Input has also; been very much appreciated from the developers working on the Perforce TotalView; HPC Debugger and GCC compiler. The inputs provided and insights gained so far have been incorporated into this; current version. The plan is to participate in upstreaming the work and; addressing any feedback. If there is general interest then some or all of these; extensions could be submitted as future DWARF standard proposals. The general principles in designing the extensions have been:. 1. Be backwards compatible with the DWARF Version 5 [:ref:`DWARF; <amdgpu-dwarf-DWARF>`] standard. 2. Be vendor and architecture neutral. They are intended to apply to other; heterogeneous hardware devices including GPUs, DSPs, FPGAs, and other; specialized hardware. These collectively include similar characteristics and; requirements as AMDGPU devices. 3. Provide improved optimization support for non-GPU code. For example, some; extensions apply to traditional CPU hardware that supports large vector; registers. Compilers can map source languages, and source language; extensions, that describe large scale parallel execution, onto the lanes of; the vector registers. This is common in programming languages used in ML and; HPC. 4. Fully define well-formed DWARF in a consistent style based on the DWARF; Version 5 specification. It is possible that some of the generalizations may also benefit other DWARF; issues that have been raised. The remainder of this section enumerates the extensions and provides motivation; for each in terms of heterogeneous debugging. .. _amdgpu-dwarf-allow-location-description-on-the-dwarf-evaluation-stack:. 2.1 Allow Location Description on the DWARF Expression Stack; ------------------------------------------------------------. DWARF Version 5 does not allow location descriptions to be entries on the DWARF; expression stack. They can only be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:4203,optimiz,optimization,4203,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['optimiz'],['optimization']
Performance,"to one register file so that we minimize the cost of copying data; back and forth to satisfy the (possibly conflicting) requirements of all the; instructions. Register Banks are a means to constrain the register allocator to; use a particular register file for a virtual register. In practice, register files A and B are rarely equal. They can typically store; the same data but there's usually some restrictions on what operations you can; do on each register file. A fairly common pattern is for one of them to be; accessible to integer operations and the other accessible to floating point; operations. To accommodate this, let's rename A and B to GPR (general purpose; registers) and FPR (floating point registers). We now have some additional constraints that limit us. An operation like G_FMUL; has to happen in FPR and G_ADD has to happen in GPR. However, even though this; prescribes a lot of the assignments we still have some freedom. A G_LOAD can; happen in both GPR and FPR, and which we want depends on who is going to consume; the loaded data. Similarly, G_FNEG can happen in both GPR and FPR. If we assign; it to FPR, then we'll use floating point negation. However, if we assign it to; GPR then we can equivalently G_XOR the sign bit with 1 to invert it. In summary, Register Banks are a means of disambiguating between seemingly; equivalent choices based on some analysis of the differences when each choice; is applied in a given context. To give some concrete examples:. AArch64. AArch64 has three main banks. GPR for integer operations, FPR for floating; point and also for the NEON vector instruction set. The third is CCR and; describes the condition code register used for predication. MIPS. MIPS has five main banks of which many programs only really use one or two.; GPR is the general purpose bank for integer operations. FGR or CP1 is for; the floating point operations as well as the MSA vector instructions and a; few other application specific extensions. CP0 is for syst",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:5093,load,loaded,5093,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,1,['load'],['loaded']
Performance,"to other target; debug info formats such as STABS. It would also be reasonable to use debug information to feed profiling tools; for analysis of generated code, or, tools for reconstructing the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a pro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4263,optimiz,optimizations,4263,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['optimiz'],['optimizations']
Performance,"to performing the following steps to; push a composite location description. *The composite location description is conceptually the base location; description BL with the overlay location description OL positioned as an; overlay starting at the overlay offset BO and covering overlay bit size BS.*. 1. If BO is not 0 then push BL followed by performing the ``DW_OP_bit_piece; BO, 0`` operation.; 2. Push OL followed by performing the ``DW_OP_bit_piece BS, 0`` operation.; 3. If *rbss(BL)* is greater than BO plus BS, push BL followed by performing; the ``DW_OP_bit_piece (rbss(BL) - BO - BS), (BO + BS)`` operation.; 4. Perform the ``DW_OP_LLVM_piece_end`` operation. .. _amdgpu-dwarf-location-list-expressions:. A.2.5.5 DWARF Location List Expressions; +++++++++++++++++++++++++++++++++++++++. .. note::. This section replaces DWARF Version 5 section 2.6.2. *To meet the needs of recent computer architectures and optimization techniques,; debugging information must be able to describe the location of an object whose; location changes over the object’s lifetime, and may reside at multiple; locations during parts of an object's lifetime. Location list expressions are; used in place of operation expressions whenever the object whose location is; being described has these requirements.*. A location list expression consists of a series of location list entries. Each; location list entry is one of the following kinds:. *Bounded location description*. This kind of location list entry provides an operation expression that; evaluates to the location description of an object that is valid over a; lifetime bounded by a starting and ending address. The starting address is the; lowest address of the address range over which the location is valid. The; ending address is the address of the first location past the highest address; of the address range. The location list entry matches when the current program location is within; the given range. There are several kinds of bounded location descr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:142552,optimiz,optimization,142552,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['optimiz'],['optimization']
Performance,"to provide a library implementation of it. This gets even worse when code from different languages is linked; into a single executable (which is fairly common in large apps).; Having a single malloc would just not suffice, and instead would simply; complicate the picture further because it adds an extra variant in; addition to the one each language provides. Instead, providing a default library version of malloc and free; (and perhaps a malloc_gc with garbage collection instead of free); would make a good implementation available to anyone who wants it. I don't recall all your arguments in favor so let's discuss this again,; and soon. o 'alloca' on the other hand sounds like a good idea, and the; implementation seems fairly language-independent so it doesn't have the; problems with malloc listed above. o About indirect call:; Your option #2 sounded good to me. I'm not sure I understand your; concern about an explicit 'icall' instruction?. o A pair of important synchronization instr'ns to think about:; load-linked; store-conditional. o Other classes of instructions that are valuable for pipeline performance:; conditional-move		 ; predicated instructions. o I believe tail calls are relatively easy to identify; do you know why; .NET has a tailcall instruction?. o I agree that we need a static data space. Otherwise, emulating global; data gets unnecessarily complex. o About explicit parallelism:. We once talked about adding a symbolic thread-id field to each; instruction. (It could be optional so single-threaded codes are; not penalized.) This could map well to multi-threaded architectures; while providing easy ILP for single-threaded onces. But it is probably; too radical an idea to include in a base version of LLVM. Instead, it; could a great topic for a separate study. What is the semantics of the IA64 stop bit?. o And finally, another thought about the syntax for arrays :-). Although this syntax:; 	 array <dimension-list> of <type>; is verbose, it will be used only ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt:3347,load,load-linked,3347,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt,1,['load'],['load-linked']
Performance,"to replace; it with any other `i1` value. Any pass can; freely do it if it can benefit from non-default lowering. '``llvm.load.relative``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.load.relative.iN(ptr %ptr, iN %offset) nounwind memory(argmem: read). Overview:; """""""""""""""""". This intrinsic loads a 32-bit value from the address ``%ptr + %offset``,; adds ``%ptr`` to that value and returns it. The constant folder specifically; recognizes the form of this intrinsic and the constant initializers it may; load from; if a loaded constant initializer is known to have the form; ``i32 trunc(x - %ptr)``, the intrinsic call is folded to ``x``. LLVM provides that the calculation of such a constant initializer will; not overflow at link time under the medium code model if ``x`` is an; ``unnamed_addr`` function. However, it does not provide this guarantee for; a constant initializer folded into a function body. This intrinsic can be; used to avoid the possibility of overflows when loading from such a constant. .. _llvm_sideeffect:. '``llvm.sideeffect``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.sideeffect() inaccessiblememonly nounwind willreturn. Overview:; """""""""""""""""". The ``llvm.sideeffect`` intrinsic doesn't perform any operation. Optimizers; treat it as having side effects, so it can be inserted into a loop to; indicate that the loop shouldn't be assumed to terminate (which could; potentially lead to the loop being optimized away entirely), even if it's; an infinite loop with no other side effects. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". This intrinsic actually does nothing, but optimizers must assume that it; has externally observable side effects. '``llvm.is.constant.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use llvm.is.constant with any argument type. ::. declare i1 @llvm.is.constant.i32(i32 %operand) nounwind m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:951623,load,loading,951623,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loading']
Performance,"to scalar/aggregate/complex and; lvalue/rvalue paths, depending on what kind of result your expression; produces. On occasion, this requires some careful factoring of code to; avoid duplication.; * ``CodeGenFunction`` contains functions ``ConvertType`` and; ``ConvertTypeForMem`` that convert Clang's types (``clang::Type*`` or; ``clang::QualType``) to LLVM types. Use the former for values, and the; latter for memory locations: test with the C++ ""``bool``"" type to check; this. If you find that you are having to use LLVM bitcasts to make the; subexpressions of your expression have the type that your expression; expects, STOP! Go fix semantic analysis and the AST so that you don't; need these bitcasts.; * The ``CodeGenFunction`` class has a number of helper functions to make; certain operations easy, such as generating code to produce an lvalue or; an rvalue, or to initialize a memory location with a given value. Prefer; to use these functions rather than directly writing loads and stores,; because these functions take care of some of the tricky details for you; (e.g., for exceptions).; * If your expression requires some special behavior in the event of an; exception, look at the ``push*Cleanup`` functions in ``CodeGenFunction``; to introduce a cleanup. You shouldn't have to deal with; exception-handling directly.; * Testing is extremely important in IR generation. Use ``clang -cc1; -emit-llvm`` and `FileCheck; <https://llvm.org/docs/CommandGuide/FileCheck.html>`_ to verify that you're; generating the right IR. #. Teach template instantiation how to cope with your AST node, which requires; some fairly simple code:. * Make sure that your expression's constructor properly computes the flags; for type dependence (i.e., the type your expression produces can change; from one instantiation to the next), value dependence (i.e., the constant; value your expression produces can change from one instantiation to the; next), instantiation dependence (i.e., a template parameter occu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:151766,load,loads,151766,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['load'],['loads']
Performance,"to separate the; arguments of the ``-debug-only`` option. For performance reasons, -debug-only is not available in optimized build; (``--enable-optimized``) of LLVM. The ``DEBUG_WITH_TYPE`` macro is also available for situations where you would; like to set ``DEBUG_TYPE``, but only for one specific ``DEBUG`` statement. It; takes an additional first parameter, which is the type to use. For example, the; preceding example could be written as:. .. code-block:: c++. DEBUG_WITH_TYPE(""foo"", dbgs() << ""'foo' debug type\n"");; DEBUG_WITH_TYPE(""bar"", dbgs() << ""'bar' debug type\n"");. .. _Statistic:. The ``Statistic`` class & ``-stats`` option; -------------------------------------------. The ``llvm/ADT/Statistic.h`` (`doxygen; <https://llvm.org/doxygen/Statistic_8h_source.html>`__) file provides a class; named ``Statistic`` that is used as a unified way to keep track of what the LLVM; compiler is doing and how effective various optimizations are. It is useful to; see what optimizations are contributing to making a particular program run; faster. Often you may run your pass on some big program, and you're interested to see; how many times it makes a certain transformation. Although you can do this with; hand inspection, or some ad-hoc method, this is a real pain and not very useful; for big programs. Using the ``Statistic`` class makes it very easy to keep; track of this information, and the calculated information is presented in a; uniform manner with the rest of the passes being executed. There are many examples of ``Statistic`` uses, but the basics of using it are as; follows:. Define your statistic like this:. .. code-block:: c++. #define DEBUG_TYPE ""mypassname"" // This goes after any #includes.; STATISTIC(NumXForms, ""The # of times I did stuff"");. The ``STATISTIC`` macro defines a static variable, whose name is specified by; the first argument. The pass name is taken from the ``DEBUG_TYPE`` macro, and; the description is taken from the second argument. The variable defined",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:46605,optimiz,optimizations,46605,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['optimiz'],['optimizations']
Performance,"to the ReadySet. Every cycle, the scheduler checks if instructions can be moved from the WaitSet; to the ReadySet, and if instructions from the ReadySet can be issued to the; underlying pipelines. The algorithm prioritizes older instructions over younger; instructions. Write-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39379,load,load,39379,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['load'],"['load', 'loads']"
Performance,"to the `two_dim_fit` structure pointer, see manual; - **`sizex`**: length x of the source spectrum; - **`sizey`**: length y of the source spectrum. The `two_dim_fit` structure has the form of. ``` {.cpp}; class TSpectrumTwoDimFit{. public:. int number_of_peaks; // input parameter, should be>0; int number_of_iterations; // input parameter, should be >0; int xmin; // first fitted channel in x direction; int xmax; // last fitted channel in x direction; int ymin; // first fitted channel in y direction; int ymax; // last fitted channel in y direction; double alpha; // convergence coefficient, input parameter, it should be a positive number and <=1; double chi; // here the function returns resulting chi square; int statistic_type; // type of statistics, possible values are:; // FIT2_OPTIM_CHI_COUNTS (chi square statistics with counts as weighting coefficients),; // FIT2_OPTIM_CHI_FUNC_VALUES (chi square statistics with function values as weighting coefficients),; // FIT2_OPTIM_MAX_LIKELIHOOD; int alpha_optim; // optimization of convergence coefficients, possible values are:; // FIT2_ALPHA_HALVING, FIT2_ALPHA_OPTIMAL; int power; // possible values are: FIT21_FIT_POWER2,4,6,8,10,12; int fit_taylor; // order of Taylor expansion, possible values are:; // FIT2_TAYLOR_ORDER_FIRST,; // FIT2_TAYLOR_ORDER_SECOND; double position_init_x[MAX_NUMBER_OF_PEAKS2]; // initial values of x positions of 2D peaks, input parameters; double position_calc_x[MAX_NUMBER_OF_PEAKS2]; // calculated values of fitted x positions of 2D peaks, output parameters; double position_err_x[MAX_NUMBER_OF_PEAKS2]; // x position errors of 2D peaks; bool fix_position_x[MAX_NUMBER_OF_PEAKS2]; // logical vector which allows to fix the appropriate x positions of 2D peaks (not fit). However, they are present in the estimated functional; double position_init_y[MAX_NUMBER_OF_PEAKS2]; // initial values of y positions of 2D peaks, input parameters; double position_calc_y[MAX_NUMBER_OF_PEAKS2]; // calculated values of fitt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:49706,optimiz,optimization,49706,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['optimiz'],['optimization']
Performance,"to the final visualization in form of highly ; customizable, publication-ready plots. It is reliable, performant and well supported,; easy to use and obtain, and strives to maximize the quantity and impact of scientific ; results obtained per unit cost, both of human effort and computing resources. ROOT provides a very efficient storage system for data models, ; that demonstrated to scale at the Large Hadron Collider experiments: Exabytes ; of scientific data are written in columnar ROOT format.; ROOT comes with histogramming capabilities in an arbitrary number of ; dimensions, curve fitting, statistical modelling, minimization, to allow; the easy setup of a data analysis system that can query and process the data; interactively or in batch mode, as well as a general parallel processing; framework, RDataFrame, that can considerably speed up an analysis, taking ; full advantage of multi-core and distributed systems. ROOT is performance critical software written in C++ and enables rapid prototyping ; powered by a unique C++ compliant interpreter called Cling. ; Cling also enables performant C++ type introspection which is a building block of automatic ; interoperability with Python. Thanks to PyROOT, leveraging the cppyy technology, ; ROOT offers efficient, on-demand C++/Python interoperability in a uniform cross-language ; execution environment. ROOT fully embraces open-source, it's made with passion by its community,; for the benefit of its community. [![License: LGPL v2.1+](https://img.shields.io/badge/License-LGPL%20v2.1+-blue.svg)](https://www.gnu.org/licenses/lgpl.html); [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5060/badge)](https://bestpractices.coreinfrastructure.org/projects/5060). ## Contribution Guidelines; - [How to contribute](https://github.com/root-project/root/blob/master/CONTRIBUTING.md); - [Coding conventions](https://root.cern/coding-conventions); - [Meetings](https://root.cern/meetings). ## Cite; When citing ROOT, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README.md:1209,perform,performance,1209,README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README.md,1,['perform'],['performance']
Performance,"to; ``%reg1 - reg2``. This list of values should be provided by the containing; intrinsic/instruction.; - ``DW_OP_breg`` (or ``DW_OP_bregx``) represents a content on the provided; signed offset of the specified register. The opcode is only generated by the; ``AsmPrinter`` pass to describe call site parameter value which requires an; expression over two registers.; - ``DW_OP_push_object_address`` pushes the address of the object which can then; serve as a descriptor in subsequent calculation. This opcode can be used to; calculate bounds of fortran allocatable array which has array descriptors.; - ``DW_OP_over`` duplicates the entry currently second in the stack at the top; of the stack. This opcode can be used to calculate bounds of fortran assumed; rank array which has rank known at run time and current dimension number is; implicitly first element of the stack.; - ``DW_OP_LLVM_implicit_pointer`` It specifies the dereferenced value. It can; be used to represent pointer variables which are optimized out but the value; it points to is known. This operator is required as it is different than DWARF; operator DW_OP_implicit_pointer in representation and specification (number; and types of operands) and later can not be used as multiple level. .. code-block:: text. IR for ""*ptr = 4;""; --------------; call void @llvm.dbg.value(metadata i32 4, metadata !17, metadata !20); !17 = !DILocalVariable(name: ""ptr1"", scope: !12, file: !3, line: 5,; type: !18); !18 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !19, size: 64); !19 = !DIBasicType(name: ""int"", size: 32, encoding: DW_ATE_signed); !20 = !DIExpression(DW_OP_LLVM_implicit_pointer)). IR for ""**ptr = 4;""; --------------; call void @llvm.dbg.value(metadata i32 4, metadata !17, metadata !21); !17 = !DILocalVariable(name: ""ptr1"", scope: !12, file: !3, line: 5,; type: !18); !18 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !19, size: 64); !19 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !20, size: 64); !20 = ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:266129,optimiz,optimized,266129,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimized']
Performance,"to; express the input LLVM code in the target instruction set. This stage; produces the initial code for the program in the target instruction set, then; makes use of virtual registers in SSA form and physical registers that; represent any required register assignments due to target constraints or; calling conventions. This step turns the LLVM code into a DAG of target; instructions. 2. `Scheduling and Formation`_ --- This phase takes the DAG of target; instructions produced by the instruction selection phase, determines an; ordering of the instructions, then emits the instructions as :raw-html:`<tt>`; `MachineInstr`_\s :raw-html:`</tt>` with that ordering. Note that we; describe this in the `instruction selection section`_ because it operates on; a `SelectionDAG`_. 3. `SSA-based Machine Code Optimizations`_ --- This optional stage consists of a; series of machine-code optimizations that operate on the SSA-form produced by; the instruction selector. Optimizations like modulo-scheduling or peephole; optimization work here. 4. `Register Allocation`_ --- The target code is transformed from an infinite; virtual register file in SSA form to the concrete register file used by the; target. This phase introduces spill code and eliminates all virtual register; references from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:6253,optimiz,optimization,6253,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['optimiz'],['optimization']
Performance,"toc@ha; addis 4, 2, .LCPI0_1@toc@ha; addi 3, 3, .LCPI0_0@toc@l; addi 4, 4, .LCPI0_1@toc@l; lxvw4x 0, 0, 3; addi 3, 1, -16; lxvw4x 35, 0, 4; stxvw4x 0, 0, 3; ori 2, 2, 0; lxvw4x 34, 0, 3; addi 3, 1, -32; stxvw4x 35, 0, 3; vpmsumb 2, 2, 3; blr; .long 0; .quad 0. The two stxvw4x instructions are not needed.; With -mtriple=powerpc64le-unknown-linux-gnu, the associated permutes; are present too. //===----------------------------------------------------------------------===//. The following example is found in test/CodeGen/PowerPC/vec_add_sub_doubleword.ll:. define <2 x i64> @increment_by_val(<2 x i64> %x, i64 %val) nounwind {; %tmpvec = insertelement <2 x i64> <i64 0, i64 0>, i64 %val, i32 0; %tmpvec2 = insertelement <2 x i64> %tmpvec, i64 %val, i32 1; %result = add <2 x i64> %x, %tmpvec2; ret <2 x i64> %result. This will generate the following instruction sequence:; std 5, -8(1); std 5, -16(1); addi 3, 1, -16; ori 2, 2, 0; lxvd2x 35, 0, 3; vaddudm 2, 2, 3; blr. This will almost certainly cause a load-hit-store hazard. ; Since val is a value parameter, it should not need to be saved onto; the stack, unless it's being done set up the vector register. Instead,; it would be better to splat the value into a vector register, and then; remove the (dead) stores to the stack. //===----------------------------------------------------------------------===//. At the moment we always generate a lxsdx in preference to lfd, or stxsdx in; preference to stfd. When we have a reg-immediate addressing mode, this is a; poor choice, since we have to load the address into an index register. This; should be fixed for P7/P8. . //===----------------------------------------------------------------------===//. Right now, ShuffleKind 0 is supported only on BE, and ShuffleKind 2 only on LE.; However, we could actually support both kinds on either endianness, if we check; for the appropriate shufflevector pattern for each case ... this would cause; some additional shufflevectors to be recognized and ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt:7910,load,load-hit-store,7910,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,1,['load'],['load-hit-store']
Performance,"tolerance parameter `fTol` (a member of the base class; **`TDecompBase`**) plays a crucial role in all operations of the; decomposition classes. It gives the user a tool to monitor and steer the; operations its default value is $\varepsilon$ where $1+\varepsilon=1$. If you do not want to be bothered by the following considerations, like; in most other linear algebra packages, just set the tolerance with; `SetTol` to an arbitrary small number. The tolerance number is used by; each decomposition method to decide whether the matrix is near singular,; except of course SVD that can handle singular matrices. This will be; checked in a different way for any decomposition. For instance in LU, a; matrix is considered singular in the solving stage when a diagonal; element of the decomposed matrix is smaller than `fTol`. Here an; important point is raised. The `Decompose()` method is successful as; long no zero diagonal element is encountered. Therefore, the user could; perform decomposition and only after this step worry about the tolerance; number. If the matrix is flagged as being singular, operations with the; decomposition will fail and will return matrices or vectors that are; invalid. If one would like to monitor the tolerance parameter but not; have the code stop in case of a number smaller than `fTol`, one could; proceed as follows:. ``` {.cpp}; TVectorD b = ..;; TMatrixD a = ..;; .; TDecompLU lu(a);; Bool_t ok;; TVectorD x = lu.Solve(b,ok);; Int_t nr = 0;; while (!ok) {; lu.SetMatrix(a);; lu.SetTol(0.1*lu.GetTol());; if (nr++ > 10) break;; x = lu.Solve(b,ok);; }; if (x.IsValid()); cout << ""solved with tol ="" << lu.GetTol() << endl;; else; cout << ""solving failed "" << endl;; ```. The observant reader will notice that by scaling the complete matrix by; some small number the decomposition will detect a singular matrix. In; this case, the user will have to reduce the tolerance number by this; factor. (For CPU time saving we decided not to make this an automatic procedure)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md:40573,perform,perform,40573,documentation/users-guide/LinearAlgebra.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md,1,['perform'],['perform']
Performance,"tomic value being; acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - If OpenCL omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:366363,perform,performing,366363,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"tomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:218589,cache,cache,218589,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"tomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:250401,load,loads,250401,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"tomic/atomicrmw.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before; the following; buffer_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/sto",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:318278,load,load,318278,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"tomicExpand Codegen pass if; ``shouldInsertFencesForAtomic()`` returns true. The MachineMemOperand for all atomic operations is currently marked as volatile;; this is not correct in the IR sense of volatile, but CodeGen handles anything; marked volatile very conservatively. This should get fixed at some point. One very important property of the atomic operations is that if your backend; supports any inline lock-free atomic operations of a given size, you should; support *ALL* operations of that size in a lock-free manner. When the target implements atomic ``cmpxchg`` or LL/SC instructions (as most do); this is trivial: all the other operations can be implemented on top of those; primitives. However, on many older CPUs (e.g. ARMv5, SparcV8, Intel 80386) there; are atomic load and store instructions, but no ``cmpxchg`` or LL/SC. As it is; invalid to implement ``atomic load`` using the native instruction, but; ``cmpxchg`` using a library call to a function that uses a mutex, ``atomic; load`` must *also* expand to a library call on such architectures, so that it; can remain atomic with regards to a simultaneous ``cmpxchg``, by using the same; mutex. AtomicExpandPass can help with that: it will expand all atomic operations to the; proper ``__atomic_*`` libcalls for any size above the maximum set by; ``setMaxAtomicSizeInBitsSupported`` (which defaults to 0). On x86, all atomic loads generate a ``MOV``. SequentiallyConsistent stores; generate an ``XCHG``, other stores generate a ``MOV``. SequentiallyConsistent; fences generate an ``MFENCE``, other fences do not cause any code to be; generated. ``cmpxchg`` uses the ``LOCK CMPXCHG`` instruction. ``atomicrmw xchg``; uses ``XCHG``, ``atomicrmw add`` and ``atomicrmw sub`` use ``XADD``, and all; other ``atomicrmw`` operations generate a loop with ``LOCK CMPXCHG``. Depending; on the users of the result, some ``atomicrmw`` operations can be translated into; operations like ``LOCK AND``, but that does not work in general. On ARM (be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:19228,load,load,19228,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,2,['load'],['load']
Performance,"tomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; glob",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226145,load,loads,226145,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"tomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:222402,perform,performing,222402,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"tonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1 dlc=1. - If GFX11, omit dlc=1. store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If CU wavefront execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If CU wavefront execution; mode, omit.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If CU wavefront execution; mode, omit glc=1. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If CU wavefront execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_gl0_inv and any; following global/generic; load",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:346487,load,load,346487,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"tor are taken from the corresponding lanes of the '``passthru``' operand. Arguments:; """""""""""""""""""". The first operand is a vector of pointers which holds all memory addresses to read. The second operand is an alignment of the source addresses. It must be 0 or a power of two constant integer value. The third operand, mask, is a vector of boolean values with the same number of elements as the return type. The fourth is a pass-through value that is used to fill the masked-off lanes of the result. The return type, underlying type of the vector of pointers and the type of the '``passthru``' operand are the same vector types. Semantics:; """""""""""""""""""". The '``llvm.masked.gather``' intrinsic is designed for conditional reading of multiple scalar values from arbitrary memory locations in a single IR operation. It is useful for targets that support vector masked gathers and allows vectorizing basic blocks with data and control divergence. Other targets may support this intrinsic differently, for example by lowering it into a sequence of scalar load operations.; The semantics of this operation are equivalent to a sequence of conditional scalar loads with subsequent gathering all loaded values into a single vector. The mask restricts memory access to certain lanes and facilitates vectorization of predicated basic blocks. ::. %res = call <4 x double> @llvm.masked.gather.v4f64.v4p0(<4 x ptr> %ptrs, i32 8, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x double> poison). ;; The gather with all-true mask is equivalent to the following instruction sequence; %ptr0 = extractelement <4 x ptr> %ptrs, i32 0; %ptr1 = extractelement <4 x ptr> %ptrs, i32 1; %ptr2 = extractelement <4 x ptr> %ptrs, i32 2; %ptr3 = extractelement <4 x ptr> %ptrs, i32 3. %val0 = load double, ptr %ptr0, align 8; %val1 = load double, ptr %ptr1, align 8; %val2 = load double, ptr %ptr2, align 8; %val3 = load double, ptr %ptr3, align 8. %vec0 = insertelement <4 x double> poison, %val0, 0; %vec01 = insertelement <4 x d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:850487,load,load,850487,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"tor the second matrix column; // return a slice of the first row from element (0,1) : r2[0] = m(0,1); r2[1] = m(0,2); SVector2 r2 = m.SubRow<SVector2> (0,1);; // return a slice of the second column from element (0,1) : c2[0] = m(0,1); c2[1] = m(1,1);; SVector2 c2 = m.SubCol<SVector2> (1,0);; // return a sub-matrix 2x2 with the upper left corner at the values (1,1); SMatrix22 subM = m.Sub<SMatrix22> (1,1);; // return the diagonal element in a SVector; SVector3 diag = m.Diagonal();; // return the upper(lower) block of the matrix m; SVector6 vub = m.UpperBlock(); // vub = [ 1, 2, 3, 5, 6, 9 ]; SVector6 vlb = m.LowerBlock(); // vlb = [ 1, 4, 5, 7, 8, 9 ]; ~~~. ### Linear Algebra Functions. Only limited linear algebra functionality is available for SMatrix. It is possible; for squared matrices NxN, to find the inverse or to calculate the determinant.; Different inversion algorithms are used if the matrix is smaller than 6x6 or if it; is symmetric. In the case of a small matrix, a faster direct inversion is used.; For a large (N > 6) symmetric matrix the Bunch-Kaufman diagonal pivoting method; is used while for a large (N > 6) general matrix an LU factorization is performed; using the same algorithm as in the CERNLIB routine; [dinv](https://cern-tex.web.cern.ch/cern-tex/shortwrupsdir/f010/top.html). ~~~ {.cpp}; // Invert a NxN matrix. The inverted matrix replace the existing one and returns if the result is successful; bool ret = m.Invert(); // return the inverse matrix of m. If the inversion fails ifail is different than zero; int ifail = 0;; mInv = m.Inverse(ifail);; ~~~. The determinant of a square matrix can be obtained as follows:. ~~~ {.cpp}; double det;; // calculate the determinant modifying the matrix content. Returns if the calculation was successful; bool ret = m.Det(det);; // calculate the determinant using a temporary matrix but preserving the matrix content; bool ret = n.Det2(det);; ~~~. For additional Matrix functionality see the \ref MatVecFunctions page. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md:8250,perform,performed,8250,math/smatrix/doc/SMatrixClass.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md,1,['perform'],['performed']
Performance,"torLength()``?). Result: VP usable for IR-level vectorizers (LV, VPlan, RegionVectorizer),; potential integration in Clang with builtins. 2. CodeGen support; ------------------. - VP intrinsics translate to first-class SDNodes; (eg ``llvm.vp.fdiv.* -> vp_fdiv``).; - VP legalization (legalize explicit vector length to mask (AVX512), legalize VP; SDNodes to pre-existing ones (SSE, NEON)). Result: Backend development based on VP SDNodes. 3. Lift InstSimplify/InstCombine/DAGCombiner to VP; --------------------------------------------------. - Introduce PredicatedInstruction, PredicatedBinaryOperator, .. helper classes; that match standard vector IR and VP intrinsics.; - Add a matcher context to PatternMatch and context-aware IR Builder APIs.; - Incrementally lift DAGCombiner to work on VP SDNodes as well as on regular; vector instructions.; - Incrementally lift InstCombine/InstSimplify to operate on VP as well as; regular IR instructions. Result: Optimization of VP intrinsics on par with standard vector instructions. 4. Deprecate llvm.masked.* / llvm.experimental.reduce.*; -------------------------------------------------------. - Modernize llvm.masked.* / llvm.experimental.reduce* by translating to VP.; - DCE transitional APIs. Result: VP has superseded earlier vector intrinsics. 5. Predicated IR Instructions; -----------------------------. - Vector instructions have an optional mask and vector length parameter. These; lower to VP SDNodes (from Stage 2).; - Phase out VP intrinsics, only keeping those that are not equivalent to; vectorized scalar instructions (reduce, shuffles, ..); - InstCombine/InstSimplify expect predication in regular Instructions (Stage (3); has laid the groundwork). Result: Native vector predication in IR. References; ==========. .. [MaskedIR] `llvm.masked.*` intrinsics,; https://llvm.org/docs/LangRef.html#masked-vector-load-and-store-intrinsics. .. [VPRFC] RFC: Prototype & Roadmap for vector predication in LLVM,; https://reviews.llvm.org/D57504; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VectorPredication.rst:2988,load,load-and-store-intrinsics,2988,interpreter/llvm-project/llvm/docs/Proposals/VectorPredication.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VectorPredication.rst,1,['load'],['load-and-store-intrinsics']
Performance,"torT<Float_t> TEveVector;; typedef TEveVectorT<Float_t> TEveVectorF;; typedef TEveVectorT<Double_t> TEveVectorD;. All projectable classes now take into account their transformation; matrix. The projected versions are still stored in global; coordinates.; TEveShape -- a new abstract base-class for 2D/3D shapes that; require fill / outline color, line-width and various flags; controlling the area / outline drawing.; TEveGeoShape and projected classes: subclass from TEveShape. Add; support for TGeoCompositeShapes. In 2D projected class; (TEvePolygonSetProjected) improve detection of duplicate polygons; and add support for detection of minimal-outline (triggered via; Bool_t TEveShape::fMiniOutline).; TEveBox: New class to draw a simple cuboid with minimal memory; usage. It is projectable.; TEveBoxSet: for box-type kBT_FreeBox assure proper face; orientation at registration time and calculate normals when; rendering. TEveJetCone is now projectable.; Several performance improvements when dealing with large; collections of EVE objects. Profiled with simulated heavy-ion; data. In particular, for destruction of self-contained sub-hierarchies of objects; one can use TEveElement::Annihilate() and; TEveElement::AnnihilateElements(). See class docs for constraints. Minor changes. Add support for projecting a new child (all children) of an; element after the element and its old children have already been; projected. This is provided by the following virtual functions in; TEveElement:; void ProjectChild(TEveElement* el, Bool_t sameDepth=kTRUE);; void ProjectAllChildren(Bool_t same_depth=kTRUE);. Several improvements in drawing of TEveCalo axes and labels.; TEveTrackPropagator. Fix some issues with Runge-Kutta track; propagator. Move in controls specifying how to plot tracks that get; split in RhoZ projection.; Fix rendering of TEveJetCone: normals at apex were not changing as they should.; Support single-color for TEveDigitSet (call TEveDigitSet::UseSingleColor()).; Always add chil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v528/index.html:5678,perform,performance,5678,graf3d/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v528/index.html,1,['perform'],['performance']
Performance,"tore atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 3. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc1=1; store atomic release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:308622,perform,performing,308622,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"tore i32 %val0, ptr %ptr0, align 4; store i32 %val1, ptr %ptr1, align 4; ..; store i32 %val7, ptr %ptr7, align 4. Masked Vector Expanding Load and Compressing Store Intrinsics; -------------------------------------------------------------. LLVM provides intrinsics for expanding load and compressing store operations. Data selected from a vector according to a mask is stored in consecutive memory addresses (compressed store), and vice-versa (expanding load). These operations effective map to ""if (cond.i) a[j++] = v.i"" and ""if (cond.i) v.i = a[j++]"" patterns, respectively. Note that when the mask starts with '1' bits followed by '0' bits, these operations are identical to :ref:`llvm.masked.store <int_mstore>` and :ref:`llvm.masked.load <int_mload>`. .. _int_expandload:. '``llvm.masked.expandload.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. Several values of integer, floating point or pointer data type are loaded from consecutive memory addresses and stored into the elements of a vector according to the mask. ::. declare <16 x float> @llvm.masked.expandload.v16f32 (ptr <ptr>, <16 x i1> <mask>, <16 x float> <passthru>); declare <2 x i64> @llvm.masked.expandload.v2i64 (ptr <ptr>, <2 x i1> <mask>, <2 x i64> <passthru>). Overview:; """""""""""""""""". Reads a number of scalar values sequentially from memory location provided in '``ptr``' and spreads them in a vector. The '``mask``' holds a bit for each vector lane. The number of elements read from memory is equal to the number of '1' bits in the mask. The loaded elements are positioned in the destination vector according to the sequence of '1' and '0' bits in the mask. E.g., if the mask vector is '10010001', ""expandload"" reads 3 values from memory addresses ptr, ptr+1, ptr+2 and places them in lanes 0, 3 and 7 accordingly. The masked-off lanes are filled by elements from the corresponding lanes of the '``passthru``' operand. Arguments:; """""""""""""""""""". The first operand i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:855313,load,loaded,855313,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loaded']
Performance,"tore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :pro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42664,load,loads,42664,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['load'],['loads']
Performance,"tors are:. * ``Ninja`` --- for generating `Ninja <https://ninja-build.org>`_; build files. Most llvm developers use Ninja.; * ``Unix Makefiles`` --- for generating make-compatible parallel makefiles.; * ``Visual Studio`` --- for generating Visual Studio projects and; solutions.; * ``Xcode`` --- for generating Xcode projects. * See the `CMake docs; <https://cmake.org/cmake/help/latest/manual/cmake-generators.7.html>`_; for a more comprehensive list. Some common options:. * ``-DLLVM_ENABLE_PROJECTS='...'`` --- semicolon-separated list of the LLVM; subprojects you'd like to additionally build. Can include any of: clang,; clang-tools-extra, lldb, lld, polly, or cross-project-tests. For example, to build LLVM, Clang, and LLD, use; ``-DLLVM_ENABLE_PROJECTS=""clang;lld""``. * ``-DCMAKE_INSTALL_PREFIX=directory`` --- Specify for *directory* the full; pathname of where you want the LLVM tools and libraries to be installed; (default ``/usr/local``). * ``-DCMAKE_BUILD_TYPE=type`` --- Controls optimization level and debug; information of the build. Valid options for *type* are ``Debug``,; ``Release``, ``RelWithDebInfo``, and ``MinSizeRel``. For more detailed; information see :ref:`CMAKE_BUILD_TYPE <cmake_build_type>`. * ``-DLLVM_ENABLE_ASSERTIONS=ON`` --- Compile with assertion checks enabled; (default is ON for Debug builds, OFF for all other build types). * ``-DLLVM_USE_LINKER=lld`` --- Link with the `lld linker`_, assuming it; is installed on your system. This can dramatically speed up link times; if the default linker is slow. * ``-DLLVM_PARALLEL_{COMPILE,LINK}_JOBS=N`` --- Limit the number of; compile/link jobs running in parallel at the same time. This is; especially important for linking since linking can use lots of memory. If; you run into memory issues building LLVM, try setting this to limit the; maximum number of compile/link jobs running at the same time. * ``cmake --build build [--target <target>]`` or the build system specified; above directly. * The default target ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:2938,optimiz,optimization,2938,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['optimiz'],['optimization']
Performance,"tors for each pass to the containing upper; level pass manager. For example,. .. code-block:: c++. ModulePassManager MPM;; MPM.addPass(createModuleToFunctionPassAdaptor(FunctionPass1()));; MPM.addPass(createModuleToFunctionPassAdaptor(FunctionPass2()));; MPM.run();. will run ``FunctionPass1`` on each function in a module, then run; ``FunctionPass2`` on each function in the module. In contrast,. .. code-block:: c++. ModulePassManager MPM;. FunctionPassManager FPM;; FPM.addPass(FunctionPass1());; FPM.addPass(FunctionPass2());. MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM)));. will run ``FunctionPass1`` and ``FunctionPass2`` on the first function in a; module, then run both passes on the second function in the module, and so on.; This is better for cache locality around LLVM data structures. This similarly; applies for the other IR types, and in some cases can even affect the quality; of optimization. For example, running all loop passes on a loop may cause a; later loop to be able to be optimized more than if each loop pass were run; separately. Inserting Passes into Default Pipelines; =======================================. Rather than manually adding passes to a pass manager, the typical way of; creating a pass manager is to use a ``PassBuilder`` and call something like; ``PassBuilder::buildPerModuleDefaultPipeline()`` which creates a typical; pipeline for a given optimization level. Sometimes either frontends or backends will want to inject passes into the; pipeline. For example, frontends may want to add instrumentation, and target; backends may want to add passes that lower custom intrinsics. For these; cases, ``PassBuilder`` exposes callbacks that allow injecting passes into; certain parts of the pipeline. For example,. .. code-block:: c++. PassBuilder PB;; PB.registerPipelineStartEPCallback([&](ModulePassManager &MPM,; PassBuilder::OptimizationLevel Level) {; MPM.addPass(FooPass());; };. will add ``FooPass`` near the very beginning of the pipeli",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:4884,optimiz,optimized,4884,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['optimiz'],['optimized']
Performance,"tors; may be used to endorse or promote products derived from this software without; specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS; ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED; TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR; PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS; BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE; GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION); HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT; LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY; OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF; SUCH DAMAGE. You are under no obligation whatsoever to provide any bug fixes,; patches, or upgrades to the features, functionality or performance of; the source code (""Enhancements"") to anyone; however, if you choose to; make your Enhancements available either publicly, or directly to; Lawrence Berkeley National Laboratory, without imposing a separate; written license agreement for such Enhancements, then you hereby grant; the following license: a non-exclusive, royalty-free perpetual license; to install, use, modify, prepare derivative works, incorporate into; other computer software, distribute, and sublicense such Enhancements; or derivative works thereof, in binary and source code form. Additional copyright holders; ----------------------------. In addition to LBNL/UC Berkeley, this package contains files copyrighted by; one or more of the following people and organizations, and licensed under; the same conditions (except for some compatible licenses as retained in the; source code):. CERN; Lucio Asnaghi; Torok Attila; Simone Bacchio; Niko Fink; Aaron Jomy; Mac Kolin; Baidyanath Kundu; Toby StClere-Smithe; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/LICENSE.txt:1855,perform,performance,1855,bindings/pyroot/cppyy/CPyCppyy/LICENSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/LICENSE.txt,1,['perform'],['performance']
Performance,"tps://github.com/brendangregg/FlameGraph>`_. To generate output for a flamegraph, a few more options are necessary. - ``--all-stacks`` - Emits all of the stacks.; - ``--stack-format`` - Choose the flamegraph output format 'flame'.; - ``--aggregation-type`` - Choose the metric to graph. You may pipe the command output directly to the flamegraph tool to obtain an; svg file. ::. $ llvm-xray stack xray-log.llc.5rqxkU --instr_map=./bin/llc --stack-format=flame --aggregation-type=time --all-stacks | \; /path/to/FlameGraph/flamegraph.pl > flamegraph.svg. If you open the svg in a browser, mouse events allow exploring the call stacks. Chrome Trace Viewer Visualization; ---------------------------------. We can also generate a trace which can be loaded by the Chrome Trace Viewer; from the same generated trace:. ::. $ llvm-xray convert --symbolize --instr_map=./bin/llc \; --output-format=trace_event xray-log.llc.5rqxkU \; | gzip > llc-trace.txt.gz. From a Chrome browser, navigating to ``chrome:///tracing`` allows us to load; the ``sample-trace.txt.gz`` file to visualize the execution trace. Further Exploration; -------------------. The ``llvm-xray`` tool has a few other subcommands that are in various stages; of being developed. One interesting subcommand that can highlight a few; interesting things is the ``graph`` subcommand. Given for example the following; toy program that we build with XRay instrumentation, we can see how the; generated graph may be a helpful indicator of where time is being spent for the; application. .. code-block:: c++. // sample.cc; #include <iostream>; #include <thread>. [[clang::xray_always_instrument]] void f() {; std::cerr << '.';; }. [[clang::xray_always_instrument]] void g() {; for (int i = 0; i < 1 << 10; ++i) {; std::cerr << '-';; }; }. int main(int argc, char* argv[]) {; std::thread t1([] {; for (int i = 0; i < 1 << 10; ++i); f();; });; std::thread t2([] {; g();; });; t1.join();; t2.join();; std::cerr << '\n';; }. We then build the above with",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:13738,load,load,13738,interpreter/llvm-project/llvm/docs/XRayExample.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst,1,['load'],['load']
Performance,"tput and a chain and we; want to map it into one that just output a chain. The current trick is to select; it into a MERGE_VALUES with the first definition being an implicit_def. The; proper solution is to add new ISD opcodes for the no-output variant. DAG; combiner can then transform the node before it gets to target node selection. Problem #2 is we are adding a whole bunch of x86 atomic instructions when in; fact these instructions are identical to the non-lock versions. We need a way to; add target specific information to target nodes and have this information; carried over to machine instructions. Asm printer (or JIT) can use this; information to add the ""lock"" prefix. //===---------------------------------------------------------------------===//. struct B {; unsigned char y0 : 1;; };. int bar(struct B* a) { return a->y0; }. define i32 @bar(%struct.B* nocapture %a) nounwind readonly optsize {; %1 = getelementptr inbounds %struct.B* %a, i64 0, i32 0; %2 = load i8* %1, align 1; %3 = and i8 %2, 1; %4 = zext i8 %3 to i32; ret i32 %4; }. bar: # @bar; # %bb.0:; movb (%rdi), %al; andb $1, %al; movzbl %al, %eax; ret. Missed optimization: should be movl+andl. //===---------------------------------------------------------------------===//. The x86_64 abi says:. Booleans, when stored in a memory object, are stored as single byte objects the; value of which is always 0 (false) or 1 (true). We are not using this fact:. int bar(_Bool *a) { return *a; }. define i32 @bar(i8* nocapture %a) nounwind readonly optsize {; %1 = load i8* %a, align 1, !tbaa !0; %tmp = and i8 %1, 1; %2 = zext i8 %tmp to i32; ret i32 %2; }. bar:; movb (%rdi), %al; andb $1, %al; movzbl %al, %eax; ret. GCC produces. bar:; movzbl (%rdi), %eax; ret. //===---------------------------------------------------------------------===//. Take the following C code:; int f(int a, int b) { return (unsigned char)a == (unsigned char)b; }. We generate the following IR with clang:; define i32 @f(i32 %a, i32 %b) nounwind rea",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:35015,load,load,35015,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['load'],['load']
Performance,"tr %struct.ST, <4 x ptr> %s, <4 x i64> %ind1,; <4 x i32> <i32 2, i32 2, i32 2, i32 2>,; <4 x i32> <i32 1, i32 1, i32 1, i32 1>,; <4 x i32> %ind4,; <4 x i64> <i64 13, i64 13, i64 13, i64 13>. getelementptr %struct.ST, <4 x ptr> %s, <4 x i64> %ind1,; i32 2, i32 1, <4 x i32> %ind4, i64 13. Let's look at the C code, where the vector version of ``getelementptr``; makes sense:. .. code-block:: c. // Let's assume that we vectorize the following loop:; double *A, *B; int *C;; for (int i = 0; i < size; ++i) {; A[i] = B[C[i]];; }. .. code-block:: llvm. ; get pointers for 8 elements from array B; %ptrs = getelementptr double, ptr %B, <8 x i32> %C; ; load 8 elements from array B into A; %A = call <8 x double> @llvm.masked.gather.v8f64.v8p0f64(<8 x ptr> %ptrs,; i32 8, <8 x i1> %mask, <8 x double> %passthru). Conversion Operations; ---------------------. The instructions in this category are the conversion instructions; (casting) which all take a single operand and a type. They perform; various bit conversions on the operand. .. _i_trunc:. '``trunc .. to``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = trunc <ty> <value> to <ty2> ; yields ty2. Overview:; """""""""""""""""". The '``trunc``' instruction truncates its operand to the type ``ty2``. Arguments:; """""""""""""""""""". The '``trunc``' instruction takes a value to trunc, and a type to trunc; it to. Both types must be of :ref:`integer <t_integer>` types, or vectors; of the same number of integers. The bit size of the ``value`` must be; larger than the bit size of the destination type, ``ty2``. Equal sized; types are not allowed. Semantics:; """""""""""""""""""". The '``trunc``' instruction truncates the high order bits in ``value``; and converts the remaining bits to ``ty2``. Since the source size must; be larger than the destination size, ``trunc`` cannot be a *no-op cast*.; It will always truncate bits. Example:; """""""""""""""". .. code-block:: llvm. %X = trunc i32 257 to i8 ; yields i8:1; %Y = trunc i32 123 to i1 ; yields i1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:441999,perform,perform,441999,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"tr; %ptr = alloca i32, i32 4 ; yields ptr; %ptr = alloca i32, i32 4, align 1024 ; yields ptr; %ptr = alloca i32, align 1024 ; yields ptr. .. _i_load:. '``load``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = load [volatile] <ty>, ptr <pointer>[, align <alignment>][, !nontemporal !<nontemp_node>][, !invariant.load !<empty_node>][, !invariant.group !<empty_node>][, !nonnull !<empty_node>][, !dereferenceable !<deref_bytes_node>][, !dereferenceable_or_null !<deref_bytes_node>][, !align !<align_node>][, !noundef !<empty_node>]; <result> = load atomic [volatile] <ty>, ptr <pointer> [syncscope(""<target-scope>"")] <ordering>, align <alignment> [, !invariant.group !<empty_node>]; !<nontemp_node> = !{ i32 1 }; !<empty_node> = !{}; !<deref_bytes_node> = !{ i64 <dereferenceable_bytes> }; !<align_node> = !{ i64 <value_alignment> }. Overview:; """""""""""""""""". The '``load``' instruction is used to read from memory. Arguments:; """""""""""""""""""". The argument to the ``load`` instruction specifies the memory address from which; to load. The type specified must be a :ref:`first class <t_firstclass>` type of; known size (i.e. not containing an :ref:`opaque structural type <t_opaque>`). If; the ``load`` is marked as ``volatile``, then the optimizer is not allowed to; modify the number or order of execution of this ``load`` with other; :ref:`volatile operations <volatile>`. If the ``load`` is marked as ``atomic``, it takes an extra :ref:`ordering; <ordering>` and optional ``syncscope(""<target-scope>"")`` argument. The; ``release`` and ``acq_rel`` orderings are not valid on ``load`` instructions.; Atomic loads produce :ref:`defined <memmodel>` results when they may see; multiple atomic stores. The type of the pointee must be an integer, pointer, or; floating-point type whose bit width is a power of two greater than or equal to; eight and less than or equal to a target-specific size limit. ``align`` must be; explicitly specified on atomic loads. Note: if the alignment is not grea",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:412650,load,load,412650,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['load'],['load']
Performance,"trace_LIBFILE}); set(system_libs ${system_libs} ${Backtrace_LIBFILE}); endif(); if( LLVM_ENABLE_TERMINFO ); set(imported_libs ${imported_libs} Terminfo::terminfo); endif(); set(system_libs ${system_libs} ${LLVM_ATOMIC_LIB}); set(system_libs ${system_libs} ${LLVM_PTHREAD_LIB}); if( UNIX AND NOT (BEOS OR HAIKU) ); set(system_libs ${system_libs} m); endif(); if( UNIX AND ${CMAKE_SYSTEM_NAME} MATCHES ""SunOS"" ); set(system_libs ${system_libs} kstat socket); endif(); if( FUCHSIA ); set(system_libs ${system_libs} zircon); endif(); if ( HAIKU ); add_compile_definitions(_BSD_SOURCE); set(system_libs ${system_libs} bsd network); endif(); endif( MSVC OR MINGW ). # Delay load shell32.dll if possible to speed up process startup.; set (delayload_flags); if (MSVC); # When linking with Swift, `swiftc.exe` is used as the linker drive rather; # than invoking `link.exe` directly. In such a case, the flags should be; # marked as `-Xlinker` to pass them directly to the linker. As a temporary; # workaround simply elide the delay loading.; set (delayload_flags $<$<NOT:$<LINK_LANGUAGE:Swift>>:delayimp -delayload:shell32.dll -delayload:ole32.dll>); endif(). # Link Z3 if the user wants to build it.; if(LLVM_WITH_Z3); set(system_libs ${system_libs} ${Z3_LIBRARIES}); endif(). # Override the C runtime allocator on Windows and embed it into LLVM tools & libraries; if(LLVM_INTEGRATED_CRT_ALLOC); if (NOT CMAKE_MSVC_RUNTIME_LIBRARY OR CMAKE_MSVC_RUNTIME_LIBRARY MATCHES ""DLL$""); message(FATAL_ERROR ""LLVM_INTEGRATED_CRT_ALLOC only works with CMAKE_MSVC_RUNTIME_LIBRARY set to MultiThreaded or MultiThreadedDebug.""); endif(). string(REGEX REPLACE ""(/|\\\\)$"" """" LLVM_INTEGRATED_CRT_ALLOC ""${LLVM_INTEGRATED_CRT_ALLOC}""). if(NOT EXISTS ""${LLVM_INTEGRATED_CRT_ALLOC}""); message(FATAL_ERROR ""Cannot find the path to `git clone` for the CRT allocator! (${LLVM_INTEGRATED_CRT_ALLOC}). Currently, rpmalloc, snmalloc and mimalloc are supported.""); endif(). if(LLVM_INTEGRATED_CRT_ALLOC MATCHES ""rpmalloc$""); add_compil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/CMakeLists.txt:3269,load,loading,3269,interpreter/llvm-project/llvm/lib/Support/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/CMakeLists.txt,1,['load'],['loading']
Performance,"tracking a declaration and a path; of fields and indices into that allocation.; * **TargetPointer**: represents a target address derived from a base address; through pointer arithmetic, such as ``((int *)0x100)[20]``. Null pointers are; target pointers with a zero offset.; * **TypeInfoPointer**: tracks information for the opaque type returned by; ``typeid``; * **InvalidPointer**: is dummy pointer created by an invalid operation which; allows the interpreter to continue execution. Does not allow pointer; arithmetic or dereferencing. Besides the previously mentioned union, a number of other pointer-like types; have their own type:. * **ObjCBlockPointer** tracks Objective-C blocks; * **FnPointer** tracks functions and lazily caches their compiled version; * **MemberPointer** tracks C++ object members. Void pointers, which can be built by casting any of the aforementioned; pointers, are implemented as a union of all pointer types. The ``BitCast``; opcode is responsible for performing all legal conversions between these; types and primitive integers. BlockPointer; ~~~~~~~~~~~~. Block pointers track a ``Pointee``, the block to which they point, along; with a ``Base`` and an ``Offset``. The base identifies the innermost field,; while the offset points to an array element relative to the base (including; one-past-end pointers). The offset identifies the array element or field; which is referenced, while the base points to the outer object or array which; contains the field. These two fields allow all pointers to be uniquely; identified, disambiguated and characterised. As an example, consider the following structure:. .. code-block:: c. struct A {; struct B {; int x;; int y;; } b;; struct C {; int a;; int b;; } c[2];; int z;; };; constexpr A a;. On the target, ``&a`` and ``&a.b.x`` are equal. So are ``&a.c[0]`` and; ``&a.c[0].a``. In the interpreter, all these pointers must be; distinguished since the are all allowed to address distinct range of; memory. In the interpreter, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst:10087,perform,performing,10087,interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,1,['perform'],['performing']
Performance,"tradicting assumptions, this can lead to arbitrary; miscompilations. See `issue #44218; <https://github.com/llvm/llvm-project/issues/44218>`_.; - x86-32 (even with SSE2 enabled) may implicitly perform such a conversion on; values returned from a function for some calling conventions. See `issue; #66803 <https://github.com/llvm/llvm-project/issues/66803>`_.; - Older MIPS versions use the opposite polarity for the quiet/signaling bit, and; LLVM does not correctly represent this. See `issue #60796; <https://github.com/llvm/llvm-project/issues/60796>`_. .. _fastmath:. Fast-Math Flags; ---------------. LLVM IR floating-point operations (:ref:`fneg <i_fneg>`, :ref:`fadd <i_fadd>`,; :ref:`fsub <i_fsub>`, :ref:`fmul <i_fmul>`, :ref:`fdiv <i_fdiv>`,; :ref:`frem <i_frem>`, :ref:`fcmp <i_fcmp>`), :ref:`phi <i_phi>`,; :ref:`select <i_select>` and :ref:`call <i_call>`; may use the following flags to enable otherwise unsafe; floating-point transformations. ``nnan``; No NaNs - Allow optimizations to assume the arguments and result are not; NaN. If an argument is a nan, or the result would be a nan, it produces; a :ref:`poison value <poisonvalues>` instead. ``ninf``; No Infs - Allow optimizations to assume the arguments and result are not; +/-Inf. If an argument is +/-Inf, or the result would be +/-Inf, it; produces a :ref:`poison value <poisonvalues>` instead. ``nsz``; No Signed Zeros - Allow optimizations to treat the sign of a zero; argument or zero result as insignificant. This does not imply that -0.0; is poison and/or guaranteed to not exist in the operation. ``arcp``; Allow Reciprocal - Allow optimizations to use the reciprocal of an; argument rather than perform division. ``contract``; Allow floating-point contraction (e.g. fusing a multiply followed by an; addition into a fused multiply-and-add). This does not enable reassociating; to form arbitrary contractions. For example, ``(a*b) + (c*d) + e`` can not; be transformed into ``(a*b) + ((c*d) + e)`` to create two fma operat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:161848,optimiz,optimizations,161848,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"transformations. When creating; a matrix or a translation, this is by default owned by external objects.; The manager class becomes owner of all transformations used for; positioning volumes. In order to force the ownership for other; transformations, one can use TGeoMatrix::RegisterYourself() method. Do; not be therefore surprised that some transformations cannot be found by; name when creating a composite shape for instance if you did not; register them after creation. Logical nodes (positioned volumes) are created and destroyed by the; TGeoVolume class. Physical nodes and their global transformations; are subjected to a caching mechanism due to the sometimes very large; memory requirements of logical graph expansion. The total number of; physical instances of volumes triggers the caching mechanism and the; cache manager is a client of TGeoManager. The manager class also; controls the drawing/checking package (TGeoPainter client). This; is linked with %ROOT graphical libraries loaded on demand in order to; control visualization actions. \anchor GP02; ## Navigation and Tracking. Tracking is the feature allowing the transport of a given particle; knowing its kinematics. A state is determined by any combination of the; position \f$\vec{r}\f$ and direction \f$\vec{n}\f$ with respect to the world; reference frame. The direction \f$\vec{n}\f$ must be a unit vector having as; components the director cosines. The full classification of a given; state will provide the following information: the deepest physical node; containing the position vector, the distance to the closest boundary; along the direction vector, the next physical node after propagating the; current point with this distance and the safety distance to the nearest; boundary. This information allows the propagation of particles inside a; detector geometry by taking into account both geometrical and physical; constraints. We will hereby describe the user interface of `TGeo` to access; tracking functionality. T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:61156,load,loaded,61156,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['load'],['loaded']
Performance,"trated by the fact that the instruction only; spent 1cy in the scheduler's queue. There is a gap of 5 cycles between the write-back stage and the retire event.; That is because instructions must retire in program order, so [1,0] has to wait; for [0,2] to be retired first (i.e., it has to wait until cycle 10). In the example, all instructions are in a RAW (Read After Write) dependency; chain. Register %xmm2 written by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:25482,perform,performance,25482,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['latency', 'perform']","['latency', 'performance']"
Performance,"tremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4663,optimiz,optimizers,4663,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,2,['optimiz'],"['optimize', 'optimizers']"
Performance,"tributions/4596763/) or consult the [RooBatchComupte README](https://github.com/root-project/root/tree/v6-26-00-patches/roofit/batchcompute).; The README also describes how to enable BatchMode support for your own PDFs. ### Parallel calculation of likelihood gradients during fitting; This release features two new optional RooFit libraries: `RooFit::MultiProcess` and `RooFit::TestStatistics`.; To activate both, build with `-Droofit_multiprocess=ON`. The `RooFit::TestStatistics` namespace contains a major refactoring of the `RooAbsTestStatistic`-`RooAbsOptTestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;; 2. calculation/evaluation/optimization based classes on the other hand. The main selling point of using `RooFit::TestStatistics` from a performance point of view is the implementation of the `RooFit::MultiProcess` based `LikelihoodGradientJob` calculator class.; To use it to perform a ""migrad"" fit (using Minuit2), one should create a `RooMinimizer` using a new constructor with a `RooAbsL` likelihood parameter as follows:. ```c++; using RooFit::TestStatistics::RooAbsL;; using RooFit::TestStatistics::buildLikelihood;. RooAbsPdf* pdf = ...; // build a pdf; RooAbsData* data = ...; // get some data. std::shared_ptr<RooAbsL> likelihood = buildLikelihood(pdf, data, [OPTIONAL ARGUMENTS]);. RooMinimizer m(likelihood);; m.migrad();; ```. The `RooMinimizer` object behaves as usual, except that behind the scenes it will now calculate each partial derivative on a separate process, ideally running on a separate CPU core.; This can be used to speed up fits with many parameters (at least as many as there are cores to parallelize over), since every parameter corresponds to a partial derivative.; The resulting fit parameters will be identical to those obtained with the non-parallelized gradients minimizer in most cases (see the usage notes linked below for exceptions). In upcoming releases, further developments are planned:. - Benchmark/pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:17149,perform,perform,17149,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['perform'],['perform']
Performance,"trinsic. ::. ; Insert fixed type into scalable type; declare <vscale x 4 x float> @llvm.vector.insert.nxv4f32.v4f32(<vscale x 4 x float> %vec, <4 x float> %subvec, i64 <idx>); declare <vscale x 2 x double> @llvm.vector.insert.nxv2f64.v2f64(<vscale x 2 x double> %vec, <2 x double> %subvec, i64 <idx>). ; Insert scalable type into scalable type; declare <vscale x 4 x float> @llvm.vector.insert.nxv4f64.nxv2f64(<vscale x 4 x float> %vec, <vscale x 2 x float> %subvec, i64 <idx>). ; Insert fixed type into fixed type; declare <4 x double> @llvm.vector.insert.v4f64.v2f64(<4 x double> %vec, <2 x double> %subvec, i64 <idx>). Overview:; """""""""""""""""". The '``llvm.vector.insert.*``' intrinsics insert a vector into another vector; starting from a given index. The return type matches the type of the vector we; insert into. Conceptually, this can be used to build a scalable vector out of; non-scalable vectors, however this intrinsic can also be used on purely fixed; types. Scalable vectors can only be inserted into other scalable vectors. Arguments:; """""""""""""""""""". The ``vec`` is the vector which ``subvec`` will be inserted into.; The ``subvec`` is the vector that will be inserted. ``idx`` represents the starting element number at which ``subvec`` will be; inserted. ``idx`` must be a constant multiple of ``subvec``'s known minimum; vector length. If ``subvec`` is a scalable vector, ``idx`` is first scaled by; the runtime scaling factor of ``subvec``. The elements of ``vec`` starting at; ``idx`` are overwritten with ``subvec``. Elements ``idx`` through (``idx`` +; num_elements(``subvec``) - 1) must be valid ``vec`` indices. If this condition; cannot be determined statically but is false at runtime, then the result vector; is a :ref:`poison value <poisonvalues>`. '``llvm.vector.extract``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. ; Extract fixed type from scalable type; declare <4 x float> @llvm.vector.extract.v4f32.nxv4f32(<vscale",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:663382,scalab,scalable,663382,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance,"trinsics take both pointers as separate arguments for completeness. In; this snippet, ``%object`` is the object pointer, and ``%derived`` is the derived; pointer:. .. code-block:: llvm. ;; An array type.; %class.Array = type { %class.Object, i32, [0 x %class.Object*] }; ... ;; Load the object pointer from a gcroot.; %object = load %class.Array** %object_addr. ;; Compute the derived pointer.; %derived = getelementptr %object, i32 0, i32 2, i32 %n. LLVM does not enforce this relationship between the object and derived pointer; (although a particular :ref:`collector strategy <plugin>` might). However, it; would be an unusual collector that violated it. The use of these intrinsics is naturally optional if the target GC does not; require the corresponding barrier. The GC strategy used with such a collector; should replace the intrinsic calls with the corresponding ``load`` or; ``store`` instruction if they are used. One known deficiency with the current design is that the barrier intrinsics do; not include the size or alignment of the underlying operation performed. It is; currently assumed that the operation is of pointer size and the alignment is; assumed to be the target machine's default alignment. Write barrier: ``llvm.gcwrite``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.gcwrite(i8* %value, i8* %object, i8** %derived). For write barriers, LLVM provides the ``llvm.gcwrite`` intrinsic function. It; has exactly the same semantics as a non-volatile ``store`` to the derived; pointer (the third argument). The exact code generated is specified by the; Function's selected :ref:`GC strategy <plugin>`. Many important algorithms require write barriers, including generational and; concurrent collectors. Additionally, write barriers could be used to implement; reference counting. Read barrier: ``llvm.gcread``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. i8* @llvm.gcread(i8* %object, i8** %derived). For read barriers, LLVM provides the ``llvm.gcrea",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:14483,perform,performed,14483,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['perform'],['performed']
Performance,"trivial to destroy exists at that location, the program has; undefined behavior. .. admonition:: Rationale. While these rules are far less fine-grained than C++, they are; nonetheless sufficient to express a wide spectrum of types.; Types that express some sort of ownership will generally be non-trivial; to both copy and destroy and either non-trivial or illegal to; default-initialize. Types that don't express ownership may still; be non-trivial to copy because of some sort of address sensitivity;; for example, a relative reference. Distinguishing default; initialization allows types to impose policies about how they are; created. These rules assume that assignment into an l-value is always a; modification of an existing object rather than an initialization.; Assignment is then a compound operation where the old value is; read and destroyed, if necessary, and the new value is put into; place. These are the natural semantics of value propagation, where; all basic operations on the type come down to copies and destroys,; and everything else is just an optimization on top of those. The most glaring weakness of programming with non-trivial types in C; is that there are no language mechanisms (akin to C++'s placement; ``new`` and explicit destructor calls) for explicitly creating and; destroying objects. Clang should consider adding builtins for this; purpose, as well as for common optimizations like destructive; relocation. Application of the formal C rules to nontrivial ownership qualifiers; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Nontrivially ownership-qualified types are considered non-trivial; to copy, destroy, and default-initialize. A dynamic object of nontrivially ownership-qualified type contingently; exists at a location if the memory is filled with a zero pattern, e.g.; by ``calloc`` or ``bzero``. Such an object can be safely accessed in; all of the cases above, but its memory can also be safely repurposed.; Assigning a null point",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:59290,optimiz,optimization,59290,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimization']
Performance,"trix=gGeoIdentity); ```. The objects referencing a volume and a transformation are called `NODES`; and their creation is fully handled by the modeller. They represent the; link elements in the hierarchy of volumes. Nodes are unique and distinct; geometrical objects ONLY from their container point of view. Since; volumes can be replicated in the geometry, the same node may be found on; different branches. In order to provide navigation features, volumes have to be able to find; the proper container of any point defined in the local reference frame.; This can be the volume itself, one of its positioned daughter volumes or; none if the point is actually outside. On the other hand, volumes have; to provide also other navigation methods such as finding the distances; to its shape boundaries or which daughter will be crossed first. The; implementation of these features is done at shape level, but the local; mother-daughters management is handled by volumes. These build; additional optimization structures upon geometry closure. In order to; have navigation features properly working one has to follow some rules; for building a valid geometry. - The daughter volume(s) must not extrude the mother shape. They are; allowed however to have a common boundaries.; - The volumes positioned in the same container must not overlap with; each other. They may touch on one boundaries or shape vertex. The daughter nodes of a volume can be also removed or replaced with; other nodes:. ``` {.cpp}; void RemoveNode(TGeoNode* node); TGeoNode*ReplaceNode(TGeoNode* nodeorig, TGeoShape* newshape = 0,; TGeoMatrix* newpos = 0, TGeoMedium* newmed = 0); ```. The last method allows replacing an existing daughter of a volume with; another one. Providing only the node to be replaced will just create a; new volume for the node but having exactly the same parameters as the; old one. This helps in case of divisions for decoupling a node from the; logical hierarchy so getting new content/properties. For non-di",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:68511,optimiz,optimization,68511,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['optimiz'],['optimization']
Performance,"trix=gGeoIdentity); ~~~. The objects referencing a volume and a transformation are called `NODES`; and their creation is fully handled by the modeller. They represent the; link elements in the hierarchy of volumes. Nodes are unique and distinct; geometrical objects ONLY from their container point of view. Since; volumes can be replicated in the geometry, the same node may be found on; different branches. In order to provide navigation features, volumes have to be able to find; the proper container of any point defined in the local reference frame.; This can be the volume itself, one of its positioned daughter volumes or; none if the point is actually outside. On the other hand, volumes have; to provide also other navigation methods such as finding the distances; to its shape boundaries or which daughter will be crossed first. The; implementation of these features is done at shape level, but the local; mother-daughters management is handled by volumes. These build; additional optimization structures upon geometry closure. In order to; have navigation features properly working one has to follow some rules; for building a valid geometry. - The daughter volume(s) must not extrude the mother shape. They are; allowed however to have a common boundaries.; - The volumes positioned in the same container must not overlap with; each other. They may touch on one boundaries or shape vertex. The daughter nodes of a volume can be also removed or replaced with; other nodes:. ~~~{.cpp}; void RemoveNode(TGeoNode* node); TGeoNode*ReplaceNode(TGeoNode* nodeorig, TGeoShape* newshape = 0,; TGeoMatrix* newpos = 0, TGeoMedium* newmed = 0); ~~~. The last method allows replacing an existing daughter of a volume with; another one. Providing only the node to be replaced will just create a; new volume for the node but having exactly the same parameters as the; old one. This helps in case of divisions for decoupling a node from the; logical hierarchy so getting new content/properties. For non-div",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:28932,optimiz,optimization,28932,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['optimiz'],['optimization']
Performance,"trols behavior of L2 cache. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; slc Set slc bit to 1.; ======================================== ================================================. .. _amdgpu_synid_tfe:. tfe; ~~~. Controls access to partially resident textures. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; tfe Set tfe bit to 1.; ======================================== ================================================. .. _amdgpu_synid_sc0:. sc0; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`sc1<amdgpu_synid_sc1>`; to specify cache policy. ======================================== ================================================; Syntax Description; ======================================== ================================================; sc0 Set sc0 bit to 1.; ======================================== ================================================. .. _amdgpu_synid_sc1:. sc1; ~~~. This modifier is used together with :ref:`sc0<amdgpu_synid_sc0>` to specify cache; policy. ======================================== ================================================; Syntax Description; ======================================== ================================================; sc1 Set sc1 bit to 1.; ======================================== ================================================. .. _amdgpu_synid_nt:. nt; ~~. Indicates an operation with non-temporal data. ======================================== ================================================; Syntax Description; ======",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:20125,cache,cache,20125,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,1,['cache'],['cache']
Performance,"tronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all inst",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:229326,load,load,229326,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,"['cache', 'load']","['cache', 'load']"
Performance,"tructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forward",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39935,load,load,39935,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['load'],['load']
Performance,"tructor; and destructor that initializes and destroys the global iostream objects; before they could possibly be used in the file. The code that you see in the; ``.ll`` file corresponds to the constructor and destructor registration code. If you would like to make it easier to *understand* the LLVM code generated; by the compiler in the demo page, consider using ``printf()`` instead of; ``iostream``\s to print values. Where did all of my code go??; -----------------------------; If you are using the LLVM demo page, you may often wonder what happened to; all of the code that you typed in. Remember that the demo script is running; the code through the LLVM optimizers, so if your code doesn't actually do; anything useful, it might all be deleted. To prevent this, make sure that the code is actually needed. For example, if; you are computing some expression, return the value from the function instead; of leaving it in a local variable. If you really want to constrain the; optimizer, you can read from and assign to ``volatile`` global variables. What is this ""``undef``"" thing that shows up in my code?; --------------------------------------------------------; ``undef`` is the LLVM way of representing a value that is not defined. You; can get these if you do not initialize a variable before you use it. For; example, the C function:. .. code-block:: c. int X() { int i; return i; }. Is compiled to ""``ret i32 undef``"" because ""``i``"" never has a value specified; for it. Why does instcombine + simplifycfg turn a call to a function with a mismatched calling convention into ""unreachable""? Why not make the verifier reject it?; ----------------------------------------------------------------------------------------------------------------------------------------------------------; This is a common problem run into by authors of front-ends that are using; custom calling conventions: you need to make sure to set the right calling; convention on both the function and on each call to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:8520,optimiz,optimizer,8520,interpreter/llvm-project/llvm/docs/FAQ.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst,1,['optimiz'],['optimizer']
Performance,"true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass managers are required since they may contain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; attribute, which specifies that optimizations should not be run on the; function. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:7505,optimiz,optimization,7505,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,1,['optimiz'],['optimization']
Performance,"trumenting code with sanitizers, it can be important to skip certain; functions to ensure no instrumentation is applied to them. This attribute is not always similar to absent ``sanitize_<name>``; attributes: depending on the specific sanitizer, code can be inserted into; functions regardless of the ``sanitize_<name>`` attribute to prevent false; positive reports. ``disable_sanitizer_instrumentation`` disables all kinds of instrumentation,; taking precedence over the ``sanitize_<name>`` attributes and other compiler; flags.; ``""dontcall-error""``; This attribute denotes that an error diagnostic should be emitted when a; call of a function with this attribute is not eliminated via optimization.; Front ends can provide optional ``srcloc`` metadata nodes on call sites of; such callees to attach information about where in the source language such a; call came from. A string value can be provided as a note.; ``""dontcall-warn""``; This attribute denotes that a warning diagnostic should be emitted when a; call of a function with this attribute is not eliminated via optimization.; Front ends can provide optional ``srcloc`` metadata nodes on call sites of; such callees to attach information about where in the source language such a; call came from. A string value can be provided as a note.; ``fn_ret_thunk_extern``; This attribute tells the code generator that returns from functions should; be replaced with jumps to externally-defined architecture-specific symbols.; For X86, this symbol's identifier is ``__x86_return_thunk``.; ``""frame-pointer""``; This attribute tells the code generator whether the function; should keep the frame pointer. The code generator may emit the frame pointer; even if this attribute says the frame pointer can be eliminated.; The allowed string values are:. * ``""none""`` (default) - the frame pointer can be eliminated.; * ``""non-leaf""`` - the frame pointer should be kept if the function calls; other functions.; * ``""all""`` - the frame pointer should be ke",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:82533,optimiz,optimization,82533,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance,"try block guarantees that the alloca is only; executed once, which makes analysis simpler.; #. mem2reg only promotes allocas whose uses are direct loads and stores.; If the address of the stack object is passed to a function, or if any; funny pointer arithmetic is involved, the alloca will not be; promoted.; #. mem2reg only works on allocas of `first; class <../../LangRef.html#first-class-types>`_ values (such as pointers,; scalars and vectors), and only if the array size of the allocation is; 1 (or missing in the .ll file). mem2reg is not capable of promoting; structs or arrays to registers. Note that the ""sroa"" pass is; more powerful and can promote structs, ""unions"", and arrays in many; cases. All of these properties are easy to satisfy for most imperative; languages, and we'll illustrate it below with Kaleidoscope. The final; question you may be asking is: should I bother with this nonsense for my; front-end? Wouldn't it be better if I just did SSA construction; directly, avoiding use of the mem2reg optimization pass? In short, we; strongly recommend that you use this technique for building SSA form,; unless there is an extremely good reason not to. Using this technique; is:. - Proven and well tested: clang uses this technique; for local mutable variables. As such, the most common clients of LLVM; are using this to handle a bulk of their variables. You can be sure; that bugs are found fast and fixed early.; - Extremely Fast: mem2reg has a number of special cases that make it; fast in common cases as well as fully general. For example, it has; fast-paths for variables that are only used in a single block,; variables that only have one assignment point, good heuristics to; avoid insertion of unneeded phi nodes, etc.; - Needed for debug info generation: `Debug information in; LLVM <../../SourceLevelDebugging.html>`_ relies on having the address of; the variable exposed so that debug info can be attached to it. This; technique dovetails very naturally with this style",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:9028,optimiz,optimization,9028,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['optimiz'],['optimization']
Performance,"ts and the result have the bitwidth specified; by the name of the builtin. These builtins can be used within constant; expressions. ``__builtin_unreachable``; -------------------------. ``__builtin_unreachable`` is used to indicate that a specific point in the; program cannot be reached, even if the compiler might otherwise think it can.; This is useful to improve optimization and eliminates certain warnings. For; example, without the ``__builtin_unreachable`` in the example below, the; compiler assumes that the inline asm can fall through and prints a ""function; declared '``noreturn``' should not return"" warning. **Syntax**:. .. code-block:: c++. __builtin_unreachable(). **Example of use**:. .. code-block:: c++. void myabort(void) __attribute__((noreturn));; void myabort(void) {; asm(""int3"");; __builtin_unreachable();; }. **Description**:. The ``__builtin_unreachable()`` builtin has completely undefined behavior.; Since it has undefined behavior, it is a statement that it is never reached and; the optimizer can take advantage of this to produce better code. This builtin; takes no arguments and produces a void result. Query for this feature with ``__has_builtin(__builtin_unreachable)``. ``__builtin_unpredictable``; ---------------------------. ``__builtin_unpredictable`` is used to indicate that a branch condition is; unpredictable by hardware mechanisms such as branch prediction logic. **Syntax**:. .. code-block:: c++. __builtin_unpredictable(long long). **Example of use**:. .. code-block:: c++. if (__builtin_unpredictable(x > 0)) {; foo();; }. **Description**:. The ``__builtin_unpredictable()`` builtin is expected to be used with control; flow conditions such as in ``if`` and ``switch`` statements. Query for this feature with ``__has_builtin(__builtin_unpredictable)``. ``__builtin_expect``; --------------------. ``__builtin_expect`` is used to indicate that the value of an expression is; anticipated to be the same as a statically known result. **Syntax**:. .. code-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:113056,optimiz,optimizer,113056,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimizer']
Performance,"ts any inline lock-free atomic operations of a given size, you should; support *ALL* operations of that size in a lock-free manner. When the target implements atomic ``cmpxchg`` or LL/SC instructions (as most do); this is trivial: all the other operations can be implemented on top of those; primitives. However, on many older CPUs (e.g. ARMv5, SparcV8, Intel 80386) there; are atomic load and store instructions, but no ``cmpxchg`` or LL/SC. As it is; invalid to implement ``atomic load`` using the native instruction, but; ``cmpxchg`` using a library call to a function that uses a mutex, ``atomic; load`` must *also* expand to a library call on such architectures, so that it; can remain atomic with regards to a simultaneous ``cmpxchg``, by using the same; mutex. AtomicExpandPass can help with that: it will expand all atomic operations to the; proper ``__atomic_*`` libcalls for any size above the maximum set by; ``setMaxAtomicSizeInBitsSupported`` (which defaults to 0). On x86, all atomic loads generate a ``MOV``. SequentiallyConsistent stores; generate an ``XCHG``, other stores generate a ``MOV``. SequentiallyConsistent; fences generate an ``MFENCE``, other fences do not cause any code to be; generated. ``cmpxchg`` uses the ``LOCK CMPXCHG`` instruction. ``atomicrmw xchg``; uses ``XCHG``, ``atomicrmw add`` and ``atomicrmw sub`` use ``XADD``, and all; other ``atomicrmw`` operations generate a loop with ``LOCK CMPXCHG``. Depending; on the users of the result, some ``atomicrmw`` operations can be translated into; operations like ``LOCK AND``, but that does not work in general. On ARM (before v8), MIPS, and many other RISC architectures, Acquire, Release,; and SequentiallyConsistent semantics require barrier instructions for every such; operation. Loads and stores generate normal instructions. ``cmpxchg`` and; ``atomicrmw`` can be represented using a loop with LL/SC-style instructions; which take some sort of exclusive lock on a cache line (``LDREX`` and ``STREX``; on ARM, etc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:19743,load,loads,19743,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['load'],['loads']
Performance,"ts as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads it into current; process, exposing all external symbols to Cling.; Libraries are located through load paths given to Cling, either through the; ""-L"" compiler flag or the dynamic search path environment variable (system; dependent).; Any method that brings symbols into the process (including normal linking,; e.g. when embedding Python in a C++ application) is suitable to expose; symbols.; An alternative for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` exception is raised.; If a compilation warning occurs, a Python warning is issued. `Configuring Cling`; -------------------. It is often convenient to add additional search paths for Cling to find; headers and libraries when loading a module (Python does not have st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:2588,load,load,2588,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,1,['load'],['load']
Performance,"ts second and third; operands, if they agree in classification, or else the other if one is known; retain-agnostic. If the cast operand is known retained, the conversion is treated as a; ``__bridge_transfer`` cast. If the cast operand is known unretained or known; retain-agnostic, the conversion is treated as a ``__bridge`` cast. .. admonition:: Rationale. Bridging casts are annoying. Absent the ability to completely automate the; management of CF objects, however, we are left with relatively poor attempts; to reduce the need for a glut of explicit bridges. Hence these rules. We've so far consciously refrained from implicitly turning retained CF; results from function calls into ``__bridge_transfer`` casts. The worry is; that some code patterns --- for example, creating a CF value, assigning it; to an ObjC-typed local, and then calling ``CFRelease`` when done --- are a; bit too likely to be accidentally accepted, leading to mysterious behavior. For loads from ``const`` global variables of :ref:`C retainable pointer type; <arc.misc.c-retainable>`, it is reasonable to assume that global system; constants were initialized with true constants (e.g. string literals), but; user constants might have been initialized with something dynamically; allocated, using a global initializer. .. _arc.objects.restrictions.conversion-exception-contextual:. Conversion from retainable object pointer type in certain contexts; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. :when-revised:`[beginning Apple 4.0, LLVM 3.1]`. If an expression of retainable object pointer type is explicitly cast to a; :ref:`C retainable pointer type <arc.misc.c-retainable>`, the program is; ill-formed as discussed above unless the result is immediately used:. * to initialize a parameter in an Objective-C message send where the parameter; is not marked with the ``cf_consumed`` attribute, or; * to initialize a parameter in a direct call to an; :ref:`audited <arc.misc.c-retainable.audit>` funct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:28770,load,loads,28770,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['load'],['loads']
Performance,"ts that pre-populate the CMakeCache in; a build directory with commonly used settings. You can use the caches files with the following CMake invocation:. cmake -G <build system>; -C <path to cache file>; [additional CMake options (i.e. -DCMAKE_INSTALL_PREFIX=<install path>)]; <path to llvm>. Options specified on the command line will override options in the cache files. The following cache files exist. Apple-stage1; ------------. The Apple stage1 cache configures a two stage build similar to how Apple builds; the clang shipped with Xcode. The build files generated from this invocation has; a target named ""stage2"" which performs an LTO build of clang. The Apple-stage2 cache can be used directly to match the build settings Apple; uses in shipping builds without doing a full bootstrap build. PGO; ---. The PGO CMake cache can be used to generate a multi-stage instrumented compiler.; You can configure your build directory with the following invocation of CMake:. cmake -G <generator> -C <path_to_clang>/cmake/caches/PGO.cmake <source dir>. After configuration the following additional targets will be generated:. stage2-instrumented:; Builds a stage1 x86 compiler, runtime, and required tools (llvm-config,; llvm-profdata) then uses that compiler to build an instrumented stage2 compiler. stage2-instrumented-generate-profdata:; Depends on ""stage2-instrumented"" and will use the instrumented compiler to; generate profdata based on the training files in <clang>/utils/perf-training. stage2:; Depends on ""stage2-instrumented-generate-profdata"" and will use the stage1; compiler with the stage2 profdata to build a PGO-optimized compiler. stage2-check-llvm:; Depends on stage2 and runs check-llvm using the stage3 compiler. stage2-check-clang:; Depends on stage2 and runs check-clang using the stage3 compiler. stage2-check-all:; Depends on stage2 and runs check-all using the stage3 compiler. stage2-test-suite:; Depends on stage2 and runs the test-suite using the stage3 compiler (requires; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/cmake/caches/README.txt:1087,cache,caches,1087,interpreter/llvm-project/clang/cmake/caches/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/cmake/caches/README.txt,1,['cache'],['caches']
Performance,"ts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3618,optimiz,optimizations,3618,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,1,['optimiz'],['optimizations']
Performance,"ts, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:3748,perform,performance,3748,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,2,"['optimiz', 'perform']","['optimizes', 'performance']"
Performance,"ts::; :local:. Introduction; ============. This document describes the CommandLine argument processing library. It will; show you how to use it, and what it can do. The CommandLine library uses a; declarative approach to specifying the command line options that your program; takes. By default, these options declarations implicitly hold the value parsed; for the option declared (of course this `can be changed`_). Although there are a **lot** of command line argument parsing libraries out; there in many different languages, none of them fit well with what I needed. By; looking at the features and problems of other libraries, I designed the; CommandLine library to have the following features:. #. Speed: The CommandLine library is very quick and uses little resources. The; parsing time of the library is directly proportional to the number of; arguments parsed, not the number of options recognized. Additionally,; command line argument values are captured transparently into user defined; global variables, which can be accessed like any other variable (and with the; same performance). #. Type Safe: As a user of CommandLine, you don't have to worry about; remembering the type of arguments that you want (is it an int? a string? a; bool? an enum?) and keep casting it around. Not only does this help prevent; error prone constructs, it also leads to dramatically cleaner source code. #. No subclasses required: To use CommandLine, you instantiate variables that; correspond to the arguments that you would like to capture, you don't; subclass a parser. This means that you don't have to write **any**; boilerplate code. #. Globally accessible: Libraries can specify command line arguments that are; automatically enabled in any tool that links to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types di",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:1186,perform,performance,1186,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,1,['perform'],['performance']
Performance,"ts::; :local:; :depth: 2. Introduction; ============. GWP-ASan is a sampled allocator framework that assists in finding use-after-free; and heap-buffer-overflow bugs in production environments. It informally is a; recursive acronym, ""**G**\WP-ASan **W**\ill **P**\rovide **A**\llocation; **SAN**\ity"". GWP-ASan is based on the classic; `Electric Fence Malloc Debugger <https://linux.die.net/man/3/efence>`_, with a; key adaptation. Notably, we only choose a very small percentage of allocations; to sample, and apply guard pages to these sampled allocations only. The sampling; is small enough to allow us to have very low performance overhead. There is a small, tunable memory overhead that is fixed for the lifetime of the; process. This is approximately ~40KiB per process using the default settings,; depending on the average size of your allocations. GWP-ASan vs. ASan; =================. Unlike `AddressSanitizer <https://clang.llvm.org/docs/AddressSanitizer.html>`_,; GWP-ASan does not induce a significant performance overhead. ASan often requires; the use of dedicated canaries to be viable in production environments, and as; such is often impractical. GWP-ASan is only capable of finding a subset of the memory issues detected by; ASan. Furthermore, GWP-ASan's bug detection capabilities are only probabilistic.; As such, we recommend using ASan over GWP-ASan in testing, as well as anywhere; else that guaranteed error detection is more valuable than the 2x execution; slowdown/binary size bloat. For the majority of production environments, this; impact is too high, and GWP-ASan proves extremely useful. Design; ======. **Please note:** The implementation of GWP-ASan is largely in-flux, and these; details are subject to change. There are currently other implementations of; GWP-ASan, such as the implementation featured in; `Chromium <https://cs.chromium.org/chromium/src/components/gwp_asan/>`_. The; long-term support goal is to ensure feature-parity where reasonable, and to; suppo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:1053,perform,performance,1053,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['perform'],['performance']
Performance,"ts; are reasonably small, a ``SmallSet<Type, N>`` is a good choice. This set has; space for N elements in place (thus, if the set is dynamically smaller than N,; no malloc traffic is required) and accesses them with a simple linear search.; When the set grows beyond N elements, it allocates a more expensive; representation that guarantees efficient access (for most types, it falls back; to :ref:`std::set <dss_set>`, but for pointers it uses something far better,; :ref:`SmallPtrSet <dss_smallptrset>`. The magic of this class is that it handles small sets extremely efficiently, but; gracefully handles extremely large sets without loss of efficiency. .. _dss_smallptrset:. llvm/ADT/SmallPtrSet.h; ^^^^^^^^^^^^^^^^^^^^^^. ``SmallPtrSet`` has all the advantages of ``SmallSet`` (and a ``SmallSet`` of; pointers is transparently implemented with a ``SmallPtrSet``). If more than N; insertions are performed, a single quadratically probed hash table is allocated; and grows as needed, providing extremely efficient access (constant time; insertion/deleting/queries with low constant factors) and is very stingy with; malloc traffic. Note that, unlike :ref:`std::set <dss_set>`, the iterators of ``SmallPtrSet``; are invalidated whenever an insertion occurs. Also, the values visited by the; iterators are not visited in sorted order. .. _dss_stringset:. llvm/ADT/StringSet.h; ^^^^^^^^^^^^^^^^^^^^. ``StringSet`` is a thin wrapper around :ref:`StringMap\<char\> <dss_stringmap>`,; and it allows efficient storage and retrieval of unique strings. Functionally analogous to ``SmallSet<StringRef>``, ``StringSet`` also supports; iteration. (The iterator dereferences to a ``StringMapEntry<char>``, so you; need to call ``i->getKey()`` to access the item of the StringSet.) On the; other hand, ``StringSet`` doesn't support range-insertion and; copy-construction, which :ref:`SmallSet <dss_smallset>` and :ref:`SmallPtrSet; <dss_smallptrset>` do support. .. _dss_denseset:. llvm/ADT/DenseSet.h; ^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:78911,perform,performed,78911,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['perform'],['performed']
Performance,"tsForGC_intrinsic_lowering>` for details on GC specific; lowering. Optimizer is allowed to inline memory copy when it's profitable to do so. '``llvm.memmove.element.unordered.atomic``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use; ``llvm.memmove.element.unordered.atomic`` on any integer bit width and for; different address spaces. Not all targets support all bit widths however. ::. declare void @llvm.memmove.element.unordered.atomic.p0.p0.i32(ptr <dest>,; ptr <src>,; i32 <len>,; i32 <element_size>); declare void @llvm.memmove.element.unordered.atomic.p0.p0.i64(ptr <dest>,; ptr <src>,; i64 <len>,; i32 <element_size>). Overview:; """""""""""""""""". The '``llvm.memmove.element.unordered.atomic.*``' intrinsic is a specialization; of the '``llvm.memmove.*``' intrinsic. It differs in that the ``dest`` and; ``src`` are treated as arrays with elements that are exactly ``element_size``; bytes, and the copy between buffers uses a sequence of; :ref:`unordered atomic <ordering>` load/store operations that are a positive; integer multiple of the ``element_size`` in size. Arguments:; """""""""""""""""""". The first three arguments are the same as they are in the; :ref:`@llvm.memmove <int_memmove>` intrinsic, with the added constraint that; ``len`` is required to be a positive integer multiple of the ``element_size``.; If ``len`` is not a positive integer multiple of ``element_size``, then the; behaviour of the intrinsic is undefined. ``element_size`` must be a compile-time constant positive power of two no; greater than a target-specific atomic access size limit. For each of the input pointers the ``align`` parameter attribute must be; specified. It must be a power of two no less than the ``element_size``. Caller; guarantees that both the source and destination pointers are aligned to that; boundary. Semantics:; """""""""""""""""""". The '``llvm.memmove.element.unordered.atomic.*``' intrinsic copies ``len`` bytes; of memory ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:961038,load,load,961038,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"tself is only; concerned with computing addresses. Can array indices be negative?; ------------------------------. Yes. This is basically a special case of array indices being out of bounds. Can I compare two values computed with GEPs?; --------------------------------------------. Yes. If both addresses are within the same allocated object, or; one-past-the-end, you'll get the comparison result you expect. If either is; outside of it, integer arithmetic wrapping may occur, so the comparison may not; be meaningful. Can I do GEP with a different pointer type than the type of the underlying object?; ----------------------------------------------------------------------------------. Yes. There are no restrictions on bitcasting a pointer value to an arbitrary; pointer type. The types in a GEP serve only to define the parameters for the; underlying integer computation. They need not correspond with the actual type of; the underlying object. Furthermore, loads and stores don't have to use the same types as the type of; the underlying object. Types in this context serve only to specify memory size; and alignment. Beyond that there are merely a hint to the optimizer indicating; how the value will likely be used. Can I cast an object's address to integer and add it to null?; -------------------------------------------------------------. You can compute an address that way, but if you use GEP to do the add, you can't; use that pointer to actually access the object, unless the object is managed; outside of LLVM. The underlying integer computation is sufficiently defined; null has a defined; value --- zero --- and you can add whatever value you want to it. However, it's invalid to access (load from or store to) an LLVM-aware object; with such a pointer. This includes ``GlobalVariables``, ``Allocas``, and objects; pointed to by noalias pointers. If you really need this functionality, you can do the arithmetic with explicit; integer instructions, and use inttoptr to convert the r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:15105,load,loads,15105,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['load'],['loads']
Performance,"tted by your pass is still valid and well formed LLVM, which; hasn't been broken somehow. Now that you have seen the basics of the mechanics behind passes, we can talk; about some more details of how they work and how to use them. .. _writing-an-llvm-pass-pass-classes:. Pass classes and requirements; =============================. One of the first things that you should do when designing a new pass is to; decide what class you should subclass for your pass. The :ref:`Hello World; <writing-an-llvm-pass-basiccode>` example uses the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` class for its implementation, but we did; not discuss why or when this should occur. Here we talk about the classes; available, from the most general to the most specific. When choosing a superclass for your ``Pass``, you should choose the **most; specific** class possible, while still being able to meet the requirements; listed. This gives the LLVM Pass Infrastructure information necessary to; optimize how passes are run, so that the resultant compiler isn't unnecessarily; slow. The ``ImmutablePass`` class; ---------------------------. The most plain and boring type of pass is the ""`ImmutablePass; <https://llvm.org/doxygen/classllvm_1_1ImmutablePass.html>`_"" class. This pass; type is used for passes that do not have to be run, do not change state, and; never need to be updated. This is not a normal type of transformation or; analysis, but can provide information about the current compiler configuration. Although this pass class is very infrequently used, it is important for; providing information about the current target machine being compiled for, and; other static information that can affect the various transformations. ``ImmutablePass``\ es never invalidate other transformations, are never; invalidated, and are never ""run"". .. _writing-an-llvm-pass-ModulePass:. The ``ModulePass`` class; ------------------------. The `ModulePass <https://llvm.org/doxygen/classllvm_1_1ModulePass.html",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:11770,optimiz,optimize,11770,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['optimiz'],['optimize']
Performance,"tting it into another is not necessarily easier than re-doing it.; > Optimization code is usually heavily tied in to the specific IR they use. Understood. The only reason that I brought this up is because SGI's IR is; more similar to LLVM than it is different in many respects (SSA based,; relatively low level, etc), and could be easily adapted. Also their; optimizations are written in C++ and are actually somewhat; structured... of course it would be no walk in the park, but it would be; much less time consuming to adapt, say, SSA-PRE than to rewrite it. > But your larger point is valid that adding SSA based optimizations is; > feasible and should be fun. (Again, link time cost is the issue.). Assuming linktime cost wasn't an issue, the question is: ; Does using GCC's backend buy us anything?. > It also occurs to me that GCC is probably doing quite a bit of back-end; > optimization (step 16 in your list). Do you have a breakdown of that?. Not really. The irritating part of GCC is that it mixes it all up and; doesn't have a clean separation of concerns. A lot of the ""back end; optimization"" happens right along with other data optimizations (ie, CSE; of machine specific things). As far as REAL back end optimizations go, it looks something like this:. 1. Instruction combination: try to make CISCy instructions, if available; 2. Register movement: try to get registers in the right places for the; architecture to avoid register to register moves. For example, try to get; the first argument of a function to naturally land in %o0 for sparc.; 3. Instruction scheduling: 'nuff said :); 4. Register class preferencing: ??; 5. Local register allocation; 6. global register allocation; 7. Spilling; 8. Local regalloc; 9. Jump optimization; 10. Delay slot scheduling; 11. Branch shorting for CISC machines; 12. Instruction selection & peephole optimization; 13. Debug info output. But none of this would be usable for LLVM anyways, unless we were using; GCC as a static compiler. -Chris. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt:2088,optimiz,optimization,2088,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,5,['optimiz'],"['optimization', 'optimizations']"
Performance,"ttrDocs.td``, and is; used for documenting user-facing attributes. General BackEnds; ================. Print Records; -------------. The TableGen command option ``--print-records`` invokes a simple backend; that prints all the classes and records defined in the source files. This is; the default backend option. See the :doc:`TableGen Backend Developer's Guide; <./BackGuide>` for more information. Print Detailed Records; ----------------------. The TableGen command option ``--print-detailed-records`` invokes a backend; that prints all the global variables, classes, and records defined in the; source files, with more detail than the default record printer. See the; :doc:`TableGen Backend Developer's Guide <./BackGuide>` for more; information. JSON Reference; --------------. **Purpose**: Output all the values in every ``def``, as a JSON data; structure that can be easily parsed by a variety of languages. Useful; for writing custom backends without having to modify TableGen itself,; or for performing auxiliary analysis on the same TableGen data passed; to a built-in backend. **Output**:. The root of the output file is a JSON object (i.e. dictionary),; containing the following fixed keys:. * ``!tablegen_json_version``: a numeric version field that will; increase if an incompatible change is ever made to the structure of; this data. The format described here corresponds to version 1. * ``!instanceof``: a dictionary whose keys are the class names defined; in the TableGen input. For each key, the corresponding value is an; array of strings giving the names of ``def`` records that derive; from that class. So ``root[""!instanceof""][""Instruction""]``, for; example, would list the names of all the records deriving from the; class ``Instruction``. For each ``def`` record, the root object also has a key for the record; name. The corresponding value is a subsidiary object containing the; following fixed keys:. * ``!superclasses``: an array of strings giving the names of all the; clas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst:15069,perform,performing,15069,interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,1,['perform'],['performing']
Performance,"tual register to a; physical one, use ``VirtRegMap::assignVirt2Phys(vreg, preg)``. In order to map; a certain virtual register to memory, use; ``VirtRegMap::assignVirt2StackSlot(vreg)``. This method will return the stack; slot where ``vreg``'s value will be located. If it is necessary to map another; virtual register to the same stack slot, use; ``VirtRegMap::assignVirt2StackSlot(vreg, stack_location)``. One important point; to consider when using the indirect mapping, is that even if a virtual register; is mapped to memory, it still needs to be mapped to a physical register. This; physical register is the location where the virtual register is supposed to be; found before being stored or after being reloaded. If the indirect strategy is used, after all the virtual registers have been; mapped to physical registers or stack slots, it is necessary to use a spiller; object to place load and store instructions in the code. Every virtual that has; been mapped to a stack slot will be stored to memory after being defined and will; be loaded before being used. The implementation of the spiller tries to recycle; load/store instructions, avoiding unnecessary instructions. For an example of; how to invoke the spiller, see ``RegAllocLinearScan::runOnMachineFunction`` in; ``lib/CodeGen/RegAllocLinearScan.cpp``. Handling two address instructions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. With very rare exceptions (e.g., function calls), the LLVM machine code; instructions are three address instructions. That is, each instruction is; expected to define at most one register, and to use at most two registers.; However, some architectures use two address instructions. In this case, the; defined register is also one of the used registers. For instance, an instruction; such as ``ADD %EAX, %EBX``, in X86 is actually equivalent to ``%EAX = %EAX +; %EBX``. In order to produce correct code, LLVM must convert three address instructions; that represent two address instructions into true two address",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:66116,load,loaded,66116,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['load'],['loaded']
Performance,"tunable parameters are the ones related; to the operating and window system, to the fonts to be used, to the; location of start-up files. At start-up, ROOT looks for a `.rootrc` file; in the following order:. - `./.rootrc //local directory`. - `$HOME/.rootrc //user directory`. - `$ROOTSYS/etc/system.rootrc //global ROOT directory`. If more than one `.rootrc` files are found in the search paths above,; the options are merged, with precedence local, user, global. The parsing; and interpretation of this file is handled by the ROOT class `TEnv`.; Have a look to its documentation if you need such rather advanced; features. The file `.rootrc` defines the location of two rather; important files inspected at start-up: `rootalias.C` and `rootlogon.C`.; They can contain code that needs to be loaded and executed at ROOT; startup. `rootalias.C` is only loaded and best used to define some often; used functions. `rootlogon.C` contains code that will be executed at; startup: this file is extremely useful for example to pre-load a custom; style for the plots created with ROOT. This is done most easily by; creating a new `TStyle` object with your preferred settings, as; described in the class reference guide, and then use the command; `gROOT->SetStyle(""MyStyleName"");` to make this new style definition the; default one. As an example, have a look in the file `rootlogon.C` coming; with this tutorial. Another relevant file is `rootlogoff.C` that it; called when the session is finished. ### ROOT command history ###. Every command typed at the ROOT prompt is stored in a file `.root_hist`; in your home directory. ROOT uses this file to allow for navigation in; the command history with the up-arrow and down-arrow keys. It is also; convenient to extract successful ROOT commands with the help of a text; editor for use in your own macros. ### ROOT Global Pointers ###. All global pointers in ROOT begin with a small ""g"". Some of them were; already implicitly introduced (for example in the secti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md:19039,load,load,19039,documentation/primer/ROOT_as_calculator.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md,1,['load'],['load']
Performance,"tures from OpenMP 5.0 and 5.1; see `OpenMP implementation details`_ and `OpenMP 51 implementation details`_. General improvements; ====================; - New collapse clause scheme to avoid expensive remainder operations.; Compute loop index variables after collapsing a loop nest via the; collapse clause by replacing the expensive remainder operation with; multiplications and additions. - When using the collapse clause on a loop nest the default behavior; is to automatically extend the representation of the loop counter to; 64 bits for the cases where the sizes of the collapsed loops are not; known at compile time. To prevent this conservative choice and use; at most 32 bits, compile your program with the; `-fopenmp-optimistic-collapse`. GPU devices support; ===================. Data-sharing modes; ------------------. Clang supports two data-sharing models for Cuda devices: `Generic` and `Cuda`; modes. The default mode is `Generic`. `Cuda` mode can give an additional; performance and can be activated using the `-fopenmp-cuda-mode` flag. In; `Generic` mode all local variables that can be shared in the parallel regions; are stored in the global memory. In `Cuda` mode local variables are not shared; between the threads and it is user responsibility to share the required data; between the threads in the parallel regions. Often, the optimizer is able to; reduce the cost of `Generic` mode to the level of `Cuda` mode, but the flag,; as well as other assumption flags, can be used for tuning. Features not supported or with limited support for Cuda devices; ---------------------------------------------------------------. - Cancellation constructs are not supported. - Doacross loop nest is not supported. - User-defined reductions are supported only for trivial types. - Nested parallelism: inner parallel regions are executed sequentially. - Debug information for OpenMP target regions is supported, but sometimes it may; be required to manually specify the address class of the i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst:1678,perform,performance,1678,interpreter/llvm-project/clang/docs/OpenMPSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst,1,['perform'],['performance']
Performance,"turing a send of; ``retain`` followed by a send of ``release`` to the same object, with no; intervening ``release`` on that object, is not equivalent under the high-level; semantics to a computation history in which these sends are removed. Note that; this implies that these methods may not raise exceptions. It is undefined behavior if a computation history features any use whatsoever; of an object following the completion of a send of ``release`` that is not; preceded by a send of ``retain`` to the same object. The behavior of ``autorelease`` must be equivalent to sending ``release`` when; one of the autorelease pools currently in scope is popped. It may not throw an; exception. When the semantics call for performing one of these operations on a retainable; object pointer, if that pointer is ``null`` then the effect is a no-op. All of the semantics described in this document are subject to additional; :ref:`optimization rules <arc.optimization>` which permit the removal or; optimization of operations based on local knowledge of data flow. The; semantics describe the high-level behaviors that the compiler implements, not; an exact sequence of operations that a program will be compiled into. .. _arc.objects.operands:. Retainable object pointers as operands and arguments; ----------------------------------------------------. In general, ARC does not perform retain or release operations when simply using; a retainable object pointer as an operand within an expression. This includes:. * loading a retainable pointer from an object with non-weak :ref:`ownership; <arc.ownership>`,; * passing a retainable pointer as an argument to a function or method, and; * receiving a retainable pointer as the result of a function or method call. .. admonition:: Rationale. While this might seem uncontroversial, it is actually unsafe when multiple; expressions are evaluated in ""parallel"", as with binary operators and calls,; because (for example) one expression might load from an object wh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:15090,optimiz,optimization,15090,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,2,['optimiz'],['optimization']
Performance,"turn since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also; causes it to be treated as non-volatile and so is not invalidated by; ``*_vol``.; * On APU the kernarg backing memory it is accessed as MTYPE CC (cache coherent); and so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory Model Code Sequences GFX6-GFX9; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX6-GFX9; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:211253,cache,cache,211253,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"tween. .. code-block:: c. typedef struct {; int *__counted_by(count) buf; size_t count;; } sized_buf_t;. void alloc_buf(sized_buf_t *sbuf, sized_t nelems) {; sbuf->buf = (int *)malloc(sizeof(int) * nelems);; sbuf->count = nelems;; }. To implement this rule, the compiler requires a linear representation of; statements to understand the ordering and the adjacency between the two or more; assignments. The Clang CFG is used to implement this analysis as Clang CFG; provides a linear view of statements within each ``CFGBlock`` (Clang; ``CFGBlock`` represents a single basic block in a source-level CFG). Bounds check optimizations; ==========================. In ``-fbounds-safety``, the Clang frontend emits run-time checks for every; memory dereference if the type system or analyses in the frontend couldn’t; verify its bounds safety. The implementation relies on LLVM optimizations to; remove redundant run-time checks. Using this optimization strategy, if the; original source code already has bounds checks, the fewer additional checks; ``-fbounds-safety`` will introduce. The LLVM ``ConstraintElimination`` pass is; design to remove provable redundant checks (please check Florian Hahn’s; presentation in 2021 LLVM Dev Meeting and the implementation to learn more). In; the following example, ``-fbounds-safety`` implicitly adds the redundant bounds; checks that the optimizer can remove:. .. code-block:: c. void fill_array_with_indices(int *__counted_by(count) p, size_t count) {; for (size_t i = 0; i < count; ++i) {; // implicit bounds checks:; // if (p + i < p || p + i + 1 > p + count) trap();; p[i] = i;; }; }. ``ConstraintElimination`` collects the following facts and determines if the; bounds checks can be safely removed:. * Inside the for-loop, ``0 <= i < count``, hence ``1 <= i + 1 <= count``.; * Pointer arithmetic ``p + count`` in the if-condition doesn’t wrap.; * ``-fbounds-safety`` treats pointer arithmetic overflow as deterministically; two’s complement computation, not an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst:6288,optimiz,optimization,6288,interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,1,['optimiz'],['optimization']
Performance,"ty of reasons: changes to the code base invalidate them; silently, the developer mis-annotated them (e.g., using ``LIKELY`` instead of; ``UNLIKELY``), or perhaps they assumed something incorrectly when they wrote; the annotation. Regardless of why, it is useful to detect these situations so; that the optimizer can make more useful decisions about the code. MisExpect diagnostics are intended to help developers identify and address; these situations, by comparing the branch weights added by the ``llvm.expect``; intrinsic to those collected through profiling. Whenever these values are; mismatched, a diagnostic is surfaced to the user. Details on how the checks; operate in the LLVM backed can be found in LLVM's documentation. By default MisExpect checking is quite strict, because the use of the; ``llvm.expect`` intrinsic is designed for specialized cases, where the outcome; of a condition is severely skewed. As a result, the optimizer can be extremely; aggressive, which can result in performance degradation if the outcome is less; predictable than the annotation suggests. Even when the annotation is correct; 90% of the time, it may be beneficial to either remove the annotation or to use; a different intrinsic that can communicate the probability more directly. Because this may be too strict, MisExpect diagnostics are not enabled by; default, and support an additional flag to tolerate some deviation from the; exact thresholds. The ``-fdiagnostic-misexpect-tolerance=N`` accepts; deviations when comparing branch weights within ``N%`` of the expected values.; So passing ``-fdiagnostic-misexpect-tolerance=5`` will not report diagnostic messages; if the branch weight from the profile is within 5% of the weight added by; the ``llvm.expect`` intrinsic. MisExpect diagnostics are also available in the form of optimization remarks,; which can be serialized and processed through the ``opt-viewer.py``; scripts in LLVM. .. option:: -Rpass=misexpect. Enables optimization remarks for mi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MisExpect.rst:1283,optimiz,optimizer,1283,interpreter/llvm-project/clang/docs/MisExpect.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MisExpect.rst,2,"['optimiz', 'perform']","['optimizer', 'performance']"
Performance,"ty; information for the above hierarchy:. ::. @_ZTV1A = constant [...], !type !0; @_ZTV1B = constant [...], !type !0, !type !1; @_ZTV1C = constant [...], !type !2; @_ZTV1D = constant [...], !type !0, !type !3, !type !4. !0 = !{i64 16, !""_ZTS1A""}; !1 = !{i64 16, !""_ZTS1B""}; !2 = !{i64 16, !""_ZTS1C""}; !3 = !{i64 16, !""_ZTS1D""}; !4 = !{i64 48, !""_ZTS1C""}. With this type metadata, we can now use the ``llvm.type.test`` intrinsic to; test whether a given pointer is compatible with a type identifier. Working; backwards, if ``llvm.type.test`` returns true for a particular pointer,; we can also statically determine the identities of the virtual functions; that a particular virtual call may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:4708,load,load,4708,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst,1,['load'],['load']
Performance,"u can use the `.x` command. This is the same as executing a; named script; you can also provide parameters. The only; difference is you need to append a + or a ++. ``` {.cpp}; root[] .x MyScript.C+(4000); Creating shared library /home/./MyScript_C.so; ```. You can select whether the script in compiled with debug symbol or; with optimization by appending the letter 'g' or 'O' after the '+' or; '++'. Without the specification, the script is compiled with the same; level of debugging symbol and optimization as the currently running; ROOT executable. For example:. ``` {.cpp}; root[] .L MyScript.C++g; ```. will compile `MyScript.C` with debug symbols; usually this means; giving the `-g` option to compiler. ``` {.cpp}; root[] .L MyScript.C++O; ```. will compile `MyScript.C` with optimizations; usually this means; giving the `-O` option to compiler. The syntax:. ``` {.cpp}; root[] .L MyScript.C++; ```. is using the default optimization level. The initial default is to; compile with the same level of optimization as the root executable; itself. The default can be changed by:. ``` {.cpp}; root[] gSystem->SetAclicMode(TSystem::kDebug);; root[] gSystem->SetAclicMode(TSystem::kOpt);; ```. Note that the commands:. ``` {.cpp}; root[] .L MyScript.C+g; root[] .L MyScript.C+O; ```. respectively compile `MyScript.C` with debug and optimization if the; library does not exist yet; they will not change the debug and the; optimization level if the library already exist and it is up to date.; To use ACLiC from compiled code or from inside another macro, we; recommend using `gROOT->ProcessLine()`. For; example, in one script you can use ACLiC to compile and load another; script. ``` {.cpp}; gROOT->ProcessLine("".L MyScript.C+""); gROOT->ProcessLine("".L MyScript.C++""); ```. ### Setting the Include Path. You can get the include path by typing:. ``` {.cpp}; root[] .include; ```. You can append to the include path by typing:. ``` {.cpp}; root[] .include $HOME/mypackage/include; ```. In a script y",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md:15611,optimiz,optimization,15611,documentation/users-guide/Cling.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md,1,['optimiz'],['optimization']
Performance,"u supplied the -M option); most filenames can be written to the file without any special formatting.; Different Make tools will treat different sets of characters as ""special""; and use different conventions for telling the Make tool that the character; is actually part of the filename. Normally Clang uses backslash to ""escape""; a special character, which is the convention used by GNU Make. The -MV; option tells Clang to put double-quotes around the entire filename, which; is the convention used by NMake and Jom. .. option:: -femit-dwarf-unwind=<value>. When to emit DWARF unwind (EH frame) info. This is a Mach-O-specific option. Valid values are:. * ``no-compact-unwind`` - Only emit DWARF unwind when compact unwind encodings; aren't available. This is the default for arm64.; * ``always`` - Always emit DWARF unwind regardless.; * ``default`` - Use the platform-specific default (``always`` for all; non-arm64-platforms). ``no-compact-unwind`` is a performance optimization -- Clang will emit smaller; object files that are more quickly processed by the linker. This may cause; binary compatibility issues on older x86_64 targets, however, so use it with; caution. .. _configuration-files:. Configuration files; -------------------. Configuration files group command-line options and allow all of them to be; specified just by referencing the configuration file. They may be used, for; example, to collect options required to tune compilation for particular; target, such as ``-L``, ``-I``, ``-l``, ``--sysroot``, codegen options, etc. Configuration files can be either specified on the command line or loaded; from default locations. If both variants are present, the default configuration; files are loaded first. The command line option ``--config=`` can be used to specify explicit; configuration files in a Clang invocation. If the option is used multiple times,; all specified files are loaded, in order. For example:. ::. clang --config=/home/user/cfgs/testing.txt; clang --config=deb",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:30269,perform,performance,30269,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,"['optimiz', 'perform']","['optimization', 'performance']"
Performance,"u>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to an ``std::complex`` function,; especially when compiling without optimizations. As of 2016-11-16, clang supports ``std::complex`` without these caveats. It is; tested with libstdc++ 4.8.5 and newer, but is known to work only with libc++; newer than 2016-11-16. ``<algorithm>``; ---------------. In C++14, many useful functions from ``<algorithm>`` (notably, ``std::min`` and; ``std::max``) become constexpr. You can therefore use these in device code,; when compiling with clang. Detecting clang vs NVCC from code; =================================. Although clang's CUDA implementation is largely compatible with NVCC's, you may; still want to detect when you're compiling CUDA code specifically with clang. This is tricky, because NVCC may invoke clang as part of its own compilation; process! For example, NVCC uses the host compiler's preprocessor when; compiling for device code, and that host compiler may in fact be clang. When clang is actually compiling CUDA code -- rather",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:7079,optimiz,optimizations,7079,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,1,['optimiz'],['optimizations']
Performance,"ualifier on the second operand pointer type; always matches the address space qualifier on the result type. How is GEP different from ``ptrtoint``, arithmetic, and ``inttoptr``?; ---------------------------------------------------------------------. It's very similar; there are only subtle differences. With ptrtoint, you have to pick an integer type. One approach is to pick i64;; this is safe on everything LLVM supports (LLVM internally assumes pointers are; never wider than 64 bits in many places), and the optimizer will actually narrow; the i64 arithmetic down to the actual pointer size on targets which don't; support 64-bit arithmetic in most cases. However, there are some cases where it; doesn't do this. With GEP you can avoid this problem. Also, GEP carries additional pointer aliasing rules. It's invalid to take a GEP; from one object, address into a different separately allocated object, and; dereference it. IR producers (front-ends) must follow this rule, and consumers; (optimizers, specifically alias analysis) benefit from being able to rely on; it. See the `Rules`_ section for more information. And, GEP is more concise in common cases. However, for the underlying integer computation implied, there is no; difference. I'm writing a backend for a target which needs custom lowering for GEP. How do I do this?; -----------------------------------------------------------------------------------------. You don't. The integer computation implied by a GEP is target-independent.; Typically what you'll need to do is make your backend pattern-match expressions; trees involving ADD, MUL, etc., which are what GEP is lowered into. This has the; advantage of letting your code work correctly in more cases. GEP does use target-dependent parameters for the size and layout of data types,; which targets can customize. If you require support for addressing units which are not 8 bits, you'll need to; fix a lot of code in the backend, with GEP lowering being only a small piece of; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:10522,optimiz,optimizers,10522,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['optimiz'],['optimizers']
Performance,"ualization. Turned off by default, because it is; still experimental. .. option:: -fwhole-program-vtables. Enable whole-program vtable optimizations, such as single-implementation; devirtualization and virtual constant propagation, for classes with; :doc:`hidden LTO visibility <LTOVisibility>`. Requires ``-flto``. .. option:: -f[no]split-lto-unit. Controls splitting the :doc:`LTO unit <LTOVisibility>` into regular LTO and; :doc:`ThinLTO` portions, when compiling with -flto=thin. Defaults to false; unless ``-fsanitize=cfi`` or ``-fwhole-program-vtables`` are specified, in; which case it defaults to true. Splitting is required with ``fsanitize=cfi``,; and it is an error to disable via ``-fno-split-lto-unit``. Splitting is; optional with ``-fwhole-program-vtables``, however, it enables more; aggressive whole program vtable optimizations (specifically virtual constant; propagation). When enabled, vtable definitions and select virtual functions are placed; in the split regular LTO module, enabling more aggressive whole program; vtable optimizations required for CFI and virtual constant propagation.; However, this can increase the LTO link time and memory requirements over; pure ThinLTO, as all split regular LTO modules are merged and LTO linked; with regular LTO. .. option:: -fforce-emit-vtables. In order to improve devirtualization, forces emitting of vtables even in; modules where it isn't necessary. It causes more inline virtual functions; to be emitted. .. option:: -fno-assume-sane-operator-new. Don't assume that the C++'s new operator is sane. This option tells the compiler to do not assume that C++'s global; new operator will always return a pointer that does not alias any; other pointer when the function returns. .. option:: -fassume-nothrow-exception-dtor. Assume that an exception object' destructor will not throw, and generate; less code for catch handlers. A throw expression of a type with a; potentially-throwing destructor will lead to an error. By default, Cla",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:81460,optimiz,optimizations,81460,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance,"uation is complete. Otherwise, the DWARF expression is ill-formed if the updated operation; position is not in the range of the first to last operation inclusive, or; not at the start of an operation. 4. ``DW_OP_bra``. ``DW_OP_bra`` is a conditional branch. Its single operand is a 2-byte signed; integer constant. This operation pops the top of stack. If the value popped; is not the constant 0, the 2-byte constant operand is the number of bytes of; the DWARF operation expression to skip forward or backward from the current; operation, beginning after the 2-byte constant. If the updated position is at one past the end of the last operation, then; the operation expression evaluation is complete. Otherwise, the DWARF expression is ill-formed if the updated operation; position is not in the range of the first to last operation inclusive, or; not at the start of an operation. 5. ``DW_OP_call2, DW_OP_call4, DW_OP_call_ref``. ``DW_OP_call2``, ``DW_OP_call4``, and ``DW_OP_call_ref`` perform DWARF; procedure calls during evaluation of a DWARF operation expression. ``DW_OP_call2`` and ``DW_OP_call4``, have one operand that is, respectively,; a 2-byte or 4-byte unsigned offset DR that represents the byte offset of a; debugging information entry D relative to the beginning of the current; compilation unit. ``DW_OP_call_ref`` has one operand that is a 4-byte unsigned value in the; 32-bit DWARF format, or an 8-byte unsigned value in the 64-bit DWARF format,; that represents the byte offset DR of a debugging information entry D; relative to the beginning of the ``.debug_info`` section that contains the; current compilation unit. D may not be in the current compilation unit. .. note::. DWARF Version 5 states that DR can be an offset in a ``.debug_info``; section other than the one that contains the current compilation unit. It; states that relocation of references from one executable or shared object; file to another must be performed by the consumer. But given that DR is; defined as",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:72319,perform,perform,72319,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['perform'],['perform']
Performance,ub.com/root-project/root/issues/12783)] - [IO] Writing HistFactory model file twice gives strange results since ROOT 6.26.02; * [[#12770](https://github.com/root-project/root/issues/12770)] - tmva/sofie_parsers does not build with latest Protobuf (22.x); * [[#12744](https://github.com/root-project/root/issues/12744)] - wrong Python version found during build; * [[#12718](https://github.com/root-project/root/issues/12718)] - A crash when trying to initialise a vector from a >1D numpy array in PyROOT; * [[#12685](https://github.com/root-project/root/issues/12685)] - `TEnum::GetEnum` does NOT process typedefs; * [[#12644](https://github.com/root-project/root/issues/12644)] - Can't find cxxabi.h and build module 'ROOT_Foundation_Stage1_NoRTTI' when building from source on Macos; * [[#12631](https://github.com/root-project/root/issues/12631)] - Unable to build master with external XROOTD; * [[#12621](https://github.com/root-project/root/issues/12621)] - [I/O][RDF] Usage of xrootd from multi-thread event loops runs into severe bottlenecks; * [[#12592](https://github.com/root-project/root/issues/12592)] - [doc] TProfile bin error documentation is not correct; * [[#12591](https://github.com/root-project/root/issues/12591)] - Allow partial enablement of modules; * [[#12527](https://github.com/root-project/root/issues/12527)] - MacOS build fails if configured without cocoa; * [[#12492](https://github.com/root-project/root/issues/12492)] - The problem with building ROOT v6-26-10 in debug mode on ubuntu 20.04; * [[#12230](https://github.com/root-project/root/issues/12230)] - Wrong conversion from Numpy Array to `std.vector` when using the wrong type; * [[#12091](https://github.com/root-project/root/issues/12091)] - TSpline SaveAs not using equidistant and loss of precision; * [[#11924](https://github.com/root-project/root/issues/11924)] - PyROOT: wrong overload resolution for C++ functions from python ; * [[#11901](https://github.com/root-project/root/issues/11901)] - Binary dis,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:41146,multi-thread,multi-thread,41146,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,2,"['bottleneck', 'multi-thread']","['bottlenecks', 'multi-thread']"
Performance,"ubtraction, and the second element of; which is a bit specifying if the unsigned subtraction resulted in an; overflow. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call {i32, i1} @llvm.usub.with.overflow.i32(i32 %a, i32 %b); %sum = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %overflow, label %normal. '``llvm.smul.with.overflow.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.smul.with.overflow``; on any integer bit width or vectors of integers. ::. declare {i16, i1} @llvm.smul.with.overflow.i16(i16 %a, i16 %b); declare {i32, i1} @llvm.smul.with.overflow.i32(i32 %a, i32 %b); declare {i64, i1} @llvm.smul.with.overflow.i64(i64 %a, i64 %b); declare {<4 x i32>, <4 x i1>} @llvm.smul.with.overflow.v4i32(<4 x i32> %a, <4 x i32> %b). Overview:; """""""""""""""""". The '``llvm.smul.with.overflow``' family of intrinsic functions perform; a signed multiplication of the two arguments, and indicate whether an; overflow occurred during the signed multiplication. Arguments:; """""""""""""""""""". The arguments (%a and %b) and the first element of the result structure; may be of integer types of any bit width, but they must have the same; bit width. The second element of the result structure must be of type; ``i1``. ``%a`` and ``%b`` are the two values that will undergo signed; multiplication. Semantics:; """""""""""""""""""". The '``llvm.smul.with.overflow``' family of intrinsic functions perform; a signed multiplication of the two arguments. They return a structure ---; the first element of which is the multiplication, and the second element; of which is a bit specifying if the signed multiplication resulted in an; overflow. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call {i32, i1} @llvm.smul.with.overflow.i32(i32 %a, i32 %b); %sum = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %overflow, label %normal. '``llvm.umul.with.ove",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:607906,perform,perform,607906,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"uc.edu>; Subject: another thought. I have a budding idea about making LLVM a little more ambitious: a; customizable runtime system that can be used to implement language-specific; virtual machines for many different languages. E.g., a C vm, a C++ vm, a; Java vm, a Lisp vm, .. The idea would be that LLVM would provide a standard set of runtime features; (some low-level like standard assembly instructions with code generation and; static and runtime optimization; some higher-level like type-safety and; perhaps a garbage collection library). Each language vm would select the; runtime features needed for that language, extending or customizing them as; needed. Most of the machine-dependent code-generation and optimization; features as well as low-level machine-independent optimizations (like PRE); could be provided by LLVM and should be sufficient for any language,; simplifying the language compiler. (This would also help interoperability; between languages.) Also, some or most of the higher-level; machine-independent features like type-safety and access safety should be; reusable by different languages, with minor extensions. The language; compiler could then focus on language-specific analyses and optimizations. The risk is that this sounds like a universal IR -- something that the; compiler community has tried and failed to develop for decades, and is; universally skeptical about. No matter what we say, we won't be able to; convince anyone that we have a universal IR that will work. We need to; think about whether LLVM is different or if has something novel that might; convince people. E.g., the idea of providing a package of separable; features that different languages select from. Also, using SSA with or; without type-safety as the intermediate representation. One interesting starting point would be to discuss how a JVM would be; implemented on top of LLVM a bit more. That might give us clues on how to; structure LLVM to support one or more language VMs. --Vikram. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-01-31-UniversalIRIdea.txt:1328,optimiz,optimizations,1328,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-01-31-UniversalIRIdea.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-01-31-UniversalIRIdea.txt,1,['optimiz'],['optimizations']
Performance,"uch as; Intel's Sandylake), we do so now. To see which features and CPUs that LLVM knows about, we can use; ``llc``. For example, let's look at x86:. ::. $ llvm-as < /dev/null | llc -march=x86 -mattr=help; Available CPUs for this target:. amdfam10 - Select the amdfam10 processor.; athlon - Select the athlon processor.; athlon-4 - Select the athlon-4 processor.; ... Available features for this target:. 16bit-mode - 16-bit mode (i8086).; 32bit-mode - 32-bit mode (80386).; 3dnow - Enable 3DNow! instructions.; 3dnowa - Enable 3DNow! Athlon instructions.; ... For our example, we'll use the generic CPU without any additional feature or; target option. .. code-block:: c++. auto CPU = ""generic"";; auto Features = """";. TargetOptions opt;; auto TargetMachine = Target->createTargetMachine(TargetTriple, CPU, Features, opt, Reloc::PIC_);. Configuring the Module; ======================. We're now ready to configure our module, to specify the target and; data layout. This isn't strictly necessary, but the `frontend; performance guide <../../Frontend/PerformanceTips.html>`_ recommends; this. Optimizations benefit from knowing about the target and data; layout. .. code-block:: c++. TheModule->setDataLayout(TargetMachine->createDataLayout());; TheModule->setTargetTriple(TargetTriple);. Emit Object Code; ================. We're ready to emit object code! Let's define where we want to write; our file to:. .. code-block:: c++. auto Filename = ""output.o"";; std::error_code EC;; raw_fd_ostream dest(Filename, EC, sys::fs::OF_None);. if (EC) {; errs() << ""Could not open file: "" << EC.message();; return 1;; }. Finally, we define a pass that emits object code, then we run that; pass:. .. code-block:: c++. legacy::PassManager pass;; auto FileType = CodeGenFileType::ObjectFile;. if (TargetMachine->addPassesToEmitFile(pass, dest, nullptr, FileType)) {; errs() << ""TargetMachine can't emit a file of this type"";; return 1;; }. pass.run(*TheModule);; dest.flush();. Putting It All Together; ============",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl08.rst:3572,perform,performance,3572,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl08.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl08.rst,1,['perform'],['performance']
Performance,"uction set has support for a fused operation,; and (b) that the fused operation is more efficient than the equivalent,; separate pair of mul and add instructions. Arguments:; """""""""""""""""""". The first three arguments to the '``llvm.experimental.constrained.fmuladd``'; intrinsic must be floating-point or vector of floating-point values.; All three arguments must have identical types. The fourth and fifth arguments specify the rounding mode and exception behavior; as described above. Semantics:; """""""""""""""""""". The expression:. ::. %0 = call float @llvm.experimental.constrained.fmuladd.f32(%a, %b, %c,; metadata <rounding mode>,; metadata <exception behavior>). is equivalent to the expression:. ::. %0 = call float @llvm.experimental.constrained.fmul.f32(%a, %b,; metadata <rounding mode>,; metadata <exception behavior>); %1 = call float @llvm.experimental.constrained.fadd.f32(%0, %c,; metadata <rounding mode>,; metadata <exception behavior>). except that it is unspecified whether rounding will be performed between the; multiplication and addition steps. Fusion is not guaranteed, even if the target; platform supports it.; If a fused multiply-add is required, the corresponding; :ref:`llvm.experimental.constrained.fma <int_fma>` intrinsic function should be; used instead.; This never sets errno, just as '``llvm.experimental.constrained.fma.*``'. Constrained libm-equivalent Intrinsics; --------------------------------------. In addition to the basic floating-point operations for which constrained; intrinsics are described above, there are constrained versions of various; operations which provide equivalent behavior to a corresponding libm function.; These intrinsics allow the precise behavior of these operations with respect to; rounding mode and exception behavior to be controlled. As with the basic constrained floating-point intrinsics, the rounding mode; and exception behavior arguments only control the behavior of the optimizer.; They do not change the runtime floating-point env",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:888973,perform,performed,888973,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"uction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = extractelement <n x <ty>> <val>, <ty2> <idx> ; yields <ty>; <result> = extractelement <vscale x n x <ty>> <val>, <ty2> <idx> ; yields <ty>. Overview:; """""""""""""""""". The '``extractelement``' instruction extracts a single scalar element; from a vector at a specified index. Arguments:; """""""""""""""""""". The first operand of an '``extractelement``' instruction is a value of; :ref:`vector <t_vector>` type. The second operand is an index indicating; the position from which to extract the element. The index may be a; variable of any integer type, and will be treated as an unsigned integer. Semantics:; """""""""""""""""""". The result is a scalar of the same type as the element type of ``val``.; Its value is the value at position ``idx`` of ``val``. If ``idx``; exceeds the length of ``val`` for a fixed-length vector, the result is a; :ref:`poison value <poisonvalues>`. For a scalable vector, if the value; of ``idx`` exceeds the runtime length of the vector, the result is a; :ref:`poison value <poisonvalues>`. Example:; """""""""""""""". .. code-block:: text. <result> = extractelement <4 x i32> %vec, i32 0 ; yields i32. .. _i_insertelement:. '``insertelement``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = insertelement <n x <ty>> <val>, <ty> <elt>, <ty2> <idx> ; yields <n x <ty>>; <result> = insertelement <vscale x n x <ty>> <val>, <ty> <elt>, <ty2> <idx> ; yields <vscale x n x <ty>>. Overview:; """""""""""""""""". The '``insertelement``' instruction inserts a scalar element into a; vector at a specified index. Arguments:; """""""""""""""""""". The first operand of an '``insertelement``' instruction is a value of; :ref:`vector <t_vector>` type. The second operand is a scalar value whose; type must equal the element type of the first operand. The third operand; is an index indicating the position at which to insert the value. The; index may be a variable of any integer type, and will be treated as an; unsigned inte",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:401847,scalab,scalable,401847,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance,"uctions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extract",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:4459,load,loaded,4459,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,1,['load'],['loaded']
Performance,"ucture \n (a variable with \n an address)"", shape=""box""];; left3 [label="" 3. Built-In Type \n (int, float, etc.)"", shape=""box""];; output [label="" move to 'Assign' step "", shape=""box""];. synth -> mem;; mem -> withaloc [label=""Yes""];; mem -> noaloc [label=""No""];; withaloc -> right;; noaloc -> left2;; noaloc -> left3;; right -> output;; left2 -> output;; left3 -> output;; }; output -> assign; }. Where is the captured result stored?; ------------------------------------. ``LastValue`` holds the last result of the value printing. It is a class member; because it can be accessed even after subsequent inputs. **Note:** If no value printing happens, then it is in an invalid state. Improving Efficiency and User Experience; ----------------------------------------. The Value object is essentially used to create a mapping between an expression; 'type' and the allocated 'memory'. Built-in types (bool, char, int,; float, double, etc.) are copyable. Their memory allocation size is known; and the Value object can introduce a small-buffer optimization.; In case of objects, the ``Value`` class provides reference-counted memory; management. The implementation maps the type as written and the Clang Type to be able to use; the preprocessor to synthesize the relevant cast operations. For example,; ``X(char, Char_S)``, where ``char`` is the type from the language's type system; and ``Char_S`` is the Clang builtin type which represents it. This mapping helps; to import execution results from the interpreter in a compiled program and vice; versa. The ``Value.h`` header file can be included at runtime and this is why it; has a very low token count and was developed with strict constraints in mind. This also enables the user to receive the computed 'type' back in their code; and then transform the type into something else (e.g., re-cast a double into; a float). Normally, the compiler can handle these conversions transparently,; but in interpreter mode, the compiler cannot see all the 'from' a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangRepl.rst:9051,optimiz,optimization,9051,interpreter/llvm-project/clang/docs/ClangRepl.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangRepl.rst,1,['optimiz'],['optimization']
Performance,"ucture members. Many variations are supported, but some that rely on undefined behaviour being; ignored (as other compilers do) are still being left un-vectorized. .. code-block:: c++. struct { int A[100], K, B[100]; } Foo;. void foo() {; for (int i = 0; i < 100; ++i); Foo.A[i] = Foo.B[i] + 100;; }. Vectorization of function calls; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize intrinsic math functions.; See the table below for a list of these functions. +-----+-----+---------+; | pow | exp | exp2 |; +-----+-----+---------+; | sin | cos | sqrt |; +-----+-----+---------+; | log |log2 | log10 |; +-----+-----+---------+; |fabs |floor| ceil |; +-----+-----+---------+; |fma |trunc|nearbyint|; +-----+-----+---------+; | | | fmuladd |; +-----+-----+---------+. Note that the optimizer may not be able to vectorize math library functions; that correspond to these intrinsics if the library calls access external state; such as ""errno"". To allow better optimization of C/C++ math library functions,; use ""-fno-math-errno"". The loop vectorizer knows about special instructions on the target and will; vectorize a loop containing a function call that maps to the instructions. For; example, the loop below will be vectorized on Intel x86 if the SSE4.1 roundps; instruction is available. .. code-block:: c++. void foo(float *f) {; for (int i = 0; i != 1024; ++i); f[i] = floorf(f[i]);; }. Partial unrolling during vectorization; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Modern processors feature multiple execution units, and only programs that contain a; high degree of parallelism can fully utilize the entire width of the machine.; The Loop Vectorizer increases the instruction level parallelism (ILP) by; performing partial-unrolling of loops. In the example below the entire array is accumulated into the variable 'sum'.; This is inefficient because only a single execution port can be used by the processor.; By unrolling the code the Loop Vectorizer allows two or more executi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:9840,optimiz,optimization,9840,interpreter/llvm-project/llvm/docs/Vectorizers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst,1,['optimiz'],['optimization']
Performance,"uding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running; various strategies to classify the bug, which in turn run multiple optimizer; and compilation passes over the input, taking up a lot of time. Furthermore,; when the IR crashes, it tries to reduce it by performing some sub-optimal; passes (e.g. a lot of unreachable blocks), and sometimes even fails to minimize; at all. ### ""Quirky"" Interface; Bugpoint’s current interface overwhelms and confuses the user, the help screen; alone ends up confusing rather providing guidance. And, not only are there; numerous features and options, but some of them also work in unexpected ways; and most of the time the user ends up using a custom script. Pruning and; simplifying the interface will be worth considering in order to make the tool; more useful in the general case and easier to maintain.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:3276,optimiz,optimizer,3276,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md,2,"['optimiz', 'perform']","['optimizer', 'performing']"
Performance,"ue constraint information. ``lint``: Statically lint-checks LLVM IR; ----------------------------------------. This pass statically checks for common and easily-identified constructs which; produce undefined or likely unintended behavior in LLVM IR. It is not a guarantee of correctness, in two ways. First, it isn't; comprehensive. There are checks which could be done statically which are not; yet implemented. Some of these are indicated by TODO comments, but those; aren't comprehensive either. Second, many conditions cannot be checked; statically. This pass does no dynamic instrumentation, so it can't check for; all possible problems. Another limitation is that it assumes all code will be executed. A store; through a null pointer in a basic block which is never reached is harmless, but; this pass will warn about it anyway. Optimization passes may make conditions that this pass checks for more or less; obvious. If an optimization pass appears to be introducing a warning, it may; be that the optimization pass is merely exposing an existing condition in the; code. This code may be run before :ref:`instcombine <passes-instcombine>`. In many; cases, instcombine checks for the same kinds of things and turns instructions; with undefined behavior into unreachable (or equivalent). Because of this,; this pass makes some effort to look through bitcasts and so on. ``loops``: Natural Loop Information; -----------------------------------. This analysis is used to identify natural loops and determine the loop depth of; various nodes of the CFG. Note that the loops identified may actually be; several natural loops that share the same header node... not just a single; natural loop. ``memdep``: Memory Dependence Analysis; --------------------------------------. An analysis that determines, for a given memory operation, what preceding; memory operations it depends on. It builds on alias analysis information, and; tries to provide a lazy, caching interface to a common kind of alias; in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:7237,optimiz,optimization,7237,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,2,['optimiz'],['optimization']
Performance,"ue. (Note that; the function may also return true if the given pointer is not associated; with a type metadata identifier.) If the function's return value's second; element is true, the following rules apply to the first element:. - If the given pointer is associated with the given type metadata identifier,; it is the function pointer loaded from the given byte offset from the given; pointer. - If the given pointer is not associated with the given type metadata; identifier, it is one of the following (the choice of which is unspecified):. 1. The function pointer that would have been loaded from an arbitrarily chosen; (through an unspecified mechanism) pointer associated with the type; metadata. 2. If the function has a non-void return type, a pointer to a function that; returns an unspecified value without causing side effects. If the function's return value's second element is false, the value of the; first element is undefined. .. _type.checked.load.relative:. '``llvm.type.checked.load.relative``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare {ptr, i1} @llvm.type.checked.load.relative(ptr %ptr, i32 %offset, metadata %type) argmemonly nounwind readonly. Overview:; """""""""""""""""". The ``llvm.type.checked.load.relative`` intrinsic loads a relative pointer to a; function from a virtual table pointer using metadata. Otherwise, its semantic is; identical to the ``llvm.type.checked.load`` intrinsic. A relative pointer is a pointer to an offset to the pointed to value. The; address of the underlying pointer of the relative pointer is obtained by adding; the offset to the address of the offset value. '``llvm.arithmetic.fence``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.arithmetic.fence(<type> <op>). Overview:; """""""""""""""""". The purpose of the ``llvm.arithmetic.fence`` intrinsic; is to prevent the optimizer from performing fast-math optimizations,; particularly reassociation,; between the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:939805,load,load,939805,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"ue/weight; 	 with optionally an error on the value or the coordinate and the `ROOT::Fit::UnBinData` for un-binned data sets,; 	 which consists only of a vector of coordinate values. The coordinate values can be; 	 one-dimensional (i.e. one entry per event) or multi-dimensional (N entries per event).; * Function classes defining the type of fit (the objective function used for fitting):; 	- `ROOT::Fit::Chi2FCN` for chi2 (least-square fits),; 	- `ROOT::Fit::PoissonLikelihoodFCN` for binned likelihood fits of histograms,; 	- `ROOT::Fit::LogLikelihoodFCN` for generic un-binned likelihood fits.; 	These classes are templated on the type of function interface they implement (see later). User convenient typedefs are also provided.; 	They derive from the common generic interface multi-dimensional for function evaluation, `ROOT::Math::IBaseFunctionMultiDim`. In addition the fitter classes make uses of the generic interfaces for parametric function evaluations, `ROOT::Math::IParametricFunctionMultiDim`; to define the fit model function and use the `ROOT::Math::Minimizer` interface to perform the minimization of the objective function.; More information about the function interface and the multi-dimensional minimization in ROOT is given in the Mathematical Library chapter. Here we present a detailed description of the `ROOT::Fit` classes and how to use them.; Using these classes instead of the interface provided directly in the ROOT data objects, like `TH1::Fit` allow are more fine control; to configure and customise the fits. For example, using these classes a combined fit of several histograms can be performed. To understand how these class work, let's go through a simple example, such as fitting an histogram. When fitting an histogram, instead of using `TH1::Fit` we will show in the following hot wo use the `ROOT::Fit` classes.; We will show how to perform the following different type of fits with the histogram data:; * a least square fit using the observed errors (Neyman chi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:28134,perform,perform,28134,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['perform'],['perform']
Performance,"uent for, while, do-while, or c++11 range-based for; loop. The directive allows vectorization and interleaving to be enabled or; disabled. Vector width as well as interleave count can also be manually; specified. The following example explicitly enables vectorization and; interleaving:. .. code-block:: c++. #pragma clang loop vectorize(enable) interleave(enable); while(...) {; ...; }. The following example implicitly enables vectorization and interleaving by; specifying a vector width and interleaving count:. .. code-block:: c++. #pragma clang loop vectorize_width(2) interleave_count(2); for(...) {; ...; }. See the Clang; `language extensions; <https://clang.llvm.org/docs/LanguageExtensions.html#extensions-for-loop-hint-optimizations>`_; for details. Diagnostics; -----------. Many loops cannot be vectorized including loops with complicated control flow,; unvectorizable types, and unvectorizable calls. The loop vectorizer generates; optimization remarks which can be queried using command line options to identify; and diagnose loops that are skipped by the loop-vectorizer. Optimization remarks are enabled using:. ``-Rpass=loop-vectorize`` identifies loops that were successfully vectorized. ``-Rpass-missed=loop-vectorize`` identifies loops that failed vectorization and; indicates if vectorization was specified. ``-Rpass-analysis=loop-vectorize`` identifies the statements that caused; vectorization to fail. If in addition ``-fsave-optimization-record`` is; provided, multiple causes of vectorization failure may be listed (this behavior; might change in the future). Consider the following loop:. .. code-block:: c++. #pragma clang loop vectorize(enable); for (int i = 0; i < Length; i++) {; switch(A[i]) {; case 0: A[i] = i*2; break;; case 1: A[i] = i; break;; default: A[i] = 0;; }; }. The command line ``-Rpass-missed=loop-vectorize`` prints the remark:. .. code-block:: console. no_switch.cpp:4:5: remark: loop not vectorized: vectorization is explicitly enabled [-Rpass-missed",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:2668,optimiz,optimization,2668,interpreter/llvm-project/llvm/docs/Vectorizers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst,1,['optimiz'],['optimization']
Performance,"uential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231076,load,load,231076,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"ues. The result of the instruction is a vector; whose length is the same as the shuffle mask and whose element type is the; same as the element type of the first two operands. Semantics:; """""""""""""""""""". The elements of the two input vectors are numbered from left to right; across both of the vectors. For each element of the result vector, the; shuffle mask selects an element from one of the input vectors to copy; to the result. Non-negative elements in the mask represent an index; into the concatenated pair of input vectors. A ``poison`` element in the mask vector specifies that the resulting element; is ``poison``.; For backwards-compatibility reasons, LLVM temporarily also accepts ``undef``; mask elements, which will be interpreted the same way as ``poison`` elements.; If the shuffle mask selects an ``undef`` element from one of the input; vectors, the resulting element is ``undef``. For scalable vectors, the only valid mask values at present are; ``zeroinitializer``, ``undef`` and ``poison``, since we cannot write all indices as; literals for a vector with a length unknown at compile time. Example:; """""""""""""""". .. code-block:: text. <result> = shufflevector <4 x i32> %v1, <4 x i32> %v2,; <4 x i32> <i32 0, i32 4, i32 1, i32 5> ; yields <4 x i32>; <result> = shufflevector <4 x i32> %v1, <4 x i32> poison,; <4 x i32> <i32 0, i32 1, i32 2, i32 3> ; yields <4 x i32> - Identity shuffle.; <result> = shufflevector <8 x i32> %v1, <8 x i32> poison,; <4 x i32> <i32 0, i32 1, i32 2, i32 3> ; yields <4 x i32>; <result> = shufflevector <4 x i32> %v1, <4 x i32> %v2,; <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7 > ; yields <8 x i32>. Aggregate Operations; --------------------. LLVM supports several instructions for working with; :ref:`aggregate <t_aggregate>` values. .. _i_extractvalue:. '``extractvalue``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = extractvalue <aggregate type> <val>, <idx>{, <idx>}*. Overview:; """""""""""""""""". The '``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:405214,scalab,scalable,405214,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance,"ug is found by hitting; a node that satisfies some ""bug condition"" (basically a violation of a; checking invariant). The analyzer traces out multiple paths by reasoning about branches and; then bifurcating the state: on the true branch the conditions of the; branch are assumed to be true and on the false branch the conditions; of the branch are assumed to be false. Such ""assumptions"" create; constraints on the values of the program, and those constraints are; recorded in the ProgramState object (and are manipulated by the; ConstraintManager). If assuming the conditions of a branch would; cause the constraints to be unsatisfiable, the branch is considered; infeasible and that path is not taken. This is how we get; path-sensitivity. We reduce exponential blow-up by caching nodes. If; a new node with the same state and program point as an existing node; would get generated, the path ""caches out"" and we simply reuse the; existing node. Thus the ExplodedGraph is not a DAG; it can contain; cycles as paths loop back onto each other and cache out. ProgramState and ExplodedNodes are basically immutable once created. Once; one creates a ProgramState, you need to create a new one to get a new; ProgramState. This immutability is key since the ExplodedGraph represents; the behavior of the analyzed program from the entry point. To; represent these efficiently, we use functional data structures (e.g.,; ImmutableMaps) which share data between instances. Finally, individual Checkers work by also manipulating the analysis; state. The analyzer engine talks to them via a visitor interface.; For example, the PreVisitCallExpr() method is called by ExprEngine; to tell the Checker that we are about to analyze a CallExpr, and the; checker is asked to check for any preconditions that might not be; satisfied. The checker can do nothing, or it can generate a new; ProgramState and ExplodedNode which contains updated checker state. If it; finds a bug, it can tell the BugReporter object about the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt:2705,cache,cache,2705,interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt,1,['cache'],['cache']
Performance,"ugh it's PC-relative.). XCore:. No additional modifiers. Inline Asm Metadata; ^^^^^^^^^^^^^^^^^^^. The call instructions that wrap inline asm nodes may have a; ""``!srcloc``"" MDNode attached to it that contains a list of constant; integers. If present, the code generator will use the integer as the; location cookie value when report errors through the ``LLVMContext``; error reporting mechanisms. This allows a front-end to correlate backend; errors that occur with inline asm back to the source code that produced; it. For example:. .. code-block:: llvm. call void asm sideeffect ""something bad"", """"(), !srcloc !42; ...; !42 = !{ i32 1234567 }. It is up to the front-end to make sense of the magic numbers it places; in the IR. If the MDNode contains multiple constants, the code generator; will use the one that corresponds to the line of the asm that the error; occurs on. .. _metadata:. Metadata; ========. LLVM IR allows metadata to be attached to instructions and global objects in the; program that can convey extra information about the code to the optimizers and; code generator. One example application of metadata is source-level; debug information. There are two metadata primitives: strings and nodes. Metadata does not have a type, and is not a value. If referenced from a; ``call`` instruction, it uses the ``metadata`` type. All metadata are identified in syntax by an exclamation point ('``!``'). .. _metadata-string:. Metadata Nodes and Metadata Strings; -----------------------------------. A metadata string is a string surrounded by double quotes. It can; contain any character by escaping non-printable characters with; ""``\xx``"" where ""``xx``"" is the two digit hex code. For example:; ""``!""test\00""``"". Metadata nodes are represented with notation similar to structure; constants (a comma separated list of elements, surrounded by braces and; preceded by an exclamation point). Metadata nodes can have any values as; their operand. For example:. .. code-block:: llvm. !{ !""tes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:242671,optimiz,optimizers,242671,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizers']
Performance,"uild is a standard; build using the compiler installed on the host, and a stage2 build is built; using the stage1 compiler. This nomenclature holds up to more stages too. In; general a stage*n* build is built using the output from stage*n-1*. Apple Clang Builds (A More Complex Bootstrap); =============================================. Apple's Clang builds are a slightly more complicated example of the simple; bootstrapping scenario. Apple Clang is built using a 2-stage build. The stage1 compiler is a host-only compiler with some options set. The stage1; compiler is a balance of optimization vs build time because it is a throwaway.; The stage2 compiler is the fully optimized compiler intended to ship to users. Setting up these compilers requires a lot of options. To simplify the; configuration the Apple Clang build settings are contained in CMake Cache files.; You can build an Apple Clang compiler using the following commands:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/Apple-stage1.cmake <path to source>/llvm; $ ninja stage2-distribution. This CMake invocation configures the stage1 host compiler, and sets; CLANG_BOOTSTRAP_CMAKE_ARGS to pass the Apple-stage2.cmake cache script to the; stage2 configuration step. When you build the stage2-distribution target it builds the minimal stage1; compiler and required tools, then configures and builds the stage2 compiler; based on the settings in Apple-stage2.cmake. This pattern of using cache scripts to set complex settings, and specifically to; make later stage builds include cache scripts is common in our more advanced; build configurations. Multi-stage PGO; ===============. Profile-Guided Optimizations (PGO) is a really great way to optimize the code; clang generates. Our multi-stage PGO builds are a workflow for generating PGO; profiles that can be used to optimize clang. At a high level, the way PGO works is that you build an instrumented compiler,; then you run the instrumented compi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:4071,cache,caches,4071,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,1,['cache'],['caches']
Performance,"uild; % cd gcc-${gcc_version}-build; % $PWD/../gcc-${gcc_version}/configure --prefix=$HOME/toolchains --enable-languages=c,c++; % make -j$(nproc); % make install. For more details, check out the excellent `GCC wiki entry`_, where I got most; of this information from. .. _GCC wiki entry:; https://gcc.gnu.org/wiki/InstallingGCC. Once you have a GCC toolchain, configure your build of LLVM to use the new; toolchain for your host compiler and C++ standard library. Because the new; version of libstdc++ is not on the system library search path, you need to pass; extra linker flags so that it can be found at link time (``-L``) and at runtime; (``-rpath``). If you are using CMake, this invocation should produce working; binaries:. .. code-block:: console. % mkdir build; % cd build; % CC=$HOME/toolchains/bin/gcc CXX=$HOME/toolchains/bin/g++ \; cmake .. -DCMAKE_CXX_LINK_FLAGS=""-Wl,-rpath,$HOME/toolchains/lib64 -L$HOME/toolchains/lib64"". If you fail to set rpath, most LLVM binaries will fail on startup with a message; from the loader similar to ``libstdc++.so.6: version `GLIBCXX_3.4.20' not; found``. This means you need to tweak the -rpath linker flag. This method will add an absolute path to the rpath of all executables. That's; fine for local development. If you want to distribute the binaries you build; so that they can run on older systems, copy ``libstdc++.so.6`` into the; ``lib/`` directory. All of LLVM's shipping binaries have an rpath pointing at; ``$ORIGIN/../lib``, so they will find ``libstdc++.so.6`` there. Non-distributed; binaries don't have an rpath set and won't find ``libstdc++.so.6``. Pass; ``-DLLVM_LOCAL_RPATH=""$HOME/toolchains/lib64""`` to cmake to add an absolute; path to ``libstdc++.so.6`` as above. Since these binaries are not distributed,; having an absolute local path is fine for them. When you build Clang, you will need to give *it* access to modern C++; standard library in order to use it as your new host in part of a bootstrap.; There are two easy ways",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:18633,load,loader,18633,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['load'],['loader']
Performance,"uilder->GetInsertBlock()->getParent();. // Create an alloca for the variable in the entry block.; AllocaInst *Alloca = CreateEntryBlockAlloca(TheFunction, VarName);. // Emit the start code first, without 'variable' in scope.; Value *StartVal = Start->codegen();; if (!StartVal); return nullptr;. // Store the value into the alloca.; Builder->CreateStore(StartVal, Alloca);; ... // Compute the end condition.; Value *EndCond = End->codegen();; if (!EndCond); return nullptr;. // Reload, increment, and restore the alloca. This handles the case where; // the body of the loop mutates the variable.; Value *CurVar = Builder->CreateLoad(Alloca->getAllocatedType(), Alloca,; VarName.c_str());; Value *NextVar = Builder->CreateFAdd(CurVar, StepVal, ""nextvar"");; Builder->CreateStore(NextVar, Alloca);; ... This code is virtually identical to the code `before we allowed mutable; variables <LangImpl05.html#code-generation-for-the-for-loop>`_. The big difference is that we; no longer have to construct a PHI node, and we use load/store to access; the variable as needed. To support mutable argument variables, we need to also make allocas for; them. The code for this is also pretty simple:. .. code-block:: c++. Function *FunctionAST::codegen() {; ...; Builder->SetInsertPoint(BB);. // Record the function arguments in the NamedValues map.; NamedValues.clear();; for (auto &Arg : TheFunction->args()) {; // Create an alloca for this variable.; AllocaInst *Alloca = CreateEntryBlockAlloca(TheFunction, Arg.getName());. // Store the initial value into the alloca.; Builder->CreateStore(&Arg, Alloca);. // Add arguments to variable symbol table.; NamedValues[std::string(Arg.getName())] = Alloca;; }. if (Value *RetVal = Body->codegen()) {; ... For each argument, we make an alloca, store the input value to the; function into the alloca, and register the alloca as the memory location; for the argument. This method gets invoked by ``FunctionAST::codegen()``; right after it sets up the entry block for the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:15457,load,load,15457,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['load']
Performance,"uire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:232066,load,load,232066,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"ul.with.overflow``; on any integer bit width or vectors of integers. ::. declare {i16, i1} @llvm.umul.with.overflow.i16(i16 %a, i16 %b); declare {i32, i1} @llvm.umul.with.overflow.i32(i32 %a, i32 %b); declare {i64, i1} @llvm.umul.with.overflow.i64(i64 %a, i64 %b); declare {<4 x i32>, <4 x i1>} @llvm.umul.with.overflow.v4i32(<4 x i32> %a, <4 x i32> %b). Overview:; """""""""""""""""". The '``llvm.umul.with.overflow``' family of intrinsic functions perform; a unsigned multiplication of the two arguments, and indicate whether an; overflow occurred during the unsigned multiplication. Arguments:; """""""""""""""""""". The arguments (%a and %b) and the first element of the result structure; may be of integer types of any bit width, but they must have the same; bit width. The second element of the result structure must be of type; ``i1``. ``%a`` and ``%b`` are the two values that will undergo unsigned; multiplication. Semantics:; """""""""""""""""""". The '``llvm.umul.with.overflow``' family of intrinsic functions perform; an unsigned multiplication of the two arguments. They return a structure ---; the first element of which is the multiplication, and the second; element of which is a bit specifying if the unsigned multiplication; resulted in an overflow. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call {i32, i1} @llvm.umul.with.overflow.i32(i32 %a, i32 %b); %sum = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %overflow, label %normal. Saturation Arithmetic Intrinsics; ---------------------------------. Saturation arithmetic is a version of arithmetic in which operations are; limited to a fixed range between a minimum and maximum value. If the result of; an operation is greater than the maximum value, the result is set (or; ""clamped"") to this maximum. If it is below the minimum, it is clamped to this; minimum. '``llvm.sadd.sat.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.sadd.s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:610083,perform,perform,610083,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"ular symbol. This type; of rule is typically used to implement an interactive renaming action that; allows users to specify which occurrences should be renamed during the; refactoring. Subclasses that choose to implement this rule have to implement; the ``findSymbolOccurrences`` member function. The following set of quick checks might help if you are unsure about the type; of rule you should use:. #. If you would like to transform the source in one translation unit and if; you don't need any cross-TU information, then the; ``SourceChangeRefactoringRule`` should work for you. #. If you would like to implement a rename-like operation with potential; interactive components, then ``FindSymbolOccurrencesRefactoringRule`` might; work for you. How to Create a Rule; ^^^^^^^^^^^^^^^^^^^^. Once you determine which type of rule is suitable for your needs you can; implement the refactoring by subclassing the rule and implementing its; interface. The subclass should have a constructor that takes the inputs that; are needed to perform the refactoring. For example, if you want to implement a; rule that simply deletes a selection, you should create a subclass of; ``SourceChangeRefactoringRule`` with a constructor that accepts the selection; range:. .. code-block:: c++. class DeleteSelectedRange final : public SourceChangeRefactoringRule {; public:; DeleteSelection(SourceRange Selection) : Selection(Selection) {}. Expected<AtomicChanges>; createSourceReplacements(RefactoringRuleContext &Context) override {; AtomicChange Replacement(Context.getSources(), Selection.getBegin());; Replacement.replace(Context.getSource,; CharSourceRange::getCharRange(Selection), """");; return { Replacement };; }; private:; SourceRange Selection;; };. The rule's subclass can then be added to the list of refactoring action's; rules for a particular action using the ``createRefactoringActionRule``; function. For example, the class that's shown above can be added to the; list of action rules using the followi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RefactoringEngine.rst:5240,perform,perform,5240,interpreter/llvm-project/clang/docs/RefactoringEngine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RefactoringEngine.rst,1,['perform'],['perform']
Performance,"ularity** --- SelectionDAG and FastISel are radically different and share; very little code. GlobalISel is built in a way that enables code reuse. For instance, both the; optimized and fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructionselect`. .. _progress-fastisel:. FastISel Replacement; --------------------. For the initial FastISel replacement, we intend to fallback to SelectionDAG on; selection failures. Currently, compile-time of the fast pipeline is within 1.5x of FastISel.; We're optimistic we can get to within 1.1/1.2x, but beating FastISel will be; challenging given the multi-pass approach.; Still, supporting all IR (via a complete legalizer) and avoiding the fallback; to SelectionDAG in the worst case should enable better amortized performance; than SelectionDAG+FastISel. ``NOTE``:; We considered never having a fallback to SelectionDAG, instead deciding early; whether a given function is supported by GlobalISel or not. The decision would; be based on :ref:`milegalizer` queries.; We abandoned",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:2102,perform,performance,2102,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,1,['perform'],['performance']
Performance,"ularly useful for the staging buildmaster which is silent; otherwise. #. Send the buildbot-worker access name and the access password directly to; `Galina Kistanova <mailto:gkistanova@gmail.com>`_, and wait until she; lets you know that your changes are applied and buildmaster is; reconfigured. #. Make sure you can start the buildbot-worker and successfully connect; to the silent buildmaster. Then set up your buildbot-worker to start; automatically at the start up time. See the buildbot documentation; for help. You may want to restart your computer to see if it works. #. Check the status of your buildbot-worker on the `Waterfall Display (Staging); <http://lab.llvm.org/staging/#/waterfall>`_ to make sure it is; connected, and the `Workers Display (Staging); <http://lab.llvm.org/staging/#/workers>`_ to see if administrator; contact and worker information are correct. #. At this point, you have a working builder connected to the staging; buildmaster. You can now make sure it is reliably green and keeps; up with the build queue. No notifications will be sent, so you can; keep an unstable builder connected to staging indefinitely. #. (Optional) Once the builder is stable on the staging buildmaster with; several days of green history, you can choose to move it to the production; buildmaster to enable developer notifications. Please email `Galina; Kistanova <mailto:gkistanova@gmail.com>`_ for review and approval. To move a worker to production (once approved), stop your worker, edit the; buildbot.tac file to change the port number from 9994 to 9990 and start it; again. Best Practices for Configuring a Fast Builder; =============================================. As mentioned above, we generally have a strong preference for; builders which can build every commit as they come in. This section; includes best practices and some recommendations as to how to achieve; that end. The goal; In 2020, the monorepo had just under 35 thousand commits. This works; out to an average of 4 co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:7224,queue,queue,7224,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['queue'],['queue']
Performance,"uld be undefined for pslld. //===---------------------------------------------------------------------===//. #include <math.h>; int t1(double d) { return signbit(d); }. This currently compiles to:; 	subl	$12, %esp; 	movsd	16(%esp), %xmm0; 	movsd	%xmm0, (%esp); 	movl	4(%esp), %eax; 	shrl	$31, %eax; 	addl	$12, %esp; 	ret. We should use movmskp{s|d} instead. //===---------------------------------------------------------------------===//. CodeGen/X86/vec_align.ll tests whether we can turn 4 scalar loads into a single; (aligned) vector load. This functionality has a couple of problems. 1. The code to infer alignment from loads of globals is in the X86 backend,; not the dag combiner. This is because dagcombine2 needs to be able to see; through the X86ISD::Wrapper node, which DAGCombine can't really do.; 2. The code for turning 4 x load into a single vector load is target ; independent and should be moved to the dag combiner.; 3. The code for turning 4 x load into a vector load can only handle a direct ; load from a global or a direct load from the stack. It should be generalized; to handle any load from P, P+4, P+8, P+12, where P can be anything.; 4. The alignment inference code cannot handle loads from globals in non-static; mode because it doesn't look through the extra dyld stub load. If you try; vec_align.ll without -relocation-model=static, you'll see what I mean. //===---------------------------------------------------------------------===//. We should lower store(fneg(load p), q) into an integer load+xor+store, which; eliminates a constant pool load. For example, consider:. define i64 @ccosf(float %z.0, float %z.1) nounwind readonly {; entry:; %tmp6 = fsub float -0.000000e+00, %z.1		; <float> [#uses=1]; %tmp20 = tail call i64 @ccoshf( float %tmp6, float %z.0 ) nounwind readonly; ret i64 %tmp20; }; declare i64 @ccoshf(float %z.0, float %z.1) nounwind readonly. This currently compiles to:. LCPI1_0:					# <4 x float>; 	.long	2147483648	# float -0; 	.long	2147483648	# ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:11906,load,load,11906,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,4,['load'],['load']
Performance,"uld look at the; root reference guide at: <http://root.cern.ch/root/Reference.html>. ## Overview of Matrix Classes. The figure below shows an overview of the classes available in the; linear algebra library,` libMatrix.so`. At the center is the base class; **`TMatrixDBase`** from which three different matrix classes,; **`TMatrixD`**, **`TMatrixDSym`** and **`TMatrixDFSparse`** derive. The; user can define customized matrix operations through the classes; **`TElementActionD`** and **`TElementsPosActionD`**. ![Overview of matrix classes](pictures/0300012D.png). Reference to different views of the matrix can be created through the; classes on the right-hand side, see ""Matrix Views"". These references; provide a natural connection to vectors. Matrix decompositions (used in equation solving and matrix inversion); are available through the classes on the left-hand side (see ""Matrix; Decompositions""). They inherit from the **`TDecompBase`** class. The; Eigen Analysis is performed through the classes at the top, see ""Matrix; Eigen Analysis"". In both cases, only some matrix types can be analyzed.; For instance, **`TDecompChol`** will only accept symmetric matrices as; defined **`TMatrixDSym`**. The assignment operator behaves somewhat; different than of most other classes. The following lines will result in; an error:. ``` {.cpp}; TMatrixD a(3,4);; TMatrixD b(5,6);; b = a;; ```. It required to first resize matrix b to the shape of `a`. ``` {.cpp}; TMatrixD a(3,4);; TMatrixD b(5,6);; b.ResizeTo(a);; b = a;; ```. ## Matrix Properties. A matrix has five properties, which are all set in the constructor:. - `precision` - float or double. In the first case you will use the; **`TMatrixF`** class family, in the latter case the **`TMatrixD`**; one;. - `type` - general (**`TMatrixD`**), symmetric (**`TMatrixDSym`**) or; sparse (**`TMatrixDSparse`**);. - `size` - number of rows and columns;. - `index` - range start of row and column index. By default these; start at zero;. - `sparse` `ma",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md:2337,perform,performed,2337,documentation/users-guide/LinearAlgebra.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md,1,['perform'],['performed']
Performance,"ule-path=<path/to/directory>``.; * (2) ``-fmodule-file=<path/to/BMI>`` (Deprecated).; * (3) ``-fmodule-file=<module-name>=<path/to/BMI>``. The option ``-fprebuilt-module-path`` tells the compiler the path where to search for dependent BMIs.; It may be used multiple times just like ``-I`` for specifying paths for header files. The look up rule here is:. * (1) When we import module M. The compiler would look up M.pcm in the directories specified; by ``-fprebuilt-module-path``.; * (2) When we import partition module unit M:P. The compiler would look up M-P.pcm in the; directories specified by ``-fprebuilt-module-path``. The option ``-fmodule-file=<path/to/BMI>`` tells the compiler to load the specified BMI directly.; The option ``-fmodule-file=<module-name>=<path/to/BMI>`` tells the compiler to load the specified BMI; for the module specified by ``<module-name>`` when necessary. The main difference is that; ``-fmodule-file=<path/to/BMI>`` will load the BMI eagerly, whereas; ``-fmodule-file=<module-name>=<path/to/BMI>`` will only load the BMI lazily, which is similar; with ``-fprebuilt-module-path``. The option ``-fmodule-file=<path/to/BMI>`` for named modules is deprecated; and is planning to be removed in future versions. In case all ``-fprebuilt-module-path=<path/to/directory>``, ``-fmodule-file=<path/to/BMI>`` and; ``-fmodule-file=<module-name>=<path/to/BMI>`` exist, the ``-fmodule-file=<path/to/BMI>`` option; takes highest precedence and ``-fmodule-file=<module-name>=<path/to/BMI>`` will take the second; highest precedence. We need to specify all the dependent (directly and indirectly) BMIs.; See https://github.com/llvm/llvm-project/issues/62707 for detail. When we compile a ``module implementation unit``, we must specify the BMI of the corresponding; ``primary module interface unit``.; Since the language specification says a module implementation unit implicitly imports; the primary module interface unit. [module.unit]p8. A module-declaration that contains neither ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst:11788,load,load,11788,interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,2,['load'],['load']
Performance,"ules. For; ROOT it is between 40-60 MB depending on the concrete configuration.; When the workload increases we notice that the overall memory performance; decreases in number of cases.; * Execution times -- likewise we have an execution overhead. For ; workflows which take ms the slowdown can be 2x. Increasing of the work; to seconds shows 50-60% slowdowns. The performance is dependent on many factors such as configuration of ROOT and; workflow. You can read more at our Intel IPCC-ROOT Showcase presentation; here (pp 25-33)[[8]]. #### Loading C++ Modules on Demand. In long term, we should optimize the preloading of modules to be a no-op and; avoid recursive behavior based on identifier lookup callbacks. Unfortunately,; at the moment the loading of C++ modules on demand shows significantly better; performance results. You can visit our continuous performance monitoring tool where we compare; the performance of ROOT against ROOT with a PCH [[9]].; *Note: if you get error 400, clean your cache or open a private browser session.*. ## How to use; C++ Modules in ROOT are default since v6.20 (Unix) and v6.22 (OSX). Enjoy. To disable C++ Modules in ROOT use `-Druntime_cxxmodules=Off`. ## Citing ROOT's C++ Modules; ```latex; % Peer-Reviewed Publication; %; % 22nd International Conference on Computing in High Energy and Nuclear Physics (CHEP); % 8-14 October, 2016, San Francisco, USA; %; @inproceedings{Vassilev_ROOTModules,; author = {Vassilev,V.},; title = {{Optimizing ROOT's Performance Using C++ Modules}},; journal = {Journal of Physics: Conference Series},; year = 2017,; month = {oct},; volume = {898},; number = {7},; pages = {072023},; doi = {10.1088/1742-6596/898/7/072023},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/898/7/072023/pdf},; publisher = {{IOP} Publishing}; }; ```; ; # Acknowledgement. We would like to thank the ROOT team. We would like to thank Liz Sexton-Kennedy (FNAL) in particular for supporting; this project. We would like to thank Axel",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:19311,cache,cache,19311,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['cache'],['cache']
Performance,"ull as a function parameter; which is annotated with ``_Nonnull``.; - ``-fsanitize=nullability-assign``: Assigning null to an lvalue which; is annotated with ``_Nonnull``.; - ``-fsanitize=nullability-return``: Returning null from a function with; a return type annotated with ``_Nonnull``.; - ``-fsanitize=objc-cast``: Invalid implicit cast of an ObjC object pointer; to an incompatible type. This is often unintentional, but is not undefined; behavior, therefore the check is not a part of the ``undefined`` group.; Currently only supported on Darwin.; - ``-fsanitize=object-size``: An attempt to potentially use bytes which; the optimizer can determine are not part of the object being accessed.; This will also detect some types of undefined behavior that may not; directly access memory, but are provably incorrect given the size of; the objects involved, such as invalid downcasts and calling methods on; invalid pointers. These checks are made in terms of; ``__builtin_object_size``, and consequently may be able to detect more; problems at higher optimization levels.; - ``-fsanitize=pointer-overflow``: Performing pointer arithmetic which; overflows, or where either the old or new pointer value is a null pointer; (or in C, when they both are).; - ``-fsanitize=return``: In C++, reaching the end of a; value-returning function without returning a value.; - ``-fsanitize=returns-nonnull-attribute``: Returning null pointer; from a function which is declared to never return null.; - ``-fsanitize=shift``: Shift operators where the amount shifted is; greater or equal to the promoted bit-width of the left hand side; or less than zero, or where the left hand side is negative. For a; signed left shift, also checks for signed overflow in C, and for; unsigned overflow in C++. You can use ``-fsanitize=shift-base`` or; ``-fsanitize=shift-exponent`` to check only left-hand side or; right-hand side of shift operation, respectively.; - ``-fsanitize=unsigned-shift-base``: check that an unsigned l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst:7538,optimiz,optimization,7538,interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst,1,['optimiz'],['optimization']
Performance,"ult all such opcodes are filtered out.; This flag will instead show only such unstable opcodes. .. option:: --ignore-invalid-sched-class=false. If set, ignore instructions that do not have a sched class (class idx = 0). .. option:: --mtriple=<triple name>. Target triple. See `-version` for available targets. .. option:: --mcpu=<cpu name>. If set, measure the cpu characteristics using the counters for this CPU. This; is useful when creating new sched models (the host CPU is unknown to LLVM).; (`-mcpu=help` for details). .. option:: --analysis-override-benchmark-triple-and-cpu. By default, llvm-exegesis will analyze the benchmarks for the triple/CPU they; were measured for, but if you want to analyze them for some other combination; (specified via `-mtriple`/`-mcpu`), you can pass this flag. .. option:: --dump-object-to-disk=true. If set, llvm-exegesis will dump the generated code to a temporary file to; enable code inspection. Disabled by default. .. option:: --use-dummy-perf-counters. If set, llvm-exegesis will not read any real performance counters and; return a dummy value instead. This can be used to ensure a snippet doesn't; crash when hardware performance counters are unavailable and for; debugging :program:`llvm-exegesis` itself. .. option:: --execution-mode=[inprocess,subprocess]. This option specifies what execution mode to use. The `inprocess` execution; mode is the default. The `subprocess` execution mode allows for additional; features such as memory annotations but is currently restricted to X86-64; on Linux. .. option:: --benchmark-repeat-count=<repeat-count>. This option enables specifying the number of times to repeat the measurement; when performing latency measurements. By default, llvm-exegesis will repeat; a latency measurement enough times to balance run-time and noise reduction. EXIT STATUS; -----------. :program:`llvm-exegesis` returns 0 on success. Otherwise, an error message is; printed to standard error, and the tool returns a non 0 value.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:17602,perform,performance,17602,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,5,"['latency', 'perform']","['latency', 'performance', 'performing']"
Performance,"ult from 1.9 GBytes to 100 GBytes.; Add new special functions in TTreeFormula (and hence TTree::Draw and TTree::Scan) to calculate the minimun and maximum with an entry:; ; Min$(formula),Max$(formula):return the minimun/maximum (within one TTree entry) of the value of the; elements of the formula given as a parameter.; MinIf$(formula,condition),MaxIf$(formula,condition):return the minimum (maximum) (within one TTree entry); of the value of the elements of the formula given as a parameter; if they match the condition. If not element match the condition, the result is zero. To avoid the; the result is zero. To avoid the consequent peak a zero, use the; pattern:; tree->Draw(""MinIf$(formula,condition)"",""condition"");; which will avoid calculation MinIf$ for the entries that have no match; for the condition. Add support in TTreeFormula (and hence TTree::Draw and TTree::Scan) for the ternary condition operator ( cond ? if_expr : else_expr ).; Significantly (by 2 order of magnitude) improved the performance of TTree::Draw calling C++ functions.; Replace the function TSelectorDraw::MakeIndex and TSelectorDraw::GetNameByIndex; with the function TSelectorDraw::SplitNames. ; Add a return value to SetBranchAddress, a return value greater or equal to zero indicate success, a negative; value indicates failure (in both case, the address is still updated). Example:; if (tree->SetBranchAddress(mybranch,&myvar) < 0) {; cerr << ""Something went wrong\n"";; return;; }; The possible return values are:; kMissingBranch (-5) : Missing branch; kInternalError (-4) : Internal error (could not find the type corresponding to a data type number.; kMissingCompiledCollectionProxy (-3) : Missing compiled collection proxy for a compiled collection.; kMismatch (-2) : Non-Class Pointer type given does not match the type expected by the branch.; kClassMismatch (-1) : Class Pointer type given does not match the type expected by the branch.; kMatch (0) : perfect match.; kMatchConversion (1) : match with (I/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:1039,perform,performance,1039,tree/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html,1,['perform'],['performance']
Performance,"ult; environment. When code is compiled in this default mode, operations that depend; on the environment (such as floating-point arithmetic and `FLT_ROUNDS`) may have; undefined behavior if the dynamic environment is not the default environment; for; example, `FLT_ROUNDS` may or may not simply return its default value for the target; instead of reading the dynamic environment, and floating-point operations may be; optimized as if the dynamic environment were the default. Similarly, it is undefined; behavior to change the floating point environment in this default mode, for example; by calling the `fesetround` function.; C provides two pragmas to allow code to dynamically modify the floating point environment:. - ``#pragma STDC FENV_ACCESS ON`` allows dynamic changes to the entire floating; point environment. - ``#pragma STDC FENV_ROUND FE_DYNAMIC`` allows dynamic changes to just the floating; point rounding mode. This may be more optimizable than ``FENV_ACCESS ON`` because; the compiler can still ignore the possibility of floating-point exceptions by default. Both of these can be used either at the start of a block scope, in which case; they cover all code in that scope (unless they're turned off in a child scope),; or at the top level in a file, in which case they cover all subsequent function; bodies until they're turned off. Note that it is undefined behavior to enter; code that is *not* covered by one of these pragmas from code that *is* covered; by one of these pragmas unless the floating point environment has been restored; to its default state. See the C standard for more information about these pragmas. The command line option ``-frounding-math`` behaves as if the translation unit; began with ``#pragma STDC FENV_ROUND FE_DYNAMIC``. The command line option; ``-ffp-model=strict`` behaves as if the translation unit began with ``#pragma STDC FENV_ACCESS ON``. Code that just wants to use a specific rounding mode for specific floating point; operations can avoid mo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:70383,optimiz,optimizable,70383,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizable']
Performance,"ulting; ``llvm.module.flags`` metadata is the union of the modules' flags. That is, for; each unique metadata ID string, there will be exactly one entry in the merged; modules ``llvm.module.flags`` metadata table, and the value for that entry will; be determined by the merge behavior flag, as described below. The only exception; is that entries with the *Require* behavior are always preserved. The following behaviors are supported:. .. list-table::; :header-rows: 1; :widths: 10 90. * - Value; - Behavior. * - 1; - **Error**; Emits an error if two values disagree, otherwise the resulting value; is that of the operands. * - 2; - **Warning**; Emits a warning if two values disagree. The result value will be the; operand for the flag from the first module being linked, unless the; other module uses **Min** or **Max**, in which case the result will; be **Min** (with the min value) or **Max** (with the max value),; respectively. * - 3; - **Require**; Adds a requirement that another module flag be present and have a; specified value after linking is performed. The value must be a; metadata pair, where the first element of the pair is the ID of the; module flag to be restricted, and the second element of the pair is; the value the module flag should be restricted to. This behavior can; be used to restrict the allowable results (via triggering of an; error) of linking IDs with the **Override** behavior. * - 4; - **Override**; Uses the specified value, regardless of the behavior or value of the; other module. If both modules specify **Override**, but the values; differ, an error will be emitted. * - 5; - **Append**; Appends the two values, which are required to be metadata nodes. * - 6; - **AppendUnique**; Appends the two values, which are required to be metadata; nodes. However, duplicate entries in the second list are dropped; during the append operation. * - 7; - **Max**; Takes the max of the two values, which are required to be integers. * - 8; - **Min**; Takes the min of th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:328841,perform,performed,328841,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"ultiple locations over part or all of its lifetime.*. If a location description has more than one single location description, the; DWARF expression is ill-formed if the object value held in each single location; description's position within the associated location storage is not the same; value, except for the parts of the value that are uninitialized. *A location description that has more than one single location description can; only be created by a location list expression that has overlapping program; location ranges, or certain expression operations that act on a location; description that has more than one single location description. There are no; operation expression operations that can directly create a location description; with more than one single location description.*. *A location description with more than one single location description can be; used to describe objects that reside in more than one piece of storage at the; same time. An object may have more than one location as a result of; optimization. For example, a value that is only read may be promoted from memory; to a register for some region of code, but later code may revert to reading the; value from memory as the register may be used for other purposes. For the code; region where the value is in a register, any change to the object value must be; made in both the register and the memory so both regions of code will read the; updated value.*. *A consumer of a location description with more than one single location; description can read the object's value from any of the single location; descriptions (since they all refer to location storage that has the same value),; but must write any changed value to all the single location descriptions.*. The evaluation of an expression may require context elements to create a; location description. If such a location description is accessed, the storage it; denotes is that associated with the context element values specified when the; location descrip",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:60774,optimiz,optimization,60774,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['optimiz'],['optimization']
Performance,"ultiple; sections. Supported flag names are `alloc`, `load`, `noload`, `readonly`, `exclude`,; `debug`, `code`, `data`, `rom`, `share`, `contents`, `merge`, `strings`, and; `large`. Not all flags are meaningful for all object file formats or target; architectures. For ELF objects, the flags have the following effects:. - `alloc` = add the `SHF_ALLOC` flag.; - `load` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `readonly` = if this flag is not specified, add the `SHF_WRITE` flag.; - `exclude` = add the `SHF_EXCLUDE` flag.; - `code` = add the `SHF_EXECINSTR` flag.; - `merge` = add the `SHF_MERGE` flag.; - `strings` = add the `SHF_STRINGS` flag.; - `contents` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `large` = add the `SHF_X86_64_LARGE` on x86_64; rejected if the target; architecture is not x86_64. For COFF objects, the flags have the following effects:. - `alloc` = add the `IMAGE_SCN_CNT_UNINITIALIZED_DATA` and `IMAGE_SCN_MEM_READ`; flags, unless the `load` flag is specified.; - `noload` = add the `IMAGE_SCN_LNK_REMOVE` and `IMAGE_SCN_MEM_READ` flags.; - `readonly` = if this flag is not specified, add the `IMAGE_SCN_MEM_WRITE`; flag.; - `exclude` = add the `IMAGE_SCN_LNK_REMOVE` and `IMAGE_SCN_MEM_READ` flags.; - `debug` = add the `IMAGE_SCN_CNT_INITIALIZED_DATA`,; `IMAGE_SCN_MEM_DISCARDABLE` and `IMAGE_SCN_MEM_READ` flags.; - `code` = add the `IMAGE_SCN_CNT_CODE`, `IMAGE_SCN_MEM_EXECUTE` and; `IMAGE_SCN_MEM_READ` flags.; - `data` = add the `IMAGE_SCN_CNT_INITIALIZED_DATA` and `IMAGE_SCN_MEM_READ`; flags.; - `share` = add the `IMAGE_SCN_MEM_SHARED` and `IMAGE_SCN_MEM_READ` flags. .. option:: --strip-all-gnu. Remove all symbols, debug sections and relocations from the output. This option; is equivalent to GNU :program:`objcopy`'s ``--strip-all`` switch. .. option:: --strip-all, -S. For ELF objects, remove from the output all symbols and non-alloc sections not; within segments, except for .gnu.war",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:5857,load,load,5857,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,1,['load'],['load']
Performance,"ultiplication trees. First, the intrinsic needs to be extended to support integers, and second the; code generator needs to be enhanced to lower these to multiplication trees. //===---------------------------------------------------------------------===//. Interesting? testcase for add/shift/mul reassoc:. int bar(int x, int y) {; return x*x*x+y+x*x*x*x*x*y*y*y*y;; }; int foo(int z, int n) {; return bar(z, n) + bar(2*z, 2*n);; }. This is blocked on not handling X*X*X -> powi(X, 3) (see note above). The issue; is that we end up getting t = 2*X s = t*t and don't turn this into 4*X*X,; which is the same number of multiplies and is canonical, because the 2*X has; multiple uses. Here's a simple example:. define i32 @test15(i32 %X1) {; %B = mul i32 %X1, 47 ; X1*47; %C = mul i32 %B, %B; ret i32 %C; }. //===---------------------------------------------------------------------===//. Reassociate should handle the example in GCC PR16157:. extern int a0, a1, a2, a3, a4; extern int b0, b1, b2, b3, b4; ; void f () { /* this can be optimized to four additions... */ ; b4 = a4 + a3 + a2 + a1 + a0; ; b3 = a3 + a2 + a1 + a0; ; b2 = a2 + a1 + a0; ; b1 = a1 + a0; ; } . This requires reassociating to forms of expressions that are already available,; something that reassoc doesn't think about yet. //===---------------------------------------------------------------------===//. These two functions should generate the same code on big-endian systems:. int g(int *j,int *l) { return memcmp(j,l,4); }; int h(int *j, int *l) { return *j - *l; }. this could be done in SelectionDAGISel.cpp, along with other special cases,; for 1,2,4,8 bytes. //===---------------------------------------------------------------------===//. It would be nice to revert this patch:; http://lists.llvm.org/pipermail/llvm-commits/Week-of-Mon-20060213/031986.html. And teach the dag combiner enough to simplify the code expanded before ; legalize. It seems plausible that this knowledge would let it simplify other; stuff too. /",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:2622,optimiz,optimized,2622,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['optimiz'],['optimized']
Performance,"um size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. That is because the FP multiplier JFPM is only available; from pipeline JFPU1. Instruction encodings are displayed within the instruction info view when flag; `-show-encoding` is specified. Below is an example of `-show-encoding` output for the dot-product kernel:. .. code-block:: none.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:18358,perform,performance,18358,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['bottleneck', 'perform']","['bottleneck', 'performance']"
Performance,"umber in the current; tree. Assuming that `fChain` is the pointer to the **`TChain`**; being processed, use. ``` {.cpp}; fChain->GetTree()->GetEntry(entry);; ```. To create a selector call:. ``` {.cpp}; root[] T->MakeSelector(""MySelector"");; ```. Where `T` is the **`TTree`** and `MySelector` is the name of created; class and the name of the `.h` and `.C` files. The resulting; **`TSelector`** is the argument to **`TTree::Process`**. The argument can; be the file name or a pointer to the selector object. ``` {.cpp}; root[] T->Process(""MySelector.C"","""",1000,100);; ```. This call will interpret the class defined in `MySelector.C` and process; 1000 entries beginning with entry 100. The file name can be appended; with a ""+"" or a ""++"" to use `ACLiC`. ``` {.cpp}; root[] T->Process(""MySelector.C++"","""",1000,100);; ```. When appending a ""++"", the class will be compiled and dynamically; loaded. ``` {.cpp}; root[] T->Process(""MySelector.C+"","""",1000,100);; ```. When appending a ""+"", the class will also be compiled and dynamically; loaded. When it is called again, it recompiles only if the macro; (`MySelector.C`) has changed since it was compiled last. If not, it; loads the existing library. The next example shows how to create a; selector with a pointer:. ``` {.cpp}; MySelector *selector = (MySelector *)TSelector::GetSelector(""MySelector.C+"");; T->Process(selector);; ```. `Using this form, you can do things like:`. ``` {.cpp}; selector->public_attribute1 = init_value;; for (int i=0; i<limit; i++) {; T->Process(selector);; selector->public_attribute1 =; function(selector->public_attribute2);; }; ```. `TTree::Process()` is aware of PROOF, ROOT parallel processing facility.; If PROOF is setup, it divides the processing amongst the slave CPUs. ### Performance Benchmarks; \index{benchmarks}. The program `$ROOTSYS/test/bench.cxx` compares the I/O performance of; STL vectors to the ROOT native **`TClonesArray`**`s` collection class.; It creates trees with and without compression for the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:134376,load,loaded,134376,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['load'],['loaded']
Performance,"umber of alias queries. This can cause debugging techniques; involving pausing execution after a predetermined number of queries to be; unreliable. Many alias queries can be reformulated in terms of other alias queries. When; multiple ``AliasAnalysis`` queries are chained together, it would make sense to; start those queries from the beginning of the chain, with care taken to avoid; infinite looping, however currently an implementation which wants to do this can; only start such queries from itself. Using alias analysis results; ============================. There are several different ways to use alias analysis results. In order of; preference, these are:. Using the ``MemoryDependenceAnalysis`` Pass; -------------------------------------------. The ``memdep`` pass uses alias analysis to provide high-level dependence; information about memory-using instructions. This will tell you which store; feeds into a load, for example. It uses caching and other techniques to be; efficient, and is used by Dead Store Elimination, GVN, and memcpy optimizations. .. _AliasSetTracker:. Using the ``AliasSetTracker`` class; -----------------------------------. Many transformations need information about alias **sets** that are active in; some scope, rather than information about pairwise aliasing. The; `AliasSetTracker <https://llvm.org/doxygen/classllvm_1_1AliasSetTracker.html>`__; class is used to efficiently build these Alias Sets from the pairwise alias; analysis information provided by the ``AliasAnalysis`` interface. First you initialize the AliasSetTracker by using the ""``add``"" methods to add; information about various potentially aliasing instructions in the scope you are; interested in. Once all of the alias sets are completed, your pass should; simply iterate through the constructed alias sets, using the ``AliasSetTracker``; ``begin()``/``end()`` methods. The ``AliasSet``\s formed by the ``AliasSetTracker`` are guaranteed to be; disjoint, calculate mod/ref information and vo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:19802,optimiz,optimizations,19802,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['optimiz'],['optimizations']
Performance,"ume objects inherit from TAttLine class so the line style or; width can also be changed:. ``` {.cpp}; myVolume->SetLineColor(kRed);; myVolume->SetLineWith(2);; myVolume->SetLineStyle(kDotted);; ```. When drawing in solid mode, the color of the drawn volume corresponds to; the line color. #### Visibility Settings. The way geometry is build forces the definition of several volumes that; does not represent real objects, but just virtual containers used for; grouping and positioning volumes together. One would not want to see; them in the picture. Since every volume is by default visible, one has; to do this sort of tuning by its own:. ``` {.cpp}; myVolumeContainer->SetVisibility(kFALSE);; ```. As described before, the drawing package supports two main global; options: 1 (default) - only final volume leaves; 0 - all volumes down; the drawn one appear on the screen. The global visible level put a; limitation on the maximum applied depth. Combined with visibility; settings per volume, these can tune quite well what should appear on the; screen. However, there are situations when users want to see a volume; branch displayed down to the maximum depth, keeping at the same time a; limitation or even suppressing others. In order to accomplish that, one; should use the volume attribute: `Visible daughters`. By default, all; daughters of all volumes are displayed if there is no limitation related; with their level depth with respect to the top drawn volume. ### Ray Tracing. Ray tracing is a quite known drawing technique based on tracking rays; from the eye position through all pixels of a view port device. The; pixel color is derived from the properties of the first crossed surface,; according some illumination model and material optical properties. While; there are currently existing quite sophisticated ray tracing models,; **`TGeo`** is currently using a very simple approach where the light; source is matching the eye position (no shadows or back-tracing of the; reflected ray)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:142619,tune,tune,142619,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['tune'],['tune']
Performance,"ume you have an X86-64 machine. To measure the latency of a single; instruction, run:. .. code-block:: bash. $ llvm-exegesis --mode=latency --opcode-name=ADD64rr. Measuring the uop decomposition or inverse throughput of an instruction works similarly:. .. code-block:: bash. $ llvm-exegesis --mode=uops --opcode-name=ADD64rr; $ llvm-exegesis --mode=inverse_throughput --opcode-name=ADD64rr. The output is a YAML document (the default is to write to stdout, but you can; redirect the output to a file using `--benchmarks-file`):. .. code-block:: none. ---; key:; opcode_name: ADD64rr; mode: latency; config: ''; cpu_name: haswell; llvm_triple: x86_64-unknown-linux-gnu; num_repetitions: 10000; measurements:; - { key: latency, value: 1.0058, debug_string: '' }; error: ''; info: 'explicit self cycles, selecting one aliasing configuration.; Snippet:; ADD64rr R8, R8, R10; '; ... To measure the latency of all instructions for the host architecture, run:. .. code-block:: bash. $ llvm-exegesis --mode=latency --opcode-index=-1. EXAMPLE 2: benchmarking a custom code snippet; ---------------------------------------------. To measure the latency/uops of a custom piece of code, you can specify the; `snippets-file` option (`-` reads from standard input). .. code-block:: bash. $ echo ""vzeroupper"" | llvm-exegesis --mode=uops --snippets-file=-. Real-life code snippets typically depend on registers or memory.; :program:`llvm-exegesis` checks the liveliness of registers (i.e. any register; use has a corresponding def or is a ""live in""). If your code depends on the; value of some registers, you need to use snippet annotations to ensure setup; is performed properly. For example, the following code snippet depends on the values of XMM1 (which; will be set by the tool) and the memory buffer passed in RDI (live in). .. code-block:: none. # LLVM-EXEGESIS-LIVEIN RDI; # LLVM-EXEGESIS-DEFREG XMM1 42; vmulps	(%rdi), %xmm1, %xmm2; vhaddps	%xmm2, %xmm2, %xmm3; addq $0x10, %rdi. Example 3: benchmarking wit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:5793,latency,latency,5793,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['latency'],['latency']
Performance,"ument only accepts constants. Semantics:; """""""""""""""""""". Using this intrinsic on a coroutine that does not have a coroutine promise; leads to undefined behavior. It is possible to read and modify coroutine; promise of the coroutine which is currently executing. The coroutine author and; a coroutine user are responsible to makes sure there is no data races. Example:; """""""""""""""". .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %promise = alloca i32; ; the second argument to coro.id points to the coroutine promise.; %id = call token @llvm.coro.id(i32 0, ptr %promise, ptr null, ptr null); ...; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); ...; store i32 42, ptr %promise ; store something into the promise; ...; ret ptr %hdl; }. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4) ; starts the coroutine and returns its handle; %promise.addr = call ptr @llvm.coro.promise(ptr %hdl, i32 4, i1 false); %val = load i32, ptr %promise.addr ; load a value from the promise; call void @print(i32 %val); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. .. _coroutine intrinsics:. Coroutine Structure Intrinsics; ------------------------------; Intrinsics described in this section are used within a coroutine to describe; the coroutine structure. They should not be used outside of a coroutine. .. _coro.size:. 'llvm.coro.size' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i32 @llvm.coro.size.i32(); declare i64 @llvm.coro.size.i64(). Overview:; """""""""""""""""". The '``llvm.coro.size``' intrinsic returns the number of bytes; required to store a `coroutine frame`_. This is only supported for; switched-resume coroutines. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". The `coro.size` intrinsic is lowered to a constant representing the size of; the coroutine frame. .. _coro.align:. 'llvm.coro.align' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i32 @llvm.coro.align.i32(); declare i64 @llvm.coro.align.i64(). Overview:; """""""""""""""""". T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:30983,load,load,30983,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['load'],['load']
Performance,"unction writes to a readonly pointer argument, the behavior is; undefined. ``writeonly``; This attribute indicates that the function may write to, but does not read; through this pointer argument (even though it may read from the memory that; the pointer points to). If a function reads from a writeonly pointer argument, the behavior is; undefined. ``writable``; This attribute is only meaningful in conjunction with ``dereferenceable(N)``; or another attribute that implies the first ``N`` bytes of the pointer; argument are dereferenceable. In that case, the attribute indicates that the first ``N`` bytes will be; (non-atomically) loaded and stored back on entry to the function. This implies that it's possible to introduce spurious stores on entry to; the function without introducing traps or data races. This does not; necessarily hold throughout the whole function, as the pointer may escape; to a different thread during the execution of the function. See also the; :ref:`atomic optimization guide <Optimization outside atomic>`. The ""other attributes"" that imply dereferenceability are; ``dereferenceable_or_null`` (if the pointer is non-null) and the; ``sret``, ``byval``, ``byref``, ``inalloca``, ``preallocated`` family of; attributes. Note that not all of these combinations are useful, e.g.; ``byval`` arguments are known to be writable even without this attribute. The ``writable`` attribute cannot be combined with ``readnone``,; ``readonly`` or a ``memory`` attribute that does not contain; ``argmem: write``. ``dead_on_unwind``; At a high level, this attribute indicates that the pointer argument is dead; if the call unwinds, in the sense that the caller will not depend on the; contents of the memory. Stores that would only be visible on the unwind; path can be elided. More precisely, the behavior is as-if any memory written through the; pointer during the execution of the function is overwritten with a poison; value on unwind. This includes memory written by the implicit ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:70503,optimiz,optimization,70503,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance,"und are the same, and as this is the recommended setting, the ""bug"" ; had very litte impact. However in order to be a ""correct"" Fisher discriminant, ; the correct calculation has now been adopted. Fisher and LD are the same, ONCE; the events are weighted such that signal and background have the same weight. ; Hence, the LD classifier still gives exactly the same result as the ""old"" Fisher; implementation, while the corrected Fisher implementation allows to ""play"" with; different event weights to perhaps find better discrimination power in certain; regions of the ROC curve. ; 2) BDT. a) Changes to some tuning options . nEventsMin --> MinNodeSize; UseNTrainEvents --> BaggedSampleFraction. have been replaced by options that are now given in terms of the relative; size of the training sample rather than in absulut numbers of events. This; is in order to facilitate the parameter tuning on different sample sizes; (i.e when starting on a smaller data sample to tune the parameter in order; to speed up the training); Furthermore, this option here has been changed name. GradBaggingFraction --> BaggedSampleFraction. in an attempt to consolidate and avoid idential duplicate code; ; The option UseWeightedTrees has been removed and set to ""true"", as was default; anyway, as a measure of further consolidation. Removed the option NNodesMax --> This should be replaced by specifying MaxDepth; instead (limiting the maximum tree depth also limits the number of possible nodes!). b) Added a trial version of a new ""cost sensitive"" boosting algorithem according to; Wei Fan and Salvatore J. Stolfo, {\em AdaCost: misclassification cost-sensitive boosting}, Proceedings of the 16th International conference on machine learning (ICML 1999)}. With the currently; chosen DEFAULT settings (all costs equal and set to ""one""), it is equivalent to the ""real-AdaBoost"" (i.e. using the option !UseYesNoLeaf (which uses the leave node purity rather than a signal or background attribute in the leaf node of eac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt:1402,tune,tune,1402,documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt,1,['tune'],['tune']
Performance,"und.dynamic"" because if the value of 'x' is +0 then; 'x-0' should evaluate to '-0' when rounding downward. However, this; transformation is legal for all other rounding modes. For values other than ""round.dynamic"" optimization passes may assume that the; actual runtime rounding mode (as defined in a target-specific manner) matches; the specified rounding mode, but this is not guaranteed. Using a specific; non-dynamic rounding mode which does not match the actual rounding mode at; runtime results in undefined behavior. The exception behavior argument is a metadata string describing the floating; point exception semantics that required for the intrinsic. This argument; must be one of the following strings:. ::. ""fpexcept.ignore""; ""fpexcept.maytrap""; ""fpexcept.strict"". If this argument is ""fpexcept.ignore"" optimization passes may assume that the; exception status flags will not be read and that floating-point exceptions will; be masked. This allows transformations to be performed that may change the; exception semantics of the original code. For example, FP operations may be; speculatively executed in this case whereas they must not be for either of the; other possible values of this argument. If the exception behavior argument is ""fpexcept.maytrap"" optimization passes; must avoid transformations that may raise exceptions that would not have been; raised by the original code (such as speculatively executing FP operations), but; passes are not required to preserve all exceptions that are implied by the; original code. For example, exceptions may be potentially hidden by constant; folding. If the exception behavior argument is ""fpexcept.strict"" all transformations must; strictly preserve the floating-point exception semantics of the original code.; Any FP exception that would have been raised by the original code must be raised; by the transformed code, and the transformed code must not raise any FP; exceptions that would not have been raised by the original code. This is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:870241,perform,performed,870241,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"undamentals and; finally work up to building a complete, working program ? Let's skip all; that. In this guide, we will describe macros executed by the ROOT C++; interpreter Cling. It is relatively easy to compile a macro, either as a pre-compiled; library to load into ROOT, or as a stand-alone application, by adding; some include statements for header file or some ""dressing code"" to any; macro. ## General Remarks on ROOT macros ##. If you have a number of lines which you were able to execute at the ROOT; prompt, they can be turned into a ROOT macro by giving them a name which; corresponds to the file name without extension. The general structure; for a macro stored in file `MacroName.C` is. ``` {.cpp}; void MacroName() {; < ...; your lines of C++ code; ... >; }; ```. The macro is executed by typing. ``` {.cpp}; > root MacroName.C; ```. at the system prompt, or executed using `.x`. ``` {.cpp}; > root; root [0] .x MacroName.C; ```. at the ROOT prompt. or it can be loaded into a ROOT session and then; be executed by typing. ``` {.cpp}; root [0].L MacroName.C; root [1] MacroName();; ```. at the ROOT prompt. Note that more than one macro can be loaded this; way, as each macro has a unique name in the ROOT name space. A small set; of options can help making your plot nicer. ``` {.cpp}; gROOT->SetStyle(""Plain""); // set plain TStyle; gStyle->SetOptStat(111111); // draw statistics on plots,; // (0) for no output; gStyle->SetOptFit(1111); // draw fit results on plot,; // (0) for no ouput; gStyle->SetPalette(57); // set color map; gStyle->SetOptTitle(0); // suppress title box; ...; ```. Next, you should create a canvas for graphical output, with size,; subdivisions and format suitable to your needs, see documentation of; class `TCanvas`:. ``` {.cpp}; TCanvas c1(""c1"",""<Title>"",0,0,400,300); // create a canvas, specify position and size in pixels; c1.Divide(2,2); //set subdivisions, called pads; c1.cd(1); //change to pad 1 of canvas c1; ```. These parts of a well-written macro a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/your_first_ROOT_macro.md:1052,load,loaded,1052,documentation/primer/your_first_ROOT_macro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/your_first_ROOT_macro.md,1,['load'],['loaded']
Performance,"unded up to 1 or down to 0.5; %res = call i4 @llvm.sdiv.fix.sat.i4(i4 3, i4 4, i32 1) ; %res = 2 (or 1) (1.5 / 2 = 0.75). ; Saturation; %res = call i4 @llvm.sdiv.fix.sat.i4(i4 -8, i4 -1, i32 0) ; %res = 7 (-8 / -1 = 8 => 7); %res = call i4 @llvm.sdiv.fix.sat.i4(i4 4, i4 2, i32 2) ; %res = 7 (1 / 0.5 = 2 => 1.75); %res = call i4 @llvm.sdiv.fix.sat.i4(i4 -4, i4 1, i32 2) ; %res = -8 (-1 / 0.25 = -4 => -2). '``llvm.udiv.fix.sat.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.udiv.fix.sat``; on any integer bit width or vectors of integers. ::. declare i16 @llvm.udiv.fix.sat.i16(i16 %a, i16 %b, i32 %scale); declare i32 @llvm.udiv.fix.sat.i32(i32 %a, i32 %b, i32 %scale); declare i64 @llvm.udiv.fix.sat.i64(i64 %a, i64 %b, i32 %scale); declare <4 x i32> @llvm.udiv.fix.sat.v4i32(<4 x i32> %a, <4 x i32> %b, i32 %scale). Overview; """""""""""""""""". The '``llvm.udiv.fix.sat``' family of intrinsic functions perform unsigned; fixed point saturating division on 2 arguments of the same scale. Arguments; """""""""""""""""""". The arguments (%a and %b) and the result may be of integer types of any bit; width, but they must have the same bit width. ``%a`` and ``%b`` are the two; values that will undergo unsigned fixed point division. The argument; ``%scale`` represents the scale of both operands, and must be a constant; integer. Semantics:; """""""""""""""""""". This operation performs fixed point division on the 2 arguments of a; specified scale. The result will also be returned in the same scale specified; in the third argument. If the result value cannot be precisely represented in the given scale, the; value is rounded up or down to the closest representable value. The rounding; direction is unspecified. The maximum value this operation can clamp to is the largest unsigned value; representable by the bit width of the first 2 arguments. The minimum value is the; smallest unsigned value representable by this bit width (zero). It is un",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:636786,perform,perform,636786,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"unning programs in; an isolated and reproducible environment, especially to maintain releases for; software deployed to large distributed fleets.; It uses linux kernel namespaces and cgroups to provide a lightweight isolation; inside currently running linux kernel.; A single active instance of dockerized environment is called a *docker; container*.; A snapshot of a docker container filesystem is called a *docker image*.; One can start a container from a prebuilt docker image. Docker images are built from a so-called *Dockerfile*, a source file written in; a specialized language that defines instructions to be used when build; the docker image (see `official; documentation <https://docs.docker.com/engine/reference/builder/>`_ for more; details). A minimal Dockerfile typically contains a base image and a number; of RUN commands that have to be executed to build the image. When building a new; image, docker will first download your base image, mount its filesystem as; read-only and then add a writable overlay on top of it to keep track of all; filesystem modifications, performed while building your image. When the build; process is finished, a diff between your image's final filesystem state and the; base image's filesystem is stored in the resulting image. Overview; ========; The ``llvm/utils/docker`` folder contains Dockerfiles and simple bash scripts to; serve as a basis for anyone who wants to create their own Docker image with; LLVM components, compiled from sources. The sources are checked out from the; upstream git repository when building the image. The resulting image contains only the requested LLVM components and a few extra; packages to make the image minimally useful for C++ development, e.g. libstdc++; and binutils. The interface to run the build is ``build_docker_image.sh`` script. It accepts a; list of LLVM repositories to checkout and arguments for CMake invocation. If you want to write your own docker image, start with an ``example/`` subfolder.; It pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:2212,perform,performed,2212,interpreter/llvm-project/llvm/docs/Docker.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst,1,['perform'],['performed']
Performance,"unt can be specified explicitly with ``unroll_count(_value_)`` where; _value_ is a positive integer. If this value is greater than the trip count the; loop will be fully unrolled. Otherwise the loop is partially unrolled subject; to the same code size limit as with ``unroll(enable)``. .. code-block:: c++. #pragma clang loop unroll_count(8); for(...) {; ...; }. Unrolling of a loop can be prevented by specifying ``unroll(disable)``. Loop unroll parameters can be controlled by options; `-mllvm -unroll-count=n` and `-mllvm -pragma-unroll-threshold=n`. Loop Distribution; -----------------. Loop Distribution allows splitting a loop into multiple loops. This is; beneficial for example when the entire loop cannot be vectorized but some of the; resulting loops can. If ``distribute(enable))`` is specified and the loop has memory dependencies; that inhibit vectorization, the compiler will attempt to isolate the offending; operations into a new loop. This optimization is not enabled by default, only; loops marked with the pragma are considered. .. code-block:: c++. #pragma clang loop distribute(enable); for (i = 0; i < N; ++i) {; S1: A[i + 1] = A[i] + B[i];; S2: C[i] = D[i] * E[i];; }. This loop will be split into two loops between statements S1 and S2. The; second loop containing S2 will be vectorized. Loop Distribution is currently not enabled by default in the optimizer because; it can hurt performance in some cases. For example, instruction-level; parallelism could be reduced by sequentializing the execution of the; statements S1 and S2 above. If Loop Distribution is turned on globally with; ``-mllvm -enable-loop-distribution``, specifying ``distribute(disable)`` can; be used the disable it on a per-loop basis. Additional Information; ----------------------. For convenience multiple loop hints can be specified on a single line. .. code-block:: c++. #pragma clang loop vectorize_width(4) interleave_count(8); for(...) {; ...; }. If an optimization cannot be applied any hints t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:168216,optimiz,optimization,168216,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimization']
Performance,"unted_by`` in the example below) must be updated side by side within the; same basic block and without side effect in between. .. code-block:: c. typedef struct {; int *__counted_by(count) buf; size_t count;; } sized_buf_t;. void alloc_buf(sized_buf_t *sbuf, sized_t nelems) {; sbuf->buf = (int *)malloc(sizeof(int) * nelems);; sbuf->count = nelems;; }. To implement this rule, the compiler requires a linear representation of; statements to understand the ordering and the adjacency between the two or more; assignments. The Clang CFG is used to implement this analysis as Clang CFG; provides a linear view of statements within each ``CFGBlock`` (Clang; ``CFGBlock`` represents a single basic block in a source-level CFG). Bounds check optimizations; ==========================. In ``-fbounds-safety``, the Clang frontend emits run-time checks for every; memory dereference if the type system or analyses in the frontend couldn’t; verify its bounds safety. The implementation relies on LLVM optimizations to; remove redundant run-time checks. Using this optimization strategy, if the; original source code already has bounds checks, the fewer additional checks; ``-fbounds-safety`` will introduce. The LLVM ``ConstraintElimination`` pass is; design to remove provable redundant checks (please check Florian Hahn’s; presentation in 2021 LLVM Dev Meeting and the implementation to learn more). In; the following example, ``-fbounds-safety`` implicitly adds the redundant bounds; checks that the optimizer can remove:. .. code-block:: c. void fill_array_with_indices(int *__counted_by(count) p, size_t count) {; for (size_t i = 0; i < count; ++i) {; // implicit bounds checks:; // if (p + i < p || p + i + 1 > p + count) trap();; p[i] = i;; }; }. ``ConstraintElimination`` collects the following facts and determines if the; bounds checks can be safely removed:. * Inside the for-loop, ``0 <= i < count``, hence ``1 <= i + 1 <= count``.; * Pointer arithmetic ``p + count`` in the if-condition doesn’t w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst:6225,optimiz,optimizations,6225,interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,1,['optimiz'],['optimizations']
Performance,"untimes; (e.g. Objective C and Swift) and other JIT specific runtime code. This should; be built in a similar manner to compiler-rt (possibly even as part of it). 2. **Remote jit_dlopen / jit_dlclose**. To more fully mimic the environment that static programs operate in we would; like JIT'd code to be able to ""dlopen"" and ""dlclose"" JITDylibs, running all of; their initializers/deinitializers on the current thread. This would require; support from the runtime library described above. 3. **Debugging support**. ORC currently supports the GDBRegistrationListener API when using RuntimeDyld; as the underlying JIT linker. We will need a new solution for JITLink based; platforms. Further Future Work; -------------------. 1. **Speculative Compilation**. ORC's support for concurrent compilation allows us to easily enable; *speculative* JIT compilation: compilation of code that is not needed yet,; but which we have reason to believe will be needed in the future. This can be; used to hide compile latency and improve JIT throughput. A proof-of-concept; example of speculative compilation with ORC has already been developed (see; ``llvm/examples/SpeculativeJIT``). Future work on this is likely to focus on; re-using and improving existing profiling support (currently used by PGO) to; feed speculation decisions, as well as built-in tools to simplify use of; speculative compilation. .. [1] Formats/architectures vary in terms of supported features. MachO and; ELF tend to have better support than COFF. Patches very welcome!. .. [2] The ``LazyEmittingLayer``, ``RemoteObjectClientLayer`` and; ``RemoteObjectServerLayer`` do not have counterparts in the new; system. In the case of ``LazyEmittingLayer`` it was simply no longer; needed: in ORCv2, deferring compilation until symbols are looked up is; the default. The removal of ``RemoteObjectClientLayer`` and; ``RemoteObjectServerLayer`` means that JIT stacks can no longer be split; across processes, however this functionality appears not to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:37270,latency,latency,37270,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,2,"['latency', 'throughput']","['latency', 'throughput']"
Performance,"unwind readnone {; entry:; %sext = shl i32 %a, 24 ; <i32> [#uses=1]; %conv1 = ashr i32 %sext, 24 ; <i32> [#uses=1]; %sext6 = shl i32 %b, 24 ; <i32> [#uses=1]; %conv4 = ashr i32 %sext6, 24 ; <i32> [#uses=1]; %cmp = icmp eq i32 %conv1, %conv4 ; <i1> [#uses=1]; %conv5 = zext i1 %cmp to i32 ; <i32> [#uses=1]; ret i32 %conv5; }. And the following x86 code:; 	movsbl	%sil, %eax; 	movsbl	%dil, %ecx; 	cmpl	%eax, %ecx; 	sete	%al; 	movzbl	%al, %eax; 	ret. It should be possible to eliminate the sign extensions. //===---------------------------------------------------------------------===//. LLVM misses a load+store narrowing opportunity in this code:. %struct.bf = type { i64, i16, i16, i32 }. @bfi = external global %struct.bf* ; <%struct.bf**> [#uses=2]. define void @t1() nounwind ssp {; entry:; %0 = load %struct.bf** @bfi, align 8 ; <%struct.bf*> [#uses=1]; %1 = getelementptr %struct.bf* %0, i64 0, i32 1 ; <i16*> [#uses=1]; %2 = bitcast i16* %1 to i32* ; <i32*> [#uses=2]; %3 = load i32* %2, align 1 ; <i32> [#uses=1]; %4 = and i32 %3, -65537 ; <i32> [#uses=1]; store i32 %4, i32* %2, align 1; %5 = load %struct.bf** @bfi, align 8 ; <%struct.bf*> [#uses=1]; %6 = getelementptr %struct.bf* %5, i64 0, i32 1 ; <i16*> [#uses=1]; %7 = bitcast i16* %6 to i32* ; <i32*> [#uses=2]; %8 = load i32* %7, align 1 ; <i32> [#uses=1]; %9 = and i32 %8, -131073 ; <i32> [#uses=1]; store i32 %9, i32* %7, align 1; ret void; }. LLVM currently emits this:. movq bfi(%rip), %rax; andl $-65537, 8(%rax); movq bfi(%rip), %rax; andl $-131073, 8(%rax); ret. It could narrow the loads and stores to emit this:. movq bfi(%rip), %rax; andb $-2, 10(%rax); movq bfi(%rip), %rax; andb $-3, 10(%rax); ret. The trouble is that there is a TokenFactor between the store and the; load, making it non-trivial to determine if there's anything between; the load and the store which would prohibit narrowing. //===---------------------------------------------------------------------===//. This code:; void foo(unsigned x) {; if (x == 0)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:37657,load,load,37657,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['load'],['load']
Performance,"up *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_inv.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. buffer_wbl2 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; follo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:325884,load,load,325884,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"up *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:275174,load,load,275174,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"up - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247142,load,load,247142,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"up to the; alignment value bytes can be safely loaded without trapping in the default; address space. Access of the high bytes can interfere with debugging tools, so; should not be accessed if the function has the ``sanitize_thread`` or; ``sanitize_address`` attributes. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present. An omitted ``align`` argument means that the operation has the; ABI alignment for the target. The optional ``!nontemporal`` metadata must reference a single; metadata name ``<nontemp_node>`` corresponding to a metadata node with one; ``i32`` entry of value 1. The existence of the ``!nontemporal``; metadata on the instruction tells the optimizer and code generator; that this load is not expected to be reused in the cache. The code; generator may select special instructions to save cache bandwidth, such; as the ``MOVNT`` instruction on x86. The optional ``!invariant.load`` metadata must reference a single; metadata name ``<empty_node>`` corresponding to a metadata node with no; entries. If a load instruction tagged with the ``!invariant.load``; metadata is executed, the memory location referenced by the load has; to contain the same value at all points in the program where the; memory location is dereferenceable; otherwise, the behavior is; undefined. The optional ``!invariant.group`` metadata must reference a single metadata name; ``<empty_node>`` corresponding to a metadata node with no entries.; See ``invariant.group`` metadata :ref:`invariant.group <md_invariant.group>`. The optional ``!nonnull`` metadata must reference a single; metadata name ``<empty_node>`` corresponding to a metadata node with no; entries. The existence of the ``!nonnull`` metadata on the; instruction tells the optimizer that the value loaded is known to; never be null. If the value is null at runtime, a poison value is returned; instead. This is analogous to the ``nonnull`` attribute on parameters and; return values. This metadata ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:415322,load,load,415322,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"up/SPIRV-LLVM-Translator/#build-with-spirv-tools>`_. `The versioning; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator/releases>`_ of; ``llvm-spirv`` is aligned with Clang major releases. The same applies to the; main development branch. It is therefore important to ensure the ``llvm-spirv``; version is in alignment with the Clang version. For troubleshooting purposes; ``llvm-spirv`` can be `tested in isolation; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator#test-instructions>`_. Example usage for OpenCL kernel compilation:. .. code-block:: console. $ clang --target=spirv32 -c test.cl; $ clang --target=spirv64 -c test.cl. Both invocations of Clang will result in the generation of a SPIR-V binary file; `test.o` for 32 bit and 64 bit respectively. This file can be imported; by an OpenCL driver that support SPIR-V consumption or it can be compiled; further by offline SPIR-V consumer tools. Converting to SPIR-V produced with the optimization levels other than `-O0` is; currently available as an experimental feature and it is not guaranteed to work; in all cases. Clang also supports integrated generation of SPIR-V without use of ``llvm-spirv``; tool as an experimental feature when ``-fintegrated-objemitter`` flag is passed in; the command line. .. code-block:: console. $ clang --target=spirv32 -fintegrated-objemitter -c test.cl. Note that only very basic functionality is supported at this point and therefore; it is not suitable for arbitrary use cases. This feature is only enabled when clang; build is configured with ``-DLLVM_EXPERIMENTAL_TARGETS_TO_BUILD=SPIRV`` option. Linking is done using ``spirv-link`` from `the SPIRV-Tools project; <https://github.com/KhronosGroup/SPIRV-Tools#linker>`_. Similar to other external; linkers, Clang will expect ``spirv-link`` to be installed separately and to be; present in the ``PATH`` environment variable. Please refer to `the build and; installation instructions; <https://github.com/KhronosGroup/SPIRV-Tools#build>`_. .. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:167065,optimiz,optimization,167065,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance,"updated using the '``llvm.instrprof.mcdc.condbitmap.update``' intrinsic with; the true or false evaluation of each condition, uniquely identifies an executed; MC/DC test vector and is used as a bit index into the global test vector; bitmap. Arguments:; """""""""""""""""""". The first argument is a pointer to a global variable containing the; name of the entity being instrumented. This should generally be the; (mangled) function name for a set of counters. The second argument is a hash value that can be used by the consumer; of the profile data to detect changes to the instrumented source. The third argument is the number of bitmap bytes required by the function to; record the number of test vectors executed for each boolean expression. The fourth argument is the byte index into the global test vector bitmap; corresponding to the function. The fifth argument is the address of the condition bitmap, which contains a; value representing an executed MC/DC test vector. It is loaded and used as the; bit index of the test vector bitmap. Semantics:; """""""""""""""""""". This intrinsic represents the final operation of an MC/DC instrumentation; sequence and will cause the ``-instrprof`` pass to generate the code to; instrument an update of a function's global test vector bitmap to indicate that; a test vector has been executed. The global test vector bitmap can be consumed; by the ``llvm-profdata`` and ``llvm-cov`` tools. '``llvm.thread.pointer``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.thread.pointer(). Overview:; """""""""""""""""". The '``llvm.thread.pointer``' intrinsic returns the value of the thread; pointer. Semantics:; """""""""""""""""""". The '``llvm.thread.pointer``' intrinsic returns a pointer to the TLS area; for the current thread. The exact semantics of this value are target; specific: it may point to the start of TLS area, to the end, or somewhere; in the middle. Depending on the target, this intrinsic may read a register,; call a helper function, rea",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:536249,load,loaded,536249,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loaded']
Performance,"uperimpose several objects; 9. Implement col2 and col3 draw options, using html5 canvas; 10. Support 'p' and 'p0' draw options for TH1 class. ## Development of version 3.0. ### November 2014; 1. Better font size and position in pave stats; 2. Resize/move of element only inside correspondent pad; 3. Adjust of frame size when Y-axis exceed pad limits; 4. Correct values in tooltip for THStack; 5. Exclude drawing of markers from TGraph outside visible range; 6. Drawing of canvas without TFrame object; 7. Many other small bug fixes and improvements, thanks to Maximilian Dietrich. ### October 2014; 1. Add ""shortcut icon""; 2. Add demo of online THttpServer - shell script copies data from; running httpserver.C macro on Apache webserver; 3. Evaluate 'monitoring' parameter for online server like:; <http://localhost:8080/?monitoring=1000>; Parameter defines how often displayed objects should be updated.; 4. Implement 'opt' and 'opts' URL parameters for main page.; 5. Show progress with scripts loading in the browser window; 6. When one appends ""+"" to the filename, its content read completely with first I/O operation.; 7. Implement JS custom streamer for TCanvas, restore aspect ratio when drawing; 8. Major redesign of drawing classes. Resize and update of TCanvas are implemented.; All major draw functions working with HTML element id as first argument.; 9. Extract 3D drawings into separate JSRoot3DPainter.js script; 10. Use newest three.min.js (r68) for 3D drawings, solves problem with Firefox.; 11. Introduce generic list of draw functions for all supported classes.; 12. Add possibility to 'expand' normal objects in the hierarchy browser.; For instance, this gives access to single elements of canvas,; when whole canvas cannot be drawn.; 13. Correct usage of colors map, provided with TCanvas.; 14. Introduce JSROOT.redraw() function which is capable to create or update object drawing.; 15. In main index.htm page browser can be disabled (nobrowser parameter) and; page can be used t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:70836,load,loading,70836,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['load'],['loading']
Performance,"uplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2821,cache,caches,2821,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['cache'],['caches']
Performance,"upport atomic; scopes, then they will behave exactly as the standard GNU atomic builtins. Low-level ARM exclusive memory builtins; ---------------------------------------. Clang provides overloaded builtins giving direct access to the three key ARM; instructions for implementing atomic operations. .. code-block:: c. T __builtin_arm_ldrex(const volatile T *addr);; T __builtin_arm_ldaex(const volatile T *addr);; int __builtin_arm_strex(T val, volatile T *addr);; int __builtin_arm_stlex(T val, volatile T *addr);; void __builtin_arm_clrex(void);. The types ``T`` currently supported are:. * Integer types with width at most 64 bits (or 128 bits on AArch64).; * Floating-point types; * Pointer types. Note that the compiler does not guarantee it will not insert stores which clear; the exclusive monitor in between an ``ldrex`` type operation and its paired; ``strex``. In practice this is only usually a risk when the extra store is on; the same cache line as the variable being modified and Clang will only insert; stack stores on its own, so it is best not to use these operations on variables; with automatic storage duration. Also, loads and stores may be implicit in code written between the ``ldrex`` and; ``strex``. Clang will not necessarily mitigate the effects of these either, so; care should be exercised. For these reasons the higher level atomic primitives should be preferred where; possible. Non-temporal load/store builtins; --------------------------------. Clang provides overloaded builtins allowing generation of non-temporal memory; accesses. .. code-block:: c. T __builtin_nontemporal_load(T *addr);; void __builtin_nontemporal_store(T value, T *addr);. The types ``T`` currently supported are:. * Integer types.; * Floating-point types.; * Vector types. Note that the compiler does not guarantee that non-temporal loads or stores; will be used. C++ Coroutines support builtins; --------------------------------. .. warning::; This is a work in progress. Compatibility across ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:144269,cache,cache,144269,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['cache'],['cache']
Performance,"upported. Assembly Printer; ================. During the code emission stage, the code generator may utilize an LLVM pass to; produce assembly output. To do this, you want to implement the code for a; printer that converts LLVM IR to a GAS-format assembly language for your target; machine, using the following steps:. * Define all the assembly strings for your target, adding them to the; instructions defined in the ``XXXInstrInfo.td`` file. (See; :ref:`instruction-set`.) TableGen will produce an output file; (``XXXGenAsmWriter.inc``) with an implementation of the ``printInstruction``; method for the ``XXXAsmPrinter`` class. * Write ``XXXTargetAsmInfo.h``, which contains the bare-bones declaration of; the ``XXXTargetAsmInfo`` class (a subclass of ``TargetAsmInfo``). * Write ``XXXTargetAsmInfo.cpp``, which contains target-specific values for; ``TargetAsmInfo`` properties and sometimes new implementations for methods. * Write ``XXXAsmPrinter.cpp``, which implements the ``AsmPrinter`` class that; performs the LLVM-to-assembly conversion. The code in ``XXXTargetAsmInfo.h`` is usually a trivial declaration of the; ``XXXTargetAsmInfo`` class for use in ``XXXTargetAsmInfo.cpp``. Similarly,; ``XXXTargetAsmInfo.cpp`` usually has a few declarations of ``XXXTargetAsmInfo``; replacement values that override the default values in ``TargetAsmInfo.cpp``.; For example in ``SparcTargetAsmInfo.cpp``:. .. code-block:: c++. SparcTargetAsmInfo::SparcTargetAsmInfo(const SparcTargetMachine &TM) {; Data16bitsDirective = ""\t.half\t"";; Data32bitsDirective = ""\t.word\t"";; Data64bitsDirective = 0; // .xword is only supported by V9.; ZeroDirective = ""\t.skip\t"";; CommentString = ""!"";; ConstantPoolSection = ""\t.section \"".rodata\"",#alloc\n"";; }. The X86 assembly printer implementation (``X86TargetAsmInfo``) is an example; where the target specific ``TargetAsmInfo`` class uses an overridden methods:; ``ExpandInlineAsm``. A target-specific implementation of ``AsmPrinter`` is written in; ``XXXAsmPrin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:67519,perform,performs,67519,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['perform'],['performs']
Performance,"ur expression's constructor properly computes the flags; for type dependence (i.e., the type your expression produces can change; from one instantiation to the next), value dependence (i.e., the constant; value your expression produces can change from one instantiation to the; next), instantiation dependence (i.e., a template parameter occurs; anywhere in your expression), and whether your expression contains a; parameter pack (for variadic templates). Often, computing these flags; just means combining the results from the various types and; subexpressions.; * Add ``TransformXXX`` and ``RebuildXXX`` functions to the ``TreeTransform``; class template in ``Sema``. ``TransformXXX`` should (recursively); transform all of the subexpressions and types within your expression,; using ``getDerived().TransformYYY``. If all of the subexpressions and; types transform without error, it will then call the ``RebuildXXX``; function, which will in turn call ``getSema().BuildXXX`` to perform; semantic analysis and build your expression.; * To test template instantiation, take those tests you wrote to make sure; that you were type checking with type-dependent expressions and dependent; types (from step #2) and instantiate those templates with various types,; some of which type-check and some that don't, and test the error messages; in each case. #. There are some ""extras"" that make other features work better. It's worth; handling these extras to give your expression complete integration into; Clang:. * Add code completion support for your expression in; ``SemaCodeComplete.cpp``.; * If your expression has types in it, or has any ""interesting"" features; other than subexpressions, extend libclang's ``CursorVisitor`` to provide; proper visitation for your expression, enabling various IDE features such; as syntax highlighting, cross-referencing, and so on. The; ``c-index-test`` helper program can be used to test these features. Testing; -------; All functional changes to Clang should come w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:153422,perform,perform,153422,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['perform'],['perform']
Performance,"urceTracker::remove``.; See the subsection `How to remove code`_. For code examples and suggestions of how to use the ORCv2 APIs, please see; the section `How-tos`_. How-tos; =======. How to manage symbol strings; ----------------------------. Symbol strings in ORC are uniqued to improve lookup performance, reduce memory; overhead, and allow symbol names to function as efficient keys. To get the; unique ``SymbolStringPtr`` for a string value, call the; ``ExecutionSession::intern`` method:. .. code-block:: c++. ExecutionSession ES;; /// ...; auto MainSymbolName = ES.intern(""main"");. If you wish to perform lookup using the C/IR name of a symbol you will also; need to apply the platform linker-mangling before interning the string. On; Linux this mangling is a no-op, but on other platforms it usually involves; adding a prefix to the string (e.g. '_' on Darwin). The mangling scheme is; based on the DataLayout for the target. Given a DataLayout and an; ExecutionSession, you can create a MangleAndInterner function object that; will perform both jobs for you:. .. code-block:: c++. ExecutionSession ES;; const DataLayout &DL = ...;; MangleAndInterner Mangle(ES, DL);. // ... // Portable IR-symbol-name lookup:; auto Sym = ES.lookup({&MainJD}, Mangle(""main""));. How to create JITDylibs and set up linkage relationships; --------------------------------------------------------. In ORC, all symbol definitions reside in JITDylibs. JITDylibs are created by; calling the ``ExecutionSession::createJITDylib`` method with a unique name:. .. code-block:: c++. ExecutionSession ES;; auto &JD = ES.createJITDylib(""libFoo.dylib"");. The JITDylib is owned by the ``ExecutionEngine`` instance and will be freed; when it is destroyed. How to remove code; ------------------. To remove an individual module from a JITDylib it must first be added using an; explicit ``ResourceTracker``. The module can then be removed by calling; ``ResourceTracker::remove``:. .. code-block:: c++. auto &JD = ... ;; auto M = .",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:22831,perform,perform,22831,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['perform'],['perform']
Performance,"ure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:14493,cache,cached,14493,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,1,['cache'],['cached']
Performance,"ure.png; :align: center; :alt: Driver Architecture Diagram. Driver Stages; -------------. The driver functionality is conceptually divided into five stages:. #. **Parse: Option Parsing**. The command line argument strings are decomposed into arguments; (``Arg`` instances). The driver expects to understand all available; options, although there is some facility for just passing certain; classes of options through (like ``-Wl,``). Each argument corresponds to exactly one abstract ``Option``; definition, which describes how the option is parsed along with some; additional metadata. The Arg instances themselves are lightweight and; merely contain enough information for clients to determine which; option they correspond to and their values (if they have additional; parameters). For example, a command line like ""-Ifoo -I foo"" would parse to two; Arg instances (a JoinedArg and a SeparateArg instance), but each; would refer to the same Option. Options are lazily created in order to avoid populating all Option; classes when the driver is loaded. Most of the driver code only needs; to deal with options by their unique ID (e.g., ``options::OPT_I``),. Arg instances themselves do not generally store the values of; parameters. In many cases, this would simply result in creating; unnecessary string copies. Instead, Arg instances are always embedded; inside an ArgList structure, which contains the original vector of; argument strings. Each Arg itself only needs to contain an index into; this vector instead of storing its values directly. The clang driver can dump the results of this stage using the; ``-###`` flag (which must precede any actual command; line arguments). For example:. .. code-block:: console. $ clang -### -Xarch_i386 -fomit-frame-pointer -Wa,-fast -Ifoo -I foo t.c; Option 0 - Name: ""-Xarch_"", Values: {""i386"", ""-fomit-frame-pointer""}; Option 1 - Name: ""-Wa,"", Values: {""-fast""}; Option 2 - Name: ""-I"", Values: {""foo""}; Option 3 - Name: ""-I"", Values: {""foo""}; Option 4 - N",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst:4766,load,loaded,4766,interpreter/llvm-project/clang/docs/DriverInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst,1,['load'],['loaded']
Performance,"ures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions eve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:230554,load,load,230554,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"ures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. fence acq_rel - syste",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:276823,load,load,276823,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"ures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:230251,load,load,230251,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"ures`. The code sequences used to implement the memory model for GFX10-GFX11 are defined in; table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx10-gfx11-table`. .. table:: AMDHSA Memory Model Code Sequences GFX10-GFX11; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx10-gfx11-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX10-GFX11; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; slc=1 dlc=1. - If GFX10, omit dlc=1. - volatile. 1. buffer/global/flat_load; glc=1 dlc=1. 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1 dlc=1. - If GFX10, omit dlc=1. - volatile. 1. buffer/global/flat_store; dlc=1. - If GFX10, omit dlc=1. 2. s_waitcnt vscnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:344061,load,load,344061,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"urity protocols in the list of protocols returned by the serverMake the readahead strategy more conservativeFix a rare race condition happening when destroying instances with outstanding open requestsEnforce cache coherency in the case of reads+writes in the same fileCorrectly guess the filesize of a file opened for writing in sync modeMake server host name check more flexible for GSI authenticationFix some relevant issues with cache handling on the client, including a rare but fatal bug in; determining the cache holes list and the end of a cache lookupMore complete detection of async read errorsGeneralFix problem in handling the return code; of X509_REQ_verify; in XrdCryptosslX509Req.ccAvoid SEGV when doing an lsd admin command with; authenticated xrootd clientsClose race conditions that allowed a supervisor/manager; to subscribe without declaring a data port. Initialize nostage state in; XrdCmsState to prevent erroneous state declaration during; initialization.Fix a problem with the subject name of proxies of level; > 1; this was creating a failure when a Globus application was; trying to use the proxy certificateFix a problem with cache refreshing in XrdSutCache; affecting automatic reloading of password filesFor now, turn off IPV6 processing as it seems to create; several problems.Fix a few issues with the available releases of gcc 4.4Fix a few issues with the 'icc' compilerFix several issues in GSI and PWD authentication modulesNew featuresNew File Residency Manager (frm), replacement for the MPS scriptsScripts are now provided toautomatically donwload a CRL certificate; (utils/getCRLcert)install the recommended verion of OpenSSL and build it; with the options optimal for usage in XROOTD/SCALLA; (utils/installOpenSSL.sh)install the recommended verion of OpenAFS and build it; with the options optimal for usage in; XROOTD/SCALLA (utils/installOpenAFS.sh)MiscellaneaTokenAuthz and CS2 modules are no longer part of the main; built; they have to be built externally. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v524/index.html:3197,cache,cache,3197,net/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v524/index.html,1,['cache'],['cache']
Performance,"urn (a&&b) || (a&&!b);}; Should fold to ""a"". Currently not optimized with ""clang -emit-llvm-bc; | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a, int b, int c) {return (a&&b) || (!a&&c);}; Should fold to ""a ? b : c"", or at least something sane. Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a, int b, int c) {return (a&&b) || (a&&c) || (a&&b&&c);}; Should fold to a && (b || c). Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int x) {return x | ((x & 8) ^ 8);}; Should combine to x | 8. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int x) {return x ^ ((x & 8) ^ 8);}; Should also combine to x | 8. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int x) {return ((x | -9) ^ 8) & x;}; Should combine to x & -9. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned a(unsigned a) {return a * 0x11111111 >> 28 & 1;}; Should combine to ""a * 0x88888888 >> 31"". Currently not optimized; with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned a(char* x) {if ((*x & 32) == 0) return b();}; There's an unnecessary zext in the generated code with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned a(unsigned long long x) {return 40 * (x >> 1);}; Should combine to ""20 * (((unsigned)x) & -2)"". Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===-------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:25594,optimiz,optimized,25594,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['optimiz'],['optimized']
Performance,"urn S->getKind() == SK_Square;; + }; };. class Circle : public Shape {; double Radius;; public:; Circle(double R) : Shape(SK_Circle), Radius(R) {}; double computeArea() override;; +; + static bool classof(const Shape *S) {; + return S->getKind() == SK_Circle;; + }; };. The job of ``classof`` is to dynamically determine whether an object of; a base class is in fact of a particular derived class. In order to; downcast a type ``Base`` to a type ``Derived``, there needs to be a; ``classof`` in ``Derived`` which will accept an object of type ``Base``. To be concrete, consider the following code:. .. code-block:: c++. Shape *S = ...;; if (isa<Circle>(S)) {; /* do something ... */; }. The code of the ``isa<>`` test in this code will eventually boil; down---after template instantiation and some other machinery---to a; check roughly like ``Circle::classof(S)``. For more information, see; :ref:`classof-contract`. The argument to ``classof`` should always be an *ancestor* class because; the implementation has logic to allow and optimize away; upcasts/up-``isa<>``'s automatically. It is as though every class; ``Foo`` automatically has a ``classof`` like:. .. code-block:: c++. class Foo {; [...]; template <class T>; static bool classof(const T *,; ::std::enable_if<; ::std::is_base_of<Foo, T>::value; >::type* = 0) { return true; }; [...]; };. Note that this is the reason that we did not need to introduce a; ``classof`` into ``Shape``: all relevant classes derive from ``Shape``,; and ``Shape`` itself is abstract (has no entry in the ``Kind`` enum),; so this notional inferred ``classof`` is all we need. See `Concrete; Bases and Deeper Hierarchies`_ for more information about how to extend; this example to more general hierarchies. Although for this small example setting up LLVM-style RTTI seems like a lot; of ""boilerplate"", if your classes are doing anything interesting then this; will end up being a tiny fraction of the code. Concrete Bases and Deeper Hierarchies; =================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst:6282,optimiz,optimize,6282,interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,1,['optimiz'],['optimize']
Performance,"urrent module.; #) Embed the pre-link bitcode in a special ``.llvm.lto`` section.; #) Finish optimizing the module using the ModuleOptimization pipeline.; #) Emit the object file, including the new ``.llvm.lto`` section. .. NOTE. Previously, we conservatively ran independent pipelines on separate copies; of the LLVM module to generate the bitcode section and the object code,; which happen to be identical to those used outside of FatLTO. While that; resulted in compiled artifacts that were identical to those produced by the; default and (Thin)LTO pipelines, module cloning led to some cases of; miscompilation, and we have moved away from trying to keep bitcode; generation and optimization completely disjoint. Bit-for-bit compatibility is not (and never was) a guarantee, and we reserve; the right to change this at any time. Explicitly, users should not rely on; the produced bitcode or object code to match their non-LTO counterparts; precisely. They will exhibit similar performance characteristics, but may; not be bit-for-bit the same. Internally, the ``.llvm.lto`` section is created by running the; ``EmbedBitcodePass`` after the ``ThinLTOPreLinkDefaultPipeline``. This pass is; responsible for emitting the ``.llvm.lto`` section. Afterwards, the; ``ThinLTODefaultPipeline`` runs and the compiler can emit the fat object file. Limitations; ===========. Linkers; -------. Currently, using LTO with LLVM fat lto objects is supported by LLD and by the; GNU linkers via :doc:`GoldPlugin`. This may change in the future, but; extending support to other linkers isn't planned for now. .. NOTE; For standard linking the fat object files should be usable by any; linker capable of using ELF objects, since the ``.llvm.lto`` section is; marked ``SHF_EXCLUDE``. Supported File Formats; ----------------------. The current implementation only supports ELF files. At time of writing, it is; unclear if it will be useful to support other object file formats like ``COFF``; or ``Mach-O``. Usage; =====",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst:1917,perform,performance,1917,interpreter/llvm-project/llvm/docs/FatLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst,1,['perform'],['performance']
Performance,"use ICM, STCM, or CLM. --. We don't use ADD (LOGICAL) HIGH, SUBTRACT (LOGICAL) HIGH,; or COMPARE (LOGICAL) HIGH yet. --. DAGCombiner doesn't yet fold truncations of extended loads. Functions like:. unsigned long f (unsigned long x, unsigned short *y); {; return (x << 32) | *y;; }. therefore end up as:. sllg %r2, %r2, 32; llgh %r0, 0(%r3); lr %r2, %r0; br %r14. but truncating the load would give:. sllg %r2, %r2, 32; lh %r2, 0(%r3); br %r14. --. Functions like:. define i64 @f1(i64 %a) {; %and = and i64 %a, 1; ret i64 %and; }. ought to be implemented as:. lhi %r0, 1; ngr %r2, %r0; br %r14. but two-address optimizations reverse the order of the AND and force:. lhi %r0, 1; ngr %r0, %r2; lgr %r2, %r0; br %r14. CodeGen/SystemZ/and-04.ll has several examples of this. --. Out-of-range displacements are usually handled by loading the full; address into a register. In many cases it would be better to create; an anchor point instead. E.g. for:. define void @f4a(i128 *%aptr, i64 %base) {; %addr = add i64 %base, 524288; %bptr = inttoptr i64 %addr to i128 *; %a = load volatile i128 *%aptr; %b = load i128 *%bptr; %add = add i128 %a, %b; store i128 %add, i128 *%aptr; ret void; }. (from CodeGen/SystemZ/int-add-08.ll) we load %base+524288 and %base+524296; into separate registers, rather than using %base+524288 as a base for both. --. Dynamic stack allocations round the size to 8 bytes and then allocate; that rounded amount. It would be simpler to subtract the unrounded; size from the copy of the stack pointer and then align the result.; See CodeGen/SystemZ/alloca-01.ll for an example. --. If needed, we can support 16-byte atomics using LPQ, STPQ and CSDG. --. We might want to model all access registers and use them to spill; 32-bit values. --. We might want to use the 'overflow' condition of eg. AR to support; llvm.sadd.with.overflow.i32 and related instructions - the generated code; for signed overflow check is currently quite bad. This would improve; the results of using -ftrapv.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/README.txt:2920,load,load,2920,interpreter/llvm-project/llvm/lib/Target/SystemZ/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/README.txt,3,['load'],['load']
Performance,"use complexities in SSA; construction, consider this extremely simple C example:. .. code-block:: c. int G, H;; int test(_Bool Condition) {; int X;; if (Condition); X = G;; else; X = H;; return X;; }. In this case, we have the variable ""X"", whose value depends on the path; executed in the program. Because there are two different possible values; for X before the return instruction, a PHI node is inserted to merge the; two values. The LLVM IR that we want for this example looks like this:. .. code-block:: llvm. @G = weak global i32 0 ; type of @G is i32*; @H = weak global i32 0 ; type of @H is i32*. define i32 @test(i1 %Condition) {; entry:; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; br label %cond_next. cond_next:; %X.2 = phi i32 [ %X.1, %cond_false ], [ %X.0, %cond_true ]; ret i32 %X.2; }. In this example, the loads from the G and H global variables are; explicit in the LLVM IR, and they live in the then/else branches of the; if statement (cond\_true/cond\_false). In order to merge the incoming; values, the X.2 phi node in the cond\_next block selects the right value; to use based on where control flow is coming from: if control flow comes; from the cond\_false block, X.2 gets the value of X.1. Alternatively, if; control flow comes from cond\_true, it gets the value of X.0. The intent; of this chapter is not to explain the details of SSA form. For more; information, see one of the many `online; references <http://en.wikipedia.org/wiki/Static_single_assignment_form>`_. The question for this article is ""who places the phi nodes when lowering; assignments to mutable variables?"". The issue here is that LLVM; *requires* that its IR be in SSA form: there is no ""non-ssa"" mode for; it. However, SSA construction requires non-trivial algorithms and data; structures, so it is inconvenient and wasteful for every front-end to; have to reproduce this logic. Memory in LLV",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:2431,load,loads,2431,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['loads']
Performance,"use the `httpRequest` method.; For instance to receive object from a THttpServer server one could do:. ```javascript; import { httpRequest } from 'https://root.cern/js/latest/modules/main.mjs';; let obj = await httpRequest(""http://your_root_server:8080/Canvases/c1/root.json"", ""object""); console.log('Read object of type', obj._typename);; ```. Function returns Promise, which provides parsed object (or Error in case of failure). If JSON string was obtained by different method, it could be parsed with `parse` function:. ```javascript; import { parse } from 'https://root.cern/js/latest/modules/main.mjs';; let obj = parse(json_string);; ```. ### Objects drawing. After an object has been created, one can directly draw it. If HTML page has `<div>` element:. ```html; <div id=""drawing""></div>; ```. One could use the `draw` function:. ```javascript; import { draw } from 'https://root.cern/js/latest/modules/main.mjs';; draw(""drawing"", obj, ""colz"");; ```. The first argument is the id of the HTML div element, where drawing will be performed. The second argument is the object to draw and the third one is the drawing option. Here is complete [running example](https://root.cern/js/latest/api.htm#custom_html_read_json) ans [source code](https://github.com/root-project/jsroot/blob/master/demo/read_json.htm):. ```javascript; import { httpRequest, draw, redraw, resize, cleanup } from 'https://root.cern/js/latest/modules/main.mjs';; let filename = ""https://root.cern/js/files/th2ul.json.gz"";; let obj = await httpRequest(filename, 'object');; draw(""drawing"", obj, ""lego"");; ```. In very seldom cases one need to access painter object, created in `draw()` function. This can be done via; handling Promise results like:. ```javascript; let painter = await draw(""drawing"", obj, ""colz"");; console.log('Object type in painter', painter.getClassName());; ```. One is also able to update the drawing with a new version of the object:. ```javascript; // after some interval request object again; redraw(""dr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:38163,perform,performed,38163,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['perform'],['performed']
Performance,"used to; get the address of the most recent dynamic alloca, allocated by :ref:`alloca <i_alloca>`; on the caller's stack. In particular, for targets where stack grows downwards,; adding this offset to the native stack pointer would get the address of the most; recent dynamic alloca. For targets where stack grows upwards, the situation is a bit more; complicated, because subtracting this value from stack pointer would get the address; one past the end of the most recent dynamic alloca. Although for most targets `llvm.get.dynamic.area.offset <int_get_dynamic_area_offset>`; returns just a zero, for others, such as PowerPC and PowerPC64, it returns a; compile-time-known constant value. The return value type of :ref:`llvm.get.dynamic.area.offset <int_get_dynamic_area_offset>`; must match the target's default address space's (address space 0) pointer type. '``llvm.prefetch``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.prefetch(ptr <address>, i32 <rw>, i32 <locality>, i32 <cache type>). Overview:; """""""""""""""""". The '``llvm.prefetch``' intrinsic is a hint to the code generator to; insert a prefetch instruction if supported; otherwise, it is a noop.; Prefetches have no effect on the behavior of the program but can change; its performance characteristics. Arguments:; """""""""""""""""""". ``address`` is the address to be prefetched, ``rw`` is the specifier; determining if the fetch should be for a read (0) or write (1), and; ``locality`` is a temporal locality specifier ranging from (0) - no; locality, to (3) - extremely local keep in cache. The ``cache type``; specifies whether the prefetch is performed on the data (1) or; instruction (0) cache. The ``rw``, ``locality`` and ``cache type``; arguments must be constant integers. Semantics:; """""""""""""""""""". This intrinsic does not modify the behavior of the program. In; particular, prefetches cannot trap and do not produce a value. On; targets that support this intrinsic, the prefetch can provide hints to;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:523018,cache,cache,523018,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['cache'],['cache']
Performance,"uses a *destructive* or; *non-reversible* modification of the address to prevent an attacker from; reversing the check using attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of per",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:6697,perform,performance,6697,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['perform'],['performance']
Performance,"uses that compiler to build an instrumented stage2 compiler. **stage2-instrumented-generate-profdata**; Depends on stage2-instrumented and will use the instrumented compiler to; generate profdata based on the training files in clang/utils/perf-training. **stage2**; Depends on stage2-instrumented-generate-profdata and will use the stage1; compiler with the stage2 profdata to build a PGO-optimized compiler. **stage2-check-llvm**; Depends on stage2 and runs check-llvm using the stage2 compiler. **stage2-check-clang**; Depends on stage2 and runs check-clang using the stage2 compiler. **stage2-check-all**; Depends on stage2 and runs check-all using the stage2 compiler. **stage2-test-suite**; Depends on stage2 and runs the test-suite using the stage2 compiler (requires; in-tree test-suite). BOLT; ====. `BOLT <https://github.com/llvm/llvm-project/blob/main/bolt/README.md>`_; (Binary Optimization and Layout Tool) is a tool that optimizes binaries; post-link by profiling them at runtime and then using that information to; optimize the layout of the final binary among other optimizations performed; at the binary level. There are also CMake caches available to build; LLVM/Clang with BOLT. To configure a single-stage build that builds LLVM/Clang and then optimizes; it with BOLT, use the following CMake configuration:. .. code-block:: console. $ cmake <path to source>/llvm -C <path to source>/clang/cmake/caches/BOLT.cmake. Then, build the BOLT-optimized binary by running the following ninja command:. .. code-block:: console. $ ninja clang-bolt. If you're seeing errors in the build process, try building with a recent; version of Clang/LLVM by setting the CMAKE_C_COMPILER and; CMAKE_CXX_COMPILER flags to the appropriate values. It is also possible to use BOLT on top of PGO and (Thin)LTO for an even more; significant runtime speedup. To configure a three stage PGO build with ThinLTO; that optimizes the resulting binary with BOLT, use the following CMake; configuration command:. .. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:9949,optimiz,optimizes,9949,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,4,"['optimiz', 'perform']","['optimizations', 'optimize', 'optimizes', 'performed']"
Performance,"using advanced hardware features,; such as multiple execution units and out-of-order execution. The vectorizer uses; a cost model that depends on the register pressure and generated code size to; select the interleaving count. Vectorization is enabled by ``vectorize(enable)`` and interleaving is enabled; by ``interleave(enable)``. This is useful when compiling with ``-Os`` to; manually enable vectorization or interleaving. .. code-block:: c++. #pragma clang loop vectorize(enable); #pragma clang loop interleave(enable); for(...) {; ...; }. The vector width is specified by; ``vectorize_width(_value_[, fixed|scalable])``, where _value_ is a positive; integer and the type of vectorization can be specified with an optional; second parameter. The default for the second parameter is 'fixed' and; refers to fixed width vectorization, whereas 'scalable' indicates the; compiler should use scalable vectors instead. Another use of vectorize_width; is ``vectorize_width(fixed|scalable)`` where the user can hint at the type; of vectorization to use without specifying the exact width. In both variants; of the pragma the vectorizer may decide to fall back on fixed width; vectorization if the target does not support scalable vectors. The interleave count is specified by ``interleave_count(_value_)``, where; _value_ is a positive integer. This is useful for specifying the optimal; width/count of the set of target architectures supported by your application. .. code-block:: c++. #pragma clang loop vectorize_width(2); #pragma clang loop interleave_count(2); for(...) {; ...; }. Specifying a width/count of 1 disables the optimization, and is equivalent to; ``vectorize(disable)`` or ``interleave(disable)``. Vector predication is enabled by ``vectorize_predicate(enable)``, for example:. .. code-block:: c++. #pragma clang loop vectorize(enable); #pragma clang loop vectorize_predicate(enable); for(...) {; ...; }. This predicates (masks) all instructions in the loop, which allows the scalar; re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:164808,scalab,scalable,164808,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['scalab'],['scalable']
Performance,"using an index access operator of an array.) All similar accesses in derived classes should be replaced by the getters `get_curWeight()`; or better `get_wgt(i)`, which were also supported in ROOT \<v6.24. More details on what happened:. - Reduced side effects. This code produces undefined behaviour because the side effect of `get(i)`, i.e., loading the new weight into `_curWeight`; is not guaranteed to happen before `weight()` is called:; ```; processEvent(dataHist.get(i), dataHist.weight()); // Dangerous! Order of evaluation is not guaranteed.; ```; With the modernised interface, one would use:; ```; processEvent(dataHist.get(i), dataHist.weight(i));; ```; To modernise old code, one should replace patterns like `h.get(i); h.func()` by `h.func(i);`. One may `#define R__SUGGEST_NEW_INTERFACE` to switch on; deprecation warnings for the functions in question.; Similarly, the bin content can now be set using an index, making prior loading of a certain coordinate unnecessary:; ```; for (int i=0 ; i<hist->numEntries() ; i++) {; - hist->get(i) ;; - hist->set(hist->weight() / sum);; + hist->set(i, hist->weight(i) / sum, 0.);; }; ```; - More const correctness. `calcTreeIndex()` doesn't rely on side effects, any more. Instead of overwriting the internal; coordinates with new values:; ```; // In a RooDataHist subclass:; _vars = externalCoordinates;; auto index = calcTreeIndex();. // Or from the outside:; auto index = dataHist.getIndex(externalCoordinates); // Side effect: Active bin is now `index`.; ```; coordinates are now passed into calcTreeIndex without side effects:; ```; // In a subclass:; auto index = calcTreeIndex(externalCoordinates, fast=<true/false>); // No side effect. // From the outside:; auto index = dataHist.getIndex(externalCoordinates); // No side effect; ```; This will allow for marking more functions const, or for lying less about const correctness. - RooDataHist now supports fits with RooFit's faster `BatchMode()`.; - Lower memory footprint. If weight erro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:22049,load,loading,22049,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['load'],['loading']
Performance,"usion with non-ARC practice, which did; not ultimately strike us as sufficient to justify requiring extra syntax and; (more importantly) forcing novices to understand ownership rules just to; declare a property when the default is so reasonable. Changing the rule away; from non-ARC practice was acceptable because we had conservatively banned the; synthesis in order to give ourselves exactly this leeway. Applying ``__attribute__((NSObject))`` to a property not of retainable object; pointer type has the same behavior it does outside of ARC: it requires the; property type to be some sort of pointer and permits the use of modifiers other; than ``assign``. These modifiers only affect the synthesized getter and; setter; direct accesses to the ivar (even if synthesized) still have primitive; semantics, and the value in the ivar will not be automatically released during; deallocation. .. _arc.ownership.semantics:. Semantics; ---------. There are five :arc-term:`managed operations` which may be performed on an; object of retainable object pointer type. Each qualifier specifies different; semantics for each of these operations. It is still undefined behavior to; access an object outside of its lifetime. A load or store with ""primitive semantics"" has the same semantics as the; respective operation would have on an ``void*`` lvalue with the same alignment; and non-ownership qualification. :arc-term:`Reading` occurs when performing a lvalue-to-rvalue conversion on an; object lvalue. * For ``__weak`` objects, the current pointee is retained and then released at; the end of the current full-expression. In particular, messaging a ``__weak``; object keeps the object retained until the end of the full expression. .. code-block:: objc. __weak MyObject *weakObj;. void foo() {; // weakObj is retained before the message send and released at the end of; // the full expression.; [weakObj m];; }. This must execute atomically with respect to assignments and to the final; release of the point",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:37456,perform,performed,37456,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['perform'],['performed']
Performance,"usion with the first index usually arises from thinking about the; GetElementPtr instruction as if it was a C index operator. They aren't the; same. For example, when we write, in ""C"":. .. code-block:: c++. AType *Foo;; ...; X = &Foo->F;. it is natural to think that there is only one index, the selection of the field; ``F``. However, in this example, ``Foo`` is a pointer. That pointer; must be indexed explicitly in LLVM. C, on the other hand, indices through it; transparently. To arrive at the same address location as the C code, you would; provide the GEP instruction with two index operands. The first operand indexes; through the pointer; the second operand indexes the field ``F`` of the; structure, just as if you wrote:. .. code-block:: c++. X = &Foo[0].F;. Sometimes this question gets rephrased as:. .. _GEP index through first pointer:. *Why is it okay to index through the first pointer, but subsequent pointers; won't be dereferenced?*. The answer is simply because memory does not have to be accessed to perform the; computation. The second operand to the GEP instruction must be a value of a; pointer type. The value of the pointer is provided directly to the GEP; instruction as an operand without any need for accessing memory. It must,; therefore be indexed and requires an index operand. Consider this example:. .. code-block:: c++. struct munger_struct {; int f1;; int f2;; };; void munge(struct munger_struct *P) {; P[0].f1 = P[1].f1 + P[2].f2;; }; ...; struct munger_struct Array[3];; ...; munge(Array);. In this ""C"" example, the front end compiler (Clang) will generate three GEP; instructions for the three indices through ""P"" in the assignment statement. The; function argument ``P`` will be the second operand of each of these GEP; instructions. The third operand indexes through that pointer. The fourth; operand will be the field offset into the ``struct munger_struct`` type, for; either the ``f1`` or ``f2`` field. So, in LLVM assembly the ``munge`` function; looks ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:2129,perform,perform,2129,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['perform'],['perform']
Performance,"ust be applied and; memory permission and code cache invalidation (if required) must be completed. Object Loading; ==============. Once an object image has been obtained, either through code generation or; having been retrieved from an ObjectCache, it is passed to RuntimeDyld to; be loaded. The RuntimeDyld wrapper class examines the object to determine; its file format and creates an instance of either RuntimeDyldELF or; RuntimeDyldMachO (both of which derive from the RuntimeDyldImpl base; class) and calls the RuntimeDyldImpl::loadObject method to perform that; actual loading. .. image:: MCJIT-dyld-load.png. RuntimeDyldImpl::loadObject begins by creating an ObjectImage instance; from the ObjectBuffer it received. ObjectImage, which wraps the; ObjectFile class, is a helper class which parses the binary object image; and provides access to the information contained in the format-specific; headers, including section, symbol and relocation information. RuntimeDyldImpl::loadObject then iterates through the symbols in the; image. Information about common symbols is collected for later use. For; each function or data symbol, the associated section is loaded into memory; and the symbol is stored in a symbol table map data structure. When the; iteration is complete, a section is emitted for the common symbols. Next, RuntimeDyldImpl::loadObject iterates through the sections in the; object image and for each section iterates through the relocations for; that sections. For each relocation, it calls the format-specific; processRelocationRef method, which will examine the relocation and store; it in one of two data structures, a section-based relocation list map and; an external symbol relocation map. .. image:: MCJIT-load-object.png. When RuntimeDyldImpl::loadObject returns, all of the code and data; sections for the object will have been loaded into memory allocated by the; memory manager and relocation information will have been prepared, but the; relocations have not yet been ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst:4368,load,loadObject,4368,interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,1,['load'],['loadObject']
Performance,"ust be registered; using ``dfsan_set_conditional_callback(my_callback);``, where my_callback is; a function with a signature matching; ``void my_callback(dfsan_label l, dfsan_origin o);``.; This signature is the same when origin tracking is disabled - in this case; the dfsan_origin passed in it will always be 0. The callback will only be called when a tainted value reaches a conditional; expression for control flow (such as an if's condition).; The callback will be skipped for conditional expressions inside signal; handlers, as this is prone to deadlock. Tainted values used in conditional; expressions inside signal handlers will instead be aggregated via bitwise; or, and can be accessed using; ``dfsan_label dfsan_get_labels_in_signal_conditional();``. * ``-dfsan-track-origins`` -- Controls how to track origins. When its value is; 0, the runtime does not track origins. When its value is 1, the runtime tracks; origins at memory store operations. When its value is 2, the runtime tracks; origins at memory load and store operations. Its default value is 0. * ``-dfsan-instrument-with-call-threshold`` -- If a function being instrumented; requires more than this number of origin stores, use callbacks instead of; inline checks (-1 means never use callbacks). Its default value is 3500. Environment Variables; ---------------------. * ``warn_unimplemented`` -- Whether to warn on unimplemented functions. Its; default value is false.; * ``strict_data_dependencies`` -- Whether to propagate labels only when there is; explicit obvious data dependency (e.g., when comparing strings, ignore the fact; that the output of the comparison might be implicit data-dependent on the; content of the strings). This applies only to functions with ``custom`` category; in ABI list. Its default value is true.; * ``origin_history_size`` -- The limit of origin chain length. Non-positive values; mean unlimited. Its default value is 16.; * ``origin_history_per_stack_limit`` -- The limit of origin node's r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst:9266,load,load,9266,interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst,1,['load'],['load']
Performance,"ust happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:259386,load,load,259386,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"ust happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. flat_atomic sc1=1; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:324322,perform,performing,324322,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"ust need to run; the example and you will get the following picture that you can rotate; using the mouse; or you can zoom / move it around (see what the Help; menu of the GL window displays). ~~~{.cpp}; % root rootgeom.C; ~~~. \image html geometry001.png width=600px. Now let us browse the hierarchy that was just created. Start a browser; and double-click on the item simple1 representing the; `gGeoManager` object. Note that right click opens the context menu; of the manager class where several global methods are available. ~~~{.cpp}; root[] new TBrowser;; ~~~. \image html geometry002.jpg width=600px. The folders `Materials`, `Media` and `Local transformations` are in fact; the containers where the geometry manager stores the corresponding; objects. The `Illegal overlaps` folder is empty but can be filled after; performing a geometry validity check (see section: ""Checking the; Geometry""). If tracking is performed using `TGeo`, the folder; `Tracks` might contain user-defined tracks that can be; visualized/animated in the geometry context (see section: ""Creating and; Visualizing Tracks""). Since for the time being we are interested more in; the geometrical hierarchy, we will focus on the last two displayed items; `TOP `and `TOP_1`. These are the top volume and the corresponding top; node in the hierarchy. Double clicking on the `TOP` volume will unfold all different volumes; contained by the top volume. In the right panel, we will see all the; volumes contained by `TOP` (if the same is positioned 4 times we will; get 4 identical items). This rule will apply to any clicked volume in; the hierarchy. Note that right clicking a volume item activates the; volume context menu containing several specific methods. We will call; the volume hierarchy developed in this way as the; `logical geometry graph`. The volume objects are nodes inside this graph; and the same volume can be accessed starting from different branches. On the other hand, the real geometrical objects that are see",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:11986,perform,performed,11986,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performed']
Performance,"ut filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your ""``cl::list``"" variable:. .. code-block:: c++. cl::list<Opts> OptimizationList(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-block:: c++. for (unsigned i = 0; i != OptimizationList.size(); ++i); switch (OptimizationList[i]); ... ... to iterate through the list of options specified. Note that the ""``cl::list``"" template is completely general and may be used with; any data types or other arguments that you can use with the ""``cl::opt``""; template. One es",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:19614,optimiz,optimizations,19614,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,2,"['optimiz', 'perform']","['optimizations', 'perform']"
Performance,"ut pointers aliasing, etc). Many of the enhancements are; user-driven: people want LLVM to include some specific feature, so they; go ahead and extend it. Third, it is *possible and easy* to add language-specific optimizations,; and you have a number of choices in how to do it. As one trivial; example, it is easy to add language-specific optimization passes that; ""know"" things about code compiled for a language. In the case of the C; family, there is an optimization pass that ""knows"" about the standard C; library functions. If you call ""exit(0)"" in main(), it knows that it is; safe to optimize that into ""return 0;"" because C specifies what the; 'exit' function does. In addition to simple library knowledge, it is possible to embed a; variety of other language-specific information into the LLVM IR. If you; have a specific need and run into a wall, please bring the topic up on; the llvm-dev list. At the very worst, you can always treat LLVM as if it; were a ""dumb code generator"" and implement the high-level optimizations; you desire in your front-end, on the language-specific AST. Tips and Tricks; ===============. There is a variety of useful tips and tricks that you come to know after; working on/with LLVM that aren't obvious at first glance. Instead of; letting everyone rediscover them, this section talks about some of these; issues. Implementing portable offsetof/sizeof; -------------------------------------. One interesting thing that comes up, if you are trying to keep the code; generated by your compiler ""target independent"", is that you often need; to know the size of some LLVM type or the offset of some field in an; llvm structure. For example, you might need to pass the size of a type; into a function that allocates memory. Unfortunately, this can vary widely across targets: for example the; width of a pointer is trivially target-specific. However, there is a; `clever way to use the getelementptr; instruction <http://nondot.org/sabre/LLVMNotes/SizeOf-OffsetOf-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst:11157,optimiz,optimizations,11157,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,1,['optimiz'],['optimizations']
Performance,"ute must be specified. It; must be a power of two no less than the ``element_size``. Caller guarantees that; both the source and destination pointers are aligned to that boundary. Semantics:; """""""""""""""""""". The '``llvm.memcpy.element.unordered.atomic.*``' intrinsic copies ``len`` bytes of; memory from the source location to the destination location. These locations are not; allowed to overlap. The memory copy is performed as a sequence of load/store operations; where each access is guaranteed to be a multiple of ``element_size`` bytes wide and; aligned at an ``element_size`` boundary. The order of the copy is unspecified. The same value may be read from the source; buffer many times, but only one write is issued to the destination buffer per; element. It is well defined to have concurrent reads and writes to both source and; destination provided those reads and writes are unordered atomic when specified. This intrinsic does not provide any additional ordering guarantees over those; provided by a set of unordered loads from the source location and stores to the; destination. Lowering:; """""""""""""""""". In the most general case call to the '``llvm.memcpy.element.unordered.atomic.*``' is; lowered to a call to the symbol ``__llvm_memcpy_element_unordered_atomic_*``. Where '*'; is replaced with an actual element size. See :ref:`RewriteStatepointsForGC intrinsic; lowering <RewriteStatepointsForGC_intrinsic_lowering>` for details on GC specific; lowering. Optimizer is allowed to inline memory copy when it's profitable to do so. '``llvm.memmove.element.unordered.atomic``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use; ``llvm.memmove.element.unordered.atomic`` on any integer bit width and for; different address spaces. Not all targets support all bit widths however. ::. declare void @llvm.memmove.element.unordered.atomic.p0.p0.i32(ptr <dest>,; ptr <src>,; i32 <len>,; i32 <element_size>); declare void @l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:959608,load,loads,959608,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loads']
Performance,"utorials/hist/ratioplot?.C`. * New option ""I"" allowing to draw TGraph with invisible axis (used by `TRatioPlot`);. ## New histogram drawing options. ### COL2; COL2 is a new rendering technique providing potential performance improvements; compared to the standard COL option. The performance comparison of the COL2 to; the COL option depends on the histogram and the size of the rendering region in; the current pad. In general, a small (approx. less than 100 bins per axis),; sparsely populated TH2 will render faster with the COL option. However, for larger histograms (approx. more than 100 bins per axis) that are; not sparse, the COL2 option will provide up to 20 times performance improvements.; For example, a 1000x1000 bin TH2 that is not sparse will render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:22605,optimiz,optimized,22605,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['optimiz'],['optimized']
Performance,"uts that are representative of the typical; behavior. Code that is not exercised in the profile will be optimized as if it; is unimportant, and the compiler may make poor optimization choices for code; that is disproportionately used while profiling. Differences Between Sampling and Instrumentation; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Although both techniques are used for similar purposes, there are important; differences between the two:. 1. Profile data generated with one cannot be used by the other, and there is no; conversion tool that can convert one to the other. So, a profile generated; via ``-fprofile-generate`` or ``-fprofile-instr-generate`` must be used with; ``-fprofile-use`` or ``-fprofile-instr-use``. Similarly, sampling profiles; generated by external profilers must be converted and used with ``-fprofile-sample-use``; or ``-fauto-profile``. 2. Instrumentation profile data can be used for code coverage analysis and; optimization. 3. Sampling profiles can only be used for optimization. They cannot be used for; code coverage analysis. Although it would be technically possible to use; sampling profiles for code coverage, sample-based profiles are too; coarse-grained for code coverage purposes; it would yield poor results. 4. Sampling profiles must be generated by an external tool. The profile; generated by that tool must then be converted into a format that can be read; by LLVM. The section on sampling profilers describes one of the supported; sampling profile formats. Using Sampling Profilers; ^^^^^^^^^^^^^^^^^^^^^^^^. Sampling profilers are used to collect runtime information, such as; hardware counters, while your application executes. They are typically; very efficient and do not incur a large runtime overhead. The; sample data collected by the profiler can be used during compilation; to determine what the most executed areas of the code are. Using the data from a sample profiler requires some changes in the way; a program is built. Befor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:91525,optimiz,optimization,91525,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance,"v/null | llc -march=xyz -mattr=help. .. option:: --frame-pointer. Specify effect of frame pointer elimination optimization (all,non-leaf,none). .. option:: --disable-excess-fp-precision. Disable optimizations that may produce excess precision for floating point.; Note that this option can dramatically slow down code on some systems; (e.g. X86). .. option:: --enable-no-infs-fp-math. Enable optimizations that assume no Inf values. .. option:: --enable-no-nans-fp-math. Enable optimizations that assume no NAN values. .. option:: --enable-no-signed-zeros-fp-math. Enable FP math optimizations that assume the sign of 0 is insignificant. .. option:: --enable-no-trapping-fp-math. Enable setting the FP exceptions build attribute not to use exceptions. .. option:: --enable-unsafe-fp-math. Enable optimizations that make unsafe assumptions about IEEE math (e.g. that; addition is associative) or may not work for all input ranges. These; optimizations allow the code generator to make use of some instructions which; would otherwise not be usable (such as ``fsin`` on X86). .. option:: --stats. Print statistics recorded by code-generation passes. .. option:: --time-passes. Record the amount of time needed for each pass and print a report to standard; error. .. option:: --load=<dso_path>. Dynamically load ``dso_path`` (a path to a dynamically shared object) that; implements an LLVM target. This will permit the target name to be used with; the :option:`-march` option so that code can be generated for that target. .. option:: -meabi=[default|gnu|4|5]. Specify which EABI version should conform to. Valid EABI versions are *gnu*,; *4* and *5*. Default value (*default*) depends on the triple. .. option:: -stack-size-section. Emit the .stack_sizes section which contains stack size metadata. The section; contains an array of pairs of function symbol values (pointer size) and stack; sizes (unsigned LEB128). The stack size values only include the space allocated; in the function prologue. Functi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst:3981,optimiz,optimizations,3981,interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,1,['optimiz'],['optimizations']
Performance,"vailable in LLVM. The main goal of this tool is not just to predict the performance of the code; when run on the target, but also help with diagnosing potential performance; issues. Given an assembly code sequence, :program:`llvm-mca` estimates the Instructions; Per Cycle (IPC), as well as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-mca` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-mca` will send its output; to standard output if the input is from standard input. If the :option:`-o`; option specifies ""``-``"", then the output will also be sent to standard output. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Use ``<filename>`` as the output filename. See the summary above for more; details. .. option:: -mtriple=<ta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:1553,throughput,throughput,1553,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['throughput'],['throughput']
Performance,"vailable to JIT'd code), to dynamic code generation based on symbol; names, and even lazy compilation. One immediate benefit of the symbol resolution rule is that we can now extend; the language by writing arbitrary C++ code to implement operations. For example,; if we add:. .. code-block:: c++. #ifdef _WIN32; #define DLLEXPORT __declspec(dllexport); #else; #define DLLEXPORT; #endif. /// putchard - putchar that takes a double and returns 0.; extern ""C"" DLLEXPORT double putchard(double X) {; fputc((char)X, stderr);; return 0;; }. Note, that for Windows we need to actually export the functions because; the dynamic symbol loader will use ``GetProcAddress`` to find the symbols. Now we can produce simple output to the console by using things like:; ""``extern putchard(x); putchard(120);``"", which prints a lowercase 'x'; on the console (120 is the ASCII code for 'x'). Similar code could be; used to implement file I/O, console input, and many other capabilities; in Kaleidoscope. This completes the JIT and optimizer chapter of the Kaleidoscope; tutorial. At this point, we can compile a non-Turing-complete; programming language, optimize and JIT compile it in a user-driven way.; Next up we'll look into `extending the language with control flow; constructs <LangImpl05.html>`_, tackling some interesting LLVM IR issues; along the way. Full Code Listing; =================. Here is the complete code listing for our running example, enhanced with; the LLVM JIT and optimizer. To build this example, use:. .. code-block:: bash. # Compile; clang++ -g toy.cpp `llvm-config --cxxflags --ldflags --system-libs --libs core orcjit native` -O3 -o toy; # Run; ./toy. If you are compiling this on Linux, make sure to add the ""-rdynamic""; option as well. This makes sure that the external functions are resolved; properly at runtime. Here is the code:. .. literalinclude:: ../../../examples/Kaleidoscope/Chapter4/toy.cpp; :language: c++. `Next: Extending the language: control flow <LangImpl05.html>`_. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:24626,optimiz,optimizer,24626,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,3,['optimiz'],"['optimize', 'optimizer']"
Performance,"valid. A value of 0 disables the percentage; size-based pruning. The default is 75%. - ``cache_size_bytes=X``, ``cache_size_bytes=Xk``, ``cache_size_bytes=Xm``,; ``cache_size_bytes=Xg``:; Sets the maximum size for the cache directory to ``X`` bytes (or KB, MB,; GB respectively). A value over the amount of available space on the disk; will be reduced to the amount of available space. A value of 0 disables; the byte size-based pruning. The default is no byte size-based pruning. Note that ThinLTO will apply both size-based pruning policies simultaneously,; and changing one does not affect the other. For example, a policy of; ``cache_size_bytes=1g`` on its own will cause both the 1GB and default 75%; policies to be applied unless the default ``cache_size`` is overridden. - ``cache_size_files=X``:; Set the maximum number of files in the cache directory. Set to 0 to indicate; no limit. The default is 1000000 files. - ``prune_after=Xs``, ``prune_after=Xm``, ``prune_after=Xh``: Sets the; expiration time for cache files to ``X`` seconds (or minutes, hours; respectively). When a file hasn't been accessed for ``prune_after`` seconds,; it is removed from the cache. A value of 0 disables the expiration-based; pruning. The default is 1 week. - ``prune_interval=Xs``, ``prune_interval=Xm``, ``prune_interval=Xh``:; Sets the pruning interval to ``X`` seconds (or minutes, hours; respectively). This is intended to be used to avoid scanning the directory; too often. It does not impact the decision of which files to prune. A; value of 0 forces the scan to occur. The default is every 20 minutes. Clang Bootstrap; ---------------. To `bootstrap clang/LLVM <https://llvm.org/docs/AdvancedBuilds.html#bootstrap-builds>`_; with ThinLTO, follow these steps:. 1. The host compiler_ must be a version of clang that supports ThinLTO.; #. The host linker_ must support ThinLTO (and in the case of gold, must be; `configured with plugins enabled <https://llvm.org/docs/GoldPlugin.html>`_).; #. Use the foll",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst:6979,cache,cache,6979,interpreter/llvm-project/clang/docs/ThinLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst,1,['cache'],['cache']
Performance,"validate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:240158,cache,caches,240158,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance,"validating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247978,cache,cache,247978,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"valuation method.; * ``double`` The compiler uses ``double`` as the floating-point evaluation method for all float expressions of type that is narrower than ``double``.; * ``extended`` The compiler uses ``long double`` as the floating-point evaluation method for all float expressions of type that is narrower than ``long double``. .. option:: -f[no-]protect-parens. This option pertains to floating-point types, complex types with; floating-point components, and vectors of these types. Some arithmetic; expression transformations that are mathematically correct and permissible; according to the C and C++ language standards may be incorrect when dealing; with floating-point types, such as reassociation and distribution. Further,; the optimizer may ignore parentheses when computing arithmetic expressions; in circumstances where the parenthesized and unparenthesized expression; express the same mathematical value. For example (a+b)+c is the same; mathematical value as a+(b+c), but the optimizer is free to evaluate the; additions in any order regardless of the parentheses. When enabled, this; option forces the optimizer to honor the order of operations with respect; to parentheses in all circumstances.; Defaults to ``-fno-protect-parens``. Note that floating-point contraction (option `-ffp-contract=`) is disabled; when `-fprotect-parens` is enabled. Also note that in safe floating-point; modes, such as `-ffp-model=precise` or `-ffp-model=strict`, this option; has no effect because the optimizer is prohibited from making unsafe; transformations. .. option:: -fexcess-precision:. The C and C++ standards allow floating-point expressions to be computed as if; intermediate results had more precision (and/or a wider range) than the type; of the expression strictly allows. This is called excess precision; arithmetic.; Excess precision arithmetic can improve the accuracy of results (although not; always), and it can make computation significantly faster if the target lacks; direct ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:65682,optimiz,optimizer,65682,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizer']
Performance,"value that has been read back. For both of these, using retpolines would be equally sufficient. One possible; hybrid approach is to use retpolines for indirect call and jump, while relying; on SLH to mitigate returns. Another approach that is sufficient for both of these is to harden all of the; speculative stores. However, as most stores aren't interesting and don't; inherently leak data, this is expected to be prohibitively expensive given the; attack it is defending against. ## Implementation Details. There are a number of complex details impacting the implementation of this; technique, both on a particular architecture and within a particular compiler.; We discuss proposed implementation techniques for the x86 architecture and the; LLVM compiler. These are primarily to serve as an example, as other; implementation techniques are very possible. ### x86 Implementation Details. On the x86 platform we break down the implementation into three core; components: accumulating the predicate state through the control flow graph,; checking the loads, and checking control transfers between procedures. #### Accumulating Predicate State. Consider baseline x86 instructions like the following, which test three; conditions and if all pass, loads data from memory and potentially leaks it; through some side channel:; ```; # %bb.0: # %entry; pushq %rax; testl %edi, %edi; jne .LBB0_4; # %bb.1: # %then1; testl %esi, %esi; jne .LBB0_4; # %bb.2: # %then2; testl %edx, %edx; je .LBB0_3; .LBB0_4: # %exit; popq %rax; retq; .LBB0_3: # %danger; movl (%rcx), %edi; callq leak; popq %rax; retq; ```. When we go to speculatively execute the load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the fla",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:15012,load,loads,15012,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loads']
Performance,"value, but; sometimes zero, for static data, or ""uninitialized"", for stack variables). .. code-block:: cpp. int manyInts[10];; manyInts[1] = 42; // Creates a Direct binding for manyInts[1].; print(manyInts[1]); // Retrieves the Direct binding for manyInts[1];; print(manyInts[0]); // There is no Direct binding for manyInts[0].; // Is there a Default binding for the entire array?; // There is not, but it is a stack variable, so we use; // ""uninitialized"" as the default value (and emit a; // diagnostic!). NOTE: The fact that bindings are stored as a base region plus an offset limits; the Default Binding strategy, because in C aggregates can contain other; aggregates. In the current implementation of RegionStore, there is no way to; distinguish a Default binding for an entire aggregate from a Default binding; for the sub-aggregate at offset 0. Lazy Bindings (LazyCompoundVal); -------------------------------. RegionStore implements an optimization for copying aggregates (structs and; arrays) called ""lazy bindings"", implemented using a special SVal called; LazyCompoundVal. When the store is asked for the ""binding"" for an entire; aggregate (i.e. for an lvalue-to-rvalue conversion), it returns a; LazyCompoundVal instead. When this value is then stored into a variable, it is; bound as a Default value. This makes copying arrays and structs much cheaper; than if they had required memberwise access. Under the hood, a LazyCompoundVal is implemented as a uniqued pair of (region,; store), representing ""the value of the region during this 'snapshot' of the; store"". This has important implications for any sort of liveness or; reachability analysis, which must take the bindings in the old store into; account. Retrieving a value from a lazy binding happens in the same way as any other; Default binding: since there is no direct binding, the store manager falls back; to super-regions to look for an appropriate default binding. LazyCompoundVal; differs from a normal default binding, howe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/RegionStore.rst:6629,optimiz,optimization,6629,interpreter/llvm-project/clang/docs/analyzer/developer-docs/RegionStore.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/RegionStore.rst,1,['optimiz'],['optimization']
Performance,"value`` must be; larger than the bit size of the destination type, ``ty2``. Equal sized; types are not allowed. Semantics:; """""""""""""""""""". The '``trunc``' instruction truncates the high order bits in ``value``; and converts the remaining bits to ``ty2``. Since the source size must; be larger than the destination size, ``trunc`` cannot be a *no-op cast*.; It will always truncate bits. Example:; """""""""""""""". .. code-block:: llvm. %X = trunc i32 257 to i8 ; yields i8:1; %Y = trunc i32 123 to i1 ; yields i1:true; %Z = trunc i32 122 to i1 ; yields i1:false; %W = trunc <2 x i16> <i16 8, i16 7> to <2 x i8> ; yields <i8 8, i8 7>. .. _i_zext:. '``zext .. to``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = zext <ty> <value> to <ty2> ; yields ty2. Overview:; """""""""""""""""". The '``zext``' instruction zero extends its operand to type ``ty2``. The ``nneg`` (non-negative) flag, if present, specifies that the operand is; non-negative. This property may be used by optimization passes to later; convert the ``zext`` into a ``sext``. Arguments:; """""""""""""""""""". The '``zext``' instruction takes a value to cast, and a type to cast it; to. Both types must be of :ref:`integer <t_integer>` types, or vectors of; the same number of integers. The bit size of the ``value`` must be; smaller than the bit size of the destination type, ``ty2``. Semantics:; """""""""""""""""""". The ``zext`` fills the high order bits of the ``value`` with zero bits; until it reaches the size of the destination type, ``ty2``. When zero extending from i1, the result will always be either 0 or 1. If the ``nneg`` flag is set, and the ``zext`` argument is negative, the result; is a poison value. Example:; """""""""""""""". .. code-block:: llvm. %X = zext i32 257 to i64 ; yields i64:257; %Y = zext i1 true to i32 ; yields i32:1; %Z = zext <2 x i16> <i16 8, i16 7> to <2 x i32> ; yields <i32 8, i32 7>. %a = zext nneg i8 127 to i16 ; yields i16 127; %b = zext nneg i8 -1 to i16 ; yields i16 poison. .. _i_sext:. '``sext .. to``' I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:443500,optimiz,optimization,443500,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance,"vas.MoveOpaque: false; Rint.Canvas.HighLightColor: 5; ```. The various options are explained in `$ROOTSYS/etc/system.rootrc`. The; `.rootrc` file contents are combined. For example, if the flag to use; true type fonts is set to true in the `system.rootrc` file, you have; to set explicitly it false in your local `.rootrc` file if you do not; want to use true type fonts. Removing the `UseTTFonts `statement in; the local `.rootrc` file will not disable true fonts. The value of the; environment variable `ROOTDEBUG` overrides the value in the `.rootrc`; file at startup. Its value is used to set ***`gDebug`*** and helps for; quick turn on debug mode in **`TROOT`** startup. ROOT looks for scripts in the path specified in the `.rootrc` file in; the `Root.Macro.Path` variable. You can expand this path to hold your; own directories. ### Logon and Logoff Scripts. The `rootlogon.C` and `rootlogoff.C` files are scripts loaded and; executed at start-up and shutdown. The `rootalias.C` file is loaded; but not executed. It typically contains small utility functions. For; example, the `rootalias.C` script that comes with the ROOT; distributions (located in `$ROOTSYS/tutorials)` defines the function; `edit(char *file)`. This allows the user to call the editor from the; command line. This particular function will start the VI editor if the; environment variable `EDITOR` is not set. ``` {.cpp}; root[0] edit(""c1.C""); ```. For more details, see `$ROOTSYS/tutorials/rootalias.C`. ### History File. You can use the up and down arrow at the command line, to access the; previous and next command. The commands are recorded in the history; file `$HOME/.root_hist`. It is a text file, and you can edit, cut, and; paste from it. You can specify the history file in the `system.rootrc`; file, by setting the `Rint.History `option. You can also turn off the; command logging in the `system.rootrc` file with the option:; `Rint.History: -`. The number of history lines to be kept can be set also in `.rootrc`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md:37913,load,loaded,37913,documentation/users-guide/GettingStarted.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md,1,['load'],['loaded']
Performance,"ve 'xpd.putenv' in the; xrootd config file.Input dataIntroduce the; concept of 'input data': these are objects that are distributed in; optimal way to the workers, which are available via the input list, but; which are not saved in the TQueryResult object. These are meant for big; objects whic can create a big overload when distributed via the; standard input list (which should mostly be used for job control; parameters).  To add an input-data object just use; TProof::AddInputData(TObject *); if the input-data objects are in a; file you can use TProof::SetInputDataFile(const char *file); the final; set of input-data objects is assembled from the objects added via; AddInputData and those found in the file defined bySetInputDataFile.  . Improvements:. More; complete set of tests in test/stressProof . To run with PROOF-Lite pass; the argument 'lite' as master URL, e.g. './stressProof lite'.Possibility; to control on the client via rc variable the location of the sandbox,; package directory, cache and dataset directory (the latters two only; for PROOF-Lite); the variable names are 'Proof.Sandbox', ; 'Proof.PackageDir', 'Proof.CacheDir' and 'Proof.DataSetDir'. The default location of the sandbox has been changed from ""~/proof"" to ""~/.proof"" to avoid interferences with possible users' working areas.XrdProofd plug-in. Overall refactorization for easier; maintainance and improved solidity; Improved format of printout messages: all information; messages contain now the tag 'xpd-I' and all error messages the; tag 'xpd-E', so that they can easily be grepped out from the; log file.; . Log sending. Implement selective sending of logs from workers to master to avoid duplicating; too many text lines on the master log. Logs are now sent only after Exec, Print; requests and in case an error (level >= kError) occured. Of course, the full; logs can always be retrieved via TProofMgr::GetSessionLogs; . Log retrieval:. for 'grep' operations, use the system 'grep' command; via 'popen'; ins",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:4151,cache,cache,4151,proof/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html,1,['cache'],['cache']
Performance,"ve been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) has also been removed, while a SetModel(const ModelConfig &); function is introduced. Users are supposed to pass all the model information using the; ModelConfig class rather than via the; RooWorkspace or specifying directly the pdf and parameter; objects in the constructors. ; Setter methods using pdf instances and parameter lists are maintained in the derived classes, like the ProfileLikelihoodCalculator or the HybridCalculator, but those passing a string for the name of the pdf have been removed. ; All the calculator classes do not keep anymore a pointer to the workspace, but they contain pointers to the pdf, the data and the parameters required to run the calculator. These pointers are managed outside by the users or by the RooWorkspace. They can be passed either directly to the classes, for example via the constructor, or by using the ModelConfig class. The ModelConfig class acts as an interface to the Workspace in order to load and store all the; needed information. . ProfileLikelihoodCalculator, LikelihoodInterval. The Minos algorithm of Minuit is used now to find the limit of the likelihood intervals instead of searching directly the roots of the RooProfileLL class. Minos is used via the ROOT::Math::Minimizer interface. By default TMinuit is used, one can also use Minuit2 by doing ROOT::Math::MinimizerOptions::SetDefaultMinimizer(""Minuit2"").; The LikelihoodInterval class now provides now two new methods, FindLimits which finds both the upper and lower interval bounds, and GetContourPoints to find the 2D contour points defining the likelihood interval. GetContourPoints is now used by the LikelihoodIntervalPlot class to draw the 2D contour.; ; New tutorials have been added: rs501_ProfileLikelihoodCalculator_limit.C and rs502_ProfileLikelihoodCalculator_significance.C for getting the interval limits and significance using the ProfileLikelihoodCalculator. The tutorials can be run on a set of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:12683,load,load,12683,roofit/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html,1,['load'],['load']
Performance,"ve relocation, computed as ``pc - entry``. To decode, a user has to; compute ``entry + *entry``. The size of each entry depends on the code model. With large and medium sized; code models, the entry size matches pointer size. For any smaller code model; the entry size is just 32 bits. Encoding Options; ----------------. Optional encoding options can be passed in the first ``MDString`` operator:; ``<section>!<options>``. The following options are available:. * ``C`` -- Compress constant integers of size 2-8 bytes as ULEB128; this; includes the function size (but excludes the PC entry). For example, ``foo!C`` will emit into section ``foo`` with all constants; encoded as ULEB128. Guarantees on Code Generation; =============================. Attaching ``!pcsections`` metadata to LLVM IR instructions *shall not* affect; optimizations or code generation outside the requested PC sections. While relying on LLVM IR metadata to request PC sections makes the above; guarantee relatively trivial, propagation of metadata through the optimization; and code generation pipeline has the following guarantees. Metadata Propagation; --------------------. In general, LLVM *does not make any guarantees* about preserving IR metadata; (attached to an ``Instruction``) through IR transformations. When using PC; sections metadata, this guarantee is unchanged, and ``!pcsections`` metadata is; remains *optional* until lowering to machine IR (MIR). Note for Code Generation; ------------------------. As with other LLVM IR metadata, there are no requirements for LLVM IR; transformation passes to preserve ``!pcsections`` metadata, with the following; exceptions:. * The ``AtomicExpandPass`` shall preserve ``!pcsections`` metadata; according to the below rules 1-4. When translating LLVM IR to MIR, the ``!pcsections`` metadata shall be copied; from the source ``Instruction`` to the target ``MachineInstr`` (set with; ``MachineInstr::setPCSections()``). The instruction selectors and MIR; optimization pass",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PCSectionsMetadata.rst:2924,optimiz,optimization,2924,interpreter/llvm-project/llvm/docs/PCSectionsMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PCSectionsMetadata.rst,1,['optimiz'],['optimization']
Performance,"ve zero; behavior. The ARM target has the same kind of min/max instructions and has; implemented optimizations for them; we should do similar optimizations for; WebAssembly. //===---------------------------------------------------------------------===//. AArch64 runs SeparateConstOffsetFromGEPPass, followed by EarlyCSE and LICM.; Would these be useful to run for WebAssembly too? Also, it has an option to; run SimplifyCFG after running the AtomicExpand pass. Would this be useful for; us too?. //===---------------------------------------------------------------------===//. Register stackification uses the VALUE_STACK physical register to impose; ordering dependencies on instructions with stack operands. This is pessimistic;; we should consider alternate ways to model stack dependencies. //===---------------------------------------------------------------------===//. Lots of things could be done in WebAssemblyTargetTransformInfo.cpp. Similarly,; there are numerous optimization-related hooks that can be overridden in; WebAssemblyTargetLowering. //===---------------------------------------------------------------------===//. Instead of the OptimizeReturned pass, which should consider preserving the; ""returned"" attribute through to MachineInstrs and extending the; MemIntrinsicResults pass to do this optimization on calls too. That would also; let the WebAssemblyPeephole pass clean up dead defs for such calls, as it does; for stores. //===---------------------------------------------------------------------===//. Consider implementing optimizeSelect, optimizeCompareInstr, optimizeCondBranch,; optimizeLoadInstr, and/or getMachineCombinerPatterns. //===---------------------------------------------------------------------===//. Find a clean way to fix the problem which leads to the Shrink Wrapping pass; being run after the WebAssembly PEI pass. //===---------------------------------------------------------------------===//. When setting multiple local variables to the same co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt:2907,optimiz,optimization-related,2907,interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt,1,['optimiz'],['optimization-related']
Performance,"ve, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to set the flags register (much like ours!) with no actual dependency. In those; cases, it is safe to directly insert these instructions. Alternatively we may; be able to move them earlier to avoid clobbering the used value. However, this may ultimately be impossible. In that case, we need to preserve; the flags around these instructions:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; pushfq; orq %rax, %rcx # Mask the pointer if misspeculating.; orq %rax, %rdx # Mask the index if misspeculating.; popfq; movl (%rcx,%rdx), %edi; ```. Using the `pushf` and `popf` instructions saves the flags register around our; inserted code, but comes at a high co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:31729,load,loaded,31729,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loaded']
Performance,"vector-of-vectors, map-of-vectors). It is not intended for; building composite data structures. .. _dss_FoldingSet:. llvm/ADT/FoldingSet.h; ^^^^^^^^^^^^^^^^^^^^^. FoldingSet is an aggregate class that is really good at uniquing; expensive-to-create or polymorphic objects. It is a combination of a chained; hash table with intrusive links (uniqued objects are required to inherit from; FoldingSetNode) that uses :ref:`SmallVector <dss_smallvector>` as part of its ID; process. Consider a case where you want to implement a ""getOrCreateFoo"" method for a; complex object (for example, a node in the code generator). The client has a; description of **what** it wants to generate (it knows the opcode and all the; operands), but we don't want to 'new' a node, then try inserting it into a set; only to find out it already exists, at which point we would have to delete it; and return the node that already exists. To support this style of client, FoldingSet perform a query with a; FoldingSetNodeID (which wraps SmallVector) that can be used to describe the; element that we want to query for. The query either returns the element; matching the ID or it returns an opaque ID that indicates where insertion should; take place. Construction of the ID usually does not require heap traffic. Because FoldingSet uses intrusive links, it can support polymorphic objects in; the set (for example, you can have SDNode instances mixed with LoadSDNodes).; Because the elements are individually allocated, pointers to the elements are; stable: inserting or removing elements does not invalidate any pointers to other; elements. .. _dss_set:. <set>; ^^^^^. ``std::set`` is a reasonable all-around set class, which is decent at many; things but great at nothing. std::set allocates memory for each element; inserted (thus it is very malloc intensive) and typically stores three pointers; per element in the set (thus adding a large amount of per-element space; overhead). It offers guaranteed log(n) performance, whi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:82530,perform,perform,82530,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['perform'],['perform']
Performance,"vector: avoid code like this:. .. code-block:: c++. for ( ... ) {; std::vector<foo> V;; // make use of V.; }. Instead, write this as:. .. code-block:: c++. std::vector<foo> V;; for ( ... ) {; // make use of V.; V.clear();; }. Doing so will save (at least) one heap allocation and free per iteration of the; loop. .. _dss_deque:. <deque>; ^^^^^^^. ``std::deque`` is, in some senses, a generalized version of ``std::vector``.; Like ``std::vector``, it provides constant time random access and other similar; properties, but it also provides efficient access to the front of the list. It; does not guarantee continuity of elements within memory. In exchange for this extra flexibility, ``std::deque`` has significantly higher; constant factor costs than ``std::vector``. If possible, use ``std::vector`` or; something cheaper. .. _dss_list:. <list>; ^^^^^^. ``std::list`` is an extremely inefficient class that is rarely useful. It; performs a heap allocation for every element inserted into it, thus having an; extremely high constant factor, particularly for small data types.; ``std::list`` also only supports bidirectional iteration, not random access; iteration. In exchange for this high cost, std::list supports efficient access to both ends; of the list (like ``std::deque``, but unlike ``std::vector`` or; ``SmallVector``). In addition, the iterator invalidation characteristics of; std::list are stronger than that of a vector class: inserting or removing an; element into the list does not invalidate iterator or pointers to other elements; in the list. .. _dss_ilist:. llvm/ADT/ilist.h; ^^^^^^^^^^^^^^^^. ``ilist<T>`` implements an 'intrusive' doubly-linked list. It is intrusive,; because it requires the element to store and provide access to the prev/next; pointers for the list. ``ilist`` has the same drawbacks as ``std::list``, and additionally requires an; ``ilist_traits`` implementation for the element type, but it provides some novel; characteristics. In particular, it can effici",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:65931,perform,performs,65931,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['perform'],['performs']
Performance,"vector; registers, to generate better spill code. //===----------------------------------------------------------------------===//. The first should be a single lvx from the constant pool, the second should be ; a xor/stvx:. void foo(void) {; int x[8] __attribute__((aligned(128))) = { 1, 1, 1, 17, 1, 1, 1, 1 };; bar (x);; }. #include <string.h>; void foo(void) {; int x[8] __attribute__((aligned(128)));; memset (x, 0, sizeof (x));; bar (x);; }. //===----------------------------------------------------------------------===//. Altivec: Codegen'ing MUL with vector FMADD should add -0.0, not 0.0:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=8763. When -ffast-math is on, we can use 0.0. //===----------------------------------------------------------------------===//. Consider this:; v4f32 Vector;; v4f32 Vector2 = { Vector.X, Vector.X, Vector.X, Vector.X };. Since we know that ""Vector"" is 16-byte aligned and we know the element offset ; of "".X"", we should change the load into a lve*x instruction, instead of doing; a load/store/lve*x sequence. //===----------------------------------------------------------------------===//. Implement passing vectors by value into calls and receiving them as arguments. //===----------------------------------------------------------------------===//. GCC apparently tries to codegen { C1, C2, Variable, C3 } as a constant pool load; of C1/C2/C3, then a load and vperm of Variable. //===----------------------------------------------------------------------===//. We need a way to teach tblgen that some operands of an intrinsic are required to; be constants. The verifier should enforce this constraint. //===----------------------------------------------------------------------===//. We currently codegen SCALAR_TO_VECTOR as a store of the scalar to a 16-byte; aligned stack slot, followed by a load/vperm. We should probably just store it; to a scalar stack slot, then use lvsl/vperm to load it. If the value is already; in memory this is a big win. //=",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt:1123,load,load,1123,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,2,['load'],['load']
Performance,"vector_length>). Overview:; """""""""""""""""". The '``llvm.vp.sext``' intrinsic sign extends its first operand to the return; type. The operation has a mask and an explicit vector length parameter. Arguments:; """""""""""""""""""". The '``llvm.vp.sext``' intrinsic takes a value to cast as its first operand.; The return type is the type to cast the value to. Both types must be vectors of; :ref:`integer <t_integer>` type. The bit size of the value must be smaller than; the bit size of the return type. The second operand is the vector mask. The; return type, the value to cast, and the vector mask have the same number of; elements. The third operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.sext``' intrinsic performs a sign extension by copying the sign; bit (highest order bit) of the value until it reaches the size of the return; type. When sign extending from i1, the result will always be either -1 or 0.; The conversion is performed on lane positions below the explicit vector length; and where the vector mask is true. Masked-off lanes are ``poison``. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.sext.v4i32.v4i16(<4 x i16> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = sext <4 x i16> %a to <4 x i32>; %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_fptrunc:. '``llvm.vp.fptrunc.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.fptrunc.v16f32.v16f64 (<16 x double> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.trunc.nxv4f32.nxv4f64 (<vscale x 4 x double> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". The '``llvm.vp.fptrunc``' intrinsic truncates its first operand to the return; type. The operation has a mask and an explicit vector length parameter. Arguments:; """""""""""""""""""". The '``llvm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:800599,perform,performed,800599,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"vectorize a loop body. Clang offers a family of flags which the optimizers can use to emit; a diagnostic in three cases:. 1. When the pass makes a transformation (`-Rpass`). 2. When the pass fails to make a transformation (`-Rpass-missed`). 3. When the pass determines whether or not to make a transformation; (`-Rpass-analysis`). NOTE: Although the discussion below focuses on `-Rpass`, the exact; same options apply to `-Rpass-missed` and `-Rpass-analysis`. Since there are dozens of passes inside the compiler, each of these flags; take a regular expression that identifies the name of the pass which should; emit the associated diagnostic. For example, to get a report from the inliner,; compile the code with:. .. code-block:: console. $ clang -O2 -Rpass=inline code.cc -o code; code.cc:4:25: remark: foo inlined into bar [-Rpass=inline]; int bar(int j) { return foo(j, j - 2); }; ^. Note that remarks from the inliner are identified with `[-Rpass=inline]`.; To request a report from every optimization pass, you should use; `-Rpass=.*` (in fact, you can use any valid POSIX regular; expression). However, do not expect a report from every transformation; made by the compiler. Optimization remarks do not really make sense; outside of the major transformations (e.g., inlining, vectorization,; loop optimizations) and not every optimization pass supports this; feature. Note that when using profile-guided optimization information, profile hotness; information can be included in the remarks (see; :ref:`-fdiagnostics-show-hotness <opt_fdiagnostics-show-hotness>`). Current limitations; ^^^^^^^^^^^^^^^^^^^. 1. Optimization remarks that refer to function names will display the; mangled name of the function. Since these remarks are emitted by the; back end of the compiler, it does not know anything about the input; language, nor its mangling rules. 2. Some source locations are not displayed correctly. The front end has; a more detailed source location tracking than the locations included; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:24841,optimiz,optimization,24841,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance,"vectors together. The intention is for arrays and vectors to have identical memory layouts - ``[4 x i8]`` and ``<4 x i8>`` should be represented the same in memory. Without this property there would be many special cases that the optimizer would have to cleverly handle. Use of ``LDR`` would break this lane ordering property. This doesn't preclude the use of ``LDR``, but we would have to do one of two things:. 1. Insert a ``REV`` instruction to reverse the lane order after every ``LDR``.; 2. Disable all optimizations that rely on lane layout, and for every access to an individual lane (``insertelement``/``extractelement``/``shufflevector``) reverse the lane index. AAPCS; -----. The ARM procedure call standard (AAPCS) defines the ABI for passing vectors between functions in registers. It states:. When a short vector is transferred between registers and memory it is treated as an opaque object. That is a short vector is stored in memory as if it were stored with a single ``STR`` of the entire register; a short vector is loaded from memory using the corresponding ``LDR`` instruction. On a little-endian system this means that element 0 will always contain the lowest addressed element of a short vector; on a big-endian system element 0 will contain the highest-addressed element of a short vector. -- Procedure Call Standard for the ARM 64-bit Architecture (AArch64), 4.1.2 Short Vectors. The use of ``LDR`` and ``STR`` as the ABI defines has at least one advantage over ``LD1`` and ``ST1``. ``LDR`` and ``STR`` are oblivious to the size of the individual lanes of a vector. ``LD1`` and ``ST1`` are not - the lane size is encoded within them. This is important across an ABI boundary, because it would become necessary to know the lane width the callee expects. Consider the following code:. .. code-block:: c. <callee.c>; void callee(uint32x2_t v) {; ...; }. <caller.c>; extern void callee(uint32x2_t);; void caller() {; callee(...);; }. If ``callee`` changed its signature to ``uint16",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:5885,load,loaded,5885,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,1,['load'],['loaded']
Performance,"ved and set to ""true"", as was default; anyway, as a measure of further consolidation. Removed the option NNodesMax --> This should be replaced by specifying MaxDepth; instead (limiting the maximum tree depth also limits the number of possible nodes!). b) Added a trial version of a new ""cost sensitive"" boosting algorithem according to; Wei Fan and Salvatore J. Stolfo, {\em AdaCost: misclassification cost-sensitive boosting}, Proceedings of the 16th International conference on machine learning (ICML 1999)}. With the currently; chosen DEFAULT settings (all costs equal and set to ""one""), it is equivalent to the ""real-AdaBoost"" (i.e. using the option !UseYesNoLeaf (which uses the leave node purity rather than a signal or background attribute in the leaf node of each individual tree). Unfortunatly, no reasonable performance has been achieved yet when choosing different cost parameters. c) BDT's with little tree depth (as favoured for good performance) do not *like* it if; there are very clean signal and background separation cuts available, which however ; have NOT been applied yet as preselection. Now there is a possibility to choose the option; ""DoPreselection"" that looks for suitable preselection cuts and applies them prior to ; the Decision Tree training. While that works fine, this clearly gives ""sharp"" peaks at +1 (-1); for the MVA output distribution and therefore the ""smoothing"" of this distribution used to; produce the ROC curve and efficiency estimates are somewhat thwarted.; ; --> It's better if you do these preselection cuts YOURSELF when defining training and test; sample!. d) Removed completely the (hopefully never used) option of treating negative events weights; via: PairNegWeightsInNode. e) Renamed option: IgnoreNegEvents --> IgnoreNegEventsInTraining; and removed the IDENTICAL option NoNegeventsInTraining. 6) SVM; All but the Gauss kernel options have been ""removed"" (guess that was done already some; time ago, probably with the introduction of ""regression",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt:2611,perform,performance,2611,documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt,1,['perform'],['performance']
Performance,"ved classes, allowing a more; abstract shape description (""a sphere of inner radius x, outer radius; y""). This enables a viewer, which knows how to draw (tessellate) the; shape itself to do so, while providing a generic fallback suitable for; all viewers. The rules for client negotiation with the viewer are:. - If suitable specialized **`TBuffer3D`** class exists, use it,; otherwise use **`TBuffer3D`**. - Complete the mandatory `kCore` section. - Complete the `kShapeSpecific` section if applicable. - Complete the `kBoundingBox` if you can. - Pass this buffer to the viewer using one of the; `TBuffer3D::AddObject()` methods. If the viewer requires more sections to be completed (`kRaw/kRawSizes`); `TBuffer3D::AddObject()` will return flags indicating which ones,; otherwise it returns `kNone`. If requested, you must fill the buffer,; mark these sections valid, and call `TBuffer3D::AddObject` again, to; complete adding the object. For example, in out **`TGeo`** geometry; package, in `TGeoPainter::PaintShape`, we perform the negotiation with; viewer:. ``` {.cpp}; TVirtualViewer3D * viewer = gPad->GetViewer3D();; if (shape.IsA() != TGeoCompositeShape::Class()) {; // Does viewer prefer local frame positions?; Bool_t localFrame = viewer->PreferLocalFrame();; // Perform first fetch of buffer from the shape and adding; // it to the viewer; const TBuffer3D &buffer = shape.GetBuffer3D(TBuffer3D::kCore |; TBuffer3D::kBoundingBox |; TBuffer3D::kShapeSpecific, localFrame);; Int_t reqSections = viewer->AddObject(buffer, &addDaughters);; // If the viewer requires additional sections fetch from the; // shape (if possible) and add again; if (reqSections != TBuffer3D::kNone) {; shape.GetBuffer3D(reqSections, localFrame);; viewer->AddObject(buffer, &addDaughters);; }; }; ```. The buffer is supplied/filled by the appropriate `TShape::GetBuffer3D()`; and **`TShape::FillBuffer3D` overloads e.g. for a sphere in; `TGeoSphere`**. ``` {.cpp}; const TBuffer3D &TGeoSphere::GetBuffer3D(Int_t reqSe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:128926,perform,perform,128926,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['perform'],['perform']
Performance,"ved"" retaining; operations. Specifically, the object must be laid out such that the; Objective-C message send machinery can successfully send it the following; messages:. * ``retain``, taking no arguments and returning a pointer to the object.; * ``release``, taking no arguments and returning ``void``.; * ``autorelease``, taking no arguments and returning a pointer to the object. The behavior of these methods is constrained in the following ways. The term; :arc-term:`high-level semantics` is an intentionally vague term; the intent is; that programmers must implement these methods in a way such that the compiler,; modifying code in ways it deems safe according to these constraints, will not; violate their requirements. For example, if the user puts logging statements; in ``retain``, they should not be surprised if those statements are executed; more or less often depending on optimization settings. These constraints are; not exhaustive of the optimization opportunities: values held in local; variables are subject to additional restrictions, described later in this; document. It is undefined behavior if a computation history featuring a send of; ``retain`` followed by a send of ``release`` to the same object, with no; intervening ``release`` on that object, is not equivalent under the high-level; semantics to a computation history in which these sends are removed. Note that; this implies that these methods may not raise exceptions. It is undefined behavior if a computation history features any use whatsoever; of an object following the completion of a send of ``release`` that is not; preceded by a send of ``retain`` to the same object. The behavior of ``autorelease`` must be equivalent to sending ``release`` when; one of the autorelease pools currently in scope is popped. It may not throw an; exception. When the semantics call for performing one of these operations on a retainable; object pointer, if that pointer is ``null`` then the effect is a no-op. All of the sema",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:13956,optimiz,optimization,13956,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimization']
Performance,"vefront size used when; generating code for kernels. When disabled; native wavefront size 32 is used, when enabled; wavefront size 64 is used. xnack - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for XNACK replay. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with XNACK replay enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of XNACK replay. XNACK replay can be used for demand paging and; page migration. If enabled in the device, then if; a page fault occurs the code may execute; incorrectly unless generated with XNACK replay; enabled, or generated for code object V4 or above without; specifying XNACK replay. Executing code that was; generated with XNACK replay enabled, or generated; for code object V4 or above without specifying XNACK replay,; on a device that does not have XNACK replay; enabled will execute correctly but may be less; performant than code generated for XNACK replay; disabled.; =============== ============================ ==================================================. .. _amdgpu-target-id:. Target ID; ---------. AMDGPU supports target IDs. See `Clang Offload Bundler; <https://clang.llvm.org/docs/ClangOffloadBundler.html>`_ for a general; description. The AMDGPU target specific information is:. **processor**; Is an AMDGPU processor or alternative processor name specified in; :ref:`amdgpu-processor-table`. The non-canonical form target ID allows both; the primary processor and alternative processor names. The canonical form; target ID only allow the primary processor name. **target-feature**; Is a target feature name specified in :ref:`amdgpu-target-features-table` that; is supported by the processor. The target features supported by each processor; is specified in :ref:`amdgpu-processor-table`. Those that can b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:18945,perform,performant,18945,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performant']
Performance,"ven have to think about it. The second (even bigger) issue is that writing the loop in the first form hints; to the reader that the loop is mutating the container (a fact that a comment; would handily confirm!). If you write the loop in the second form, it is; immediately obvious without even looking at the body of the loop that the; container isn't being modified, which makes it easier to read the code and; understand what it does. While the second form of the loop is a few extra keystrokes, we do strongly; prefer it. ``#include <iostream>`` is Forbidden; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The use of ``#include <iostream>`` in library files is hereby **forbidden**,; because many common implementations transparently inject a `static constructor`_; into every translation unit that includes it. Note that using the other stream headers (``<sstream>`` for example) is not; problematic in this regard --- just ``<iostream>``. However, ``raw_ostream``; provides various APIs that are better performing for almost every use than; ``std::ostream`` style APIs. .. note::. New code should always use `raw_ostream`_ for writing, or the; ``llvm::MemoryBuffer`` API for reading files. .. _raw_ostream:. Use ``raw_ostream``; ^^^^^^^^^^^^^^^^^^^. LLVM includes a lightweight, simple, and efficient stream implementation in; ``llvm/Support/raw_ostream.h``, which provides all of the common features of; ``std::ostream``. All new code should use ``raw_ostream`` instead of; ``ostream``. Unlike ``std::ostream``, ``raw_ostream`` is not a template and can be forward; declared as ``class raw_ostream``. Public headers should generally not include; the ``raw_ostream`` header, but use forward declarations and constant references; to ``raw_ostream`` instances. Avoid ``std::endl``; ^^^^^^^^^^^^^^^^^^^. The ``std::endl`` modifier, when used with ``iostreams`` outputs a newline to; the output stream specified. In addition to doing this, however, it also; flushes the output stream. In other words, these a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:55434,perform,performing,55434,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['perform'],['performing']
Performance,"ver; - ``clang-dxc`` for the ``dxc`` driver. For example, when calling ``x86_64-pc-linux-gnu-clang-g++``,; the driver will first attempt to use the configuration file named::. x86_64-pc-linux-gnu-clang++.cfg. If this file is not found, it will attempt to use the name found; in the executable instead::. x86_64-pc-linux-gnu-clang-g++.cfg. Note that options such as ``--driver-mode=``, ``--target=``, ``-m32`` affect; the search algorithm. For example, the aforementioned executable called with; ``-m32`` argument will instead search for::. i386-pc-linux-gnu-clang++.cfg. If none of the aforementioned files are found, the driver will instead search; for separate driver and target configuration files and attempt to load both.; The former is named ``<driver>.cfg`` while the latter is named; ``<triple>.cfg``. Similarly to the previous variants, the canonical driver name; will be preferred, and the compiler will fall back to the actual name. For example, ``x86_64-pc-linux-gnu-clang-g++`` will attempt to load two; configuration files named respectively::. clang++.cfg; x86_64-pc-linux-gnu.cfg. with fallback to trying::. clang-g++.cfg; x86_64-pc-linux-gnu.cfg. It is not an error if either of these files is not found. The configuration file consists of command-line options specified on one or; more lines. Lines composed of whitespace characters only are ignored as well as; lines in which the first non-blank character is ``#``. Long options may be split; between several lines by a trailing backslash. Here is example of a; configuration file:. ::. # Several options on line; -c --target=x86_64-unknown-linux-gnu. # Long option split between lines; -I/usr/lib/gcc/x86_64-linux-gnu/5.4.0/../../../../\; include/c++/5.4.0. # other config files may be included; @linux.options. Files included by ``@file`` directives in configuration files are resolved; relative to the including file. For example, if a configuration file; ``~/.llvm/target.cfg`` contains the directive ``@os/linux.opts``, the fil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:33840,load,load,33840,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['load'],['load']
Performance,"verflow. Issues caught by this sanitizer are; not undefined behavior, but are often unintentional.; - ``-fsanitize=signed-integer-overflow``: Signed integer overflow, where the; result of a signed integer computation cannot be represented in its type.; This includes all the checks covered by ``-ftrapv``, as well as checks for; signed division overflow (``INT_MIN/-1``), but not checks for; lossy implicit conversions performed before the computation; (see ``-fsanitize=implicit-conversion``). Both of these two issues are; handled by ``-fsanitize=implicit-conversion`` group of checks.; - ``-fsanitize=unreachable``: If control flow reaches an unreachable; program point.; - ``-fsanitize=unsigned-integer-overflow``: Unsigned integer overflow, where; the result of an unsigned integer computation cannot be represented in its; type. Unlike signed integer overflow, this is not undefined behavior, but; it is often unintentional. This sanitizer does not check for lossy implicit; conversions performed before such a computation; (see ``-fsanitize=implicit-conversion``).; - ``-fsanitize=vla-bound``: A variable-length array whose bound; does not evaluate to a positive value.; - ``-fsanitize=vptr``: Use of an object whose vptr indicates that it is of; the wrong dynamic type, or that its lifetime has not begun or has ended.; Incompatible with ``-fno-rtti``. Link must be performed by ``clang++``, not; ``clang``, to make sure C++-specific parts of the runtime library and C++; standard libraries are present. You can also use the following check groups:; - ``-fsanitize=undefined``: All of the checks listed above other than; ``float-divide-by-zero``, ``unsigned-integer-overflow``,; ``implicit-conversion``, ``local-bounds`` and the ``nullability-*`` group; of checks.; - ``-fsanitize=undefined-trap``: Deprecated alias of; ``-fsanitize=undefined``.; - ``-fsanitize=implicit-integer-truncation``: Catches lossy integral; conversions. Enables ``implicit-signed-integer-truncation`` and; ``implicit-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst:9528,perform,performed,9528,interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst,1,['perform'],['performed']
Performance,"verhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what it would cost to get a fully; mitigated baseline. Here we assume targeting a Haswell (or newer) processor and; using all of the tricks to improve performance (so leaves the low 2gb; unprotected and +/- 2gb surrounding any PC in the program). We ran both; Google's microbenchmark suite and a large highly-tuned server built using; ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:46364,perform,performance,46364,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['perform'],['performance']
Performance,"very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec. Lower is better. The last column shows the geomean of all the kernels. .. image:: gcc-loops.png. And Linpack-pc with the same configuration. Result is Mflops, higher is better. .. image:: linpack-pc.png. Ongoing Development Directions; ------------------------------. .. toctree::; :hidden:. VectorizationPlan. :doc:`VectorizationPlan`; Modeling the process and upgrading the infrastructure of LLVM's Loop Vectorizer. .. _slp-vectorizer:. The SLP Vectorizer; ==================. Details; -------. The goal of SLP vectorization (a.k.a. superword-level parallelism) is; to combine similar independent instructions; into vector instructions. Memory accesses, arithmetic operations, comparison; operations, PHI-nodes, can all be vectorized using this technique. For example, the following function performs very similar operations on its; inputs (a1, b1) and (a2, b2). The basic-block vectorizer may combine these; into vector operations. .. code-block:: c++. void foo(int a1, int a2, int b1, int b2, int *A) {; A[0] = a1*(a1 + b1);; A[1] = a2*(a2 + b2);; A[2] = a1*(a1 + b1);; A[3] = a2*(a2 + b2);; }. The SLP-vectorizer processes the code bottom-up, across basic blocks, in search of scalars to combine. Usage; ------. The SLP Vectorizer is enabled by default, but it can be disabled; through clang using the command line flag:. .. code-block:: console. $ clang -fno-slp-vectorize file.c; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:13597,perform,performs,13597,interpreter/llvm-project/llvm/docs/Vectorizers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst,1,['perform'],['performs']
Performance,"ves ``foo2()``. * As soon as ``foo2()`` is removed, the optimizer recognizes that condition ``i; < 0`` is always false, which means ``foo3()`` is never used. Hence, the; optimizer also removes ``foo3()``. * And this in turn, enables linker to remove ``foo4()``. This example illustrates the advantage of tight integration with the; linker. Here, the optimizer can not remove ``foo3()`` without the linker's; input. Alternative Approaches; ----------------------. **Compiler driver invokes link time optimizer separately.**; In this model the link time optimizer is not able to take advantage of; information collected during the linker's normal symbol resolution phase.; In the above example, the optimizer can not remove ``foo2()`` without the; linker's input because it is externally visible. This in turn prohibits the; optimizer from removing ``foo3()``. **Use separate tool to collect symbol information from all object files.**; In this model, a new, separate, tool or library replicates the linker's; capability to collect information for link time optimization. Not only is; this code duplication difficult to justify, but it also has several other; disadvantages. For example, the linking semantics and the features provided; by the linker on various platform are not unique. This means, this new tool; needs to support all such features and platforms in one super tool or a; separate tool per platform is required. This increases maintenance cost for; link time optimizer significantly, which is not necessary. This approach; also requires staying synchronized with linker developments on various; platforms, which is not the main focus of the link time optimizer. Finally,; this approach increases end user's build time due to the duplication of work; done by this separate tool and the linker itself. Multi-phase communication between ``libLTO`` and linker; =======================================================. The linker collects information about symbol definitions and uses in vari",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:3839,optimiz,optimization,3839,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['optimiz'],['optimization']
Performance,"vice disjoint ranges of virtual; addresses.; * Each L1 quadrant of a single SA accesses a different L2 channel. Each L1; quadrant has a separate request queue per L2 channel. Therefore, the vector; and scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different SAs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is; required to ensure synchronization between vector memory operations of; different SAs. It ensures a previous vector memory operation has completed; before executing a subsequent vector memory and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence.; * On GFX10.3 and GFX11 a memory attached last level (MALL) cache exists for GPU memory.; The MALL cache is fully coherent with GPU memory and has no impact on system; coherence. All agents (GPU and CPU) access GPU memory through the MALL cache. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; ret",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:339818,cache,cache,339818,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"vided by the; allocator. The allocator trusts the memory mapping primitives of the OS to; provide pages at (mostly) non-predictable locations in memory, as well as the; binaries to be compiled with ASLR. In the event one of those assumptions is; incorrect, the security will be greatly reduced. Scudo further randomizes how; blocks are allocated in the Primary, can randomize how caches are assigned to; threads. Memory reclaiming; -----------------; Primary and Secondary allocators have different behaviors with regard to; reclaiming. While Secondary mapped allocations can be unmapped on deallocation,; it isn't the case for the Primary, which could lead to a steady growth of the; RSS of a process. To counteract this, if the underlying OS allows it, pages; that are covered by contiguous free memory blocks in the Primary can be; released: this generally means they won't count towards the RSS of a process and; be zero filled on subsequent accesses). This is done in the deallocation path,; and several options exist to tune this behavior. Usage; =====. Platform; --------; If using Fuchsia or an Android version greater than 11, your memory allocations; are already service by Scudo (note that Android Svelte configurations still use; jemalloc). Library; -------; The allocator static library can be built from the LLVM tree thanks to the; ``scudo_standalone`` CMake rule. The associated tests can be exercised thanks to; the ``check-scudo_standalone`` CMake rule. Linking the static library to your project can require the use of the; ``whole-archive`` linker flag (or equivalent), depending on your linker.; Additional flags might also be necessary. Your linked binary should now make use of the Scudo allocation and deallocation; functions. You may also build Scudo like this:. .. code:: console. cd $LLVM/compiler-rt/lib; clang++ -fPIC -std=c++17 -msse4.2 -O2 -pthread -shared \; -I scudo/standalone/include \; scudo/standalone/*.cpp \; -o $HOME/libscudo.so. and then use it with existing b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:5502,tune,tune,5502,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['tune'],['tune']
Performance,"vironment, which is similar to what is described in; the chapter ‘Environment Settings'. Note that the `$ROOTSYS` entries are; probably already there if you followed the standard instructions, and; that the `PYTHONDIR` entries should be replaced as appropriate by your; choice at configuration time, or be left out if you had the; configuration script pick up them up from a default location. ### Using PyROOT. Since it is an extension module, the usage of `PyROOT` probably comes; naturally if you're used to Python. In general, `PyROOT` attempts to; allow working in both Python and ROOT style, and although it is; succeeding, it isn't perfect: there are edges. The following sections; explain in some detail what you can expect, and what you need to watch; out for. #### Access to ROOT Classes. Before a ROOT class can be used from Python, its dictionary needs to be; loaded into the current process. Starting with ROOT version 4.00/06,; this happens automatically for all classes that are declared to the; auto-loading mechanism through so-called `rootmap` files. Effectively,; this means that all classes in the ROOT distributions are directly; available for import. For example:. ``` {.cpp}; from ROOT import TCanvas # available at startup; c = TCanvas(). from ROOT import TLorentzVector # triggers auto-load of libPhysics; l = TLorentzVector(); ```. Although it is not recommended, a simple way of working with `PyROOT` is; doing a global import:. ``` {.cpp}; from ROOT import *. c = TCanvas(); l = TLorentzVector(); ```. Keeping the ROOT namespace (""`import ROOT`""), or only importing from; ROOT those classes that you will actually use (see above), however, will; always be cleaner and clearer:. ``` {.cpp}; import ROOT. c = ROOT.TCanvas(); l = ROOT.TLorentzVector(); ```. Since it is foreseen that most people will use the simple approach; anyway, the request to copy all from module ROOT will not actually; result in copying all ROOT classes into the current namespace. Instead,; classes w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:9608,load,loading,9608,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['load'],['loading']
Performance,"vl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. flat_atomic; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - Howe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:273541,perform,performing,273541,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"vm-tblgen self-reference.td -Dmacro1 -Dmacro3. Appendix A: Bang Operators; ==========================. Bang operators act as functions in value expressions. A bang operator takes; one or more arguments, operates on them, and produces a result. If the; operator produces a boolean result, the result value will be 1 for true or 0; for false. When an operator tests a boolean argument, it interprets 0 as false; and non-0 as true. .. warning::; The ``!getop`` and ``!setop`` bang operators are deprecated in favor of; ``!getdagop`` and ``!setdagop``. ``!add(``\ *a*\ ``,`` *b*\ ``, ...)``; This operator adds *a*, *b*, etc., and produces the sum. ``!and(``\ *a*\ ``,`` *b*\ ``, ...)``; This operator does a bitwise AND on *a*, *b*, etc., and produces the; result. A logical AND can be performed if all the arguments are either; 0 or 1. ``!cast<``\ *type*\ ``>(``\ *a*\ ``)``; This operator performs a cast on *a* and produces the result.; If *a* is not a string, then a straightforward cast is performed, say; between an ``int`` and a ``bit``, or between record types. This allows; casting a record to a class. If a record is cast to ``string``, the; record's name is produced. If *a* is a string, then it is treated as a record name and looked up in; the list of all defined records. The resulting record is expected to be of; the specified *type*. For example, if ``!cast<``\ *type*\ ``>(``\ *name*\ ``)``; appears in a multiclass definition, or in a; class instantiated inside a multiclass definition, and the *name* does not; reference any template arguments of the multiclass, then a record by; that name must have been instantiated earlier; in the source file. If *name* does reference; a template argument, then the lookup is delayed until ``defm`` statements; instantiating the multiclass (or later, if the defm occurs in another; multiclass and template arguments of the inner multiclass that are; referenced by *name* are substituted by values that themselves contain; references to template a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:59699,perform,performed,59699,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['perform'],['performed']
Performance,"vm-tblgen""); if path is None:; raise OSError(""llvm-tblgen not found""); return path; ; _ = find_tblgen(); ```. If the above cell raises an exception, either put `llvm-tblgen` on your `PATH` or point to it using the `LLVM_TBLGEN_EXECUTABLE` environment variable. Alternatively, edit the code to use whatever path you want. Then we need to compile some TableGen by passing it to `llvm-tblgen`'s stdin. We will be using the option `--dump-json` and returning the JSON as a Python dictionary if the compilation succeeds. If it fails, we raise an exception. ```python; import subprocess; import tempfile; import json. def run_tblgen(src):; # Passing to stdin requires a file like object.; with tempfile.TemporaryFile(""w+"") as f:; f.write(src); f.seek(0); got = subprocess.run(; [find_tblgen(), ""--dump-json""],; stdin=f,; stderr=subprocess.PIPE,; stdout=subprocess.PIPE,; universal_newlines=True,; ); ; if got.stderr:; raise RuntimeError(""llvm-tblgen failed with stderr: "" + got.stderr); ; return json.loads(got.stdout); ; print(json.dumps(run_tblgen(""class Foo {}""), indent=4)); ```. {; ""!instanceof"": {; ""Foo"": []; },; ""!tablegen_json_version"": 1; }. ## Structure of a SQL Query. This backend is going to generate SQL queries. The general form of a SQL query is:; ```; SELECT <some field names> FROM <table name>; WHERE <conditions>; ORDER BY <field tags>;; ```. ## SQL Query TableGen. ```python; query_tblgen = """"""\; def all;; def fields;; def none;. def eq;; def ne;; def gt;; def ge;; def and;; def or;; """"""; ```. Normally you'd write this to a `.td` file but here we have it in a Python string to fit into this notebook. We will add to this string to produce the final source. This section defines some constants. First are the fields we want to get back from the query:; * `all` - Return all fields.; * `fields` - Means that we will provide a list of fields we are interested in. The second set are the logical operators for what will become the `WHERE` clause (called `condition` in the TableGen). T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md:2328,load,loads,2328,interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md,1,['load'],['loads']
Performance,"vm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; --",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:13797,perform,performance,13797,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['perform'],['performance']
Performance,"vm. %r = call <4 x i32> @llvm.vp.fshr.v4i32(<4 x i32> %a, <4 x i32> %b, <4 x i32> %c, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x i32> @llvm.fshr.v4i32(<4 x i32> %a, <4 x i32> %b, <4 x i32> %c); %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. '``llvm.vp.is.fpclass.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <vscale x 2 x i1> @llvm.vp.is.fpclass.nxv2f32(<vscale x 2 x float> <op>, i32 <test>, <vscale x 2 x i1> <mask>, i32 <vector_length>); declare <2 x i1> @llvm.vp.is.fpclass.v2f16(<2 x half> <op>, i32 <test>, <2 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated llvm.is.fpclass :ref:`llvm.is.fpclass <llvm.is.fpclass>`. Arguments:; """""""""""""""""""". The first operand is a floating-point vector, the result type is a vector of; boolean with the same number of elements as the first argument. The second; operand specifies, which tests to perform :ref:`llvm.is.fpclass <llvm.is.fpclass>`.; The third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.is.fpclass``' intrinsic performs llvm.is.fpclass (:ref:`llvm.is.fpclass <llvm.is.fpclass>`). Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <2 x i1> @llvm.vp.is.fpclass.v2f16(<2 x half> %x, i32 3, <2 x i1> %m, i32 %evl); %t = call <vscale x 2 x i1> @llvm.vp.is.fpclass.nxv2f16(<vscale x 2 x half> %x, i32 3, <vscale x 2 x i1> %m, i32 %evl). .. _int_mload_mstore:. Masked Vector Load and Store Intrinsics; ---------------------------------------. LLVM provides intrinsics for predicated vector load and store operations. The predicate is specified by a mask operand, which holds one bit per vector element, switching the associated vector lane on or off. The memory addresses corresponding to the ""off"" lanes are not acce",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:841980,perform,perform,841980,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"vm.vector.insert``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. ; Insert fixed type into scalable type; declare <vscale x 4 x float> @llvm.vector.insert.nxv4f32.v4f32(<vscale x 4 x float> %vec, <4 x float> %subvec, i64 <idx>); declare <vscale x 2 x double> @llvm.vector.insert.nxv2f64.v2f64(<vscale x 2 x double> %vec, <2 x double> %subvec, i64 <idx>). ; Insert scalable type into scalable type; declare <vscale x 4 x float> @llvm.vector.insert.nxv4f64.nxv2f64(<vscale x 4 x float> %vec, <vscale x 2 x float> %subvec, i64 <idx>). ; Insert fixed type into fixed type; declare <4 x double> @llvm.vector.insert.v4f64.v2f64(<4 x double> %vec, <2 x double> %subvec, i64 <idx>). Overview:; """""""""""""""""". The '``llvm.vector.insert.*``' intrinsics insert a vector into another vector; starting from a given index. The return type matches the type of the vector we; insert into. Conceptually, this can be used to build a scalable vector out of; non-scalable vectors, however this intrinsic can also be used on purely fixed; types. Scalable vectors can only be inserted into other scalable vectors. Arguments:; """""""""""""""""""". The ``vec`` is the vector which ``subvec`` will be inserted into.; The ``subvec`` is the vector that will be inserted. ``idx`` represents the starting element number at which ``subvec`` will be; inserted. ``idx`` must be a constant multiple of ``subvec``'s known minimum; vector length. If ``subvec`` is a scalable vector, ``idx`` is first scaled by; the runtime scaling factor of ``subvec``. The elements of ``vec`` starting at; ``idx`` are overwritten with ``subvec``. Elements ``idx`` through (``idx`` +; num_elements(``subvec``) - 1) must be valid ``vec`` indices. If this condition; cannot be determined statically but is false at runtime, then the result vector; is a :ref:`poison value <poisonvalues>`. '``llvm.vector.extract``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:663223,scalab,scalable,663223,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['scalab'],['scalable']
Performance,"vm.vp.load.v4f32.p0(ptr %ptr, <4 x i1> %mask, i32 %evl); declare <vscale x 2 x i16> @llvm.vp.load.nxv2i16.p0(ptr %ptr, <vscale x 2 x i1> %mask, i32 %evl); declare <8 x float> @llvm.vp.load.v8f32.p1(ptr addrspace(1) %ptr, <8 x i1> %mask, i32 %evl); declare <vscale x 1 x i64> @llvm.vp.load.nxv1i64.p6(ptr addrspace(6) %ptr, <vscale x 1 x i1> %mask, i32 %evl). Overview:; """""""""""""""""". The '``llvm.vp.load.*``' intrinsic is the vector length predicated version of; the :ref:`llvm.masked.load <int_mload>` intrinsic. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is a; vector of boolean values with the same number of elements as the return type.; The third is the explicit vector length of the operation. The return type and; underlying type of the base pointer are the same vector types. The :ref:`align <attr_align>` parameter attribute can be provided for the first; operand. Semantics:; """""""""""""""""""". The '``llvm.vp.load``' intrinsic reads a vector from memory in the same way as; the '``llvm.masked.load``' intrinsic, where the mask is taken from the; combination of the '``mask``' and '``evl``' operands in the usual VP way.; Certain '``llvm.masked.load``' operands do not have corresponding operands in; '``llvm.vp.load``': the '``passthru``' operand is implicitly ``poison``; the; '``alignment``' operand is taken as the ``align`` parameter attribute, if; provided. The default alignment is taken as the ABI alignment of the return; type as specified by the :ref:`datalayout string<langref_datalayout>`. Examples:; """""""""""""""""". .. code-block:: text. %r = call <8 x i8> @llvm.vp.load.v8i8.p0(ptr align 2 %ptr, <8 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %also.r = call <8 x i8> @llvm.masked.load.v8i8.p0(ptr %ptr, i32 2, <8 x i1> %mask, <8 x i8> poison). .. _int_vp_store:. '``llvm.vp.store``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:784013,load,load,784013,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"vm.vp.umax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.umax.v16i32 (<16 x i32> <left_op>, <16 x i32> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.umax.nxv4i32 (<vscale x 4 x i32> <left_op>, <vscale x 4 x i32> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.umax.v256i64 (<256 x i64> <left_op>, <256 x i64> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer unsigned maximum of two vectors of integers. Arguments:; """""""""""""""""""". The first two operands and the result have the same vector of integer type. The; third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.umax``' intrinsic performs integer unsigned maximum (:ref:`umax <int_umax>`); of the first and second vector operand on each enabled lane. The result on; disabled lanes is a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.umax.v4i32(<4 x i32> %a, <4 x i32> %b, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x i32> @llvm.umax.v4i32(<4 x i32> %a, <4 x i32> %b); %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_umin:. '``llvm.vp.umin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.umin.v16i32 (<16 x i32> <left_op>, <16 x i32> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.umin.nxv4i32 (<vscale x 4 x i32> <left_op>, <vscale x 4 x i32> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.umin.v256i64 (<256 x i64> <left_op>, <256 x i64> <right_op>, <25",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:721526,perform,performs,721526,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"vm.vp.umin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.umin.v16i32 (<16 x i32> <left_op>, <16 x i32> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.umin.nxv4i32 (<vscale x 4 x i32> <left_op>, <vscale x 4 x i32> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.umin.v256i64 (<256 x i64> <left_op>, <256 x i64> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer unsigned minimum of two vectors of integers. Arguments:; """""""""""""""""""". The first two operands and the result have the same vector of integer type. The; third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.umin``' intrinsic performs integer unsigned minimum (:ref:`umin <int_umin>`); of the first and second vector operand on each enabled lane. The result on; disabled lanes is a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.umin.v4i32(<4 x i32> %a, <4 x i32> %b, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x i32> @llvm.umin.v4i32(<4 x i32> %a, <4 x i32> %b); %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_copysign:. '``llvm.vp.copysign.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.copysign.v16f32 (<16 x float> <mag_op>, <16 x float> <sign_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.copysign.nxv4f32 (<vscale x 4 x float> <mag_op>, <vscale x 4 x float> <sign_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.copysign.v256f64 (<256 x double> <mag",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:723028,perform,performs,723028,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"void foo2(void) {; i = -1;; }. static int foo3() {; foo4();; return 10;; }. int foo1(void) {; int data = 0;. if (i < 0); data = foo3();. data = data + 42;; return data;; }. --- main.c ---; #include <stdio.h>; #include ""a.h"". void foo4(void) {; printf(""Hi\n"");; }. int main() {; return foo1();; }. To compile, run:. .. code-block:: console. % clang -flto -c a.c -o a.o # <-- a.o is LLVM bitcode file; % clang -c main.c -o main.o # <-- main.o is native object file; % clang -flto a.o main.o -o main # <-- standard link command with -flto. * In this example, the linker recognizes that ``foo2()`` is an externally; visible symbol defined in LLVM bitcode file. The linker completes its usual; symbol resolution pass and finds that ``foo2()`` is not used; anywhere. This information is used by the LLVM optimizer and it; removes ``foo2()``. * As soon as ``foo2()`` is removed, the optimizer recognizes that condition ``i; < 0`` is always false, which means ``foo3()`` is never used. Hence, the; optimizer also removes ``foo3()``. * And this in turn, enables linker to remove ``foo4()``. This example illustrates the advantage of tight integration with the; linker. Here, the optimizer can not remove ``foo3()`` without the linker's; input. Alternative Approaches; ----------------------. **Compiler driver invokes link time optimizer separately.**; In this model the link time optimizer is not able to take advantage of; information collected during the linker's normal symbol resolution phase.; In the above example, the optimizer can not remove ``foo2()`` without the; linker's input because it is externally visible. This in turn prohibits the; optimizer from removing ``foo3()``. **Use separate tool to collect symbol information from all object files.**; In this model, a new, separate, tool or library replicates the linker's; capability to collect information for link time optimization. Not only is; this code duplication difficult to justify, but it also has several other; disadvantages. For exam",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:2953,optimiz,optimizer,2953,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['optimiz'],['optimizer']
Performance,"volume **B** does. After finding out the node containing; the particle, one can check if the geometry state is different compared; to the last located point:. ``` {.cpp}; Bool_t *TGeoManager::IsSameLocation(); ```. The algorithm for finding where a point is located in geometry is; presented in the figure 17-36. It always starts by checking if the last computed modeller state is the; answer. This optimizes the search when continuously tracking a particle.; The main actions performed are:. - moving up and down in the logical node tree while updating the; current node and its global matrix; - converting the global position into the local frame of the current; node/volume; - checking whether the local position lies within the geometrical; shape of the current volume - if this is the case continue the; search downwards for the daughters of the current node, otherwise; search upwards its containers until the top level is reached.; - the number of candidate nodes to be checked at a given level is; minimized by an additional optimization structure: voxels. This is; effective even in case there is only one daughter of the current; volume.; - in case the current node is declared as possibly overlapping, the; method FindInCluster() is invoked. This method checks all different; possibilities within the cluster of overlapping candidates. One of; the candidates is prioritized if one of the following conditions id; fulfilled (in order):; - Is declared as non-overlapping (these are anyway searched first); - Has at least one daughter that contains the current point; - Was already declared as containing the point at a previous step. ![Finding the location of a point in the geometry hierarchy](pictures/080001E7.png). ### Finding the Distance to Next Crossed Boundary. The most important feature provided by the modeller related to track; propagation is the computation of the distance to the next boundary; along a straight line. The relevant state parameters used for this task are:. - Cur",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:157749,optimiz,optimization,157749,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['optimiz'],['optimization']
Performance,"vp.reverse.nxv4i32(<vscale x 4 x i32> %vec, <vscale x 4 x i1> %mask, i32 %evl). Overview:; """""""""""""""""". The '``llvm.experimental.vp.reverse.*``' intrinsic is the vector length; predicated version of the '``llvm.experimental.vector.reverse.*``' intrinsic. Arguments:; """""""""""""""""""". The result and the first argument ``vec`` are vectors with the same type.; The second argument ``mask`` is a vector mask and has the same number of; elements as the result. The third argument is the explicit vector length of; the operation. Semantics:; """""""""""""""""""". This intrinsic reverses the order of the first ``evl`` elements in a vector.; The lanes in the result vector disabled by ``mask`` are ``poison``. The; elements past ``evl`` are poison. .. _int_vp_load:. '``llvm.vp.load``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <4 x float> @llvm.vp.load.v4f32.p0(ptr %ptr, <4 x i1> %mask, i32 %evl); declare <vscale x 2 x i16> @llvm.vp.load.nxv2i16.p0(ptr %ptr, <vscale x 2 x i1> %mask, i32 %evl); declare <8 x float> @llvm.vp.load.v8f32.p1(ptr addrspace(1) %ptr, <8 x i1> %mask, i32 %evl); declare <vscale x 1 x i64> @llvm.vp.load.nxv1i64.p6(ptr addrspace(6) %ptr, <vscale x 1 x i1> %mask, i32 %evl). Overview:; """""""""""""""""". The '``llvm.vp.load.*``' intrinsic is the vector length predicated version of; the :ref:`llvm.masked.load <int_mload>` intrinsic. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is a; vector of boolean values with the same number of elements as the return type.; The third is the explicit vector length of the operation. The return type and; underlying type of the base pointer are the same vector types. The :ref:`align <attr_align>` parameter attribute can be provided for the first; operand. Semantics:; """""""""""""""""""". The '``llvm.vp.load``' intrinsic reads a vector from memory in the same way as; the '``llvm.masked.load``' intrinsic, where the mask is taken from th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:783144,load,load,783144,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"vp_sub:. '``llvm.vp.sub.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.sub.v16i32 (<16 x i32> <left_op>, <16 x i32> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.sub.nxv4i32 (<vscale x 4 x i32> <left_op>, <vscale x 4 x i32> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.sub.v256i64 (<256 x i64> <left_op>, <256 x i64> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer subtraction of two vectors of integers. Arguments:; """""""""""""""""""". The first two operands and the result have the same vector of integer type. The; third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.sub``' intrinsic performs integer subtraction; (:ref:`sub <i_sub>`) of the first and second vector operand on each enabled; lane. The result on disabled lanes is a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.sub.v4i32(<4 x i32> %a, <4 x i32> %b, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = sub <4 x i32> %a, %b; %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_mul:. '``llvm.vp.mul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.mul.v16i32 (<16 x i32> <left_op>, <16 x i32> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.mul.nxv46i32 (<vscale x 4 x i32> <left_op>, <vscale x 4 x i32> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.mul.v256i64 (<256 x i64> <left_op>, <256 x i64> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:699684,perform,performs,699684,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vm/vscnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 4. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:369242,cache,caches,369242,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance,"w definition. If the; directory does not exist, it creates it as in ""new"". - ""+"": This option can be used in combination with the other three. It; will create the necessary files to easily build a shared library; containing the class definitions.Specifically it will:. - Generate a script called `MAKE` that builds the shared library; containing the definition of all classes in the directory. - Generate a `LinkDef.h `files to use with `rootcling` in `MAKE`. - Run `rootcling` to generate a `<dirname>ProjectDict.cxx` file. - Compile the \<`dirname>ProjectDict.cxx `with the current options in; `compiledata.h`. - Build a shared library` <dirname>.so`. - ""++"":This option can be used instead of the single ""+"". It does; everything the single ""+"" does, and dynamically loads the shared; library `<dirname>.so`. This example makes a directory called `MyProject` that will contain all; class definitions from the `atlfast.root` file. The necessary `makefile`; to build a shared library are also created, and since the '++' is; appended, the shared library is also loaded. ``` {.cpp}; root[] f.MakeProject(""MyProject"",""*"", ""recreate++""); MakeProject has generated 0 classes in MyProject; MyProject/MAKE file has been generated; Shared lib MyProject/MyProject.so has been generated; Shared lib MyProject/MyProject.so has been dynamically linked; ```. The contents of `MyProject`:. ``` {.cpp}; root[] .! ls MyProject; ATLFCluster.h ATLFJet.h ATLFMiscMaker.h ATLFTrack.h; TMCParticle.h ATLFClusterMaker.h ATLFJetMaker.h ATLFMuon.h; ATLFElectron.h ATLFMCMaker.h ATLFMuonMaker.h ATLFElectronMaker.h; ATLFMaker.h ATLFPhoton.h ATLFHistBrowser.h ATLFMisc.h; ATLFPhotonMaker.h ATLFTrackMaker.h ATLFTrigger.h ATLFTriggerMaker.h; LinkDef.h MAKE MyProject.so MyProjectProjectDict.h; MyProjectProjectDict.cxx MyProjectProjectDict.o; ```. Now you can load the shared library in any consecutive root session to; use the `atlfast` classes. ``` {.cpp}; root[]gSystem->Load(""MyProject/MyProject""); root[]ATLFMuon muon; ``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:89549,load,loaded,89549,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['load'],['loaded']
Performance,"w has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/gene",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227952,load,load,227952,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"w that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory oper",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226824,perform,performing,226824,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"w-tests. List all of the discovered tests and exit. EXIT STATUS; -----------. :program:`lit` will exit with an exit code of 1 if there are any FAIL or XPASS; results. Otherwise, it will exit with the status 0. Other exit codes are used; for non-test related failures (for example a user error or an internal program; error). .. _test-discovery:. TEST DISCOVERY; --------------. The inputs passed to :program:`lit` can be either individual tests, or entire; directories or hierarchies of tests to run. When :program:`lit` starts up, the; first thing it does is convert the inputs into a complete list of tests to run; as part of *test discovery*. In the :program:`lit` model, every test must exist inside some *test suite*.; :program:`lit` resolves the inputs specified on the command line to test suites; by searching upwards from the input path until it finds a :file:`lit.cfg` or; :file:`lit.site.cfg` file. These files serve as both a marker of test suites; and as configuration files which :program:`lit` loads in order to understand; how to find and run the tests inside the test suite. Once :program:`lit` has mapped the inputs into test suites it traverses the; list of inputs adding tests for individual files and recursively searching for; tests in directories. This behavior makes it easy to specify a subset of tests to run, while still; allowing the test suite configuration to control exactly how tests are; interpreted. In addition, :program:`lit` always identifies tests by the test; suite they are in, and their relative path inside the test suite. For; appropriately configured projects, this allows :program:`lit` to provide; convenient and flexible support for out-of-tree builds. .. _test-status-results:. TEST STATUS RESULTS; -------------------. Each test ultimately produces one of the following eight results:. **PASS**. The test succeeded. **FLAKYPASS**. The test succeeded after being re-run more than once. This only applies to; tests containing an ``ALLOW_RETRIES:`` annot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:11623,load,loads,11623,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['load'],['loads']
Performance,"waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Mus",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:270062,load,loads,270062,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acq_rel - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before; the following; buffer_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:317242,load,load,317242,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acq_rel - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Mus",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:266719,load,load,266719,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_gl*_inv.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the caches. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:373375,load,load,373375,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"wards compatibility? If not, it; can be eliminated, and the producer can use; ``DW_OP_LLVM_form_aspace_address``. If a stack entry is required to be a value, but it is a location description L; with one memory location description SL in the target architecture default; address space with a bit offset B that is a multiple of 8, then it is implicitly; converted to a value equal to B divided by 8 (the byte size) with the generic; type. 1. ``DW_OP_addr``. ``DW_OP_addr`` has a single byte constant value operand, which has the size; of the generic type, that represents an address A. It pushes a location description L with one memory location description SL; on the stack. SL specifies the memory location storage corresponding to the; target architecture default address space with a bit offset equal to A; scaled by 8 (the byte size). *If the DWARF is part of a code object, then A may need to be relocated. For; example, in the ELF code object format, A must be adjusted by the difference; between the ELF segment virtual address and the virtual address at which the; segment is loaded.*. 2. ``DW_OP_addrx``. ``DW_OP_addrx`` has a single unsigned LEB128 integer operand that represents; a zero-based index into the ``.debug_addr`` section relative to the value of; the ``DW_AT_addr_base`` attribute of the associated compilation unit. The; address value A in the ``.debug_addr`` section has the size of the generic; type. It pushes a location description L with one memory location description SL; on the stack. SL specifies the memory location storage corresponding to the; target architecture default address space with a bit offset equal to A; scaled by 8 (the byte size). *If the DWARF is part of a code object, then A may need to be relocated. For; example, in the ELF code object format, A must be adjusted by the difference; between the ELF segment virtual address and the virtual address at which the; segment is loaded.*. 3. ``DW_OP_LLVM_form_aspace_address`` *New*. ``DW_OP_LLVM_form_as",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:109368,load,loaded,109368,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['load'],['loaded']
Performance,"ware_concurrency`` number of threads in parallel.; For machines with hyper-threading, this is the total number of; virtual cores. For some applications and machine configurations this; may be too aggressive, in which case the amount of parallelism can; be reduced to ``N`` via:. - gold:; ``-Wl,-plugin-opt,jobs=N``; - ld64:; ``-Wl,-mllvm,-threads=N``; - ld.lld, ld64.lld:; ``-Wl,--thinlto-jobs=N``; - lld-link:; ``/opt:lldltojobs=N``. Other possible values for ``N`` are:. - 0:; Use one thread per physical core (default); - 1:; Use a single thread only (disable multi-threading); - all:; Use one thread per logical core (uses all hyper-threads). Incremental; -----------; .. _incremental:. ThinLTO supports fast incremental builds through the use of a cache,; which currently must be enabled through a linker option. - gold (as of LLVM 4.0):; ``-Wl,-plugin-opt,cache-dir=/path/to/cache``; - ld64 (supported since clang 3.9 and Xcode 8) and Mach-O ld64.lld (as of LLVM; 15.0):; ``-Wl,-cache_path_lto,/path/to/cache``; - ELF ld.lld (as of LLVM 5.0):; ``-Wl,--thinlto-cache-dir=/path/to/cache``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocache:/path/to/cache``. Cache Pruning; -------------. To help keep the size of the cache under control, ThinLTO supports cache; pruning. Cache pruning is supported with gold, ld64, and lld, but currently only; gold and lld allow you to control the policy with a policy string. The cache; policy must be specified with a linker option. - gold (as of LLVM 6.0):; ``-Wl,-plugin-opt,cache-policy=POLICY``; - ELF ld.lld (as of LLVM 5.0), Mach-O ld64.lld (as of LLVM 15.0):; ``-Wl,--thinlto-cache-policy=POLICY``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocachepolicy:POLICY``. A policy string is a series of key-value pairs separated by ``:`` characters.; Possible key-value pairs are:. - ``cache_size=X%``: The maximum size for the cache directory is ``X`` percent; of the available space on the disk. Set to 100 to indicate no limit,; 50 to indicate that the cach",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst:4890,cache,cache,4890,interpreter/llvm-project/clang/docs/ThinLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst,1,['cache'],['cache']
Performance,"wavefront to be terminated.; llvm.debugtrap *none* Compiler warning given that there is no; trap handler installed.; =============== =============== ===========================================. Source Languages; ================. .. _amdgpu-opencl:. OpenCL; ------. When the language is OpenCL the following differences occur:. 1. The OpenCL memory model is used (see :ref:`amdgpu-amdhsa-memory-model`).; 2. The AMDGPU backend appends additional arguments to the kernel's explicit; arguments for the AMDHSA OS (see; :ref:`opencl-kernel-implicit-arguments-appended-for-amdhsa-os-table`).; 3. Additional metadata is generated; (see :ref:`amdgpu-amdhsa-code-object-metadata`). .. table:: OpenCL kernel implicit arguments appended for AMDHSA OS; :name: opencl-kernel-implicit-arguments-appended-for-amdhsa-os-table. ======== ==== ========= ===========================================; Position Byte Byte Description; Size Alignment; ======== ==== ========= ===========================================; 1 8 8 OpenCL Global Offset X; 2 8 8 OpenCL Global Offset Y; 3 8 8 OpenCL Global Offset Z; 4 8 8 OpenCL address of printf buffer; 5 8 8 OpenCL address of virtual queue used by; enqueue_kernel.; 6 8 8 OpenCL address of AqlWrap struct used by; enqueue_kernel.; 7 8 8 Pointer argument used for Multi-gird; synchronization.; ======== ==== ========= ===========================================. .. _amdgpu-hcc:. HCC; ---. When the language is HCC the following differences occur:. 1. The HSA memory model is used (see :ref:`amdgpu-amdhsa-memory-model`). .. _amdgpu-assembler:. Assembler; ---------. AMDGPU backend has LLVM-MC based assembler which is currently in development.; It supports AMDGCN GFX6-GFX11. This section describes general syntax for instructions and operands. Instructions; ~~~~~~~~~~~~. An instruction has the following :doc:`syntax<AMDGPUInstructionSyntax>`:. | ``<``\ *opcode*\ ``> <``\ *operand0*\ ``>, <``\ *operand1*\ ``>,...; <``\ *modifier0*\ ``> <``\ *modifier1*\ ``>...``. :doc:`O",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:421895,queue,queue,421895,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance,"wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - system *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; -----------------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:255795,load,load,255795,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"we are referring to; WebAssembly reference types, not C++ reference types unless stated; otherwise. ``__builtin_wasm_table_set``; ----------------------------. This builtin function stores a value in a WebAssembly table.; It takes three arguments.; The first argument is the table to store a value into, the second; argument is the index to which to store the value into, and the; third argument is a value of reference type to store in the table.; It returns nothing. .. code-block:: c++. static __externref_t table[0];; extern __externref_t JSObj;. void store(int index) {; __builtin_wasm_table_set(table, index, JSObj);; }. ``__builtin_wasm_table_get``; ----------------------------. This builtin function is the counterpart to ``__builtin_wasm_table_set``; and loads a value from a WebAssembly table of reference typed values.; It takes 2 arguments.; The first argument is a table of reference typed values and the; second argument is an index from which to load the value. It returns; the loaded reference typed value. .. code-block:: c++. static __externref_t table[0];. __externref_t load(int index) {; __externref_t Obj = __builtin_wasm_table_get(table, index);; return Obj;; }. ``__builtin_wasm_table_size``; -----------------------------. This builtin function returns the size of the WebAssembly table.; Takes the table as an argument and returns an unsigned integer (``size_t``); with the current table size. .. code-block:: c++. typedef void (*__funcref funcref_t)();; static __funcref table[0];. size_t getSize() {; return __builtin_wasm_table_size(table);; }. ``__builtin_wasm_table_grow``; -----------------------------. This builtin function grows the WebAssembly table by a certain amount.; Currently, as all WebAssembly tables created in C/C++ are zero-sized,; this always needs to be called to grow the table. It takes three arguments. The first argument is the WebAssembly table; to grow. The second argument is the reference typed value to store in; the new table entries (the i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:92894,load,loaded,92894,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['load'],['loaded']
Performance,"weak and unsafe references cannot be used; when Objective-C garbage collection is enabled. Except as noted below, the language rules for the ``__weak`` and; ``__unsafe_unretained`` qualifiers (and the ``weak`` and; ``unsafe_unretained`` property attributes) are just as laid out; in the :doc:`ARC specification <AutomaticReferenceCounting>`.; In particular, note that some classes do not support forming weak; references to their instances, and note that special care must be; taken when storing weak references in memory where initialization; and deinitialization are outside the responsibility of the compiler; (such as in ``malloc``-ed memory). Loading from a ``__weak`` variable always implicitly retains the; loaded value. In non-ARC modes, this retain is normally balanced; by an implicit autorelease. This autorelease can be suppressed; by performing the load in the receiver position of a ``-retain``; message send (e.g. ``[weakReference retain]``); note that this performs; only a single retain (the retain done when primitively loading from; the weak reference). For the most part, ``__unsafe_unretained`` in non-ARC modes is just the; default behavior of variables and therefore is not needed. However,; it does have an effect on the semantics of block captures: normally,; copying a block which captures an Objective-C object or block pointer; causes the captured pointer to be retained or copied, respectively,; but that behavior is suppressed when the captured variable is qualified; with ``__unsafe_unretained``. Note that the ``__weak`` qualifier formerly meant the GC qualifier in; all non-ARC modes and was silently ignored outside of GC modes. It now; means the ARC-style qualifier in all non-GC modes and is no longer; allowed if not enabled by either ``-fobjc-arc`` or ``-fobjc-weak``.; It is expected that ``-fobjc-weak`` will eventually be enabled by default; in all non-GC Objective-C modes. .. _objc-fixed-enum:. Enumerations with a fixed underlying type; -------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:72820,perform,performs,72820,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,2,"['load', 'perform']","['loading', 'performs']"
Performance,"ween them an ""edge"" but this causes a much more; complex control flow graph. Instead, we accumulate the set of conditions; necessary for fallthrough and use a sequence of `cmovCC` instructions in a; single fallthrough edge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Cond",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22541,load,loaded,22541,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,2,['load'],"['load', 'loaded']"
Performance,"wering:; """""""""""""""""". Lowers to a call to `objc_copyWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#void-objc-copyweak-id-dest-id-src>`_. '``llvm.objc.destroyWeak``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.destroyWeak(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_destroyWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#void-objc-destroyweak-id-object>`_. '``llvm.objc.initWeak``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.initWeak(ptr, ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_initWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-initweak>`_. '``llvm.objc.loadWeak``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.loadWeak(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_loadWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-loadweak>`_. '``llvm.objc.loadWeakRetained``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.loadWeakRetained(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_loadWeakRetained <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-loadweakretained>`_. '``llvm.objc.moveWeak``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.moveWeak(ptr, ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_moveWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#void-objc-moveweak-id-dest-id-src>`_. '``llvm.objc.release``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.release(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_release <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#void-objc-release-id-value>`_. '``llvm.objc.retain``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:968869,load,loadweak,968869,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loadweak']
Performance,"werings it can do:. * cmpxchg -> loop with load-linked/store-conditional; by overriding ``shouldExpandAtomicCmpXchgInIR()``, ``emitLoadLinked()``,; ``emitStoreConditional()``; * large loads/stores -> ll-sc/cmpxchg; by overriding ``shouldExpandAtomicStoreInIR()``/``shouldExpandAtomicLoadInIR()``; * strong atomic accesses -> monotonic accesses + fences by overriding; ``shouldInsertFencesForAtomic()``, ``emitLeadingFence()``, and; ``emitTrailingFence()``; * atomic rmw -> loop with cmpxchg or load-linked/store-conditional; by overriding ``expandAtomicRMWInIR()``; * expansion to __atomic_* libcalls for unsupported sizes.; * part-word atomicrmw/cmpxchg -> target-specific intrinsic by overriding; ``shouldExpandAtomicRMWInIR``, ``emitMaskedAtomicRMWIntrinsic``,; ``shouldExpandAtomicCmpXchgInIR``, and ``emitMaskedAtomicCmpXchgIntrinsic``. For an example of these look at the ARM (first five lowerings) or RISC-V (last; lowering) backend. AtomicExpandPass supports two strategies for lowering atomicrmw/cmpxchg to; load-linked/store-conditional (LL/SC) loops. The first expands the LL/SC loop; in IR, calling target lowering hooks to emit intrinsics for the LL and SC; operations. However, many architectures have strict requirements for LL/SC; loops to ensure forward progress, such as restrictions on the number and type; of instructions in the loop. It isn't possible to enforce these restrictions; when the loop is expanded in LLVM IR, and so affected targets may prefer to; expand to LL/SC loops at a very late stage (i.e. after register allocation).; AtomicExpandPass can help support lowering of part-word atomicrmw or cmpxchg; using this strategy by producing IR for any shifting and masking that can be; performed outside of the LL/SC loop. Libcalls: __atomic_*; ====================. There are two kinds of atomic library calls that are generated by LLVM. Please; note that both sets of library functions somewhat confusingly share the names of; builtin functions defined by clang. Despite",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:21881,load,load-linked,21881,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['load'],['load-linked']
Performance,"when enabled CU wavefront execution mode is used; (see :ref:`amdgpu-amdhsa-memory-model`). sramecc - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for SRAMECC. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with SRAMECC enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of SRAMECC. tgsplit ``-m[no-]tgsplit`` Enable/disable generating code that assumes; work-groups are launched in threadgroup split mode.; When enabled the waves of a work-group may be; launched in different CUs. wavefrontsize64 - ``-m[no-]wavefrontsize64`` Control the wavefront size used when; generating code for kernels. When disabled; native wavefront size 32 is used, when enabled; wavefront size 64 is used. xnack - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for XNACK replay. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with XNACK replay enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of XNACK replay. XNACK replay can be used for demand paging and; page migration. If enabled in the device, then if; a page fault occurs the code may execute; incorrectly unless generated with XNACK replay; enabled, or generated for code object V4 or above without; specifying XNACK replay. Executing code that was; generated with XNACK replay enabled, or generated; for code object V4 or above without specifying XNACK replay,; on a device that does not have XNACK replay; enabled will execute correctly but may be less; performant than code generated for XNACK replay; disabled.; =============== ============================ =================================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:18086,load,loaded,18086,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loaded']
Performance,"where we are; missing the StreamerInfo and need to guess whether the symbol represent an enum,; a class or a namespace. To use genreflex, call MakeProject with the ""genreflex"" option, for example:. file->MakeProject(libdir,""*"",""NEW+genreflex"");. To make sure the library created by MakeProject does not double delete an object,; tell the StreamerElement representing one of the pointers pointing to the object; to never delete the object. For example:. TClass::AddRule(""HepMC::GenVertex m_event attributes=NotOwner"");. MakeProject now implements a move constructor for each classes. For the implementation, we 'use' the 'copy constructor' until the C++ compilers properly support the official move constructor notation. Implementing a move constructor avoid having to delete and reconstruct resource during a std::vector resize and avoid the double delete induced by using the default copy constructor. MakeProject now adds dictionaries for auto_ptr. MakeProject no longer request the dictionary for std::pair instances that already have been loaded. Misc. TFile::Open now does variable expansion so that you can include the protocol in the variable (for example: export H1=""http://root.cern/files/h1""; ...; TFile::Open(""$H1/dstarmb.root"");; Added warning if the file does contain any StreamerInfo objects and was written with a different version of ROOT.; Implemented polymorphism for Emulated object (still not supporting polymorphism of Emulated Object inheriting from compiled class). See the Core/Meta section for details.; Add support for streaming auto_ptr when generating their dictionary via rootcint; Enable the use of the I/O customization rules on data members that are either a variable size array or a fixed size array. For example:. #pragma read sourceClass = ""ACache"" targetClass = ""ACache"" version = ""[8]"" \; source = ""Int_t *fArray; Int_t fN;"" \; target = ""fArray"" \; code = ""{ fArray = new Char_t[onfile.fN]; Char_t* gtc=fArray; Int_t* gti=onfile.fArray; \; for(Int_t i=0; i<onfile",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:9161,load,loaded,9161,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,1,['load'],['loaded']
Performance,"which can reorder assignments (discussed below).; Function parameter locations are moved to the beginning of the function if; they're not already, to ensure they're immediately available on function entry. To demonstrate variable locations during instruction selection, consider; the following example:. .. code-block:: llvm. define i32 @foo(i32* %addr) {; entry:; call void @llvm.dbg.value(metadata i32 0, metadata !3, metadata !DIExpression()), !dbg !5; br label %bb1, !dbg !5. bb1: ; preds = %bb1, %entry; %bar.0 = phi i32 [ 0, %entry ], [ %add, %bb1 ]; call void @llvm.dbg.value(metadata i32 %bar.0, metadata !3, metadata !DIExpression()), !dbg !5; %addr1 = getelementptr i32, i32 *%addr, i32 1, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr1, metadata !3, metadata !DIExpression()), !dbg !5; %loaded1 = load i32, i32* %addr1, !dbg !5; %addr2 = getelementptr i32, i32 *%addr, i32 %bar.0, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr2, metadata !3, metadata !DIExpression()), !dbg !5; %loaded2 = load i32, i32* %addr2, !dbg !5; %add = add i32 %bar.0, 1, !dbg !5; call void @llvm.dbg.value(metadata i32 %add, metadata !3, metadata !DIExpression()), !dbg !5; %added = add i32 %loaded1, %loaded2; %cond = icmp ult i32 %added, %bar.0, !dbg !5; br i1 %cond, label %bb1, label %bb2, !dbg !5. bb2: ; preds = %bb1; ret i32 0, !dbg !5; }. If one compiles this IR with ``llc -o - -start-after=codegen-prepare -stop-after=expand-isel-pseudos -mtriple=x86_64--``, the following MIR is produced:. .. code-block:: text. bb.0.entry:; successors: %bb.1(0x80000000); liveins: $rdi. %2:gr64 = COPY $rdi; %3:gr32 = MOV32r0 implicit-def dead $eflags; DBG_VALUE 0, $noreg, !3, !DIExpression(), debug-location !5. bb.1.bb1:; successors: %bb.1(0x7c000000), %bb.2(0x04000000). %0:gr32 = PHI %3, %bb.0, %1, %bb.1; DBG_VALUE %0, $noreg, !3, !DIExpression(), debug-location !5; DBG_VALUE %2, $noreg, !3, !DIExpression(DW_OP_plus_uconst, 4, DW_OP_stack_value), debug-location !5; %4:gr32 = MOV32rm %2, 1, $",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:30091,load,load,30091,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['load'],['load']
Performance,"which holds all memory addresses to read. The second operand is an alignment of the source addresses. It must be 0 or a power of two constant integer value. The third operand, mask, is a vector of boolean values with the same number of elements as the return type. The fourth is a pass-through value that is used to fill the masked-off lanes of the result. The return type, underlying type of the vector of pointers and the type of the '``passthru``' operand are the same vector types. Semantics:; """""""""""""""""""". The '``llvm.masked.gather``' intrinsic is designed for conditional reading of multiple scalar values from arbitrary memory locations in a single IR operation. It is useful for targets that support vector masked gathers and allows vectorizing basic blocks with data and control divergence. Other targets may support this intrinsic differently, for example by lowering it into a sequence of scalar load operations.; The semantics of this operation are equivalent to a sequence of conditional scalar loads with subsequent gathering all loaded values into a single vector. The mask restricts memory access to certain lanes and facilitates vectorization of predicated basic blocks. ::. %res = call <4 x double> @llvm.masked.gather.v4f64.v4p0(<4 x ptr> %ptrs, i32 8, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x double> poison). ;; The gather with all-true mask is equivalent to the following instruction sequence; %ptr0 = extractelement <4 x ptr> %ptrs, i32 0; %ptr1 = extractelement <4 x ptr> %ptrs, i32 1; %ptr2 = extractelement <4 x ptr> %ptrs, i32 2; %ptr3 = extractelement <4 x ptr> %ptrs, i32 3. %val0 = load double, ptr %ptr0, align 8; %val1 = load double, ptr %ptr1, align 8; %val2 = load double, ptr %ptr2, align 8; %val3 = load double, ptr %ptr3, align 8. %vec0 = insertelement <4 x double> poison, %val0, 0; %vec01 = insertelement <4 x double> %vec0, %val1, 1; %vec012 = insertelement <4 x double> %vec01, %val2, 2; %vec0123 = insertelement <4 x double> %vec012, %val3, 3. .. _",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:850588,load,loads,850588,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['load'],"['loaded', 'loads']"
Performance,"widenable_cond = call i1 @llvm.experimental.widenable.condition(); %new_cond = and i1 %any_other_cond, %widenable_cond; %new_guard_cond = and i1 %cond, %new_cond; br i1 %new_guard_cond, label %guarded, label %deopt. for this branch. Here `%any_other_cond` is an arbitrarily chosen; well-defined `i1` value. By making guard widening, we may; impose stricter conditions on `guarded` block and bail to the; deopt when the new condition is not met. Lowering:; """""""""""""""""". Default lowering strategy is replacing the result of; call of ``@llvm.experimental.widenable.condition`` with; constant `true`. However it is always correct to replace; it with any other `i1` value. Any pass can; freely do it if it can benefit from non-default lowering. '``llvm.load.relative``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.load.relative.iN(ptr %ptr, iN %offset) nounwind memory(argmem: read). Overview:; """""""""""""""""". This intrinsic loads a 32-bit value from the address ``%ptr + %offset``,; adds ``%ptr`` to that value and returns it. The constant folder specifically; recognizes the form of this intrinsic and the constant initializers it may; load from; if a loaded constant initializer is known to have the form; ``i32 trunc(x - %ptr)``, the intrinsic call is folded to ``x``. LLVM provides that the calculation of such a constant initializer will; not overflow at link time under the medium code model if ``x`` is an; ``unnamed_addr`` function. However, it does not provide this guarantee for; a constant initializer folded into a function body. This intrinsic can be; used to avoid the possibility of overflows when loading from such a constant. .. _llvm_sideeffect:. '``llvm.sideeffect``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.sideeffect() inaccessiblememonly nounwind willreturn. Overview:; """""""""""""""""". The ``llvm.sideeffect`` intrinsic doesn't perform any operation. Optimizers; treat it as having side effects, so it can",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:950934,load,loads,950934,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loads']
Performance,"wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before execut",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:279880,load,load,279880,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"with state ""A"",""B"",""C"",""D"" the specification. SplitParamConstrained(""m"",""c"",""D""). will result in parameters m_A,m_B,m_C and a formula expression m_D; that evaluates to (1-(m_A+m_B+m_C)). Constrained split can also be; specified in product of categories. In that case the name of the; remainder state follows the syntax {State1;State2} where State1; and State2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:13924,cache,cache,13924,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,2,['cache'],['cache']
Performance,"with target; dependent code, turning it into a function. Then ``tramp`` needs to be; passed to :ref:`llvm.adjust.trampoline <int_at>` to get a pointer which can; be :ref:`bitcast (to a new function) and called <int_trampoline>`. The new; function's signature is the same as that of ``func`` with any arguments; marked with the ``nest`` attribute removed. At most one such ``nest``; argument is allowed, and it must be of pointer type. Calling the new; function is equivalent to calling ``func`` with the same argument list,; but with ``nval`` used for the missing ``nest`` argument. If, after; calling ``llvm.init.trampoline``, the memory pointed to by ``tramp`` is; modified, then the effect of any later call to the returned function; pointer is undefined. .. _int_at:. '``llvm.adjust.trampoline``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.adjust.trampoline(ptr <tramp>). Overview:; """""""""""""""""". This performs any required machine-specific adjustment to the address of; a trampoline (passed as ``tramp``). Arguments:; """""""""""""""""""". ``tramp`` must point to a block of memory which already has trampoline; code filled in by a previous call to; :ref:`llvm.init.trampoline <int_it>`. Semantics:; """""""""""""""""""". On some architectures the address of the code to be executed needs to be; different than the address where the trampoline is actually stored. This; intrinsic returns the executable address corresponding to ``tramp``; after performing the required machine specific adjustments. The pointer; returned can then be :ref:`bitcast and executed <int_trampoline>`. .. _int_vp:. Vector Predication Intrinsics; -----------------------------; VP intrinsics are intended for predicated SIMD/vector code. A typical VP; operation takes a vector mask and an explicit vector length parameter as in:. ::. <W x T> llvm.vp.<opcode>.*(<W x T> %x, <W x T> %y, <W x i1> %mask, i32 %evl). The vector mask parameter (%mask) always has a vector of `i1` type, for example; `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:690943,perform,performs,690943,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"with the driver, but you; transparently use it to run the other tools. Preprocessing; This stage handles tokenization of the input source file, macro expansion,; #include expansion and handling of other preprocessor directives. The; output of this stage is typically called a "".i"" (for C), "".ii"" (for C++),; "".mi"" (for Objective-C), or "".mii"" (for Objective-C++) file. Parsing and Semantic Analysis; This stage parses the input file, translating preprocessor tokens into a; parse tree. Once in the form of a parse tree, it applies semantic; analysis to compute types for expressions as well and determine whether; the code is well formed. This stage is responsible for generating most of; the compiler warnings as well as parse errors. The output of this stage is; an ""Abstract Syntax Tree"" (AST). Code Generation and Optimization; This stage translates an AST into low-level intermediate code (known as; ""LLVM IR"") and ultimately to machine code. This phase is responsible for; optimizing the generated code and handling target-specific code generation.; The output of this stage is typically called a "".s"" file or ""assembly"" file. Clang also supports the use of an integrated assembler, in which the code; generator produces object files directly. This avoids the overhead of; generating the "".s"" file and of calling the target assembler. Assembler; This stage runs the target assembler to translate the output of the; compiler into a target object file. The output of this stage is typically; called a "".o"" file or ""object"" file. Linker; This stage runs the target linker to merge multiple object files into an; executable or dynamic library. The output of this stage is typically called; an ""a.out"", "".dylib"" or "".so"" file. :program:`Clang Static Analyzer`. The Clang Static Analyzer is a tool that scans source code to try to find bugs; through code analysis. This tool uses many parts of Clang and is built into; the same driver. Please see <https://clang-analyzer.llvm.org> for more details; on",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:1760,optimiz,optimizing,1760,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['optimiz'],['optimizing']
Performance,"with; the best intentions. Introduction; ============. The LLVM project and many of the core projects built on LLVM build using CMake.; This document aims to provide a brief overview of CMake for developers modifying; LLVM projects or building their own projects on top of LLVM. The official CMake language references is available in the cmake-language; manpage and `cmake-language online documentation; <https://cmake.org/cmake/help/v3.4/manual/cmake-language.7.html>`_. 10,000 ft View; ==============. CMake is a tool that reads script files in its own language that describe how a; software project builds. As CMake evaluates the scripts it constructs an; internal representation of the software project. Once the scripts have been; fully processed, if there are no errors, CMake will generate build files to; actually build the project. CMake supports generating build files for a variety; of command line build tools as well as for popular IDEs. When a user runs CMake it performs a variety of checks similar to how autoconf; worked historically. During the checks and the evaluation of the build; description scripts CMake caches values into the CMakeCache. This is useful; because it allows the build system to skip long-running checks during; incremental development. CMake caching also has some drawbacks, but that will be; discussed later. Scripting Overview; ==================. CMake's scripting language has a very simple grammar. Every language construct; is a command that matches the pattern _name_(_args_). Commands come in three; primary types: language-defined (commands implemented in C++ in CMake), defined; functions, and defined macros. The CMake distribution also contains a suite of; CMake modules that contain definitions for useful functionality. The example below is the full CMake build for building a C++ ""Hello World""; program. The example uses only CMake language-defined functions. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); ad",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:1275,perform,performs,1275,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,1,['perform'],['performs']
Performance,"wn the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation, then reduce the portion of the test; program which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugpoint; =========================. ``bugpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and miscompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:5192,optimiz,optimizations,5192,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,1,['optimiz'],['optimizations']
Performance,"wn``, return their; first argument aligned up/down to the next multiple of the second argument.; If the value is already sufficiently aligned, it is returned unchanged.; The builtin ``__builtin_is_aligned`` returns whether the first argument is; aligned to a multiple of the second argument.; All of these builtins expect the alignment to be expressed as a number of bytes. These builtins can be used for all integer types as well as (non-function); pointer types. For pointer types, these builtins operate in terms of the integer; address of the pointer and return a new pointer of the same type (including; qualifiers such as ``const``) with an adjusted address.; When aligning pointers up or down, the resulting value must be within the same; underlying allocation or one past the end (see C17 6.5.6p8, C++ [expr.add]).; This means that arbitrary integer values stored in pointer-type variables must; not be passed to these builtins. For those use cases, the builtins can still be; used, but the operation must be performed on the pointer cast to ``uintptr_t``. If Clang can determine that the alignment is not a power of two at compile time,; it will result in a compilation failure. If the alignment argument is not a; power of two at run time, the behavior of these builtins is undefined. Non-standard C++11 Attributes; =============================. Clang's non-standard C++11 attributes live in the ``clang`` attribute; namespace. Clang supports GCC's ``gnu`` attribute namespace. All GCC attributes which; are accepted with the ``__attribute__((foo))`` syntax are also accepted as; ``[[gnu::foo]]``. This only extends to attributes which are specified by GCC; (see the list of `GCC function attributes; <https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html>`_, `GCC variable; attributes <https://gcc.gnu.org/onlinedocs/gcc/Variable-Attributes.html>`_, and; `GCC type attributes; <https://gcc.gnu.org/onlinedocs/gcc/Type-Attributes.html>`_). As with the GCC; implementation, these attr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:153018,perform,performed,153018,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['perform'],['performed']
Performance,"wo different structs that have a single int field): these types; will compile down into a single LLVM type and it will be impossible to; tell what it came from. Second, while LLVM does lose information, LLVM is not a fixed target: we; continue to enhance and improve it in many different ways. In addition; to adding new features (LLVM did not always support exceptions or debug; info), we also extend the IR to capture important information for; optimization (e.g. whether an argument is sign or zero extended,; information about pointers aliasing, etc). Many of the enhancements are; user-driven: people want LLVM to include some specific feature, so they; go ahead and extend it. Third, it is *possible and easy* to add language-specific optimizations,; and you have a number of choices in how to do it. As one trivial; example, it is easy to add language-specific optimization passes that; ""know"" things about code compiled for a language. In the case of the C; family, there is an optimization pass that ""knows"" about the standard C; library functions. If you call ""exit(0)"" in main(), it knows that it is; safe to optimize that into ""return 0;"" because C specifies what the; 'exit' function does. In addition to simple library knowledge, it is possible to embed a; variety of other language-specific information into the LLVM IR. If you; have a specific need and run into a wall, please bring the topic up on; the llvm-dev list. At the very worst, you can always treat LLVM as if it; were a ""dumb code generator"" and implement the high-level optimizations; you desire in your front-end, on the language-specific AST. Tips and Tricks; ===============. There is a variety of useful tips and tricks that you come to know after; working on/with LLVM that aren't obvious at first glance. Instead of; letting everyone rediscover them, this section talks about some of these; issues. Implementing portable offsetof/sizeof; -------------------------------------. One interesting thing that comes up, if",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst:10595,optimiz,optimization,10595,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,1,['optimiz'],['optimization']
Performance,"wo different use cases having different ways of invoking the; geometry editors. The first one applies when starting with geometry from; scratch and using the builder functionality to create new geometry; objects. In this case, one should use the sequence:. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""MyGeom"",; ""Test builder"");; root[] geom->Edit(Option_t *option="""");; ~~~. The lines above will create a new TGeoManager class, create an; empty canvas and start the editor in the left-sided editor frame; attached to the canvas. To open the editor in a separate frame one; should provide a non-empty string as option to the `Edit()` method. \image html geometry018.png ""The geometry manager editor"". \anchor GP08b; ### The Geometry Manager Editor. \image html geometry019.png ""Accessing/creating different categories of editable objects"" width=600px. The second use case applies when starting to edit an existing geometry.; Supposing the geometry was loaded into memory, besides the first method; that still applies one can also edit drawn geometry objects. For this,; the menu entry View/Editor of the canvas containing for instance a drawn; volume must be activated. For starting the volume editor one can click; on a volume. The GUI of the TGeoManager class can be started by; clicking on the top-right `40x40` pixels corner of the pad with a drawn; geometry. This is the main entry point for editing the geometry or creating new; objects. Once the interface is created (using one of the methods; described above), several categories can be accessed via a shutter GUI; widget:. - *General.* This allows changing the name/title of the geometry,; setting the top volume, closing the geometry and saving the geometry; in a file. The file name is formed by `geometry_name.C` or `.root`; depending if the geometry need to be saved as a `C` macro or a; `.root` file.; - *Shapes.* The category provides buttons for creation of all; supported shapes. The new shape name is chosen by the interfac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:127420,load,loaded,127420,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['load'],['loaded']
Performance,"wo distinct regions:; the safe stack and the unsafe stack. The safe stack stores return addresses,; register spills, and local variables that are always accessed in a safe way,; while the unsafe stack stores everything else. This separation ensures that; buffer overflows on the unsafe stack cannot be used to overwrite anything; on the safe stack. SafeStack is a part of the `Code-Pointer Integrity (CPI) Project; <https://dslab.epfl.ch/research/cpi/>`_. Performance; -----------. The performance overhead of the SafeStack instrumentation is less than 0.1% on; average across a variety of benchmarks (see the `Code-Pointer Integrity; <https://dslab.epfl.ch/pubs/cpi.pdf>`__ paper for details). This is mainly; because most small functions do not have any variables that require the unsafe; stack and, hence, do not need unsafe stack frames to be created. The cost of; creating unsafe stack frames for large functions is amortized by the cost of; executing the function. In some cases, SafeStack actually improves the performance. Objects that end up; being moved to the unsafe stack are usually large arrays or variables that are; used through multiple stack frames. Moving such objects away from the safe; stack increases the locality of frequently accessed values on the stack, such; as register spills, return addresses, and small local variables. Compatibility; -------------. Most programs, static libraries, or individual files can be compiled; with SafeStack as is. SafeStack requires basic runtime support, which, on most; platforms, is implemented as a compiler-rt library that is automatically linked; in when the program is compiled with SafeStack. Linking a DSO with SafeStack is not currently supported. Known compatibility limitations; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Certain code that relies on low-level stack manipulations requires adaption to; work with SafeStack. One example is mark-and-sweep garbage collection; implementations for C/C++ (e.g., Oilpan in chromium/blink), which",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst:1318,perform,performance,1318,interpreter/llvm-project/clang/docs/SafeStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst,1,['perform'],['performance']
Performance,"wo primary goals in mind. First we strive to ; enable the best possible division of labor between static and dynamic ; compilers, and second, we need a flexible and powerful interface ; between these two complementary stages of compilation. We feel that ; providing a solution to these two goals will yield an excellent solution ; to the performance problem faced by modern architectures and programming ; languages. A key insight into current compiler and runtime systems is that a ; compiler may fall in anywhere in a ""continuum of compilation"" to do its ; job. On one side, scripting languages statically compile nothing and ; dynamically compile (or equivalently, interpret) everything. On the far ; other side, traditional static compilers process everything statically and ; nothing dynamically. These approaches have typically been seen as a ; tradeoff between performance and portability. On a deeper level, however, ; there are two reasons that optimal system performance may be obtained by a; system somewhere in between these two extremes: Dynamic application ; behavior and social constraints. From a technical perspective, pure static compilation cannot ever give ; optimal performance in all cases, because applications have varying dynamic; behavior that the static compiler cannot take into consideration. Even ; compilers that support profile guided optimization generate poor code in ; the real world, because using such optimization tunes that application ; to one particular usage pattern, whereas real programs (as opposed to ; benchmarks) often have several different usage patterns. On a social level, static compilation is a very shortsighted solution to ; the performance problem. Instruction set architectures (ISAs) continuously ; evolve, and each implementation of an ISA (a processor) must choose a set ; of tradeoffs that make sense in the market context that it is designed for. ; With every new processor introduced, the vendor faces two fundamental ; problems: First, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt:1009,perform,performance,1009,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt,1,['perform'],['performance']
Performance,"would not hold. To ensure all uses of a given register observe the same value (even if; '``undef``'), the :ref:`freeze instruction <i_freeze>` can be used. .. code-block:: llvm. %A = sdiv undef, %X; %B = sdiv %X, undef; Safe:; %A = 0; b: unreachable. These examples show the crucial difference between an *undefined value*; and *undefined behavior*. An undefined value (like '``undef``') is; allowed to have an arbitrary bit-pattern. This means that the ``%A``; operation can be constant folded to '``0``', because the '``undef``'; could be zero, and zero divided by any value is zero.; However, in the second example, we can make a more aggressive; assumption: because the ``undef`` is allowed to be an arbitrary value,; we are allowed to assume that it could be zero. Since a divide by zero; has *undefined behavior*, we are allowed to assume that the operation; does not execute at all. This allows us to delete the divide and all; code after it. Because the undefined operation ""can't happen"", the; optimizer can assume that it occurs in dead code. .. code-block:: text. a: store undef -> %X; b: store %X -> undef; Safe:; a: <deleted> (if the stored value in %X is provably not poison); b: unreachable. A store *of* an undefined value can be assumed to not have any effect;; we can assume that the value is overwritten with bits that happen to; match what was already there. This argument is only valid if the stored value; is provably not ``poison``. However, a store *to* an undefined; location could clobber arbitrary memory, therefore, it has undefined; behavior. Branching on an undefined value is undefined behavior.; This explains optimizations that depend on branch conditions to construct; predicates, such as Correlated Value Propagation and Global Value Numbering.; In case of switch instruction, the branch condition should be frozen, otherwise; it is undefined behavior. .. code-block:: llvm. Unsafe:; br undef, BB1, BB2 ; UB. %X = and i32 undef, 255; switch %X, label %ret [ .. ] ; U",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:195423,optimiz,optimizer,195423,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance,"write clang tools, and their pros and cons. LibClang; --------. `LibClang <https://clang.llvm.org/doxygen/group__CINDEX.html>`_ is a stable high; level C interface to clang. When in doubt LibClang is probably the interface; you want to use. Consider the other interfaces only when you have a good; reason not to use LibClang. Canonical examples of when to use LibClang:. * Xcode; * Clang Python Bindings. Use LibClang when you...:. * want to interface with clang from other languages than C++; * need a stable interface that takes care to be backwards compatible; * want powerful high-level abstractions, like iterating through an AST with a; cursor, and don't want to learn all the nitty gritty details of Clang's AST. Do not use LibClang when you...:. * want full control over the Clang AST. Clang Plugins; -------------. :doc:`Clang Plugins <ClangPlugins>` allow you to run additional actions on the; AST as part of a compilation. Plugins are dynamic libraries that are loaded at; runtime by the compiler, and they're easy to integrate into your build; environment. Canonical examples of when to use Clang Plugins:. * special lint-style warnings or errors for your project; * creating additional build artifacts from a single compile step. Use Clang Plugins when you...:. * need your tool to rerun if any of the dependencies change; * want your tool to make or break a build; * need full control over the Clang AST. Do not use Clang Plugins when you...:. * want to run tools outside of your build environment; * want full control on how Clang is set up, including mapping of in-memory; virtual files; * need to run over a specific subset of files in your project which is not; necessarily related to any changes which would trigger rebuilds. LibTooling; ----------. :doc:`LibTooling <LibTooling>` is a C++ interface aimed at writing standalone; tools, as well as integrating into services that run clang tools. Canonical; examples of when to use LibTooling:. * a simple syntax checker; * refactorin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Tooling.rst:1305,load,loaded,1305,interpreter/llvm-project/clang/docs/Tooling.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Tooling.rst,1,['load'],['loaded']
Performance,"ws vectorizing loop with cross-iteration dependency like in the following example:. .. code-block:: c. // In this loop we load from B and spread the elements into array A.; double *A, B; int *C;; for (int i = 0; i < size; ++i) {; if (C[i] != 0); A[i] = B[j++];; }. .. code-block:: llvm. ; Load several elements from array B and expand them in a vector.; ; The number of loaded elements is equal to the number of '1' elements in the Mask.; %Tmp = call <8 x double> @llvm.masked.expandload.v8f64(ptr %Bptr, <8 x i1> %Mask, <8 x double> poison); ; Store the result in A; call void @llvm.masked.store.v8f64.p0(<8 x double> %Tmp, ptr %Aptr, i32 8, <8 x i1> %Mask). ; %Bptr should be increased on each iteration according to the number of '1' elements in the Mask.; %MaskI = bitcast <8 x i1> %Mask to i8; %MaskIPopcnt = call i8 @llvm.ctpop.i8(i8 %MaskI); %MaskI64 = zext i8 %MaskIPopcnt to i64; %BNextInd = add i64 %BInd, %MaskI64. Other targets may support this intrinsic differently, for example, by lowering it into a sequence of conditional scalar load operations and shuffles.; If all mask elements are '1', the intrinsic behavior is equivalent to the regular unmasked vector load. .. _int_compressstore:. '``llvm.masked.compressstore.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. A number of scalar values of integer, floating point or pointer data type are collected from an input vector and stored into adjacent memory addresses. A mask defines which elements to collect from the vector. ::. declare void @llvm.masked.compressstore.v8i32 (<8 x i32> <value>, ptr <ptr>, <8 x i1> <mask>); declare void @llvm.masked.compressstore.v16f32 (<16 x float> <value>, ptr <ptr>, <16 x i1> <mask>). Overview:; """""""""""""""""". Selects elements from input vector '``value``' according to the '``mask``'. All selected elements are written into adjacent memory addresses starting at address '`ptr`', from lower to higher. The mask holds a bit for each",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:858022,load,load,858022,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"ws:. ```c++; using RooFit::TestStatistics::RooAbsL;; using RooFit::TestStatistics::buildLikelihood;. RooAbsPdf* pdf = ...; // build a pdf; RooAbsData* data = ...; // get some data. std::shared_ptr<RooAbsL> likelihood = buildLikelihood(pdf, data, [OPTIONAL ARGUMENTS]);. RooMinimizer m(likelihood);; m.migrad();; ```. The `RooMinimizer` object behaves as usual, except that behind the scenes it will now calculate each partial derivative on a separate process, ideally running on a separate CPU core.; This can be used to speed up fits with many parameters (at least as many as there are cores to parallelize over), since every parameter corresponds to a partial derivative.; The resulting fit parameters will be identical to those obtained with the non-parallelized gradients minimizer in most cases (see the usage notes linked below for exceptions). In upcoming releases, further developments are planned:. - Benchmark/profile and optimize performance further; - Add a `RooAbsPdf::fitTo` interface around these new classes; - Achieve feature parity with existing `RooNLLVar` functionality, e.g. ranges are not yet supported. For more details, consult the usage notes in the [TestStatistics README.md](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics/README.md).; For benchmarking results on the prototype version of the parallelized gradient calculator, see the corresponding [CHEP19 proceedings paper](https://doi.org/10.1051/epjconf/202024506027). ### New pythonizations. Various new pythonizations are introduced to streamline your RooFit code in Python. For a complete list of all pythonized classes and functions, please see the [RooFit pythonizations page in the reference guide](https://root.cern/doc/v626/group__RoofitPythonizations.html).; All RooFit Python tutorials have been updated to profit from all available pythonizations. Some notable highlights are listed in the following. #### Keyword argument pythonizations. All functions that take RooFit ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:18226,optimiz,optimize,18226,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,2,"['optimiz', 'perform']","['optimize', 'performance']"
Performance,"www.cis.upenn.edu/~cis501/papers/producing-wrong-data.pdf for; example. General; ================================. * Use a high resolution timer, e.g. perf under linux. * Run the benchmark multiple times to be able to recognize noise. * Disable as many processes or services as possible on the target system. * Disable frequency scaling, turbo boost and address space; randomization (see OS specific section). * Static link if the OS supports it. That avoids any variation that; might be introduced by loading dynamic libraries. This can be done; by passing ``-DLLVM_BUILD_STATIC=ON`` to cmake. * Try to avoid storage. On some systems you can use tmpfs. Putting the; program, inputs and outputs on tmpfs avoids touching a real storage; system, which can have a pretty big variability. To mount it (on linux and freebsd at least)::. mount -t tmpfs -o size=<XX>g none dir_to_mount. Linux; =====. * Disable address space randomization::. echo 0 > /proc/sys/kernel/randomize_va_space. * Set scaling_governor to performance::. for i in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do; echo performance > /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; done. * Use https://github.com/lpechacek/cpuset to reserve cpus for just the; program you are benchmarking. If using perf, leave at least 2 cores; so that perf runs in one and your program in another::. cset shield -c N1,N2 -k on. This will move all threads out of N1 and N2. The ``-k on`` means; that even kernel threads are moved out. * Disable the SMT pair of the cpus you will use for the benchmark. The; pair of cpu N can be found in; ``/sys/devices/system/cpu/cpuN/topology/thread_siblings_list`` and; disabled with::. echo 0 > /sys/devices/system/cpu/cpuX/online. * Run the program with::. cset shield --exec -- perf stat -r 10 <cmd>. This will run the command after ``--`` in the isolated cpus. The; particular perf command runs the ``<cmd>`` 10 times and reports; statistics. With these in place you can expect perf variations o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Benchmarking.rst:1363,perform,performance,1363,interpreter/llvm-project/llvm/docs/Benchmarking.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Benchmarking.rst,1,['perform'],['performance']
Performance,"x 4 x float> <left_op>, <vscale x 4 x float> <middle_op>, <vscale x 4 x float> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.fmuladd.v256f64 (<256 x double> <left_op>, <256 x double> <middle_op>, <256 x double> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point multiply-add of two vectors of floating-point values; that can be fused if code generator determines that (a) the target instruction; set has support for a fused operation, and (b) that the fused operation is more; efficient than the equivalent, separate pair of mul and add instructions. Arguments:; """""""""""""""""""". The first three operands and the result have the same vector of floating-point; type. The fourth operand is the vector mask and has the same number of elements; as the result vector type. The fifth operand is the explicit vector length of; the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.fmuladd``' intrinsic performs floating-point multiply-add (:ref:`llvm.fuladd <int_fmuladd>`); of the first, second, and third vector operand on each enabled lane. The result; on disabled lanes is a :ref:`poison value <poisonvalues>`. The operation is; performed in the default floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.fmuladd.v4f32(<4 x float> %a, <4 x float> %b, <4 x float> %c, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.fmuladd(<4 x float> %a, <4 x float> %b, <4 x float> %c); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_reduce_add:. '``llvm.vp.reduce.add.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.add.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.add.nxv8i16(i16 <start_value>, <vscale x 8 x i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:747569,perform,performs,747569,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"x Decompositions. The linear algebra package offers several classes to assist in matrix; decompositions. Each of the decomposition methods performs a set of; matrix transformations to facilitate solving a system of linear; equations, the formation of inverses as well as the estimation of; determinants and condition numbers. More specifically the classes; **`TDecompLU`**, **`TDecompBK`**, **`TDecompChol`**, **`TDecompQRH`** and; **`TDecompSVD`** give a simple and consistent interface to the LU,; Bunch-Kaufman, Cholesky, QR and SVD decompositions. All of these classes; are derived from the base class **`TDecompBase`** of which the important; methods are listed in next table:. +-----------------------------------------------------+--------------------------------------+; | Method | Action |; +-----------------------------------------------------+--------------------------------------+; | `Bool_t Decompose()` | perform the matrix decomposition |; +-----------------------------------------------------+--------------------------------------+; | `Double_t Condition()` | calculate ||*A*||1 ||*A*-1||1, |; | | see ""Condition number"" |; +-----------------------------------------------------+--------------------------------------+; | `void Det(Double_t &d1,Double_t &d2)` | the determinant is `d1` $2^{d_{2}}$. |; | | Expressing the determinant this |; | | way makes under/over-flow very |; | | unlikely |; +-----------------------------------------------------+--------------------------------------+; | `Bool_t Solve(TVectorD &b)` | solve `Ax=b`; vector` b` is |; | | supplied through the argument and |; | | replaced with solution `x` |; +-----------------------------------------------------+--------------------------------------+; | `TVectorD Solve(const TVectorD &b,Bool_t &ok)` | solve `Ax=b; x` is returned |; +-----------------------------------------------------+--------------------------------------+; | `Bool_t Solve(TMatrixDColumn &b)` | solve |; | | `Ax=column(B,j)`;` column(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md:34271,perform,perform,34271,documentation/users-guide/LinearAlgebra.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md,1,['perform'],['perform']
Performance,"x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_floor:. '``llvm.vp.floor.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.floor.v16f32 (<16 x float> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.floor.nxv4f32 (<vscale x 4 x float> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.floor.v256f64 (<256 x double> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point floor of a vector of floating-point values. Arguments:; """""""""""""""""""". The first operand and the result have the same vector of floating-point type.; The second operand is the vector mask and has the same number of elements as the; result vector type. The third operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.floor``' intrinsic performs floating-point floor; (:ref:`floor <int_floor>`) of the first vector operand on each enabled lane.; The result on disabled lanes is a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.floor.v4f32(<4 x float> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.floor.v4f32(<4 x float> %a); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_rint:. '``llvm.vp.rint.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.rint.v16f32 (<16 x float> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.rint.nxv4f32 (<vscale x 4 x float> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.rint.v256f64 (<256 x double> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point rint of a vec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:823596,perform,performs,823596,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_round:. '``llvm.vp.round.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.round.v16f32 (<16 x float> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.round.nxv4f32 (<vscale x 4 x float> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.round.v256f64 (<256 x double> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point round of a vector of floating-point values. Arguments:; """""""""""""""""""". The first operand and the result have the same vector of floating-point type.; The second operand is the vector mask and has the same number of elements as the; result vector type. The third operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.round``' intrinsic performs floating-point round; (:ref:`round <int_round>`) of the first vector operand on each enabled lane.; The result on disabled lanes is a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.round.v4f32(<4 x float> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.round.v4f32(<4 x float> %a); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_roundeven:. '``llvm.vp.roundeven.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.roundeven.v16f32 (<16 x float> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.roundeven.nxv4f32 (<vscale x 4 x float> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.roundeven.v256f64 (<256 x double> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated fl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:827869,perform,performs,827869,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.xor.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``XOR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.xor``' intrinsic performs the integer ``XOR`` reduction; (:ref:`llvm.vector.reduce.xor <int_vector_reduce_xor>`) of the vector operand; ``val`` on each enabled lane, performing an '``xor``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.xor.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %masked.a); %also.r = xor i32 %reduction, %start. .. _int_vp_reduce_smax:. '``llvm.vp.reduce.smax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smax.v4i32(i32 <start_value>,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:761930,perform,performing,761930,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performing']
Performance,"x i32> %t, <4 x i32> poison. .. _int_vp_xor:. '``llvm.vp.xor.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.xor.v16i32 (<16 x i32> <left_op>, <16 x i32> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.xor.nxv4i32 (<vscale x 4 x i32> <left_op>, <vscale x 4 x i32> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.xor.v256i64 (<256 x i64> <left_op>, <256 x i64> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Vector-predicated, bitwise xor. Arguments:; """""""""""""""""""". The first two operands and the result have the same vector of integer type. The; third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.xor``' intrinsic performs a bitwise xor (:ref:`xor <i_xor>`) of; the first two operands on each enabled lane.; The result on disabled lanes is a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.xor.v4i32(<4 x i32> %a, <4 x i32> %b, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = xor <4 x i32> %a, %b; %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_abs:. '``llvm.vp.abs.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.abs.v16i32 (<16 x i32> <op>, <16 x i1> <mask>, i32 <vector_length>, i1 <is_int_min_poison>); declare <vscale x 4 x i32> @llvm.vp.abs.nxv4i32 (<vscale x 4 x i32> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>, i1 <is_int_min_poison>); declare <256 x i64> @llvm.vp.abs.v256i64 (<256 x i64> <op>, <256 x i1> <mask>, i32 <vector_length>, i1 <is_int_min_poison>). Overview:; """""""""""""""""". Predicated abs of a v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:715467,perform,performs,715467,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"x is defined by the following BNF syntax:. .. code::. <target-id> ::== <processor> ( "":"" <target-feature> ( ""+"" | ""-"" ) )*. Where:. **processor**; Is a the target specific processor or any alternative processor name. **target-feature**; Is a target feature name that is supported by the processor. Each target; feature must appear at most once in a target ID and can have one of three; values:. *Any*; Specified by omitting the target feature from the target ID.; A code object compiled with a target ID specifying the default; value of a target feature can be loaded and executed on a processor; configured with the target feature on or off. *On*; Specified by ``+``, indicating the target feature is enabled. A code; object compiled with a target ID specifying a target feature on; can only be loaded on a processor configured with the target feature on. *Off*; specified by ``-``, indicating the target feature is disabled. A code; object compiled with a target ID specifying a target feature off; can only be loaded on a processor configured with the target feature off. .. _compatibility-target-id:. Compatibility Rules for Target ID; ---------------------------------. A code object compiled for a Target ID is considered compatible for a; target, if:. * Their processor is same.; * Their feature set is compatible as defined above. There are two forms of target ID:. *Non-Canonical Form*; The non-canonical form is used as the input to user commands to allow the user; greater convenience. It allows both the primary and alternative processor name; to be used and the target features may be specified in any order. *Canonical Form*; The canonical form is used for all generated output to allow greater; convenience for tools that consume the information. It is also used for; internal passing of information between tools. Only the primary and not; alternative processor name is used and the target features are specified in; alphabetic order. Command line tools convert non-canonical form to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst:12519,load,loaded,12519,interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,1,['load'],['loaded']
Performance,"x(""Run"",""Event"");; // to read entry corresponding to Run=1234 and Event=56789; tree.GetEntryWithIndex(1234,56789);; ```. Note that `majorname` and `minorname` may be expressions using original; tree variables e.g.: ""`run-90000`"", ""`event +3*xx`"". In case an; expression is specified, the equivalent expression must be computed when; calling `GetEntryWithIndex()`. To build an index with only `majorname`,; specify `minorname=""0""` (default). Note that once the index is built, it can be saved with the **`TTree`**; object with:. ``` {.cpp}; tree.Write(); //if the file has been open in ""update"" mode; ```. The most convenient place to create the index is at the end of the; filling process just before saving the tree header. If a previous index; was computed, it is redefined by this new call. Note that this function can also be applied to a **`TChain`**. The; return value is the number of entries in the Index (\< 0 indicates; failure). ## Branches. The organization of branches allows the designer to optimize the data; for the anticipated use. The class for a branch is called **`TBranch`**.; If two variables are independent, and the designer knows the variables; will not be used together, they should be placed on separate branches.; If, however, the variables are related, such as the coordinates of a; point, it is most efficient to create one branch with both coordinates; on it. A variable on a **`TBranch`** is called a leaf (yes -; **`TLeaf`**). Another point to keep in mind when designing trees is that; branches of the same **`TTree`** can be written to separate files. To; add a **`TBranch`** to a **`TTree`** we call the; method **`TTree::Branch()`**. Note that we DO NOT use the `TBranch`; constructor. The `TTree::Branch` method has several signatures. The branch type; differs by what is stored in it. A branch can hold an entire object, a; list of simple variables, contents of a folder, contents of a; **`TList`**, or an array of objects. Let's see some examples. To follow; a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:18060,optimiz,optimize,18060,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['optimiz'],['optimize']
Performance,"x, int y); {; return (abs(x)) >= 0;; }; This should optimize to x == INT_MIN. (With -fwrapv.) Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. From GCC Bug 14753:; void; rotate_cst (unsigned int a); {; a = (a << 10) | (a >> 22);; if (a == 123); bar ();; }; void; minus_cst (unsigned int a); {; unsigned int tem;. tem = 20 - a;; if (tem == 5); bar ();; }; void; mask_gt (unsigned int a); {; /* This is equivalent to a > 15. */; if ((a & ~7) > 8); bar ();; }; void; rshift_gt (unsigned int a); {; /* This is equivalent to a > 23. */; if ((a >> 2) > 5); bar ();; }. All should simplify to a single comparison. All of these are; currently not optimized with ""clang -emit-llvm-bc | opt; -O3"". //===---------------------------------------------------------------------===//. From GCC Bug 32605:; int c(int* x) {return (char*)x+2 == (char*)x;}; Should combine to 0. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"" (although llc can optimize it). //===---------------------------------------------------------------------===//. int a(unsigned b) {return ((b << 31) | (b << 30)) >> 31;}; Should be combined to ""((b >> 1) | b) & 1"". Currently not optimized; with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned a(unsigned x, unsigned y) { return x | (y & 1) | (y & 2);}; Should combine to ""x | (y & 3)"". Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a, int b, int c) {return (~a & c) | ((c|a) & b);}; Should fold to ""(~a & c) | (a & b)"". Currently not optimized with; ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a,int b) {return (~(a|b))|a;}; Should fold to ""a|~b"". Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===----",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:23482,optimiz,optimized,23482,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['optimiz'],"['optimize', 'optimized']"
Performance,"x08`` Reserved.; reserved ``s_trap 0xfe`` Reserved.; reserved ``s_trap 0xff`` Reserved.; =================== =============== =============== =======================================. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V3; :name: amdgpu-trap-handler-for-amdhsa-os-v3-table. =================== =============== =============== =======================================; Usage Code Sequence Trap Handler Description; Inputs; =================== =============== =============== =======================================; reserved ``s_trap 0x00`` Reserved by hardware.; debugger breakpoint ``s_trap 0x01`` *none* Reserved for debugger to use for; breakpoints. Causes wave to be halted; with the PC at the trap instruction.; The debugger is responsible to resume; the wave, including the instruction; that the breakpoint overwrote.; ``llvm.trap`` ``s_trap 0x02`` ``SGPR0-1``: Causes wave to be halted with the PC at; ``queue_ptr`` the trap instruction. The associated; queue is signalled to put it into the; error state. When the queue is put in; the error state, the waves executing; dispatches on the queue will be; terminated.; ``llvm.debugtrap`` ``s_trap 0x03`` *none* - If debugger not enabled then behaves; as a no-operation. The trap handler; is entered and immediately returns to; continue execution of the wavefront.; - If the debugger is enabled, causes; the debug trap to be reported by the; debugger and the wavefront is put in; the halt state with the PC at the; instruction. The debugger must; increment the PC and resume the wave.; reserved ``s_trap 0x04`` Reserved.; reserved ``s_trap 0x05`` Reserved.; reserved ``s_trap 0x06`` Reserved.; reserved ``s_trap 0x07`` Reserved.; reserved ``s_trap 0x08`` Reserved.; reserved ``s_trap 0xfe`` Reserved.; reserved ``s_trap 0xff`` Reserved.; =================== =============== =============== =======================================. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V4 and Above; :name: amdgpu-trap-h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:383050,queue,queue,383050,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance,"x:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.or.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.or.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``OR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.or``' intrinsic performs the integer ``OR`` reduction; (:ref:`llvm.vector.reduce.or <int_vector_reduce_or>`) of the vector operand; ``val`` on each enabled lane, performing an '``or``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.or.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %masked.a); %also.r = or i32 %reduction, %start. .. _int_vp_reduce_xor:. '``llvm.vp.reduce.xor.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:759771,perform,performs,759771,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"xample, the; address of an instance variable could be written to some global; location and then freely accessed during the lifetime of the local,; or a function could return an inner pointer of an object and store; it to a local. These cases would be potentially impossible to; reason about and so would basically prevent any optimizations based; on imprecise lifetime. There are also uncommon enough to make it; reasonable to require the precise-lifetime annotation if someone; really wants to rely on them. Dependency does propagate through return values of pointer type.; The compelling source of need for this rule is a property accessor; which returns an un-autoreleased result; the calling function must; have the chance to operate on the value, e.g. to retain it, before; ARC releases the original pointer. Note again, however, that; dependence does not survive a store, so ARC does not guarantee the; continued validity of the return value past the end of the; full-expression. .. _arc.optimization.object_lifetime:. No object lifetime extension; ----------------------------. If, in the formal computation history of the program, an object ``X``; has been deallocated by the time of an observable side-effect, then; ARC must cause ``X`` to be deallocated by no later than the occurrence; of that side-effect, except as influenced by the re-ordering of the; destruction of objects. .. admonition:: Rationale. This rule is intended to prohibit ARC from observably extending the; lifetime of a retainable object, other than as specified in this; document. Together with the rule limiting the transformation of; releases, this rule requires ARC to eliminate retains and release; only in pairs. ARC's power to reorder the destruction of objects is critical to its; ability to do any optimization, for essentially the same reason that; it must retain the power to decrease the lifetime of an object.; Unfortunately, while it's generally poor style for the destruction; of objects to have arbitrary ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:82397,optimiz,optimization,82397,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimization']
Performance,"xcept that we will compute ``C = pow(A, B)`` instead of ``C = A + B``.; Libdevice provides an ``__nv_powf`` function that we will use. .. code-block:: llvm. target datalayout = ""e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v16:16:16-v32:32:32-v64:64:64-v128:128:128-n16:32:64""; target triple = ""nvptx64-nvidia-cuda"". ; Intrinsic to read X component of thread ID; declare i32 @llvm.nvvm.read.ptx.sreg.tid.x() readnone nounwind; ; libdevice function; declare float @__nv_powf(float, float). define void @kernel(float addrspace(1)* %A,; float addrspace(1)* %B,; float addrspace(1)* %C) {; entry:; ; What is my ID?; %id = tail call i32 @llvm.nvvm.read.ptx.sreg.tid.x() readnone nounwind. ; Compute pointers into A, B, and C; %ptrA = getelementptr float, float addrspace(1)* %A, i32 %id; %ptrB = getelementptr float, float addrspace(1)* %B, i32 %id; %ptrC = getelementptr float, float addrspace(1)* %C, i32 %id. ; Read A, B; %valA = load float, float addrspace(1)* %ptrA, align 4; %valB = load float, float addrspace(1)* %ptrB, align 4. ; Compute C = pow(A, B); %valC = call float @__nv_powf(float %valA, float %valB). ; Store back to C; store float %valC, float addrspace(1)* %ptrC, align 4. ret void; }. !nvvm.annotations = !{!0}; !0 = !{void (float addrspace(1)*,; float addrspace(1)*,; float addrspace(1)*)* @kernel, !""kernel"", i32 1}. To compile this kernel, we perform the following steps:. 1. Link with libdevice; 2. Internalize all but the public kernel function; 3. Run ``NVVMReflect`` and set ``__CUDA_FTZ`` to 0; 4. Optimize the linked module; 5. Codegen the module. These steps can be performed by the LLVM ``llvm-link``, ``opt``, and ``llc``; tools. In a complete compiler, these steps can also be performed entirely; programmatically by setting up an appropriate pass configuration (see; :ref:`libdevice`). .. code-block:: text. # llvm-link t2.bc libdevice.compute_20.10.bc -o t2.linked.bc; # opt -internalize -internalize-public-api-list=kernel -nvvm-reflect-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst:24572,load,load,24572,interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,2,['load'],['load']
Performance,"xecution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; sc0=1 sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. load atomic acquire - agent - generic 1. flat_load sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load sc0=1 sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv.; - Ensures the f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:297543,load,load,297543,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,"['cache', 'load']","['cache', 'load']"
Performance,"xed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; correct case for a switch statement implemented as a jump table.; * A hot common return address may be predicted incorrectly when returning from; a function. These code patterns are also vulnerable to Spectre variant #2, and as such are; best mitigated with a; [retpoline](https://support.google.com/faqs/answer/7625886) on x86 platforms.; When a mitigation technique like retpoline is used, speculation simply cannot; proceed through an indirect control flow edge (or it cannot be mispredicted in; the case of a filled RSB) and so",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:8240,load,loaded,8240,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loaded']
Performance,"xes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:13647,perform,performance,13647,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['perform'],['performance']
Performance,"xit would be jumped from both %latch and %entry,; but %entry is not contained in the loop).; Note that a loop has to be in Loop Simplify Form beforehand; too for LoopRotate to be applied successfully. The main advantage of this form is that it allows hoisting; invariant instructions, especially loads, into the preheader.; That could be done in non-rotated loops as well but with; some disadvantages. Let's illustrate them with an example:. .. code-block:: C. for (int i = 0; i < n; ++i) {; auto v = *p;; use(v);; }. We assume that loading from p is invariant and use(v) is some; statement that uses v.; If we wanted to execute the load only once we could move it; ""out"" of the loop body, resulting in this:. .. code-block:: C. auto v = *p;; for (int i = 0; i < n; ++i) {; use(v);; }. However, now, in the case that n <= 0, in the initial form,; the loop body would never execute, and so, the load would; never execute. This is a problem mainly for semantic reasons.; Consider the case in which n <= 0 and loading from p is invalid.; In the initial program there would be no error. However, with this; transformation we would introduce one, effectively breaking; the initial semantics. To avoid both of these problems, we can insert a guard:. .. code-block:: C. if (n > 0) { // loop guard; auto v = *p;; for (int i = 0; i < n; ++i) {; use(v);; }; }. This is certainly better but it could be improved slightly. Notice; that the check for whether n is bigger than 0 is executed twice (and; n does not change in between). Once when we check the guard condition; and once in the first execution of the loop. To avoid that, we could; do an unconditional first execution and insert the loop condition; in the end. This effectively means transforming the loop into a do-while loop:. .. code-block:: C. if (0 < n) {; auto v = *p;; do {; use(v);; ++i;; } while (i < n);; }. Note that LoopRotate does not generally do such; hoisting. Rather, it is an enabling transformation for other; passes like Loop-Invari",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:22968,load,loading,22968,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,1,['load'],['loading']
Performance,"xpects to take; ownership of a +1 retain count. This is done by adding the; ``ns_returns_retained`` attribute to the function or method declaration, like; so:. .. code-block:: objc. id foo(void) __attribute((ns_returns_retained));; - (id) foo __attribute((ns_returns_retained));. This attribute is part of the type of the function or method. When returning from such a function or method, ARC retains the value at the; point of evaluation of the return statement, before leaving all local scopes. When receiving a return result from such a function or method, ARC releases the; value at the end of the full-expression it is contained within, subject to the; usual optimizations for local values. .. admonition:: Rationale. This formalizes direct transfers of ownership from a callee to a caller. The; most common scenario this models is the retained return from ``init``,; ``alloc``, ``new``, and ``copy`` methods, but there are other cases in the; frameworks. After optimization there are typically no extra retains and; releases required. Methods in the ``alloc``, ``copy``, ``init``, ``mutableCopy``, and ``new``; :ref:`families <arc.method-families>` are implicitly marked; ``__attribute__((ns_returns_retained))``. This may be suppressed by explicitly; marking the method ``__attribute__((ns_returns_not_retained))``. It is undefined behavior if the method to which an Objective-C message send; statically resolves has different retain semantics on its result from the; method it dynamically resolves to. It is undefined behavior if a block or; function call is made through a static type with different retain semantics on; its result from the implementation of the called block or function. .. admonition:: Rationale. Mismatches with returned results will cause over-retains or over-releases,; depending on the direction. Again, the rule about function calls is really; just an application of the existing C/C++ rule about calling functions; through an incompatible function type. .. _arc.obje",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:20220,optimiz,optimization,20220,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimization']
Performance,"xposing atomic operations, these are much easier to reason; about for the programmer than other kinds of operations, and using them is; generally a practical performance tradeoff. Notes for optimizers; Optimizers not aware of atomics can treat this like a nothrow call. For; SequentiallyConsistent loads and stores, the same reorderings are allowed as; for Acquire loads and Release stores, except that SequentiallyConsistent; operations may not be reordered. Notes for code generation; SequentiallyConsistent loads minimally require the same barriers as Acquire; operations and SequentiallyConsistent stores require Release; barriers. Additionally, the code generator must enforce ordering between; SequentiallyConsistent stores followed by SequentiallyConsistent loads. This; is usually done by emitting either a full fence before the loads or a full; fence after the stores; which is preferred varies by architecture. Atomics and IR optimization; ===========================. Predicates for optimizer writers to query:. * ``isSimple()``: A load or store which is not volatile or atomic. This is; what, for example, memcpyopt would check for operations it might transform. * ``isUnordered()``: A load or store which is not volatile and at most; Unordered. This would be checked, for example, by LICM before hoisting an; operation. * ``mayReadFromMemory()``/``mayWriteToMemory()``: Existing predicate, but note; that they return true for any operation which is volatile or at least; Monotonic. * ``isStrongerThan`` / ``isAtLeastOrStrongerThan``: These are predicates on; orderings. They can be useful for passes that are aware of atomics, for; example to do DSE across a single atomic access, but not across a; release-acquire pair (see MemoryDependencyAnalysis for an example of this). * Alias analysis: Note that AA will return ModRef for anything Acquire or; Release, and for the address accessed by any Monotonic operation. To support optimizing around atomic operations, make sure you are using",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:15843,optimiz,optimizer,15843,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['optimiz'],['optimizer']
Performance,"xpression in. UIWebView *webView = ...;; CGRect bodyFrame = webView.frame;; bodyFrame.size.height = self.bodyContentHeight;; webView.frame = bodyFrame;; // ^---- matches here. Matcher<ObjCMessageExpr>hasNullSelector; Matches when the selector is the empty selector. Matches only when the selector of the objCMessageExpr is NULL. This may; represent an error condition in the tree!. Matcher<ObjCMessageExpr>hasSelectorstd::string BaseName; Matches when BaseName == Selector.getAsString(). matcher = objCMessageExpr(hasSelector(""loadHTMLString:baseURL:""));; matches the outer message expr in the code below, but NOT the message; invocation for self.bodyView.; [self.bodyView loadHTMLString:html baseURL:NULL];. Matcher<ObjCMessageExpr>hasUnarySelector; Matches when the selector is a Unary Selector. matcher = objCMessageExpr(matchesSelector(hasUnarySelector());; matches self.bodyView in the code below, but NOT the outer message; invocation of ""loadHTMLString:baseURL:"".; [self.bodyView loadHTMLString:html baseURL:NULL];. Matcher<ObjCMessageExpr>isClassMessage; Returns true when the Objective-C message is sent to a class. Example; matcher = objcMessageExpr(isClassMessage()); matches; [NSString stringWithFormat:@""format""];; but not; NSString *x = @""hello"";; [x containsString:@""h""];. Matcher<ObjCMessageExpr>isInstanceMessage; Returns true when the Objective-C message is sent to an instance. Example; matcher = objcMessageExpr(isInstanceMessage()); matches; NSString *x = @""hello"";; [x containsString:@""h""];; but not; [NSString stringWithFormat:@""format""];. Matcher<ObjCMessageExpr>matchesSelectorStringRef RegExp, Regex::RegexFlags Flags = NoFlags; Matches ObjC selectors whose name contains; a substring matched by the given RegExp.; matcher = objCMessageExpr(matchesSelector(""loadHTMLStringmatches the outer message expr in the code below, but NOT the message; invocation for self.bodyView.; [self.bodyView loadHTMLString:html baseURL:NULL];. If the matcher is used in clang-query, RegexFlags",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:107195,load,loadHTMLString,107195,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,1,['load'],['loadHTMLString']
Performance,"xpressions to retain their same meaning,; while enabling the ability to explicitly create memory location descriptions in; non-default address spaces and generalizing the power of composite location; descriptions to any kind of location description. For those familiar with the definition of location descriptions in DWARF Version; 5, the definitions in these extensions are presented differently, but does in; fact define the same concept with the same fundamental semantics. However, it; does so in a way that allows the concept to extend to support address spaces,; bit addressing, the ability for composite location descriptions to be composed; of any kind of location description, and the ability to support objects located; at multiple places. Collectively these changes expand the set of architectures; that can be supported and improves support for optimized code. Several approaches were considered, and the one presented, together with the; extensions it enables, appears to be the simplest and cleanest one that offers; the greatest improvement of DWARF's ability to support debugging optimized GPU; and non-GPU code. Examining the GDB debugger and LLVM compiler, it appears only; to require modest changes as they both already have to support general use of; location descriptions. It is anticipated that will also be the case for other; debuggers and compilers. GDB has been modified to evaluate DWARF Version 5 expressions with location; descriptions as stack entries and with implicit conversions. All GDB tests have; passed, except one that turned out to be an invalid test case by DWARF Version 5; rules. The code in GDB actually became simpler as all evaluation is done on a; single stack and there was no longer a need to maintain a separate structure for; the location description results. This gives confidence in backwards; compatibility. See :ref:`amdgpu-dwarf-expressions` and nested sections. This extension is separately described at *Allow Location Descriptions on the; DWA",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:7150,optimiz,optimized,7150,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['optimiz'],['optimized']
Performance,"xpressions with location; descriptions as stack entries and with implicit conversions. All GDB tests have; passed, except one that turned out to be an invalid test case by DWARF Version 5; rules. The code in GDB actually became simpler as all evaluation is done on a; single stack and there was no longer a need to maintain a separate structure for; the location description results. This gives confidence in backwards; compatibility. See :ref:`amdgpu-dwarf-expressions` and nested sections. This extension is separately described at *Allow Location Descriptions on the; DWARF Expression Stack* [:ref:`AMDGPU-DWARF-LOC; <amdgpu-dwarf-AMDGPU-DWARF-LOC>`]. 2.2 Generalize CFI to Allow Any Location Description Kind; ---------------------------------------------------------. CFI describes restoring callee saved registers that are spilled. Currently CFI; only allows a location description that is a register, memory address, or; implicit location description. AMDGPU optimized code may spill scalar registers; into portions of vector registers. This requires extending CFI to allow any; location description kind to be supported. See :ref:`amdgpu-dwarf-call-frame-information`. 2.3 Generalize DWARF Operation Expressions to Support Multiple Places; ---------------------------------------------------------------------. In DWARF Version 5 a location description is defined as a single location; description or a location list. A location list is defined as either; effectively an undefined location description or as one or more single; location descriptions to describe an object with multiple places. With; :ref:`amdgpu-dwarf-allow-location-description-on-the-dwarf-evaluation-stack`,; the ``DW_OP_push_object_address`` and ``DW_OP_call*`` operations can put a; location description on the stack. Furthermore, debugger information entry; attributes such as ``DW_AT_data_member_location``, ``DW_AT_use_location``, and; ``DW_AT_vtable_elem_location`` are defined as pushing a location description on; t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:8446,optimiz,optimized,8446,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['optimiz'],['optimized']
Performance,"xt boundary is:. ~~~{.cpp}; TGeoNode *TGeoManager::FindNextBoundary(stepmax, path); ~~~. The output node returned by the method is the object which shape; boundary will be crossed first. The distance to the next crossing can be; retrieved after the call:. ~~~{.cpp}; Double_t TGeoManager::GetStep(); ~~~. - The main input parameter is `stepmax,` which act as a trigger for; different features. The absolute value of this parameter represents; the step value proposed by the user. The algorithm will never try o; search for boundaries further than this distance. In case no; boundary is found the returned node will be the current one and the; computed step to boundary will be equal to abs (`stepmax`) having; the meaning ""step approved"". The default value for `stepmax` is; TGeoShape::Big with the meaning that boundaries are looked for; without limitation. \image html geometry017.png ""Finding the distance to the next crossed boundary"" width=600px. According the values of the input parameters the method will perform; additional optional tasks:. `|stepmax| < TGeoShape::Big()`. The safe distance in the current volume is also computed. Moving the; particle from its current location with this distance in any direction; is safe in the sense that will never change the current state. `stepmax < 0`. The global matrix for the object that will have the next crossed; boundary is also computed. This can be retrieved for masterlocal point; or vector conversions: TGeoManager::GetNextMatrix(). In case the computation of the normal vector to the next crossed surface; is required, using a negative stepmax value is recommended. In this case; one can subsequently call a method for fast normal computation:. ~~~{.cpp}; Double_t *TGeoManager::FindNormalFast(); ~~~. `path 0`. In case a path to a given physical object is specified, the distance to; its boundary is computed ignoring the rest of the geometry. \anchor GP07c; #### Output Values. TGeoManager::GetStep(): distance to next boundary. TGeoMana",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:120565,perform,perform,120565,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['perform']
Performance,"xternal; references in a final linked binary. .. option:: --dylibs-used. Display the shared libraries used for linked files. .. option:: --dsym=<string>. Use .dSYM file for debug info. .. option:: --dylib-id. Display the shared library's ID for dylib files. .. option:: --exports-trie. Display exported symbols. .. option:: --function-starts [=<addrs|names|both>]. Print the function starts table for Mach-O objects. Either ``addrs``; (default) to print only the addresses of functions, ``names`` to print only; the names of the functions (when available), or ``both`` to print the; names beside the addresses. .. option:: -g. Print line information from debug info if available. .. option:: --full-leading-addr. Print the full leading address when disassembling. .. option:: --indirect-symbols. Display the indirect symbol table. .. option:: --info-plist. Display the info plist section as strings. .. option:: --lazy-bind. Display lazy binding info. .. option:: --link-opt-hints. Display the linker optimization hints. .. option:: -m, --macho. Use Mach-O specific object file parser. Commands and other options may behave; differently when used with ``--macho``. .. option:: --no-leading-headers. Do not print any leading headers. .. option:: --no-symbolic-operands. Do not print symbolic operands when disassembling. .. option:: --non-verbose. Display the information for Mach-O objects in non-verbose or numeric form. .. option:: --objc-meta-data. Display the Objective-C runtime meta data. .. option:: --private-header. Display only the first format specific file header. .. option:: --rebase. Display rebasing information. .. option:: --rpaths. Display runtime search paths for the binary. .. option:: --universal-headers. Display universal headers. .. option:: --weak-bind. Display weak binding information. XCOFF ONLY OPTIONS AND COMMANDS; ---------------------------------. .. option:: --symbol-description. Add symbol description to disassembly output. .. option:: --traceback-table. Decode ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:10853,optimiz,optimization,10853,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,1,['optimiz'],['optimization']
Performance,"xtra; information for one optimization. Alias analysis itself is typically; greater than linear in asymptotic complexity, so this extra analaysis; would not affect the runtime of the optimization in a significant; way. Additionally, this would be an unlikely optimization to do at; runtime. IDEAS TO CONSIDER; -----------------. 1. Including dominator information in the LLVM bytecode; representation. This is one example of an analysis result that may be; packaged with the bytecodes themselves. As a conceptual implementation ; idea, we could include an immediate dominator number for each basic block; in the LLVM bytecode program. Basic blocks could be numbered according; to the order of occurrence in the bytecode representation. 2. Including loop header and body information. This would facilitate; detection of intervals and natural loops. UNRESOLVED ISSUES ; ----------------- . 1. Will oSUIF provide enough of an infrastructure to support the research; that we will be doing? We know that it has less than stellar; performance, but hope that this will be of little importance for our; static compiler. This could affect us if we decided to do some IP; research. Also we do not yet understand the level of exception support; currently implemented. 2. Should we consider the requirements of a direct hardware implementation; of the LLVM when we design it? If so, several design issues should; have their priorities shifted. The other option is to focus on a; software layer interpreting the LLVM in all cases. 3. Should we use some form of packetized format to improve forward; compatibility? For example, we could design the system to encode a; packet type and length field before analysis information, to allow a; runtime to skip information that it didn't understand in a bytecode; stream. The obvious benefit would be for compatibility, the drawback; is that it would tend to splinter that 'standard' LLVM definition. 4. Should we use fixed length instructions or variable length; instruct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt:1964,perform,performance,1964,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt,1,['perform'],['performance']
Performance,"xtremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see its ""All input ok"" message, you might try ``llvm-link; -v`` on the same set of input files. If that also crashes, you may be; experiencing a linker bug. * ``bugpoint`` is useful for proactively finding bugs in LLVM. Invoking; ``bugpoint`` with the ``-find-bugs`` option will cause the list of specified; optimizations to be randomized and applied to the program. This process will; repeat until a bug is found or the user kills ``bugpoint``. * ``bugpoint`` can produce IR which contains long names. Run ``opt; -passes=metarenamer`` over the IR to rename everything using easy-to-read,; metasyntactic names. Alternatively, run ``opt -passes=strip,instnamer`` to; rename everything with very short (often purely numeric) names. What to do when bugpoint isn't enough; =====================================; 	; Sometimes, ``bugpoint`` is not enough. In particular, InstCombine and; TargetLowering both have visitor structured code with lots of potential; transformations. If the process of using bugpoint has left you with still too; much code to figure out and the problem seems to be in instcombine, the; following steps may help. These same techniques are useful with TargetLowering; as well. Turn on ``-debug-only=instcombine`` and see which transformations within; instcombine are firing ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:7756,optimiz,optimizations,7756,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,1,['optimiz'],['optimizations']
Performance,"xy>(M).getManager();. // Invalidate all analysis results for function F1.; FAM.invalidate(F1, PreservedAnalyses::none());. // Invalidate all analysis results across the entire module.; AM.invalidate(M, PreservedAnalyses::none());. // Clear the entry in the analysis manager for function F2 if we've completely removed it from the module.; FAM.clear(F2);. ...; }. One thing to note when accessing inner level IR analyses is cached results for; deleted IR. If a function is deleted in a module pass, its address is still used; as the key for cached analyses. Take care in the pass to either clear the; results for that function or not use inner analyses at all. ``AM.invalidate(M, PreservedAnalyses::none());`` will invalidate the inner; analysis manager proxy which will clear all cached analyses, conservatively; assuming that there are invalid addresses used as keys for cached analyses.; However, if you'd like to be more selective about which analyses are; cached/invalidated, you can mark the analysis manager proxy as preserved,; essentially saying that all deleted entries have been taken care of manually.; This should only be done with measurable compile time gains as it can be tricky; to make sure all the right analyses are invalidated. Implementing Analysis Invalidation; ==================================. By default, an analysis is invalidated if ``PreservedAnalyses`` says that; analyses on the IR unit it runs on are not preserved (see; ``AnalysisResultModel::invalidate()``). An analysis can implement; ``invalidate()`` to be more conservative when it comes to invalidation. For; example,. .. code-block:: c++. bool FooAnalysisResult::invalidate(Function &F, const PreservedAnalyses &PA,; FunctionAnalysisManager::Invalidator &) {; auto PAC = PA.getChecker<FooAnalysis>();; // the default would be:; // return !(PAC.preserved() || PAC.preservedSet<AllAnalysesOn<Function>>());; return !(PAC.preserved() || PAC.preservedSet<AllAnalysesOn<Function>>(); || PAC.preservedSet<CFGAnalyses",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:14618,cache,cached,14618,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['cache'],['cached']
Performance,"y add attributes itself.; For instance, the vectorizer adds a ``llvm.loop.isvectorized`` attribute and; all attributes from the original loop excluding its loop vectorizer; attributes. To avoid this, an empty followup attribute can be used, e.g. .. code-block:: llvm. !3 = !{!""llvm.loop.vectorize.followup_vectorized""}. The followup attributes of a transformation that cannot be applied will; never be added to a loop and are therefore effectively ignored. This means; that any followup-transformation in such attributes requires that its; prior transformations are applied before the followup-transformation.; The user should receive a warning about the first transformation in the; transformation chain that could not be applied if it a forced; transformation. All following transformations are skipped. Pass-Specific Transformation Metadata; =====================================. Transformation options are specific to each transformation. In the; following, we present the model for each LLVM loop optimization pass and; the metadata to influence them. Loop Vectorization and Interleaving; -----------------------------------. Loop vectorization and interleaving is interpreted as a single; transformation. It is interpreted as forced if; ``!{""llvm.loop.vectorize.enable"", i1 true}`` is set. Assuming the pre-vectorization loop is. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; Stmt(i);. then the code after vectorization will be approximately (assuming an; SIMD width of 4):. .. code-block:: c. int i = 0;; if (rtc) {; for (; i + 3 < n; i+=4) // vectorized/interleaved loop; Stmt(i:i+3);; }; for (; i < n; i+=1) // epilogue loop; Stmt(i);. where ``rtc`` is a generated runtime check. ``llvm.loop.vectorize.followup_vectorized`` will set the attributes for; the vectorized loop. If not specified, ``llvm.loop.isvectorized`` is; combined with the original loop's attributes to avoid it being; vectorized multiple times. ``llvm.loop.vectorize.followup_epilogue`` will set the a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:5481,optimiz,optimization,5481,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst,1,['optimiz'],['optimization']
Performance,"y apply to inherited fields. 4. Parse the body of the record. * Add any fields to the record.; * Modify the values of fields according to local ``let`` statements.; * Define any ``defvar`` variables. 5. Make a pass over all the fields to resolve any inter-field references. 6. Add the record to the final record list. Because references between fields are resolved (step 5) after ``let`` bindings are; applied (step 3), the ``let`` statement has unusual power. For example:. .. code-block:: text. class C <int x> {; int Y = x;; int Yplus1 = !add(Y, 1);; int xplus1 = !add(x, 1);; }. let Y = 10 in {; def rec1 : C<5> {; }; }. def rec2 : C<5> {; let Y = 10;; }. In both cases, one where a top-level ``let`` is used to bind ``Y`` and one; where a local ``let`` does the same thing, the results are:. .. code-block:: text. def rec1 { // C; int Y = 10;; int Yplus1 = 11;; int xplus1 = 6;; }; def rec2 { // C; int Y = 10;; int Yplus1 = 11;; int xplus1 = 6;; }. ``Yplus1`` is 11 because the ``let Y`` is performed before the ``!add(Y,; 1)`` is resolved. Use this power wisely. Using Classes as Subroutines; ============================. As described in `Simple values`_, a class can be invoked in an expression; and passed template arguments. This causes TableGen to create a new anonymous; record inheriting from that class. As usual, the record receives all the; fields defined in the class. This feature can be employed as a simple subroutine facility. The class can; use the template arguments to define various variables and fields, which end; up in the anonymous record. Those fields can then be retrieved in the; expression invoking the class as follows. Assume that the field ``ret``; contains the final value of the subroutine. .. code-block:: text. int Result = ... CalcValue<arg>.ret ...;. The ``CalcValue`` class is invoked with the template argument ``arg``. It; calculates a value for the ``ret`` field, which is then retrieved at the; ""point of call"" in the initialization for the Result fiel",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:54897,perform,performed,54897,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['perform'],['performed']
Performance,"y are different; . Use intrinsic; (set v16i8:$XT, (int_ppc_vsx_xxperm v16i8:$XA, v16i8:$XB)); (set v16i8:$XT, (int_ppc_vsx_xxpermr v16i8:$XA, v16i8:$XB)). - Vector Splat Immediate Byte: xxspltib; . Similar to XXSPLTW:; def XXSPLTW : XX2Form_2<60, 164,; (outs vsrc:$XT), (ins vsrc:$XB, u2imm:$UIM),; ""xxspltw $XT, $XB, $UIM"", IIC_VecPerm, []>;. . No SDAG, intrinsic, builtin are required?. - Load/Store Vector: lxv stxv; . Has likely SDAG match:; (set v?:$XT, (load ix16addr:$src)); (set v?:$XT, (store ix16addr:$dst)). . Need define ix16addr in PPCInstrInfo.td; ix16addr: 16-byte aligned, see ""def memrix16"" in PPCInstrInfo.td. - Load/Store Vector Indexed: lxvx stxvx; . Has likely SDAG match:; (set v?:$XT, (load xoaddr:$src)); (set v?:$XT, (store xoaddr:$dst)). - Load/Store DWord: lxsd stxsd; . Similar to lxsdx/stxsdx:; def LXSDX : XX1Form<31, 588,; (outs vsfrc:$XT), (ins memrr:$src),; ""lxsdx $XT, $src"", IIC_LdStLFD,; [(set f64:$XT, (load xoaddr:$src))]>;. . (set f64:$XT, (load iaddrX4:$src)); (set f64:$XT, (store iaddrX4:$dst)). - Load/Store SP, with conversion from/to DP: lxssp stxssp; . Similar to lxsspx/stxsspx:; def LXSSPX : XX1Form<31, 524, (outs vssrc:$XT), (ins memrr:$src),; ""lxsspx $XT, $src"", IIC_LdStLFD,; [(set f32:$XT, (load xoaddr:$src))]>;. . (set f32:$XT, (load iaddrX4:$src)); (set f32:$XT, (store iaddrX4:$dst)). - Load as Integer Byte/Halfword & Zero Indexed: lxsibzx lxsihzx; . Similar to lxsiwzx:; def LXSIWZX : XX1Form<31, 12, (outs vsfrc:$XT), (ins memrr:$src),; ""lxsiwzx $XT, $src"", IIC_LdStLFD,; [(set f64:$XT, (PPClfiwzx xoaddr:$src))]>;. . (set f64:$XT, (PPClfiwzx xoaddr:$src)). - Store as Integer Byte/Halfword Indexed: stxsibx stxsihx; . Similar to stxsiwx:; def STXSIWX : XX1Form<31, 140, (outs), (ins vsfrc:$XT, memrr:$dst),; ""stxsiwx $XT, $dst"", IIC_LdStSTFD,; [(PPCstfiwx f64:$XT, xoaddr:$dst)]>;. . (PPCstfiwx f64:$XT, xoaddr:$dst). - Load Vector Halfword*8/Byte*16 Indexed: lxvh8x lxvb16x; . Similar to lxvd2x/lxvw4x:; def LXVD2X : XX1Form<31, 844,; (out",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt:17885,load,load,17885,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,1,['load'],['load']
Performance,"y as to allow users (that is, people like; you) to easily add missing importers and exporters for existing; `RooFit` classes as well as custom implementations you might be using. ### Native and proxy-based importers and exporters. `RooFitHS3` allows to different types of importers and exporters:; *Native* implementations, and *proxy-based* ones. If for a certain; class several implementations are provided, the native; implementation(s) take precedence. ### Writing your own importers and exporters: Proxy-based. Proxy-based implementations can be added very easily and without; actually writing any `C++` code -- you only need to add a short item; to a list in a `JSON` file, namely the; [export keys](https://github.com/root-project/root/blob/master/etc/RooFitHS3_wsexportkeys.json); for an exporter, or the; [factory expressions](https://github.com/root-project/root/blob/master/etc/RooFitHS3_wsfactoryexpressions.json); for an importer. This works in the following way: Every `RooFit` class performs; dependency tracking via proxies, which have names. This can be; exploited to perform the mapping of proxy names to `json` keys upon; export. In the other direction, the `RooWorkspace` has a factory; interface that allows to call any constructor via a string; interface. Hence:; - If a `RooFit` class has no other members aside from proxies, it can; be exported using a set of `export keys`.; - If all relevant members to a `RooFit` class are passed as; constructor arguments, it can be imported using a `factory; expression`. For the importer, an entry in the; [factory expressions](https://github.com/root-project/root/blob/master/etc/RooFitHS3_wsfactoryexpressions.json); needs to be added as follows:. ``` {.json}; ""<json-key>"": {; ""class"": ""<C++ class name>"",; ""arguments"": [; ""<json-key of constructor argument #1>"",; ""<json-key of constructor argument #2>"",; ...; ]; }; ```. Similarly, for the exporter, an entry in the; [export keys](https://github.com/root-project/root/blob/master/etc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_hs3.md:2971,perform,performs,2971,roofit/doc/developers/roofit_hs3.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_hs3.md,1,['perform'],['performs']
Performance,"y be applied to one; parameter. .. _swiftasync:. ``swiftasync``; This indicates that the parameter is the asynchronous context parameter and; triggers the creation of a target-specific extended frame record to store; this pointer. This is not a valid attribute for return values and can only; be applied to one parameter. ``swifterror``; This attribute is motivated to model and optimize Swift error handling. It; can be applied to a parameter with pointer to pointer type or a; pointer-sized alloca. At the call site, the actual argument that corresponds; to a ``swifterror`` parameter has to come from a ``swifterror`` alloca or; the ``swifterror`` parameter of the caller. A ``swifterror`` value (either; the parameter or the alloca) can only be loaded and stored from, or used as; a ``swifterror`` argument. This is not a valid attribute for return values; and can only be applied to one parameter. These constraints allow the calling convention to optimize access to; ``swifterror`` variables by associating them with a specific register at; call boundaries rather than placing them in memory. Since this does change; the calling convention, a function which uses the ``swifterror`` attribute; on a parameter is not ABI-compatible with one which does not. These constraints also allow LLVM to assume that a ``swifterror`` argument; does not alias any other memory visible within a function and that a; ``swifterror`` alloca passed as an argument does not escape. ``immarg``; This indicates the parameter is required to be an immediate; value. This must be a trivial immediate integer or floating-point; constant. Undef or constant expressions are not valid. This is; only valid on intrinsic declarations and cannot be applied to a; call site or arbitrary function. ``noundef``; This attribute applies to parameters and return values. If the value; representation contains any undefined or poison bits, the behavior is; undefined. Note that this does not refer to padding introduced by the; type'",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:63771,optimiz,optimize,63771,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimize']
Performance,"y buffer passed in RDI (live in). .. code-block:: none. # LLVM-EXEGESIS-LIVEIN RDI; # LLVM-EXEGESIS-DEFREG XMM1 42; vmulps	(%rdi), %xmm1, %xmm2; vhaddps	%xmm2, %xmm2, %xmm3; addq $0x10, %rdi. Example 3: benchmarking with memory annotations; -----------------------------------------------. Some snippets require memory setup in specific places to execute without; crashing. Setting up memory can be accomplished with the `LLVM-EXEGESIS-MEM-DEF`; and `LLVM-EXEGESIS-MEM-MAP` annotations. To execute the following snippet:. .. code-block:: none. movq $8192, %rax; movq (%rax), %rdi. We need to have at least eight bytes of memory allocated starting `0x2000`.; We can create the necessary execution environment with the following; annotations added to the snippet:. .. code-block:: none. # LLVM-EXEGESIS-MEM-DEF test1 4096 7fffffff; # LLVM-EXEGESIS-MEM-MAP test1 8192. movq $8192, %rax; movq (%rax), %rdi. EXAMPLE 4: analysis; -------------------. Assuming you have a set of benchmarked instructions (either latency or uops) as; YAML in file `/tmp/benchmarks.yaml`, you can analyze the results using the; following command:. .. code-block:: bash. $ llvm-exegesis --mode=analysis \; --benchmarks-file=/tmp/benchmarks.yaml \; --analysis-clusters-output-file=/tmp/clusters.csv \; --analysis-inconsistencies-output-file=/tmp/inconsistencies.html. This will group the instructions into clusters with the same performance; characteristics. The clusters will be written out to `/tmp/clusters.csv` in the; following format:. .. code-block:: none. cluster_id,opcode_name,config,sched_class; ...; 2,ADD32ri8_DB,,WriteALU,1.00; 2,ADD32ri_DB,,WriteALU,1.01; 2,ADD32rr,,WriteALU,1.01; 2,ADD32rr_DB,,WriteALU,1.00; 2,ADD32rr_REV,,WriteALU,1.00; 2,ADD64i32,,WriteALU,1.01; 2,ADD64ri32,,WriteALU,1.01; 2,MOVSX64rr32,,BSWAP32r_BSWAP64r_MOVSX64rr32,1.00; 2,VPADDQYrr,,VPADDBYrr_VPADDDYrr_VPADDQYrr_VPADDWYrr_VPSUBBYrr_VPSUBDYrr_VPSUBQYrr_VPSUBWYrr,1.02; 2,VPSUBQYrr,,VPADDBYrr_VPADDDYrr_VPADDQYrr_VPADDWYrr_VPSUBBYrr_VPSU",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:7580,latency,latency,7580,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['latency'],['latency']
Performance,"y calling a helper function; `Instruction::mergeDIAssignID`. **Inlining** stores: As stores are inlined we generate `llvm.dbg.assign`; intrinsics and `DIAssignID` attachments as if the stores represent source; assignments, just like the in frontend. This isn’t perfect, as stores may have; been moved, modified or deleted before inlining, but it does at least keep the; information about the variable correct within the non-inlined scope. **Splitting** stores: SROA and passes that split stores treat `llvm.dbg.assign`; intrinsics similarly to `llvm.dbg.declare` intrinsics. Clone the; `llvm.dbg.assign` intrinsics linked to the store, update the FragmentInfo in; the `ValueExpression`, and give the split stores (and cloned intrinsics) new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:7855,load,loads,7855,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md,1,['load'],['loads']
Performance,"y common collector designs and easy; extension points. If you don't already have a specific binary interface; you need to support, we recommend trying to use one of these built in collector; strategies. .. _gc_intrinsics:. LLVM IR Features; ================. This section describes the garbage collection facilities provided by the; :doc:`LLVM intermediate representation <LangRef>`. The exact behavior of these; IR features is specified by the selected :ref:`GC strategy description; <plugin>`. Specifying GC code generation: ``gc ""...""``; -------------------------------------------. .. code-block:: text. define <returntype> @name(...) gc ""name"" { ... }. The ``gc`` function attribute is used to specify the desired GC strategy to the; compiler. Its programmatic equivalent is the ``setGC`` method of ``Function``. Setting ``gc ""name""`` on a function triggers a search for a matching subclass; of GCStrategy. Some collector strategies are built in. You can add others; using either the loadable plugin mechanism, or by patching your copy of LLVM.; It is the selected GC strategy which defines the exact nature of the code; generated to support GC. If none is found, the compiler will raise an error. Specifying the GC style on a per-function basis allows LLVM to link together; programs that use different garbage collection algorithms (or none at all). .. _gcroot:. Identifying GC roots on the stack; ----------------------------------. LLVM currently supports two different mechanisms for describing references in; compiled code at safepoints. ``llvm.gcroot`` is the older mechanism;; ``gc.statepoint`` has been added more recently. At the moment, you can choose; either implementation (on a per :ref:`GC strategy <plugin>` basis). Longer; term, we will probably either migrate away from ``llvm.gcroot`` entirely, or; substantially merge their implementations. Note that most new development; work is focused on ``gc.statepoint``. Using ``gc.statepoint``; ^^^^^^^^^^^^^^^^^^^^^^^^; :doc:`This pa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:8942,load,loadable,8942,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['load'],['loadable']
Performance,"y constants that followed the respective section name in the; ``MD_pcsections`` metadata. To avoid relocations in the final binary, each PC address stored at ``entry``; is a relative relocation, computed as ``pc - entry``. To decode, a user has to; compute ``entry + *entry``. The size of each entry depends on the code model. With large and medium sized; code models, the entry size matches pointer size. For any smaller code model; the entry size is just 32 bits. Encoding Options; ----------------. Optional encoding options can be passed in the first ``MDString`` operator:; ``<section>!<options>``. The following options are available:. * ``C`` -- Compress constant integers of size 2-8 bytes as ULEB128; this; includes the function size (but excludes the PC entry). For example, ``foo!C`` will emit into section ``foo`` with all constants; encoded as ULEB128. Guarantees on Code Generation; =============================. Attaching ``!pcsections`` metadata to LLVM IR instructions *shall not* affect; optimizations or code generation outside the requested PC sections. While relying on LLVM IR metadata to request PC sections makes the above; guarantee relatively trivial, propagation of metadata through the optimization; and code generation pipeline has the following guarantees. Metadata Propagation; --------------------. In general, LLVM *does not make any guarantees* about preserving IR metadata; (attached to an ``Instruction``) through IR transformations. When using PC; sections metadata, this guarantee is unchanged, and ``!pcsections`` metadata is; remains *optional* until lowering to machine IR (MIR). Note for Code Generation; ------------------------. As with other LLVM IR metadata, there are no requirements for LLVM IR; transformation passes to preserve ``!pcsections`` metadata, with the following; exceptions:. * The ``AtomicExpandPass`` shall preserve ``!pcsections`` metadata; according to the below rules 1-4. When translating LLVM IR to MIR, the ``!pcsections`` metadata",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PCSectionsMetadata.rst:2716,optimiz,optimizations,2716,interpreter/llvm-project/llvm/docs/PCSectionsMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PCSectionsMetadata.rst,1,['optimiz'],['optimizations']
Performance,"y converted into; opaque pointers. This simplifies migration and allows testing existing IR with; opaque pointers. .. code-block:: llvm. define i8* @test(i8* %p) {; %p2 = getelementptr i8, i8* %p, i64 1; ret i8* %p2; }. ; Is automatically converted into the following if -opaque-pointers; ; is enabled:. define ptr @test(ptr %p) {; %p2 = getelementptr i8, ptr %p, i64 1; ret ptr %p2; }. Migration Instructions; ======================. In order to support opaque pointers, two types of changes tend to be necessary.; The first is the removal of all calls to ``PointerType::getElementType()`` and; ``Type::getPointerElementType()``. In the LLVM middle-end and backend, this is usually accomplished by inspecting; the type of relevant operations instead. For example, memory access related; analyses and optimizations should use the types encoded in the load and store; instructions instead of querying the pointer type. Here are some common ways to avoid pointer element type accesses:. * For loads, use ``getType()``.; * For stores, use ``getValueOperand()->getType()``.; * Use ``getLoadStoreType()`` to handle both of the above in one call.; * For getelementptr instructions, use ``getSourceElementType()``.; * For calls, use ``getFunctionType()``.; * For allocas, use ``getAllocatedType()``.; * For globals, use ``getValueType()``.; * For consistency assertions, use; ``PointerType::isOpaqueOrPointeeTypeEquals()``.; * To create a pointer type in a different address space, use; ``PointerType::getWithSamePointeeType()``.; * To check that two pointers have the same element type, use; ``PointerType::hasSameElementTypeAs()``.; * While it is preferred to write code in a way that accepts both typed and; opaque pointers, ``Type::isOpaquePointerTy()`` and; ``PointerType::isOpaque()`` can be used to handle opaque pointers specially.; ``PointerType::getNonOpaquePointerElementType()`` can be used as a marker in; code-paths where opaque pointers have been explicitly excluded.; * To get the type of a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst:6826,load,loads,6826,interpreter/llvm-project/llvm/docs/OpaquePointers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst,1,['load'],['loads']
Performance,"y efficient, it cannot be; extended to the experiments’ software stacks because of its design constraints.; On the contrary, the C++ Modules can be used in third-party code where the PCH; is not available. The comparisons are to give a good metric when we are ready to switch ROOT to use; C++ Modules by default. However, since it is essentially the same technology,; optimizations of C++ Modules also affect the PCH. We have a few tricks up in; the sleeves to but they come with given trade-offs. #### Preloading of C++ Modules. The main focus for the technology preview was not in performance until recently.; We have invested some resources in optimizations and we would like to show you; (probably outdated) performance results:. * Memory footprint -- mostly due to importing all C++ Modules at startup; we see overhead which depends on the number of preloaded modules. For; ROOT it is between 40-60 MB depending on the concrete configuration.; When the workload increases we notice that the overall memory performance; decreases in number of cases.; * Execution times -- likewise we have an execution overhead. For ; workflows which take ms the slowdown can be 2x. Increasing of the work; to seconds shows 50-60% slowdowns. The performance is dependent on many factors such as configuration of ROOT and; workflow. You can read more at our Intel IPCC-ROOT Showcase presentation; here (pp 25-33)[[8]]. #### Loading C++ Modules on Demand. In long term, we should optimize the preloading of modules to be a no-op and; avoid recursive behavior based on identifier lookup callbacks. Unfortunately,; at the moment the loading of C++ modules on demand shows significantly better; performance results. You can visit our continuous performance monitoring tool where we compare; the performance of ROOT against ROOT with a PCH [[9]].; *Note: if you get error 400, clean your cache or open a private browser session.*. ## How to use; C++ Modules in ROOT are default since v6.20 (Unix) and v6.22 (OSX). Enjoy",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:18453,perform,performance,18453,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['perform'],['performance']
Performance,"y first chain does not point to any chain. Every four 4-bytes aligned application bytes share a 4-byte origin trace ID. A; 4-byte origin trace ID contains a 4-bit depth and a 28-bit hash ID of a chain. A chain ID is calculated as a hash from a chain structure. A chain structure; contains a stack ID and the previous chain ID. The chain head has a zero; previous chain ID. A stack ID is a hash from a stack trace. The 4-bit depth; limits the maximal length of a path. The environment variable ``origin_history_size``; can set the depth limit. Non-positive values mean unlimited. Its default value; is 16. When reaching the limit, origin tracking ignores following propagation; chains. The first chain of a trace starts by `dfsan_set_label` with non-zero labels. A; new chain is appended at the end of a trace at stores or memory transfers when; ``-dfsan-track-origins`` is 1. Memory transfers include LLVM memory transfer; instructions, glibc memcpy and memmove. When ``-dfsan-track-origins`` is 2, a; new chain is also appended at loads. Other instructions do not create new chains, but simply propagate origin trace; IDs. If an instruction has more than one operands with non-zero labels, the origin; treace ID of the last operand with non-zero label is propagated to the result of; the instruction. Memory layout and label management; ----------------------------------. The following is the memory layout for Linux/x86\_64:. +---------------+---------------+--------------------+; | Start | End | Use |; +===============+===============+====================+; | 0x700000000000|0x800000000000 | application 3 |; +---------------+---------------+--------------------+; | 0x610000000000|0x700000000000 | unused |; +---------------+---------------+--------------------+; | 0x600000000000|0x610000000000 | origin 1 |; +---------------+---------------+--------------------+; | 0x510000000000|0x600000000000 | application 2 |; +---------------+---------------+--------------------+; | 0x500000000000|0x5",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst:7397,load,loads,7397,interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,1,['load'],['loads']
Performance,"y following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monotonic - workgroup - global 1. buffer/global/flat_load; - generic sc0=1; load atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_load; load atomic monotonic - agent - global 1. buffer/global/flat_load; - generic sc1=1; load atomic monotonic - system - global 1. buffer/global/flat_load; - generic sc0=1 sc1=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic monotonic - workgroup - global 1. buffer/global/flat_store; - generic sc0=1; store atomic monotonic - agent - global 1. buffer/global/flat_store; - generic sc1=1; store atomic monotonic - system - global 1. buffer/global/flat_store; - generic sc0=1 sc1=1; store atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic sc1=1; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; -----------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:294480,load,load,294480,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"y for building; ``` {.cpp}; $ mkdir build; $ cd build; ```. 3. Run cmake and make; ``` {.cpp}; $ cmake ../root; $ make -j8; ```. 4. Setup and run ROOT; ``` {.cpp}; $ source bin/thisroot.sh; $ root; ```. #### Staying up-to-date. To keep your local ROOT source up-to-date with the GitHub repository; you should regularly run the command:. ``` {.cpp}; % git pull; ```. ## File system.rootrc. ROOT Environment settings are handled via the class **`TEnv`**.; `gEnv->Print()`shows which values are active. Any settings can be; obtained by `TEnv::GetValue` methods that return an integer, double or; character value for a named resource. If the resource is not found, the; default value (given as the second parameter) is returned. ``` {.cpp}; fShowEventStatus = gEnv->GetValue(""Canvas.ShowEventStatus"",kFALSE);; ```. Via the method `TEnv::SetValue` allows you can set the value of a; resource or create a new resource:. ``` {.cpp}; gEnv->SetValue(""Root.ObjectStat"",1);; ```. Path used by dynamic loader to find shared libraries and macros. Paths; are different for Unix and Windows. The example shows the defaults for; all ROOT applications for either Unix or Windows:. ``` {.cpp}; Unix.*.Root.DynamicPath: .:$(ROOTSYS)/lib; Unix.*.Root.MacroPath: .:$(ROOTSYS)/macros; WinNT.*.Root.DynamicPath: .;$(ROOTSYS)/bin;$(PATH); WinNT.*.Root.MacroPath: .;$(ROOTSYS)/macros; ```. Path where to look for `TrueType` fonts:. ``` {.cpp}; Unix.*.Root.UseTTFonts: true; *.*.Root.TTFontPath: $(ROOTSYS)/fonts; ```. Use `Net* API` functions:. ``` {.cpp}; WinNT.UseNetAPI: true; ```. Use thread library (if exists). ``` {.cpp}; Unix.*.Root.UseThreads: false; ```. Select the compression algorithm (0=old zlib, 1=new zlib). Setting this; to \`0' may be a security vulnerability. ``` {.cpp}; Root.ZipMode: 1; ```. Show where item is found in the specified path:. ``` {.cpp}; Root.ShowPath: false; ```. Activate memory statistics. ``` {.cpp}; Root.ObjectStat: 0; ```. Global debug mode. When `>0` turns on progressively more det",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InstallandBuild.md:3469,load,loader,3469,documentation/users-guide/InstallandBuild.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InstallandBuild.md,1,['load'],['loader']
Performance,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1327,perform,performs,1327,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,2,['perform'],['performs']
Performance,"y into the object root directory:. .. code-block:: console. % cd OBJ_ROOT. #. Run the ``cmake``:. .. code-block:: console. % cmake -G ""Unix Makefiles"" -DCMAKE_BUILD_TYPE=<type> -DCMAKE_INSTALL_PREFIX=/install/path; [other options] SRC_ROOT. Compiling the LLVM Suite Source Code; ------------------------------------. Unlike with autotools, with CMake your build type is defined at configuration.; If you want to change your build type, you can re-run cmake with the following; invocation:. .. code-block:: console. % cmake -G ""Unix Makefiles"" -DCMAKE_BUILD_TYPE=<type> SRC_ROOT. Between runs, CMake preserves the values set for all options. CMake has the; following build types defined:. Debug. These builds are the default. The build system will compile the tools and; libraries unoptimized, with debugging information, and asserts enabled. Release. For these builds, the build system will compile the tools and libraries; with optimizations enabled and not generate debug info. CMakes default; optimization level is -O3. This can be configured by setting the; ``CMAKE_CXX_FLAGS_RELEASE`` variable on the CMake command line. RelWithDebInfo. These builds are useful when debugging. They generate optimized binaries with; debug information. CMakes default optimization level is -O2. This can be; configured by setting the ``CMAKE_CXX_FLAGS_RELWITHDEBINFO`` variable on the; CMake command line. Once you have LLVM configured, you can build it by entering the *OBJ_ROOT*; directory and issuing the following command:. .. code-block:: console. % make. If the build fails, please `check here`_ to see if you are using a version of; GCC that is known not to compile LLVM. If you have multiple processors in your machine, you may wish to use some of the; parallel build options provided by GNU Make. For example, you could use the; command:. .. code-block:: console. % make -j2. There are several special targets which are useful when working with the LLVM; source code:. ``make clean``. Removes all files ge",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:29177,optimiz,optimization,29177,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['optimiz'],['optimization']
Performance,"y number of 0.0 simultaneously. Currently we only use it for simple; insertions. See comments in LowerINSERT_VECTOR_ELT_SSE4. //===---------------------------------------------------------------------===//. On a random note, SSE2 should declare insert/extract of 2 x f64 as legal, not; Custom. All combinations of insert/extract reg-reg, reg-mem, and mem-reg are; legal, it'll just take a few extra patterns written in the .td file. Note: this is not a code quality issue; the custom lowered code happens to be; right, but we shouldn't have to custom lower anything. This is probably related; to <2 x i64> ops being so bad. //===---------------------------------------------------------------------===//. LLVM currently generates stack realignment code, when it is not necessary; needed. The problem is that we need to know about stack alignment too early,; before RA runs. At that point we don't know, whether there will be vector spill, or not.; Stack realignment logic is overly conservative here, but otherwise we can; produce unaligned loads/stores. Fixing this will require some huge RA changes. Testcase:; #include <emmintrin.h>. typedef short vSInt16 __attribute__ ((__vector_size__ (16)));. static const vSInt16 a = {- 22725, - 12873, - 22725, - 12873, - 22725, - 12873,; - 22725, - 12873};;. vSInt16 madd(vSInt16 b); {; return _mm_madd_epi16(a, b);; }. Generated code (x86-32, linux):; madd:; pushl %ebp; movl %esp, %ebp; andl $-16, %esp; movaps .LCPI1_0, %xmm1; pmaddwd %xmm1, %xmm0; movl %ebp, %esp; popl %ebp; ret. //===---------------------------------------------------------------------===//. Consider:; #include <emmintrin.h> ; __m128 foo2 (float x) {; return _mm_set_ps (0, 0, x, 0);; }. In x86-32 mode, we generate this spiffy code:. _foo2:; 	movss	4(%esp), %xmm0; 	pshufd	$81, %xmm0, %xmm0; 	ret. in x86-64 mode, we generate this code, which could be better:. _foo2:; 	xorps	%xmm1, %xmm1; 	movss	%xmm0, %xmm1; 	pshufd	$81, %xmm1, %xmm0; 	ret. In sse4 mode, we could use insertps t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:15175,load,loads,15175,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,1,['load'],['loads']
Performance,"y objects in the current module. In particular, linking; code into a module with a private global value may cause the; private to be renamed as necessary to avoid collisions. Because the; symbol is private to the module, all references can be updated. This; doesn't show up in any symbol table in the object file.; ``internal``; Similar to private, but the value shows as a local symbol; (``STB_LOCAL`` in the case of ELF) in the object file. This; corresponds to the notion of the '``static``' keyword in C.; ``available_externally``; Globals with ""``available_externally``"" linkage are never emitted into; the object file corresponding to the LLVM module. From the linker's; perspective, an ``available_externally`` global is equivalent to; an external declaration. They exist to allow inlining and other; optimizations to take place given knowledge of the definition of the; global, which is known to be somewhere outside the module. Globals; with ``available_externally`` linkage are allowed to be discarded at; will, and allow inlining and other optimizations. This linkage type is; only allowed on definitions, not declarations.; ``linkonce``; Globals with ""``linkonce``"" linkage are merged with other globals of; the same name when linkage occurs. This can be used to implement; some forms of inline functions, templates, or other code which must; be generated in each translation unit that uses it, but where the; body may be overridden with a more definitive definition later.; Unreferenced ``linkonce`` globals are allowed to be discarded. Note; that ``linkonce`` linkage does not actually allow the optimizer to; inline the body of this function into callers because it doesn't; know if this definition of the function is the definitive definition; within the program or whether it will be overridden by a stronger; definition. To enable inlining and other optimizations, use; ""``linkonce_odr``"" linkage.; ``weak``; ""``weak``"" linkage has the same merging semantics as ``linkonce``; linkage",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:8502,optimiz,optimizations,8502,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"y of the descriptor.; It can display individual entries (`RNTupleReader::Show()`) and summary information (`RNTupleReader::PrintInfo()`). ### RNTupleView<T>; RNTuple views provide read access to individual fields.; Views are created from an RNTupleReader.; Views are templated; for simple types (e.g., `float`, `int`), views provide read-only access directly to an RNTuple page in memory.; Complex types and void views require additional memory copies to populate an object in memory from the column data. A view can iterate over the entry range, over the field range, and over the range of a collection within an entry.; For instance, for a field `std::vector<float> pt`, a view can iterate over all `pt` values of all entries, or over the `pt` values of a particular entry. A view can safely outlive its originating reader.; Once the reader is deconstructed, any attempt to read data will throw an exception, but the view is still properly destructed. Views that originate from the same reader _cannot_ be used concurrently by different threads. Internal Classes; ----------------. ### RNTupleDS; The `RNTupleDS` class is an internal class that provides an RNTuple data source for RDataFrame.; It is part of the `ROOTDataFrame` library.; The RNTuple data source supports chains with a constructor that takes a list of input files.; The RNTuple data source also supports multi-threaded dataframes, parallelized on the file and cluster level. The data source exposes inner fields of complex collections.; For instance, if the data model contains a vector of `Event` classes, where each `Event` has `pt` and `eta` floats,; the dataframe can use the event vector itself (`Event` column) as well as the `float` columns `Event.pt` and `Event.eta`. ### RClusterPool; The RClusterPool is an internal class owned be a page source.; The cluster pool maintains an I/O thread that asynchronously prefetches the next few clusters.; Through `RPageSource::SetEntryRange()`, the cluster pool is instructed to not r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:14346,concurren,concurrently,14346,tree/ntuple/v7/doc/Architecture.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md,1,['concurren'],['concurrently']
Performance,"y reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To ensure coherence of local memory reads of CUs in different agents a; ``buffer_inv sc0 sc1`` is required. It will invalidate non-local L2 cache; lines if configured to have multiple L2 caches. * PCIe access from the GPU to the CPU can be kept coherent by using the MTYPE; UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:290176,cache,caches,290176,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance,"y specifier ranging from (0) - no; locality, to (3) - extremely local keep in cache. The ``cache type``; specifies whether the prefetch is performed on the data (1) or; instruction (0) cache. The ``rw``, ``locality`` and ``cache type``; arguments must be constant integers. Semantics:; """""""""""""""""""". This intrinsic does not modify the behavior of the program. In; particular, prefetches cannot trap and do not produce a value. On; targets that support this intrinsic, the prefetch can provide hints to; the processor cache for better performance. '``llvm.pcmarker``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.pcmarker(i32 <id>). Overview:; """""""""""""""""". The '``llvm.pcmarker``' intrinsic is a method to export a Program; Counter (PC) in a region of code to simulators and other tools. The; method is target specific, but it is expected that the marker will use; exported symbols to transmit the PC of the marker. The marker makes no; guarantees that it will remain with any specific instruction after; optimizations. It is possible that the presence of a marker will inhibit; optimizations. The intended use is to be inserted after optimizations to; allow correlations of simulation runs. Arguments:; """""""""""""""""""". ``id`` is a numerical id identifying the marker. Semantics:; """""""""""""""""""". This intrinsic does not modify the behavior of the program. Backends; that do not support this intrinsic may ignore it. '``llvm.readcyclecounter``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i64 @llvm.readcyclecounter(). Overview:; """""""""""""""""". The '``llvm.readcyclecounter``' intrinsic provides access to the cycle; counter register (or similar low latency, high accuracy clocks) on those; targets that support it. On X86, it should map to RDTSC. On Alpha, it; should map to RPCC. As the backing counters overflow quickly (on the; order of 9 seconds on alpha), this should only be used for small; timings. Semantics:; """""""""""""""""""". When directl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:524535,optimiz,optimizations,524535,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"y the dynamic; > compiler?. B. This is kind of similar to another idea that I have: make OOP; constructs (virtual function tables, class heirarchies, etc) explicit; in the VM representation. I believe that the number of additional; constructs would be fairly low, but would give us lots of important; information... something else that would/could be important is to; have exceptions as first class types so that they would be handled in; a uniform way for the entire VM... so that C functions can call Java; functions for example... > c. How do we get more high-level information into the VM while keeping; > to a low-level VM design?; > o Explicit array references as operands? An alternative is; > to have just an array type, and let the index computations be; > separate 3-operand instructions. C. In the model I was thinking of (subject to change of course), we; would just have an array type (distinct from the pointer; types). This would allow us to have arbitrarily complex index; expressions, while still distinguishing ""load"" from ""Array load"",; for example. Perhaps also, switch jump tables would be first class; types as well? This would allow better reasoning about the program. 5. Support dynamic loading of code from various sources. Already; mentioned above was the example of loading java bytecodes, but we want; to support dynamic loading of VM code as well. This makes the job of; the runtime compiler much more interesting: it can do interprocedural; optimizations that the static compiler can't do, because it doesn't; have all of the required information (for example, inlining from; shared libraries, etc...). 6. Define a set of generally useful annotations to add to the VM; representation. For example, a function can be analysed to see if it; has any sideeffects when run... also, the MOD/REF sets could be; calculated, etc... we would have to determine what is reasonable. This; would generally be used to make IP optimizations cheaper for the; runtime compiler... > o Expli",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:5401,load,load,5401,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,2,['load'],['load']
Performance,"y the front end into a simple standalone program that; you can execute, debug, and see results. First we make our anonymous function that contains our top level; statement be our ""main"":. .. code-block:: udiff. - auto Proto = std::make_unique<PrototypeAST>("""", std::vector<std::string>());; + auto Proto = std::make_unique<PrototypeAST>(""main"", std::vector<std::string>());. just with the simple change of giving it a name. Then we're going to remove the command line code wherever it exists:. .. code-block:: udiff. @@ -1129,7 +1129,6 @@ static void HandleTopLevelExpression() {; /// top ::= definition | external | expression | ';'; static void MainLoop() {; while (true) {; - fprintf(stderr, ""ready> "");; switch (CurTok) {; case tok_eof:; return;; @@ -1184,7 +1183,6 @@ int main() {; BinopPrecedence['*'] = 40; // highest. // Prime the first token.; - fprintf(stderr, ""ready> "");; getNextToken();. Lastly we're going to disable all of the optimization passes and the JIT so; that the only thing that happens after we're done parsing and generating; code is that the LLVM IR goes to standard error:. .. code-block:: udiff. @@ -1108,17 +1108,8 @@ static void HandleExtern() {; static void HandleTopLevelExpression() {; // Evaluate a top-level expression into an anonymous function.; if (auto FnAST = ParseTopLevelExpr()) {; - if (auto *FnIR = FnAST->codegen()) {; - // We're just doing this to make sure it executes.; - TheExecutionEngine->finalizeObject();; - // JIT the function, returning a function pointer.; - void *FPtr = TheExecutionEngine->getPointerToFunction(FnIR);; -; - // Cast it to the right type (takes no arguments, returns a double) so we; - // can call it as a native function.; - double (*FP)() = (double (*)())(intptr_t)FPtr;; - // Ignore the return value for this.; - (void)FP;; + if (!FnAST->codegen()) {; + fprintf(stderr, ""Error generating code for top level expr"");; }; } else {; // Skip token for error recovery.; @@ -1439,11 +1459,11 @@ int main() {; // target lays out dat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst:3665,optimiz,optimization,3665,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,1,['optimiz'],['optimization']
Performance,"y to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extracted functions. .. image:: block-extract.png. The command to do the extraction is:. .. code-block:: shell. ./bin/llvm-extract -o - -S -b ‘foo:bb1;bb4’ <input> > extracted.ll. This particular example extracts two basic blocks from a function named ``foo``.; The new LLVM-IR can then be modified to add the ``failedISel`` attribute to the; extracted function containing bb4 to make that function use SelectionDAG. This can prevent some optimizations as GlobalISel ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:4892,perform,perform,4892,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,1,['perform'],['perform']
Performance,"y, double z) {...}`, `clad::differentiate(f, ""z"")`; is equivalent to `clad::differentiate(f, 2)`. `clad::gradient(f, ""x, y"")`; differentiates with respect to `x` and `y` but not `z`. The gradient results; are stored in a `_result` parameter in the same order as `x` and `y` were; specified. Namely, the result of `x` is stored in `_result[0]` and the result; of `y` in `_result[1]`. If we invert the arguments specified in the string to; `clad::gradient(f, ""y, x"")` the results will be stored inversely.; * Enable recursive differentiation.; * Support single- and multi-dimensional arrays -- works for arrays with constant; size like `double A[] = {1, 2, 3};`, `double A[3];` or `double A[1][2][3][4];`. ## RooFit Libraries; ### RooJohnson PDF; The Johnson SU PDF has been added to RooFit. It comes with an analytical integral and a generator function,; which make it superior (faster and more accurate) than implementing it manually with an interpreted/compiled formula. ### HistFactory; hist2workspace performance optimisations. For a large, ATLAS-style Higgs-->bb workspace with > 100 systematic uncertainties and more than 10 channels, the run time for converting histograms to a fit model decreases by a factor 11 to 12. ### Faster, STL-like Collections in RooFit; RooFit's collections `RooArgSet` and `RooArgList` have been made more STL-like. The underlying implementation used to be the `RooLinkedList`, but now both collections work with `std::vector`. The collections have an STL-like interface concerning iterators such that iterations over the two collections that looked like; ```; TIterator* depIter = intDepList.createIterator() ;; RooAbsArg* arg;; while((arg=(RooAbsArg*)depIter->Next())) {; ...; }; delete depIter;; ```; now look like:; ```; for (auto arg : intDepList) {; ...; }; ```; Depending on how many elements are iterated, RooFit will be between 10 and 20% faster if the new iterators are used. Heavily using old iterators might slow it down by 5 to 10%. Iterators in key clas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:14554,perform,performance,14554,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['perform'],['performance']
Performance,"y. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected typ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:7602,tune,tuned,7602,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,2,"['perform', 'tune']","['performance', 'tuned']"
Performance,"y:. .. code-block:: bash. bugpoint [bugpoint args] --tool-args -- [tool args]. The ""``--``"" right after the **--tool-args** option tells **bugpoint** to; consider any options starting with ""``-``"" to be part of the **--tool-args**; option, not as options to **bugpoint** itself. (See **--args**, above.). **--safe-tool-args** *tool args*. Pass all arguments specified after **--safe-tool-args** to the ""safe"" execution; tool. **--gcc-tool-args** *gcc tool args*. Pass all arguments specified after **--gcc-tool-args** to the invocation of; **gcc**. **--opt-args** *opt args*. Pass all arguments specified after **--opt-args** to the invocation of **opt**. **--disable-{dce,simplifycfg}**. Do not run the specified passes to clean up and reduce the size of the test; program. By default, **bugpoint** uses these passes internally when attempting to; reduce test programs. If you're trying to find a bug in one of these passes,; **bugpoint** may crash. **--enable-valgrind**. Use valgrind to find faults in the optimization phase. This will allow; bugpoint to find otherwise asymptomatic problems caused by memory; mis-management. **-find-bugs**. Continually randomize the specified passes and run them on the test program; until a bug is found or the user kills **bugpoint**. **-help**. Print a summary of command line options. **--input** *filename*. Open *filename* and redirect the standard input of the test program, whenever; it runs, to come from that file. **--load** *plugin*. Load the dynamic object *plugin* into **bugpoint** itself. This object should; register new optimization passes. Once loaded, the object will add new command; line options to enable various optimizations. To see the new complete list of; optimizations, use the **-help** and **--load** options together; for example:. .. code-block:: bash. bugpoint --load myNewPass.so -help. **--mlimit** *megabytes*. Specifies an upper limit on memory usage of the optimization and codegen. Set; to zero to disable the limit. **--ou",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst:2838,optimiz,optimization,2838,interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,1,['optimiz'],['optimization']
Performance,"y; ...; >>> print(""Total lennard jones potential ="", potential_numba_scalar(cppyy.gbl.atoms)); Total lennard jones potential = -0.5780277345740283. Overhead; --------. The main overhead of JITing Numba traces is in the type annotation in Numba; itself, optimization of the IR and assembly by the backend less so.; (There is also a non-negligible cost to Numba initialization, which is why; ``cppyy`` does not provide automatic extension hooks.); The use of ``cppyy`` bound C++, which relies on the same Numba machinery,; does not change that, since the reflection-based lookups are in C++ and; comparatively very fast.; For example, there is no appreciable difference in wall clock time to JIT a; trace using Numba's included math functions (from module ``math`` or; ``numpy``) or one that uses C++ bound ones whether from the standard library; or a templated versions from e.g. Eigen.; Use of very complex template expressions may change this balance, but in; principle, wherever it makes sense in the first place to use Numba JITing, it; is also fine, performance-wise, to use ``cppyy`` bound C++ inside the trace. A second important overhead is in unboxing Python proxies of C++ objects,; in particular when passed as an argument to a Numba-JITed function.; The main costs are in the lookup (types are matched at every invocation) and; to a lesser extent the subsequent copying of the instance data.; Thus, functions that take a C++ object as an argument will require more time; spent in the function body for JITing to be worth it than functions that do; not. The current implementation invokes C++ callables through function pointers; and accesses data through offsets calculations from the object's base; address.; A future implementation may be able to inline C++ into the Numba trace if; code is available in headers files or was JITed. Further Information; -------------------. - Numba documentation:; `numba.readthedocs.io <https://numba.readthedocs.io/en/stable/user/index.html>`_. - ""Using",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:10140,perform,performance-wise,10140,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,1,['perform'],['performance-wise']
Performance,"y; please take a look at; the `latest version of PrintFunctionNames.cpp; <https://github.com/llvm/llvm-project/blob/main/clang/examples/PrintFunctionNames/PrintFunctionNames.cpp>`_. Running the plugin; ==================. Using the compiler driver; --------------------------. The Clang driver accepts the `-fplugin` option to load a plugin.; Clang plugins can receive arguments from the compiler driver command; line via the `fplugin-arg-<plugin name>-<argument>` option. Using this; method, the plugin name cannot contain dashes itself, but the argument; passed to the plugin can. .. code-block:: console. $ export BD=/path/to/build/directory; $ make -C $BD CallSuperAttr; $ clang++ -fplugin=$BD/lib/CallSuperAttr.so \; -fplugin-arg-call_super_plugin-help \; test.cpp. If your plugin name contains dashes, either rename the plugin or used the; cc1 command line options listed below. Using the cc1 command line; --------------------------. To run a plugin, the dynamic library containing the plugin registry must be; loaded via the `-load` command line option. This will load all plugins; that are registered, and you can select the plugins to run by specifying the; `-plugin` option. Additional parameters for the plugins can be passed with; `-plugin-arg-<plugin-name>`. Note that those options must reach clang's cc1 process. There are two; ways to do so:. * Directly call the parsing process by using the `-cc1` option; this; has the downside of not configuring the default header search paths, so; you'll need to specify the full system path configuration on the command; line.; * Use clang as usual, but prefix all arguments to the cc1 process with; `-Xclang`. For example, to run the ``print-function-names`` plugin over a source file in; clang, first build the plugin, and then call clang with the plugin from the; source tree:. .. code-block:: console. $ export BD=/path/to/build/directory; $ (cd $BD && make PrintFunctionNames ); $ clang++ -D_GNU_SOURCE -D_DEBUG -D__STDC_CONSTANT_MACROS \; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst:5243,load,loaded,5243,interpreter/llvm-project/clang/docs/ClangPlugins.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst,2,['load'],"['load', 'loaded']"
Performance,yModule.cpp; clang-tools-extra/clang-tidy/openmp/UseDefaultNoneCheck.cpp; clang-tools-extra/clang-tidy/openmp/UseDefaultNoneCheck.h; clang-tools-extra/clang-tidy/performance/FasterStringFindCheck.cpp; clang-tools-extra/clang-tidy/performance/ForRangeCopyCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.h; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.h; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.cpp; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.h; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.cpp; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.h; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.cpp; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.h; clang-tools-extra/clang-tidy/performance/PerformanceTidyModule.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.h; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.cpp; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.h; clang-tools-extra/clang-tidy/performance/UnnecessaryCopyInitialization.cpp; clang-tools-extra/clang-tidy/performance/UnnecessaryValueParamCheck.cpp; clang-tools-extra/clang-tidy/performance/UnnecessaryValueParamCheck.h; clang-tools-extra/clang-tidy/plugin/ClangTidyPlugin.cpp; clang-tools-extra/clang-tidy/portability/PortabilityTidyModule.cpp; clang-tools-extra/clang-tidy/portability/RestrictSystemIncludes,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:65539,perform,performance,65539,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['perform'],['performance']
Performance,"y_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:9071,queue,queue,9071,interpreter/llvm-project/llvm/docs/XRay.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst,1,['queue'],['queue']
Performance,"ybridResult::CLsplusbError() or HybridResult::CLsError().; A new tutorial has been added for showing the usage of the hybrid calculator: rs505_HybridCalculator_significance.C. new class HypoTestInverter. New class for performing an hypothesis test inversion by scanning; the hypothesis test results of the HybridCalculator for; various values of the parameter of interest. An upper (or lower) limit can be derived by looking at the; confidence level curve of the result as function of the parameter of; interest, where it intersects the desired confidence level. The class implements the IntervalCalculator interface and returns an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find optimally the curve and it will stop when the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method returns a SimpleInterval which contains the lower and upper value of the bayesian interval obtained from the posterior probability for the given confidence level.; The class return also the posterior ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:15319,perform,perform,15319,roofit/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html,1,['perform'],['perform']
Performance,"ynamic.area.offset <int_get_dynamic_area_offset>`; must match the target's default address space's (address space 0) pointer type. '``llvm.prefetch``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.prefetch(ptr <address>, i32 <rw>, i32 <locality>, i32 <cache type>). Overview:; """""""""""""""""". The '``llvm.prefetch``' intrinsic is a hint to the code generator to; insert a prefetch instruction if supported; otherwise, it is a noop.; Prefetches have no effect on the behavior of the program but can change; its performance characteristics. Arguments:; """""""""""""""""""". ``address`` is the address to be prefetched, ``rw`` is the specifier; determining if the fetch should be for a read (0) or write (1), and; ``locality`` is a temporal locality specifier ranging from (0) - no; locality, to (3) - extremely local keep in cache. The ``cache type``; specifies whether the prefetch is performed on the data (1) or; instruction (0) cache. The ``rw``, ``locality`` and ``cache type``; arguments must be constant integers. Semantics:; """""""""""""""""""". This intrinsic does not modify the behavior of the program. In; particular, prefetches cannot trap and do not produce a value. On; targets that support this intrinsic, the prefetch can provide hints to; the processor cache for better performance. '``llvm.pcmarker``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.pcmarker(i32 <id>). Overview:; """""""""""""""""". The '``llvm.pcmarker``' intrinsic is a method to export a Program; Counter (PC) in a region of code to simulators and other tools. The; method is target specific, but it is expected that the marker will use; exported symbols to transmit the PC of the marker. The marker makes no; guarantees that it will remain with any specific instruction after; optimizations. It is possible that the presence of a marker will inhibit; optimizations. The intended use is to be inserted after optimizations to; allow correlations of simulation runs. Argumen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:523720,cache,cache,523720,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['cache'],['cache']
Performance,"you think; you need a patched build, please ask for advice on llvm-dev. There may be an; easy way we can extend the support to make it work for your use case without; requiring a custom build. Collector Requirements; ----------------------. You should be able to leverage any existing collector library that includes the following elements:. #. A memory allocator which exposes an allocation function your compiled; code can call. #. A binary format for the stack map. A stack map describes the location; of references at a safepoint and is used by precise collectors to identify; references within a stack frame on the machine stack. Note that collectors; which conservatively scan the stack don't require such a structure. #. A stack crawler to discover functions on the call stack, and enumerate the; references listed in the stack map for each call site. #. A mechanism for identifying references in global locations (e.g. global; variables). #. If you collector requires them, an LLVM IR implementation of your collectors; load and store barriers. Note that since many collectors don't require; barriers at all, LLVM defaults to lowering such barriers to normal loads; and stores unless you arrange otherwise. Implementing a collector plugin; -------------------------------. User code specifies which GC code generation to use with the ``gc`` function; attribute or, equivalently, with the ``setGC`` method of ``Function``. To implement a GC plugin, it is necessary to subclass ``llvm::GCStrategy``,; which can be accomplished in a few lines of boilerplate code. LLVM's; infrastructure provides access to several important algorithms. For an; uncontroversial collector, all that remains may be to compile LLVM's computed; stack map to assembly code (using the binary representation expected by the; runtime library). This can be accomplished in about 100 lines of code. This is not the appropriate place to implement a garbage collected heap or a; garbage collector itself. That code should exis",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:23171,load,load,23171,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['load'],['load']
Performance,"ype of load with the other type of load plus a ``REV`` instruction. So we're not deciding which instructions to use, but which format to use (which will then influence which instruction is best to use). .. The 'clearer' container is required to make the following section header come after the floated; images above.; .. container:: clearer. Note that throughout this section we only mention loads. Stores have exactly the same problems as their associated loads, so have been skipped for brevity. Considerations; ==============. LLVM IR Lane ordering; ---------------------. LLVM IR has first class vector types. In LLVM IR, the zero'th element of a vector resides at the lowest memory address. The optimizer relies on this property in certain areas, for example when concatenating vectors together. The intention is for arrays and vectors to have identical memory layouts - ``[4 x i8]`` and ``<4 x i8>`` should be represented the same in memory. Without this property there would be many special cases that the optimizer would have to cleverly handle. Use of ``LDR`` would break this lane ordering property. This doesn't preclude the use of ``LDR``, but we would have to do one of two things:. 1. Insert a ``REV`` instruction to reverse the lane order after every ``LDR``.; 2. Disable all optimizations that rely on lane layout, and for every access to an individual lane (``insertelement``/``extractelement``/``shufflevector``) reverse the lane index. AAPCS; -----. The ARM procedure call standard (AAPCS) defines the ABI for passing vectors between functions in registers. It states:. When a short vector is transferred between registers and memory it is treated as an opaque object. That is a short vector is stored in memory as if it were stored with a single ``STR`` of the entire register; a short vector is loaded from memory using the corresponding ``LDR`` instruction. On a little-endian system this means that element 0 will always contain the lowest addressed element of a short vector; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:5082,optimiz,optimizer,5082,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,1,['optimiz'],['optimizer']
Performance,"ypes; > Right now, I've spec'd out the language to have a pointer type, which; > works fine for lots of stuff... except that Java really has; > references: constrained pointers that cannot be manipulated: added and; > subtracted, moved, etc... Do we want to have a type like this? It; > could be very nice for analysis (pointer always points to the start of; > an object, etc...) and more closely matches Java semantics. The; > pointer type would be kept for C++ like semantics. Through analysis,; > C++ pointers could be promoted to references in the LLVM; > representation. You're right, having references would be useful. Even for C++ the *static*; compiler could generate references instead of pointers with fairly; straightforward analysis. Let's include a reference type for now. But I'm; also really concerned that LLVM is becoming big and complex and (perhaps); too high-level. After we get some initial performance results, we may have; a clearer idea of what our goals should be and we should revisit this; question then. > 2. Our ""implicit"" memory references in assembly language:; > After thinking about it, this model has two problems:; > A. If you do pointer analysis and realize that two stores are; > independent and can share the same memory source object,. not sure what you meant by ""share the same memory source object"". > there is; > no way to represent this in either the bytecode or assembly.; > B. When parsing assembly/bytecode, we effectively have to do a full; > SSA generation/PHI node insertion pass to build the dependencies; > when we don't want the ""pinned"" representation. This is not; > cool. I understand the concern. But again, let's focus on the performance first; and then look at the language design issues. E.g., it would be good to know; how big the bytecode files are before expanding them further. I am pretty; keen to explore the implications of LLVM for mobile devices. Both bytecode; size and power consumption are important to consider there. --Vikram. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-13-Reference-MemoryResponse.txt:1848,perform,performance,1848,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-13-Reference-MemoryResponse.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-13-Reference-MemoryResponse.txt,1,['perform'],['performance']
Performance,"yright 2000 Free Software Foundation, Inc.; GDB is free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show warranty"" for details.; This GDB was configured as ""sparc-sun-solaris2.6""...; (gdb). Note that :program:`opt` has a lot of debugging information in it, so it takes; time to load. Be patient. Since we cannot set a breakpoint in our pass yet; (the shared object isn't loaded until runtime), we must execute the process,; and have it stop before it invokes our pass, but after it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`` method you are now; free to set breakpoints in your pass so that you can trace through execution or; do other standard debugging stuff. Miscellaneous Problems; ^^^^^^^^^^^^^^^^^^^^^^. Once you have the basics down, there are a couple of problems that GDB has,; some with solutions, some without. * Inline functions have bogus stack information. In general, GDB does a pretty; good job getting stack traces and stepping through inline functions. When a; pass is dynamically loaded however, it somehow completely loses this; capability. The only solution I know of is to de-inline a function (move it; from the body of a class to a ``.cpp`` file). * Restart",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:53707,load,load,53707,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['load'],['load']
Performance,"ysis results may be invalid.; PreservedAnalyses PA;; PA.preserve<DominatorAnalysis>();; return PA;. // We haven't made any control flow changes, any analyses that only care about the control flow are still valid.; PreservedAnalyses PA;; PA.preserveSet<CFGAnalyses>();; return PA;. The pass manager will call the analysis manager's ``invalidate()`` method; with the pass's returned ``PreservedAnalyses``. This can be also done; manually within the pass:. .. code-block:: c++. FooModulePass::run(Module& M, ModuleAnalysisManager& AM) {; auto &FAM = AM.getResult<FunctionAnalysisManagerModuleProxy>(M).getManager();. // Invalidate all analysis results for function F1.; FAM.invalidate(F1, PreservedAnalyses::none());. // Invalidate all analysis results across the entire module.; AM.invalidate(M, PreservedAnalyses::none());. // Clear the entry in the analysis manager for function F2 if we've completely removed it from the module.; FAM.clear(F2);. ...; }. One thing to note when accessing inner level IR analyses is cached results for; deleted IR. If a function is deleted in a module pass, its address is still used; as the key for cached analyses. Take care in the pass to either clear the; results for that function or not use inner analyses at all. ``AM.invalidate(M, PreservedAnalyses::none());`` will invalidate the inner; analysis manager proxy which will clear all cached analyses, conservatively; assuming that there are invalid addresses used as keys for cached analyses.; However, if you'd like to be more selective about which analyses are; cached/invalidated, you can mark the analysis manager proxy as preserved,; essentially saying that all deleted entries have been taken care of manually.; This should only be done with measurable compile time gains as it can be tricky; to make sure all the right analyses are invalidated. Implementing Analysis Invalidation; ==================================. By default, an analysis is invalidated if ``PreservedAnalyses`` says that; analyses on t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:14081,cache,cached,14081,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['cache'],['cached']
Performance,"ysis`). NOTE: Although the discussion below focuses on `-Rpass`, the exact; same options apply to `-Rpass-missed` and `-Rpass-analysis`. Since there are dozens of passes inside the compiler, each of these flags; take a regular expression that identifies the name of the pass which should; emit the associated diagnostic. For example, to get a report from the inliner,; compile the code with:. .. code-block:: console. $ clang -O2 -Rpass=inline code.cc -o code; code.cc:4:25: remark: foo inlined into bar [-Rpass=inline]; int bar(int j) { return foo(j, j - 2); }; ^. Note that remarks from the inliner are identified with `[-Rpass=inline]`.; To request a report from every optimization pass, you should use; `-Rpass=.*` (in fact, you can use any valid POSIX regular; expression). However, do not expect a report from every transformation; made by the compiler. Optimization remarks do not really make sense; outside of the major transformations (e.g., inlining, vectorization,; loop optimizations) and not every optimization pass supports this; feature. Note that when using profile-guided optimization information, profile hotness; information can be included in the remarks (see; :ref:`-fdiagnostics-show-hotness <opt_fdiagnostics-show-hotness>`). Current limitations; ^^^^^^^^^^^^^^^^^^^. 1. Optimization remarks that refer to function names will display the; mangled name of the function. Since these remarks are emitted by the; back end of the compiler, it does not know anything about the input; language, nor its mangling rules. 2. Some source locations are not displayed correctly. The front end has; a more detailed source location tracking than the locations included; in the debug info (e.g., the front end can locate code inside macro; expansions). However, the locations used by `-Rpass` are; translated from debug annotations. That translation can be lossy,; which results in some remarks having no location information. Options to Emit Resource Consumption Reports; ---------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:25151,optimiz,optimizations,25151,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,['optimiz'],"['optimization', 'optimizations']"
Performance,"ysis`` interface to delete calls to functions that do not have; side-effects and are not used. The ``-licm`` pass; ^^^^^^^^^^^^^^^^^^. The ``-licm`` pass implements various Loop Invariant Code Motion related; transformations. It uses the ``AliasAnalysis`` interface for several different; transformations:. * It uses mod/ref information to hoist or sink load instructions out of loops if; there are no instructions in the loop that modifies the memory loaded. * It uses mod/ref information to hoist function calls out of loops that do not; write to memory and are loop-invariant. * It uses alias information to promote memory objects that are loaded and stored; to in loops to live in a register instead. It can do this if there are no may; aliases to the loaded/stored memory location. The ``-argpromotion`` pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``-argpromotion`` pass promotes by-reference arguments to be passed in; by-value instead. In particular, if pointer arguments are only loaded from it; passes in the value loaded instead of the address to the function. This pass; uses alias information to make sure that the value loaded from the argument; pointer is not modified between the entry of the function and any load of the; pointer. The ``-gvn``, ``-memcpyopt``, and ``-dse`` passes; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These passes use AliasAnalysis information to reason about loads and stores. .. _the clients:. Clients for debugging and evaluation of implementations; -------------------------------------------------------. These passes are useful for evaluating the various alias analysis; implementations. You can use them with commands like:. .. code-block:: bash. % opt -ds-aa -aa-eval foo.bc -disable-output -stats. The ``-print-alias-sets`` pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``-print-alias-sets`` pass is exposed as part of the ``opt`` tool to print; out the Alias Sets formed by the `AliasSetTracker`_ class. This is useful if; you're using the ``AliasSetTr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:28400,load,loaded,28400,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,2,['load'],['loaded']
Performance,"yte aligned for the ``amdgcn`` architecture. .. note::. The ``amdgcn`` value is selected to avoid dynamic stack alignment for the; OpenCL language which has the largest base type defined as 16 bytes. On entry, the swizzled SP value is the address of the first function; argument passed on the stack. Other stack passed arguments are positive; offsets from the entry swizzled SP value. The function may use positive offsets beyond the last stack passed argument; for stack allocated local variables and register spill slots. If necessary,; the function may align these to greater alignment than 16 bytes. After these; the function may dynamically allocate space for such things as runtime sized; ``alloca`` local allocations. If the function calls another function, it will place any stack allocated; arguments after the last local allocation and adjust SGPR32 to the address; after the last local allocation. 9. All other registers are unspecified.; 10. Any necessary ``s_waitcnt`` has been performed to ensure memory is available; to the function.; 11. Use pass-by-reference (byref) in stead of pass-by-value (byval) for struct; arguments in C ABI. Callee is responsible for allocating stack memory and; copying the value of the struct if modified. Note that the backend still; supports byval for struct arguments. On exit from a function:. 1. VGPR0-31 and SGPR4-29 are used to pass function result arguments as; described below. Any registers used are considered clobbered registers.; 2. The following registers are preserved and have the same value as on entry:. * FLAT_SCRATCH; * EXEC; * GFX6-GFX8: M0; * All SGPR registers except the clobbered registers of SGPR4-31.; * VGPR40-47; * VGPR56-63; * VGPR72-79; * VGPR88-95; * VGPR104-111; * VGPR120-127; * VGPR136-143; * VGPR152-159; * VGPR168-175; * VGPR184-191; * VGPR200-207; * VGPR216-223; * VGPR232-239; * VGPR248-255. .. note::. Except the argument registers, the VGPRs clobbered and the preserved; registers are intermixed at regular intervals",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:389881,perform,performed,389881,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performed']
Performance,"yy package, but the built-in module takes; precedence.; To use cppyy, first import a compatibility module::. $ pypy; [PyPy 5.8.0 with GCC 5.4.0] on linux2; >>>> import cppyy_compat, cppyy; >>>>. You may have to set ``LD_LIBRARY_PATH`` appropriately if you get an; ``EnvironmentError`` (it will indicate the needed directory). Note that your python interpreter (whether CPython or ``pypy-c``) may not have; been linked by the C++ compiler.; This can lead to problems during loading of C++ libraries and program shutdown.; In that case, re-linking is highly recommended. Very old versions of PyPy (5.6.0 and earlier) have a built-in ``cppyy`` based; on `Reflex`_, which is less feature-rich and no longer supported.; However, both the :doc:`distribution utilities <utilities>` and user-facing; Python codes are very backwards compatible, making migration straightforward. Precompiled header; ------------------. For performance reasons (reduced memory and CPU usage), a precompiled header; (PCH) of the system and compiler header files will be installed or, failing; that, generated on startup.; Obviously, this PCH is not portable and should not be part of any wheel. Some compiler features, such as AVX, OpenMP, fast math, etc. need to be; active during compilation of the PCH, as they depend both on compiler flags; and system headers (for intrinsics, or API calls).; You can control compiler flags through the ``EXTRA_CLING_ARGS`` envar and thus; what is active in the PCH.; In principle, you can also change the C++ language standard by setting the; appropriate flag on ``EXTRA_CLING_ARGS`` and rebuilding the PCH.; However, if done at this stage, that disables some automatic conversion for; C++ types that were introduced after C++11 (such as ``string_view`` and; ``optional``). If you want multiple PCHs living side-by-side, you can generate them; yourself (note that the given path must be absolute)::. >>> import cppyy_backend.loader as l; >>> l.set_cling_compile_options(True) # adds defaults",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:7520,perform,performance,7520,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,1,['perform'],['performance']
Performance,"z, Double_t weight); ~~~. - `iel:` index of the element` [0,nel-1]`; - `a` and `z:` the atomic mass and charge; - `weight:` proportion by mass of the elements; - `natoms`: number of atoms of the element in the molecule making the; mixture. The radiation length is automatically computed when all elements are; defined. Since tracking MC provide several other ways to create; materials/mixtures, the materials classes are likely to evolve as the; interfaces to these engines are being developed. Generally in the; process of tracking material properties are not enough and more specific; media properties have to be defined. These highly depend on the MC; performing tracking and sometimes allow the definition of different; media properties (e.g. energy or range cuts) for the same material. \anchor GM00b; ### Radionuclides. A new class TGeoElementRN was introduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (TGeoElementTable class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ~~~. One can make materials or mixtures from radionuclides:. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""C14"", c14, 2.0);; ~~~. The following properties of radionuclides can be currently accessed via; getters in the TGeoElementRN class:. Atomic number and charge (from the base class TGeoElement). - Isomeric number (`ISO`); - ENDF code - following the convention: `ENDF=10000*Z+100*A+ISO`; - Isomeric energy le",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:5108,load,loaded,5108,geom/geom/doc/materials.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md,1,['load'],['loaded']
Performance,"zation managed by our JIT will allow us to optimize lazily too, rather; than having to do all our optimization up-front. To add optimization support to our JIT we will take the KaleidoscopeJIT from; Chapter 1 and compose an ORC *IRTransformLayer* on top. We will look at how the; IRTransformLayer works in more detail below, but the interface is simple: the; constructor for this layer takes a reference to the execution session and the; layer below (as all layers do) plus an *IR optimization function* that it will; apply to each Module that is added via addModule:. .. code-block:: c++. class KaleidoscopeJIT {; private:; ExecutionSession ES;; RTDyldObjectLinkingLayer ObjectLayer;; IRCompileLayer CompileLayer;; IRTransformLayer TransformLayer;. DataLayout DL;; MangleAndInterner Mangle;; ThreadSafeContext Ctx;. public:. KaleidoscopeJIT(JITTargetMachineBuilder JTMB, DataLayout DL); : ObjectLayer(ES,; []() { return std::make_unique<SectionMemoryManager>(); }),; CompileLayer(ES, ObjectLayer, ConcurrentIRCompiler(std::move(JTMB))),; TransformLayer(ES, CompileLayer, optimizeModule),; DL(std::move(DL)), Mangle(ES, this->DL),; Ctx(std::make_unique<LLVMContext>()) {; ES.getMainJITDylib().addGenerator(; cantFail(DynamicLibrarySearchGenerator::GetForCurrentProcess(DL.getGlobalPrefix())));; }. Our extended KaleidoscopeJIT class starts out the same as it did in Chapter 1,; but after the CompileLayer we introduce a new member, TransformLayer, which sits; on top of our CompileLayer. We initialize our OptimizeLayer with a reference to; the ExecutionSession and output layer (standard practice for layers), along with; a *transform function*. For our transform function we supply our classes; optimizeModule static method. .. code-block:: c++. // ...; return cantFail(OptimizeLayer.addModule(std::move(M),; std::move(Resolver)));; // ... Next we need to update our addModule method to replace the call to; ``CompileLayer::add`` with a call to ``OptimizeLayer::add`` instead. .. code-block:: c++. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:3431,optimiz,optimizeModule,3431,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,1,['optimiz'],['optimizeModule']
Performance,"zation routines.; These can be run on PDFs and datasets before starting a fit.; They search the calculation graph for parts that are independent of the fit parameters, precalculates them, and adds them to (a clone of) the dataset so that these values can be used during calculation. In `RooFit::TestStatistics`, we separated this functionality out into the `ConstantTermsOptimizer` class.; In fact, it is not so much a class, as it is a collection of static functions that can be applied to any combination of pdf and dataset.; This class does essentially the same as `constOptimizeTestStatistic` did on a `RooNLLVar`, except that it has been factored out into a separate class. ### Usage example: apply constant term optimization on pdf and dataset inside a likelihood; Applying the default `ConstantTermsOptimizer` optimization routines on the pdf and dataset inside a `RooAbsL` likelihood is as simple as:. ``` {.cpp}; likelihood.constOptimizeTestStatistic();; ```; This applies constant term optimization to the cloned pdf and dataset inside the likelihood object.; It will not modify anything outside of the likelihood. Optimization can also be activated through the minimizer, which may be more familiar to most users.; Given the `RooMinimizer` object `m` as defined in the example above, we can do:; ``` {.cpp}; m.optimizeConst(2);; ```. For the adventurous user, it is also possible to apply constant term optimization to a pdf and dataset directly without needing a likelihood object, e.g. given some `RooArgSet` set of observables `normSet`:; ``` {.cpp}; bool applyTrackingOpt = true;; ConstantTermsOptimizer::enableConstantTermsOptimization(&pdf, &normSet, dataset, applyTrackingOpt);; ```; We refer to RooFit documentation for more about ""tracking optimization"" which can be enabled or disabled using the final boolean parameter. ## Caveats; This package is still under development.; Some functionality that users of `RooAbsPdf::fitTo` or `RooAbsPdf::createNLL` were used to has not yet be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/test_statistics.md:10598,optimiz,optimization,10598,roofit/doc/developers/test_statistics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/test_statistics.md,1,['optimiz'],['optimization']
Performance,"zations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing concurrently. See; ``DW_AT_LLVM_iterations`` in :ref:`amdgpu-dwarf-low-level-information`. 2.20 DWARF Operation to Create Runtime Overlay Composite Location Description; -----------------------------------------------------------------------------. It is common in SIMD vectorization for the compiler to generate code that; promotes portions of an array into vector registers. For example, if the; hardware has vector registers with 8 elements, and 8 wide SIMD instructions, the; compiler may vectorize a loop so that is executes 8 iterations concurrently for; each vectorized loop iteration. On the first iteration of the generated vectorized loop, iterations 0 to 7 of; the source language loop will be executed using SIMD instructions. Then on the; next iteration of the generated vectorized loop, iteration 8 to 15 will be; executed, and so on. If the source language loop accesses an array element based on the loop; iteration index, the compi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:34690,concurren,concurrently,34690,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['concurren'],['concurrently']
Performance,"ze the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extracted functions. .. image:: block-extract.png. The command to do the extraction is:. .. code-block:: shell. ./bin/llvm-extract -o - -S -b ‘foo:bb1;bb4’ <input> > extracted.ll. This particular example extracts two basic blocks from a function named ``foo``.; The new LLVM-IR can then be modified to add the ``failedISel`` attribute to the; extracted function containing bb4 to make that function use SelectionDAG. This can prevent some optimizations as GlobalISel is generally able to work on a; single function at a time. This technique can be repeated for different; combinations of basic blocks until you have identified the critical blocks; involved in a bug. Once the critical blocks have been identified, you can further increase the; resolution to the critical instructions by splitting the blocks like from:. .. code-block:: none. bb1:; ..",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:5325,perform,performance,5325,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,1,['perform'],['performance']
Performance,"ze_thread`` or; ``sanitize_address`` attributes. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present. An omitted ``align`` argument means that the operation has the; ABI alignment for the target. The optional ``!nontemporal`` metadata must reference a single; metadata name ``<nontemp_node>`` corresponding to a metadata node with one; ``i32`` entry of value 1. The existence of the ``!nontemporal``; metadata on the instruction tells the optimizer and code generator; that this load is not expected to be reused in the cache. The code; generator may select special instructions to save cache bandwidth, such; as the ``MOVNT`` instruction on x86. The optional ``!invariant.load`` metadata must reference a single; metadata name ``<empty_node>`` corresponding to a metadata node with no; entries. If a load instruction tagged with the ``!invariant.load``; metadata is executed, the memory location referenced by the load has; to contain the same value at all points in the program where the; memory location is dereferenceable; otherwise, the behavior is; undefined. The optional ``!invariant.group`` metadata must reference a single metadata name; ``<empty_node>`` corresponding to a metadata node with no entries.; See ``invariant.group`` metadata :ref:`invariant.group <md_invariant.group>`. The optional ``!nonnull`` metadata must reference a single; metadata name ``<empty_node>`` corresponding to a metadata node with no; entries. The existence of the ``!nonnull`` metadata on the; instruction tells the optimizer that the value loaded is known to; never be null. If the value is null at runtime, a poison value is returned; instead. This is analogous to the ``nonnull`` attribute on parameters and; return values. This metadata can only be applied to loads of a pointer type. The optional ``!dereferenceable`` metadata must reference a single metadata; name ``<deref_bytes_node>`` corresponding to a metadata node with one ``i64``; entry.; See ``dere",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:415496,load,load,415496,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['load'],['load']
Performance,"ze`.; Higher values lead to more accurate measurements but lengthen the benchmark. .. option:: --loop-body-size=<Preferred loop body size>. Only effective for `-repetition-mode=[loop|min]`.; Instead of looping over the snippet directly, first duplicate it so that the; loop body contains at least this many instructions. This potentially results; in loop body being cached in the CPU Op Cache / Loop Cache, which allows to; which may have higher throughput than the CPU decoders. .. option:: --max-configs-per-opcode=<value>. Specify the maximum configurations that can be generated for each opcode.; By default this is `1`, meaning that we assume that a single measurement is; enough to characterize an opcode. This might not be true of all instructions:; for example, the performance characteristics of the LEA instruction on X86; depends on the value of assigned registers and immediates. Setting a value of; `-max-configs-per-opcode` larger than `1` allows `llvm-exegesis` to explore; more configurations to discover if some register or immediate assignments; lead to different performance characteristics. .. option:: --benchmarks-file=</path/to/file>. File to read (`analysis` mode) or write (`latency`/`uops`/`inverse_throughput`; modes) benchmark results. ""-"" uses stdin/stdout. .. option:: --analysis-clusters-output-file=</path/to/file>. If provided, write the analysis clusters as CSV to this file. ""-"" prints to; stdout. By default, this analysis is not run. .. option:: --analysis-inconsistencies-output-file=</path/to/file>. If non-empty, write inconsistencies found during analysis to this file. `-`; prints to stdout. By default, this analysis is not run. .. option:: --analysis-filter=[all|reg-only|mem-only]. By default, all benchmark results are analysed, but sometimes it may be useful; to only look at those that to not involve memory, or vice versa. This option; allows to either keep all benchmarks, or filter out (ignore) either all the; ones that do involve memory (involve in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:14441,perform,performance,14441,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['perform'],['performance']
Performance,"zero status. When this option is enabled, :program:`lit` will also automatically provide a; ""``valgrind``"" feature that can be used to conditionally disable (or expect; failure in) certain tests. .. option:: --vg-arg=ARG. When :option:`--vg` is used, specify an additional argument to pass to; :program:`valgrind` itself. .. option:: --vg-leak. When :option:`--vg` is used, enable memory leak checks. When this option is; enabled, :program:`lit` will also automatically provide a ""``vg_leak``""; feature that can be used to conditionally disable (or expect failure in); certain tests. .. option:: --time-tests. Track the wall time individual tests take to execute and includes the results; in the summary output. This is useful for determining which tests in a test; suite take the most time to execute. .. option:: --ignore-fail. Exit with status zero even if some tests fail. .. _selection-options:. SELECTION OPTIONS; -----------------. By default, `lit` will run failing tests first, then run tests in descending; execution time order to optimize concurrency. The execution order can be; changed using the :option:`--order` option. The timing data is stored in the `test_exec_root` in a file named; `.lit_test_times.txt`. If this file does not exist, then `lit` checks the; `test_source_root` for the file to optionally accelerate clean builds. .. option:: --shuffle. Run the tests in a random order, not failing/slowest first. Deprecated,; use :option:`--order` instead. .. option:: --per-test-coverage. Emit the necessary test coverage data, divided per test case (involves; setting a unique value to LLVM_PROFILE_FILE for each RUN). The coverage; data files will be emitted in the directory specified by `config.test_exec_root`. .. option:: --max-failures N. Stop execution after the given number ``N`` of failures.; An integer argument should be passed on the command line; prior to execution. .. option:: --max-tests=N. Run at most ``N`` tests and then terminate. .. option:: --max-time=N. Sp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:5472,optimiz,optimize,5472,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,2,"['concurren', 'optimiz']","['concurrency', 'optimize']"
Performance,"zero. Examples; """""""""""""""""". .. code-block:: llvm. %res = call i4 @llvm.sdiv.fix.i4(i4 6, i4 2, i32 0) ; %res = 3 (6 / 2 = 3); %res = call i4 @llvm.sdiv.fix.i4(i4 6, i4 4, i32 1) ; %res = 3 (3 / 2 = 1.5); %res = call i4 @llvm.sdiv.fix.i4(i4 3, i4 -2, i32 1) ; %res = -3 (1.5 / -1 = -1.5). ; The result in the following could be rounded up to 1 or down to 0.5; %res = call i4 @llvm.sdiv.fix.i4(i4 3, i4 4, i32 1) ; %res = 2 (or 1) (1.5 / 2 = 0.75). '``llvm.udiv.fix.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.udiv.fix``; on any integer bit width or vectors of integers. ::. declare i16 @llvm.udiv.fix.i16(i16 %a, i16 %b, i32 %scale); declare i32 @llvm.udiv.fix.i32(i32 %a, i32 %b, i32 %scale); declare i64 @llvm.udiv.fix.i64(i64 %a, i64 %b, i32 %scale); declare <4 x i32> @llvm.udiv.fix.v4i32(<4 x i32> %a, <4 x i32> %b, i32 %scale). Overview; """""""""""""""""". The '``llvm.udiv.fix``' family of intrinsic functions perform unsigned; fixed point division on 2 arguments of the same scale. Arguments; """""""""""""""""""". The arguments (%a and %b) and the result may be of integer types of any bit; width, but they must have the same bit width. The arguments may also work with; int vectors of the same length and int size. ``%a`` and ``%b`` are the two; values that will undergo unsigned fixed point division. The argument; ``%scale`` represents the scale of both operands, and must be a constant; integer. Semantics:; """""""""""""""""""". This operation performs fixed point division on the 2 arguments of a; specified scale. The result will also be returned in the same scale specified; in the third argument. If the result value cannot be precisely represented in the given scale, the; value is rounded up or down to the closest representable value. The rounding; direction is unspecified. It is undefined behavior if the result value does not fit within the range of; the fixed point type, or if the second argument is zero. Examples; """""""""""""""""". ..",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:632410,perform,perform,632410,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"zzer accepts flags after `ignore_remaining_args=1`. The flags match; those of :doc:`llc <CommandGuide/llc>` and the triple is required. For example,; the following command would fuzz AArch64 with :doc:`GlobalISel/index`:. .. code-block:: shell. % bin/llvm-isel-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple aarch64 -global-isel -O0. Some flags can also be specified in the binary name itself in order to support; OSS Fuzz, which has trouble with required arguments. To do this, you can copy; or move ``llvm-isel-fuzzer`` to ``llvm-isel-fuzzer--x-y-z``, separating options; from the binary name using ""--"". The valid options are architecture names; (``aarch64``, ``x86_64``), optimization levels (``O0``, ``O2``), or specific; keywords, like ``gisel`` for enabling global instruction selection. In this; mode, the same example could be run like so:. .. code-block:: shell. % bin/llvm-isel-fuzzer--aarch64-O0-gisel <corpus-dir>. llvm-opt-fuzzer; ---------------. A |LLVM IR fuzzer| aimed at finding bugs in optimization passes. It receives optimization pipeline and runs it for each fuzzer input. Interface of this fuzzer almost directly mirrors ``llvm-isel-fuzzer``. Both; ``mtriple`` and ``passes`` arguments are required. Passes are specified in a; format suitable for the new pass manager. You can find some documentation about; this format in the doxygen for ``PassBuilder::parsePassPipeline``. .. code-block:: shell. % bin/llvm-opt-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple x86_64 -passes instcombine. Similarly to the ``llvm-isel-fuzzer`` arguments in some predefined configurations; might be embedded directly into the binary file name:. .. code-block:: shell. % bin/llvm-opt-fuzzer--x86_64-instcombine <corpus-dir>. llvm-mc-assemble-fuzzer; -----------------------. A |generic fuzzer| that fuzzes the MC layer's assemblers by treating inputs as; target specific assembly. Note that this fuzzer has an unusual command line interface which is not fully; compatible with all of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:3386,optimiz,optimization,3386,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,1,['optimiz'],['optimization']
Performance,"{.cpp}; TLorentzRotation a,b,c;; c = b*a; // product; c = a.MatrixMultiplication(b); // a is unchanged; a *= b; // a=a*b; c = a.Transform(b) // a=b*a then c=a; ```. Lorentz boosts:. ``` {.cpp}; Double_t bx, by, bz;; TVector3 v(bx,by,bz);; TLorentzRotation l;; l.Boost(v);; l.Boost(bx,by,bz);; ```. Rotations:. ``` {.cpp}; TVector3 axis;; l.RotateX(TMath::Pi()); // rotation around x-axis; l.Rotate(.5,axis); // rotation around specified vector; ```. Inverse transformation: use the method `Inverse() `to return the inverse; transformation keeping the current one unchanged`.` The method; `Invert()` inverts the current **`TLorentzRotation`**:. ``` {.cpp}; l1 = l2.Inverse(); // l1 is inverse of l2, l2 unchanged; l1 = l2.Invert(); // invert l2, then l1=l2; ```. The matrix for the inverse transformation of a **`TLorentzRotation`** is; as follows:. $$; \left|; \begin{array}{cccc}; xx & xy & xz & -tx \\; yx & yy & yz & -ty \\; zx & zy & zz & -tz \\; -xt & -yt & -zt & tt; \end{array}; \right|; $$. ### Transformation of a TLorentzVector. To apply **`TLorentzRotation`** to **`TLorentzVector`** you can use; either the `VectorMultiplication()` method or the `* operator`. You can; also use the `Transform()` function and the `*= `operator of the class; **`TLorentzVector`**. ``` {.cpp}; TLorentzVector v;; TLorentzRotation l;; ...; v = l.VectorMultiplication(v);; v = l * v;; v.Transform(l);; v *= l; // v = l*v; ```. ### Physics Vector Example. The test file `$ROOTSYS/test/TestVectors.cxx is` an example of using; physics vectors. The vector classes are not loaded by default, and to; run it, you will need to load `libPhysics.so` first:. ``` {.cpp}; root[] .L $ROOTSYS/lib/libPhysics.so; root[] .x TestVectors.cxx; ```. To load the physics vector library in a ROOT application use:. ``` {.cpp}; gSystem->Load(""libPhysics"");; ```. The example `$ROOTSYS/test/TestVectors.cxx` does not return much,; especially if all went well, but when you look at the code you will find; examples for many calls.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md:18221,load,loaded,18221,documentation/users-guide/PhysicsVectors.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md,3,['load'],"['load', 'loaded']"
Performance,"{; // ... code; }; // C++11 attribute; [[clang::optnone]] int bar() {; // ... code; }. To facilitate disabling optimization for a range of function definitions, a; range-based pragma is provided. Its syntax is ``#pragma clang optimize``; followed by ``off`` or ``on``. All function definitions in the region between an ``off`` and the following; ``on`` will be decorated with the ``optnone`` attribute unless doing so would; conflict with explicit attributes already present on the function (e.g. the; ones that control inlining). .. code-block:: c++. #pragma clang optimize off; // This function will be decorated with optnone.; int foo() {; // ... code; }. // optnone conflicts with always_inline, so bar() will not be decorated.; __attribute__((always_inline)) int bar() {; // ... code; }; #pragma clang optimize on. If no ``on`` is found to close an ``off`` region, the end of the region is the; end of the compilation unit. Note that a stray ``#pragma clang optimize on`` does not selectively enable; additional optimizations when compiling at low optimization levels. This feature; can only be used to selectively disable optimizations. The pragma has an effect on functions only at the point of their definition; for; function templates, this means that the state of the pragma at the point of an; instantiation is not necessarily relevant. Consider the following example:. .. code-block:: c++. template<typename T> T twice(T t) {; return 2 * t;; }. #pragma clang optimize off; template<typename T> T thrice(T t) {; return 3 * t;; }. int container(int a, int b) {; return twice(a) + thrice(b);; }; #pragma clang optimize on. In this example, the definition of the template function ``twice`` is outside; the pragma region, whereas the definition of ``thrice`` is inside the region.; The ``container`` function is also in the region and will not be optimized, but; it causes the instantiation of ``twice`` and ``thrice`` with an ``int`` type; of; these two instantiations, ``twice`` will be opti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:159874,optimiz,optimize,159874,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,3,['optimiz'],"['optimization', 'optimizations', 'optimize']"
Performance,"{i=1}^{N}; \frac{y_i-f(i,a^{(t)})}{y_i}; \frac{\partial f(i,a^t)}{\partial a_k}=; \sum_{j=1}^{M}\sum_{i=1}^{N}; \frac{\partial f(i,a^{(t)})}{\partial a_j}; \frac{\partial f(i,a^{(t)})}{\partial a_k}; \Delta a_j^{(t)} $$. - in gamma-ray spectra we have to fit together tens, hundreds of peaks; simultaneously that sometimes represent thousands of parameters. - the calculation of the inversion matrix of such a size is; practically impossible. - the awmi method is based on the assumption that the off-diagonal; terms in the matrix A are equal to zero. $$; \Delta a_{k}^{(t+1)} = \alpha^{(t)}; \frac{; \sum_{i=1}^{N} \frac{e_{i}^{(t)}}{y_i}\frac{\partial f(i,a^{(t)})}{\partial a_k}; }{; \sum_{i=1}^{N} \left[ \frac{\partial f(i,a^{(t)})}{\partial a_k}\right]^2\frac{1}{y_i}; }; $$. where the error in the channel `i` is $e_{i}^{(t)} = y_i-f(i,a^{(t)}); k=1,2,...,M$ and; $\alpha^{(t)}=1$ if the process is convergent or $\alpha^{(t)}=0.5 \alpha^{(t-1)}$; if it is divergent. Another possibility is to optimize this coefficient. The error of `k`-th parameter estimate is. $$; \Delta a_k^{(e)}=; \sqrt{\frac; {\sum_{i=1}^{N}\frac{e_i^2}{y_i}}; {\sum_{i=1}^{N} \left[ \frac{\partial f(i,a^{(t)})}{\partial a_k}\right]^2\frac{1}{y_i}}; }; $$. Algorithm with higher powers `w=1,2,3...`:. $$; \Delta a_{k,w}^{(t+1)}=; \alpha^{(t)}; \frac; {\sum_{i=1}^{N} \frac{e_i}{y_i}\left[ \frac{\partial f(i,a^{(t)})}{\partial a_k}\right]^{2w-1}}; {\sum_{i=1}^{N} \left[ \frac{\partial f(i,a^{(t)})}{\partial a_k}\right]^{2w}\frac{1}{y_i}}; $$. We have implemented the non-symmetrical semi-empirical peak shape function. It contains the symmetrical Gaussian as well as non-symmetrical terms:. $$; f(i,a) =; \sum_{i=1}^{M} A(j); \left\{; exp\left[\frac{-(i-p(j))^2}{2\sigma^2}\right]; +\frac{1}{2}T.exp\left[\frac{(i-p(j))}{B\sigma}\right]; .erfc\left[\frac{(i-p(j))}{\sigma}+\frac{1}{2B}\right]; +\frac{1}{2}S.erfc\left[\frac{(i-p(j))}{\sigma}\right]; \right\}; $$. where `T, S` are relative amplitudes and `B` is a slo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:39602,optimiz,optimize,39602,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['optimiz'],['optimize']
Performance,"| Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and max. ![Microbenchmark result visualization](speculative_load_hardening_microbenchmarks.png). We don't yet have benchmark data on SPEC or the LLVM test suite, but we can; work on getting that. Still, the above should give a pretty clear; characterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine granularity such as on a per-function basis,; including intelligent handling of inlining decisions -- protected code can be; prevented from inlining into unprotected code, and unprotected code will become; protected when inlined into protected code. For systems where only a limited; set of code is reachable by externally controlled inputs, it may be possible to; limit the scope of mitigation through such mechanisms without compromising the; application's overall security. The performance impact may also be focused in a; few key functions",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:48720,perform,performance,48720,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['perform'],['performance']
Performance,"| count 3; ; This should produce one 'or' or 'cror' instruction per function. ; RUN: llvm-as < %s | llc -march=ppc32 | grep mfcr | count 3; ; PR2964. define i32 @test(double %x, double %y) nounwind {; entry:; 	%tmp3 = fcmp ole double %x, %y		; <i1> [#uses=1]; 	%tmp345 = zext i1 %tmp3 to i32		; <i32> [#uses=1]; 	ret i32 %tmp345; }. define i32 @test2(double %x, double %y) nounwind {; entry:; 	%tmp3 = fcmp one double %x, %y		; <i1> [#uses=1]; 	%tmp345 = zext i1 %tmp3 to i32		; <i32> [#uses=1]; 	ret i32 %tmp345; }. define i32 @test3(double %x, double %y) nounwind {; entry:; 	%tmp3 = fcmp ugt double %x, %y		; <i1> [#uses=1]; 	%tmp34 = zext i1 %tmp3 to i32		; <i32> [#uses=1]; 	ret i32 %tmp34; }. //===---------------------------------------------------------------------===//; for the following code:. void foo (float *__restrict__ a, int *__restrict__ b, int n) {; a[n] = b[n] * 2.321;; }. we load b[n] to GPR, then move it VSX register and convert it float. We should ; use vsx scalar integer load instructions to avoid direct moves. //===----------------------------------------------------------------------===//; ; RUN: llvm-as < %s | llc -march=ppc32 | not grep fneg. ; This could generate FSEL with appropriate flags (FSEL is not IEEE-safe, and ; ; should not be generated except with -enable-finite-only-fp-math or the like).; ; With the correctness fixes for PR642 (58871) LowerSELECT_CC would need to; ; recognize a more elaborate tree than a simple SETxx. define double @test_FNEG_sel(double %A, double %B, double %C) {; %D = fsub double -0.000000e+00, %A ; <double> [#uses=1]; %Cond = fcmp ugt double %D, -0.000000e+00 ; <i1> [#uses=1]; %E = select i1 %Cond, double %B, double %C ; <double> [#uses=1]; ret double %E; }. //===----------------------------------------------------------------------===//; The save/restore sequence for CR in prolog/epilog is terrible:; - Each CR subreg is saved individually, rather than doing one save as a unit.; - On Darwin, the save is done after the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt:12286,load,load,12286,interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,1,['load'],['load']
Performance,"}=${VALUE}` (e.g.; `SCUDO_OPTIONS=GWP_ASAN_SampleRate=100`). Options defined this way will; override any definition made through ``__gwp_asan_default_options``. The options string follows a syntax similar to ASan, where distinct options; can be assigned in the same string, separated by colons. For example, using the environment variable:. .. code:: console. GWP_ASAN_OPTIONS=""MaxSimultaneousAllocations=16:SampleRate=5000"" ./a.out. Or using the function:. .. code:: cpp. extern ""C"" const char *__gwp_asan_default_options() {; return ""MaxSimultaneousAllocations=16:SampleRate=5000"";; }. The following options are available:. +----------------------------+---------+--------------------------------------------------------------------------------+; | Option | Default | Description |; +----------------------------+---------+--------------------------------------------------------------------------------+; | Enabled | true | Is GWP-ASan enabled? |; +----------------------------+---------+--------------------------------------------------------------------------------+; | PerfectlyRightAlign | false | When allocations are right-aligned, should we perfectly align them up to the |; | | | page boundary? By default (false), we round up allocation size to the nearest |; | | | power of two (2, 4, 8, 16) up to a maximum of 16-byte alignment for |; | | | performance reasons. Setting this to true can find single byte |; | | | buffer-overflows at the cost of performance, and may be incompatible with |; | | | some architectures. |; +----------------------------+---------+--------------------------------------------------------------------------------+; | MaxSimultaneousAllocations | 16 | Number of simultaneously-guarded allocations available in the pool. |; +----------------------------+---------+--------------------------------------------------------------------------------+; | SampleRate | 5000 | The probability (1 / SampleRate) that a page is selected for GWP-ASan |; | | | sampling. Sam",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:7580,perform,performance,7580,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['perform'],['performance']
Performance,"}][f61]. ## Toy Monte Carlo Experiments ##. Let us look at a simple example of a toy experiment comparing two; methods to fit a function to a histogram, the $\chi^{2}$. method and a method called ""binned log-likelihood fit"", both available in ROOT. As a very simple yet powerful quantity to check the quality of the fit; results, we construct for each pseudo-data set the so-called ""pull"", the; difference of the estimated and the true value of a parameter,; normalised to the estimated error on the parameter,; $\frac{(p_{estim} - p_{true})}{\sigma_{p}}$. If everything is OK, the; distribution of the pull values is a standard normal distribution, i.e.; a Gaussian distribution centred around zero with a standard deviation of one. The macro performs a rather big number of toy experiments, where a; histogram is repeatedly filled with Gaussian distributed numbers,; representing the pseudo-data in this example. Each time, a fit is; performed according to the selected method, and the pull is calculated; and filled into a histogram. Here is the code:. ``` {.cpp .numberLines}; @ROOT_INCLUDE_FILE macros/macro9.C; ```. Your present knowledge of ROOT should be enough to understand all the; technicalities behind the macro. Note that the variable `pull` in line; *61* is different from the definition above: instead of the parameter; error on `mean`, the fitted standard deviation of the distribution; divided by the square root of the number of entries,; `sig/sqrt(n_tot_entries)`, is used. - What method exhibits the better performance with the default; parameters ?. - What happens if you increase the number of entries per histogram by; a factor of ten ? Why ?. The answers to these questions are well beyond the scope of this guide.; Basically all books about statistical methods provide a complete; treatment of the aforementioned topics. [^5]: ""Monte Carlo"" simulation means that random numbers play a role here; which is as crucial as in games of pure chance in the Casino of Monte Carlo.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/functions_and_parameter_estimation.md:5532,perform,performance,5532,documentation/primer/functions_and_parameter_estimation.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/functions_and_parameter_estimation.md,1,['perform'],['performance']
Performance,"     ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the end of the query, a set of workers are promoted; submergers and assigned a sub-set of workers to merge. Once each; sub-merger has merged its sub-set of workers, it sends its result to; the master, which merges the partial results into the final; set of results.; The determination of the sub-mergers is always done dynamically, based; on the recent performance of workers. An optimal (i.e. giving the; highest speed-up) number can be calculated analytically under simple; assumptions.; Merging via submergers is by default disabled. To enable it, with the; optimal number of sub-mergers, one should set the integer parameter; 'PROOF_UseMergers' to 0, i.e.                     ; proof->SetParameter(""PROOF_UseMergers"", 0). To force S sub-mergers (regardless of the optimal number) do.                     ; proof->SetParameter(""PROOF_UseMergers"", S). The new functionality can be tested in tutorials by adding the argument; 'submergers' to runProof, e.g. .        ;        ;      root [0] .L; tutorials/proof/runProof.C+ ;        ;        ;      root [1]; runProof(""simple(nhist=10000,submergers)"") . (see the top of tutorials/proof/runProof.C for additional options). A test for the submerger functionality has also been added to; test/stressProof.cxx .; In PROOF-Lite, add the possibility for the administrator; to c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:2349,perform,performance,2349,proof/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html,1,['perform'],['performance']
Safety," ""C""`` and reports them as ``CXCursor_LinkageSpec``.; - Changed the libclang library on AIX to export only the necessary symbols to; prevent issues of resolving to the wrong duplicate symbol. Static Analyzer; ---------------. New features; ^^^^^^^^^^^^. - Implemented the ``[[clang::suppress]]`` attribute for suppressing diagnostics; of static analysis tools, such as the Clang Static Analyzer.; `Documentation <https://clang.llvm.org/docs/AttributeReference.html#suppress>`__. - Support ""Deducing this"" (P0847R7). (Worked out of the box); (`af4751738db8 <https://github.com/llvm/llvm-project/commit/af4751738db89a142a8880c782d12d4201b222a8>`__). - Added a new checker ``core.BitwiseShift`` which reports situations where; bitwise shift operators produce undefined behavior (because some operand is; negative or too large).; `Documentation <https://clang.llvm.org/docs/analyzer/checkers.html#core-bitwiseshift-c-c>`__. - Added a new experimental checker ``alpha.core.StdVariant`` to detect variant; accesses via wrong alternatives.; `Documentation <https://clang.llvm.org/docs/analyzer/checkers.html#alpha-core-stdvariant-c>`__.; (`#66481 <https://github.com/llvm/llvm-project/pull/66481>`_). - Added a new experimental checker ``alpha.cplusplus.ArrayDelete`` to detect; destructions of arrays of polymorphic objects that are destructed as their; base class (`CERT EXP51-CPP <https://wiki.sei.cmu.edu/confluence/display/cplusplus/EXP51-CPP.+Do+not+delete+an+array+through+a+pointer+of+the+incorrect+type>`_).; `Documentation <https://clang.llvm.org/docs/analyzer/checkers.html#alpha-cplusplus-arraydelete-c>`__.; (`0e246bb67573 <https://github.com/llvm/llvm-project/commit/0e246bb67573799409d0085b89902a330998ddcc>`_). - Added a new checker configuration option ``InvalidatingGetEnv=[true,false]`` to; ``security.cert.env.InvalidPtr``. It's not set by default.; If set, ``getenv`` calls won't invalidate previously returned pointers.; `Documentation <https://clang.llvm.org/docs/analyzer/checkers.ht",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:69691,detect,detect,69691,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['detect'],['detect']
Safety," ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:47047,abort,abort,47047,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['abort'],['abort']
Safety," #endif. __wchar_t WideCharacter;; ... Include File Checking Macros; ============================. Not all developments systems have the same include files. The; :ref:`langext-__has_include` and :ref:`langext-__has_include_next` macros allow; you to check for the existence of an include file before doing a possibly; failing ``#include`` directive. Include file checking macros must be used; as expressions in ``#if`` or ``#elif`` preprocessing directives. .. _langext-__has_include:. ``__has_include``; -----------------. This function-like macro takes a single file name string argument that is the; name of an include file. It evaluates to 1 if the file can be found using the; include paths, or 0 otherwise:. .. code-block:: c++. // Note the two possible file name string formats.; #if __has_include(""myinclude.h"") && __has_include(<stdint.h>); # include ""myinclude.h""; #endif. To test for this feature, use ``#if defined(__has_include)``:. .. code-block:: c++. // To avoid problem with non-clang compilers not having this macro.; #if defined(__has_include); #if __has_include(""myinclude.h""); # include ""myinclude.h""; #endif; #endif. .. _langext-__has_include_next:. ``__has_include_next``; ----------------------. This function-like macro takes a single file name string argument that is the; name of an include file. It is like ``__has_include`` except that it looks for; the second instance of the given file found in the include paths. It evaluates; to 1 if the second instance of the file can be found using the include paths,; or 0 otherwise:. .. code-block:: c++. // Note the two possible file name string formats.; #if __has_include_next(""myinclude.h"") && __has_include_next(<stdint.h>); # include_next ""myinclude.h""; #endif. // To avoid problem with non-clang compilers not having this macro.; #if defined(__has_include_next); #if __has_include_next(""myinclude.h""); # include_next ""myinclude.h""; #endif; #endif. Note that ``__has_include_next``, like the GNU extension ``#include_next``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:10674,avoid,avoid,10674,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['avoid'],['avoid']
Safety," $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ROOT_GENERATE_DICTIONARY(ElementStructDict ElementStruct.h LINKDEF ElementStructLinkDef.h OPTIONS -inlineInputHeader); ROOT_ADD_GTEST(testTOffsetGeneration TOffsetGeneration.cxx ElementStruct.cxx ElementStructDict.cxx; LIBRARIES RIO Tree MathCore; ); if(MSVC AND NOT CMAKE_GENERATOR MATCHES Ninja); add_custom_command(TARGET testTOffsetGeneration POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy ${CMAKE_CURRENT_BINARY_DIR}/libElementStructDict_rdict.pcm; ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIG>/libElementStructDict_rdict.pcm); endif(); target_include_directories(testTOffsetGeneration PRIVATE ${CMAKE_CURRENT_SOURCE_DIR}); ROOT_STANDARD_LIBRARY_PACKAGE(SillyStruct NO_INSTALL_HEADERS HEADERS ${CMAKE_CURRENT_SOURCE_DIR}/SillyStruct.h SOURCES SillyStruct.cxx LINKDEF SillyStructLinkDef.h DEPENDENCIES RIO); ROOT_ADD_GTEST(testBulkApi BulkApi.cxx LIBRARIES RIO Tree TreePlayer); #FIXME: tests are having timeout on 32bit CERN VM (in docker container everything is fine),; # to be reverted after investigation.; if(NOT CMAKE_SIZEOF_VOID_P EQUAL 4); ROOT_ADD_GTEST(testBulkApiMultiple BulkApiMultiple.cxx LIBRARIES RIO Tree TreePlayer TIMEOUT 3000); ROOT_ADD_GTEST(testBulkApiVarLength BulkApiVarLength.cxx LIBRARIES RIO Tree TreePlayer); ROOT_ADD_GTEST(testBulkApiSillyStruct BulkApiSillyStruct.cxx LIBRARIES RIO Tree TreePlayer SillyStruct); endif(); ROOT_ADD_GTEST(testTBasket TBasket.cxx LIBRARIES RIO Tree); ROOT_ADD_GTEST(testTBranch TBranch.cxx LIBRARIES RIO Tree MathCore); ROOT_ADD_GTEST(testTIOFeatures TIOFeatures.cxx LIBRARIES RIO Tree); ROOT_ADD_GTEST(testTTreeCluster TTreeClusterTest.cxx LIBRARIES RIO Tree MathCore); ROOT_ADD_GTEST(testTChainParsing TChainParsing.cxx LIBRARIES RIO Tree); if(imt); ROOT_ADD_GTEST(testTTreeImplicitMT ImplicitMT.cxx LIBRARIES RIO Tree); endif(); ROOT_ADD_GTEST(testTChainSaveAsCxx TChainSaveAsCxx.cxx LIBRARIES RIO Tree); ROOT_ADD_GTEST(testTChainRegressions TChainRegressions.cxx",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/test/CMakeLists.txt:1093,timeout,timeout,1093,tree/tree/test/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/test/CMakeLists.txt,1,['timeout'],['timeout']
Safety," %ROOT Matrix Linear Algebra package. The %ROOT linear algebra package provides a complete environment in %ROOT to perform matrix; calculations such as matrix-vector and matrix-matrix multiplications and other linear; algebra calculations like equation solving and eigenvalue decompositions. The present package implements all the basic algorithms dealing; with vectors, matrices, matrix columns, rows, diagonals, etc.; In addition eigen-Vector analysis and several matrix decomposition; have been added (LU,QRH,Cholesky,Bunch-Kaufman and SVD) .; The decompositions are used in matrix inversion, equation solving. ### Matrix classes. %ROOT provides the following matrix classes, among others:. - `TMatrixDBase`. - `TMatrixF`. - `TMatrixFSym`. - `TVectorF`. - `TMatrixD`. - `TMatrixDSym`. - `TMatrixDSparse`. - `TDecompBase`. - `TDecompChol`. For a dense matrix, elements are arranged in memory in a ROW-wise; fashion . For (n x m) matrices where n*m <=kSizeMax (=25 currently); storage space is available on the stack, thus avoiding expensive; allocation/deallocation of heap space . However, this introduces of; course kSizeMax overhead for each matrix object . If this is an; issue recompile with a new appropriate value (>=0) for kSizeMax. Sparse matrices are also stored in row-wise fashion but additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify arbitrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). #### Matrix properties. A matrix has five properties, which are all set in the constructor:. - `precision` <br>; If the `precision` is float (i.e. single precision), use the `TMatrixF` class family. If th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:1089,avoid,avoiding,1089,math/matrix/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md,1,['avoid'],['avoiding']
Safety," (default value is 0.1). This tool checks all possible; significant pairs of candidates inside a given volume (not declared as; overlapping or division volumes). The check is performed by verifying; the mesh representation of one candidate against the shape of the other.; This sort of check cannot identify all possible overlapping topologies,; but it works for more than 95% and is much faster than the usual; shape-to-shape comparison. For a 100% reliability, one can perform the; check at the level of a single volume by using `option`=""`d`"" or; `option`=""`d<number>`"" to perform overlap checking by sampling the; volume with \<`number`\> random points (default 1 million). This; produces also a picture showing in red the overlapping region and; estimates the volume of the overlaps. An extrusion *A)* is declared in any of the following cases:. - At least one of the vertices of the daughter mesh representation is; outside the mother volume (in fact its shape) and having a safety; distance to the mother greater than the desired value;; - At least one of the mother vertices is contained also by one of its; daughters, in the same conditions. An overlap *B)* is declared if:. - At least one vertex of a positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. Once; the checking tool is fired-up inside a volume or at top level, the list; of overlaps (visible as Illegal overlaps inside a TBrowser) held; by the manager class will be filled with TGeoOverlap objects; containing a full description of the detected overlaps. The list is; sorted in the decreasing order of the overlapping distance, extrusions; coming first. An overlap object name represents the full description of; the overlap, containing",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:94270,safe,safety,94270,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['safe'],['safety']
Safety," * A type conversion may involve both a bitcast and a bounds annotation cast. For; example, casting from ``int *__bidi_indexable`` to ``char *__single`` involve; a bitcast (``int *`` to ``char *``) and a bounds annotation cast; (``__bidi_indexable`` to ``__single``). In this case, the compiler performs; the bitcast and then converts the bounds annotation. This means, ``int; *__bidi_indexable`` will be converted to ``char *__bidi_indexable`` and then; to ``char *__single``. * ``__terminated_by(T)`` cannot cast to any safe pointer type without the same; ``__terminated_by(T)`` attribute. To perform the cast, programmers can use an; intrinsic function such as ``__unsafe_terminated_by_to_indexable(P)`` to force; the conversion. * ``__terminated_by(T)`` can cast to ``__unsafe_indexable``. * Any type without ``__terminated_by(T)`` cannot cast to ``__terminated_by(T)``; without explicitly using an intrinsic function to allow it. + ``__unsafe_terminated_by_from_indexable(T, PTR [, PTR_TO_TERM])`` casts any; safe pointer PTR to a ``__terminated_by(T)`` pointer. ``PTR_TO_TERM`` is an; optional argument where the programmer can provide the exact location of the; terminator. With this argument, the function can skip reading the entire; array in order to locate the end of the pointer (or the upper bound).; Providing an incorrect ``PTR_TO_TERM`` causes a run-time trap. + ``__unsafe_forge_terminated_by(T, P, E)`` creates ``T __terminated_by(E)``; pointer given any pointer ``P``. Tmust be a pointer type. Portability with toolchains that do not support the extension; -------------------------------------------------------------. The language model is designed so that it doesn't alter the semantics of the; original C program, other than introducing deterministic traps where otherwise; the behavior is undefined and/or unsafe. Clang provides a toolchain header; (``ptrcheck.h``) that macro-defines the annotations as type attributes when; ``-fbounds-safety`` is enabled and defines them to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:44592,safe,safe,44592,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['safe'],['safe']
Safety," - Shape; - Custom; - Error; - Log. #### SOFIE Keras Parser; - The Swish Activation function is now supported in the SOFIE Keras parser. ## 2D Graphics Libraries. - Introduce `TAxis::ChangeLabelByValue` to set custom label defined by axis value. It works also; when axis zooming changes and position and index of correspondent axis label changes as well.; `TAxis::ChangeLabel` method to change axis label by index works as before. - Introduce `TCanvas::SaveAll` method. Allows to store several pads at once into different image file formats.; File name can include printf qualifier to code pad number. Also allows to store all pads in single PDF; or single ROOT file. Significantly improves performance when creating many image files using web graphics. - Introduce `TCanvas::UpdateAsync` method. In case of web-based canvas triggers update of the canvas on the client side,; but does not wait that real update is completed. Avoids blocking of caller thread.; Have to be used if called from other web-based widget to avoid logical dead-locks.; In case of normal canvas just canvas->Update() is performed. - The Delaunay triangles (used by TGraph2D) were computed by the external package `triangle.c`; included in the ROOT distribution. This package had several issues:; - It was not maintained anymore.; - Its license was not compatible with LGPL; This code is now replaced by the [CDT package](https://github.com/artem-ogre/CDT) which is; properly maintained and has a license (MLP) compatible with LGPL. It will appear in 6.03.02. ## Machine Learning integration. - ROOT now offers functionality to extract batches of events out of a dataset for use in common ML training workflows. For example, one can generate PyTorch tensors from a TTree. The functionality is available through the `RBatchGenerator` class and can be seamlessly integrated in user code, for example:; ```python; # Returns two generators that return training and validation batches as PyTorch tensors.; gen_train, gen_validation ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:20136,avoid,avoid,20136,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,1,['avoid'],['avoid']
Safety," --config Release --target libcef_dll_wrapper; ~~~. 5. Before compiling ROOT, `set CEF_ROOT=C:\Soft\cef` variable. ## Using plain CEF in ROOT batch mode on Linux. Default CEF builds, provided by [https://cef-builds.spotifycdn.com/index.html](https://cef-builds.spotifycdn.com/index.html), do; not include support of Ozone framework, which the only support headless mode in CEF. To run ROOT in headless (or batch) made with such CEF distribution,; one can use `Xvfb` server. Most simple way is to use `xvfb-run` utility like:. ~~~; $ xvfb-run --server-args='-screen 0, 1024x768x16' root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. Or run `Xvfb` before starting ROOT:. ~~~; $ Xvfb :99 &; $ export DISPLAY=:99; $ root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. ## Compile CEF with ozone support. Since March 2019 one can compile [CEF without X11](https://bitbucket.org/chromiumembedded/cef/issues/2296/), but such builds not provided.; Therefore to be able to use real headless mode in CEF, one should compile it from sources.; On [CEF build tutorial](https://bitbucket.org/chromiumembedded/cef/wiki/AutomatedBuildSetup.md) one can find complete compilation documentation.; Several Ubuntu distributions are supported by CEF, all others may require extra work. Once all depndencies are installed,; CEF with ozone support can be compiled with following commands:. ~~~; $ export GN_DEFINES=""is_official_build=true use_sysroot=true use_allocator=none symbol_level=1 is_cfi=false use_thin_lto=false use_ozone=true""; $ python automate-git.py --download-dir=/home/user/cef --branch=4638 --minimal-distrib --client-distrib --force-clean --x64-build --build-target=cefsimple; ~~~. With little luck one get prepared tarballs in `/home/user/cef/chromium/src/cef/binary_distrib`.; Just install it in the same way as described before in this document.; ROOT will automatically detect that CEF build with `ozone` support and will use it for both interactive and headless modes. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md:4195,detect,detect,4195,gui/cefdisplay/Readme.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md,1,['detect'],['detect']
Safety," -enable-finite-only-fp-math or the like).; ; With the correctness fixes for PR642 (58871) LowerSELECT_CC would need to; ; recognize a more elaborate tree than a simple SETxx. define double @test_FNEG_sel(double %A, double %B, double %C) {; %D = fsub double -0.000000e+00, %A ; <double> [#uses=1]; %Cond = fcmp ugt double %D, -0.000000e+00 ; <i1> [#uses=1]; %E = select i1 %Cond, double %B, double %C ; <double> [#uses=1]; ret double %E; }. //===----------------------------------------------------------------------===//; The save/restore sequence for CR in prolog/epilog is terrible:; - Each CR subreg is saved individually, rather than doing one save as a unit.; - On Darwin, the save is done after the decrement of SP, which means the offset; from SP of the save slot can be too big for a store instruction, which means we; need an additional register (currently hacked in 96015+96020; the solution there; is correct, but poor).; - On SVR4 the same thing can happen, and I don't think saving before the SP; decrement is safe on that target, as there is no red zone. This is currently; broken AFAIK, although it's not a target I can exercise.; The following demonstrates the problem:; extern void bar(char *p);; void foo() {; char x[100000];; bar(x);; __asm__("""" ::: ""cr2"");; }. //===-------------------------------------------------------------------------===; Naming convention for instruction formats is very haphazard.; We have agreed on a naming scheme as follows:. <INST_form>{_<OP_type><OP_len>}+. Where:; INST_form is the instruction format (X-form, etc.); OP_type is the operand type - one of OPC (opcode), RD (register destination),; RS (register source),; RDp (destination register pair),; RSp (source register pair), IM (immediate),; XO (extended opcode); OP_len is the length of the operand in bits. VSX register operands would be of length 6 (split across two fields),; condition register fields of length 3.; We would not need denote reserved fields in names of instruction formats. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt:13606,safe,safe,13606,interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,1,['safe'],['safe']
Safety," ... ]; [ !""<section#2"">; [ , !2 ... ]; ... ]; }; !1 = !{ iXX <aux-consts#1>, ... }; !2 = !{ iXX <aux-consts#2>, ... }; ... The occurrence of ``section#1``, ``section#2``, ..., ``section#N`` in the; metadata causes the backend to emit the PC for the associated instruction or; function to all named sections. For each emitted PC in a section #N, the; constants ``aux-consts#N`` in the tuple ``!N`` will be emitted after the PC.; Multiple tuples with constant data may be provided after a section name string; (e.g. ``!0 = !{""s1"", !1, !2}``), and a single constant tuple may be reused for; different sections (e.g. ``!0 = !{""s1"", !1, ""s2"", !1}``). Binary Encoding; ===============. *Instructions* result in emitting a single PC, and *functions* result in; emission of the start of the function and a 32-bit size. This is followed by; the auxiliary constants that followed the respective section name in the; ``MD_pcsections`` metadata. To avoid relocations in the final binary, each PC address stored at ``entry``; is a relative relocation, computed as ``pc - entry``. To decode, a user has to; compute ``entry + *entry``. The size of each entry depends on the code model. With large and medium sized; code models, the entry size matches pointer size. For any smaller code model; the entry size is just 32 bits. Encoding Options; ----------------. Optional encoding options can be passed in the first ``MDString`` operator:; ``<section>!<options>``. The following options are available:. * ``C`` -- Compress constant integers of size 2-8 bytes as ULEB128; this; includes the function size (but excludes the PC entry). For example, ``foo!C`` will emit into section ``foo`` with all constants; encoded as ULEB128. Guarantees on Code Generation; =============================. Attaching ``!pcsections`` metadata to LLVM IR instructions *shall not* affect; optimizations or code generation outside the requested PC sections. While relying on LLVM IR metadata to request PC sections makes the above; guarant",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PCSectionsMetadata.rst:1802,avoid,avoid,1802,interpreter/llvm-project/llvm/docs/PCSectionsMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PCSectionsMetadata.rst,1,['avoid'],['avoid']
Safety," // Warning, mu is not locked.; if (success) {; a = 0; // Ok.; mu.Unlock();; } else {; a = 0; // Warning, mu is not locked.; }; }. ASSERT_CAPABILITY(...) and ASSERT_SHARED_CAPABILITY(...); --------------------------------------------------------. *Previously:* ``ASSERT_EXCLUSIVE_LOCK``, ``ASSERT_SHARED_LOCK``. These are attributes on a function or method which asserts the calling thread; already holds the given capability, for example by performing a run-time test; and terminating if the capability is not held. Presence of this annotation; causes the analysis to assume the capability is held after calls to the; annotated function. See :ref:`mutexheader`, below, for example uses. GUARDED_VAR and PT_GUARDED_VAR; ------------------------------. Use of these attributes has been deprecated. Warning flags; -------------. * ``-Wthread-safety``: Umbrella flag which turns on the following:. + ``-Wthread-safety-attributes``: Semantic checks for thread safety attributes.; + ``-Wthread-safety-analysis``: The core analysis.; + ``-Wthread-safety-precise``: Requires that mutex expressions match precisely.; This warning can be disabled for code which has a lot of aliases.; + ``-Wthread-safety-reference``: Checks when guarded members are passed by reference. :ref:`negative` are an experimental feature, which are enabled with:. * ``-Wthread-safety-negative``: Negative capabilities. Off by default. When new features and checks are added to the analysis, they can often introduce; additional warnings. Those warnings are initially released as *beta* warnings; for a period of time, after which they are migrated into the standard analysis. * ``-Wthread-safety-beta``: New features. Off by default. .. _negative:. Negative Capabilities; =====================. Thread Safety Analysis is designed to prevent both race conditions and; deadlock. The GUARDED_BY and REQUIRES attributes prevent race conditions, by; ensuring that a capability is held before reading or writing to guarded data,; and the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:15933,safe,safety-analysis,15933,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['safe'],['safety-analysis']
Safety," 0x7fcf47b21bc0 by main thread:; #0 main tiny_race.c:10 (exe+0x00000000a3b4). Thread T1 (running) created at:; #0 pthread_create tsan_interceptors.cc:705 (exe+0x00000000c790); #1 main tiny_race.c:9 (exe+0x00000000a3a4). ``__has_feature(thread_sanitizer)``; ------------------------------------. In some cases one may need to execute different code depending on whether; ThreadSanitizer is enabled.; :ref:`\_\_has\_feature <langext-__has_feature-__has_extension>` can be used for; this purpose. .. code-block:: c. #if defined(__has_feature); # if __has_feature(thread_sanitizer); // code that builds only under ThreadSanitizer; # endif; #endif. ``__attribute__((no_sanitize(""thread"")))``; -----------------------------------------------. Some code should not be instrumented by ThreadSanitizer. One may use the; function attribute ``no_sanitize(""thread"")`` to disable instrumentation of plain; (non-atomic) loads/stores in a particular function. ThreadSanitizer still; instruments such functions to avoid false positives and provide meaningful stack; traces. This attribute may not be supported by other compilers, so we suggest; to use it together with ``__has_feature(thread_sanitizer)``. ``__attribute__((disable_sanitizer_instrumentation))``; --------------------------------------------------------. The ``disable_sanitizer_instrumentation`` attribute can be applied to functions; to prevent all kinds of instrumentation. As a result, it may introduce false; positives and incorrect stack traces. Therefore, it should be used with care,; and only if absolutely required; for example for certain code that cannot; tolerate any instrumentation and resulting side-effects. This attribute; overrides ``no_sanitize(""thread"")``. Ignorelist; ----------. ThreadSanitizer supports ``src`` and ``fun`` entity types in; :doc:`SanitizerSpecialCaseList`, that can be used to suppress data race reports; in the specified source files or functions. Unlike functions marked with; ``no_sanitize(""thread"")`` attribu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSanitizer.rst:2747,avoid,avoid,2747,interpreter/llvm-project/clang/docs/ThreadSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSanitizer.rst,1,['avoid'],['avoid']
Safety," 2 64-bit address of amd_queue_t; (enable_sgpr_queue_ptr) object for AQL queue on which; the dispatch packet was; queued.; then Kernarg Segment Ptr 2 64-bit address of Kernarg; (enable_sgpr_kernarg segment. This is directly; _segment_ptr) copied from the; kernarg_address in the kernel; dispatch packet. Having CP load it once avoids; loading it at the beginning of; every wavefront.; then Dispatch Id 2 64-bit Dispatch ID of the; (enable_sgpr_dispatch_id) dispatch packet being; executed.; then Flat Scratch Init 2 See; (enable_sgpr_flat_scratch :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; _init); then Preloaded Kernargs N/A See; (kernarg_preload_spec :ref:`amdgpu-amdhsa-kernarg-preload`.; _length); then Private Segment Size 1 The 32-bit byte size of a; (enable_sgpr_private single work-item's memory; _segment_size) allocation. This is the; value from the kernel; dispatch packet Private; Segment Byte Size rounded up; by CP to a multiple of; DWORD. Having CP load it once avoids; loading it at the beginning of; every wavefront. This is not used for; GFX7-GFX8 since it is the same; value as the second SGPR of; Flat Scratch Init. However, it; may be needed for GFX9-GFX11 which; changes the meaning of the; Flat Scratch Init value.; then Work-Group Id X 1 32-bit work-group id in X; (enable_sgpr_workgroup_id dimension of grid for; _X) wavefront.; then Work-Group Id Y 1 32-bit work-group id in Y; (enable_sgpr_workgroup_id dimension of grid for; _Y) wavefront.; then Work-Group Id Z 1 32-bit work-group id in Z; (enable_sgpr_workgroup_id dimension of grid for; _Z) wavefront.; then Work-Group Info 1 {first_wavefront, 14'b0000,; (enable_sgpr_workgroup ordered_append_term[10:0],; _info) threadgroup_size_in_wavefronts[5:0]}; then Scratch Wavefront Offset 1 See; (enable_sgpr_private :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; _segment_wavefront_offset) and; :ref:`amdgpu-amdhsa-kernel-prolog-private-segment-buffer`.; ========== ========================== ====== ================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:185525,avoid,avoids,185525,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['avoid'],['avoids']
Safety," 3: through views; // Each view will only trigger reading of the related field, without reading other fields at the same entry number.; auto reader = RNTupleReader::Open(ntuple);; auto viewPt = reader->GetView<float>(""pt"");; // Load the pt from the first entry; auto pt = viewPt(0);; ```. In the above cases, RNTuple creates the objects being read into.; It is also possible to bind already existing objects.; This is shown below for entries and works similarly for views. ```c++; // A bare entry is an entry that has initially no bindings (all top-level fields need to be bound by the caller); auto entry = reader->GetModel().CreateBareEntry();; auto ptToken = entry->GetToken(""pt"");. // Option 1: type safe, shared ownership; std::shared_ptr<float> ptTypedSharedPtr;; entry->BindValue(ptToken, ptTypedSharedPtr);. // Option 2: type unsafe, shared ownership; std::shared_ptr<void> ptVoidSharedPtr;; entry->BindValue(ptToken, ptVoidSharedPtr);. // Option 3: type unsafe, application owns the object; void *ptVoidPtr;; entry->BindRawPtr(ptToken, ptVoidPtr);. // Option 4: switch back from application-provided object to RNTuple-created object; entry->EmplaceNewValue(ptToken);. // For all options: use an explicit entry; reader->LoadEntry(0, *entry);; ```. Walkthrough: Writing Data; -------------------------. ```c++; auto model = RNTupleModel::Create();; // Add a field to the model and return the shared pointer for that field in the model's default entry.; auto ptrPt = model->MakeField<float>(""pt"");. auto file = std::make_unique<TFile>(""data.root"", ""APPEND"");; // The writer creates a page sink and connects the model's fields to it; auto writer = RNTupleWriter::Append(std::move(model), ""ntpl"", *file);; *ptrPt = 1.0;; // Append the model's default entry; writer->Fill();; // Commit the dataset by destructing the writer; writer.reset();; ```. The points on object type-safety and ownership apply in the same way as for reading data. Creation of the RNTuple model can use runtime type informatio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:4096,unsafe,unsafe,4096,tree/ntuple/v7/doc/Architecture.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md,1,['unsafe'],['unsafe']
Safety," < `** ***`TGeoShape::Big()`*** **` `**. The safe distance in the current volume is also computed. Moving the; particle from its current location with this distance in any direction; is safe in the sense that will never change the current state. **`stepmax < 0`**. The global matrix for the object that will have the next crossed; boundary is also computed. This can be retrieved for masterlocal point; or vector conversions: **`TGeoManager`**::`GetNextMatrix`(). In case the computation of the normal vector to the next crossed surface; is required, using a negative stepmax value is recommended. In this case; one can subsequently call a method for fast normal computation:. ``` {.cpp}; Double_t *TGeoManager::FindNormalFast(); ```. **`path `** **` 0`**. In case a path to a given physical object is specified, the distance to; its boundary is computed ignoring the rest of the geometry. #### Output Values. `TGeoManager::GetStep()`: distance to next boundary. `TGeoManager::GetSafeDistance()`: safe distance (in case it was; computed). `TGeoManager::IsOnBoundary()`: the initial point `(x,y,z)` was (or was; not) on a boundary within `TGeoShape::Tolerance()`. The algorithm checks first if the computation of safety was required. If; this is the case and the global point coordinates did not change from; the last query, the last computed safety is taken. Otherwise, the method; **`TGeoManager`**`::Safety ()` is invoked. A safety value less than; **`TGeoShape`**`::Tolerance()` will set the flag IsOnBoundary to true.; On the other hand, a safety value bigger than the proposed step will; stop the computation of the distance to next boundary, returning the; current geometry location with the meaning that the proposed step is; safe. The next stage is to check if computation of the distance to a give; physical object specified by a path was required. If this is the case,; the modeller changes the state to point to the required object, converts; the current point and direction coordinates to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:161019,safe,safe,161019,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['safe'],['safe']
Safety," <workflow-monocheckout-multicommit>`.; * :ref:`Commit an API Change in LLVM and Update the Sub-projects <workflow-cross-repo-commit>`.; * :ref:`Branching/Stashing/Updating for Local Development or Experiments <workflow-mono-branching>`.; * :ref:`Bisecting <workflow-mono-bisecting>`. Workflow Before/After; =====================. This section goes through a few examples of workflows, intended to illustrate; how end-users or developers would interact with the repository for; various use-cases. .. _workflow-checkout-commit:. Checkout/Clone a Single Project, with Commit Access; ---------------------------------------------------. Currently; ^^^^^^^^^. ::. # direct SVN checkout; svn co https://user@llvm.org/svn/llvm-project/llvm/trunk llvm; # or using the read-only Git view, with git-svn; git clone https://llvm.org/git/llvm.git; cd llvm; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l # -l avoids fetching ahead of the git mirror. Commits are performed using `svn commit` or with the sequence `git commit` and; `git svn dcommit`. .. _workflow-multicheckout-nocommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. With the monorepo variant, there are a few options, depending on your; constraints. First, you could just clone the full repository:. git clone https://github.com/llvm/llvm-project.git. At this point you have every sub-project (llvm, clang, lld, lldb, ...), which; :ref:`doesn't imply you have to build all of them <build_single_project>`. You; can still build only compiler-rt for instance. In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checkout; git read-tree -mu HEAD. The data for all sub-projects is still in your `.git` director",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:13251,avoid,avoids,13251,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['avoid'],['avoids']
Safety," = getelementptr inbounds %struct.anon* %tmp3, i64 %indvar, i32 0; %tmp5 = load double* %tmp4, align 8, !tbaa !4; %idxprom7 = sext i32 %i.01718 to i64; %tmp10 = getelementptr inbounds %struct.anon* %tmp3, i64 %idxprom7, i32 0; %tmp11 = load double* %tmp10, align 8, !tbaa !4; %cmp12 = fcmp ogt double %tmp5, %tmp11; br i1 %cmp12, label %if.then, label %for.inc. if.then: ; preds = %for.body; %i.017 = trunc i64 %indvar to i32; br label %for.inc. for.inc: ; preds = %for.body, %if.then; %i.01719 = phi i32 [ %i.01718, %for.body ], [ %i.017, %if.then ]; %indvar.next = add i64 %indvar, 1; %exitcond = icmp eq i64 %indvar.next, %tmp22; br i1 %exitcond, label %for.cond.for.end_crit_edge, label %for.body. It is good that we hoisted the reloads of numf2's, and Y out of the loop and; sunk the store to winner out. However, this is awful on several levels: the conditional truncate in the loop; (-indvars at fault? why can't we completely promote the IV to i64?). Beyond that, we have a partially redundant load in the loop: if ""winner"" (aka ; %i.01718) isn't updated, we reload Y[winner].y the next time through the loop.; Similarly, the addressing that feeds it (including the sext) is redundant. In; the end we get this generated assembly:. LBB0_2: ## %for.body; ## =>This Inner Loop Header: Depth=1; 	movsd	(%rdi), %xmm0; 	movslq	%edx, %r8; 	shlq	$4, %r8; 	ucomisd	(%rcx,%r8), %xmm0; 	jbe	LBB0_4; 	movl	%esi, %edx; LBB0_4: ## %for.inc; 	addq	$16, %rdi; 	incq	%rsi; 	cmpq	%rsi, %rax; 	jne	LBB0_2. All things considered this isn't too bad, but we shouldn't need the movslq or; the shlq instruction, or the load folded into ucomisd every time through the; loop. On an x86-specific topic, if the loop can't be restructure, the movl should be a; cmov. //===---------------------------------------------------------------------===//. [STORE SINKING]. GCC PR37810 is an interesting case where we should sink load/store reload; into the if block and outside the loop, so we don't reload/store it on the; non-c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:31184,redund,redundant,31184,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['redund'],['redundant']
Safety," ================================. HWASAN:; * Is less portable than :doc:`AddressSanitizer`; as it relies on hardware `Address Tagging`_ (AArch64).; Address Tagging can be emulated with compiler instrumentation,; but it will require the instrumentation to remove the tags before; any load or store, which is infeasible in any realistic environment; that contains non-instrumented code.; * May have compatibility problems if the target code uses higher; pointer bits for other purposes.; * May require changes in the OS kernels (e.g. Linux seems to dislike; tagged pointers passed from address space:; https://www.kernel.org/doc/Documentation/arm64/tagged-pointers.txt).; * **Does not require redzones to detect buffer overflows**,; but the buffer overflow detection is probabilistic, with roughly; `1/(2**TS)` chance of missing a bug (6.25% or 0.39% with 4 and 8-bit TS; respectively).; * **Does not require quarantine to detect heap-use-after-free,; or stack-use-after-return**.; The detection is similarly probabilistic. The memory overhead of HWASAN is expected to be much smaller; than that of AddressSanitizer:; `1/TG` extra memory for the shadow; and some overhead due to `TG`-aligning all objects. Supported architectures; =======================; HWASAN relies on `Address Tagging`_ which is only available on AArch64.; For other 64-bit architectures it is possible to remove the address tags; before every load and store by compiler instrumentation, but this variant; will have limited deployability since not all of the code is; typically instrumented. On x86_64, HWASAN utilizes page aliasing to place tags in userspace address; bits. Currently only heap tagging is supported. The page aliases rely on; shared memory, which will cause heap memory to be shared between processes if; the application calls ``fork()``. Therefore x86_64 is really only safe for; applications that do not fork. HWASAN does not currently support 32-bit architectures since they do not; support `Address Tagging`_ ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:10174,detect,detection,10174,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,1,['detect'],['detection']
Safety," API under test.; Like this:. .. code-block:: c++. // fuzz_target.cc; extern ""C"" int LLVMFuzzerTestOneInput(const uint8_t *Data, size_t Size) {; DoSomethingInterestingWithMyAPI(Data, Size);; return 0; // Values other than 0 and -1 are reserved for future use.; }. Note that this fuzz target does not depend on libFuzzer in any way; and so it is possible and even desirable to use it with other fuzzing engines; e.g. AFL_ and/or Radamsa_. Some important things to remember about fuzz targets:. * The fuzzing engine will execute the fuzz target many times with different inputs in the same process.; * It must tolerate any kind of input (empty, huge, malformed, etc).; * It must not `exit()` on any input.; * It may use threads but ideally all threads should be joined at the end of the function.; * It must be as deterministic as possible. Non-determinism (e.g. random decisions not based on the input bytes) will make fuzzing inefficient.; * It must be fast. Try avoiding cubic or greater complexity, logging, or excessive memory consumption.; * Ideally, it should not modify any global state (although that's not strict).; * Usually, the narrower the target the better. E.g. if your target can parse several data formats, split it into several targets, one per format. Fuzzer Usage; ------------. Recent versions of Clang (starting from 6.0) include libFuzzer, and no extra installation is necessary. In order to build your fuzzer binary, use the `-fsanitize=fuzzer` flag during the; compilation and linking. In most cases you may want to combine libFuzzer with; AddressSanitizer_ (ASAN), UndefinedBehaviorSanitizer_ (UBSAN), or both. You can; also build with MemorySanitizer_ (MSAN), but support is experimental::. clang -g -O1 -fsanitize=fuzzer mytarget.c # Builds the fuzz target w/o sanitizers; clang -g -O1 -fsanitize=fuzzer,address mytarget.c # Builds the fuzz target with ASAN; clang -g -O1 -fsanitize=fuzzer,signed-integer-overflow mytarget.c # Builds the fuzz target with a part of UBSAN; c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:2376,avoid,avoiding,2376,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['avoid'],['avoiding']
Safety," AddInputData and those found in the file defined bySetInputDataFile.  . Improvements:. More; complete set of tests in test/stressProof . To run with PROOF-Lite pass; the argument 'lite' as master URL, e.g. './stressProof lite'.Possibility; to control on the client via rc variable the location of the sandbox,; package directory, cache and dataset directory (the latters two only; for PROOF-Lite); the variable names are 'Proof.Sandbox', ; 'Proof.PackageDir', 'Proof.CacheDir' and 'Proof.DataSetDir'. The default location of the sandbox has been changed from ""~/proof"" to ""~/.proof"" to avoid interferences with possible users' working areas.XrdProofd plug-in. Overall refactorization for easier; maintainance and improved solidity; Improved format of printout messages: all information; messages contain now the tag 'xpd-I' and all error messages the; tag 'xpd-E', so that they can easily be grepped out from the; log file.; . Log sending. Implement selective sending of logs from workers to master to avoid duplicating; too many text lines on the master log. Logs are now sent only after Exec, Print; requests and in case an error (level >= kError) occured. Of course, the full; logs can always be retrieved via TProofMgr::GetSessionLogs; . Log retrieval:. for 'grep' operations, use the system 'grep' command; via 'popen'; instead of a handmade filtering; this implies that the full grep; functionality is now available; set the default number of displayed lines to 100; instead of 10. Improve diagnostic in case of worker death: clients will; now; receive a message containing the low level reason for the failure and a; hint for getting more informationIn; TProofOutputFile, support the ""<user>"" and ""<group>""; placeholders in the output file name to automatically re-direct the; output to an area specific to the logged user.; Addition of a new class TProofProgressStatus, which is used to keep; the query progress stauts in all the TProofPlayer objects and in the; TPacketizerAdaptive. It is a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:4823,avoid,avoid,4823,proof/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html,1,['avoid'],['avoid']
Safety," AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produce; false alarms. Once a memory corruption occurs, the program is in an inconsistent; state, which could lead to confusing results and potentially misleading; subsequent reports. If your process is sandboxed and you are running on OS X 10.10 or earlier, you; will need to set ``DYLD_INSERT_LIBRARIES`` environment variable and point it to; the ASan library that is packaged with the compiler used to build the; executable. (You can find the library by searching for dynamic libraries with; ``asan`` in their name.) If the environment variable is not set, the process will; try to re-exec. Also keep in mind that when moving the executable to another machine,; the ASan library will also need to be copied over. Symbolizing the Reports; =========================. To make AddressSaniti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:2475,detect,detected,2475,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,1,['detect'],['detected']
Safety," But pointers to member functions are nowhere near as common as arrays. Very true. If you're implementing an object oriented language, however,; remember that you have to do all the pointer to member function stuff; yourself.... so every time you invoke a virtual method one is involved; (instead of having C++ hide it for you behind ""syntactic sugar""). > And the old array syntax:; > type [ int, int, ...]; > is just much more familiar and clear to people than anything new you; > introduce, no matter how logical it is. . Erm... excuse me but how is this the ""old array syntax""? If you are; arguing for consistency with C, you should be asking for 'type int []',; which is significantly different than the above (beside the above; introduces a new operator and duplicates information; needlessly). Basically what I am suggesting is exactly the above without; the fluff. So instead of:. type [ int, int, ...]. you use:. type [ int ]. > Introducing a new syntax that may; > make function pointers easier but makes arrays much more difficult seems; > very risky to me. This is not about function pointers. This is about consistency in the; type system, and consistency with the rest of the language. The point; above does not make arrays any more difficult to use, and makes the; structure of types much more obvious than the ""c way"". > > In my opinion, it is critically important to have clear and concise type; > > specifications, because types are going to be all over the programs.; > ; > I absolutely agree. But the question is, what is more clear and concise?; > The syntax programmers are used to out of years of experience or a new; > syntax that they have never seen that has a more logical structure. I think; > the answer is the former. Sometimes, you have to give up a better idea; > because you can't overcome sociological barriers to it. Qwerty keyboards; > and Windows are two classic examples of bad technology that are difficult to; > root out. Very true, but you seem to be advocating",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-06-TypeNotationDebateResp4.txt:3188,risk,risky,3188,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-06-TypeNotationDebateResp4.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-06-TypeNotationDebateResp4.txt,1,['risk'],['risky']
Safety," C++'s global; new operator will always return a pointer that does not alias any; other pointer when the function returns. .. option:: -fassume-nothrow-exception-dtor. Assume that an exception object' destructor will not throw, and generate; less code for catch handlers. A throw expression of a type with a; potentially-throwing destructor will lead to an error. By default, Clang assumes that the exception object may have a throwing; destructor. For the Itanium C++ ABI, Clang generates a landing pad to; destroy local variables and call ``_Unwind_Resume`` for the code; ``catch (...) { ... }``. This option tells Clang that an exception object's; destructor will not throw and code simplification is possible. .. option:: -ftrap-function=[name]. Instruct code generator to emit a function call to the specified; function name for ``__builtin_trap()``. LLVM code generator translates ``__builtin_trap()`` to a trap; instruction if it is supported by the target ISA. Otherwise, the; builtin is translated into a call to ``abort``. If this option is; set, then the code generator will always lower the builtin to a call; to the specified function regardless of whether the target ISA has a; trap instruction. This option is useful for environments (e.g.; deeply embedded) where a trap cannot be properly handled, or when; some custom behavior is desired. .. option:: -ftls-model=[model]. Select which TLS model to use. Valid values are: ``global-dynamic``, ``local-dynamic``,; ``initial-exec`` and ``local-exec``. The default value is; ``global-dynamic``. The compiler may use a different model if the; selected model is not supported by the target, or if a more; efficient model can be used. The TLS model can be overridden per; variable using the ``tls_model`` attribute. .. option:: -femulated-tls. Select emulated TLS model, which overrides all -ftls-model choices. In emulated TLS mode, all access to TLS variables are converted to; calls to __emutls_get_address in the runtime library. .. opti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:83060,abort,abort,83060,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['abort'],['abort']
Safety, C++11; Disambiguating user-defined literals; Unknown. 1176; C++11; Definition of release sequence; Unknown. 1177; C++11; Intra-thread dependency-ordered-before; Unknown. 1178; C++11; Deduction failure matching placement new; Unknown. 1179; NAD; Cv-qualification of non-type template parameters; Unknown. 1180; C++11; Over-aligned class types; Unknown. 1181; C++11; What is a “built-in type?”; Unknown. 1182; C++11; Incorrect description of pack expansion syntax; Unknown. 1183; C++11; Expansion of parameter packs in declarators; Unknown. 1184; C++11; Argument conversions to nondeduced parameter types; Unknown. 1185; C++11; Misleading description of language linkage and member function types; Unknown. 1186; C++11; Non-dependent constexpr violations in function templates; Unknown. 1187; C++11; Problems in initialization example; Unknown. 1188; C++11; Type punning in constant expressions; Unknown. 1189; C++11; Address of distinct base class subobjects; Unknown. 1190; C++11; Operations on non-safely-derived pointers; Unknown. 1191; C++11; Deleted subobject destructors and implicitly-defined constructors; Unknown. 1192; C++11; Inadvertent change to ODR and templates; Unknown. 1193; C++11; Use of address-constant pointers in constant expressions; Unknown. 1194; C++11; Constexpr references; Unknown. 1195; C++11; References to non-literal types in constexpr functions; Unknown. 1196; C++11; Definition required for explicit instantiation after explicit specialization?; Unknown. 1197; C++11; Constexpr arrays; Unknown. 1198; C++11; Literal types and copy constructors; Unknown. 1199; C++11; Deleted constexpr functions; Unknown. 1200; CD6; Lookup rules for template parameters; N/A. 1201; C++11; Are deleted and defaulted functions definitions?; Unknown. 1202; C++11; Calling virtual functions during destruction; Unknown. 1203; dup; Misleading note regarding initialized static data members; Unknown. 1204; C++11; Specifiers in a for-range-declaration; Unknown. 1205; dup; Lvalue reference ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:79188,safe,safely-derived,79188,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,1,['safe'],['safely-derived']
Safety," CMAKE_SOURCE_DIR STREQUAL CMAKE_BINARY_DIR AND NOT MSVC_IDE ); message(FATAL_ERROR ""In-source builds are not allowed. CMake would overwrite ""; ""the makefiles distributed with LLVM. Please create a directory and run cmake ""; ""from there, passing the path to this source directory as the last argument. ""; ""This process created the file `CMakeCache.txt' and the directory ""; ""`CMakeFiles'. Please delete them.""); endif(). # From ROOT:; function(cling_add_cxx_flag var flag); string(REGEX REPLACE ""[-.+/:= ]"" ""_"" flag_esc ""${flag}""); CHECK_CXX_COMPILER_FLAG(""${flag}"" CXX_HAS${flag_esc}); if(CXX_HAS${flag_esc}); set(${var} ""${${var}} ${flag}"" PARENT_SCOPE); endif(); endfunction(). if(CLING_ENABLE_WARNINGS AND NOT LLVM_ENABLE_WARNINGS AND (LLVM_COMPILER_IS_GCC_COMPATIBLE OR CLANG_CL)); # from HandleLLCMOptions.cmake:; append(""-Wall -W -Wno-unused-parameter -Wwrite-strings"" CMAKE_C_FLAGS CMAKE_CXX_FLAGS); append(""-Wcast-qual"" CMAKE_CXX_FLAGS). # Turn off missing field initializer warnings for gcc to avoid noise from; # false positives with empty {}. Turn them on otherwise (they're off by; # default for clang).; check_cxx_compiler_flag(""-Wmissing-field-initializers"" CXX_SUPPORTS_MISSING_FIELD_INITIALIZERS_FLAG); if (CXX_SUPPORTS_MISSING_FIELD_INITIALIZERS_FLAG); if (CMAKE_COMPILER_IS_GNUCXX); append(""-Wno-missing-field-initializers"" CMAKE_C_FLAGS CMAKE_CXX_FLAGS); else(); append(""-Wmissing-field-initializers"" CMAKE_C_FLAGS CMAKE_CXX_FLAGS); endif(); endif(). if (LLVM_ENABLE_PEDANTIC AND LLVM_COMPILER_IS_GCC_COMPATIBLE); append(""-pedantic"" CMAKE_C_FLAGS CMAKE_CXX_FLAGS); append(""-Wno-long-long"" CMAKE_C_FLAGS CMAKE_CXX_FLAGS); endif(). add_flag_if_supported(""-Wcovered-switch-default"" COVERED_SWITCH_DEFAULT_FLAG); append_if(USE_NO_UNINITIALIZED ""-Wno-uninitialized"" CMAKE_CXX_FLAGS); append_if(USE_NO_MAYBE_UNINITIALIZED ""-Wno-maybe-uninitialized"" CMAKE_CXX_FLAGS). # Check if -Wnon-virtual-dtor warns even though the class is marked final.; # If it does, don't add it. So it won't be ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/CMakeLists.txt:6096,avoid,avoid,6096,interpreter/cling/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/CMakeLists.txt,1,['avoid'],['avoid']
Safety," Check `b1` again -- unnecessary!; g();; }; }; }; ```. A checker that finds this pattern syntactically is already implemented in; ClangTidy using AST matchers (`bugprone-redundant-branch-condition`). To implement it using the data flow analysis framework, we can produce a warning; if any part of the branch condition is implied by the flow condition. ```c++; int F(bool b1, bool b2) {; // Flow condition: true.; if (b1) {; // Flow condition: b1.; f();; if (b1 && b2) { // `b1` is implied by the flow condition.; g();; }; }; }; ```. One way to check this implication is to use a SAT solver. Without a SAT solver,; we could keep the flow condition in the CNF form and then it would be easy to; check the implication. ## Example: finding unchecked `std::optional` unwraps. Calling `optional::value()` is only valid if `optional::has_value()` is true. We; want to show that when `x.value()` is executed, the flow condition implies; `x.has_value()`. In the example below `x.value()` is accessed safely because it is guarded by the; `x.has_value()` check. ```c++; void Example(std::optional<int> &x) {; if (x.has_value()) {; use(x.value());; }; }; ```. While entering the if branch we deduce that `x.has_value()` is implied by the; flow condition. ```c++; void Example(std::optional<int> x) {; // Flow condition: true.; if (x.has_value()) {; // Flow condition: x.has_value() == true.; use(x.value());; }; // Flow condition: true.; }; ```. We also need to prove that `x` is not modified between check and value access.; The modification of `x` may be very subtle:. ```c++; void F(std::optional<int> &x);. void Example(std::optional<int> &x) {; if (x.has_value()) {; // Flow condition: x.has_value() == true.; unknown_function(x); // may change x.; // Flow condition: true.; use(x.value());; }; }; ```. ## Example: finding dead code behind A/B experiment flags. Finding dead code is a classic application of data flow analysis. Unused flags for A/B experiment hide dead code. However, this flavor of dead; co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:27048,safe,safely,27048,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['safe'],['safely']
Safety, Clang 2.9. Changing undefined behavior into diagnosable errors; N1727; Clang 2.9. Delegating constructors; N1986; Clang 3.0. Inheriting constructors; N2540; Clang 3.3. P0136R1 (DR); Clang 3.9. Explicit conversion operators; N2437; Clang 3.0. New character types; N2249; Clang 2.9. Unicode string literals; N2442; Clang 3.0. Raw string literals; N2442; Clang 3.0. Universal character names in literals; N2170; Clang 3.1. User-defined literals; N2765; Clang 3.1. Standard Layout Types; N2342; Clang 3.0. Defaulted functions; N2346; Clang 3.0. ; P1286R2 (DR); Clang 9. Deleted functions; N2346; Clang 2.9. Extended friend declarations; N1791; Clang 2.9. Extending sizeof; N2253; DR850; Clang 3.1. Inline namespaces; N2535; Clang 2.9. Unrestricted unions; N2544; Clang 3.1. Local and unnamed types as template arguments; N2657; Clang 2.9. Range-based for; N2930; Clang 3.0. P0962R1 (DR); Clang 8. Explicit virtual overrides; N2928; N3206; N3272; Clang 3.0. Minimal support for garbage collection and reachability-based leak detection; N2670; N/A (2). Allowing move constructors to throw [noexcept]; N3050; Clang 3.0. Defining move special member functions; N3053; Clang 3.0. Concurrency. Sequence points; N2239; Clang 3.3. Atomic operations; N2427; Clang 3.1. Strong Compare and Exchange; N2748; Clang 3.1 (3). Bidirectional Fences; N2752; Clang 3.1. Memory model; N2429; Clang 3.2. Data-dependency ordering: atomics and memory model; N2664; Clang 3.2 (4). Propagating exceptions; N2179; Clang 2.9. Allow atomics use in signal handlers; N2547; Clang 3.1. Thread-local storage; N2659; Clang 3.3 (5). Dynamic initialization and destruction with concurrency; N2660; Clang 2.9. C99 Features in C++11. __func__ predefined identifier; N2340; Clang 2.9. C99 preprocessor; N1653; Clang 2.9. long long; N1811; Clang 2.9. Extended integral types; N1988; N/A (6). (1): The [[carries_dependency]] attribute; has no effect.; (2): No compiler changes are required for an implementation; such as Clang that does not pr,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html:17357,detect,detection,17357,interpreter/llvm-project/clang/www/cxx_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html,1,['detect'],['detection']
Safety," DL member. The constructor begins by initializing our; ObjectLayer. The ObjectLayer requires a reference to the ExecutionSession, and; a function object that will build a JIT memory manager for each module that is; added (a JIT memory manager manages memory allocations, memory permissions, and; registration of exception handlers for JIT'd code). For this we use a lambda; that returns a SectionMemoryManager, an off-the-shelf utility that provides all; the basic memory management functionality required for this chapter. Next we; initialize our CompileLayer. The CompileLayer needs three things: (1) A; reference to the ExecutionSession, (2) A reference to our object layer, and (3); a compiler instance to use to perform the actual compilation from IR to object; files. We use the off-the-shelf ConcurrentIRCompiler utility as our compiler,; which we construct using this constructor's JITTargetMachineBuilder argument.; The ConcurrentIRCompiler utility will use the JITTargetMachineBuilder to build; llvm TargetMachines (which are not thread safe) as needed for compiles. After; this, we initialize our supporting members: ``DL``, ``Mangler`` and ``Ctx`` with; the input DataLayout, the ExecutionSession and DL member, and a new default; constructed LLVMContext respectively. Now that our members have been initialized,; so the one thing that remains to do is to tweak the configuration of the; *JITDylib* that we will store our code in. We want to modify this dylib to; contain not only the symbols that we add to it, but also the symbols from our; REPL process as well. We do this by attaching a; ``DynamicLibrarySearchGenerator`` instance using the; ``DynamicLibrarySearchGenerator::GetForCurrentProcess`` method. .. code-block:: c++. static Expected<std::unique_ptr<KaleidoscopeJIT>> Create() {; auto JTMB = JITTargetMachineBuilder::detectHost();. if (!JTMB); return JTMB.takeError();. auto DL = JTMB->getDefaultDataLayoutForTarget();; if (!DL); return DL.takeError();. return std::make_uniq",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst:7929,safe,safe,7929,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst,1,['safe'],['safe']
Safety," Flow Integrity. LLVM Builds and Distributions; -----------------------------. :doc:`BuildingADistribution`; A best-practices guide for using LLVM's CMake build system to package and; distribute LLVM-based tools. :doc:`CMake`; An addendum to the main Getting Started guide for those using the `CMake; build system <http://www.cmake.org>`_. :doc:`Docker`; A reference for using Dockerfiles provided with LLVM. :doc:`Support Library <SupportLibrary>`; This document describes the LLVM Support Library (``lib/Support``) and; how to keep LLVM source code portable. :doc:`AdvancedBuilds`; This document describes more advanced build configurations. Optimizations; -------------. :doc:`WritingAnLLVMPass`; Information on how to write LLVM transformations and analyses. :doc:`WritingAnLLVMNewPMPass`; Information on how to write LLVM transformations under the new pass; manager. :doc:`Passes`; A list of optimizations and analyses implemented in LLVM. :doc:`StackSafetyAnalysis`; This document describes the design of the stack safety analysis of local; variables. :doc:`MergeFunctions`; Describes functions merging optimization. :doc:`AliasAnalysis`; Information on how to write a new alias analysis implementation or how to; use existing analyses. :doc:`MemorySSA`; Information about the MemorySSA utility in LLVM, as well as how to use it. :doc:`LoopTerminology`; A document describing Loops and associated terms as used in LLVM. :doc:`CycleTerminology`; A document describing cycles as a generalization of loops. :doc:`Vectorizers`; This document describes the current status of vectorization in LLVM. :doc:`LinkTimeOptimization`; This document describes the interface between LLVM intermodular optimizer; and the linker and its design. :doc:`GoldPlugin`; How to build your programs with link-time optimization on Linux. :doc:`Remarks`; A reference on the implementation of remarks in LLVM. :doc:`Source Level Debugging with LLVM <SourceLevelDebugging>`; This document describes the design and philosophy",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:2977,safe,safety,2977,interpreter/llvm-project/llvm/docs/UserGuides.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst,1,['safe'],['safety']
Safety," Git view, with git-svn; git clone https://llvm.org/git/llvm.git; cd llvm; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l # -l avoids fetching ahead of the git mirror. Commits are performed using `svn commit` or with the sequence `git commit` and; `git svn dcommit`. .. _workflow-multicheckout-nocommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. With the monorepo variant, there are a few options, depending on your; constraints. First, you could just clone the full repository:. git clone https://github.com/llvm/llvm-project.git. At this point you have every sub-project (llvm, clang, lld, lldb, ...), which; :ref:`doesn't imply you have to build all of them <build_single_project>`. You; can still build only compiler-rt for instance. In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checkout; git read-tree -mu HEAD. The data for all sub-projects is still in your `.git` directory, but in your; checkout, you only see `compiler-rt`.; Before you push, you'll need to fetch and rebase (`git pull --rebase`) as; usual. Note that when you fetch you'll likely pull in changes to sub-projects you don't; care about. If you are using sparse checkout, the files from other projects; won't appear on your disk. The only effect is that your commit hash changes. You can check whether the changes in the last fetch are relevant to your commit; by running::. git log origin/main@{1}..origin/main -- libcxx. This command can be hidden in a script so that `git llvmpush` would perform all; these steps, fail only if such a dependent change exists, and show immediately; the change that prevented the push. An immediate repeat of the command would; (almost) certai",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:13970,avoid,avoid,13970,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['avoid'],['avoid']
Safety," If the formal result type of such a method is ``id`` or protocol-qualified; ``id``, or a type equal to the declaring class or a superclass, then it is said; to have a related result type. In this case, when invoked in an explicit; message send, it is assumed to return a type related to the type of the; receiver:. * if it is a class method, and the receiver is a class name ``T``, the message; send expression has type ``T*``; otherwise; * if it is an instance method, and the receiver has type ``T``, the message; send expression has type ``T``; otherwise; * the message send expression has the normal result type of the method. This is a new rule of the Objective-C language and applies outside of ARC. .. admonition:: Rationale. ARC's automatic code emission is more prone than most code to signature; errors, i.e. errors where a call was emitted against one method signature,; but the implementing method has an incompatible signature. Having more; precise type information helps drastically lower this risk, as well as; catching a number of latent bugs. .. _arc.optimization:. Optimization; ============. Within this section, the word :arc-term:`function` will be used to; refer to any structured unit of code, be it a C function, an; Objective-C method, or a block. This specification describes ARC as performing specific ``retain`` and; ``release`` operations on retainable object pointers at specific; points during the execution of a program. These operations make up a; non-contiguous subsequence of the computation history of the program.; The portion of this sequence for a particular retainable object; pointer for which a specific function execution is directly; responsible is the :arc-term:`formal local retain history` of the; object pointer. The corresponding actual sequence executed is the; `dynamic local retain history`. However, under certain circumstances, ARC is permitted to re-order and; eliminate operations in a manner which may alter the overall; computation history be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:75414,risk,risk,75414,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['risk'],['risk']
Safety," It was decided that because original variable sources could be; reconstructed from SSA form in linear time, that it would be an; unjustified expense for the common case to include the extra; information for one optimization. Alias analysis itself is typically; greater than linear in asymptotic complexity, so this extra analaysis; would not affect the runtime of the optimization in a significant; way. Additionally, this would be an unlikely optimization to do at; runtime. IDEAS TO CONSIDER; -----------------. 1. Including dominator information in the LLVM bytecode; representation. This is one example of an analysis result that may be; packaged with the bytecodes themselves. As a conceptual implementation ; idea, we could include an immediate dominator number for each basic block; in the LLVM bytecode program. Basic blocks could be numbered according; to the order of occurrence in the bytecode representation. 2. Including loop header and body information. This would facilitate; detection of intervals and natural loops. UNRESOLVED ISSUES ; ----------------- . 1. Will oSUIF provide enough of an infrastructure to support the research; that we will be doing? We know that it has less than stellar; performance, but hope that this will be of little importance for our; static compiler. This could affect us if we decided to do some IP; research. Also we do not yet understand the level of exception support; currently implemented. 2. Should we consider the requirements of a direct hardware implementation; of the LLVM when we design it? If so, several design issues should; have their priorities shifted. The other option is to focus on a; software layer interpreting the LLVM in all cases. 3. Should we use some form of packetized format to improve forward; compatibility? For example, we could design the system to encode a; packet type and length field before analysis information, to allow a; runtime to skip information that it didn't understand in a bytecode; stream. The obvious be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt:1745,detect,detection,1745,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt,1,['detect'],['detection']
Safety," Kernel Estimation in High-Energy; Physics. Computer Physics Communications 136:198-207,2001"" -; e-Print Archive: hep ex/0011057 and more information can be found; also in ""Scott DW, Multivariate Density Estimation. Theory, Practice and Visualization. New York: Wiley"",; and ""Jann Ben -, Univariate kernel; density estimation document for KDENS "".; . New TSVDUnfold class; TSVDUnfold implements the singular value decomposition based; unfolding method proposed in NIM A372, 469 (1996); [hep-ph/9509307]. The regularisation is implemented as; a discrete minimum curvature condition. This minimal implementation of; TSVDUnfold provides unfolding of one-dimensional histograms with; equal number of, not necessarily equidistant, bins in the measured and; unfolded distributions. In addition to the unfolding itself,; TSVDUnfold provides. Propagation of covariance matrices from the measured to the unfolded; spectrum via GetUnfoldCovMatrix; Evaluation of covariance matrix due to finite statistics in detector; response via GetAdetCovMatrix; Access to distribution of |d_i| useful for determining the proper; regularisation via GetD; Access to singular values via GetSV. A toy example for the use of TSVDUnfold is included in the math; tutorials (TSVDUnfoldExample.C). New TH2Poly class; TH2Poly is a 2D Histogram class, inheriting from TH2,; allowing to define polygonal bins of arbitary shape. Each bin, in a TH2Poly histogram, is a TH2PolyBin object.; TH2PolyBin is a very simple class containing the vertices, stored; as TGraphs and TMultiGraphs, and the content of the polygonal; bin. Bins are defined using one of the AddBin() methods. The bins definition; should be done before filling. TH2Poly implements a partitioning algorithm to speed up bins' filling.; The following very simple macro shows how to build and fill a TH2Poly:. {; TH2Poly *h2p = new TH2Poly();. Double_t x1[] = {0, 5, 5};; Double_t y1[] = {0, 0, 5};; Double_t x2[] = {0, -1, -1, 0};; Double_t y2[] = {0, 0, -1, -1};; Double_t x",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v528/index.html:12210,detect,detector,12210,hist/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v528/index.html,1,['detect'],['detector']
Safety," KeysList; 20010404/092347 At:8976 N=53 FreeSegments; 20010404/092347 At:9029 N=1 END; ```. The second to last entry is a list of free segments. In our case, this; starts 8976 and is not very long, only 53 bytes, since we have not; deleted any objects. The last entry is the address of the last byte in; the file. ### File Recovery. A file may become corrupted or it may be impossible to write it to disk; and close it properly. For example if the file is too large and exceeds; the disk quota, or the job crashes or a batch job reaches its time limit; before the file can be closed. In these cases, it is imperative to; recover and retain as much information as possible. ROOT provides an; intelligent and elegant file recovery mechanism using the redundant; directory information in the record header. If a file that has been not properly closed is opened again, it is; scanned and rebuilt according to the information in the record header.; The recovery algorithm reads the file and creates the saved objects in; memory according to the header information. It then rebuilds the; directory and file structure. If the file is opened in write mode, the; recovery makes the correction on disk when the file is closed; however; if the file is opened in read mode, the correction can not be written to; disk. You can also explicitly invoke the recovery procedure by calling; the `TFile::Recover()` method. You can recover the directory structure,; but you cannot save what you recovered to the file on disk. In the; following example, we interrupted and aborted the previous ROOT session,; causing the file not to be closed. When we start a new session and; attempt to open the file, it gives us an explanation and status on the; recovery attempt. ``` {.cpp}; root[] TFile f(""demo.root""); Warning in <TFile::TFile>: file demo.root probably not closed, trying to recover successfully recovered 15 keys; ```. ## The Logical ROOT File: TFile and TKey. We saw that the `TFile::Map()` method reads the file se",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:15325,recover,recovery,15325,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['recover'],['recovery']
Safety," LLVM, the community realized that pointee types were; more of a hindrance for LLVM development and that the extra type checking with; some frontends wasn't worth it. LLVM's type system was `originally designed; <https://llvm.org/pubs/2003-05-01-GCCSummit2003.html>`_ to support high-level; optimization. However, years of LLVM implementation experience have demonstrated; that the pointee type system design does not effectively support; optimization. Memory optimization algorithms, such as SROA, GVN, and AA,; generally need to look through LLVM's struct types and reason about the; underlying memory offsets. The community realized that pointee types hinder LLVM; development, rather than helping it. Some of the initially proposed high-level; optimizations have evolved into `TBAA; <https://llvm.org/docs/LangRef.html#tbaa-metadata>`_ due to limitations with; representing higher-level language information directly via SSA values. Pointee types provide some value to frontends because the IR verifier uses types; to detect straightforward type confusion bugs. However, frontends also have to; deal with the complexity of inserting bitcasts everywhere that they might be; required. The community consensus is that the costs of pointee types; outweight the benefits, and that they should be removed. Many operations do not actually care about the underlying type. These; operations, typically intrinsics, usually end up taking an arbitrary pointer; type ``i8*`` and sometimes a size. This causes lots of redundant no-op bitcasts; in the IR to and from a pointer with a different pointee type. No-op bitcasts take up memory/disk space and also take up compile time to look; through. However, perhaps the biggest issue is the code complexity required to; deal with bitcasts. When looking up through def-use chains for pointers it's; easy to forget to call `Value::stripPointerCasts()` to find the true underlying; pointer obfuscated by bitcasts. And when looking down through def-use chains; passes ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst:3189,detect,detect,3189,interpreter/llvm-project/llvm/docs/OpaquePointers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst,1,['detect'],['detect']
Safety," Let us focus on the biggest pack - it is mandatory to; define one. Consider the simplest geometry that is made of a single box.; Here is an example on how to build it:. \anchor GP00a; ### Example 1: Creating the World. We first need to load the geometry library. This is not needed if one; does ""make map"" in root folder. ~~~{.cpp}; root[] gSystem->Load(""libGeom"");; ~~~. Second, we have to create an instance of the geometry manager class.; This takes care of all the modeller components, performing several tasks; to insure geometry validity and containing the user interface for; building and interacting with the geometry. After its creation, the; geometry manager class can be accessed with the global; `gGeoManager`:. ~~~{.cpp}; root[] new TGeoManager(""world"", ""the simplest geometry"");; ~~~. We want to create a single volume in our geometry, but since any volume; needs to have an associated medium, we will create a dummy one. You can; safely ignore the following lines for the time being, since materials; and media will be explained in detail later on. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""Vacuum"",0,0,0);; root[] TGeoMedium *med = new TGeoMedium(""Vacuum"",1,mat);; ~~~. We can finally make our volume having a box shape. Note that the world; volume does not need to be a box - it can be any other shape. Generally,; boxes and tubes are the most recommendable shapes for this purpose due; to their fast navigation algorithms. ~~~{.cpp}; root[] TGeoVolume *top=gGeoManager->MakeBox(""Top"",med,10.,10.,10.);; ~~~. The default units are in centimeters. Now we want to make this volume; our world. We have to do this operation **before** closing the geometry. ~~~{.cpp}; root[] gGeoManager->SetTopVolume(top);; ~~~. This should be enough, but it is not since always after defining some; geometry hierarchy, TGeo needs to build some optimization; structures and perform some checks. Note the messages posted after the; statement is executed. We will describe the corresponding",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:5633,safe,safely,5633,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['safe'],['safely']
Safety," Like :option:`-O2` with extra optimizations to reduce code; size. :option:`-Oz` Like :option:`-Os` (and thus :option:`-O2`), but reduces code; size further. :option:`-Og` Like :option:`-O1`. In future versions, this option might; disable different optimizations in order to improve debuggability. :option:`-O` Equivalent to :option:`-O1`. :option:`-O4` and higher. Currently equivalent to :option:`-O3`. .. option:: -g, -gline-tables-only, -gmodules. Control debug information output. Note that Clang debug information works; best at :option:`-O0`. When more than one option starting with `-g` is; specified, the last one wins:. :option:`-g` Generate debug information. :option:`-gline-tables-only` Generate only line table debug information. This; allows for symbolicated backtraces with inlining information, but does not; include any information about variables, their locations or types. :option:`-gmodules` Generate debug information that contains external; references to types defined in Clang modules or precompiled headers instead; of emitting redundant debug type information into every object file. This; option transparently switches the Clang module format to object file; containers that hold the Clang module together with the debug information.; When compiling a program that uses Clang modules or precompiled headers,; this option produces complete debug information with faster compile; times and much smaller object files. This option should not be used when building static libraries for; distribution to other machines because the debug info will contain; references to the module cache on the machine the object files in the; library were built on. .. option:: -fstandalone-debug -fno-standalone-debug. Clang supports a number of optimizations to reduce the size of debug; information in the binary. They work based on the assumption that the; debug type information can be spread out over multiple compilation units.; For instance, Clang will not emit type definitions for types",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:12185,redund,redundant,12185,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['redund'],['redundant']
Safety," Making a volume with a given shape in one step; TGeoVolume *vol = gGeoManager->MakeBox(""VNAME"",ptrMed,dx,dy,dz);; TGeoVolume *vol = gGeoManager->MakeTubs(""VNAME"",ptrMed,rmin,rmax,; dz,phi1,phi2);. // See class TGeoManager for the rest of shapes.; // Making a volume with a given shape with a unique prototype; TGeoVolume *vol = gGeoManager->Volume(""VNAME"",""XXXX"",nmed,upar,; npar);. // Where XXXX stands for the first 4 letters of the specific shape; // classes, nmed is the medium number, upar is an Double_t * array; // of the shape parameters and npar is the number of parameters.; // This prototype allows (npar = 0) to define volumes with shape; // defined only at positioning time (volumes defined in this way; // need to be positioned using TGeoManager::Node() method); ```. #### Positioned Volumes (Nodes). Geometrical modeling is a difficult task when the number of different; geometrical objects is 106-108. This is more or less the case for; detector geometries of complex experiments, where a ‘flat' CSG model; description cannot scale with the current CPU performances. This is the; reason why models like GEANT [1] introduced an additional dimension; (depth) in order to reduce the complexity of the problem. This concept; is also preserved by the ROOT modeller and introduces a pure geometrical; constraint between objects (volumes in our case) - containment. This; means in fact that any positioned volume has to be contained by another.; Now what means contained and positioned?. - We will say that a volume `contains` a point if this is inside the; shape associated to the volume. For instance, a volume having a box; shape will contain all points `P=(X,Y,Z)` verifying the conditions:; `Abs(Pi)dXi`. The points on the shape boundaries are considered as; inside the volume. The volume contains a daughter if it contains all; the points contained by the daughter.; - The definition of containment works of course only with points; defined in the local coordinate system of the consid",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:65738,detect,detector,65738,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['detect'],['detector']
Safety," Notes. The RNTuple binary format version is inspired by semantic versioning.; It uses the following scheme: EPOCH.MAJOR.MINOR.PATCH. _Epoch_: an increment of the epoch indicates backward-incompatible changes.; The RNTuple pre-release has epoch 0.; The first public release will get epoch 1.; There is currently no further epoch foreseen. _Major_: an increment of the major version indicates forward-incompatible changes.; A forward-incompatible change is known to break reading in previous software versions that do not support that feature.; The use of new, forward-incompatible features must be indicated in the feature flag in the header (see below).; For the RNTuple pre-release (epoch == 0), the major version is the release candidate number. _Minor_: an increment of the minor version indicates new, optional format features.; Such optional features, although unknown to previous software versions,; won't prevent those software versions from properly reading the file.; Old readers will safely ignore these features. _Patch_: an increment of the patch version indicates backported features from newer format versions.; The backported features may correspond to a major or a minor release. Except for the epoch, the versioning is for reporting only.; Readers should use the feature flag in the header to determine whether they support reading the file. ## Introduction. The RNTuple binary format describes the serialized, on-disk representation of an RNTuple data set.; The data on disk is organized in **pages** (typically tens to hundreds of kilobytes in size); and several **envelopes** that contain information about the data such as header and footer.; The RNTuple format specifies the binary layout of the pages and the envelopes. Pages and envelopes are meant to be embedded in a data container; such as a ROOT file or a set of objects in an object store.; Envelopes can reference other envelopes and pages by means of a **locator** or an **envelope link**;; for a file embedding, the l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:1140,safe,safely,1140,tree/ntuple/v7/doc/BinaryFormatSpecification.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md,1,['safe'],['safely']
Safety," ON). option(LLVM_ENABLE_CRASH_OVERRIDES ""Enable crash overrides."" ON); if(LLVM_ENABLE_CRASH_OVERRIDES); set(ENABLE_CRASH_OVERRIDES 1); endif(). option(LLVM_ENABLE_CRASH_DUMPS ""Turn on memory dumps on crashes. Currently only implemented on Windows."" OFF). set(WINDOWS_PREFER_FORWARD_SLASH_DEFAULT OFF); if (MINGW); # Cygwin doesn't identify itself as Windows, and thus gets path::Style::posix; # as native path style, regardless of what this is set to.; set(WINDOWS_PREFER_FORWARD_SLASH_DEFAULT ON); endif(); option(LLVM_WINDOWS_PREFER_FORWARD_SLASH ""Prefer path names with forward slashes on Windows."" ${WINDOWS_PREFER_FORWARD_SLASH_DEFAULT}). option(LLVM_ENABLE_FFI ""Use libffi to call external functions from the interpreter"" OFF); set(FFI_LIBRARY_DIR """" CACHE PATH ""Additional directory, where CMake should search for libffi.so""); set(FFI_INCLUDE_DIR """" CACHE PATH ""Additional directory, where CMake should search for ffi.h or ffi/ffi.h""). set(LLVM_TARGET_ARCH ""host""; CACHE STRING ""Set target to use for LLVM JIT or use \""host\"" for automatic detection.""). option(LLVM_ENABLE_TERMINFO ""Use terminfo database if available."" ON). set(LLVM_ENABLE_LIBXML2 ""ON"" CACHE STRING ""Use libxml2 if available. Can be ON, OFF, or FORCE_ON""). option(LLVM_ENABLE_LIBEDIT ""Use libedit if available."" ON). option(LLVM_ENABLE_LIBPFM ""Use libpfm for performance counters if available."" ON). # On z/OS, threads cannot be used because TLS is not supported.; if (CMAKE_SYSTEM_NAME MATCHES ""OS390""); option(LLVM_ENABLE_THREADS ""Use threads if available."" OFF); else(); option(LLVM_ENABLE_THREADS ""Use threads if available."" ON); endif(). set(LLVM_ENABLE_ZLIB ""ON"" CACHE STRING ""Use zlib for compression/decompression if available. Can be ON, OFF, or FORCE_ON""). set(LLVM_ENABLE_ZSTD ""ON"" CACHE STRING ""Use zstd for compression/decompression if available. Can be ON, OFF, or FORCE_ON""). set(LLVM_USE_STATIC_ZSTD FALSE CACHE BOOL ""Use static version of zstd. Can be TRUE, FALSE""). set(LLVM_ENABLE_CURL ""OFF"" CACHE STRING """,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:21889,detect,detection,21889,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['detect'],['detection']
Safety," OUTPUT_NAME LLVM ${INSTALL_WITH_TOOLCHAIN} ${SOURCES}); # Add symlink for backwards compatibility with old library name; llvm_install_library_symlink(LLVM-${LLVM_VERSION_MAJOR}${LLVM_VERSION_SUFFIX} $<TARGET_FILE_NAME:LLVM> SHARED FULL_DEST COMPONENT LLVM); endif(). list(REMOVE_DUPLICATES LIB_NAMES); if(""${CMAKE_SYSTEM_NAME}"" STREQUAL ""Darwin""); set(LIB_NAMES -Wl,-all_load ${LIB_NAMES}); else(); configure_file(; ${CMAKE_CURRENT_SOURCE_DIR}/simple_version_script.map.in; ${LLVM_LIBRARY_DIR}/tools/llvm-shlib/simple_version_script.map). # GNU ld doesn't resolve symbols in the version script.; set(LIB_NAMES -Wl,--whole-archive ${LIB_NAMES} -Wl,--no-whole-archive); if (NOT LLVM_LINKER_IS_SOLARISLD AND NOT MINGW); # Solaris ld does not accept global: *; so there is no way to version *all* global symbols; set(LIB_NAMES -Wl,--version-script,${LLVM_LIBRARY_DIR}/tools/llvm-shlib/simple_version_script.map ${LIB_NAMES}); endif(); if (NOT MINGW AND NOT LLVM_LINKER_IS_SOLARISLD_ILLUMOS); # Optimize function calls for default visibility definitions to avoid PLT and; # reduce dynamic relocations.; # Note: for -fno-pic default, the address of a function may be different from; # inside and outside libLLVM.so.; target_link_options(LLVM PRIVATE LINKER:-Bsymbolic-functions); endif(); endif(). target_link_libraries(LLVM PRIVATE ${LIB_NAMES}). if(LLVM_ENABLE_THREADS AND NOT HAVE_CXX_ATOMICS64_WITHOUT_LIB); target_link_libraries(LLVM PUBLIC atomic); endif(). if (APPLE); set_property(TARGET LLVM APPEND_STRING PROPERTY; LINK_FLAGS; "" -compatibility_version 1 -current_version ${LLVM_VERSION_MAJOR}.${LLVM_VERSION_MINOR}.${LLVM_VERSION_PATCH}""); endif(). if(TARGET libLLVMExports); add_dependencies(LLVM libLLVMExports); endif(); endif(). if(LLVM_BUILD_LLVM_C_DYLIB AND NOT MSVC); if(NOT APPLE); message(FATAL_ERROR ""Generating libLLVM-c is only supported on Darwin""); endif(). if(NOT LLVM_BUILD_LLVM_DYLIB); message(FATAL_ERROR ""Generating libLLVM-c requires LLVM_BUILD_LLVM_C_DYLIB on Darwin""); endif",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt:2415,avoid,avoid,2415,interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt,1,['avoid'],['avoid']
Safety," Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Arthur Tsang, CERN/SFT, \; Peter van Gemmeren, ANL,\; Vassil Vassilev, Princeton Univ./CMS,\; Xavier Valls Pla, CERN/UJI, \; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, KIT,\; Omar Zapata. ## General News. This release now supports building with C++17 enabled using either libstdc++ or; libc++. This requires Clang >= 5.0, or GCC >= 7.3.0. At the date of this; release, GCC 7.2.0 still does not provide full support to compile ROOT with C++17. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.10. - Remove the deprecated `TSelectorCint.h` and `TSelectorCint.cxx`.; - Remove the deprecated `Riosfwd.h` and `Rtypeinfo.h`.; - `TTreeReader::SetLastEntry()` was replaced by `TTreeReader::SetEntriesRange()`. ## Core Libraries. - Added support for XCode 9 and MacOS High Sierra.; - When invoking root with the ""-t"" argument, ROOT enables thread-safety and,; if configured, implicit multithreading within ROOT.; - `NULL` is not defined by `Rtypes.h` anymore. Instead, its definition is expected to be; provided by `Rtype.h`'s `#include` of `stddef.h`.; - ROOT now supports dictionaries, autoload and autoparse for classes with template parameter packs.; - std::make_unique has been backported; - If a class overloads TObject::Hash, this derived class should also add; ```; ROOT::CallRecursiveRemoveIfNeeded(*this); ```; Otherwise, when RecursiveRemove is called (by ~TObject or example) for this; type of object, the transversal of THashList and THashTable containers will; will have to be done without call Hash (and hence be linear rather than; logarithmic complexity). You will also see warnings like; ```; Error in <ROOT::Internal::TCheckHashRecursiveRemoveConsistency::CheckRecursiveRemove>: The class SomeName overrides TObject::Hash but does not call TROOT::RecursiveRemove in its destructor.; ```; - When a container relies on TObject::H",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:1771,safe,safety,1771,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['safe'],['safety']
Safety," RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made GC parseable by wrapping the; call into a statepoint. This makes it possible to take a safepoint during; copy operation. Note that a GC parseable copy operation is not required to; take a safepoint. For example, a short copy operation may be performed without; taking a safepoint. GC parseable calls to '``llvm.memcpy.element.unordered.atomic.*``',; '``llvm.memmove.element.unordered.atomic.*``' intrinsics are lowered to calls; to '``__llvm_memcpy_element_unordered_atomic_safepoint_*``',; '``__llvm_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:30008,safe,safepoint,30008,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['safe'],['safepoint']
Safety," The string '``undef``' can be used anywhere a constant is expected, and; indicates that the user of the value may receive an unspecified; bit-pattern. Undefined values may be of any type (other than '``label``'; or '``void``') and be used anywhere a constant is permitted. .. note::. A '``poison``' value (described in the next section) should be used instead of; '``undef``' whenever possible. Poison values are stronger than undef, and; enable more optimizations. Just the existence of '``undef``' blocks certain; optimizations (see the examples below). Undefined values are useful because they indicate to the compiler that; the program is well defined no matter what value is used. This gives the; compiler more freedom to optimize. Here are some examples of; (potentially surprising) transformations that are valid (in pseudo IR):. .. code-block:: llvm. %A = add %X, undef; %B = sub %X, undef; %C = xor %X, undef; Safe:; %A = undef; %B = undef; %C = undef. This is safe because all of the output bits are affected by the undef; bits. Any output bit can have a zero or one depending on the input bits. .. code-block:: llvm. %A = or %X, undef; %B = and %X, undef; Safe:; %A = -1; %B = 0; Safe:; %A = %X ;; By choosing undef as 0; %B = %X ;; By choosing undef as -1; Unsafe:; %A = undef; %B = undef. These logical operations have bits that are not always affected by the; input. For example, if ``%X`` has a zero bit, then the output of the; '``and``' operation will always be a zero for that bit, no matter what; the corresponding bit from the '``undef``' is. As such, it is unsafe to; optimize or assume that the result of the '``and``' is '``undef``'.; However, it is safe to assume that all bits of the '``undef``' could be; 0, and optimize the '``and``' to 0. Likewise, it is safe to assume that; all the bits of the '``undef``' operand to the '``or``' could be set,; allowing the '``or``' to be folded to -1. .. code-block:: llvm. %A = select undef, %X, %Y; %B = select undef, 42, %Y; %C = se",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:191719,safe,safe,191719,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['safe'],['safe']
Safety," Unix-like platforms, LLVM requires the presence of GCC's atomic; intrinsics in order to support threaded operation. If you need a; multithreading-capable LLVM on a platform without a suitably modern system; compiler, consider compiling LLVM and LLVM-GCC in single-threaded mode, and; using the resultant compiler to build a copy of LLVM with multithreading; support. .. _shutdown:. Ending Execution with ``llvm_shutdown()``; -----------------------------------------. When you are done using the LLVM APIs, you should call ``llvm_shutdown()`` to; deallocate memory used for internal structures. .. _managedstatic:. Lazy Initialization with ``ManagedStatic``; ------------------------------------------. ``ManagedStatic`` is a utility class in LLVM used to implement static; initialization of static resources, such as the global type tables. In a; single-threaded environment, it implements a simple lazy initialization scheme.; When LLVM is compiled with support for multi-threading, however, it uses; double-checked locking to implement thread-safe lazy initialization. .. _llvmcontext:. Achieving Isolation with ``LLVMContext``; ----------------------------------------. ``LLVMContext`` is an opaque class in the LLVM API which clients can use to; operate multiple, isolated instances of LLVM concurrently within the same; address space. For instance, in a hypothetical compile-server, the compilation; of an individual translation unit is conceptually independent from all the; others, and it would be desirable to be able to compile incoming translation; units concurrently on independent server threads. Fortunately, ``LLVMContext``; exists to enable just this kind of scenario!. Conceptually, ``LLVMContext`` provides isolation. Every LLVM entity; (``Module``\ s, ``Value``\ s, ``Type``\ s, ``Constant``\ s, etc.) in LLVM's; in-memory IR belongs to an ``LLVMContext``. Entities in different contexts; *cannot* interact with each other: ``Module``\ s in different contexts cannot be; linked to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:122458,safe,safe,122458,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['safe'],['safe']
Safety," Value Types...; static const MVT::ValueType IntRegsVTs[] = {; MVT::i32, MVT::Other; };. namespace SP { // Register class instances; DFPRegsClass DFPRegsRegClass;; FPRegsClass FPRegsRegClass;; IntRegsClass IntRegsRegClass;; ...; // IntRegs Sub-register Classes...; static const TargetRegisterClass* const IntRegsSubRegClasses [] = {; NULL; };; ...; // IntRegs Super-register Classes..; static const TargetRegisterClass* const IntRegsSuperRegClasses [] = {; NULL; };; ...; // IntRegs Register Class sub-classes...; static const TargetRegisterClass* const IntRegsSubclasses [] = {; NULL; };; ...; // IntRegs Register Class super-classes...; static const TargetRegisterClass* const IntRegsSuperclasses [] = {; NULL; };. IntRegsClass::IntRegsClass() : TargetRegisterClass(IntRegsRegClassID,; IntRegsVTs, IntRegsSubclasses, IntRegsSuperclasses, IntRegsSubRegClasses,; IntRegsSuperRegClasses, 4, 4, 1, IntRegs, IntRegs + 32) {}; }. The register allocators will avoid using reserved registers, and callee saved; registers are not used until all the volatile registers have been used. That; is usually good enough, but in some cases it may be necessary to provide custom; allocation orders. Implement a subclass of ``TargetRegisterInfo``; ----------------------------------------------. The final step is to hand code portions of ``XXXRegisterInfo``, which; implements the interface described in ``TargetRegisterInfo.h`` (see; :ref:`TargetRegisterInfo`). These functions return ``0``, ``NULL``, or; ``false``, unless overridden. Here is a list of functions that are overridden; for the SPARC implementation in ``SparcRegisterInfo.cpp``:. * ``getCalleeSavedRegs`` --- Returns a list of callee-saved registers in the; order of the desired callee-save stack frame offset. * ``getReservedRegs`` --- Returns a bitset indexed by physical register; numbers, indicating if a particular register is unavailable. * ``hasFP`` --- Return a Boolean indicating if a function should have a; dedicated frame pointer register.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:26043,avoid,avoid,26043,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['avoid'],['avoid']
Safety," `Browser Help → About ROOT`. ## Deprecation and Removal; * rootcling flags `-cint`, `-gccxml`, `-p`, `-r` and `-c` have no effect; and will be removed. Please remove them from the rootcling invocations.; * rootcling legacy cint flags `+P`, `+V` and `+STUB` have no effect and will be; removed. Please remove them from the rootcling invocations.; * genreflex flag `--deep` has no effect and will be removed. Please remove it; from the genreflex invocation.; * rootcling warns if it sees and unrecognized flag (usually coming from the; CXXFLAGS of the build system). Please remove them from the invocation because; the warning will become a hard error in the next releases.; * The empty headers `Gtypes.h` and `Htypes.h` are deprecated. Please include; `Rtypes.h`; * TInterpreter::EnableAutoLoading currently does nothing and is deprecated. ### Deprecated packages. ### Removed packages. ## Core Libraries. * Speed-up startup, in particular in case of no or poor network accesibility, by avoiding; a network access that was used as input to generate a globally unique ID for the current; process.; * This network access is replaced by a passive scan of the network interface. This; reduces somewhat the uniqueness of the unique ID as the IP address is no longer; guaranteed by the DNS server to be unique. Note that this was already the case when; the network access (used to look up the hostname and its IP address) failed. ## I/O Libraries. * TFile: A new bit `TFile::kReproducible` was introduced. It can be enabled by; specifying the `""reproducible""` url option when creating the file:; ~~~ {.cpp}; TFile *f = TFile::Open(""name.root?reproducible"",""RECREATE"",""File title"");; ~~~; Unlike regular `TFile`s, the content of such file has reproducible binary; content when writing exactly same data. This achieved by writing pre-defined; values for creation and modification date of TKey/TDirectory objects and null; value for TUUID objects inside TFile. As drawback, TRef objects stored in such; file c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md:2801,avoid,avoiding,2801,README/ReleaseNotes/v620/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md,1,['avoid'],['avoiding']
Safety," `ROOT::Internal` namespace (non-public interfaces),; with the notable exception of the descriptor classes (`RNTupleDescriptor`, `RFieldDescriptor`, etc.).; Most classes in the upper layers provide public interfaces. | Layer | Description | Example of classes |; |------------|---------------------------------------------------------------------|-------------------------------------------------------------|; | Storage | Read and write pages (physical: file, object store; virtual: e.g. buffered) | RPage{Source,Sink}, RNTupleDescriptor, RClusterPool |; | Primitives | Storage-backed columns of simple types | RColumn, RColumnElement, RPage |; | Logical | Mapping of C++ types onto columns | RField, RNTupleModel, REntry |; | Iteration | Reading and writing events / properties | RNTuple{Reader,Writer}, RNTupleView, RNTupleDS (RDataFrame) |; | Tooling | Higher-level, RNTuple related utility classes | RNTupleMerger, RNTupleImporter, RNTupleInspector |. The RNTuple classes are, unless explicitly stated otherwise, conditionally thread safe. The read and write APIs provide templated, compile-time type-safe APIs,; APIs where the type at hand is passed as string and which are runtime type-safe,; and type-unsafe APIs using void pointers. On I/O errors and invalid input, RNTuple classes throw an `RException`. Walkthrough: Reading Data; -------------------------. ```c++; auto file = std::make_unique<TFile>(""data.root"");; auto ntuple = std::unique_ptr<RNTuple>(file->Get<RNTuple>(""ntpl""));. // Option 1: entire row; // The reader creates a page source; the page source creates a model from the on-disk information; auto reader = RNTupleReader::Open(ntuple);; // Populate the objects that are used in the model's default entry; reader->LoadEntry(0);; std::shared_ptr<float> pt = reader->GetDefaultEntry().GetPtr<float>(""pt"");. // Option 2: imposed model; auto model = RNTupleModel::Create();; auto pt = model->MakeField<float>(""pt"");; // The reader checks the passed model for compatibility; only",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:2026,safe,safe,2026,tree/ntuple/v7/doc/Architecture.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md,1,['safe'],['safe']
Safety," ``MyVar+40``, and the value of; ``%idx2`` is also ``MyVar+40``. Can GEP index into vector elements?; -----------------------------------. This hasn't always been forcefully disallowed, though it's not recommended. It; leads to awkward special cases in the optimizers, and fundamental inconsistency; in the IR. In the future, it will probably be outright disallowed. What effect do address spaces have on GEPs?; -------------------------------------------. None, except that the address space qualifier on the second operand pointer type; always matches the address space qualifier on the result type. How is GEP different from ``ptrtoint``, arithmetic, and ``inttoptr``?; ---------------------------------------------------------------------. It's very similar; there are only subtle differences. With ptrtoint, you have to pick an integer type. One approach is to pick i64;; this is safe on everything LLVM supports (LLVM internally assumes pointers are; never wider than 64 bits in many places), and the optimizer will actually narrow; the i64 arithmetic down to the actual pointer size on targets which don't; support 64-bit arithmetic in most cases. However, there are some cases where it; doesn't do this. With GEP you can avoid this problem. Also, GEP carries additional pointer aliasing rules. It's invalid to take a GEP; from one object, address into a different separately allocated object, and; dereference it. IR producers (front-ends) must follow this rule, and consumers; (optimizers, specifically alias analysis) benefit from being able to rely on; it. See the `Rules`_ section for more information. And, GEP is more concise in common cases. However, for the underlying integer computation implied, there is no; difference. I'm writing a backend for a target which needs custom lowering for GEP. How do I do this?; -----------------------------------------------------------------------------------------. You don't. The integer computation implied by a GEP is target-independent.; Typ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:9920,safe,safe,9920,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['safe'],['safe']
Safety," ``__block`` variables did not implicitly retain during capture. ``__block`` variables of retainable object owner type are moved off the stack; by initializing the heap copy with the result of moving from the stack copy. With the exception of retains done as part of initializing a ``__strong``; parameter variable or reading a ``__weak`` variable, whenever these semantics; call for retaining a value of block-pointer type, it has the effect of a; ``Block_copy``. The optimizer may remove such copies when it sees that the; result is used only as an argument to a call. When a block pointer type is converted to a non-block pointer type (such as; ``id``), ``Block_copy`` is called. This is necessary because a block allocated; on the stack won't get copied to the heap when the non-block pointer escapes.; A block pointer is implicitly converted to ``id`` when it is passed to a; function as a variadic argument. .. _arc.misc.exceptions:. Exceptions; ----------. By default in Objective C, ARC is not exception-safe for normal releases:. * It does not end the lifetime of ``__strong`` variables when their scopes are; abnormally terminated by an exception.; * It does not perform releases which would occur at the end of a; full-expression if that full-expression throws an exception. A program may be compiled with the option ``-fobjc-arc-exceptions`` in order to; enable these, or with the option ``-fno-objc-arc-exceptions`` to explicitly; disable them, with the last such argument ""winning"". .. admonition:: Rationale. The standard Cocoa convention is that exceptions signal programmer error and; are not intended to be recovered from. Making code exceptions-safe by; default would impose severe runtime and code size penalties on code that; typically does not actually care about exceptions safety. Therefore,; ARC-generated code leaks by default on exceptions, which is just fine if the; process is going to be immediately terminated anyway. Programs which do care; about recovering from except",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:97735,safe,safe,97735,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['safe'],['safe']
Safety," ``__unsafe_terminated_by_to_indexable(P, T)`` (or; ``__unsafe_null_terminated_to_indexable(P)``) which converts the; ``__terminated_by`` pointer ``P`` to an ``__indexable`` pointer. * ``__null_terminated`` : The pointer or array is terminated by ``NULL`` or; ``0``. Modifying the terminator or incrementing the pointer beyond it is; prevented at run time. * ``__terminated_by(T)`` : The pointer or array is terminated by ``T`` which is; a constant expression. Accessing or incrementing the pointer beyond the; terminator is not allowed. This is a generalization of ``__null_terminated``; which is defined as ``__terminated_by(0)``. Annotation for interoperating with bounds-unsafe code; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A pointer with the ``__unsafe_indexable`` annotation behaves the same as a plain; C pointer. That is, the pointer does not have any bounds information and pointer; operations are not checked. ``__unsafe_indexable`` can be used to mark pointers from system headers or; pointers from code that has not adopted -fbounds safety. This enables; interoperation between code using ``-fbounds-safety`` and code that does not. Default pointer types; ---------------------. ABI visibility and default annotations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Requiring ``-fbounds-safety`` adopters to add bounds annotations to all pointers; in the codebase would be a significant adoption burden. To avoid this and to; secure all pointers by default, ``-fbounds-safety`` applies default bounds; annotations to pointer types.; Default annotations apply to pointer types of declarations. ``-fbounds-safety`` applies default bounds annotations to pointer types used in; declarations. The default annotations are determined by the ABI visibility of; the pointer. A pointer type is ABI-visible if changing its size or; representation affects the ABI. For instance, changing the size of a type used; in a function parameter will affect the ABI and thus pointers used in function; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:19839,safe,safety,19839,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['safe'],['safety']
Safety," ``__weak`` objects, the current pointee is retained and then released at; the end of the current full-expression. In particular, messaging a ``__weak``; object keeps the object retained until the end of the full expression. .. code-block:: objc. __weak MyObject *weakObj;. void foo() {; // weakObj is retained before the message send and released at the end of; // the full expression.; [weakObj m];; }. This must execute atomically with respect to assignments and to the final; release of the pointee.; * For all other objects, the lvalue is loaded with primitive semantics. :arc-term:`Assignment` occurs when evaluating an assignment operator. The; semantics vary based on the qualification:. * For ``__strong`` objects, the new pointee is first retained; second, the; lvalue is loaded with primitive semantics; third, the new pointee is stored; into the lvalue with primitive semantics; and finally, the old pointee is; released. This is not performed atomically; external synchronization must be; used to make this safe in the face of concurrent loads and stores.; * For ``__weak`` objects, the lvalue is updated to point to the new pointee,; unless the new pointee is an object currently undergoing deallocation, in; which case the lvalue is updated to a null pointer. This must execute; atomically with respect to other assignments to the object, to reads from the; object, and to the final release of the new pointee.; * For ``__unsafe_unretained`` objects, the new pointee is stored into the; lvalue using primitive semantics.; * For ``__autoreleasing`` objects, the new pointee is retained, autoreleased,; and stored into the lvalue using primitive semantics. :arc-term:`Initialization` occurs when an object's lifetime begins, which; depends on its storage duration. Initialization proceeds in two stages:. #. First, a null pointer is stored into the lvalue using primitive semantics.; This step is skipped if the object is ``__unsafe_unretained``.; #. Second, if the object has an initiali",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:38975,safe,safe,38975,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['safe'],['safe']
Safety," ``get_buf()`` which returns ``void; *__unsafe_indexable.`` Under the type rules, this cannot be directly assigned to; ``void *buf`` (implicitly ``void *__bidi_indexable``). Thus,; ``__unsafe_forge_bidi_indexable`` is used to manually create a; ``__bidi_indexable`` from the unsafe buffer. .. code-block:: c. // unsafe_library.h; void *__unsafe_indexable get_buf(void);; size_t get_buf_size(void);. // my_source1.c (enables -fbounds-safety); #include ""unsafe_library.h""; void example_forge_bidi(void) {; void *buf =; __unsafe_forge_bidi_indexable(void *, get_buf(), get_buf_size());; // ...; }. // my_source2.c (enables -fbounds-safety); #include <stdio.h>; void example_forge_single(void) {; FILE *fp = __unsafe_forge_single(FILE *, fopen(""mypath"", ""rb""));; // ...; }. * Function ``example_forge_single`` takes a file handle by calling fopen defined; in system header ``stdio.h``. Assuming ``stdio.h`` did not adopt; ``-fbounds-safety``, the return type of ``fopen`` would implicitly be ``FILE; *__unsafe_indexable`` and thus it cannot be directly assigned to ``FILE *fp``; in the bounds-safe source. To allow this operation, ``__unsafe_forge_single``; is used to create a ``__single`` from the return value of ``fopen``. * Similar to ``__unsafe_indexable``, any non-pointer type (including ``int``,; ``intptr_t``, ``uintptr_t``, etc.) cannot be converted to any safe pointer; type because these don't have bounds information. ``__unsafe_forge_single`` or; ``__unsafe_forge_bidi_indexable`` must be used to force the conversion. * Any safe pointer types can cast to ``__unsafe_indexable`` because it doesn't; have any invariant to maintain. * ``__single`` casts to ``__bidi_indexable`` if the pointee type has a known; size. After the conversion, the resulting ``__bidi_indexable`` has the size of; a single object of the pointee type of ``__single``. ``__single`` cannot cast; to ``__bidi_indexable`` if the pointee type is incomplete or sizeless. For; example, ``void *__single`` cannot convert to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:41406,safe,safety,41406,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,2,['safe'],"['safe', 'safety']"
Safety," a ``G_CONSTANT`` with; value ``1``. However, the following::. %2:_(s32) = G_FOO %0:_(s32), i32 1. can say that it's legal iff operand 2 is an immediate with value ``1`` because; that information is entirely contained within the single instruction. .. _api-legalizerinfo:. API: LegalizerInfo; ^^^^^^^^^^^^^^^^^^. The recommended [#legalizer-legacy-footnote]_ API looks like this::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legalFor({s32, s64, v2s32, v4s32, v2s64}); .clampScalar(0, s32, s64); .widenScalarToNextPow2(0); .clampNumElements(0, v2s32, v4s32); .clampNumElements(0, v2s64, v2s64); .moreElementsToNextPow2(0);. and describes a set of rules by which we can either declare an instruction legal; or decide which action to take to make it more legal. At the core of this ruleset is the ``LegalityQuery`` which describes the; instruction. We use a description rather than the instruction to both allow other; passes to determine legality without having to create an instruction and also to; limit the information available to the predicates to that which is safe to rely; on. Currently, the information available to the predicates that determine; legality contains:. * The opcode for the instruction. * The type of each type index (see ``type0``, ``type1``, etc.). * The size in bytes and atomic ordering for each MachineMemOperand. .. note::. An alternative worth investigating is to generalize the API to represent; actions using ``std::function`` that implements the action, instead of explicit; enum tokens (``Legal``, ``WidenScalar``, ...) that instruct it to call a; function. This would have some benefits, most notable being that Custom could; be removed. .. rubric:: Footnotes. .. [#legalizer-legacy-footnote] An API is broadly similar to; SelectionDAG/TargetLowering is available but is not recommended as a more; powerful API is available. Rule Processing and Declaring Rules; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The ``getActionDefinitionsBuilde",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:2964,safe,safe,2964,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,1,['safe'],['safe']
Safety," a global ``ExitOnError`` variable in your program:. .. code-block:: c++. ExitOnError ExitOnErr;. Calls to fallible functions can then be wrapped with a call to ``ExitOnErr``,; turning them into non-failing calls:. .. code-block:: c++. Error mayFail();; Expected<int> mayFail2();. void foo() {; ExitOnErr(mayFail());; int X = ExitOnErr(mayFail2());; }. On failure, the error's log message will be written to ``stderr``, optionally; preceded by a string ""banner"" that can be set by calling the setBanner method. A; mapping can also be supplied from ``Error`` values to exit codes using the; ``setExitCodeMapper`` method:. .. code-block:: c++. int main(int argc, char *argv[]) {; ExitOnErr.setBanner(std::string(argv[0]) + "" error:"");; ExitOnErr.setExitCodeMapper(; [](const Error &Err) {; if (Err.isA<BadFileFormat>()); return 2;; return 1;; });. Use ``ExitOnError`` in your tool code where possible as it can greatly improve; readability. .. _err_cantfail:. Using cantFail to simplify safe callsites; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Some functions may only fail for a subset of their inputs, so calls using known; safe inputs can be assumed to succeed. The cantFail functions encapsulate this by wrapping an assertion that their; argument is a success value and, in the case of Expected<T>, unwrapping the; T value:. .. code-block:: c++. Error onlyFailsForSomeXValues(int X);; Expected<int> onlyFailsForSomeXValues2(int X);. void foo() {; cantFail(onlyFailsForSomeXValues(KnownSafeValue));; int Y = cantFail(onlyFailsForSomeXValues2(KnownSafeValue));; ...; }. Like the ExitOnError utility, cantFail simplifies control flow. Their treatment; of error cases is very different however: Where ExitOnError is guaranteed to; terminate the program on an error input, cantFail simply asserts that the result; is success. In debug builds this will result in an assertion failure if an error; is encountered. In release builds the behavior of cantFail for failure values is; undefined. As such, care",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:32055,safe,safe,32055,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['safe'],['safe']
Safety," a name; +/- 1 sigma variations (eg. 1.05 and 0.95 for a 5% uncertainty); 	 ; several 'Histogram Systematics' in shape with:; 	 ; a name (which can be shared with the OverallSyst if correlated); +/- 1 sigma variational histograms; 	 . RooStats; ModelConfig. This class is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; Various fixes by and improvements to make it usable with all; the existing calculator.; ModelConfig contains now always a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class remains, but with a new name: HybridCalculatorOriginal. ; The tutorial rs201b_hybridcalculator shows the usage of; the new class.; Note that the new",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:3797,avoid,avoid,3797,roofit/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html,2,['avoid'],['avoid']
Safety, a non-zero exit code when encountering a corrupted file; * [[#8942](https://github.com/root-project/root/issues/8942)] - cannot buid the dependent project; * [[#8794](https://github.com/root-project/root/issues/8794)] - [TGNumberEntry] centiseconds; * [[#8720](https://github.com/root-project/root/issues/8720)] - Apply TChain::SetImplicitMT() to underlying trees; * [[#8639](https://github.com/root-project/root/issues/8639)] - (RDataFrame) AsNumpy returns Boolean branches as 'object' dtype numpy arrays; * [[#8582](https://github.com/root-project/root/issues/8582)] - TThreadTimer behavior; * [[#8581](https://github.com/root-project/root/issues/8581)] - [ntuple] RNTupleModel columns ownership issue; * [[#8517](https://github.com/root-project/root/issues/8517)] - Add integer support to TVectorT; * [[#8494](https://github.com/root-project/root/issues/8494)] - cling crashes on conditional parameter in template; * [[#8260](https://github.com/root-project/root/issues/8260)] - Build system cannot detect version of oneTBB; * [[#8148](https://github.com/root-project/root/issues/8148)] - Document TMethodCall class limitations; * [[#7950](https://github.com/root-project/root/issues/7950)] - Assertion exception including header file with GaudiPython module; * [[#7900](https://github.com/root-project/root/issues/7900)] - Support spectator variables in RReader; * [[#7872](https://github.com/root-project/root/issues/7872)] - TExecutorCRTP::Map() should support void; * [[#7871](https://github.com/root-project/root/issues/7871)] - Usability of TExecutor::MapReduce; * [[#7845](https://github.com/root-project/root/issues/7845)] - Improve TMatrix reference documentation; * [[#7805](https://github.com/root-project/root/issues/7805)] - Inconsistent and unintuitive behaviour of TFormula::SetParNames and TFormula::SetParameters; * [[#7774](https://github.com/root-project/root/issues/7774)] - Unreasonably slow behaviour of CompileMacro; * [[#7699](https://github.com/root-project/root/issues/7,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:47525,detect,detect,47525,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['detect'],['detect']
Safety," a single ``:`` separates each key from its value, and arbitrary; whitespace separates the pairs. The value (right-hand side) of each pair; either is one or more ``0`` digits, or is ``0x`` followed by hexadecimal; digits. Each value might be a memory address or might be some other integer; (including an integer that looks like a likely memory address but actually has; an unrelated purpose). When the contextual information about the memory layout; suggests that a given value could be a code location or a global variable data; address, it might be presented as a source location or variable name or with; active UI that makes such interpretation optionally visible. The intended use is for things like register dumps, where the emitter doesn't; know which values might have a symbolic interpretation but a presentation that; makes plausible symbolic interpretations available might be very useful to; someone reading the log. At the same time, a flat text presentation should; usually avoid interfering too much with the original contents and formatting; of the dump. For example, it might use footnotes with source locations for; values that appear to be code locations. An active UI presentation might show; the dump text as is, but highlight values with symbolic information available; and pop up a presentation of symbolic details when a value is selected. Example::. {{{hexdict:; CS: 0 RIP: 0x6ee17076fb80 EFL: 0x10246 CR2: 0; RAX: 0xc53d0acbcf0 RBX: 0x1e659ea7e0d0 RCX: 0 RDX: 0x6ee1708300cc; RSI: 0 RDI: 0x6ee170830040 RBP: 0x3b13734898e0 RSP: 0x3b13734898d8; R8: 0x3b1373489860 R9: 0x2776ff4f R10: 0x2749d3e9a940 R11: 0x246; R12: 0x1e659ea7e0f0 R13: 0xd7231230fd6ff2e7 R14: 0x1e659ea7e108 R15: 0xc53d0acbcf0; }}}. Trigger elements; ================. These elements cause an external action and will be presented to the user in a; human readable form. Generally they trigger an external action to occur that; results in a linkable page. The link or some other informative information about",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:14567,avoid,avoid,14567,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,1,['avoid'],['avoid']
Safety," a, b; Foo(); ~Foo(); Foo(const Foo &); };; void g(Foo a, Foo b);; void f() {; g(Foo(), Foo());; }. .. code-block:: text. %struct.Foo = type { i32, i32 }; declare void @Foo_ctor(%struct.Foo* %this); declare void @Foo_dtor(%struct.Foo* %this); declare void @g(<{ %struct.Foo, %struct.Foo }>* inalloca %memargs). define void @f() {; entry:; %base = call i8* @llvm.stacksave(); %memargs = alloca <{ %struct.Foo, %struct.Foo }>; %b = getelementptr <{ %struct.Foo, %struct.Foo }>* %memargs, i32 1; call void @Foo_ctor(%struct.Foo* %b). ; If a's ctor throws, we must destruct b.; %a = getelementptr <{ %struct.Foo, %struct.Foo }>* %memargs, i32 0; invoke void @Foo_ctor(%struct.Foo* %a); to label %invoke.cont unwind %invoke.unwind. invoke.cont:; call void @g(<{ %struct.Foo, %struct.Foo }>* inalloca %memargs); call void @llvm.stackrestore(i8* %base); ... invoke.unwind:; call void @Foo_dtor(%struct.Foo* %b); call void @llvm.stackrestore(i8* %base); ...; }. To avoid stack leaks, the frontend saves the current stack pointer with; a call to :ref:`llvm.stacksave <int_stacksave>`. Then, it allocates the; argument stack space with alloca and calls the default constructor. The; default constructor could throw an exception, so the frontend has to; create a landing pad. The frontend has to destroy the already; constructed argument ``b`` before restoring the stack pointer. If the; constructor does not unwind, ``g`` is called. In the Microsoft C++ ABI,; ``g`` will destroy its arguments, and then the stack is restored in; ``f``. Design Considerations; =====================. Lifetime; --------. The biggest design consideration for this feature is object lifetime.; We cannot model the arguments as static allocas in the entry block,; because all calls need to use the memory at the top of the stack to pass; arguments. We cannot vend pointers to that memory at function entry; because after code generation they will alias. The rule against allocas between argument allocations and the call site; avoids",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst:2543,avoid,avoid,2543,interpreter/llvm-project/llvm/docs/InAlloca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst,1,['avoid'],['avoid']
Safety," add_llvm_install_targets(install-llvm-libraries; DEPENDS llvm-libraries; COMPONENT llvm-libraries); endif(). get_property(LLVM_LIBS GLOBAL PROPERTY LLVM_LIBS); if(LLVM_LIBS); list(REMOVE_DUPLICATES LLVM_LIBS); foreach(lib ${LLVM_LIBS}); add_dependencies(llvm-libraries ${lib}); if (NOT LLVM_ENABLE_IDE); add_dependencies(install-llvm-libraries install-${lib}); add_dependencies(install-llvm-libraries-stripped install-${lib}-stripped); endif(); endforeach(); endif(); endif(). # This must be at the end of the LLVM root CMakeLists file because it must run; # after all targets are created.; llvm_distribution_add_targets(); process_llvm_pass_plugins(GEN_CONFIG); include(CoverageReport). # This allows us to deploy the Universal CRT DLLs by passing -DCMAKE_INSTALL_UCRT_LIBRARIES=ON to CMake; if (MSVC AND CMAKE_HOST_SYSTEM_NAME STREQUAL ""Windows"" AND CMAKE_INSTALL_UCRT_LIBRARIES); include(InstallRequiredSystemLibraries); endif(). if (LLVM_INCLUDE_BENCHMARKS); # Override benchmark defaults so that when the library itself is updated these; # modifications are not lost.; set(BENCHMARK_ENABLE_TESTING OFF CACHE BOOL ""Disable benchmark testing"" FORCE); set(BENCHMARK_ENABLE_EXCEPTIONS OFF CACHE BOOL ""Disable benchmark exceptions"" FORCE); set(BENCHMARK_ENABLE_INSTALL OFF CACHE BOOL ""Don't install benchmark"" FORCE); set(BENCHMARK_DOWNLOAD_DEPENDENCIES OFF CACHE BOOL ""Don't download dependencies"" FORCE); set(BENCHMARK_ENABLE_GTEST_TESTS OFF CACHE BOOL ""Disable Google Test in benchmark"" FORCE); set(BENCHMARK_ENABLE_WERROR ${LLVM_ENABLE_WERROR} CACHE BOOL; ""Handle -Werror for Google Benchmark based on LLVM_ENABLE_WERROR"" FORCE); # Since LLVM requires C++11 it is safe to assume that std::regex is available.; set(HAVE_STD_REGEX ON CACHE BOOL ""OK"" FORCE); add_subdirectory(${LLVM_THIRD_PARTY_DIR}/benchmark; ${CMAKE_CURRENT_BINARY_DIR}/third-party/benchmark); add_subdirectory(benchmarks); endif(). if (LLVM_INCLUDE_UTILS AND LLVM_INCLUDE_TOOLS); add_subdirectory(utils/llvm-locstats); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:54701,safe,safe,54701,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['safe'],['safe']
Safety," addition to the TVirtualFitter provides the following functionality:; ; access direct to references to ROOT::Fit::FitResult and ROOT::FitConfig objects via the member functions TBackCompFitter::GetFitResult() and TBackCompFitter::GetFitConfig(); Possibility to set the fit the fit function directly as a function pointer to a muldi-dimensional function interface instead of using the TMinuit FCN style API.; New methods for making in a easy way contour , with TBackCompFitter::Contour, and scan plots of the objective function, with TBackCompFitter::Scan. Both Scan and Contour takes as input a TGraph which on exit will be filled with the scanned or contour points. ; TH1. Re-implement TH1::Fit using the functions defined in HFitImpl.cxx.; Add new function TH1::Interpolate to approximate the value via linear interpolation. Implementation from Any Mastbaum. ; Fixed a bug in rebinning in a new variable bin histogram.; Fixed a bug in copy constructor of histograms; define now kNstat as an enumeration in the TH1 class, to avoid using wrong values for this constant variable. This fixes a previous bug in TProfile3D; ; TH2. Share a common implementation for (FitSlicesX,FitSclicesY) and (ProfileX, ProfileY) using a common protected method.; Add possibility to be used in the FitPanel (add a TH2::FitPanel() method).; Add also here the new function TH2::Interpolate. ; fix a bug in the resulting statistics in TH2::ProjectionX(Y) when all range was used; fix a bug in getting the right axis and limits in TH2::ProfileX(Y); ; TH3. Add new option ""NUF"" and ""NOF"" in TH3::Project to have excluded the underflow/overflow (they are included by default).; Add option ""UF"" and ""OF"" in TH3::ProjectProfile to include the underflow/overflow. By default they are now excluded while in the previous version they were included. This is consistent with the projection from a TH2.; ; Fixed a bug in TH3::Project reported by Marco Van Leeuwen in setting the bin error in the projected histogram when a range was",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v522/index.html:2858,avoid,avoid,2858,hist/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v522/index.html,1,['avoid'],['avoid']
Safety," adds; ``[[clang::lifetimebound]]`` to the parameter of ``__builtin_addressof``. **Example of use**:. .. code-block:: c++. template<typename T> constexpr T *addressof(T &value) {; return __builtin_addressof(value);; }. ``__builtin_function_start``; -----------------------------. ``__builtin_function_start`` returns the address of a function body. **Syntax**:. .. code-block:: c++. void *__builtin_function_start(function). **Example of use**:. .. code-block:: c++. void a() {}; void *p = __builtin_function_start(a);. class A {; public:; void a(int n);; void a();; };. void A::a(int n) {}; void A::a() {}. void *pa1 = __builtin_function_start((void(A::*)(int)) &A::a);; void *pa2 = __builtin_function_start((void(A::*)()) &A::a);. **Description**:. The ``__builtin_function_start`` builtin accepts an argument that can be; constant-evaluated to a function, and returns the address of the function; body. This builtin is not supported on all targets. The returned pointer may differ from the normally taken function address; and is not safe to call. For example, with ``-fsanitize=cfi``, taking a; function address produces a callable pointer to a CFI jump table, while; ``__builtin_function_start`` returns an address that fails; :doc:`cfi-icall<ControlFlowIntegrity>` checks. ``__builtin_operator_new`` and ``__builtin_operator_delete``; ------------------------------------------------------------. A call to ``__builtin_operator_new(args)`` is exactly the same as a call to; ``::operator new(args)``, except that it allows certain optimizations; that the C++ standard does not permit for a direct function call to; ``::operator new`` (in particular, removing ``new`` / ``delete`` pairs and; merging allocations), and that the call is required to resolve to a; `replaceable global allocation function; <https://en.cppreference.com/w/cpp/memory/new/operator_new>`_. Likewise, ``__builtin_operator_delete`` is exactly the same as a call to; ``::operator delete(args)``, except that it permits optimi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:118701,safe,safe,118701,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['safe'],['safe']
Safety," allows to e.g., interactively adjust axis parameters before performing; projections from high-dimensional histograms,. ```{.cpp}; // Create a chain of histograms called `h`.; THnChain chain(""h"");. // Add files containing histograms `h` to `chain`.; chain->AddFile(""file1.root"");. chain->GetXaxis(1)->SetRangeUser(0.1, 0.2);. TH1* projection = chain->Projection(0); ```. ## Math Libraries. * Improve thread friendliness of the TMinuit class. ## RooFit Libraries. - Remove deprecated `RooComplex` superseded by `std::complex`. ## TTree Libraries. - `TTreeReader` now supports `TEntryList`s, `Double32_t` / `Float16_t`.; - `TTreeReader::SetLastEntry()` has been deprecated. Its name is misleading; please use `TTreePlayer::SetEntriesRange()` instead.; - `TTree::Branch()` now complains for wrong leaf list strings, e.g. ""value/F[4]"" (which should really be spelled as ""value[4]/F"").; - Allow reading of older version of TTreePerfStats (ROOT-8520); - In `TTree::OptimizeBaskets()` do not call GetBasket(0) to avoid disc reads; - It is now possible to define the precision of the default histogram created; by `TTree::Draw`. Three new parameters are available in `$ROOTSYS/etcsystem.rootrc`; ```{.cpp}; Hist.Precision.1D: float; Hist.Precision.2D: float; Hist.Precision.3D: float; ```; the default values are `float`. They can be set to `double`.; - Fix ROOT-8742: TTree::SetBranchAddress could not be invoked safely even when dealing with the same tree obtained from the same file opened in different threads.; - TTree::Branch() now complains if a ""name[size]/F"" branch specification is passed wrongly (e.g. as ""name/F[size]""). ### TDataFrame; - Creation of the TDataFrame class. The TDataFrame allows to interact with data; stored in columnar format in a functional and intuitive way in order to perform; data analysis. Parallelism is accessible simply by activating implicit; multi-threading with the ROOT::EnableImplicitMT() function.; In a nutshell, the functionality provided is:; - Create and fill",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:5472,avoid,avoid,5472,README/ReleaseNotes/v610/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md,1,['avoid'],['avoid']
Safety," along a straight line.; The starting point and direction for this procedure are the ones; corresponding to the current state. The boundary search is initialized; inside the current volume and the crossed boundary can belong either to; the current node or to one of its daughters. The full prototype of the; method is:. ``` {.cpp}; TGeoNode *TGeoManager::FindNextBoundary(Double_t step=kBig);; ```. In the prototype above, besides the current point and direction that are; supposed already initialized, the only input parameter is `step`. This; represents the maximum step allowed by the tracking algorithm or the; `physical step`. The modeller will search for a boundary crossing only; up to a distance equal to this value. If a boundary is found, a pointer; to the object (node) having it is returned; otherwise the method returns; `NULL`. The computed value for the computed distance can be subsequently; retrieved from the manager class:. ``` {.cpp}; Double_t snext = gGeoManager->GetStep();; Double_t safety = gGeoManager->GetSafeDistance();; ```. According the step value, two use cases are possible:. - `step =` `TGeoShape::kBig `(default behavior; `kBig = 1030`). In; this case, there is no limitation on the search algorithm, the first; crossed node is returned and the corresponding distance computed. If; the current point is outside geometry and the top node is not; crossed, the corresponding distance will be set to `kBig` and a; `NULL` pointer returned. No additional quantity will be computed.; - `step < kBig`. In this case, the progressive search starting from; the current point will be stopped after a distance equal with the; supplied step. In addition to the distance to the first crossed; boundary, the `safety radius` is also computed. Whenever the; information regarding the maximum required step is known it is; recommended to be provided as input parameter in order to speed-up; the search. In addition to the distance computation, the method sets an additional; flag tellin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:116772,safe,safety,116772,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['safe'],['safety']
Safety," an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:3290,safe,safepoint,3290,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['safe'],['safepoint']
Safety," and categorize scalar; expressions in loops. It specializes in recognizing general induction; variables, representing them with the abstract and opaque ``SCEV`` class.; Given this analysis, trip counts of loops and other important properties can be; obtained. This analysis is primarily useful for induction variable substitution and; strength reduction. ``scev-aa``: ScalarEvolution-based Alias Analysis; -------------------------------------------------. Simple alias analysis implemented in terms of ``ScalarEvolution`` queries. This differs from traditional loop dependence analysis in that it tests for; dependencies within a single iteration of a loop, rather than dependencies; between different iterations. ``ScalarEvolution`` has a more complete understanding of pointer arithmetic; than ``BasicAliasAnalysis``' collection of ad-hoc analyses. ``stack-safety``: Stack Safety Analysis; ---------------------------------------. The ``StackSafety`` analysis can be used to determine if stack allocated; variables can be considered safe from memory access bugs. This analysis' primary purpose is to be used by sanitizers to avoid unnecessary; instrumentation of safe variables. Transform Passes; ================. This section describes the LLVM Transform Passes. ``adce``: Aggressive Dead Code Elimination; ------------------------------------------. ADCE aggressively tries to eliminate code. This pass is similar to :ref:`DCE; <passes-dce>` but it assumes that values are dead until proven otherwise. This; is similar to :ref:`SCCP <passes-sccp>`, except applied to the liveness of; values. ``always-inline``: Inliner for ``always_inline`` functions; ----------------------------------------------------------. A custom inliner that handles only functions that are marked as ""always; inline"". ``argpromotion``: Promote 'by reference' arguments to scalars; -------------------------------------------------------------. This pass promotes ""by reference"" arguments to be ""by value"" arguments. I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:11561,safe,safe,11561,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['safe'],['safe']
Safety," and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capable (so far: single-target only). PDEFoam:; PDE-Foam is a variation of the PDE-RS method using a self-adapting binning; method to divide the multi-dimensional variable space into a finite number; of hyper-rectangles (cells). The binning algorithm adjusts the size and; position of a predefined number of cells such that the variance of the; signal and background densities inside the cells reaches a minimum. BDT:; Introduced gradient boosting and stochastic gradient boosting for ; classification with BDT (as desribed by Friedman 1999). See ""BDTG"" ; example in TMVAClassification.C/cxx. A new option allows to restrict the maximum tree depth. This may be used to; avoid overtraining and often gives better performance than pruning. (The; pruning mechanism needs to be revisited). MLP:; Introduced recognition of convergence via general ConvergenceTest-class for; interrupting computations when convergence is reached. This feature has is; used now in MethodMLP. Improved treatment of event-weights in BFGS training. Implemented random and importance sampling of events in DataSet. Implemented; the usage of this feature for MLP.; ; TMlpANN (interface to TMultiLayerPerceptron) now also uses event weights; and writes standalone C++ class. k-NN:; A new global knn search function has been added to NodekNN that searches for; k-nearest neighbor using event weights instead of raw event counts. ModulekNN; has been modified to allow searches using ""weight"" or ""count"" option, where; ""count"" is default. Added UseWeight option to MethodKNN to allow using of; ""weight"" or ""count"". ; (Work by Rustem Ospanov, CERN). . Likelihood (and general PDF treatment):; Adaptive smoothing the PDF class, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:2999,avoid,avoid,2999,tmva/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html,1,['avoid'],['avoid']
Safety," and have lengths up to 64bit. _String_: A string is stored as a 32bit unsigned integer indicating the length of the string; followed by the characters.; Strings are ASCII encoded; every character is a signed 8bit integer. _Compression settings_: A 32bit integer containing both a compression algorithm and the compression level.; The compression settings are encoded according to this formula: $settings = algorithm * 100 + level$.; The level is between 1 and 9 and is extrapolated to the spectrum of levels of the corresponding algorithm. ### Feature Flags. Feature flags are 64bit integers where every bit represents a certain forward-incompatible feature that is used; in the binary format of the RNTuple at hand (see Versioning Notes).; The most significant bit is used to indicate that one or more flags is active with a bit higher than 63.; That means that readers need to continue reading feature flags as long as their signed integer value is negative. Readers should gracefully abort reading when they encounter unknown bits set. At the moment, there are no feature flag bits defined. ## Frames. RNTuple envelopes can store records and lists of basic types and other records by means of **frames**. A frame has the following format; ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Size +-+; |  |T|; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Number of Items (for list frames) |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | FRAME PAYLOAD |; | ... |; ```. _Size_: The absolute value gives the (uncompressed) size in bytes of the frame and the payload. _T(ype)_: Can be either 0 for a **record frame** or 1 for a **list frame**.; The type should be interpreted as the sign bit of the size, i.e. negative sizes indicate list frames. _Number of items_: Only used for list frames to indicate the length of the list in the frame payload. Fil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:7775,abort,abort,7775,tree/ntuple/v7/doc/BinaryFormatSpecification.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md,1,['abort'],['abort']
Safety," and so on. (The first such attempt, returning an ``Error`` from; MachOObjectFile's constructor, was abandoned after the diff reached 3000 lines,; impacted half a dozen libraries, and was still growing). To solve this problem, the ``Error``/``std::error_code`` interoperability requirement was; introduced. Two pairs of functions allow any ``Error`` value to be converted to a; ``std::error_code``, any ``Expected<T>`` to be converted to an ``ErrorOr<T>``, and vice; versa:. .. code-block:: c++. std::error_code errorToErrorCode(Error Err);; Error errorCodeToError(std::error_code EC);. template <typename T> ErrorOr<T> expectedToErrorOr(Expected<T> TOrErr);; template <typename T> Expected<T> errorOrToExpected(ErrorOr<T> TOrEC);. Using these APIs it is easy to make surgical patches that update individual; functions from ``std::error_code`` to ``Error``, and from ``ErrorOr<T>`` to; ``Expected<T>``. Returning Errors from error handlers; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Error recovery attempts may themselves fail. For that reason, ``handleErrors``; actually recognises three different forms of handler signature:. .. code-block:: c++. // Error must be handled, no new errors produced:; void(UserDefinedError &E);. // Error must be handled, new errors can be produced:; Error(UserDefinedError &E);. // Original error can be inspected, then re-wrapped and returned (or a new; // error can be produced):; Error(std::unique_ptr<UserDefinedError> E);. Any error returned from a handler will be returned from the ``handleErrors``; function so that it can be handled itself, or propagated up the stack. .. _err_exitonerr:. Using ExitOnError to simplify tool code; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Library code should never call ``exit`` for a recoverable error, however in tool; code (especially command line tools) this can be a reasonable approach. Calling; ``exit`` upon encountering an error dramatically simplifies control flow as the; error no longer needs to be propagated up the sta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:29683,recover,recovery,29683,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['recover'],['recovery']
Safety," and will be implemented soon for other; global Objects as e.g. ***`gVirtualX`***. #### Canceling a TThread. Canceling of a thread is a rather dangerous action. In **`TThread`**; canceling is forbidden by default. The user can change this default by; calling `TThread::SetCancelOn()`. There are two cancellation modes:; deferred and asynchronous. #### Deferred. Set by `TThread::SetCancelDeferred()` (default): When the user knows; safe places in their code where a thread can be canceled without risk for; the rest of the system, they can define these points by invoking; **`TThread`**`::CancelPoint()`. Then, if a thread is canceled, the; cancellation is deferred up to the call of; **`TThread`**`::CancelPoint()` and then the thread is canceled safely.; There are some default cancel points for `pthreads` implementation, e.g.; any call of the `TCondition::Wait()`, **`TCondition`**`::TimedWait()`,; `TThread::Join()`. #### Asynchronous. Set by `TThread::SetCancelAsynchronous()`: If the user is sure that; their application is cancel safe, they could call:. ``` {.cpp}; TThread::SetCancelAsynchronous();; TThread::SetCancelOn();; // Now cancelation in any point is allowed.; ...; // Return to default; TThread::SetCancelOff();; TThread::SetCancelDeferred();; ```. To cancel a thread `TThread* th` call:. ``` {.cpp}; th->Kill();; ```. To cancel by thread name:. ``` {.cpp}; TThread::Kill(name);; ```. To cancel a thread by ID:. ``` {.cpp}; TThread::Kill(tid);; ```. To cancel a thread and delete `th` when cancel finished:. ``` {.cpp}; th->Delete();; ```. Deleting of the thread instance by the operator delete is dangerous. Use; `th->Delete()` instead. C++ delete is safe only if thread is not; running. Often during the canceling, some clean up actions must be; taken. To define clean up functions use:. ``` {.cpp}; void UserCleanUp(void *arg) {; // here the user cleanup is done; ...; }; TThread::CleanUpPush(&UserCleanUp,arg);; // push user function into cleanup stack""last in, first out""; TThr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:11938,safe,safe,11938,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['safe'],['safe']
Safety," any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.rint.f32(float %Val); declare double @llvm.rint.f64(double %Val); declare x86_fp80 @llvm.rint.f80(x86_fp80 %Val); declare fp128 @llvm.rint.f128(fp128 %Val); declare ppc_fp128 @llvm.rint.ppcf128(ppc_fp128 %Val). Overview:; """""""""""""""""". The '``llvm.rint.*``' intrinsics returns the operand rounded to the; nearest integer. It may raise an inexact floating-point exception if the; operand isn't an integer. Arguments:; """""""""""""""""""". The argument and return value are floating-point numbers of the same; type. Semantics:; """""""""""""""""""". This function returns the same values as the libm ``rint`` functions; would, and handles error conditions in the same way. Since LLVM assumes the; :ref:`default floating-point environment <floatenv>`, the rounding mode is; assumed to be set to ""nearest"", so halfway cases are rounded to the even; integer. Use :ref:`Constrained Floating-Point Intrinsics <constrainedfp>`; to avoid that assumption. .. _int_nearbyint:. '``llvm.nearbyint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.nearbyint`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.nearbyint.f32(float %Val); declare double @llvm.nearbyint.f64(double %Val); declare x86_fp80 @llvm.nearbyint.f80(x86_fp80 %Val); declare fp128 @llvm.nearbyint.f128(fp128 %Val); declare ppc_fp128 @llvm.nearbyint.ppcf128(ppc_fp128 %Val). Overview:; """""""""""""""""". The '``llvm.nearbyint.*``' intrinsics returns the operand rounded to the; nearest integer. Arguments:; """""""""""""""""""". The argument and return value are floating-point numbers of the same; type. Semantics:; """""""""""""""""""". This function returns the same values as the libm ``nearbyint``; functions would, and handles error conditions in the same way. Since LLVM; assumes the :ref:`default floating-point envi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:582598,avoid,avoid,582598,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['avoid'],['avoid']
Safety," approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data in the first place.; * It accumulates the predicate state, protecting even in the face of nested; *correctly* predicted control flows.; * It passes this predicate state across function boundaries to provide; [interprocedural protection](#interprocedural-checking).; * When hardening the address of a load, it uses a *destructive* or; *non-reversible* modification of the address to prevent an attacker from; reversing the check using attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/H",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:6194,predict,prediction,6194,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['predict'],['prediction']
Safety," argument of the; builtin should be a pointer to a complete record type to dump. The second argument ``f``; should be some callable expression, and can be a function object or an overload; set. The builtin calls ``f``, passing any further arguments ``args...``; followed by a ``printf``-compatible format string and the corresponding; arguments. ``f`` may be called more than once, and ``f`` and ``args`` will be; evaluated once per call. In C++, ``f`` may be a template or overload set and; resolve to different functions for each call. In the format string, a suitable format specifier will be used for builtin; types that Clang knows how to format. This includes standard builtin types, as; well as aggregate structures, ``void*`` (printed with ``%p``), and ``const; char*`` (printed with ``%s``). A ``*%p`` specifier will be used for a field; that Clang doesn't know how to format, and the corresponding argument will be a; pointer to the field. This allows a C++ templated formatting function to detect; this case and implement custom formatting. A ``*`` will otherwise not precede a; format specifier. This builtin does not return a value. This builtin can be used in constant expressions. Query for this feature with ``__has_builtin(__builtin_dump_struct)``. .. _langext-__builtin_shufflevector:. ``__builtin_shufflevector``; ---------------------------. ``__builtin_shufflevector`` is used to express generic vector; permutation/shuffle/swizzle operations. This builtin is also very important; for the implementation of various target-specific header files like; ``<xmmintrin.h>``. **Syntax**:. .. code-block:: c++. __builtin_shufflevector(vec1, vec2, index1, index2, ...). **Examples**:. .. code-block:: c++. // identity operation - return 4-element vector v1.; __builtin_shufflevector(v1, v1, 0, 1, 2, 3). // ""Splat"" element 0 of V1 into a 4-element result.; __builtin_shufflevector(V1, V1, 0, 0, 0, 0). // Reverse 4-element vector V1.; __builtin_shufflevector(V1, V1, 3, 2, 1, 0). // Conca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:105922,detect,detect,105922,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['detect'],['detect']
Safety," around with the elements. This is good for vectors that are ""usually small"" (e.g. the number of; predecessors/successors of a block is usually less than 8). On the other hand,; this makes the size of the SmallVector itself large, so you don't want to; allocate lots of them (doing so will waste a lot of space). As such,; SmallVectors are most useful when on the stack. In the absence of a well-motivated choice for the number of; inlined elements ``N``, it is recommended to use ``SmallVector<T>`` (that is,; omitting the ``N``). This will choose a default number of; inlined elements reasonable for allocation on the stack (for example, trying; to keep ``sizeof(SmallVector<T>)`` around 64 bytes). SmallVector also provides a nice portable and efficient replacement for; ``alloca``. SmallVector has grown a few other minor advantages over std::vector, causing; ``SmallVector<Type, 0>`` to be preferred over ``std::vector<Type>``. #. std::vector is exception-safe, and some implementations have pessimizations; that copy elements when SmallVector would move them. #. SmallVector understands ``std::is_trivially_copyable<Type>`` and uses realloc aggressively. #. Many LLVM APIs take a SmallVectorImpl as an out parameter (see the note; below). #. SmallVector with N equal to 0 is smaller than std::vector on 64-bit; platforms, since it uses ``unsigned`` (instead of ``void*``) for its size; and capacity. .. note::. Prefer to use ``ArrayRef<T>`` or ``SmallVectorImpl<T>`` as a parameter type. It's rarely appropriate to use ``SmallVector<T, N>`` as a parameter type.; If an API only reads from the vector, it should use :ref:`ArrayRef; <dss_arrayref>`. Even if an API updates the vector the ""small size"" is; unlikely to be relevant; such an API should use the ``SmallVectorImpl<T>``; class, which is the ""vector header"" (and methods) without the elements; allocated after it. Note that ``SmallVector<T, N>`` inherits from; ``SmallVectorImpl<T>`` so the conversion is implicit and costs nothing. E.g.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:61023,safe,safe,61023,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['safe'],['safe']
Safety," auto pt = model->MakeField<float>(""pt"");; // The reader checks the passed model for compatibility; only the subset of fields defined in the model is read; auto reader = RNTupleReader::Open(std::move(model), ntuple);; reader->LoadEntry(0);. // Option 3: through views; // Each view will only trigger reading of the related field, without reading other fields at the same entry number.; auto reader = RNTupleReader::Open(ntuple);; auto viewPt = reader->GetView<float>(""pt"");; // Load the pt from the first entry; auto pt = viewPt(0);; ```. In the above cases, RNTuple creates the objects being read into.; It is also possible to bind already existing objects.; This is shown below for entries and works similarly for views. ```c++; // A bare entry is an entry that has initially no bindings (all top-level fields need to be bound by the caller); auto entry = reader->GetModel().CreateBareEntry();; auto ptToken = entry->GetToken(""pt"");. // Option 1: type safe, shared ownership; std::shared_ptr<float> ptTypedSharedPtr;; entry->BindValue(ptToken, ptTypedSharedPtr);. // Option 2: type unsafe, shared ownership; std::shared_ptr<void> ptVoidSharedPtr;; entry->BindValue(ptToken, ptVoidSharedPtr);. // Option 3: type unsafe, application owns the object; void *ptVoidPtr;; entry->BindRawPtr(ptToken, ptVoidPtr);. // Option 4: switch back from application-provided object to RNTuple-created object; entry->EmplaceNewValue(ptToken);. // For all options: use an explicit entry; reader->LoadEntry(0, *entry);; ```. Walkthrough: Writing Data; -------------------------. ```c++; auto model = RNTupleModel::Create();; // Add a field to the model and return the shared pointer for that field in the model's default entry.; auto ptrPt = model->MakeField<float>(""pt"");. auto file = std::make_unique<TFile>(""data.root"", ""APPEND"");; // The writer creates a page sink and connects the model's fields to it; auto writer = RNTupleWriter::Append(std::move(model), ""ntpl"", *file);; *ptrPt = 1.0;; // Append the model's def",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:3837,safe,safe,3837,tree/ntuple/v7/doc/Architecture.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md,1,['safe'],['safe']
Safety," available.; This class emulates the existing `NumCPU(>1)` functionality of the `RooAbsTestStatistic` tree, which is implemented based on `RooRealMPFE`.; This class is not yet thoroughly tested and should not be considered production ready. ### Usage example: `MultiProcess` enabled parallel gradient calculator. The main selling point of using `RooFit::TestStatistics` from a performance point of view is the implementation of the `RooFit::MultiProcess` based `LikelihoodGradientJob` calculator class.; To use it, one should create a `RooMinimizer` using the new constructor that takes a `RooAbsL`-based likelihood instead of a `RooAbsReal`. Taking any of the above created `likelihood` objects (as long as they are in a `std::shared_ptr`), we can create a `RooMinimizer` with parallel gradient calculation using:; ``` {.cpp}; std::shared_ptr<RooAbsL> likelihood = /* see examples above */;; RooMinimizer m(likelihood);; ```. By default, `RooFit::MultiProcess` spins up as many workers as there are cores in the system (as detected by `std::thread::hardware_concurrency()`).; To change the number of workers, call `RooFit::MultiProcess::Config::setDefaultNWorkers(desired_N_workers)` **before** creating the `RooMinimizer`. As noted above, offsetting is purely a function of the `RooMinimizer` when using `TestStatistics` classes.; Whereas with `fitTo` we can pass in a `RooFit::Offset(true)` optional `RooCmdArg` argument to activate offsetting, here we must do it on the minimizer as follows:; ``` {.cpp}; m.setOffsetting(true);; ```. All existing functionality of the `RooMinimizer` can be used on `TestStatistics` likelihoods as well.; For instance, running a `migrad` fit:; ``` {.cpp}; m.migrad(); ```. ## Constant term optimization; The `RooAbsTestStatistic` based classes not only combine statistics and calculation, but also constant term optimization routines.; These can be run on PDFs and datasets before starting a fit.; They search the calculation graph for parts that are independent of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/test_statistics.md:8772,detect,detected,8772,roofit/doc/developers/test_statistics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/test_statistics.md,1,['detect'],['detected']
Safety," because the functions from the include files live in the; llvm namespace. Next we have:. .. code-block:: c++. namespace {. ... which starts out an anonymous namespace. Anonymous namespaces are to C++; what the ""``static``"" keyword is to C (at global scope). It makes the things; declared inside of the anonymous namespace visible only to the current file.; If you're not familiar with them, consult a decent C++ book for more; information. Next, we declare our pass itself:. .. code-block:: c++. struct Hello : public FunctionPass {. This declares a ""``Hello``"" class that is a subclass of :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>`. The different builtin pass subclasses; are described in detail :ref:`later <writing-an-llvm-pass-pass-classes>`, but; for now, know that ``FunctionPass`` operates on a function at a time. .. code-block:: c++. static char ID;; Hello() : FunctionPass(ID) {}. This declares pass identifier used by LLVM to identify pass. This allows LLVM; to avoid using expensive C++ runtime information. .. code-block:: c++. bool runOnFunction(Function &F) override {; errs() << ""Hello: "";; errs().write_escaped(F.getName()) << '\n';; return false;; }; }; // end of struct Hello; } // end of anonymous namespace. We declare a :ref:`runOnFunction <writing-an-llvm-pass-runOnFunction>` method,; which overrides an abstract virtual method inherited from :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>`. This is where we are supposed to do our; thing, so we just print out our message with the name of each function. .. code-block:: c++. char Hello::ID = 0;. We initialize pass ID here. LLVM uses ID's address to identify a pass, so; initialization value is not important. .. code-block:: c++. static RegisterPass<Hello> X(""hello"", ""Hello World Pass"",; false /* Only looks at CFG */,; false /* Analysis Pass */);. Lastly, we :ref:`register our class <writing-an-llvm-pass-registration>`; ``Hello``, giving it a command line argument ""``hello``"", and a name ""Hello;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:5321,avoid,avoid,5321,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['avoid'],['avoid']
Safety," been added to RooFit.; Also see [arxiv:2012.02746](https://arxiv.org/abs/2012.02746). ### More accurate residual and pull distributions. When making residual or pull distributions with `RooPlot::residHist` or `RooPlot::pullHist`, the histogram is now compared with the curve's average values within a given bin by default, ensuring that residual and pull distributions are valid for strongly curved distributions.; The old default behaviour was to interpolate the curve at the bin centres, which can still be enabled by setting the `useAverage` parameter of `RooPlot::residHist` or `RooPlot::pullHist` to `false`. ### Improved recovery from invalid parameters. When a function in RooFit is undefined (Poisson with negative mean, PDF with negative values, etc), RooFit can now pass information about the; ""badness"" of the violation to the minimiser. The minimiser can use this to compute a gradient to find its way out of the undefined region.; This can drastically improve its ability to recover when unstable fit models are used, for example RooPolynomial. For details, see the RooFit tutorial [rf612_recoverFromInvalidParameters.C](https://root.cern/doc/v624/rf612__recoverFromInvalidParameters_8C.html); and [arxiv:2012.02746](https://arxiv.org/abs/2012.02746). ### Modernised RooDataHist. RooDataHist was partially modernised to improve const-correctness, to reduce side effects as well as its memory footprint, and to make; it ready for RooFit's faster batch evaluations.; Derived classes that directly access protected members might need to be updated. This holds especially for direct accesses to `_curWeight`,; `_curWeightErrLo`, etc, which have been removed. (It doesn't make sense to write to these members from const functions when the same information; can be retrieved using an index access operator of an array.) All similar accesses in derived classes should be replaced by the getters `get_curWeight()`; or better `get_wgt(i)`, which were also supported in ROOT \<v6.24. More details ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:20314,recover,recover,20314,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['recover'],['recover']
Safety," behavior is dependent on the track; parameters, which is a highly undesirable effect. *B)* We will call ""overlaps"" only the regions in space contained by; more than one node inside the same container. The owner of such regions; cannot be determined based on hierarchical considerations; therefore; they will be considered as belonging to the node from which the current; track is coming from. When coming from their container, the ownership is totally; unpredictable. Again, the ownership of overlapping regions highly; depends on the current track parameters. We must say that even the overlaps of type *A)* and *B)* are allowed in case; the corresponding nodes are created using; TGeoVolume::AddNodeOverlap() method. Navigation is performed in such; cases by giving priority to the non-overlapping nodes. The modeller has; to perform an additional search through the overlapping candidates.; These are detected automatically during the geometry closing procedure; in order to optimize the algorithm, but we will stress that extensive; usage of this feature leads to a drastic deterioration of performance.; In the following we will focus on the non-declared overlaps of type *A)*; and *B)* since this is the main source of errors during tracking. These; are generally non-intended overlaps due to coding mistakes or bad; geometry design. The checking package is loaded together with the; painter classes and contains an automated overlap checker. \image html geometry008.png ""Overlap checking"". This can be activated both at volume level (checking for illegal; overlaps only one level inside a given volume) and from the geometry; manager level (checking full geometry):. ~~~{.cpp}; myVolume->CheckOverlaps(precision, option);; gGeoManager->CheckOverlaps(precision);; myNode->CheckOverlaps(precision);; ~~~. Here precision represents the desired maximum accepted overlap value in; centimeters (default value is 0.1). This tool checks all possible; significant pairs of candidates inside a given vol",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:92299,detect,detected,92299,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['detect'],['detected']
Safety," bounds; are encoded as strings in the typedef’s name (e.g.,; ``__bounds_safety$counted_by:N``). Recognizing ``-fbounds-safety`` traps; -------------------------------------. Clang emits debug info for ``-fbounds-safety`` traps as inlined functions, where; the function name encodes the error message. LLDB implements a frame recognizer; to surface a human-readable error cause to the end user. A debug info consumer; that is unaware of this sees an inlined function whose name encodes an error; message (e.g., : ``__bounds_safety$Bounds check failed``). Expression Parsing; ------------------. In our implementation, LLDB’s expression evaluator does not enable the; ``-fbounds-safety`` language option because it’s currently unable to fully; reconstruct the pointers with external bounds annotations, and also because the; evaluator operates in C++ mode, utilizing C++ reference types, while; ``-fbounds-safety`` does not currently support C++. This means LLDB’s expression; evaluator can only evaluate a subset of the ``-fbounds-safety`` language model.; Specifically, it’s capable of evaluating the wide pointers that already exist in; the source code. All other expressions are evaluated according to C/C++; semantics. C++ support; ===========. C++ has multiple options to write code in a bounds-safe manner, such as; following the bounds-safety core guidelines and/or using hardened libc++ along; with the `C++ Safe Buffer model; <https://discourse.llvm.org/t/rfc-c-buffer-hardening/65734>`_. However, these; techniques may require ABI changes and may not be applicable to code; interoperating with C. When the ABI of an existing program needs to be preserved; and for headers shared between C and C++, ``-fbounds-safety`` offers a potential; solution. ``-fbounds-safety`` is not currently supported in C++, but we believe the; general approach would be applicable for future efforts. Upstreaming plan; ================. Gradual updates with experimental flag; ----------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst:10217,safe,safety,10217,interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,1,['safe'],['safety']
Safety," caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L0 and L1 caches at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is accessed as MTYPE UC (uncached) to avoid; needing to invalidate the L2 cache.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC (non-coherent). Since the private address space is only accessed; by a single thread, and is always write-before-read, there is never a need to; invalidate these entries from the L0 or L1 caches. Wavefronts are executed in native mode with in-order reporting of loads and; sample instructions. In this mode vmcnt reports completion of load, atomic with; return and sample instructions in order, and the vscnt reports the completion of; store and atomic without return in order. See ``MEM_ORDERED`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`. Wavefronts can be executed in WGP or CU wavefront execution mode:. * In WGP wavefront execution mode the wavefronts of a work-group ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:341336,avoid,avoid,341336,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['avoid'],['avoid']
Safety," can be; false positives if two pointers both point to the same mutex. .. code-block:: c++. class MutexUnlocker {; Mutex* mu;. public:; MutexUnlocker(Mutex* m) RELEASE(m) : mu(m) { mu->Unlock(); }; ~MutexUnlocker() ACQUIRE(mu) { mu->Lock(); }; };. Mutex mutex;; void test() REQUIRES(mutex) {; {; MutexUnlocker munl(&mutex); // unlocks mutex; doSomeIO();; } // Warning: locks munl.mu; }. The MutexUnlocker class is intended to be the dual of the MutexLocker class,; defined in :ref:`mutexheader`. However, it doesn't work because the analysis; doesn't know that munl.mu == mutex. The SCOPED_CAPABILITY attribute handles; aliasing for MutexLocker, but does so only for that particular pattern. ACQUIRED_BEFORE(...) and ACQUIRED_AFTER(...) are currently unimplemented.; -------------------------------------------------------------------------. To be fixed in a future update. .. _mutexheader:. mutex.h; =======. Thread safety analysis can be used with any threading library, but it does; require that the threading API be wrapped in classes and methods which have the; appropriate annotations. The following code provides ``mutex.h`` as an example;; these methods should be filled in to call the appropriate underlying; implementation. .. code-block:: c++. #ifndef THREAD_SAFETY_ANALYSIS_MUTEX_H; #define THREAD_SAFETY_ANALYSIS_MUTEX_H. // Enable thread safety attributes only with clang.; // The attributes can be safely erased when compiling with other compilers.; #if defined(__clang__) && (!defined(SWIG)); #define THREAD_ANNOTATION_ATTRIBUTE__(x) __attribute__((x)); #else; #define THREAD_ANNOTATION_ATTRIBUTE__(x) // no-op; #endif. #define CAPABILITY(x) \; THREAD_ANNOTATION_ATTRIBUTE__(capability(x)). #define SCOPED_CAPABILITY \; THREAD_ANNOTATION_ATTRIBUTE__(scoped_lockable). #define GUARDED_BY(x) \; THREAD_ANNOTATION_ATTRIBUTE__(guarded_by(x)). #define PT_GUARDED_BY(x) \; THREAD_ANNOTATION_ATTRIBUTE__(pt_guarded_by(x)). #define ACQUIRED_BEFORE(...) \; THREAD_ANNOTATION_ATTRIBUTE__(acquir",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:24744,safe,safety,24744,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['safe'],['safety']
Safety," can see that for creating; volumes one needs to create tracking media before. The way to proceed; for those not interested in performing tracking with external MC's is to; define and use only one `dummy tracking medium` as in the example (or a; `NULL` pointer). ### User Interface for Handling Materials and Media. The **`TGeoManager`** class contains the API for accessing and handling; defined materials:. ``` {.cpp}; TGeoManager::GetMaterial(name);; ```. ## Shapes. Shapes are geometrical objects that provide the basic modeling; functionality. They provide the definition of the `local` coordinate; system of the volume. Any volume must have a shape. Any shape recognized; by the modeller has to derive from the base **`TGeoShape`** class,; providing methods for:. - Finding out if a point defined in their local frame is contained or; not by the shape;; - Computing the distance to enter/exit the shape from a local point,; given a known direction;; - Computing the maximum distance in any direction from a local point; that does NOT result in a boundary crossing of the shape (safe; distance);; - Computing the cosines of the normal vector to the crossed shape; surface, given a starting local point and an ongoing direction. All the features above are globally managed by the modeller in order to; provide navigation functionality. In addition to those, shapes have also; to implement additional specific abstract methods:. - Computation of the minimal box bounding the shape, given that this; box have to be aligned with the local coordinates;; - Algorithms for dividing the shape along a given axis. The modeller currently provides a set of 20 basic shapes, which we will; call `primitives`. It also provides a special class allowing the; creation of shapes as a result of Boolean operations between primitives.; These are called `composite shapes` and the composition operation can be; recursive (combined composites). This allows the creation of a quite; large number of different shape to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:23756,safe,safe,23756,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['safe'],['safe']
Safety," canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a tra",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:3781,safe,safe,3781,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['safe'],['safe']
Safety," changes from the clients to the analysis implementations.; Various alias analysis implementations should use these methods to ensure that; their internal data structures are kept up-to-date as the program changes (for; example, when an instruction is deleted), and clients of alias analysis must be; sure to call these interfaces appropriately. The ``deleteValue`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``deleteValue`` method is called by transformations when they remove an; instruction or any other value from the program (including values that do not; use pointers). Typically alias analyses keep data structures that have entries; for each value in the program. When this method is called, they should remove; any entries for the specified value, if they exist. The ``copyValue`` method; ^^^^^^^^^^^^^^^^^^^^^^^^. The ``copyValue`` method is used when a new value is introduced into the; program. There is no way to introduce a value into the program that did not; exist before (this doesn't make sense for a safe compiler transformation), so; this is the only way to introduce a new value. This method indicates that the; new value has exactly the same properties as the value being copied. The ``replaceWithNewValue`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This method is a simple helper method that is provided to make clients easier to; use. It is implemented by copying the old analysis information to the new; value, then deleting the old value. This method cannot be overridden by alias; analysis implementations. The ``addEscapingUse`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``addEscapingUse`` method is used when the uses of a pointer value have; changed in ways that may invalidate precomputed analysis information.; Implementations may either use this callback to provide conservative responses; for points whose uses have change since analysis time, or may recompute some or; all of their internal state to continue providing accurate responses. In general, any new use of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:15168,safe,safe,15168,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['safe'],['safe']
Safety," channel:; ```; # %bb.0: # %entry; pushq %rax; testl %edi, %edi; jne .LBB0_4; # %bb.1: # %then1; testl %esi, %esi; jne .LBB0_4; # %bb.2: # %then2; testl %edx, %edx; je .LBB0_3; .LBB0_4: # %exit; popq %rax; retq; .LBB0_3: # %danger; movl (%rcx), %edi; callq leak; popq %rax; retq; ```. When we go to speculatively execute the load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; like the following:; ```; # %bb.0: # %entry; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; testl %edi, %edi; jne .LBB0_1; # %bb.2: # %then1; cmovneq %r8, %rax # Conditionally update predicate state.; testl %esi, %esi; jne .LBB0_1; # %bb.3: # %then2; cmovneq %r8, %rax # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:16245,predict,predicted,16245,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['predict'],['predicted']
Safety," classes:. - **`ROOT::Math::Cartesian3D`**, based on (`x,y,z`);. - **`ROOT::Math::Polar3D`**, based on (`r,theta,phi`);. - **`ROOT::Math::Cylindrical3D`**, based on (`rho,z,phi`). - **`ROOT::Math::CylindricalEta3D`**, based on (`rho,eta,phi`), where; `eta` is the pseudo-rapidity;. 4D coordinate system classes:. - **`ROOT::Math::PxPyPzE4D`**, based on based on (`px,py,pz,E`);. - **`ROOT::Math::PxPyPzM4D`**, based on based on (`px,py,pz,M`);. - **`ROOT::Math::PtEtaPhiE4D`**, based on based on (`pt,eta,phi,E`);. - **`ROOT::Math::PtEtaPhiM4D`**, based on based on (`pt,eta,phi,M`);. Users can define the vectors according to the coordinate type, which is; the most efficient for their use. Transformations between the various; coordinate systems are available through copy constructors or the; assignment (=) operator. For maximum flexibility and minimize memory; allocation, the coordinate system classes are templated on the scalar; type. To avoid exposing templated parameter to the users, typedefs are; defined for all types of vectors based on doubles. See in the examples; for all the possible types of vector classes, which can be constructed; by users with the available coordinate system types. #### Coordinate System Tag. The 2D and 3D points and vector classes can be associated to a tag; defining the coordinate system. This can be used to distinguish between; vectors of different coordinate systems like global or local vectors.; The coordinate system tag is a template parameter of the; **`ROOT::Math::`**`DisplacementVector3D` and; `ROOT::Math::PositionVector3D` (and also for 2D classes). A default tag; exists for users who do not need this functionality,; `ROOT::Math::DefaultCoordinateSystemTag`. #### Transformations. The transformations are modeled using simple (non-template) classes,; using double as the scalar type to avoid too large numerical errors. The; transformations are grouped in rotations (in 3 dimensions), Lorentz; transformations and Poincare transformations, w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:71696,avoid,avoid,71696,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['avoid'],['avoid']
Safety," code can call MakeStruct(). Unfortunately, this idiom isn't compatible with nvcc, because it doesn't allow; you to overload based on the H/D attributes. Here's an idiom that works with; both clang and nvcc:. .. code-block:: c++. struct HostS { ... };; struct DeviceS { ... };. #ifdef __NVCC__; #ifndef __CUDA_ARCH__; __host__ HostS MakeStruct() { return HostS(); }; #else; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif; #else; __host__ HostS MakeStruct() { return HostS(); }; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif. // Now host and device code can call MakeStruct(). Hopefully you don't have to do this sort of thing often. Optimizations; =============. Modern CPUs and GPUs are architecturally quite different, so code that's fast; on a CPU isn't necessarily fast on a GPU. We've made a number of changes to; LLVM to make it generate good GPU code. Among these changes are:. * `Straight-line scalar optimizations <https://goo.gl/4Rb9As>`_ -- These; reduce redundancy within straight-line code. * `Aggressive speculative execution; <https://llvm.org/docs/doxygen/html/SpeculativeExecution_8cpp_source.html>`_; -- This is mainly for promoting straight-line scalar optimizations, which are; most effective on code along dominator paths. * `Memory space inference; <https://llvm.org/doxygen/NVPTXInferAddressSpaces_8cpp_source.html>`_ --; In PTX, we can operate on pointers that are in a particular ""address space""; (global, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend. 64-bit integer divides are much slower than 32-bit ones on ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:18494,redund,redundancy,18494,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,1,['redund'],['redundancy']
Safety," collection, the entry in the collection; becomes in turn top level branches, etc. The split level is decreased by; 1 every time a new collection is found. For example if `list` is a; **`TObjArray`**\*. - If `splitlevel = 1`, one top level branch is created for each; element of the **`TObjArray`**. - If `splitlevel = 2`, one top level branch is created for each array; element. If one of the array elements is a **`TCollection`**, one; top level branch will be created for each element of this; collection. In case a collection element is a **`TClonesArray`**, the special Tree; constructor for **`TClonesArray`** is called. The collection itself; cannot be a **`TClonesArray`**. If `name` is given, all branch names; will be prefixed with `name_`. *IMPORTANT NOTE1:* This function should not be called if `splitlevel<1`.; *IMPORTANT NOTE2:* The branches created by this function will have names; corresponding to the collection or object names. It is important to give; names to collections to avoid misleading branch names or identical; branch names. By default collections have a name equal to the; corresponding class name, e.g. the default name of **`TList`** is; ""`TList`"". ## Examples for Writing and Reading Trees. The following sections are examples of writing and reading trees; increasing in complexity from a simple tree with a few variables to a; tree containing folders and complex Event objects. Each example has a; named script in the `$ROOTSYS/tutorials/tree` directory. They are called; tree1.C to tree4.C. The examples are:. - `tree1.C`: a tree with several simple (integers and floating point); variables. - `tree2.C`: a tree built from a C structure (`struct`). This example; uses the `Geant3` C wrapper as an example of a FORTRAN common block; ported to C with a C structure. - `tree3.C:` in this example, we will show how to extend a tree with a; branch from another tree with the Friends feature. These trees have; branches with variable length arrays. Each entry has a varia",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:32917,avoid,avoid,32917,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['avoid'],['avoid']
Safety, compiler-rt/lib/orc/endianness.h; compiler-rt/lib/orc/error.h; compiler-rt/lib/orc/executor_address.h; compiler-rt/lib/orc/extensible_rtti.cpp; compiler-rt/lib/orc/extensible_rtti.h; compiler-rt/lib/orc/log_error_to_stderr.cpp; compiler-rt/lib/orc/macho_ehframe_registration.cpp; compiler-rt/lib/orc/macho_platform.cpp; compiler-rt/lib/orc/macho_platform.h; compiler-rt/lib/orc/run_program_wrapper.cpp; compiler-rt/lib/orc/simple_packed_serialization.h; compiler-rt/lib/orc/wrapper_function_utils.h; compiler-rt/lib/orc/unittests/adt_test.cpp; compiler-rt/lib/orc/unittests/c_api_test.cpp; compiler-rt/lib/orc/unittests/endian_test.cpp; compiler-rt/lib/orc/unittests/error_test.cpp; compiler-rt/lib/orc/unittests/executor_address_test.cpp; compiler-rt/lib/orc/unittests/extensible_rtti_test.cpp; compiler-rt/lib/orc/unittests/orc_unit_test_main.cpp; compiler-rt/lib/orc/unittests/simple_packed_serialization_test.cpp; compiler-rt/lib/orc/unittests/wrapper_function_utils_test.cpp; compiler-rt/lib/safestack/safestack_util.h; compiler-rt/lib/sanitizer_common/sancov_flags.h; compiler-rt/lib/sanitizer_common/sanitizer_allocator_dlsym.h; compiler-rt/lib/sanitizer_common/sanitizer_allocator_report.h; compiler-rt/lib/sanitizer_common/sanitizer_chained_origin_depot.cpp; compiler-rt/lib/sanitizer_common/sanitizer_chained_origin_depot.h; compiler-rt/lib/sanitizer_common/sanitizer_dense_map.h; compiler-rt/lib/sanitizer_common/sanitizer_dense_map_info.h; compiler-rt/lib/sanitizer_common/sanitizer_errno.h; compiler-rt/lib/sanitizer_common/sanitizer_errno_codes.h; compiler-rt/lib/sanitizer_common/sanitizer_flat_map.h; compiler-rt/lib/sanitizer_common/sanitizer_fuchsia.cpp; compiler-rt/lib/sanitizer_common/sanitizer_leb128.h; compiler-rt/lib/sanitizer_common/sanitizer_local_address_space_view.h; compiler-rt/lib/sanitizer_common/sanitizer_lzw.h; compiler-rt/lib/sanitizer_common/sanitizer_placement_new.h; compiler-rt/lib/sanitizer_common/sanitizer_platform.h; compiler-rt/lib/sanitizer_common/sani,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:97202,safe,safestack,97202,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['safe'],['safestack']
Safety," concepts behind the analysis. The; ``GUARDED_BY`` attribute declares that a thread must lock ``mu`` before it can; read or write to ``balance``, thus ensuring that the increment and decrement; operations are atomic. Similarly, ``REQUIRES`` declares that; the calling thread must lock ``mu`` before calling ``withdrawImpl``.; Because the caller is assumed to have locked ``mu``, it is safe to modify; ``balance`` within the body of the method. The ``depositImpl()`` method does not have ``REQUIRES``, so the; analysis issues a warning. Thread safety analysis is not inter-procedural, so; caller requirements must be explicitly declared.; There is also a warning in ``transferFrom()``, because although the method; locks ``this->mu``, it does not lock ``b.mu``. The analysis understands; that these are two separate mutexes, in two different objects. Finally, there is a warning in the ``withdraw()`` method, because it fails to; unlock ``mu``. Every lock must have a corresponding unlock, and the analysis; will detect both double locks, and double unlocks. A function is allowed to; acquire a lock without releasing it, (or vice versa), but it must be annotated; as such (using ``ACQUIRE``/``RELEASE``). Running The Analysis; --------------------. To run the analysis, simply compile with the ``-Wthread-safety`` flag, e.g. .. code-block:: bash. clang -c -Wthread-safety example.cpp. Note that this example assumes the presence of a suitably annotated; :ref:`mutexheader` that declares which methods perform locking,; unlocking, and so on. Basic Concepts: Capabilities; ============================. Thread safety analysis provides a way of protecting *resources* with; *capabilities*. A resource is either a data member, or a function/method; that provides access to some underlying resource. The analysis ensures that; the calling thread cannot access the *resource* (i.e. call the function, or; read/write the data) unless it has the *capability* to do so. Capabilities are associated with named ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:2922,detect,detect,2922,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['detect'],['detect']
Safety," context,; except the result kind is a location description, the compilation unit is; unspecified, the object is unspecified, and an initial stack comprising the; location description of the current CFA (see; :ref:`amdgpu-dwarf-operation-expressions`). The DWARF is ill-formed if the CFA location description is not a memory byte; address location description, or if the register size does not match the size; of an address in the address space of the current CFA location description. *Since the CFA location description is required to be a memory byte address; location description, the value of val_offset(N) will also be a memory byte; address location description since it is offsetting the CFA location; description by N bytes. Furthermore, the value of val_offset(N) will be a; memory byte address in the same address space as the CFA location; description.*. .. note::. Should DWARF allow the address size to be a different size to the size of; the register? Requiring them to be the same bit size avoids any issue of; conversion as the bit contents of the register is simply interpreted as a; value of the address. GDB has a per register hook that allows a target specific conversion on a; register by register basis. It defaults to truncation of bigger registers,; and to actually reading bytes from the next register (or reads out of bounds; for the last register) for smaller registers. There are no GDB tests that; read a register out of bounds (except an illegal hand written assembly; test). *register(R)*; This register has been stored in another register numbered R. The previous value of this register is the location description obtained using; the call frame information for the current frame and current program location; for register R. The DWARF is ill-formed if the size of this register does not match the size; of register R or if there is a cyclic dependency in the call frame; information. .. note::. Should this also allow R to be larger than this register? If so is the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:193298,avoid,avoids,193298,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['avoid'],['avoids']
Safety," coordinate type which; is most efficient for their use. Transformations between the various coordinate; systems are available through copy constructors or the assignment `operator =`.; The coordinate system classes are templated on the scalar type for maximum flexibility,; and to minimize memory usage for some use cases. ### Coordinate System Tag. The 2D and 3D point and vector classes can be associated to a tag defining the; coordinate system. This can be used to distinguish between vectors of different; coordinate systems like global or local vectors. The coordinate system tag is a; template parameter of the ROOT::Math::DisplacementVector3D; (and ROOT::Math::DisplacementVector2D) and ROOT::Math::PositionVector3D; (and ROOT::Math::PositionVector2D) classes. A default tag,; ROOT::Math::DefaultCoordinateSystemTag, exists for users who don't need this; functionality. \anchor GenVectorTypedefs; ## Concrete Vector typedefs. To avoid exposing templated parameters to the users, typedefs are defined for all types of vectors based an `double`s and `float`s.; The table below lists the `double` versions; the `float` counterpart ends on an extra `F`, such as ROOT::Math::XYPointF instead of ROOT::Math::XYPoint. ### Point2D. Type definitions for points in two dimensions, based on ROOT::Math::PositionVector2D, are defined by `Math/Point2D.h`:. * ROOT::Math::XYPoint vector based on x,y coordinates (cartesian); * ROOT::Math::Polar2DPoint vector based on r,phi coordinates (polar). ### Vector2D. Type definitions for vectors in two dimensions, based on ROOT::Math::DisplacementVector2D, are defined by `Math/Vector2D.h`:. * ROOT::Math::XYVector vector based on x,y coordinates (cartesian); * ROOT::Math::Polar2DVector vector based on r,phi coordinates (polar). ### Point3D. Type definitions for points in three dimensions, based on ROOT::Math::PositionVector3D, are defined by `Math/Point3D.h`:. * ROOT::Math::XYZPoint point based on x,y,z coordinates (cartesian); * ROOT::Math::Polar3DPoint ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md:3733,avoid,avoid,3733,math/genvector/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md,1,['avoid'],['avoid']
Safety," copy of a capability, nor can it destroy; one. A thread can only release a capability to another thread, or acquire one; from another thread. The annotations are deliberately agnostic about the; exact mechanism used to acquire and release capabilities; it assumes that the; underlying implementation (e.g. the Mutex implementation) does the handoff in; an appropriate manner. The set of capabilities that are actually held by a given thread at a given; point in program execution is a run-time concept. The static analysis works; by calculating an approximation of that set, called the *capability; environment*. The capability environment is calculated for every program point,; and describes the set of capabilities that are statically known to be held, or; not held, at that particular point. This environment is a conservative; approximation of the full set of capabilities that will actually held by a; thread at run-time. Reference Guide; ===============. The thread safety analysis uses attributes to declare threading constraints.; Attributes must be attached to named declarations, such as classes, methods,; and data members. Users are *strongly advised* to define macros for the various; attributes; example definitions can be found in :ref:`mutexheader`, below.; The following documentation assumes the use of macros. The attributes only control assumptions made by thread safety analysis and the; warnings it issues. They don't affect generated code or behavior at run-time. For historical reasons, prior versions of thread safety used macro names that; were very lock-centric. These macros have since been renamed to fit a more; general capability model. The prior names are still in use, and will be; mentioned under the tag *previously* where appropriate. GUARDED_BY(c) and PT_GUARDED_BY(c); ----------------------------------. ``GUARDED_BY`` is an attribute on data members, which declares that the data; member is protected by the given capability. Read operations on the data; requ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:5943,safe,safety,5943,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['safe'],['safety']
Safety," created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i3",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:19184,risk,risks,19184,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['risk'],['risks']
Safety," debug-location !DILocation(line: 5, column: 1, scope: !6). By default, ``mir-debugify`` inserts ``DBG_VALUE`` instructions **everywhere**; it is legal to do so. In particular, every (non-PHI) machine instruction that; defines a register must be followed by a ``DBG_VALUE`` use of that def. If; an instruction does not define a register, but can be followed by a debug inst,; MIRDebugify inserts a ``DBG_VALUE`` that references a constant. Insertion of; ``DBG_VALUE``'s can be disabled by setting ``-debugify-level=locations``. To run MIRDebugify once, simply insert ``mir-debugify`` into your ``llc``; invocation, like:. .. code-block:: bash. # Before some other pass.; $ llc -run-pass=mir-debugify,other-pass ... # After some other pass.; $ llc -run-pass=other-pass,mir-debugify ... To run MIRDebugify before each pass in a pipeline, use; ``-debugify-and-strip-all-safe``. This can be combined with ``-start-before``; and ``-start-after``. For example:. .. code-block:: bash. $ llc -debugify-and-strip-all-safe -run-pass=... <other llc args>; $ llc -debugify-and-strip-all-safe -O1 <other llc args>. If you want to check it after each pass in a pipeline, use; ``-debugify-check-and-strip-all-safe``. This can also be combined with; ``-start-before`` and ``-start-after``. For example:. .. code-block:: bash. $ llc -debugify-check-and-strip-all-safe -run-pass=... <other llc args>; $ llc -debugify-check-and-strip-all-safe -O1 <other llc args>. To check all debug info from a test, use ``mir-check-debugify``, like:. .. code-block:: bash. $ llc -run-pass=mir-debugify,other-pass,mir-check-debugify. To strip out all debug info from a test, use ``mir-strip-debug``, like:. .. code-block:: bash. $ llc -run-pass=mir-debugify,other-pass,mir-strip-debug. It can be useful to combine ``mir-debugify``, ``mir-check-debugify`` and/or; ``mir-strip-debug`` to identify backend transformations which break in; the presence of debug info. For example, to run the AArch64 backend tests; with all normal passes ""s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst:18180,safe,safe,18180,interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,1,['safe'],['safe']
Safety," define the annotations to empty. For example, the toolchain not; supporting this extension may not have a header defining ``__counted_by``, so; the code using ``__counted_by`` must define it as nothing or include a header; that has the define. .. code-block:: c. #if defined(__has_feature) && __has_feature(bounds_safety); #define __counted_by(T) __attribute__((__counted_by__(T))); // ... other bounds annotations; #else #define __counted_by(T) // defined as nothing; // ... other bounds annotations; #endif. // expands to `void foo(int * ptr, size_t count);`; // when extension is not enabled or not available; void foo(int *__counted_by(count) ptr, size_t count);. Other potential applications of bounds annotations; ==================================================. The bounds annotations provided by the ``-fbounds-safety`` programming model; have potential use cases beyond the language extension itself. For example,; static and dynamic analysis tools could use the bounds information to improve; diagnostics for out-of-bounds accesses, even if ``-fbounds-safety`` is not used.; The bounds annotations could be used to improve C interoperability with; bounds-safe languages, providing a better mapping to bounds-safe types in the; safe language interface. The bounds annotations can also serve as documentation; specifying the relationship between declarations. Limitations; ===========. ``-fbounds-safety`` aims to bring the bounds safety guarantee to the C language,; and it does not guarantee other types of memory safety properties. Consequently,; it may not prevent some of the secondary bounds safety violations caused by; other types of safety violations such as type confusion. For instance,; ``-fbounds-safety`` does not perform type-safety checks on conversions between; `__single`` pointers of different pointee types (e.g., ``char *__single`` →; ``void *__single`` → ``int *__single``) beyond what the foundation languages; (C/C++) already offer. ``-fbounds-safety`` heavily rel",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:46837,safe,safety,46837,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['safe'],['safety']
Safety," dereference, but I know that the; pointer is never null. How can I tell the analyzer that a pointer can never be; null?; How do I tell the static analyzer that I don't care about a specific dead store?; How do I tell the static analyzer that I don't care about a specific unused instance variable in Objective C?; How do I tell the static analyzer that I don't care about a specific unlocalized string?; How do I tell the analyzer that my instance variable does not need to be released in -dealloc under Manual Retain/Release?; How do I decide whether a method's return type should be _Nullable or _Nonnull?; How do I tell the analyzer that I am intentionally violating nullability?; The analyzer assumes that a loop body is never entered. How can I tell it that the loop body will be entered at least once?; How can I suppress a specific analyzer warning?; How can I selectively exclude code the analyzer examines?. Q: How do I tell the analyzer that I do not want the bug being; reported here since my custom error handler will safely end the execution before; the bug is reached?. You can tell the analyzer that this path is unreachable by teaching it about your custom assertion handlers. For example, you can modify the code segment as following. void customAssert() __attribute__((analyzer_noreturn));; int foo(int *b) {; if (!b); customAssert();; return *b;; }; Q: The analyzer reports a null dereference, but I know that the; pointer is never null. How can I tell the analyzer that a pointer can never be; null?. The reason the analyzer often thinks that a pointer can be null is because the preceding code checked compared it against null. So if you are absolutely sure that it cannot be null, remove the preceding check and, preferably, add an assertion as well. For example, in the code segment above, it will be sufficient to remove the if (!b) check. . void usePointer(int *b);; int foo(int *b) {; usePointer(b);; return *b;; }; Q: How do I tell the static analyzer that I don't care abo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/faq.html:1322,safe,safely,1322,interpreter/llvm-project/clang/www/analyzer/faq.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/faq.html,1,['safe'],['safely']
Safety," derived pointer operands are required to be live; over the associated call safepoint even if the base is otherwise unused; afterwards. If we extend our previous example to include a pointless derived pointer,; we get:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; %gep = getelementptr i8, i8 addrspace(1)* %obj, i64 20000; %token = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj, i8 addrspace(1)* %gep); %obj.relocated = call i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %token, i32 7, i32 7); %gep.relocated = call i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %token, i32 7, i32 8); %p = getelementptr i8, i8 addrspace(1)* %gep, i64 -20000; ret i8 addrspace(1)* %p; }. Note that in this example %p and %obj.relocate are the same address and we; could replace one with the other, potentially removing the derived pointer; from the live set at the safepoint entirely. .. _gc_transition_args:. GC Transitions; ^^^^^^^^^^^^^^^^^^. As a practical consideration, many garbage-collected systems allow code that is; collector-aware (""managed code"") to call code that is not collector-aware; (""unmanaged code""). It is common that such calls must also be safepoints, since; it is desirable to allow the collector to run during the execution of; unmanaged code. Furthermore, it is common that coordinating the transition from; managed to unmanaged code requires extra code generation at the call site to; inform the collector of the transition. In order to support these needs, a; statepoint may be marked as a GC transition, and data that is necessary to; perform the transition (if any) may be provided as additional arguments to the; statepoint. Note that although in many cases statepoints may be inferred to be GC; transitions based on the function symbols involved (e.g. a call from a; funct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:16200,safe,safepoint,16200,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['safe'],['safepoint']
Safety," described; below.; 7. SGPR30-31 return address (RA). The code address that the function must; return to when it completes. The value is undefined if the function is *no; return*.; 8. SGPR32 is used for the stack pointer (SP). It is an unswizzled scratch; offset relative to the beginning of the wavefront scratch backing memory. The unswizzled SP can be used with buffer instructions as an unswizzled SGPR; offset with the scratch V# in SGPR0-3 to access the stack in a swizzled; manner. The unswizzled SP value can be converted into the swizzled SP value by:. | swizzled SP = unswizzled SP / wavefront size. This may be used to obtain the private address space address of stack; objects and to convert this address to a flat address by adding the flat; scratch aperture base address. The swizzled SP value is always 4 bytes aligned for the ``r600``; architecture and 16 byte aligned for the ``amdgcn`` architecture. .. note::. The ``amdgcn`` value is selected to avoid dynamic stack alignment for the; OpenCL language which has the largest base type defined as 16 bytes. On entry, the swizzled SP value is the address of the first function; argument passed on the stack. Other stack passed arguments are positive; offsets from the entry swizzled SP value. The function may use positive offsets beyond the last stack passed argument; for stack allocated local variables and register spill slots. If necessary,; the function may align these to greater alignment than 16 bytes. After these; the function may dynamically allocate space for such things as runtime sized; ``alloca`` local allocations. If the function calls another function, it will place any stack allocated; arguments after the last local allocation and adjust SGPR32 to the address; after the last local allocation. 9. All other registers are unspecified.; 10. Any necessary ``s_waitcnt`` has been performed to ensure memory is available; to the function.; 11. Use pass-by-reference (byref) in stead of pass-by-value (byval) for struc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:388982,avoid,avoid,388982,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['avoid'],['avoid']
Safety," dump of my current mood:. * To me it seems obvious that we need to aim for a checker API that is both; simple and powerful. This can probably by keeping the API as powerful as; necessary while providing a layer of simple ready-made solutions on top of it.; Probably a few reusable components for assembling checkers. And this layer; should ideally be pleasant enough to work with, so that people would prefer to; extend it when something is lacking, instead of falling back to the complex; omnipotent API. I'm thinking of AST matchers vs. AST visitors as a roughly; similar situation: matchers are not omnipotent, but they're so nice. * Separation between core and checkers is usually quite strange. Once we have; shared state traits, i generally wouldn't mind having region store or range; constraint manager as checkers (though it's probably not worth it to transform; them - just a mood). The main thing to avoid here would be the situation when; the checker overwrites stuff written by the core because it thinks it has a; better idea what's going on, so the core should provide a good default behavior. * Yeah, i totally care about performance as well, and if i try to implement; approach, i'd make sure it's good. **Artem:**. > Approach (2): We could teach the Store to scan itself for bindings to; > metadata-symbolic-based regions during scanReachableSymbols() whenever; > a region turns out to be reachable. This requires no work on checker side,; > but it sounds performance-heavy. Nope, this approach is wrong. Metadata symbols may become out-of-date: when the; object changes, metadata symbols attached to it aren't changing (because symbols; simply don't change). The same metadata may have different symbols to denote its; value in different moments of time, but at most one of them represents the; actual metadata value. So we'd be escaping more stuff than necessary. If only we had ""ghost fields""; (https://lists.llvm.org/pipermail/cfe-dev/2016-May/049000.html), it would have; been ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst:7034,avoid,avoid,7034,interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,1,['avoid'],['avoid']
Safety," ensures that if the function; may use more stack space than the size of the guard region, stack probing; sequence will be emitted. It takes one required integer value, which; is 4096 by default. If a function that has a ``""stack-probe-size""`` attribute is inlined into; a function with another ``""stack-probe-size""`` attribute, the resulting; function has the ``""stack-probe-size""`` attribute that has the lower; numeric value. If a function that has a ``""stack-probe-size""`` attribute is; inlined into a function that has no ``""stack-probe-size""`` attribute; at all, the resulting function has the ``""stack-probe-size""`` attribute; of the callee.; ``""no-stack-arg-probe""``; This attribute disables ABI-required stack probes, if any.; ``returns_twice``; This attribute indicates that this function can return twice. The C; ``setjmp`` is an example of such a function. The compiler disables; some optimizations (like tail calls) in the caller of these; functions.; ``safestack``; This attribute indicates that; `SafeStack <https://clang.llvm.org/docs/SafeStack.html>`_; protection is enabled for this function. If a function that has a ``safestack`` attribute is inlined into a; function that doesn't have a ``safestack`` attribute or which has an; ``ssp``, ``sspstrong`` or ``sspreq`` attribute, then the resulting; function will have a ``safestack`` attribute.; ``sanitize_address``; This attribute indicates that AddressSanitizer checks; (dynamic address safety analysis) are enabled for this function.; ``sanitize_memory``; This attribute indicates that MemorySanitizer checks (dynamic detection; of accesses to uninitialized memory) are enabled for this function.; ``sanitize_thread``; This attribute indicates that ThreadSanitizer checks; (dynamic thread safety analysis) are enabled for this function.; ``sanitize_hwaddress``; This attribute indicates that HWAddressSanitizer checks; (dynamic address safety analysis based on tagged pointers) are enabled for; this function.; ``sanitize_memtag",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:99940,safe,safestack,99940,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['safe'],['safestack']
Safety," entity types are ``src`` and; ``fun``, which allow users to specify source files and functions, respectively.; Some sanitizer tools may introduce custom entity types and categories - refer to; tool-specific docs. .. code-block:: bash. # The line above is explained in the note above; # Lines starting with # are ignored.; # Turn off checks for the source file; # Entries without sections are placed into [*] and apply to all sanitizers; src:path/to/source/file.c; src:*/source/file.c; # Turn off checks for this main file, including files included by it.; # Useful when the main file instead of an included file should be ignored.; mainfile:file.c; # Turn off checks for a particular functions (use mangled names):; fun:_Z8MyFooBarv; # Glob brace expansions and character ranges are supported; fun:bad_{foo,bar}; src:bad_source[1-9].c; # ""*"" matches zero or more characters; src:bad/sources/*; fun:*BadFunction*; # Specific sanitizer tools may introduce categories.; src:/special/path/*=special_sources; # Sections can be used to limit ignorelist entries to specific sanitizers; [address]; fun:*BadASanFunc*; # Section names are globs; [{cfi-vcall,cfi-icall}]; fun:*BadCfiCall. ``mainfile`` is similar to applying ``-fno-sanitize=`` to a set of files but; does not need plumbing into the build system. This works well for internal; linkage functions but has a caveat for C++ vague linkage functions. C++ vague linkage functions (e.g. inline functions, template instantiations) are; deduplicated at link time. A function (in an included file) ignored by a; specific ``mainfile`` pattern may not be the prevailing copy picked by the; linker. Therefore, using ``mainfile`` requires caution. It may still be useful,; e.g. when patterns are picked in a way to ensure the prevailing one is ignored.; (There is action-at-a-distance risk.). ``mainfile`` can be useful enabling a ubsan check for a large code base when; finding the direct stack frame triggering the failure for every failure is; difficult.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SanitizerSpecialCaseList.rst:4584,risk,risk,4584,interpreter/llvm-project/clang/docs/SanitizerSpecialCaseList.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SanitizerSpecialCaseList.rst,1,['risk'],['risk']
Safety," errors are assertions and the; llvm_unreachable function. Assertions are used to express invariant conditions,; and should include a message describing the invariant:. .. code-block:: c++. assert(isPhysReg(R) && ""All virt regs should have been allocated already."");. The llvm_unreachable function can be used to document areas of control flow; that should never be entered if the program invariants hold:. .. code-block:: c++. enum { Foo, Bar, Baz } X = foo();. switch (X) {; case Foo: /* Handle Foo */; break;; case Bar: /* Handle Bar */; break;; default:; llvm_unreachable(""X should be Foo or Bar here"");; }. Recoverable Errors; ^^^^^^^^^^^^^^^^^^. Recoverable errors represent an error in the program's environment, for example; a resource failure (a missing file, a dropped network connection, etc.), or; malformed input. These errors should be detected and communicated to a level of; the program where they can be handled appropriately. Handling the error may be; as simple as reporting the issue to the user, or it may involve attempts at; recovery. .. note::. While it would be ideal to use this error handling scheme throughout; LLVM, there are places where this hasn't been practical to apply. In; situations where you absolutely must emit a non-programmatic error and; the ``Error`` model isn't workable you can call ``report_fatal_error``,; which will call installed error handlers, print a message, and abort the; program. The use of `report_fatal_error` in this case is discouraged. Recoverable errors are modeled using LLVM's ``Error`` scheme. This scheme; represents errors using function return values, similar to classic C integer; error codes, or C++'s ``std::error_code``. However, the ``Error`` class is; actually a lightweight wrapper for user-defined error types, allowing arbitrary; information to be attached to describe the error. This is similar to the way C++; exceptions allow throwing of user-defined types. Success values are created by calling ``Error::success()``, E",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:18008,recover,recovery,18008,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['recover'],['recovery']
Safety," evaluator operates in C++ mode, utilizing C++ reference types, while; ``-fbounds-safety`` does not currently support C++. This means LLDB’s expression; evaluator can only evaluate a subset of the ``-fbounds-safety`` language model.; Specifically, it’s capable of evaluating the wide pointers that already exist in; the source code. All other expressions are evaluated according to C/C++; semantics. C++ support; ===========. C++ has multiple options to write code in a bounds-safe manner, such as; following the bounds-safety core guidelines and/or using hardened libc++ along; with the `C++ Safe Buffer model; <https://discourse.llvm.org/t/rfc-c-buffer-hardening/65734>`_. However, these; techniques may require ABI changes and may not be applicable to code; interoperating with C. When the ABI of an existing program needs to be preserved; and for headers shared between C and C++, ``-fbounds-safety`` offers a potential; solution. ``-fbounds-safety`` is not currently supported in C++, but we believe the; general approach would be applicable for future efforts. Upstreaming plan; ================. Gradual updates with experimental flag; --------------------------------------. The upstreaming will take place as a series of smaller PRs and we will guard our; implementation with an experimental flag ``-fexperimental-bounds-safety`` until; the usable model is fully upstreamed. Once the model is ready for use, we will; expose the flag ``-fbounds-safety``. Possible patch sets; -------------------. * External bounds annotations and the (late) parsing logic.; * Internal bounds annotations (wide pointers) and their parsing logic.; * Clang code generation for wide pointers with debug information.; * Pointer cast semantics involving bounds annotations (this could be divided; into multiple sub-PRs).; * CFG analysis for pairs of related pointer and count assignments and the likes.; * Bounds check expressions in AST and the Clang code generation (this could also; be divided into multiple sub",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst:10955,safe,safety,10955,interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,1,['safe'],['safety']
Safety," fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructionselect`. .. _progress-fastisel:. FastISel Replacement; --------------------. For the initial FastISel replacement, we intend to fallback to SelectionDAG on; selection failures. Currently, compile-time of the fast pipeline is within 1.5x of FastISel.; We're optimistic we can get to within 1.1/1.2x, but beating FastISel will be; challenging given the multi-pass approach.; Still, supporting all IR (via a complete legalizer) and avoiding the fallback; to SelectionDAG in the worst case should enable better amortized performance; than SelectionDAG+FastISel. ``NOTE``:; We considered never having a fallback to SelectionDAG, instead deciding early; whether a given function is supported by GlobalISel or not. The decision would; be based on :ref:`milegalizer` queries.; We abandoned that for two reasons:; a) on IR inputs, we'd need to basically simulate the :ref:`irtranslator`;; b) to be robust against unforeseen failures and to enable iterative; improvements.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:2744,avoid,avoiding,2744,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,1,['avoid'],['avoiding']
Safety," flag. The output is the; node after the boundary crossing. #### Computing the Safe Radius. Other important navigation query for tracking is the computation of the; safe distance. This represents the `maximum` step that can be made from; the current point in `any direction` that assures that no boundary will; be crossed. Knowing this value gives additional freedom to the stepping; algorithm to propagate the current track on the corresponding range; `without checking` if the current state has changed. In other words, the; modeller insures that the current state does not change in any point; within the safety radius around the current point. The computation of the safe radius is `automatically` computed any time; when the next boundary is queried within a `limited step:`. ``` {.cpp}; TGeoNode *crossed = gGeoManager->FindNextBoundary(pstep);; Double_t safety = gGeoManager->GetSafeDistance();; ```. Otherwise, the computation of safety can always be forced:. ``` {.cpp}; Double_t safety = gGeoManager->Safety();; ```. #### Making a Step. The modeller is able to make steps starting from the current point along; the current direction and having the current step length. The new point; and its corresponding state will be automatically computed:. ``` {.cpp}; TGeoNode *TGeoManager::Step(Bool_t is_geom = kTRUE,; Bool_t cross = kTRUE);; ```. We will explain the method above by its use cases. The input flag; `is_geom` allows specifying if the step is limited by geometrical; reasons (a boundary crossing) or is an arbitrary step. The flag cross; can be used in case the step is made on a boundary and specifies if user; wants to cross or not the boundary. The returned node represents the new; current node after the step was made. - Making a geometrically contained step with boundary crossing; (`is_geom=kTRUE`, `cross=kTRUE`) - This is the default method; behavior. In this case, the step size is supposed to be already set; by a previous `TGeoManager::FindNextBoundary()` call. Due to; fl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:119887,safe,safety,119887,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['safe'],['safety']
Safety," floating-point values to x86_fp80 and; back when performing floating-point math operations; this can lead to results; with different precision than expected and it can alter NaN values. Since; optimizations can make contradicting assumptions, this can lead to arbitrary; miscompilations. See `issue #44218; <https://github.com/llvm/llvm-project/issues/44218>`_.; - x86-32 (even with SSE2 enabled) may implicitly perform such a conversion on; values returned from a function for some calling conventions. See `issue; #66803 <https://github.com/llvm/llvm-project/issues/66803>`_.; - Older MIPS versions use the opposite polarity for the quiet/signaling bit, and; LLVM does not correctly represent this. See `issue #60796; <https://github.com/llvm/llvm-project/issues/60796>`_. .. _fastmath:. Fast-Math Flags; ---------------. LLVM IR floating-point operations (:ref:`fneg <i_fneg>`, :ref:`fadd <i_fadd>`,; :ref:`fsub <i_fsub>`, :ref:`fmul <i_fmul>`, :ref:`fdiv <i_fdiv>`,; :ref:`frem <i_frem>`, :ref:`fcmp <i_fcmp>`), :ref:`phi <i_phi>`,; :ref:`select <i_select>` and :ref:`call <i_call>`; may use the following flags to enable otherwise unsafe; floating-point transformations. ``nnan``; No NaNs - Allow optimizations to assume the arguments and result are not; NaN. If an argument is a nan, or the result would be a nan, it produces; a :ref:`poison value <poisonvalues>` instead. ``ninf``; No Infs - Allow optimizations to assume the arguments and result are not; +/-Inf. If an argument is +/-Inf, or the result would be +/-Inf, it; produces a :ref:`poison value <poisonvalues>` instead. ``nsz``; No Signed Zeros - Allow optimizations to treat the sign of a zero; argument or zero result as insignificant. This does not imply that -0.0; is poison and/or guaranteed to not exist in the operation. ``arcp``; Allow Reciprocal - Allow optimizations to use the reciprocal of an; argument rather than perform division. ``contract``; Allow floating-point contraction (e.g. fusing a multiply followed by an; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:161782,unsafe,unsafe,161782,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['unsafe'],['unsafe']
Safety," foo(struct x*P);; struct x testfunc() {; struct x V1, V2;; foo(&V1);; V2 = V1;. return V2;; }. We currently compile this to:; $ clang t.c -S -o - -O0 -emit-llvm | opt -sroa -S. %struct.x = type { i8, [4 x i32] }. define void @testfunc(%struct.x* sret %agg.result) nounwind ssp {; entry:; %V1 = alloca %struct.x, align 4; call void @foo(%struct.x* %V1); %tmp1 = bitcast %struct.x* %V1 to i8*; %0 = bitcast %struct.x* %V1 to i160*; %srcval1 = load i160* %0, align 4; %tmp2 = bitcast %struct.x* %agg.result to i8*; %1 = bitcast %struct.x* %agg.result to i160*; store i160 %srcval1, i160* %1, align 4; ret void; }. This happens because SRoA sees that the temp alloca has is being memcpy'd into; and out of and it has holes and it has to be conservative. If we knew about the; holes, then this could be much much better. Having information about these holes would also improve memcpy (etc) lowering at; llc time when it gets inlined, because we can use smaller transfers. This also; avoids partial register stalls in some important cases. //===---------------------------------------------------------------------===//. We don't fold (icmp (add) (add)) unless the two adds only have a single use.; There are a lot of cases that we're refusing to fold in (e.g.) 256.bzip2, for; example:. %indvar.next90 = add i64 %indvar89, 1 ;; Has 2 uses; %tmp96 = add i64 %tmp95, 1 ;; Has 1 use; %exitcond97 = icmp eq i64 %indvar.next90, %tmp96. We don't fold this because we don't want to introduce an overlapped live range; of the ivar. However if we can make this more aggressive without causing; performance issues in two ways:. 1. If *either* the LHS or RHS has a single use, we can definitely do the; transformation. In the overlapping liverange case we're trading one register; use for one fewer operation, which is a reasonable trade. Before doing this; we should verify that the llc output actually shrinks for some benchmarks.; 2. If both ops have multiple uses, we can still fold it if the operations are; bot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:63413,avoid,avoids,63413,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['avoid'],['avoids']
Safety," from a suitable command-prompt window. Using Clang Tools; =================. After you completed the previous steps, you are ready to run clang tools. If; you have a recent clang installed, you should have ``clang-check`` in; ``$PATH``. Try to run it on any ``.cpp`` file inside the LLVM source tree:. .. code-block:: console. $ clang-check tools/clang/lib/Tooling/CompilationDatabase.cpp. If you're using vim, it's convenient to have clang-check integrated. Put; this into your ``.vimrc``:. ::. function! ClangCheckImpl(cmd); if &autowrite | wall | endif; echo ""Running "" . a:cmd . "" ...""; let l:output = system(a:cmd); cexpr l:output; cwindow; let w:quickfix_title = a:cmd; if v:shell_error != 0; cc; endif; let g:clang_check_last_cmd = a:cmd; endfunction. function! ClangCheck(); let l:filename = expand('%'); if l:filename =~ '\.\(cpp\|cxx\|cc\|c\)$'; call ClangCheckImpl(""clang-check "" . l:filename); elseif exists(""g:clang_check_last_cmd""); call ClangCheckImpl(g:clang_check_last_cmd); else; echo ""Can't detect file's compilation arguments and no previous clang-check invocation!""; endif; endfunction. nmap <silent> <F5> :call ClangCheck()<CR><CR>. When editing a .cpp/.cxx/.cc/.c file, hit F5 to reparse the file. In; case the current file has a different extension (for example, .h), F5; will re-run the last clang-check invocation made from this vim instance; (if any). The output will go into the error window, which is opened; automatically when clang-check finds errors, and can be re-opened with; ``:cope``. Other ``clang-check`` options that can be useful when working with clang; AST:. * ``-ast-print`` --- Build ASTs and then pretty-print them.; * ``-ast-dump`` --- Build ASTs and then debug dump them.; * ``-ast-dump-filter=<string>`` --- Use with ``-ast-dump`` or ``-ast-print`` to; dump/print only AST declaration nodes having a certain substring in a; qualified name. Use ``-ast-list`` to list all filterable declaration node; names.; * ``-ast-list`` --- Build ASTs and print the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HowToSetupToolingForLLVM.rst:5480,detect,detect,5480,interpreter/llvm-project/clang/docs/HowToSetupToolingForLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HowToSetupToolingForLLVM.rst,1,['detect'],['detect']
Safety," function that has a ``""stack-probe-size""`` attribute is; inlined into a function that has no ``""stack-probe-size""`` attribute; at all, the resulting function has the ``""stack-probe-size""`` attribute; of the callee.; ``""no-stack-arg-probe""``; This attribute disables ABI-required stack probes, if any.; ``returns_twice``; This attribute indicates that this function can return twice. The C; ``setjmp`` is an example of such a function. The compiler disables; some optimizations (like tail calls) in the caller of these; functions.; ``safestack``; This attribute indicates that; `SafeStack <https://clang.llvm.org/docs/SafeStack.html>`_; protection is enabled for this function. If a function that has a ``safestack`` attribute is inlined into a; function that doesn't have a ``safestack`` attribute or which has an; ``ssp``, ``sspstrong`` or ``sspreq`` attribute, then the resulting; function will have a ``safestack`` attribute.; ``sanitize_address``; This attribute indicates that AddressSanitizer checks; (dynamic address safety analysis) are enabled for this function.; ``sanitize_memory``; This attribute indicates that MemorySanitizer checks (dynamic detection; of accesses to uninitialized memory) are enabled for this function.; ``sanitize_thread``; This attribute indicates that ThreadSanitizer checks; (dynamic thread safety analysis) are enabled for this function.; ``sanitize_hwaddress``; This attribute indicates that HWAddressSanitizer checks; (dynamic address safety analysis based on tagged pointers) are enabled for; this function.; ``sanitize_memtag``; This attribute indicates that MemTagSanitizer checks; (dynamic address safety analysis based on Armv8 MTE) are enabled for; this function.; ``speculative_load_hardening``; This attribute indicates that; `Speculative Load Hardening <https://llvm.org/docs/SpeculativeLoadHardening.html>`_; should be enabled for the function body. Speculative Load Hardening is a best-effort mitigation against; information leak attacks that make us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:100431,safe,safety,100431,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['safe'],['safety']
Safety," generally happens not only for the detector; modules, but also for their components. The accurate knowledge of the; detector real misalignments can be extremely important for getting close; to its designed resolution and the expected tracking efficiency.; **`TGeo`** offers tools for representing positioning misalignments,; applying them to the ideal geometry and performing navigation under; these conditions. Detector tracking algorithms can then directly query; the geometry for navigation purposes or for retrieving actual; misalignment information. ### Physical Nodes. Physical nodes are the actual ""touchable"" objects in the geometry,; representing actually a path of positioned volumes starting with the; top node: `path=/TOP/A_1/B_4/C_3` , where `A`, `B`, `C` represent names; of volumes. The number of physical nodes is given by the total number of; possible of branches in the geometry hierarchy. In case of detector; geometries and specially for calorimeters this number can be of the; order 106-109, therefore it is impossible to create all physical nodes; as objects in memory. In **`TGeo`**, physical nodes are represented by; the class **`TGeoPhysicalNode`** and can be created on demand for; alignment purposes:. ``` {.cpp}; TGeoPhysicalNode(const char* path); ```. The knowledge of the path to the objects that need to be misaligned is; essential since there is no other way of identifying them. One can; however create ""symbolic links"" to any complex path to make it more; representable for the object it designates:. ``` {.cpp}; TGeoPNEntry(const char* unique_name, const char* path); void TGeoPNEntry::SetPhysicalNode(TGeoPhysicalNode *node); ```. Such a symbolic link hides the complexity of the path to the align; object and replaces it with a more meaningful name. In addition,; **`TGeoPNEntry`** objects are faster to search by name and they may; optionally store an additional user matrix. ``` {.cpp}; // Creating a symlink object.; TGeoPNEntry *TGeoManager::SetAlignableEn",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:146490,detect,detector,146490,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['detect'],['detector']
Safety," has type; ``U oq *``, where ``oq`` is an ownership qualifier, then the argument is a; candidate for :arc-term:`pass-by-writeback`` if:. * ``oq`` is ``__strong`` or ``__weak``, and; * it would be legal to initialize a ``T __strong *`` with a ``U __strong *``. For purposes of overload resolution, an implicit conversion sequence requiring; a pass-by-writeback is always worse than an implicit conversion sequence not; requiring a pass-by-writeback. The pass-by-writeback is ill-formed if the argument expression does not have a; legal form:. * ``&var``, where ``var`` is a scalar variable of automatic storage duration; with retainable object pointer type; * a conditional expression where the second and third operands are both legal; forms; * a cast whose operand is a legal form; * a null pointer constant. .. admonition:: Rationale. The restriction in the form of the argument serves two purposes. First, it; makes it impossible to pass the address of an array to the argument, which; serves to protect against an otherwise serious risk of mis-inferring an; ""array"" argument as an out-parameter. Second, it makes it much less likely; that the user will see confusing aliasing problems due to the implementation,; below, where their store to the writeback temporary is not immediately seen; in the original argument variable. A pass-by-writeback is evaluated as follows:. #. The argument is evaluated to yield a pointer ``p`` of type ``U oq *``.; #. If ``p`` is a null pointer, then a null pointer is passed as the argument,; and no further work is required for the pass-by-writeback.; #. Otherwise, a temporary of type ``T __autoreleasing`` is created and; initialized to a null pointer.; #. If the parameter is not an Objective-C method parameter marked ``out``,; then ``*p`` is read, and the result is written into the temporary with; primitive semantics.; #. The address of the temporary is passed as the argument to the actual call.; #. After the call completes, the temporary is loaded with ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:49621,risk,risk,49621,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['risk'],['risk']
Safety," have pretty similar semantics with Clang modules.; The semantics of both of them are like headers. In fact, we could even ""mimic"" the sytle of header units by Clang modules:. .. code-block:: c++. module ""iostream"" {; export *; header ""/path/to/libstdcxx/iostream""; }. .. code-block:: console. $ clang++ -std=c++20 -fimplicit-modules -fmodule-map-file=.modulemap main.cpp. It would be simpler if we are using libcxx:. .. code-block:: console. $ clang++ -std=c++20 main.cpp -fimplicit-modules -fimplicit-module-maps. Since there is already one; `module map <https://github.com/llvm/llvm-project/blob/main/libcxx/include/module.modulemap.in>`_; in the source of libcxx. Then immediately leads to the question: why don't we implement header units through Clang header modules?. The main reason for this is that Clang modules have more semantics like hierarchy or; wrapping multiple headers together as a big module.; However, these things are not part of Standard C++ Header units,; and we want to avoid the impression that these additional semantics get interpreted as Standard C++ behavior. Another reason is that there are proposals to introduce module mappers to the C++ standard; (for example, https://wg21.link/p1184r2).; If we decide to reuse Clang's modulemap, we may get in trouble once we need to introduce another module mapper. So the final answer for why we don't reuse the interface of Clang modules for header units is that; there are some differences between header units and Clang modules and that ignoring those; differences now would likely become a problem in the future. Discover Dependencies; =====================. Prior to modules, all the translation units can be compiled parallelly.; But it is not true for the module units. The presence of module units requires; us to compile the translation units in a (topological) order. The clang-scan-deps scanner implemented; `P1689 paper <https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p1689r5.html>`_; to describe the order.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst:31999,avoid,avoid,31999,interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,1,['avoid'],['avoid']
Safety," i32 @strlen(i8* %683) nounwind readonly . This could be eliminated by doing the strlen once in bb8, saving code size and; improving perf on the bb8->9->10 path. //===---------------------------------------------------------------------===//. I see an interesting fully redundant call to strlen left in 186.crafty:InputMove; which looks like:; %movetext11 = getelementptr [128 x i8]* %movetext, i32 0, i32 0 ; . bb62: ; preds = %bb55, %bb53; %promote.0 = phi i32 [ %169, %bb55 ], [ 0, %bb53 ] ; %171 = call i32 @strlen(i8* %movetext11) nounwind readonly align 1; %172 = add i32 %171, -1 ; <i32> [#uses=1]; %173 = getelementptr [128 x i8]* %movetext, i32 0, i32 %172 . ... no stores ...; br i1 %or.cond, label %bb65, label %bb72. bb65: ; preds = %bb62; store i8 0, i8* %173, align 1; br label %bb72. bb72: ; preds = %bb65, %bb62; %trank.1 = phi i32 [ %176, %bb65 ], [ -1, %bb62 ] ; %177 = call i32 @strlen(i8* %movetext11) nounwind readonly align 1. Note that on the bb62->bb72 path, that the %177 strlen call is partially; redundant with the %171 call. At worst, we could shove the %177 strlen call; up into the bb65 block moving it out of the bb62->bb72 path. However, note; that bb65 stores to the string, zeroing out the last byte. This means that on; that path the value of %177 is actually just %171-1. A sub is cheaper than a; strlen!. This pattern repeats several times, basically doing:. A = strlen(P);; P[A-1] = 0;; B = strlen(P);; where it is ""obvious"" that B = A-1. //===---------------------------------------------------------------------===//. 186.crafty has this interesting pattern with the ""out.4543"" variable:. call void @llvm.memcpy.i32(; i8* getelementptr ([10 x i8]* @out.4543, i32 0, i32 0),; i8* getelementptr ([7 x i8]* @""\01LC28700"", i32 0, i32 0), i32 7, i32 1) ; %101 = call@printf(i8* ... @out.4543, i32 0, i32 0)) nounwind . It is basically doing:. memcpy(globalarray, ""string"");; printf(..., globalarray);; ; Anyway, by knowing that printf just reads the memory and forw",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:40891,redund,redundant,40891,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['redund'],['redundant']
Safety," if there are no users.; | ``use_iterator use_begin()`` - Get an iterator to the start of the; use-list.; | ``use_iterator use_end()`` - Get an iterator to the end of the use-list.; | ``User *use_back()`` - Returns the last element in the list. These methods are the interface to access the def-use information in LLVM.; As with all other iterators in LLVM, the naming conventions follow the; conventions defined by the STL_. * ``Type *getType() const``; This method returns the Type of the Value. * | ``bool hasName() const``; | ``std::string getName() const``; | ``void setName(const std::string &Name)``. This family of methods is used to access and assign a name to a ``Value``, be; aware of the :ref:`precaution above <nameWarning>`. * ``void replaceAllUsesWith(Value *V)``. This method traverses the use list of a ``Value`` changing all User_\ s of the; current value to refer to ""``V``"" instead. For example, if you detect that an; instruction always produces a constant value (for example through constant; folding), you can replace all uses of the instruction with the constant like; this:. .. code-block:: c++. Inst->replaceAllUsesWith(ConstVal);. .. _User:. The ``User`` class; ------------------. ``#include ""llvm/IR/User.h""``. header source: `User.h <https://llvm.org/doxygen/User_8h_source.html>`_. doxygen info: `User Class <https://llvm.org/doxygen/classllvm_1_1User.html>`_. Superclass: Value_. The ``User`` class is the common base class of all LLVM nodes that may refer to; ``Value``\ s. It exposes a list of ""Operands"" that are all of the ``Value``\ s; that the User is referring to. The ``User`` class itself is a subclass of; ``Value``. The operands of a ``User`` point directly to the LLVM ``Value`` that it refers; to. Because LLVM uses Static Single Assignment (SSA) form, there can only be; one definition referred to, allowing this direct connection. This connection; provides the use-def information in LLVM. .. _m_User:. Important Public Members of the ``User`` class; ^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:144423,detect,detect,144423,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['detect'],['detect']
Safety," in RooFit-based frameworks. If you make sure that your framework compiles both; with and without `ROOFIT_MEMORY_SAFE_INTERFACES`, you can get rid of all memory; leaks related to RooFit user error! After making the necessary changes, you can; remove the marco definition again to keep backwards compatibility. Note that the memory-safe interfaces might become the default at some point, so; doing this **backwards-compatible migration early** is strongly encouraged and; appreciated. ### Removal of some memory-unsafe interfaces. * The final `bool takeOwnership` parameter of the **RooAddition** and; **RooStats::HistFactory::PiecewiseInterpolation** constructors was removed.; This is to avoid situations where ownership is not clear to the compiler.; Now, ownership of the input RooAbsArgs is never passed in the constructor. If; you want the pass input ownership to the created object, please use; `addOwnedComponents`. If you want to be extra safe, make sure the inputs are; in an owning collection and then `std::move` the collection, so that the; ownership is always clear. Example:; ```c++; RooArgList sumSet;; sumSet.add(*(new RooRealVar(""var1"", ""var1"", 1.0)));; sumSet.add(*(new RooRealVar(""var2"", ""var2"", 3.0)));; RooAddition addition{""addition"", ""addition"", sumSet, /*takeOwnership=*/true};; ```; should become:; ```c++; RooArgList sumSet;; sumSet.addOwned(std::make_unique<RooRealVar>(""var1"", ""var1"", 1.0));; sumSet.addOwned(std::make_unique<RooRealVar>(""var2"", ""var2"", 3.0));; RooAddition addition{""addition"", ""addition"", sumSet};; addition.addOwnedComponents(std::move(sumSet));; ```. ### Deprecation of legacy iterators. The following methods related to the RooFit legacy iterators are deprecated and will be removed in ROOT 6.34.; They should be replaced with the suitable STL-compatible interfaces, or you can just use range-based loops:. - `RooAbsArg::clientIterator()`: use `clients()` and `begin()`, `end()` or range-based loops instead; - `RooAbsArg::valueClientIterator()`: use `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:11069,safe,safe,11069,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['safe'],['safe']
Safety," in the example above:. - *ExecutionSession* represents the JIT'd program and provides context for the; JIT: It contains the JITDylibs, error reporting mechanisms, and dispatches the; materializers. - *JITDylibs* provide the symbol tables. - *Layers* (ObjLinkingLayer and CXXLayer) are wrappers around compilers and; allow clients to add uncompiled program representations supported by those; compilers to JITDylibs. - *ResourceTrackers* allow you to remove code. Several other important APIs are used explicitly. JIT clients need not be aware; of them, but Layer authors will use them:. - *MaterializationUnit* - When XXXLayer::add is invoked it wraps the given; program representation (in this example, C++ source) in a MaterializationUnit,; which is then stored in the JITDylib. MaterializationUnits are responsible for; describing the definitions they provide, and for unwrapping the program; representation and passing it back to the layer when compilation is required; (this ownership shuffle makes writing thread-safe layers easier, since the; ownership of the program representation will be passed back on the stack,; rather than having to be fished out of a Layer member, which would require; synchronization). - *MaterializationResponsibility* - When a MaterializationUnit hands a program; representation back to the layer it comes with an associated; MaterializationResponsibility object. This object tracks the definitions; that must be materialized and provides a way to notify the JITDylib once they; are either successfully materialized or a failure occurs. Absolute Symbols, Aliases, and Reexports; ========================================. ORC makes it easy to define symbols with absolute addresses, or symbols that; are simply aliases of other symbols:. Absolute Symbols; ----------------. Absolute symbols are symbols that map directly to addresses without requiring; further materialization, for example: ""foo"" = 0x1234. One use case for; absolute symbols is allowing resolution ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:12335,safe,safe,12335,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['safe'],['safe']
Safety," in; crash triage by identifying the (possibly inlined) function where the bad; memory access occurred. This rule is also meant to assist SamplePGO by banning; scenarios in which a sample of a block containing a merged instruction is; misattributed to a block containing one of the instructions-to-be-merged. Examples of transformations that should follow this rule include:. * Merging identical loads/stores which occur on both sides of a CFG diamond; (see the ``MergedLoadStoreMotion`` pass). * Merging identical loop-invariant stores (see the LICM utility; ``llvm::promoteLoopAccessesToScalars``). * Peephole optimizations which combine multiple instructions together, like; ``(add (mul A B) C) => llvm.fma.f32(A, B, C)``. Note that the location of; the ``fma`` does not exactly correspond to the locations of either the; ``mul`` or the ``add`` instructions. Examples of transformations for which this rule *does not* apply include:. * Block-local peepholes which delete redundant instructions, like; ``(sext (zext i8 %x to i16) to i32) => (zext i8 %x to i32)``. The inner; ``zext`` is modified but remains in its block, so the rule for; :ref:`preserving locations<WhenToPreserveLocation>` should apply. * Converting an if-then-else CFG diamond into a ``select``. Preserving the; debug locations of speculated instructions can make it seem like a condition; is true when it's not (or vice versa), which leads to a confusing; single-stepping experience. The rule for; :ref:`dropping locations<WhenToDropLocation>` should apply here. * Hoisting identical instructions which appear in several successor blocks into; a predecessor block (see ``BranchFolder::HoistCommonCodeInSuccs``). In this; case there is no single merged instruction. The rule for; :ref:`dropping locations<WhenToDropLocation>` applies. .. _WhenToDropLocation:. When to drop an instruction location; ------------------------------------. A transformation should drop debug locations if the rules for; :ref:`preserving<WhenToPreserve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst:4679,redund,redundant,4679,interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,1,['redund'],['redundant']
Safety," information about; a function. Function attributes are considered to be part of the; function, not of the function type, so functions with different function; attributes can have the same function type. Function attributes are simple keywords that follow the type specified.; If multiple attributes are needed, they are space separated. For; example:. .. code-block:: llvm. define void @f() noinline { ... }; define void @f() alwaysinline { ... }; define void @f() alwaysinline optsize { ... }; define void @f() optsize { ... }. ``alignstack(<n>)``; This attribute indicates that, when emitting the prologue and; epilogue, the backend should forcibly align the stack pointer.; Specify the desired alignment, which must be a power of two, in; parentheses.; ``""alloc-family""=""FAMILY""``; This indicates which ""family"" an allocator function is part of. To avoid; collisions, the family name should match the mangled name of the primary; allocator function, that is ""malloc"" for malloc/calloc/realloc/free,; ""_Znwm"" for ``::operator::new`` and ``::operator::delete``, and; ""_ZnwmSt11align_val_t"" for aligned ``::operator::new`` and; ``::operator::delete``. Matching malloc/realloc/free calls within a family; can be optimized, but mismatched ones will be left alone.; ``allockind(""KIND"")``; Describes the behavior of an allocation function. The KIND string contains comma; separated entries from the following options:. * ""alloc"": the function returns a new block of memory or null.; * ""realloc"": the function returns a new block of memory or null. If the; result is non-null the memory contents from the start of the block up to; the smaller of the original allocation size and the new allocation size; will match that of the ``allocptr`` argument and the ``allocptr``; argument is invalidated, even if the function returns the same address.; * ""free"": the function frees the block of memory specified by ``allocptr``.; Functions marked as ""free"" ``allockind`` must return void.; * ""uninitialized"": Any n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:77767,avoid,avoid,77767,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['avoid'],['avoid']
Safety," input for our; VM. Performance is not wonderful, but it works right.; * The file is scheduled to be compiled (rigorously) at a later; time. This could be done by some background process or by a second; processor in the system during idle time or something...; * To keep things ""safe"" ie to enforce a sandbox on Java/foreign code,; we could sign the generated VM code with a host specific private; key. Then before the code is executed/loaded, we can check to see if; the trusted compiler generated the code. This would be much quicker; than having to validate consistency (especially if bounds checks have; been removed, for example). > This is important because the audiences for these two goals are very; > different. Architects and many compiler people care much more about; > the second question. The Java compiler and OS community care much more; > about the first one. 3. By focusing on a more low level virtual machine, we have much more room; for value add. The nice safe ""sandbox"" VM can be provided as a layer; on top of it. It also lets us focus on the more interesting compilers; related projects. > 2. Design issues to consider (an initial list that we should continue; > to modify). Note that I'm not trying to suggest actual solutions here,; > but just various directions we can pursue:. Understood. :). > a. A single-assignment VM, which we've both already been thinking; > about. Yup, I think that this makes a lot of sense. I am still intrigued,; however, by the prospect of a minimally allocated VM representation... I; think that it could have definite advantages for certain applications; (think very small machines, like PDAs). I don't, however, think that our; initial implementations should focus on this. :). Here are some other auxiliary goals that I think we should consider:. 1. Primary goal: Support a high performance dynamic compilation; system. This means that we have an ""ideal"" division of labor between; the runtime and static compilers. Of course, the other goals ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:2360,safe,safe,2360,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['safe'],['safe']
Safety," instead of the method `FindNextBoundary()`; whenever the tracking is not imposed in association with an external MC; transport engine (which provide their own algorithms for boundary; crossing). ``` {.cpp}; TGeoNode *TGeoManager::FindNextBoundaryAndStep(Double_t stepmax,; Bool_t comp_safe=kFALSE);; ```. The meaning of the parameters here is the same as for FindNextBoundary,; but the safety value is triggered by an input flag. The output is the; node after the boundary crossing. #### Computing the Safe Radius. Other important navigation query for tracking is the computation of the; safe distance. This represents the `maximum` step that can be made from; the current point in `any direction` that assures that no boundary will; be crossed. Knowing this value gives additional freedom to the stepping; algorithm to propagate the current track on the corresponding range; `without checking` if the current state has changed. In other words, the; modeller insures that the current state does not change in any point; within the safety radius around the current point. The computation of the safe radius is `automatically` computed any time; when the next boundary is queried within a `limited step:`. ``` {.cpp}; TGeoNode *crossed = gGeoManager->FindNextBoundary(pstep);; Double_t safety = gGeoManager->GetSafeDistance();; ```. Otherwise, the computation of safety can always be forced:. ``` {.cpp}; Double_t safety = gGeoManager->Safety();; ```. #### Making a Step. The modeller is able to make steps starting from the current point along; the current direction and having the current step length. The new point; and its corresponding state will be automatically computed:. ``` {.cpp}; TGeoNode *TGeoManager::Step(Bool_t is_geom = kTRUE,; Bool_t cross = kTRUE);; ```. We will explain the method above by its use cases. The input flag; `is_geom` allows specifying if the step is limited by geometrical; reasons (a boundary crossing) or is an arbitrary step. The flag cross; can be used in case th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:119506,safe,safety,119506,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['safe'],['safety']
Safety," into memory at arbitrary locations,; and set bias to the offset between the original and the new counter location,; at which point every subsequent counter access will be to the new location,; which allows updating profile directly akin to the continuous mode. The advantage of this approach is that doesn't require any special OS support.; The disadvantage is the extra overhead due to additional instructions required; for each counter access (overhead both in terms of binary size and performance); plus duplication of counters (i.e. one copy in the binary itself and another; copy that's mapped into memory). This implementation can be also enabled for; other platforms by passing the ``-runtime-counter-relocation`` option to the; backend during compilation. For a program such as the `Lit <https://llvm.org/docs/CommandGuide/lit.html>`_; testing tool which invokes other programs, it may be necessary to set; ``LLVM_PROFILE_FILE`` for each invocation. The pattern strings ""%p"" or ""%Nm""; may help to avoid corruption due to concurrency. Note that ""%p"" is also a Lit; token and needs to be escaped as ""%%p"". .. code-block:: console. % clang++ -fprofile-instr-generate -fcoverage-mapping -mllvm -runtime-counter-relocation foo.cc -o foo. Creating coverage reports; =========================. Raw profiles have to be **indexed** before they can be used to generate; coverage reports. This is done using the ""merge"" tool in ``llvm-profdata``; (which can combine multiple raw profiles and index them at the same time):. .. code-block:: console. # Step 3(a): Index the raw profile.; % llvm-profdata merge -sparse foo.profraw -o foo.profdata. For an example of merging multiple profiles created by testing,; see the LLVM `coverage build script <https://github.com/llvm/llvm-zorg/blob/main/zorg/jenkins/jobs/jobs/llvm-coverage>`_. There are multiple different ways to render coverage reports. The simplest; option is to generate a line-oriented report:. .. code-block:: console. # Step 3(b): Create a l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:5611,avoid,avoid,5611,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['avoid'],['avoid']
Safety," is a list of differences between :program:`llvm-readelf` and; :program:`llvm-readobj`:. - :program:`llvm-readelf` uses `GNU` for the :option:`--elf-output-style` option; by default. :program:`llvm-readobj` uses `LLVM`.; - :program:`llvm-readelf` allows single-letter grouped flags (e.g.; ``llvm-readelf -SW`` is the same as ``llvm-readelf -S -W``).; :program:`llvm-readobj` does not allow grouping.; - :program:`llvm-readelf` provides :option:`-s` as an alias for; :option:`--symbols`, for GNU :program:`readelf` compatibility, whereas it is; an alias for :option:`--section-headers` in :program:`llvm-readobj`.; - :program:`llvm-readobj` provides ``-t`` as an alias for :option:`--symbols`.; :program:`llvm-readelf` does not.; - :program:`llvm-readobj` provides ``--sr``, ``--sd``, ``--st`` and ``--dt`` as; aliases for :option:`--section-relocations`, :option:`--section-data`,; :option:`--section-symbols` and :option:`--dyn-symbols` respectively.; :program:`llvm-readelf` does not provide these aliases, to avoid conflicting; with grouped flags. GENERAL AND MULTI-FORMAT OPTIONS; --------------------------------. These options are applicable to more than one file format, or are unrelated to; file formats. .. option:: --all. Equivalent to specifying all the main display options relevant to the file; format. .. option:: --addrsig. Display the address-significance table. .. option:: --decompress, -z. Dump decompressed section content when used with ``-x`` or ``-p``.; If the section(s) are not compressed, they are displayed as is. .. option:: --expand-relocs. When used with :option:`--relocs`, display each relocation in an expanded; multi-line format. .. option:: --file-header, -h. Display file headers. .. option:: --headers, -e. Equivalent to setting: :option:`--file-header`, :option:`--program-headers`,; and :option:`--sections`. .. option:: --help. Display a summary of command line options. .. option:: --hex-dump=<section[,section,...]>, -x. Display the specified section(s) as he",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:1679,avoid,avoid,1679,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,1,['avoid'],['avoid']
Safety," is also a warning in ``transferFrom()``, because although the method; locks ``this->mu``, it does not lock ``b.mu``. The analysis understands; that these are two separate mutexes, in two different objects. Finally, there is a warning in the ``withdraw()`` method, because it fails to; unlock ``mu``. Every lock must have a corresponding unlock, and the analysis; will detect both double locks, and double unlocks. A function is allowed to; acquire a lock without releasing it, (or vice versa), but it must be annotated; as such (using ``ACQUIRE``/``RELEASE``). Running The Analysis; --------------------. To run the analysis, simply compile with the ``-Wthread-safety`` flag, e.g. .. code-block:: bash. clang -c -Wthread-safety example.cpp. Note that this example assumes the presence of a suitably annotated; :ref:`mutexheader` that declares which methods perform locking,; unlocking, and so on. Basic Concepts: Capabilities; ============================. Thread safety analysis provides a way of protecting *resources* with; *capabilities*. A resource is either a data member, or a function/method; that provides access to some underlying resource. The analysis ensures that; the calling thread cannot access the *resource* (i.e. call the function, or; read/write the data) unless it has the *capability* to do so. Capabilities are associated with named C++ objects which declare specific; methods to acquire and release the capability. The name of the object serves; to identify the capability. The most common example is a mutex. For example,; if ``mu`` is a mutex, then calling ``mu.Lock()`` causes the calling thread; to acquire the capability to access data that is protected by ``mu``. Similarly,; calling ``mu.Unlock()`` releases that capability. A thread may hold a capability either *exclusively* or *shared*. An exclusive; capability can be held by only one thread at a time, while a shared capability; can be held by many threads at the same time. This mechanism enforces a; multiple-re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:3518,safe,safety,3518,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['safe'],['safety']
Safety," key adaptation. Notably, we only choose a very small percentage of allocations; to sample, and apply guard pages to these sampled allocations only. The sampling; is small enough to allow us to have very low performance overhead. There is a small, tunable memory overhead that is fixed for the lifetime of the; process. This is approximately ~40KiB per process using the default settings,; depending on the average size of your allocations. GWP-ASan vs. ASan; =================. Unlike `AddressSanitizer <https://clang.llvm.org/docs/AddressSanitizer.html>`_,; GWP-ASan does not induce a significant performance overhead. ASan often requires; the use of dedicated canaries to be viable in production environments, and as; such is often impractical. GWP-ASan is only capable of finding a subset of the memory issues detected by; ASan. Furthermore, GWP-ASan's bug detection capabilities are only probabilistic.; As such, we recommend using ASan over GWP-ASan in testing, as well as anywhere; else that guaranteed error detection is more valuable than the 2x execution; slowdown/binary size bloat. For the majority of production environments, this; impact is too high, and GWP-ASan proves extremely useful. Design; ======. **Please note:** The implementation of GWP-ASan is largely in-flux, and these; details are subject to change. There are currently other implementations of; GWP-ASan, such as the implementation featured in; `Chromium <https://cs.chromium.org/chromium/src/components/gwp_asan/>`_. The; long-term support goal is to ensure feature-parity where reasonable, and to; support compiler-rt as the reference implementation. Allocator Support; -----------------. GWP-ASan is not a replacement for a traditional allocator. Instead, it works by; inserting stubs into a supporting allocator to redirect allocations to GWP-ASan; when they're chosen to be sampled. These stubs are generally implemented in the; implementation of ``malloc()``, ``free()`` and ``realloc()``. The stubs are; extremely",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:1470,detect,detection,1470,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['detect'],['detection']
Safety," libFuzzer tries to guess; a good value based on the corpus (and reports it).; ``-len_control``; Try generating small inputs first, then try larger inputs over time.; Specifies the rate at which the length limit is increased (smaller == faster).; Default is 100. If 0, immediately try inputs with size up to max_len.; ``-timeout``; Timeout in seconds, default 1200. If an input takes longer than this timeout,; the process is treated as a failure case.; ``-rss_limit_mb``; Memory usage limit in Mb, default 2048. Use 0 to disable the limit.; If an input requires more than this amount of RSS memory to execute,; the process is treated as a failure case.; The limit is checked in a separate thread every second.; If running w/o ASAN/MSAN, you may use 'ulimit -v' instead.; ``-malloc_limit_mb``; If non-zero, the fuzzer will exit if the target tries to allocate this; number of Mb with one malloc call.; If zero (default) same limit as rss_limit_mb is applied.; ``-timeout_exitcode``; Exit code (default 77) used if libFuzzer reports a timeout.; ``-error_exitcode``; Exit code (default 77) used if libFuzzer itself (not a sanitizer) reports a bug (leak, OOM, etc).; ``-max_total_time``; If positive, indicates the maximum total time in seconds to run the fuzzer.; If 0 (the default), run indefinitely.; ``-merge``; If set to 1, any corpus inputs from the 2nd, 3rd etc. corpus directories; that trigger new code coverage will be merged into the first corpus; directory. Defaults to 0. This flag can be used to minimize a corpus.; ``-merge_control_file``; Specify a control file used for the merge process.; If a merge process gets killed it tries to leave this file in a state; suitable for resuming the merge. By default a temporary file will be used.; ``-minimize_crash``; If 1, minimizes the provided crash input.; Use with -runs=N or -max_total_time=N to limit the number of attempts.; ``-reload``; If set to 1 (the default), the corpus directory is re-read periodically to; check for new inputs; th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:11411,timeout,timeout,11411,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['timeout'],['timeout']
Safety," limited by two planes; perpendicular to the Z axis (top and bottom planes) and two hyperbolic; surfaces of revolution about Z axis (inner and outer surfaces). The; class describing hyperboloids is **`TGeoHype`** has 5 input parameters:. ``` {.cpp}; TGeoHype(Double_t rin,Double_t stin,Double_t rout,; Double_t stout,Double_t dz);; ```. ![TGeoHype Class](pictures/080001C1.png). The hyperbolic surface equation is taken in the form:. ``` {.cpp}; r2 - z2tan2() = r2min; ```. - `r,z:` cylindrical coordinates for a point on the surface; - `:` stereo angle between the hyperbola asymptotic lines and Z axis; - `r2min:` minimum distance between hyperbola and Z axis (at `z=0`). The input parameters represent:. - `rin, stin:` minimum radius and tangent of stereo angle for inner; surface; - `rout, stout:` minimum radius and tangent of stereo angle for outer; surface; - `dz:` half length in Z (bounding planes positions at `+/-dz`). The following conditions are mandatory in order to avoid intersections; between the inner and outer hyperbolic surfaces in the range `+/-dz`:. - `rin<rout`; - `rout>0`; - `rin2 + dz2*stin2 > rout2 + dz2*stout2`. Particular cases:. - `rin=0, stin0:` the inner surface is conical; - `stin=0 / stout=0:` cylindrical surface(s). #### Cones - TGeoCone Class. The cones are defined by 5 parameters:. ``` {.cpp}; TGeoCone(Double_t dz,Double_t rmin1,Double_t rmax1,; Double_t rmin2,Double_t rmax2);; ```. - `rmin1:` internal radius at Z is `-dz`; - `rmax1:` external radius at Z is `-dz`; - `rmin2:` internal radius at Z is `+dz`; - `rmax2:` external radius at Z is `+dz`; - `dz:` half length in Z (a cone ranges from `-dz` to +`dz`). A cone has Z-axis as its symmetry axis. ![TGeoCone Class](pictures/060001C2.png). #### Cone Segments - TGeoConeSeg Class. A cone segment is a cone having a range in `phi.` The cone segment class; derives from **`TGeoCone`**, having two extra parameters: `phi1` and; `phi2`. ``` {.cpp}; TGeoConeSeg(Double_t dz,Double_t rmin1,Double_t rmax1,; Do",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:34685,avoid,avoid,34685,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['avoid'],['avoid']
Safety," linking statically modules that are compiled with and; without SafeStack. An executable compiled with SafeStack can load dynamic; libraries that are not compiled with SafeStack. At the moment, compiling; dynamic libraries with SafeStack is not supported. Signal handlers that use ``sigaltstack()`` must not use the unsafe stack (see; ``__attribute__((no_sanitize(""safe-stack"")))`` below). Programs that use APIs from ``ucontext.h`` are not supported yet. Security; --------. SafeStack protects return addresses, spilled registers and local variables that; are always accessed in a safe way by separating them in a dedicated safe stack; region. The safe stack is automatically protected against stack-based buffer; overflows, since it is disjoint from the unsafe stack in memory, and it itself; is always accessed in a safe way. In the current implementation, the safe stack; is protected against arbitrary memory write vulnerabilities though; randomization and information hiding: the safe stack is allocated at a random; address and the instrumentation ensures that no pointers to the safe stack are; ever stored outside of the safe stack itself (see limitations below). Known security limitations; ~~~~~~~~~~~~~~~~~~~~~~~~~~. A complete protection against control-flow hijack attacks requires combining; SafeStack with another mechanism that enforces the integrity of code pointers; that are stored on the heap or the unsafe stack, such as `CPI; <https://dslab.epfl.ch/research/cpi/>`_, or a forward-edge control flow integrity; mechanism that enforces correct calling conventions at indirect call sites,; such as `IFCC <https://research.google.com/pubs/archive/42808.pdf>`_ with arity; checks. Clang has control-flow integrity protection scheme for :doc:`C++ virtual; calls <ControlFlowIntegrity>`, but not non-virtual indirect calls. With; SafeStack alone, an attacker can overwrite a function pointer on the heap or; the unsafe stack and cause a program to call arbitrary location, which in tur",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst:3262,safe,safe,3262,interpreter/llvm-project/clang/docs/SafeStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst,4,['safe'],['safe']
Safety," list of; optimizations, use the **-help** and **--load** options together; for example:. .. code-block:: bash. bugpoint --load myNewPass.so -help. **--mlimit** *megabytes*. Specifies an upper limit on memory usage of the optimization and codegen. Set; to zero to disable the limit. **--output** *filename*. Whenever the test program produces output on its standard output stream, it; should match the contents of *filename* (the ""reference output""). If you; do not use this option, **bugpoint** will attempt to generate a reference output; by compiling the program with the ""safe"" backend and running it. **--run-{int,jit,llc,custom}**. Whenever the test program is compiled, **bugpoint** should generate code for it; using the specified code generator. These options allow you to choose the; interpreter, the JIT compiler, the static native code compiler, or a; custom command (see **--exec-command**) respectively. **--safe-{llc,custom}**. When debugging a code generator, **bugpoint** should use the specified code; generator as the ""safe"" code generator. This is a known-good code generator; used to generate the ""reference output"" if it has not been provided, and to; compile portions of the program that as they are excluded from the testcase.; These options allow you to choose the; static native code compiler, or a custom command, (see **--exec-command**); respectively. The interpreter and the JIT backends cannot currently; be used as the ""safe"" backends. **--exec-command** *command*. This option defines the command to use with the **--run-custom** and; **--safe-custom** options to execute the bitcode testcase. This can; be useful for cross-compilation. **--compile-command** *command*. This option defines the command to use with the **--compile-custom**; option to compile the bitcode testcase. The command should exit with a; failure exit code if the file is ""interesting"" and should exit with a; success exit code (i.e. 0) otherwise (this is the same as if it crashed on; ""interest",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst:4579,safe,safe,4579,interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,1,['safe'],['safe']
Safety," locked ``mu``, it is safe to modify; ``balance`` within the body of the method. The ``depositImpl()`` method does not have ``REQUIRES``, so the; analysis issues a warning. Thread safety analysis is not inter-procedural, so; caller requirements must be explicitly declared.; There is also a warning in ``transferFrom()``, because although the method; locks ``this->mu``, it does not lock ``b.mu``. The analysis understands; that these are two separate mutexes, in two different objects. Finally, there is a warning in the ``withdraw()`` method, because it fails to; unlock ``mu``. Every lock must have a corresponding unlock, and the analysis; will detect both double locks, and double unlocks. A function is allowed to; acquire a lock without releasing it, (or vice versa), but it must be annotated; as such (using ``ACQUIRE``/``RELEASE``). Running The Analysis; --------------------. To run the analysis, simply compile with the ``-Wthread-safety`` flag, e.g. .. code-block:: bash. clang -c -Wthread-safety example.cpp. Note that this example assumes the presence of a suitably annotated; :ref:`mutexheader` that declares which methods perform locking,; unlocking, and so on. Basic Concepts: Capabilities; ============================. Thread safety analysis provides a way of protecting *resources* with; *capabilities*. A resource is either a data member, or a function/method; that provides access to some underlying resource. The analysis ensures that; the calling thread cannot access the *resource* (i.e. call the function, or; read/write the data) unless it has the *capability* to do so. Capabilities are associated with named C++ objects which declare specific; methods to acquire and release the capability. The name of the object serves; to identify the capability. The most common example is a mutex. For example,; if ``mu`` is a mutex, then calling ``mu.Lock()`` causes the calling thread; to acquire the capability to access data that is protected by ``mu``. Similarly,; calling ``mu.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:3275,safe,safety,3275,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['safe'],['safety']
Safety," loop distribute(enable); for (i = 0; i < N; ++i) {; S1: A[i + 1] = A[i] + B[i];; S2: C[i] = D[i] * E[i];; }. This loop will be split into two loops between statements S1 and S2. The; second loop containing S2 will be vectorized. Loop Distribution is currently not enabled by default in the optimizer because; it can hurt performance in some cases. For example, instruction-level; parallelism could be reduced by sequentializing the execution of the; statements S1 and S2 above. If Loop Distribution is turned on globally with; ``-mllvm -enable-loop-distribution``, specifying ``distribute(disable)`` can; be used the disable it on a per-loop basis. Additional Information; ----------------------. For convenience multiple loop hints can be specified on a single line. .. code-block:: c++. #pragma clang loop vectorize_width(4) interleave_count(8); for(...) {; ...; }. If an optimization cannot be applied any hints that apply to it will be ignored.; For example, the hint ``vectorize_width(4)`` is ignored if the loop is not; proven safe to vectorize. To identify and diagnose optimization issues use; `-Rpass`, `-Rpass-missed`, and `-Rpass-analysis` command line options. See the; user guide for details. Extensions to specify floating-point flags; ====================================================. The ``#pragma clang fp`` pragma allows floating-point options to be specified; for a section of the source code. This pragma can only appear at file scope or; at the start of a compound statement (excluding comments). When using within a; compound statement, the pragma is active within the scope of the compound; statement. Currently, the following settings can be controlled with this pragma:. ``#pragma clang fp reassociate`` allows control over the reassociation; of floating point expressions. When enabled, this pragma allows the expression; ``x + (y + z)`` to be reassociated as ``(x + y) + z``.; Reassociation can also occur across multiple statements.; This pragma can be used to disable",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:169375,safe,safe,169375,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['safe'],['safe']
Safety," method `FindNextBoundary()`; whenever the tracking is not imposed in association with an external MC; transport engine (which provide their own algorithms for boundary; crossing). ~~~{.cpp}; TGeoNode *TGeoManager::FindNextBoundaryAndStep(Double_t stepmax,; Bool_t comp_safe=kFALSE);; ~~~. The meaning of the parameters here is the same as for FindNextBoundary,; but the safety value is triggered by an input flag. The output is the; node after the boundary crossing. \anchor GP02gc; #### Computing the Safe Radius. Other important navigation query for tracking is the computation of the; safe distance. This represents the `maximum` step that can be made from; the current point in `any direction` that assures that no boundary will; be crossed. Knowing this value gives additional freedom to the stepping; algorithm to propagate the current track on the corresponding range; `without checking` if the current state has changed. In other words, the; modeller insures that the current state does not change in any point; within the safety radius around the current point. The computation of the safe radius is `automatically` computed any time; when the next boundary is queried within a `limited step:`. ~~~{.cpp}; TGeoNode *crossed = gGeoManager->FindNextBoundary(pstep);; Double_t safety = gGeoManager->GetSafeDistance();; ~~~. Otherwise, the computation of safety can always be forced:. ~~~{.cpp}; Double_t safety = gGeoManager->Safety();; ~~~. \anchor GP02gd; #### Making a Step. The modeller is able to make steps starting from the current point along; the current direction and having the current step length. The new point; and its corresponding state will be automatically computed:. ~~~{.cpp}; TGeoNode *TGeoManager::Step(Bool_t is_geom = kTRUE,; Bool_t cross = kTRUE);; ~~~. We will explain the method above by its use cases. The input flag; `is_geom` allows specifying if the step is limited by geometrical; reasons (a boundary crossing) or is an arbitrary step. The flag cross; can be us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:79968,safe,safety,79968,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['safe'],['safety']
Safety," method is the object which shape; boundary will be crossed first. The distance to the next crossing can be; retrieved after the call:. ``` {.cpp}; Double_t TGeoManager::GetStep(); ```. - The main input parameter is `stepmax,` which act as a trigger for; different features. The absolute value of this parameter represents; the step value proposed by the user. The algorithm will never try o; search for boundaries further than this distance. In case no; boundary is found the returned node will be the current one and the; computed step to boundary will be equal to abs (`stepmax`) having; the meaning *""step approved""*. The default value for `stepmax` is; `TGeoShape::Big `with the meaning that boundaries are looked for; without limitation. ![Finding the distance to the next crossed boundary](pictures/080001E8.png). According the values of the input parameters the method will perform; additional optional tasks:. **`|stepmax| < `** ***`TGeoShape::Big()`*** **` `**. The safe distance in the current volume is also computed. Moving the; particle from its current location with this distance in any direction; is safe in the sense that will never change the current state. **`stepmax < 0`**. The global matrix for the object that will have the next crossed; boundary is also computed. This can be retrieved for masterlocal point; or vector conversions: **`TGeoManager`**::`GetNextMatrix`(). In case the computation of the normal vector to the next crossed surface; is required, using a negative stepmax value is recommended. In this case; one can subsequently call a method for fast normal computation:. ``` {.cpp}; Double_t *TGeoManager::FindNormalFast(); ```. **`path `** **` 0`**. In case a path to a given physical object is specified, the distance to; its boundary is computed ignoring the rest of the geometry. #### Output Values. `TGeoManager::GetStep()`: distance to next boundary. `TGeoManager::GetSafeDistance()`: safe distance (in case it was; computed). `TGeoManager::IsOnBoundary()`:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:160067,safe,safe,160067,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['safe'],['safe']
Safety," modified, then all; load instructions from that set may be hoisted out of the loop. If any alias; sets are stored to **and** are must alias sets, then the stores may be sunk; to outside of the loop, promoting the memory location to a register for the; duration of the loop nest. Both of these transformations only apply if the; pointer argument is loop-invariant. The AliasSetTracker implementation; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The AliasSetTracker class is implemented to be as efficient as possible. It; uses the union-find algorithm to efficiently merge AliasSets when a pointer is; inserted into the AliasSetTracker that aliases multiple sets. The primary data; structure is a hash table mapping pointers to the AliasSet they are in. The AliasSetTracker class must maintain a list of all of the LLVM ``Value*``\s; that are in each AliasSet. Since the hash table already has entries for each; LLVM ``Value*`` of interest, the AliasesSets thread the linked list through; these hash-table nodes to avoid having to allocate memory unnecessarily, and to; make merging alias sets extremely efficient (the linked list merge is constant; time). You shouldn't need to understand these details if you are just a client of the; AliasSetTracker, but if you look at the code, hopefully this brief description; will help make sense of why things are designed the way they are. Using the ``AliasAnalysis`` interface directly; ----------------------------------------------. If neither of these utility class are what your pass needs, you should use the; interfaces exposed by the ``AliasAnalysis`` class directly. Try to use the; higher-level methods when possible (e.g., use mod/ref information instead of the; `alias`_ method directly if possible) to get the best precision and efficiency. Existing alias analysis implementations and clients; ===================================================. If you're going to be working with the LLVM alias analysis infrastructure, you; should know what clients ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:22209,avoid,avoid,22209,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['avoid'],['avoid']
Safety," motivated by; simplicity and extensibility. Compactness of the representation is; secondary because the runtime is expected to parse the data; immediately after compiling a module and encode the information in its; own format. Since the runtime controls the allocation of sections, it; can reuse the same stack map space for multiple modules. Stackmap support is currently only implemented for 64-bit; platforms. However, a 32-bit implementation should be able to use the; same format with an insignificant amount of wasted space. .. _stackmap-section:. Stack Map Section; ^^^^^^^^^^^^^^^^^. A JIT compiler can easily access this section by providing its own; memory manager via the LLVM C API; ``LLVMCreateSimpleMCJITMemoryManager()``. When creating the memory; manager, the JIT provides a callback:; ``LLVMMemoryManagerAllocateDataSectionCallback()``. When LLVM creates; this section, it invokes the callback and passes the section name. The; JIT can record the in-memory address of the section at this time and; later parse it to recover the stack map data. For MachO (e.g. on Darwin), the stack map section name is; ""__llvm_stackmaps"". The segment name is ""__LLVM_STACKMAPS"". For ELF (e.g. on Linux), the stack map section name is; "".llvm_stackmaps"". The segment name is ""__LLVM_STACKMAPS"". Stack Map Usage; ===============. The stack map support described in this document can be used to; precisely determine the location of values at a specific position in; the code. LLVM does not maintain any mapping between those values and; any higher-level entity. The runtime must be able to interpret the; stack map record given only the ID, offset, and the order of the; locations, records, and functions, which LLVM preserves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:16612,recover,recover,16612,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['recover'],['recover']
Safety," must define it as nothing or include a header; that has the define. .. code-block:: c. #if defined(__has_feature) && __has_feature(bounds_safety); #define __counted_by(T) __attribute__((__counted_by__(T))); // ... other bounds annotations; #else #define __counted_by(T) // defined as nothing; // ... other bounds annotations; #endif. // expands to `void foo(int * ptr, size_t count);`; // when extension is not enabled or not available; void foo(int *__counted_by(count) ptr, size_t count);. Other potential applications of bounds annotations; ==================================================. The bounds annotations provided by the ``-fbounds-safety`` programming model; have potential use cases beyond the language extension itself. For example,; static and dynamic analysis tools could use the bounds information to improve; diagnostics for out-of-bounds accesses, even if ``-fbounds-safety`` is not used.; The bounds annotations could be used to improve C interoperability with; bounds-safe languages, providing a better mapping to bounds-safe types in the; safe language interface. The bounds annotations can also serve as documentation; specifying the relationship between declarations. Limitations; ===========. ``-fbounds-safety`` aims to bring the bounds safety guarantee to the C language,; and it does not guarantee other types of memory safety properties. Consequently,; it may not prevent some of the secondary bounds safety violations caused by; other types of safety violations such as type confusion. For instance,; ``-fbounds-safety`` does not perform type-safety checks on conversions between; `__single`` pointers of different pointee types (e.g., ``char *__single`` →; ``void *__single`` → ``int *__single``) beyond what the foundation languages; (C/C++) already offer. ``-fbounds-safety`` heavily relies on run-time checks to keep the bounds safety; and the soundness of the type system. This may incur significant code size; overhead in unoptimized builds and leaving some of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:46940,safe,safe,46940,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,3,['safe'],['safe']
Safety," negatives and false positives. (Q) ""*Mutex is not locked on every path through here?*"" What does that mean?. (A) See :ref:`conditional_locks`, below. .. _limitations:. Known Limitations; =================. Lexical scope; -------------. Thread safety attributes contain ordinary C++ expressions, and thus follow; ordinary C++ scoping rules. In particular, this means that mutexes and other; capabilities must be declared before they can be used in an attribute.; Use-before-declaration is okay within a single class, because attributes are; parsed at the same time as method bodies. (C++ delays parsing of method bodies; until the end of the class.) However, use-before-declaration is not allowed; between classes, as illustrated below. .. code-block:: c++. class Foo;. class Bar {; void bar(Foo* f) REQUIRES(f->mu); // Error: mu undeclared.; };. class Foo {; Mutex mu;; };. Private Mutexes; ---------------. Good software engineering practice dictates that mutexes should be private; members, because the locking mechanism used by a thread-safe class is part of; its internal implementation. However, private mutexes can sometimes leak into; the public interface of a class.; Thread safety attributes follow normal C++ access restrictions, so if ``mu``; is a private member of ``c``, then it is an error to write ``c.mu`` in an; attribute. One workaround is to (ab)use the ``RETURN_CAPABILITY`` attribute to provide a; public *name* for a private mutex, without actually exposing the underlying; mutex. For example:. .. code-block:: c++. class MyClass {; private:; Mutex mu;. public:; // For thread safety analysis only. Does not need to be defined.; Mutex* getMu() RETURN_CAPABILITY(mu);. void doSomething() REQUIRES(mu);; };. void doSomethingTwice(MyClass& c) REQUIRES(c.getMu()) {; // The analysis thinks that c.getMu() == c.mu; c.doSomething();; c.doSomething();; }. In the above example, ``doSomethingTwice()`` is an external routine that; requires ``c.mu`` to be locked, which cannot be declar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:20037,safe,safe,20037,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['safe'],['safe']
Safety," no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27752,avoid,avoids,27752,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['avoid'],['avoids']
Safety," not be included when the module is built, nor will it be considered to be part of the module, even if an ``umbrella`` header or directory would otherwise make it part of the module. **Example:** The C header ``assert.h`` is an excellent candidate for a textual header, because it is meant to be included multiple times (possibly with different ``NDEBUG`` settings). However, declarations within it should typically be split into a separate modular header. .. parsed-literal::. module std [system] {; textual header ""assert.h""; }. A given header shall not be referenced by more than one *header-declaration*. Two *header-declaration*\s, or a *header-declaration* and a ``#include``, are; considered to refer to the same file if the paths resolve to the same file; and the specified *header-attr*\s (if any) match the attributes of that file,; even if the file is named differently (for instance, by a relative path or; via symlinks). .. note::; The use of *header-attr*\s avoids the need for Clang to speculatively; ``stat`` every header referenced by a module map. It is recommended that; *header-attr*\s only be used in machine-generated module maps, to avoid; mismatches between attribute values and the corresponding files. Umbrella directory declaration; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; An umbrella directory declaration specifies that all of the headers in the specified directory should be included within the module. .. parsed-literal::. *umbrella-dir-declaration*:; ``umbrella`` *string-literal*. The *string-literal* refers to a directory. When the module is built, all of the header files in that directory (and its subdirectories) are included in the module. An *umbrella-dir-declaration* shall not refer to the same directory as the location of an umbrella *header-declaration*. In other words, only a single kind of umbrella can be specified for a given directory. .. note::. Umbrella directories are useful for libraries that have a large number of headers but do not have an umbrella h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:38581,avoid,avoids,38581,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['avoid'],['avoids']
Safety," not returned from the function or; stored in a global. This pass is implemented as a bottom-up traversal of the; call-graph. ``globaldce``: Dead Global Elimination; --------------------------------------. This transform is designed to eliminate unreachable internal globals from the; program. It uses an aggressive algorithm, searching out globals that are known; to be alive. After it finds all of the globals which are needed, it deletes; whatever is left over. This allows it to delete recursive chunks of the; program which are unreachable. ``globalopt``: Global Variable Optimizer; ----------------------------------------. This pass transforms simple global variables that never have their address; taken. If obviously true, it marks read/write globals as constant, deletes; variables only stored to, etc. ``gvn``: Global Value Numbering; -------------------------------. This pass performs global value numbering to eliminate fully and partially; redundant instructions. It also performs redundant load elimination. .. _passes-indvars:. ``indvars``: Canonicalize Induction Variables; ---------------------------------------------. This transformation analyzes and transforms the induction variables (and; computations derived from them) into simpler forms suitable for subsequent; analysis and transformation. This transformation makes the following changes to each loop with an; identifiable induction variable:. * All loops are transformed to have a *single* canonical induction variable; which starts at zero and steps by one.; * The canonical induction variable is guaranteed to be the first PHI node in; the loop header block.; * Any pointer arithmetic recurrences are raised to use array subscripts. If the trip count of a loop is computable, this pass also makes the following; changes:. * The exit condition for the loop is canonicalized to compare the induction; value against the exit value. This turns loops like:. .. code-block:: c++. for (i = 7; i*i < 1000; ++i). into. .. code-bl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:17488,redund,redundant,17488,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['redund'],['redundant']
Safety," object libraries, so we have to trick it into; # linking the static libraries instead.; list(APPEND _DEPS ""-force_load"" ${lib}); else(); list(APPEND _OBJECTS $<TARGET_OBJECTS:obj.${lib}>); endif(); if (BUILD_SHARED_LIBS); # If we are building static libraries, then we don't need to add the static; # libraries as a dependency, because we are already linking against the; # individual object files.; list(APPEND _DEPS $<TARGET_PROPERTY:${lib},INTERFACE_LINK_LIBRARIES>); endif(). # clang libraries are redundant since we are linking all the individual; # object files into libclang-cpp.so, so filter them out from _DEPS.; # This avoids problems with LLVM global data when building with; # BUILD_SHARED_LIBS=ON; # FIXME: We could use list(FILTER) with cmake >= 3.6; # FIXME: With cmake >= 3.15 we could use the generator expression; # $<FILTER:list,INCLUDE|EXCLUDE,regex>; get_target_property(interface ${lib} LINK_LIBRARIES); if (interface); foreach(lib ${interface}); if (NOT ${lib} MATCHES ""^clang""); list(APPEND _DEPS ${lib}); endif(); endforeach(); endif(); endforeach (). if (CLANG_LINK_CLANG_DYLIB); set(INSTALL_WITH_TOOLCHAIN INSTALL_WITH_TOOLCHAIN); endif(). add_clang_library(clang-cpp; SHARED; ${INSTALL_WITH_TOOLCHAIN}; clang-shlib.cpp; ${_OBJECTS}; LINK_LIBS; ${_DEPS}); # Optimize function calls for default visibility definitions to avoid PLT and; # reduce dynamic relocations.; if (NOT APPLE AND NOT MINGW AND NOT LLVM_LINKER_IS_SOLARISLD_ILLUMOS); target_link_options(clang-cpp PRIVATE LINKER:-Bsymbolic-functions); endif(); if (MINGW OR CYGWIN); # The clang-cpp DLL is supposed to export all symbols (except for ones; # that are explicitly hidden). Normally, this is what happens anyway, but; # if there are symbols that are marked explicitly as dllexport, we'd only; # export them and nothing else. Therefore, add --export-all-symbols to; # make sure we export all symbols despite potential dllexports.; target_link_options(clang-cpp PRIVATE LINKER:--export-all-symbols); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-shlib/CMakeLists.txt:1573,avoid,avoid,1573,interpreter/llvm-project/clang/tools/clang-shlib/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-shlib/CMakeLists.txt,1,['avoid'],['avoid']
Safety," objects whic can create a big overload when distributed via the; standard input list (which should mostly be used for job control; parameters).  To add an input-data object just use; TProof::AddInputData(TObject *); if the input-data objects are in a; file you can use TProof::SetInputDataFile(const char *file); the final; set of input-data objects is assembled from the objects added via; AddInputData and those found in the file defined bySetInputDataFile.  . Improvements:. More; complete set of tests in test/stressProof . To run with PROOF-Lite pass; the argument 'lite' as master URL, e.g. './stressProof lite'.Possibility; to control on the client via rc variable the location of the sandbox,; package directory, cache and dataset directory (the latters two only; for PROOF-Lite); the variable names are 'Proof.Sandbox', ; 'Proof.PackageDir', 'Proof.CacheDir' and 'Proof.DataSetDir'. The default location of the sandbox has been changed from ""~/proof"" to ""~/.proof"" to avoid interferences with possible users' working areas.XrdProofd plug-in. Overall refactorization for easier; maintainance and improved solidity; Improved format of printout messages: all information; messages contain now the tag 'xpd-I' and all error messages the; tag 'xpd-E', so that they can easily be grepped out from the; log file.; . Log sending. Implement selective sending of logs from workers to master to avoid duplicating; too many text lines on the master log. Logs are now sent only after Exec, Print; requests and in case an error (level >= kError) occured. Of course, the full; logs can always be retrieved via TProofMgr::GetSessionLogs; . Log retrieval:. for 'grep' operations, use the system 'grep' command; via 'popen'; instead of a handmade filtering; this implies that the full grep; functionality is now available; set the default number of displayed lines to 100; instead of 10. Improve diagnostic in case of worker death: clients will; now; receive a message containing the low level reason for the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:4407,avoid,avoid,4407,proof/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html,1,['avoid'],['avoid']
Safety," of ""``<``"" to return an ""angled string"" instead of a bunch of tokens; for each thing within the filename.; * When parsing a preprocessor directive (after ""``#``"") the; ``ParsingPreprocessorDirective`` mode is entered. This changes the parser to; return EOD at a newline.; * The ``Lexer`` uses a ``LangOptions`` object to know whether trigraphs are; enabled, whether C++ or ObjC keywords are recognized, etc. In addition to these modes, the lexer keeps track of a couple of other features; that are local to a lexed buffer, which change as the buffer is lexed:. * The ``Lexer`` uses ``BufferPtr`` to keep track of the current character being; lexed.; * The ``Lexer`` uses ``IsAtStartOfLine`` to keep track of whether the next; lexed token will start with its ""start of line"" bit set.; * The ``Lexer`` keeps track of the current ""``#if``"" directives that are active; (which can be nested).; * The ``Lexer`` keeps track of an :ref:`MultipleIncludeOpt; <MultipleIncludeOpt>` object, which is used to detect whether the buffer uses; the standard ""``#ifndef XX`` / ``#define XX``"" idiom to prevent multiple; inclusion. If a buffer does, subsequent includes can be ignored if the; ""``XX``"" macro is defined. .. _TokenLexer:. The ``TokenLexer`` class; ------------------------. The ``TokenLexer`` class is a token provider that returns tokens from a list of; tokens that came from somewhere else. It typically used for two things: 1); returning tokens from a macro definition as it is being expanded 2) returning; tokens from an arbitrary buffer of tokens. The later use is used by; ``_Pragma`` and will most likely be used to handle unbounded look-ahead for the; C++ parser. .. _MultipleIncludeOpt:. The ``MultipleIncludeOpt`` class; --------------------------------. The ``MultipleIncludeOpt`` class implements a really simple little state; machine that is used to detect the standard ""``#ifndef XX`` / ``#define XX``""; idiom that people typically use to prevent multiple inclusion of headers. If a; buffer",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:55551,detect,detect,55551,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['detect'],['detect']
Safety," of any; given select conditions (:option:`--select`), only those elements that; match them, will be printed. The **elements** value is a convenient; way to specify instructions, lines, scopes, symbols and types all at; once. .. code-block:: text. =elements: Instructions, lines, scopes, symbols and types.; =instructions: Assembler instructions for code sections.; =lines: Source lines referenced in the debug information.; =scopes: Lexical blocks (function, class, namespace, etc).; =symbols: Symbols (variable, member, parameter, etc).; =types: Types (pointer, reference, type alias, etc). The following options print information, collected during the creation; of the elements, such as: scope contributions to the debug information;; summary of elements created, printed or matched (:option:`--select`);; warnings produced during the view creation. .. code-block:: text. =sizes: Debug Information scopes contributions.; =summary: Summary of elements allocated, selected or printed.; =warnings: Warnings detected. Note: The **--print=sizes** option is ELF specific. .. _output_:. OUTPUT; ~~~~~~; The following options describe how to control the output generated when; printing the logical elements. .. option:: --output-file=<path>. Redirect the output to a file specified by <path>, where - is the; standard output stream. :program:`llvm-debuginfo-analyzer` has the concept of **split view**.; When redirecting the output from a complex binary format, it is; **divided** into individual files, each one containing the logical view; output for a single compilation unit. .. option:: --output-folder=<name>. The folder to write a file per compilation unit when **--output=split**; is specified. .. option:: --output-level=<level>. Only print elements up to the given **lexical level** value. The input; file is at lexical level zero and a compilation unit is at lexical level; one. .. option:: --output=<value[,value,...]>. With **value** being one of the options in the following lists. .. code-bl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst:10550,detect,detected,10550,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst,1,['detect'],['detected']
Safety," of the `ToolBarData_t` structure is filled in; (if the icon pixmap was valid). The first parameter is the window to; which the button messages will be sent. Lastly, we create an object of; class **`TGHorizontal3DLine`** - a horizontal 3D line. It will separate; the toolbar from the menu bar because the layout hints we define as; `kLHintsTop` | `kLHintsExpandX`. It is user friendly to allow the possibility for the tool bar to be; turned on or off (via a menu). If you use a single tool bar, it should; fill the complete width of its parent. When using more than one, you; should also think about setting the bar size to the end of the most; right button. This way other bars can be displayed in the same row below; the menu bar. Tool bar buttons should have equal size, meaningful and unique icons,; and short meaningful tool tip text. The related buttons should be; grouped together by frequency or sequence of use, or importance.; Potentially destructive buttons must be separated from them to avoid; accidental activation and potentially catastrophic results. Temporarily; not available items should be displayed grayed out. ### List Boxes. The purpose of a list box is to display a collection of items from which; single or multiple selection can be made. It is always visible, having a; scroll bar when the displayed area is not enough to show all items. The; choices may be mutually exclusive (a list box with single selection) or; not mutually exclusive (a list box with multiple selection). ![](pictures/02000219.jpg). The proper usage of the list boxes is for selecting values, or objects,; or setting attributes. You have to create them to display 4 to 8 choices; at one time (3 is a required minimum in case of lack of screen space).; The list should contain not more than 40 items accessible by scrolling; view (vertical scroll bar). If more are required, you should provide a; method for using search criteria or scoping the options. The best list; boxes use is for textual data or ch",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md:78295,avoid,avoid,78295,documentation/users-guide/WritingGUI.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md,1,['avoid'],['avoid']
Safety," of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36112,avoid,avoid,36112,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['avoid'],['avoid']
Safety," of the edge. This is represented in assembly as:. .. code-block:: gas. .cg_profile from, to, 42. ``.cg_profile`` directives are processed at the end of the file. It is an error; if either ``from`` or ``to`` are undefined temporary symbols. If either symbol; is a temporary symbol, then the section symbol is used instead. If either; symbol is undefined, then that symbol is defined as if ``.weak symbol`` has been; written at the end of the file. This forces the symbol to show up in the symbol; table. ``SHT_LLVM_ADDRSIG`` Section (address-significance table); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This section is used to mark symbols as address-significant, i.e. the address; of the symbol is used in a comparison or leaks outside the translation unit. It; has the same meaning as the absence of the LLVM attributes ``unnamed_addr``; and ``local_unnamed_addr``. Any sections referred to by symbols that are not marked as address-significant; in any object file may be safely merged by a linker without breaking the; address uniqueness guarantee provided by the C and C++ language standards. The contents of the section are a sequence of ULEB128-encoded integers; referring to the symbol table indexes of the address-significant symbols. There are two associated assembly directives:. .. code-block:: gas. .addrsig. This instructs the assembler to emit an address-significance table. Without; this directive, all symbols are considered address-significant. .. code-block:: gas. .addrsig_sym sym. If ``sym`` is not otherwise referenced or defined anywhere else in the file,; this directive is a no-op. Otherwise, mark ``sym`` as address-significant. ``SHT_LLVM_SYMPART`` Section (symbol partition specification); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This section is used to mark symbols with the `partition`_ that they; belong to. An ``.llvm_sympart`` section consists of a null-terminated string; specifying the name of the partition followed by a rel",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:9979,safe,safely,9979,interpreter/llvm-project/llvm/docs/Extensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst,1,['safe'],['safely']
Safety," of the existence of ROOT's interactive features and use; them if you find them convenient. Some trial-and-error is certainly necessary; to find your way through the huge number of menus and parameter; settings. ## ROOT Beginners' FAQ ##. At this point of the guide, some basic questions could have already come; to your mind. We will try to clarify some of them with further; explanations in the following. ### ROOT type declarations for basic data types ###. In the official ROOT documentation, you find special data types; replacing the normal ones, e.g. `Double_t`, `Float_t` or `Int_t`; replacing the standard `double`, `float` or `int` types. Using the ROOT; types makes it easier to port code between platforms (64/32 bit) or; operating systems (windows/Linux), as these types are mapped to suitable; ones in the ROOT header files. If you want adaptive code of this type,; use the ROOT type declarations. However, usually you do not need such; adaptive code, and you can safely use the standard C type declarations; for your private code, as we did and will do throughout this guide. If; you intend to become a ROOT developer, however, you better stick to the; official coding rules!. ### Configure ROOT at start-up ###. The behaviour of a ROOT session can be tailored with the options in the; `.rootrc` file. Examples of the tunable parameters are the ones related; to the operating and window system, to the fonts to be used, to the; location of start-up files. At start-up, ROOT looks for a `.rootrc` file; in the following order:. - `./.rootrc //local directory`. - `$HOME/.rootrc //user directory`. - `$ROOTSYS/etc/system.rootrc //global ROOT directory`. If more than one `.rootrc` files are found in the search paths above,; the options are merged, with precedence local, user, global. The parsing; and interpretation of this file is handled by the ROOT class `TEnv`.; Have a look to its documentation if you need such rather advanced; features. The file `.rootrc` defines the location of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md:17660,safe,safely,17660,documentation/primer/ROOT_as_calculator.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md,1,['safe'],['safely']
Safety," on code that; typically does not actually care about exceptions safety. Therefore,; ARC-generated code leaks by default on exceptions, which is just fine if the; process is going to be immediately terminated anyway. Programs which do care; about recovering from exceptions should enable the option. In Objective-C++, ``-fobjc-arc-exceptions`` is enabled by default. .. admonition:: Rationale. C++ already introduces pervasive exceptions-cleanup code of the sort that ARC; introduces. C++ programmers who have not already disabled exceptions are; much more likely to actual require exception-safety. ARC does end the lifetimes of ``__weak`` objects when an exception terminates; their scope unless exceptions are disabled in the compiler. .. admonition:: Rationale. The consequence of a local ``__weak`` object not being destroyed is very; likely to be corruption of the Objective-C runtime, so we want to be safer; here. Of course, potentially massive leaks are about as likely to take down; the process as this corruption is if the program does try to recover from; exceptions. .. _arc.misc.interior:. Interior pointers; -----------------. An Objective-C method returning a non-retainable pointer may be annotated with; the ``objc_returns_inner_pointer`` attribute to indicate that it returns a; handle to the internal data of an object, and that this reference will be; invalidated if the object is destroyed. When such a message is sent to an; object, the object's lifetime will be extended until at least the earliest of:. * the last use of the returned pointer, or any pointer derived from it, in the; calling function or; * the autorelease pool is restored to a previous state. .. admonition:: Rationale. Rationale: not all memory and resources are managed with reference counts; it; is common for objects to manage private resources in their own, private way.; Typically these resources are completely encapsulated within the object, but; some classes offer their users direct access for effi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:99509,recover,recover,99509,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['recover'],['recover']
Safety," on, and the computed range minimum is > 0, and; the fHistogram minimum is zero, then it means fHistogram limits have been computed; in linear scale therefore they might be too strict and cut some points. In that; case the fHistogram limits should be recomputed ie: the existing fHistogram; should not be returned. A example covering this case has been added in; stressGraphics. TH1. Speed up TH1::GetStats, TH2::GetStats, TH3::GetStats in case the sum of weights is null and the number of entries is also null; Optimize the way the function integral is computed in TH1::FillRandom; Add new functions TH1::IsBinUnderflow(bin) and TH1::IsBinOverflow(bin) which use the global bin number.; Add new functions Int_t TH1::FindFirstBinAbove(Double_t threshold, Int_t axis) and Int_t TH1::FindLastBinAbove(Double_t threshold, Int_t axis) which find first (and last) bin with the content above the given threshold. Same function have been added in TH2 and TH3.; Add a protection in TH1::Sumw2() to avoid calling GetBinContent when the histograms are empty.; In TH1::Copy reset temporarily the kCanRebin bit before calling SetBinContent.; Fix the bug #48649in TH1::Add.; Fix a bug when calling TH1::Sumw2() on a non-empty histogram with default sum2 (i.e when TH1::GetDefaultSumw2() is true).; Add a method, TH1::ResetStats() to reset the internal statistics and force then the re-calculation suing the bin center first time is needed; Fix some problem with the statistics (in particular the number of entries) after some of the histogram operations. ; TH2. Consider in the projection of TH2 the axis range set by the user. This fix the issue https://savannah.cern.ch/bugs/index.php?47946; Add a new option, option ""o"", in the projection methods: TH2::ProjectionX, TH2::ProjectionY, TH2::ProfileX and TH2::ProfileY. When an axis range is set, using option ""o"", the original axis range of the taget axes will be; kept, but only the bins inside the selected range will be filled, while bins outside the range wi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v524/index.html:2458,avoid,avoid,2458,hist/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v524/index.html,1,['avoid'],['avoid']
Safety," or i32 %shl9, %conv; %or6 = or i32 %or, %shl5; %or10 = or i32 %or6, %shl; ret i32 %or10; }. it would be better as:. unsigned int bar(unsigned char i) {; unsigned int j=i | (i << 8); ; return j | (j<<16);; }. aka:. define i32 @bar(i8 zeroext %i) nounwind readnone ssp noredzone {; entry:; %conv = zext i8 %i to i32; %shl = shl i32 %conv, 8; %or = or i32 %shl, %conv; %shl5 = shl i32 %or, 16; %or6 = or i32 %shl5, %or; ret i32 %or6; }. or even i*0x01010101, depending on the speed of the multiplier. The best way to; handle this is to canonicalize it to a multiply in IR and have codegen handle; lowering multiplies to shifts on cpus where shifts are faster. //===---------------------------------------------------------------------===//. We do a number of simplifications in simplify libcalls to strength reduce; standard library functions, but we don't currently merge them together. For; example, it is useful to merge memcpy(a,b,strlen(b)) -> strcpy. This can only; be done safely if ""b"" isn't modified between the strlen and memcpy of course. //===---------------------------------------------------------------------===//. We compile this program: (from GCC PR11680); http://gcc.gnu.org/bugzilla/attachment.cgi?id=4487. Into code that runs the same speed in fast/slow modes, but both modes run 2x; slower than when compile with GCC (either 4.0 or 4.2):. $ llvm-g++ perf.cpp -O3 -fno-exceptions; $ time ./a.out fast; 1.821u 0.003s 0:01.82 100.0%	0+0k 0+0io 0pf+0w. $ g++ perf.cpp -O3 -fno-exceptions; $ time ./a.out fast; 0.821u 0.001s 0:00.82 100.0%	0+0k 0+0io 0pf+0w. It looks like we are making the same inlining decisions, so this may be raw; codegen badness or something else (haven't investigated). //===---------------------------------------------------------------------===//. Divisibility by constant can be simplified (according to GCC PR12849) from; being a mulhi to being a mul lo (cheaper). Testcase:. void bar(unsigned n) {; if (n % 3 == 0); true();; }. This is equivalent to the f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:18682,safe,safely,18682,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['safe'],['safely']
Safety," output[i] = RooBatchCompute::fast_exp(arg*arg * halfBySigmaSq);; ```. ### Unbiased binned fits. When RooFit performs binned fits, it takes the probability density at the bin centre as a proxy for the probability in the bin. This can lead to a bias.; To alleviate this, the new class [RooBinSamplingPdf](https://root.cern/doc/v624/classRooBinSamplingPdf.html) has been added to RooFit.; Also see [arxiv:2012.02746](https://arxiv.org/abs/2012.02746). ### More accurate residual and pull distributions. When making residual or pull distributions with `RooPlot::residHist` or `RooPlot::pullHist`, the histogram is now compared with the curve's average values within a given bin by default, ensuring that residual and pull distributions are valid for strongly curved distributions.; The old default behaviour was to interpolate the curve at the bin centres, which can still be enabled by setting the `useAverage` parameter of `RooPlot::residHist` or `RooPlot::pullHist` to `false`. ### Improved recovery from invalid parameters. When a function in RooFit is undefined (Poisson with negative mean, PDF with negative values, etc), RooFit can now pass information about the; ""badness"" of the violation to the minimiser. The minimiser can use this to compute a gradient to find its way out of the undefined region.; This can drastically improve its ability to recover when unstable fit models are used, for example RooPolynomial. For details, see the RooFit tutorial [rf612_recoverFromInvalidParameters.C](https://root.cern/doc/v624/rf612__recoverFromInvalidParameters_8C.html); and [arxiv:2012.02746](https://arxiv.org/abs/2012.02746). ### Modernised RooDataHist. RooDataHist was partially modernised to improve const-correctness, to reduce side effects as well as its memory footprint, and to make; it ready for RooFit's faster batch evaluations.; Derived classes that directly access protected members might need to be updated. This holds especially for direct accesses to `_curWeight`,; `_curWeightErrLo`,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:19953,recover,recovery,19953,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['recover'],['recovery']
Safety," page is geared towards users of the LLVM CMake build. If you're looking for; information about modifying the LLVM CMake build system you may want to see the; :doc:`CMakePrimer` page. It has a basic overview of the CMake language. .. _Quick start:. Quick start; ===========. We use here the command-line, non-interactive CMake interface. #. `Download <http://www.cmake.org/cmake/resources/software.html>`_ and install; CMake. Version 3.20.0 is the minimum required. #. Open a shell. Your development tools must be reachable from this shell; through the PATH environment variable. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake will use default values; for all build parameters. See the `Options and variables`_ section for; a list of build parameters that you can modify. This can fail if CMake can't detect your toolset, or if it thinks that the; environment is not sane enough. In this case, make sure that the toolset that; you intend to use is the only one reachable from the shell, and that the shell; itself is the correct one for your development environment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the buil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:1878,detect,detect,1878,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['detect'],['detect']
Safety," performance; of machine code in a specific CPU. Performance is measured in terms of throughput as well as processor resource; consumption. The tool currently works for processors with a backend for which; there is a scheduling model available in LLVM. The main goal of this tool is not just to predict the performance of the code; when run on the target, but also help with diagnosing potential performance; issues. Given an assembly code sequence, :program:`llvm-mca` estimates the Instructions; Per Cycle (IPC), as well as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-mca` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-mca` will send its output; to standard output if the input is from standard input. If the :option:`-o`; option specifies ""``-``"", then the outpu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:1319,detect,detects,1319,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['detect'],['detects']
Safety," pointer that outlives the call.; To be precise, a pointer is captured if one or more of the following conditions; hold:. 1. The call stores any bit of the pointer carrying information into a place,; and the stored bits can be read from the place by the caller after this call; exits. .. code-block:: llvm. @glb = global ptr null; @glb2 = global ptr null; @glb3 = global ptr null; @glbi = global i32 0. define ptr @f(ptr %a, ptr %b, ptr %c, ptr %d, ptr %e) {; store ptr %a, ptr @glb ; %a is captured by this call. store ptr %b, ptr @glb2 ; %b isn't captured because the stored value is overwritten by the store below; store ptr null, ptr @glb2. store ptr %c, ptr @glb3; call void @g() ; If @g makes a copy of %c that outlives this call (@f), %c is captured; store ptr null, ptr @glb3. %i = ptrtoint ptr %d to i64; %j = trunc i64 %i to i32; store i32 %j, ptr @glbi ; %d is captured. ret ptr %e ; %e is captured; }. 2. The call stores any bit of the pointer carrying information into a place,; and the stored bits can be safely read from the place by another thread via; synchronization. .. code-block:: llvm. @lock = global i1 true. define void @f(ptr %a) {; store ptr %a, ptr* @glb; store atomic i1 false, ptr @lock release ; %a is captured because another thread can safely read @glb; store ptr null, ptr @glb; ret void; }. 3. The call's behavior depends on any bit of the pointer carrying information. .. code-block:: llvm. @glb = global i8 0. define void @f(ptr %a) {; %c = icmp eq ptr %a, @glb; br i1 %c, label %BB_EXIT, label %BB_CONTINUE ; escapes %a; BB_EXIT:; call void @exit(); unreachable; BB_CONTINUE:; ret void; }. 4. The pointer is used in a volatile access as its address. .. _volatile:. Volatile Memory Accesses; ------------------------. Certain memory accesses, such as :ref:`load <i_load>`'s,; :ref:`store <i_store>`'s, and :ref:`llvm.memcpy <int_memcpy>`'s may be; marked ``volatile``. The optimizers must not change the number of; volatile operations or change their order of execu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:145095,safe,safely,145095,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['safe'],['safely']
Safety," processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select a small number of workers).; Consistently check both Proof.Sandbox and ProofLite.Sandbox for sandbox non-default location as done in TProofLite; Fix a problem with the registration of missing files in the; 'MissingFiles' list (files which could not be open on the workers were; not always added to the list). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:12769,timeout,timeout,12769,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,3,['timeout'],['timeout']
Safety," reference and start point here:. :doc:`WritingAnLLVMPass`. What else? Well perhaps the reader should also have some experience in LLVM pass; debugging and bug-fixing. Narrative structure; -------------------; The article consists of three parts. The first part explains pass functionality; on the top-level. The second part describes the comparison procedure itself.; The third part describes the merging process. In every part, the author tries to put the contents in the top-down form.; The top-level methods will first be described followed by the terminal ones at; the end, in the tail of each part. If the reader sees the reference to the; method that wasn't described yet, they will find its description a bit below. Basics; ======. How to do it?; -------------; Do we need to merge functions? The obvious answer is: Yes, that is quite a; possible case. We usually *do* have duplicates and it would be good to get rid; of them. But how do we detect duplicates? This is the idea: we split functions; into smaller bricks or parts and compare the ""bricks"" amount. If equal,; we compare the ""bricks"" themselves, and then do our conclusions about functions; themselves. What could the difference be? For example, on a machine with 64-bit pointers; (let's assume we have only one address space), one function stores a 64-bit; integer, while another one stores a pointer. If the target is the machine; mentioned above, and if functions are identical, except the parameter type (we; could consider it as a part of function type), then we can treat a ``uint64_t``; and a ``void*`` as equal. This is just an example; more possible details are described a bit below. As another example, the reader may imagine two more functions. The first; function performs a multiplication by 2, while the second one performs an; logical left shift by 1. Possible solutions; ^^^^^^^^^^^^^^^^^^; Let's briefly consider possible options about how and what we have to implement; in order to create full-featured functions ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst:3568,detect,detect,3568,interpreter/llvm-project/llvm/docs/MergeFunctions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst,1,['detect'],['detect']
Safety," refuse to refactor code that mixes borrowed pointer values; and unique ownership. In the following code, `GetPtr()` returns a borrowed; pointer, which is assigned to `pi`. Then, `pi` is used to hold a uniquely-owned; pointer. We don't distinguish between these two assignments, and we want each; assignment to be paired with a corresponding sink; otherwise, we transition the; pointer to a `Conflicting` state, like in this example. ```c++; void ConflictingOwnership() {; int *pi; // pi is Compatible; pi = GetPtr(); // pi is Defined; Borrow(pi); // pi is Defined. pi = new int; // pi is Conflicting; Borrow(pi);; delete pi;; // pi is Conflicting; }; ```. We could still handle this case by finding a maximal range in the code where; `pi` could be in the Compatible state, and only refactoring that part. ```c++; void ConflictingOwnership() {; int *pi;; pi = GetPtr();; Borrow(pi);. std::unique_ptr<int> pi_unique = std::make_unique<int>();; Borrow(pi_unique.get());; }; ```. ## Example: finding redundant branch conditions. In the code below `b1` should not be checked in both the outer and inner ""if""; statements. It is likely there is a bug in this code. ```c++; int F(bool b1, bool b2) {; if (b1) {; f();; if (b1 && b2) { // Check `b1` again -- unnecessary!; g();; }; }; }; ```. A checker that finds this pattern syntactically is already implemented in; ClangTidy using AST matchers (`bugprone-redundant-branch-condition`). To implement it using the data flow analysis framework, we can produce a warning; if any part of the branch condition is implied by the flow condition. ```c++; int F(bool b1, bool b2) {; // Flow condition: true.; if (b1) {; // Flow condition: b1.; f();; if (b1 && b2) { // `b1` is implied by the flow condition.; g();; }; }; }; ```. One way to check this implication is to use a SAT solver. Without a SAT solver,; we could keep the flow condition in the CNF form and then it would be easy to; check the implication. ## Example: finding unchecked `std::optional` unwraps. C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:25825,redund,redundant,25825,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['redund'],['redundant']
Safety," regular expression.; Mappings:. # Set a ""--target=thumbv7m-none-eabi"" flag if the regular expression matches; # any of the flags generated from the command line options.; # Match is a POSIX extended regular expression string.; - Match: --target=thumbv([7-9]|[1-9][0-9]+).*; # Flags is a list of one or more strings.; Flags: [--target=thumbv7m-none-eabi]. Design principles; =================. Stable interface; ----------------. ``multilib.yaml`` and ``-print-multi-flags-experimental`` are new; interfaces to Clang. In order for them to be usable over time and across LLVM; versions their interfaces should be stable.; The new multilib system will be considered experimental in LLVM 17, but in; LLVM 18 it will be stable. In particular this is important to which multilib; selection flags Clang generates from command line options. Once a flag is; generated by a released version of Clang it may be used in ``multilib.yaml``; files that exist independently of the LLVM release cycle, and therefore; ceasing to generate the flag would be a breaking change and should be; avoided. However, an exception is the normalization of ``-march``.; ``-march`` for Arm architectures contains a list of enabled and disabled; extensions and this list is likely to grow. Therefore ``-march`` flags are; unstable. Incomplete interface; --------------------. The new multilib system does multilib selection based on only a limited set of; command line options, and limits which flags can be used for multilib; selection. This is in order to avoid committing to too large an interface.; Later LLVM versions can add support for multilib selection from more command; line options as needed. Extensible; ----------. It is likely that the configuration format will need to evolve in future to; adapt to new requirements.; Using a format like YAML that supports key-value pairs helps here as it's; trivial to add new keys alongside existing ones. Backwards compatibility; -----------------------. New versions of Clang sh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst:9947,avoid,avoided,9947,interpreter/llvm-project/clang/docs/Multilib.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst,1,['avoid'],['avoided']
Safety," repaint on the attached **`TPad`** object - hence you should attach you; master geometry object to the pad (via `TObject::Draw()`), and perform; the publishing to the viewer in response to **`TObject::Paint()`**. #### Physical IDs. TVirtualViewer3D provides for two methods of object addition:. ``` {.cpp}; virtual Int_t AddObject(const TBuffer3D &buffer,; Bool_t * addChildren = 0); virtual Int_t AddObject(UInt_t physicalID,; const TBuffer3D & buffer,; Bool_t *addChildren = 0); ```. If you use the first (simple) case a viewer using logical/physical pairs; will generate sequential IDs for each physical object internally. Scene; rebuilds will require destruction and recreation of all physical; objects. For the second you can specify an identifier from the client; side, which must be unique and stable - i.e. the IDs of a published; object is consistent, regardless of changes in termination of contained; child geometry branches. In this case the viewer can safely cache the; physical objects across scene rebuilds, discarding those no longer of; interest. #### Child Objects. In many geometries there is a rigid containment hierarchy, and so if the; viewer is not interested in a certain object due to limits/size then it; will also not be interest in any of the contained branch of siblings.; Both `TBuffer3D::AddObject()` methods have an `addChildren` return; parameter. The viewer will complete this (if passed) indicating if; children of the object just sent are worth sending. #### Recycling TBuffer3D. Once add `TBuffer3D::AddObject()` has been called, the contents are; copied to the viewer's internal data structures. You are free to destroy; this **`TBuffer3D`**, or recycle it for the next object if suitable. #### Examples. For an example of a simple geometry, working in master reference frame; examine the code under `$ROOTSYS/g3d`. For a more complex example, which; works in both master and local frames, and uses logical`/`physical; division of shape geometry and placement, e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:138288,safe,safely,138288,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['safe'],['safely']
Safety," resolving.; Examples of reasons for resolving are:. * If the issue has been resolved by a particular commit, close the issue with; a brief comment mentioning which commit(s) fixed it. If you are authoring; the fix yourself, your git commit message may include the phrase; ``Fixes #<issue number>`` on a line by itself. GitHub recognizes such commit; messages and will automatically close the specified issue with a reference; to your commit. * If the reported behavior is not a bug, it is appropriate to close the issue; with a comment explaining why you believe it is not a bug, and adding the; ``invalid`` tag. * If the bug duplicates another issue, close it as a duplicate by adding the; ``duplicate`` label with a comment pointing to the issue it duplicates. * If there is a sound reason for not fixing the issue (difficulty, ABI, open; research questions, etc), add the ``wontfix`` label and a comment explaining; why no changes are expected. * If there is a specific and plausible reason to think that a given bug is; otherwise inapplicable or obsolete. One example is an open bug that doesn't; contain enough information to clearly understand the problem being reported; (e.g. not reproducible). It is fine to close such a bug, adding with the; ``worksforme`` label and leaving a comment to encourage the reporter to; reopen the bug with more information if it's still reproducible for them. .. _Maintenance of metadata:. Maintenance of metadata; =======================. Project member with write access to the project can create new labels, but we; discourage adding ad hoc labels because we want to control the proliferation of; labels and avoid single-use labels. If you would like a new label added, please; open an issue asking to create an issue label and add the ``infrastructure``; label to the issue. The request should include a description of what the label; is for. Alternatively, you can ask for the label to be created on the; ``#infrastructure`` channel on the LLVM Discord.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst:5401,avoid,avoid,5401,interpreter/llvm-project/llvm/docs/BugLifeCycle.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst,1,['avoid'],['avoid']
Safety," safe. The next stage is to check if computation of the distance to a give; physical object specified by a path was required. If this is the case,; the modeller changes the state to point to the required object, converts; the current point and direction coordinates to the local frame of this; object and computes the distance to its shape. The node returned is the; one pointed by the input path in case the shape is crossed; otherwise; the returned value is NULL. In case the distance to next crossed; boundary is required, the current point has to be physically INSIDE the; shape pointed by the current volume. This is only insured in case a call; to `TGeoManager::FindNode()` was performed for the current point.; Therefore, the first step is to convert the global current point and; direction in the local reference frame of the current volume and to; compute the distance to exit its shape from inside. The returned value; is again compared to the maximum allowed step (the proposed one) and in; case the distance is safe no other action is performed and the proposed; step is approved. In case the boundary is closer, the computed distance; is taken as maximum allowed step. For optimization purposed, for; particles starting very close to the current volume boundary (less than; 0.01 microns) and exiting the algorithm stops here. After computing the distance to exit the current node, the distance to; the daughter of the current volume which is crossed next is computed by; **`TGeoManager`**`::FindNextDaughterBoundary().` This computes the; distance to all daughter candidates that can be possibly crossed by; using volume voxelization. The algorithm is efficient in average only in; case the number of daughters is greater than 4. For fewer nodes, a; simple loop is performed and the minimum distance (from a point outside; each shape) is taken and compared to the maximum allowed step. The step; value is again updated if `step<stepmax` . A special case is when the current node is decla",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:162777,safe,safe,162777,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['safe'],['safe']
Safety," same, ONCE; the events are weighted such that signal and background have the same weight. ; Hence, the LD classifier still gives exactly the same result as the ""old"" Fisher; implementation, while the corrected Fisher implementation allows to ""play"" with; different event weights to perhaps find better discrimination power in certain; regions of the ROC curve. ; 2) BDT. a) Changes to some tuning options . nEventsMin --> MinNodeSize; UseNTrainEvents --> BaggedSampleFraction. have been replaced by options that are now given in terms of the relative; size of the training sample rather than in absulut numbers of events. This; is in order to facilitate the parameter tuning on different sample sizes; (i.e when starting on a smaller data sample to tune the parameter in order; to speed up the training); Furthermore, this option here has been changed name. GradBaggingFraction --> BaggedSampleFraction. in an attempt to consolidate and avoid idential duplicate code; ; The option UseWeightedTrees has been removed and set to ""true"", as was default; anyway, as a measure of further consolidation. Removed the option NNodesMax --> This should be replaced by specifying MaxDepth; instead (limiting the maximum tree depth also limits the number of possible nodes!). b) Added a trial version of a new ""cost sensitive"" boosting algorithem according to; Wei Fan and Salvatore J. Stolfo, {\em AdaCost: misclassification cost-sensitive boosting}, Proceedings of the 16th International conference on machine learning (ICML 1999)}. With the currently; chosen DEFAULT settings (all costs equal and set to ""one""), it is equivalent to the ""real-AdaBoost"" (i.e. using the option !UseYesNoLeaf (which uses the leave node purity rather than a signal or background attribute in the leaf node of each individual tree). Unfortunatly, no reasonable performance has been achieved yet when choosing different cost parameters. c) BDT's with little tree depth (as favoured for good performance) do not *like* it if; there ar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt:1590,avoid,avoid,1590,documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt,1,['avoid'],['avoid']
Safety," sample2[n2] containing the data; ; ROOT::Math::GoFTest goftest(n1, sample1, n2, sample2);; double pValueAD = goftest.AndersonDarling2SamplesTest();; double pValueKS = goftest.KolmogorovSmirnov2SamplesTest();; ; The class can return optionally also the test statistics instead of; the p value.; Example 2: perform a 1 sample test with a pre-defined; distribution starting from a data set sample[n]. ROOT::Math::GoFTest goftest(n, sample, ROOT::Math::GoFTest::kGaussian);; double pValueAD = goftest.AndersonDarlingTest();; double pValueKS = goftest.KolmogorovSmirnovTest();; . Example 3: perform a 1 sample test with a user-defined; distribution provided as cdf; ; ROOT::Math::Functor1D cdf_func(&ROOT::Math::landau_cdf);; ROOT::Math::GofTest goftest(n, sample, cdf_func, ROOT::Math::GoFTest::kCDF);; double pValueAD = goftest.AndersonDarlingTest();; . Example 4: perform a 1 sample test with a user-defined; distribution provided as pdf. Note that in this case to avoid; integration problems is sometimes recommended to give some; reasonable xmin and xmax values. xmin (and xmax) should however be; smaller (larger) than the minimum (maximum) data value.; ; ROOT::Math::Functor1D pdf_func(&ROOT::Math::landau_pdf);; double xmin = 5*TMath::Min_Element(n,sample);; double xmax = 5*TMath::Max_Element(n,sample);; ROOT::Math::GofTest goftest(n, sample, pdf_func, ROOT::Math::GoFTest::kPDF,xmin,xmax);; double pValueAD = goftest.AndersonDarlingTest();; . The tutorial math/goftest.C is an example on; how to use the ROOT::Math::GofTest class. New class TKDTreeBinning for binning multidimensional data.; ; The class implements multidimensional binning by constructing a; TKDTree inner structure form the data which is used as the bins.; The bins are retrieved as two double*, one for the minimum bin edges,; the other as the maximum bin edges. For one dimension one of these is enough; to correctly define the bins. The bin edges of d-dimensional data is a d-tet; of the bin's thresholds. For example if d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html:2176,avoid,avoid,2176,math/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html,1,['avoid'],['avoid']
Safety," section describes the instruction flow through the default pipeline of; :program:`llvm-mca`, as well as the functional units involved in the process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:34865,predict,prediction,34865,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['predict'],['prediction']
Safety," see; the :ref:`list <ubsan-checks>` of specific kinds of; undefined behavior that can be detected and the :ref:`list <cfi-schemes>`; of control flow integrity schemes. The ``-fsanitize=`` argument must also be provided when linking, in; order to link to the appropriate runtime library. It is not possible to combine more than one of the ``-fsanitize=address``,; ``-fsanitize=thread``, and ``-fsanitize=memory`` checkers in the same; program. .. option:: -f[no-]sanitize-recover=check1,check2,... .. option:: -f[no-]sanitize-recover[=all]. Controls which checks enabled by ``-fsanitize=`` flag are non-fatal.; If the check is fatal, program will halt after the first error; of this kind is detected and error report is printed. By default, non-fatal checks are those enabled by; :doc:`UndefinedBehaviorSanitizer`,; except for ``-fsanitize=return`` and ``-fsanitize=unreachable``. Some; sanitizers may not support recovery (or not support it by default; e.g. :doc:`AddressSanitizer`), and always crash the program after the issue; is detected. Note that the ``-fsanitize-trap`` flag has precedence over this flag.; This means that if a check has been configured to trap elsewhere on the; command line, or if the check traps by default, this flag will not have; any effect unless that sanitizer's trapping behavior is disabled with; ``-fno-sanitize-trap``. For example, if a command line contains the flags ``-fsanitize=undefined; -fsanitize-trap=undefined``, the flag ``-fsanitize-recover=alignment``; will have no effect on its own; it will need to be accompanied by; ``-fno-sanitize-trap=alignment``. .. option:: -f[no-]sanitize-trap=check1,check2,... .. option:: -f[no-]sanitize-trap[=all]. Controls which checks enabled by the ``-fsanitize=`` flag trap. This; option is intended for use in cases where the sanitizer runtime cannot; be used (for instance, when building libc or a kernel module), or where; the binary size increase caused by the sanitizer runtime is a concern. This flag is only com",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:77180,detect,detected,77180,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['detect'],['detected']
Safety," sense that will never change the current state. **`stepmax < 0`**. The global matrix for the object that will have the next crossed; boundary is also computed. This can be retrieved for masterlocal point; or vector conversions: **`TGeoManager`**::`GetNextMatrix`(). In case the computation of the normal vector to the next crossed surface; is required, using a negative stepmax value is recommended. In this case; one can subsequently call a method for fast normal computation:. ``` {.cpp}; Double_t *TGeoManager::FindNormalFast(); ```. **`path `** **` 0`**. In case a path to a given physical object is specified, the distance to; its boundary is computed ignoring the rest of the geometry. #### Output Values. `TGeoManager::GetStep()`: distance to next boundary. `TGeoManager::GetSafeDistance()`: safe distance (in case it was; computed). `TGeoManager::IsOnBoundary()`: the initial point `(x,y,z)` was (or was; not) on a boundary within `TGeoShape::Tolerance()`. The algorithm checks first if the computation of safety was required. If; this is the case and the global point coordinates did not change from; the last query, the last computed safety is taken. Otherwise, the method; **`TGeoManager`**`::Safety ()` is invoked. A safety value less than; **`TGeoShape`**`::Tolerance()` will set the flag IsOnBoundary to true.; On the other hand, a safety value bigger than the proposed step will; stop the computation of the distance to next boundary, returning the; current geometry location with the meaning that the proposed step is; safe. The next stage is to check if computation of the distance to a give; physical object specified by a path was required. If this is the case,; the modeller changes the state to point to the required object, converts; the current point and direction coordinates to the local frame of this; object and computes the distance to its shape. The node returned is the; one pointed by the input path in case the shape is crossed; otherwise; the returned value is NULL.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:161234,safe,safety,161234,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['safe'],['safety']
Safety," set of capabilities that are actually held by a given thread at a given; point in program execution is a run-time concept. The static analysis works; by calculating an approximation of that set, called the *capability; environment*. The capability environment is calculated for every program point,; and describes the set of capabilities that are statically known to be held, or; not held, at that particular point. This environment is a conservative; approximation of the full set of capabilities that will actually held by a; thread at run-time. Reference Guide; ===============. The thread safety analysis uses attributes to declare threading constraints.; Attributes must be attached to named declarations, such as classes, methods,; and data members. Users are *strongly advised* to define macros for the various; attributes; example definitions can be found in :ref:`mutexheader`, below.; The following documentation assumes the use of macros. The attributes only control assumptions made by thread safety analysis and the; warnings it issues. They don't affect generated code or behavior at run-time. For historical reasons, prior versions of thread safety used macro names that; were very lock-centric. These macros have since been renamed to fit a more; general capability model. The prior names are still in use, and will be; mentioned under the tag *previously* where appropriate. GUARDED_BY(c) and PT_GUARDED_BY(c); ----------------------------------. ``GUARDED_BY`` is an attribute on data members, which declares that the data; member is protected by the given capability. Read operations on the data; require shared access, while write operations require exclusive access. ``PT_GUARDED_BY`` is similar, but is intended for use on pointers and smart; pointers. There is no constraint on the data member itself, but the *data that; it points to* is protected by the given capability. .. code-block:: c++. Mutex mu;; int *p1 GUARDED_BY(mu);; int *p2 PT_GUARDED_BY(mu);; unique_ptr<int> p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:6355,safe,safety,6355,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['safe'],['safety']
Safety," should; not pessimize generated code. This pass obviously modifies the CFG, but updates loop information and; dominator information. ``loop-unroll``: Unroll loops; -----------------------------. This pass implements a simple loop unroller. It works best when loops have; been canonicalized by the :ref:`indvars <passes-indvars>` pass, allowing it to; determine the trip counts of loops easily. ``loop-unroll-and-jam``: Unroll and Jam loops; ---------------------------------------------. This pass implements a simple unroll and jam classical loop optimisation pass.; It transforms loop from:. .. code-block:: c++. for i.. i+= 1 for i.. i+= 4; for j.. for j..; code(i, j) code(i, j); code(i+1, j); code(i+2, j); code(i+3, j); remainder loop. Which can be seen as unrolling the outer loop and ""jamming"" (fusing) the inner; loops into one. When variables or loads can be shared in the new inner loop, this; can lead to significant performance improvements. It uses; :ref:`Dependence Analysis <passes-da>` for proving the transformations are safe. ``lower-global-dtors``: Lower global destructors; ------------------------------------------------. This pass lowers global module destructors (``llvm.global_dtors``) by creating; wrapper functions that are registered as global constructors in; ``llvm.global_ctors`` and which contain a call to ``__cxa_atexit`` to register; their destructor functions. ``loweratomic``: Lower atomic intrinsics to non-atomic form; -----------------------------------------------------------. This pass lowers atomic intrinsics to non-atomic form for use in a known; non-preemptible environment. The pass does not verify that the environment is non-preemptible (in general; this would require knowledge of the entire call graph of the program including; any libraries which may not be available in bitcode form); it simply lowers; every atomic intrinsic. ``lowerinvoke``: Lower invokes to calls, for unwindless code generators; --------------------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:28793,safe,safe,28793,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['safe'],['safe']
Safety," simple example of a framework; class managing up to four threaded methods. Class `TMhs3`; (`TMhs3.h, TMhs3.cxx)` inherits from this base class, showing the `mhs3`; example 8.1 `(mhs3.h, mhs3.cxx) `within a class. The `Makefile` of this; example builds the shared libraries `libTThreadframe.so` and; `libTMhs3.so`. These are either loaded or executed by the ROOT script; `TMhs3demo.C,` or are linked against an executable: `TMhs3run.cxx`. ### Known Problems. Parts of the ROOT framework, like the interpreter, are not yet; thread-safe. Therefore, you should use this package with caution. If you; restrict your threads to distinct and \`simple' duties, you will able to; benefit from their use. The **`TThread`** class is available on all; platforms, which provide a POSIX compliant thread implementation. On; Linux, Xavier Leroy's Linux Threads implementation is widely used, but; the **`TThread`** implementation should be usable on all platforms that; provide `pthread`. **Linux Xlib on SMP machines** is not yet thread-safe. This may cause; crashes during threaded graphics operations; this problem is independent; of ROOT. **Object instantiation:** there is no implicit locking mechanism for; memory allocation and global ROOT lists. The user has to explicitly; protect their code when using them. ## The Signals of ROOT. The list of default signals handled by ROOT is:. ``` {.cpp}; kSigChildkSigPipe; kSigBuskSigAlarm; kSigSegmentationViolationkSigUrgent; kSigIllegalInstructionkSigFloatingException; kSigSystemkSigWindowChanged; ```. The signals ***`kSigFloatingException`***,; ***`kSigSegmentationViolation`***, ***`kSigIllegalInstruction`***, and; ***`kSigBus`*** cause the printing of the ***`*** Break *** `*** message; and make a long jump back to the ROOT prompt. No other custom; **`TSignalHandler`** can be added to these signals. The ***`kSigAlarm`*** signal handles asynchronous timers. The; ***`kSigWindowChanged`*** signal handles the resizing of the terminal; window. The other sig",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:17520,safe,safe,17520,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['safe'],['safe']
Safety," simply; be passed data type; for the other three macros, this will be a specialized; version of the llvm::ImmutableList,; llvm::ImmutableSet,; or llvm::ImmutableMap; templated class. For the ExampleDataType example above, the type; created would be equivalent to writing the declaration:. using ExampleDataTypeTy = llvm::ImmutableMap<SymbolRef, int>;. These macros will cover a majority of use cases; however, they still have a; few limitations. They cannot be used inside namespaces (since they expand to; contain top-level namespace references), and the data types that they define; cannot be referenced from more than one file. Note that ProgramStates are immutable; instead of modifying an existing; one, functions that modify the state will return a copy of the previous state; with the change applied. This updated state must be then provided to the; analyzer core by calling the CheckerContext::addTransition function.; Bug Reports; When a checker detects a mistake in the analyzed code, it needs a way to; report it to the analyzer core so that it can be displayed. The two classes used; to construct this report are BugType; and ; BugReport. BugType, as the name would suggest, represents a type of bug. The; constructor for BugType takes two parameters: The name of the bug; type, and the name of the category of the bug. These are used (e.g.) in the; summary page generated by the scan-build tool. The BugReport class represents a specific occurrence of a bug. In; the most common case, three parameters are used to form a BugReport:. The type of bug, specified as an instance of the BugType class.; A short descriptive string. This is placed at the location of the bug in; the detailed line-by-line output generated by scan-build.; The context in which the bug occurred. This includes both the location of; the bug in the program and the program's state when the location is reached. These are; both encapsulated in an ExplodedNode. In order to obtain the correct ExplodedNode, a decisio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html:15615,detect,detects,15615,interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,1,['detect'],['detects']
Safety," situation with; // this surprisingly long comment, so it would be unclear without the braces; // whether the following statement is in the scope of the `if`.; handleOtherDecl(D);; }. // This should also omit braces. The `for` loop contains only a single; // statement, so it shouldn't have braces. The `if` also only contains a; // single simple statement (the `for` loop), so it also should omit braces.; if (isa<FunctionDecl>(D)); for (auto *A : D.attrs()); handleAttr(A);. // Use braces for a `do-while` loop and its enclosing statement.; if (Tok->is(tok::l_brace)) {; do {; Tok = Tok->Next;; } while (Tok);; }. // Use braces for the outer `if` since the nested `for` is braced.; if (isa<FunctionDecl>(D)) {; for (auto *A : D.attrs()) {; // In this `for` loop body, it is necessary that we explain the situation; // with this surprisingly long comment, forcing braces on the `for` block.; handleAttr(A);; }; }. // Use braces on the outer block because there are more than two levels of; // nesting.; if (isa<FunctionDecl>(D)) {; for (auto *A : D.attrs()); for (ssize_t i : llvm::seq<ssize_t>(count)); handleAttrOnDecl(D, A, i);; }. // Use braces on the outer block because of a nested `if`; otherwise the; // compiler would warn: `add explicit braces to avoid dangling else`; if (auto *D = dyn_cast<FunctionDecl>(D)) {; if (shouldProcess(D)); handleVarDecl(D);; else; markAsIgnored(D);; }. See Also; ========. A lot of these comments and recommendations have been culled from other sources.; Two particularly important books for our work are:. #. `Effective C++; <https://www.amazon.com/Effective-Specific-Addison-Wesley-Professional-Computing/dp/0321334876>`_; by Scott Meyers. Also interesting and useful are ""More Effective C++"" and; ""Effective STL"" by the same author. #. `Large-Scale C++ Software Design; <https://www.amazon.com/Large-Scale-Software-Design-John-Lakos/dp/0201633620>`_; by John Lakos. If you get some free time, and you haven't read them: do so, you might learn; something.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:65121,avoid,avoid,65121,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['avoid'],['avoid']
Safety," so callees must initialize such; fields with +1 references, and callers must balance that +1 by releasing; or transferring them. Similar transfers of responsibility occur for ``__weak`` fields, but; since both sides must use native ``__weak`` support to ensure; calling convention compatibility, this transfer is always handled; automatically by the compiler. .. admonition:: Rationale. In earlier releases, when non-trivial ownership was only permitted; on fields in Objective-C++, the ABI used for such classes was the; ordinary ABI for non-trivial C++ classes, which passes arguments and; returns indirectly and does not transfer responsibility for arguments.; When support for Objective-C structs was added, it was decided to; change to the current ABI for three reasons:. - It permits ARC / non-ARC compatibility for structs containing only; ``__strong`` references, as long as the non-ARC side is careful about; transferring ownership. - It avoids unnecessary indirection for sufficiently small types that; the C ABI would prefer to pass in registers. - Given that struct arguments must be produced at +1 to satisfy C's; semantics of initializing the local parameter variable, transferring; ownership of that copy to the callee is generally better for ARC; optimization, since otherwise there will be releases in the caller; that are much harder to pair with transfers in the callee. Breaking compatibility with existing Objective-C++ structures was; considered an acceptable cost, as most Objective-C++ code does not have; binary-compatibility requirements. Any existing code which cannot accept; this compatibility break, which is necessarily Objective-C++, should; force the use of the standard C++ ABI by declaring an empty (but; non-defaulted) destructor. .. _arc.ownership.inference:. Ownership inference; -------------------. .. _arc.ownership.inference.variables:. Objects; ^^^^^^^. If an object is declared with retainable object owner type, but without an; explicit ownership qualifi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:63860,avoid,avoids,63860,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['avoid'],['avoids']
Safety," specific; non-dynamic rounding mode which does not match the actual rounding mode at; runtime results in undefined behavior. The exception behavior argument is a metadata string describing the floating; point exception semantics that required for the intrinsic. This argument; must be one of the following strings:. ::. ""fpexcept.ignore""; ""fpexcept.maytrap""; ""fpexcept.strict"". If this argument is ""fpexcept.ignore"" optimization passes may assume that the; exception status flags will not be read and that floating-point exceptions will; be masked. This allows transformations to be performed that may change the; exception semantics of the original code. For example, FP operations may be; speculatively executed in this case whereas they must not be for either of the; other possible values of this argument. If the exception behavior argument is ""fpexcept.maytrap"" optimization passes; must avoid transformations that may raise exceptions that would not have been; raised by the original code (such as speculatively executing FP operations), but; passes are not required to preserve all exceptions that are implied by the; original code. For example, exceptions may be potentially hidden by constant; folding. If the exception behavior argument is ""fpexcept.strict"" all transformations must; strictly preserve the floating-point exception semantics of the original code.; Any FP exception that would have been raised by the original code must be raised; by the transformed code, and the transformed code must not raise any FP; exceptions that would not have been raised by the original code. This is the; exception behavior argument that will be used if the code being compiled reads; the FP exception status flags, but this mode can also be used with code that; unmasks FP exceptions. The number and order of floating-point exceptions is NOT guaranteed. For; example, a series of FP operations that each may raise exceptions may be; vectorized into a single instruction that raises each unique ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:870552,avoid,avoid,870552,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['avoid'],['avoid']
Safety," speedup in drawings; 8. SVG code improvement for TGraph, TF1, TAxis drawings; 9. Provide new tooltip kind; - created only when needed (minimizing SVG code); - tooltip can be drawn for every object in the frame; - touch devices are supported; 10. Fix - let draw same object on the canvas with different options; 11. Create cached list of known class methods. It can be extended by users.; 12. Use of cached methods improves binary I/O performance by 20%; 13. Support TGaxis; 14. Project now can be obtained via 'bower install jsroot'; 15. Support 'scat' and 'text' draw options for TH2; 16. Support in binary I/O zipped buffer bigger than 16M; 17. Correctly handle in binary I/O pointer on TArray object (like in THnSparseArrayChunk). ## Changes in 4.3; 1. Implement TGeoCtub, TGeoParaboloid and TGeoHype shapes; 2. Support TGeoTube with Rmin==0; 3. Exclude empty faces in TGeoArb8; 4. Improve TGeoSphere creation - handle all parameters combinations; 5. Introduce JSROOT.cleanup() function to safely clear all drawn objects; 6. Fix wrong resize method in 'tabs' and 'collapsible' layouts; 7. Fix canvas resize problem (issue #27); 8. Fix zero-height canvas when draw TGeo in collapsible layout; 9. Fix problem of simultaneous move TGeo drawings and canvas in flexible layout. ## Changes in 4.2; 1. Significant performance improvements in 3D drawings - TGeo/TH2/TH3; 2. Implement TGeoPara, TGeoGtra, TGeoXtru and TGeoEltu shapes; 3. Optimize (reduce vertices number) for others TGeo shapes; 4. Correct rotation/translation/scaling of TGeo nodes; 5. Workaround for axis reflection (not directly supported in three.js); 6. Support array of objects in I/O (like in TAxis3D); 7. Correct reading of multi-dim arrays like Double_t fXY[8][2];; 8. Provide canvas toolbar for actions like savepng or unzoom; 9. Implement JSROOT.resize() function to let resize drawing after changes in page layout; 10. Fix error with title display/update. ## Changes in 4.1; 1. Introduce object inspector - one could browse ob",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:57919,safe,safely,57919,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['safe'],['safely']
Safety," src/RooVectorDataStore.cxx; src/RooWorkspace.cxx; src/RooWrapperPdf.cxx; src/TestStatistics/ConstantTermsOptimizer.cxx; src/TestStatistics/LikelihoodGradientWrapper.cxx; src/TestStatistics/LikelihoodSerial.cxx; src/TestStatistics/LikelihoodWrapper.cxx; src/TestStatistics/MinuitFcnGrad.cxx; src/TestStatistics/RooAbsL.cxx; src/TestStatistics/RooBinnedL.cxx; src/TestStatistics/RooRealL.cxx; src/TestStatistics/RooSubsidiaryL.cxx; src/TestStatistics/RooSumL.cxx; src/TestStatistics/RooUnbinnedL.cxx; src/TestStatistics/buildLikelihood.cxx; src/TestStatistics/SharedOffset.cxx; ${LegacyEvalBackendSources}; ${RooFitMPTestStatisticsSources}; DICTIONARY_OPTIONS; ""-writeEmptyRootPCM""; LIBRARIES; RooBatchCompute; ${EXTRA_LIBRARIES}; DEPENDENCIES; Core; Hist; Graf; Matrix; Tree; Minuit; RIO; MathCore; Foam; Smatrix; ${EXTRA_DEPENDENCIES}; LINKDEF; inc/LinkDef.h; ${EXTRA_DICT_OPTS}; ). # The following definitions are PUBLIC so they can also be used in ROOT-internal tests. if(roofit_legacy_eval_backend); target_compile_definitions(RooFitCore PUBLIC ROOFIT_LEGACY_EVAL_BACKEND); endif(). if(roofit_multiprocess); target_compile_definitions(RooFitCore PUBLIC ROOFIT_MULTIPROCESS); endif(). if(clad); target_compile_definitions(RooFitCore PUBLIC ROOFIT_CLAD); endif(). if(cuda); target_compile_definitions(RooFitCore PUBLIC ROOFIT_CUDA); endif(). if(fftw3); target_compile_definitions(RooFitCore PUBLIC ROOFIT_MATH_FFTW3); endif(). # To avoid deprecation warnings when including old test statistics headers.; # RooFit has to include them to build the documentation.; target_compile_definitions(RooFitCore PUBLIC ROOFIT_BUILDS_ITSELF). target_include_directories(RooFitCore PUBLIC $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/res>). # For recent clang, this can facilitate auto-vectorisation.; # In RooFit, the errno side effect is not needed, anyway:; if(""${CMAKE_CXX_COMPILER_ID}"" MATCHES ""Clang""); target_compile_options(RooFitCore PUBLIC -fno-math-errno); endif(). ROOT_ADD_TEST_SUBDIRECTORY(test); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/CMakeLists.txt:11090,avoid,avoid,11090,roofit/roofitcore/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/CMakeLists.txt,1,['avoid'],['avoid']
Safety," store, update the FragmentInfo in; the `ValueExpression`, and give the split stores (and cloned intrinsics) new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` intrinsic. ### Lowering `llvm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the results for each block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:8479,avoid,avoid,8479,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md,1,['avoid'],['avoid']
Safety," style. This can be enabled/disabled via the GUI.Style entry in $ROOTSYS/etc/system.rootrc (or in a user defined $HOME/.rootrc); Create special icons for symlinks (shortcuts) in the browser (add a small arrow on bottom left corner of the original icon). TGFileDialog. Implemented the wish #78935: Longer ""File of type:"" selector is wanted (make more combo box entries visible); Enable the new (flat) button style. This can be enabled/disabled via the GUI.Style entry in $ROOTSYS/etc/system.rootrc (or in a user defined $HOME/.rootrc). TGFSContainer. The shortcuts are now working on Windows. TGColorDialog, TGFontDialog, TGTextEditDialogs. Several improvements in the layout when increasing the font size. TGTextEditor. Added a ""Close"" menu entry; Properly ask the user to save the currently opened file (if modified) when trying to open a new file; Moved the IsSaved() part of the code in the LoadFile() method, to make sure it works also when the text editor is used as a plugin in the browser; Change the text highlighing color; Cleanup the text when quitting root (avoid potential crash on Linux). TGFrame. Allow to override CTRL+S behavior by using the TGMainFrame::BindKey() function. TVirtualDragManager. Renamed TVirtualDragManager::GetDragType() to TVirtualDragManager::GetEDragType(), to avoid potential clash between two classes (TGFrame and TVirtualDragManager) having both GetDragType method with different return types. And they are both inherited by one class (TGuiBldDragManager) which doesn't define GetDragType. TGSlider. Added mouse wheel handling. TGToolTip. Properly set the text color of the tooltip label, using the value of Gui.TooltipForegroundColor in $ROOTSYS/etc/system.rootrc (or in a user defined $HOME/.rootrc). GUIHtml; TGHtmlBrowser. Only add non-empty strings (urls) in the combo box, to avoid empty entries; Enable the new (flat) button style. This can be enabled/disabled via the GUI.Style entry in $ROOTSYS/etc/system.rootrc (or in a user defined $HOME/.rootrc). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v530/index.html:3666,avoid,avoid,3666,gui/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v530/index.html,2,['avoid'],['avoid']
Safety," support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made GC parseable by wrapping the; call into a statepoint. This makes it possible to take a safepoint during; copy operation. Note that a GC parseable copy operation is not required to; take a safepoint. For example, a short copy operation may be performed without; taking a safepoint. GC parseable calls to '``llvm.memcpy.element.unordered.atomic.*``',; '``llvm.memmove.element.unordered.atomic.*``' intrinsics are lowered to calls; to '``__llvm_memcpy_element_unordered_atomic_safepoint_*``',; '``__llvm_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This requires the corresponding base; pointers to be available in the copy operation. In order to make the base; pointers available RewriteStatepointsForGC replaces derived pointers with base; pointer and offset ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:30235,safe,safepoint,30235,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['safe'],['safepoint']
Safety," suspicious behavior, and is disabled by; default. If a check fails, a diagnostic message is produced at; runtime explaining the problem. The main checks are:. - .. _opt_fsanitize_address:. ``-fsanitize=address``:; :doc:`AddressSanitizer`, a memory error; detector.; - .. _opt_fsanitize_thread:. ``-fsanitize=thread``: :doc:`ThreadSanitizer`, a data race detector.; - .. _opt_fsanitize_memory:. ``-fsanitize=memory``: :doc:`MemorySanitizer`,; a detector of uninitialized reads. Requires instrumentation of all; program code.; - .. _opt_fsanitize_undefined:. ``-fsanitize=undefined``: :doc:`UndefinedBehaviorSanitizer`,; a fast and compatible undefined behavior checker. - ``-fsanitize=dataflow``: :doc:`DataFlowSanitizer`, a general data; flow analysis.; - ``-fsanitize=cfi``: :doc:`control flow integrity <ControlFlowIntegrity>`; checks. Requires ``-flto``.; - ``-fsanitize=kcfi``: kernel indirect call forward-edge control flow; integrity.; - ``-fsanitize=safe-stack``: :doc:`safe stack <SafeStack>`; protection against stack-based memory corruption errors. There are more fine-grained checks available: see; the :ref:`list <ubsan-checks>` of specific kinds of; undefined behavior that can be detected and the :ref:`list <cfi-schemes>`; of control flow integrity schemes. The ``-fsanitize=`` argument must also be provided when linking, in; order to link to the appropriate runtime library. It is not possible to combine more than one of the ``-fsanitize=address``,; ``-fsanitize=thread``, and ``-fsanitize=memory`` checkers in the same; program. .. option:: -f[no-]sanitize-recover=check1,check2,... .. option:: -f[no-]sanitize-recover[=all]. Controls which checks enabled by ``-fsanitize=`` flag are non-fatal.; If the check is fatal, program will halt after the first error; of this kind is detected and error report is printed. By default, non-fatal checks are those enabled by; :doc:`UndefinedBehaviorSanitizer`,; except for ``-fsanitize=return`` and ``-fsanitize=unreachable``. Some; sanitize",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:75999,safe,safe-stack,75999,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,['safe'],"['safe', 'safe-stack']"
Safety," taken to manually ensure that all such; accesses are safe. Furthermore, the addresses of such local variables should; never be stored on the heap, as it would leak the location of the SafeStack. ``__builtin___get_unsafe_stack_ptr()``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. This builtin function returns current unsafe stack pointer of the current; thread. ``__builtin___get_unsafe_stack_bottom()``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. This builtin function returns a pointer to the bottom of the unsafe stack of the; current thread. ``__builtin___get_unsafe_stack_top()``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. This builtin function returns a pointer to the top of the unsafe stack of the; current thread. ``__builtin___get_unsafe_stack_start()``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Deprecated: This builtin function is an alias for; ``__builtin___get_unsafe_stack_bottom()``. Design; ======. Please refer to the `Code-Pointer Integrity <https://dslab.epfl.ch/research/cpi/>`__; project page for more information about the design of the SafeStack and its; related technologies. setjmp and exception handling; -----------------------------. The `OSDI'14 paper <https://dslab.epfl.ch/pubs/cpi.pdf>`_ mentions that; on Linux the instrumentation pass finds calls to setjmp or functions that; may throw an exception, and inserts required instrumentation at their call; sites. Specifically, the instrumentation pass saves the shadow stack pointer; on the safe stack before the call site, and restores it either after the; call to setjmp or after an exception has been caught. This is implemented; in the function ``SafeStack::createStackRestorePoints``. Publications; ------------. `Code-Pointer Integrity <https://dslab.epfl.ch/pubs/cpi.pdf>`__.; Volodymyr Kuznetsov, Laszlo Szekeres, Mathias Payer, George Candea, R. Sekar, Dawn Song.; USENIX Symposium on Operating Systems Design and Implementation; (`OSDI <https://www.usenix.org/conference/osdi14>`_), Broomfield, CO, October 2014; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst:8661,safe,safe,8661,interpreter/llvm-project/clang/docs/SafeStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst,1,['safe'],['safe']
Safety," technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to set the flags register (much like ours!) with no actual dependency. In those; cases, it is safe to directly insert these instructions. Alternatively we may; be able to move them earlier to avoid clobbering the used value. However, this may ultimately be impossible. In that case, we need to preserve; the flags around these instructions:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; pushfq; orq %rax, %rcx # Mask the pointer if misspeculating.; orq %rax, %rdx # Mask the index if misspeculating.; popfq; movl (%rcx,%rdx), %edi; ```. Using the `pushf` and `popf` instructions saves the flags register around our; inserted code, but comes at a high cost. First, we must store the flags to the; stack and reload them. Second, this causes the stack pointer to be adjusted; dynamically, requiring a frame pointer be used for referring to temporaries; spilled to the stack, etc. On newer x86 processors we can use the `lahf` and `sahf` instructions to save; all of the flags besides the overflow flag in a register rather than on the; stack. We can then use `seto` and `add` to save and restore the overflow flag; in a register. Combined, t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:32251,avoid,avoid,32251,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['avoid'],['avoid']
Safety," than 1 and ticks marks; set to the positive side, alignement issues seem to come up.; The following example shows four TGAxis drawn respectively with the; following options: RG-, RG+, LG-, LG+. For the RG+ and LG+ options,; the 10E-1 and 10E-2 labels were ill-aligned, showing a shift to the right; compared to the 1E2, 1E1 and 1 labels.; ; {; c1 = new TCanvas(""c1"",""Examples of Log TGaxis"",10,10,700,500);; c1->Range(-10,-1,10,1);; TGaxis *axis1 = new TGaxis(-7,-0.8,-7,0.8,0.01,100,50510,""RG-"");; axis1->SetTitle(""RG-""); axis1->Draw();; TGaxis *axis2 = new TGaxis(-2,-0.8,-2,0.8,0.01,100,50510,""RG+"");; axis2->SetLabelOffset(-0.04); axis2->SetTitleOffset(-1.5);; axis2->SetTitle(""RG+""); axis2->Draw();; TGaxis *axis3 = new TGaxis(2,-0.8,2,0.8,0.01,100,50510,""LG-"");; axis3->SetLabelOffset(-0.04);; axis3->SetTitle(""LG-""); axis3->Draw();; TGaxis *axis4 = new TGaxis(7,-0.8,7,0.8,0.01,100,50510,""LG+"");; axis4->SetTitleOffset(-1);; axis4->SetTitle(""LG+""); axis4->Draw();; }; ; gStyle.SetStripDecimals(kFALSE) did not work in cases like the; following one:; ; {; gStyle.SetStripDecimals(kFALSE);; gStyle.SetPadLeftMargin(.15);; TGraph graph_freq;; graph_freq.SetPoint(0, 933., 40078879.);; graph_freq.SetPoint(1, 934., 40078966.);; graph_freq.Draw(""A*"");; }; . TCrown. The crown picking did not work.; Improve help. TLatex. The text angle was not taken into account in case the; text was painted in low precision like in:; ; gStyle->SetTitleFont(60,""xy"");; TH1F* h=new TH1F(""foo"", ""bar;#int;#int"", 10, 0, 1);; h->Draw();; ; In that example the Y title was not rotated. TCanvas. A canvas is turned into GL mode only if the; canvas name starts with ""gl"". Before the; ""gl"" string could be anywhere in the name. QtRoot/ libGQt. The redundant Qt3-related code was removed.; The Q3_SUPPORT flag was eliminated.; The plug-in can be used with and without Q3_SUPPORT now.; The code was adjusted to work under the Qt 4.5.x.; Many platform depended (win32) sections; were replaced with the cross-platform code. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v524/index.html:3447,redund,redundant,3447,graf2d/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v524/index.html,1,['redund'],['redundant']
Safety," that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:4334,safe,safety,4334,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['safe'],['safety']
Safety," that update individual; functions from ``std::error_code`` to ``Error``, and from ``ErrorOr<T>`` to; ``Expected<T>``. Returning Errors from error handlers; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Error recovery attempts may themselves fail. For that reason, ``handleErrors``; actually recognises three different forms of handler signature:. .. code-block:: c++. // Error must be handled, no new errors produced:; void(UserDefinedError &E);. // Error must be handled, new errors can be produced:; Error(UserDefinedError &E);. // Original error can be inspected, then re-wrapped and returned (or a new; // error can be produced):; Error(std::unique_ptr<UserDefinedError> E);. Any error returned from a handler will be returned from the ``handleErrors``; function so that it can be handled itself, or propagated up the stack. .. _err_exitonerr:. Using ExitOnError to simplify tool code; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Library code should never call ``exit`` for a recoverable error, however in tool; code (especially command line tools) this can be a reasonable approach. Calling; ``exit`` upon encountering an error dramatically simplifies control flow as the; error no longer needs to be propagated up the stack. This allows code to be; written in straight-line style, as long as each fallible call is wrapped in a; check and call to exit. The ``ExitOnError`` class supports this pattern by; providing call operators that inspect ``Error`` values, stripping the error away; in the success case and logging to ``stderr`` then exiting in the failure case. To use this class, declare a global ``ExitOnError`` variable in your program:. .. code-block:: c++. ExitOnError ExitOnErr;. Calls to fallible functions can then be wrapped with a call to ``ExitOnErr``,; turning them into non-failing calls:. .. code-block:: c++. Error mayFail();; Expected<int> mayFail2();. void foo() {; ExitOnErr(mayFail());; int X = ExitOnErr(mayFail2());; }. On failure, the error's log message will be written to ``st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:30452,recover,recoverable,30452,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['recover'],['recoverable']
Safety," that would otherwise; be dllexported refer to internal symbols of a DLL. For example:. .. code-block:: c. void internal();. struct __declspec(dllimport) S {; void foo() { internal(); }; }. Normally, references to `S::foo()` would use the definition in the DLL from; which it was exported, and which presumably also has the definition of; `internal()`. However, when using ``/Zc:dllexportInlines-``, the inline; definition of `S::foo()` is used directly, resulting in a link error since; `internal()` is not available. Even worse, if there is an inline definition of; `internal()` containing a static local variable, we will now refer to a; different instance of that variable than in the DLL:. .. code-block:: c. inline int internal() { static int x; return x++; }. struct __declspec(dllimport) S {; int foo() { return internal(); }; }. This could lead to very subtle bugs. Using ``-fvisibility-inlines-hidden`` can; lead to the same issue. To avoid it in this case, make `S::foo()` or; `internal()` non-inline, or mark them `dllimport/dllexport` explicitly. Finding Clang runtime libraries; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. clang-cl supports several features that require runtime library support:. - Address Sanitizer (ASan): ``-fsanitize=address``; - Undefined Behavior Sanitizer (UBSan): ``-fsanitize=undefined``; - Code coverage: ``-fprofile-instr-generate -fcoverage-mapping``; - Profile Guided Optimization (PGO): ``-fprofile-generate``; - Certain math operations (int128 division) require the builtins library. In order to use these features, the user must link the right runtime libraries; into their program. These libraries are distributed alongside Clang in the; library resource directory. Clang searches for the resource directory by; searching relative to the Clang executable. For example, if LLVM is installed; in ``C:\Program Files\LLVM``, then the profile runtime library will be located; at the path; ``C:\Program Files\LLVM\lib\clang\11.0.0\lib\windows\clang_rt.profile-x86_64.li",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:190121,avoid,avoid,190121,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['avoid'],['avoid']
Safety," the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. defi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36299,redund,redundant,36299,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['redund'],['redundant']
Safety," the advantage of providing the strongest degree; of mitigation when mixed with unmitigated code by halting all misspeculation; entering a function which is mitigated, regardless of what occurred in the; caller. However, such a mixture is inherently more risky. Whether this kind of; mixture is a sufficient mitigation requires careful analysis. Unfortunately, experimental results indicate that the performance overhead of; this approach is very high for certain patterns of code. A classic example is; any form of recursive evaluation engine. The hot, rapid call and return; sequences exhibit dramatic performance loss when mitigated with `lfence`. This; component alone can regress performance by 2x or more, making it an unpleasant; tradeoff even when only used in a mixture of code. ##### Use an internal TLS location to pass predicate state. We can define a special thread-local value to hold the predicate state between; functions. This avoids direct ABI implications by using a side channel between; callers and callees to communicate the predicate state. It also allows implicit; zero-initialization of the state, which allows non-checked code to be the first; code executed. However, this requires a load from TLS in the entry block, a store to TLS; before every call and every ret, and a load from TLS after every call. As a; consequence it is expected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:42548,avoid,avoids,42548,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['avoid'],['avoids']
Safety," the asymptotically correct method when using the `RooFit::AsymptoticError()` command argument in [RooAbsPdf::fitTo()](https://root.cern.ch/doc/master/classRooAbsPdf.html#ab0721374836c343a710f5ff92a326ff5).; See also this [writeup on extended weighted fits](https://root.cern/files/extended_weighted_fits.pdf) that is also linked from the reference guide.; The [pull request](https://github.com/root-project/root/pull/14751) that introduced this feature might also be a good reference. ### Compile your code with memory safe interfaces. If you define the `ROOFIT_MEMORY_SAFE_INTERFACES` preprocessor macro, the; RooFit interface changes in a way such that memory leaks are avoided. The most prominent effect of this change is that many functions that used to; return an owning pointer (e.g., a pointer to an object that you need to; manually `delete`) are then returning a `std::unique_pt` for automatic memory; management. For example this code would not compile anymore, because there is the risk that; the caller forgets to `delete params`:; ```c++; RooArgSet * params = pdf.getParameters(nullptr);; ```; If you wrap such return values in a `std::unique_ptr`, then your code will; compile both with and without memory safe interfaces:; ```c++; std::unique_ptr<RooArgSet> params{pdf.getParameters(nullptr)};; ```. Also some `virtual` RooFit functions like [RooAbsReal::createIntegral()](https://root.cern.ch/doc/master/classRooAbsReal.html#aff4be07dd6a131721daeeccf6359aea9); are returning a different type conditional on `ROOFIT_MEMORY_SAFE_INTERFACES`.; If you are overriding such a function, you need to use the `RooFit::OwningPtr`; return type, which is an alias for `std::unique_ptr` in memory-safe mode or an; alias for a raw pointer otherwise.; ```c++; RooFit::OwningPtr<RooAbsReal> RooAbsReal::createIntegral(...) const override; {; std::unique_ptr<RooAbsReal> integral;; // Prepare a std::unique_ptr as the return value; ...; // Use the RooFit::makeOwningPtr<T>() helper to translate the; /",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:8885,risk,risk,8885,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['risk'],['risk']
Safety," the class. The :option:`-fstandalone-debug` option turns off these optimizations.; This is useful when working with 3rd-party libraries that don't come with; debug information. This is the default on Darwin. Note that Clang will; never emit type information for types that are not referenced at all by the; program. .. option:: -feliminate-unused-debug-types. By default, Clang does not emit type information for types that are defined; but not used in a program. To retain the debug info for these unused types,; the negation **-fno-eliminate-unused-debug-types** can be used. .. option:: -fexceptions. Allow exceptions to be thrown through Clang compiled stack frames (on many; targets, this will enable unwind information for functions that might have; an exception thrown through them). For most targets, this is enabled by; default for C++. .. option:: -ftrapv. Generate code to catch integer overflow errors. Signed integer overflow is; undefined in C. With this flag, extra code is generated to detect this and; abort when it happens. .. option:: -fvisibility. This flag sets the default visibility level. .. option:: -fcommon, -fno-common. This flag specifies that variables without initializers get common linkage.; It can be disabled with :option:`-fno-common`. .. option:: -ftls-model=<model>. Set the default thread-local storage (TLS) model to use for thread-local; variables. Valid values are: ""global-dynamic"", ""local-dynamic"",; ""initial-exec"" and ""local-exec"". The default is ""global-dynamic"". The default; model can be overridden with the tls_model attribute. The compiler will try; to choose a more efficient model if possible. .. option:: -flto, -flto=full, -flto=thin, -emit-llvm. Generate output files in LLVM formats, suitable for link time optimization.; When used with :option:`-S` this generates LLVM intermediate language; assembly files, otherwise this generates LLVM bitcode format object files; (which may be passed to the linker depending on the stage selection options)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:14328,detect,detect,14328,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,2,"['abort', 'detect']","['abort', 'detect']"
Safety," the following methods of synchronization:. - `TCondition::Wait()` waits until any thread sends a signal of the; same condition instance: `MyCondition.Wait()` reacts on; `MyCondition.Signal()` or `MyCondition.Broadcast()`.; `MyOtherCondition.Signal()` has no effect. - If several threads wait for the signal from the same; **`TCondition`** `MyCondition`, at `MyCondition.Signal()` only one; thread will react; to activate a further thread another; `MyCondition.Signal()` is required, etc. - If several threads wait for the signal from the same; **`TCondition`** `MyCondition`, at `MyCondition.Broadcast()` all; threads waiting for `MyCondition` are activated at once. In some tests of `MyCondition` using an internal mutex, `Broadcast()`; activated only one thread (probably depending whether `MyCondition` had; been signaled before). - `MyCondition.TimedWait(secs,nanosecs)` waits for `MyCondition` until; the *absolute* time in seconds and nanoseconds since beginning of; the epoch (January, 1st, 1970) is reached; to use relative timeouts; ‘‘delta'', it is required to calculate the absolute time at the; beginning of waiting ‘‘now''; for example:. ``` {.cpp}; Ulong_t now,then,delta; // seconds; TDatime myTime; // root daytime class; myTime.Set(); // myTime set to ""now""; now=myTime.Convert(); // to seconds since 1970; ```. - Return value wait of `MyCondition.TimedWait` should be 0, if; `MyCondition.Signal()` was received, and should be nonzero, if; timeout was reached. The conditions example shows how three threaded functions are; synchronized using **`TCondition`**: a ROOT script `condstart.C` starts; the threads, which are defined in a shared library; (`conditions.cxx, conditions.h`). #### Xlib Connections. Usually `Xlib` is not thread safe. This means that calls to the X could; fail, when it receives X-messages from different threads. The actual; result depends strongly on which version of `Xlib` has been installed on; your system. The only thing we can do here within ROOT is ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:9285,timeout,timeouts,9285,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['timeout'],['timeouts']
Safety," the function acquires the mutex a second time. .. code-block:: c++. Mutex mu;; int a GUARDED_BY(mu);. void clear() EXCLUDES(mu) {; mu.Lock();; a = 0;; mu.Unlock();; }. void reset() {; mu.Lock();; clear(); // Warning! Caller cannot hold 'mu'.; mu.Unlock();; }. Unlike ``REQUIRES``, ``EXCLUDES`` is optional. The analysis will not issue a; warning if the attribute is missing, which can lead to false negatives in some; cases. This issue is discussed further in :ref:`negative`. NO_THREAD_SAFETY_ANALYSIS; -------------------------. ``NO_THREAD_SAFETY_ANALYSIS`` is an attribute on functions or methods, which; turns off thread safety checking for that method. It provides an escape hatch; for functions which are either (1) deliberately thread-unsafe, or (2) are; thread-safe, but too complicated for the analysis to understand. Reasons for; (2) will be described in the :ref:`limitations`, below. .. code-block:: c++. class Counter {; Mutex mu;; int a GUARDED_BY(mu);. void unsafeIncrement() NO_THREAD_SAFETY_ANALYSIS { a++; }; };. Unlike the other attributes, NO_THREAD_SAFETY_ANALYSIS is not part of the; interface of a function, and should thus be placed on the function definition; (in the ``.cc`` or ``.cpp`` file) rather than on the function declaration; (in the header). RETURN_CAPABILITY(c); --------------------. *Previously*: ``LOCK_RETURNED``. ``RETURN_CAPABILITY`` is an attribute on functions or methods, which declares; that the function returns a reference to the given capability. It is used to; annotate getter methods that return mutexes. .. code-block:: c++. class MyClass {; private:; Mutex mu;; int a GUARDED_BY(mu);. public:; Mutex* getMu() RETURN_CAPABILITY(mu) { return &mu; }. // analysis knows that getMu() == mu; void clear() REQUIRES(getMu()) { a = 0; }; };. ACQUIRED_BEFORE(...), ACQUIRED_AFTER(...); -----------------------------------------. ``ACQUIRED_BEFORE`` and ``ACQUIRED_AFTER`` are attributes on member; declarations, specifically declarations of mutexes or othe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:11360,unsafe,unsafeIncrement,11360,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['unsafe'],['unsafeIncrement']
Safety," the location of the; constructor or aggregate initialization used to create the object. Otherwise; the invocation point is the same as the location of the builtin. When the invocation point of ``__builtin_FUNCTION`` is not a function scope the; empty string is returned. The builtin ``__builtin_source_location`` returns a pointer to constant static; data of type ``std::source_location::__impl``. This type must have already been; defined, and must contain exactly four fields: ``const char *_M_file_name``,; ``const char *_M_function_name``, ``<any-integral-type> _M_line``, and; ``<any-integral-type> _M_column``. The fields will be populated in the same; manner as the above four builtins, except that ``_M_function_name`` is populated; with ``__PRETTY_FUNCTION__`` rather than ``__FUNCTION__``. Alignment builtins; ------------------; Clang provides builtins to support checking and adjusting alignment of; pointers and integers.; These builtins can be used to avoid relying on implementation-defined behavior; of arithmetic on integers derived from pointers.; Additionally, these builtins retain type information and, unlike bitwise; arithmetic, they can perform semantic checking on the alignment value. **Syntax**:. .. code-block:: c. Type __builtin_align_up(Type value, size_t alignment);; Type __builtin_align_down(Type value, size_t alignment);; bool __builtin_is_aligned(Type value, size_t alignment);. **Example of use**:. .. code-block:: c++. char* global_alloc_buffer;; void* my_aligned_allocator(size_t alloc_size, size_t alignment) {; char* result = __builtin_align_up(global_alloc_buffer, alignment);; // result now contains the value of global_alloc_buffer rounded up to the; // next multiple of alignment.; global_alloc_buffer = result + alloc_size;; return result;; }. void* get_start_of_page(void* ptr) {; return __builtin_align_down(ptr, PAGE_SIZE);; }. void example(char* buffer) {; if (__builtin_is_aligned(buffer, 64)) {; do_fast_aligned_copy(buffer);; } else {; do_unalign",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:150573,avoid,avoid,150573,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['avoid'],['avoid']
Safety," the mangled name for ""typeinfo name for T"".; - Calculate MD5 hash of the name as a string.; - Reinterpret the first 8 bytes of the hash as a little-endian; 64-bit integer. It is possible, but unlikely, that collisions in the; ``CallSiteTypeId`` hashing will result in weaker CFI checks that would; still be conservatively correct. CFI_Check; ---------. In the general case, only the target DSO knows whether the call to; function ``f`` with type ``CallSiteTypeId`` is valid or not. To; export this information, every DSO implements. .. code-block:: none. void __cfi_check(uint64 CallSiteTypeId, void *TargetAddr, void *DiagData). This function provides external modules with access to CFI checks for; the targets inside this DSO. For each known ``CallSiteTypeId``, this; function performs an ``llvm.type.test`` with the corresponding type; identifier. It reports an error if the type is unknown, or if the; check fails. Depending on the values of compiler flags; ``-fsanitize-trap`` and ``-fsanitize-recover``, this function may; print an error, abort and/or return to the caller. ``DiagData`` is an; opaque pointer to the diagnostic information about the error, or; ``null`` if the caller does not provide this information. The basic implementation is a large switch statement over all values; of CallSiteTypeId supported by this DSO, and each case is similar to; the InlinedFastCheck() in the basic CFI mode. CFI Shadow; ----------. To route CFI checks to the target DSO's __cfi_check function, a; mapping from possible virtual / indirect call targets to the; corresponding __cfi_check functions is maintained. This mapping is; implemented as a sparse array of 2 bytes for every possible page (4096; bytes) of memory. The table is kept readonly most of the time. There are 3 types of shadow values:. - Address in a CFI-instrumented DSO.; - Unchecked address (a “trusted” non-instrumented DSO). Encoded as; value 0xFFFF.; - Invalid address (everything else). Encoded as value 0. For a CFI-instrument",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:21354,recover,recover,21354,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,2,"['abort', 'recover']","['abort', 'recover']"
Safety," the native functions.; For example, given the ABI list example provided in the user manual, the; following wrappers will be generated under the args ABI:. .. code-block:: llvm. define linkonce_odr { i8*, i16 } @""dfsw$malloc""(i64 %0, i16 %1) {; entry:; %2 = call i8* @malloc(i64 %0); %3 = insertvalue { i8*, i16 } undef, i8* %2, 0; %4 = insertvalue { i8*, i16 } %3, i16 0, 1; ret { i8*, i16 } %4; }. define linkonce_odr { i32, i16 } @""dfsw$tolower""(i32 %0, i16 %1) {; entry:; %2 = call i32 @tolower(i32 %0); %3 = insertvalue { i32, i16 } undef, i32 %2, 0; %4 = insertvalue { i32, i16 } %3, i16 %1, 1; ret { i32, i16 } %4; }. define linkonce_odr { i8*, i16 } @""dfsw$memcpy""(i8* %0, i8* %1, i64 %2, i16 %3, i16 %4, i16 %5) {; entry:; %labelreturn = alloca i16; %6 = call i8* @__dfsw_memcpy(i8* %0, i8* %1, i64 %2, i16 %3, i16 %4, i16 %5, i16* %labelreturn); %7 = load i16* %labelreturn; %8 = insertvalue { i8*, i16 } undef, i8* %6, 0; %9 = insertvalue { i8*, i16 } %8, i16 %7, 1; ret { i8*, i16 } %9; }. As an optimization, direct calls to native ABI functions will call the; native ABI function directly and the pass will compute the appropriate label; internally. This has the advantage of reducing the number of union operations; required when the return value label is known to be zero (i.e. ``discard``; functions, or ``functional`` functions with known unlabelled arguments). Checking ABI Consistency; ------------------------. DFSan changes the ABI of each function in the module. This makes it possible; for a function with the native ABI to be called with the instrumented ABI,; or vice versa, thus possibly invoking undefined behavior. A simple way; of statically detecting instances of this problem is to append the suffix; "".dfsan"" to the name of each instrumented-ABI function. This will not catch every such problem; in particular function pointers passed; across the instrumented-native barrier cannot be used on the other side.; These problems could potentially be caught dynamically.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst:12912,detect,detecting,12912,interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,1,['detect'],['detecting']
Safety," the optimizer. This prevents the GC from visiting; uninitialized pointers, which will almost certainly cause it to crash. As a fallback, LLVM will automatically initialize each root to ``null``; upon entry to the function. Support for this mode in code generation is; largely a legacy detail to keep old collector implementations working. Custom lowering of intrinsics; ------------------------------. For GCs which use barriers or unusual treatment of stack roots, the; implementor is responsibly for providing a custom pass to lower the; intrinsics with the desired semantics. If you have opted in to custom; lowering of a particular intrinsic your pass **must** eliminate all; instances of the corresponding intrinsic in functions which opt in to; your GC. The best example of such a pass is the ShadowStackGC and it's; ShadowStackGCLowering pass. There is currently no way to register such a custom lowering pass; without building a custom copy of LLVM. .. _safe-points:. Generating safe points; -----------------------. LLVM provides support for associating stackmaps with the return address of; a call. Any loop or return safepoints required by a given collector design; can be modeled via calls to runtime routines, or potentially patchable call; sequences. Using gcroot, all call instructions are inferred to be possible; safepoints and will thus have an associated stackmap. .. _assembly:. Emitting assembly code: ``GCMetadataPrinter``; ---------------------------------------------. LLVM allows a plugin to print arbitrary assembly code before and after the rest; of a module's assembly code. At the end of the module, the GC can compile the; LLVM stack map into assembly code. (At the beginning, this information is not; yet computed.). Since AsmWriter and CodeGen are separate components of LLVM, a separate abstract; base class and registry is provided for printing assembly code, the; ``GCMetadaPrinter`` and ``GCMetadataPrinterRegistry``. The AsmWriter will look; for such a subclass i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:34689,safe,safe,34689,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['safe'],['safe']
Safety," the support available in the specific; architecture. It is possible to alter the default extensions setting per target using; ``-cl-ext`` flag. (See :ref:`flags description <opencl_cl_ext>` for more details). Vendor extensions can be added flexibly by declaring the list of types and; functions associated with each extensions enclosed within the following; compiler pragma directives:. .. code-block:: c. #pragma OPENCL EXTENSION the_new_extension_name : begin; // declare types and functions associated with the extension here; #pragma OPENCL EXTENSION the_new_extension_name : end. For example, parsing the following code adds ``my_t`` type and ``my_func``; function to the custom ``my_ext`` extension. .. code-block:: c. #pragma OPENCL EXTENSION my_ext : begin; typedef struct{; int a;; }my_t;; void my_func(my_t);; #pragma OPENCL EXTENSION my_ext : end. There is no conflict resolution for identifier clashes among extensions.; It is therefore recommended that the identifiers are prefixed with a; double underscore to avoid clashing with user space identifiers. Vendor; extension should use reserved identifier prefix e.g. amd, arm, intel. Clang also supports language extensions documented in `The OpenCL C Language; Extensions Documentation; <https://github.com/KhronosGroup/Khronosdotorg/blob/main/api/opencl/assets/OpenCL_LangExt.pdf>`_. OpenCL-Specific Attributes; --------------------------. OpenCL support in Clang contains a set of attribute taken directly from the; specification as well as additional attributes. See also :doc:`AttributeReference`. nosvm; ^^^^^. Clang supports this attribute to comply to OpenCL v2.0 conformance, but it; does not have any effect on the IR. For more details reffer to the specification; `section 6.7.2; <https://www.khronos.org/registry/cl/specs/opencl-2.0-openclc.pdf#49>`_. opencl_unroll_hint; ^^^^^^^^^^^^^^^^^^. The implementation of this feature mirrors the unroll hint for C.; More details on the syntax can be found in the specification; `sec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:148857,avoid,avoid,148857,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['avoid'],['avoid']
Safety," the trap condition ``upper(tmp_ptr) - tmp_ptr < tmp_count`` to ``size <; tmp_count`` so if both ``size`` and ``tmp_count`` values are known at compile; time such that ``0 <= tmp_count <= size``, the optimizer can remove the check. ``ptr + size`` may still overflow if the ``__sized_by`` pointer is created from; code that doesn't enable ``-fbounds-safety``, which is undefined behavior. In the previous code example with the transformed ``alloc_buf()``, the upper; bound of ``tmp_ptr`` is derived from ``void *__sized_by_or_null(size)``, which; is the return type of ``malloc()``. Hence, the pointer arithmetic doesn't; overflow or ``tmp_ptr`` is null. Therefore, if ``nelems`` was given as a; compile-time constant, the compiler could remove the checks. Cast rules; ----------. ``-fbounds-safety`` does not enforce overall type safety and bounds invariants; can still be violated by incorrect casts in some cases. That said,; ``-fbounds-safety`` prevents type conversions that change bounds attributes in a; way to violate the bounds invariant of the destination's pointer annotation.; Type conversions that change bounds attributes may be allowed if it does not; violate the invariant of the destination or that can be verified at run time.; Here are some of the important cast rules. Two pointers that have different bounds annotations on their nested pointer; types are incompatible and cannot implicitly cast to each other. For example,; ``T *__single *__single`` cannot be converted to ``T *__bidi_indexable; *__single``. Such a conversion between incompatible nested bounds annotations; can be allowed using an explicit cast (e.g., C-style cast). Hereafter, the rules; only apply to the top pointer types. ``__unsafe_indexable`` cannot be converted; to any other safe pointer types (``__single``, ``__bidi_indexable``,; ``__counted_by``, etc) using a cast. The extension provides builtins to force; this conversion, ``__unsafe_forge_bidi_indexable(type, pointer, char_count)`` to; convert poin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:39082,safe,safety,39082,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['safe'],['safety']
Safety," the; execution known as 'safepoints' For most collectors, it is sufficient; to track at least one copy of each unique pointer value. However, for; a collector which wishes to relocate objects directly reachable from; running code, a higher standard is required. One additional challenge is that the compiler may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:2562,safe,safepoints,2562,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['safe'],['safepoints']
Safety," this is; only supported for the html format. .. option:: -output-dir=PATH. Specify a directory to write coverage reports into. If the directory does not; exist, it is created. When used in function view mode (i.e when -name or; -name-regex are used to select specific functions), the report is written to; PATH/functions.EXTENSION. When used in file view mode, a report for each file; is written to PATH/REL_PATH_TO_FILE.EXTENSION. .. option:: -Xdemangler=<TOOL>|<TOOL-OPTION>. Specify a symbol demangler. This can be used to make reports more; human-readable. This option can be specified multiple times to supply; arguments to the demangler (e.g `-Xdemangler c++filt -Xdemangler -n` for C++).; The demangler is expected to read a newline-separated list of symbols from; stdin and write a newline-separated list of the same length to stdout. .. option:: -num-threads=N, -j=N. Use N threads to write file reports (only applicable when -output-dir is; specified). When N=0, llvm-cov auto-detects an appropriate number of threads to; use. This is the default. .. option:: -compilation-dir=<dir>. Directory used as a base for relative coverage mapping paths. Only applicable; when binaries have been compiled with one of `-fcoverage-prefix-map`; `-fcoverage-compilation-dir`, or `-ffile-compilation-dir`. .. option:: -line-coverage-gt=<N>. Show code coverage only for functions with line coverage greater than the; given threshold. .. option:: -line-coverage-lt=<N>. Show code coverage only for functions with line coverage less than the given; threshold. .. option:: -region-coverage-gt=<N>. Show code coverage only for functions with region coverage greater than the; given threshold. .. option:: -region-coverage-lt=<N>. Show code coverage only for functions with region coverage less than the given; threshold. .. option:: -path-equivalence=<from>,<to>. Map the paths in the coverage data to local source file paths. This allows you; to generate the coverage data on one machine, and then use llvm-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst:11269,detect,detects,11269,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst,1,['detect'],['detects']
Safety," this, we'll start by adding a new global, ``FunctionProtos``, that; holds the most recent prototype for each function. We'll also add a convenience; method, ``getFunction()``, to replace calls to ``TheModule->getFunction()``.; Our convenience method searches ``TheModule`` for an existing function; declaration, falling back to generating a new declaration from FunctionProtos if; it doesn't find one. In ``CallExprAST::codegen()`` we just need to replace the; call to ``TheModule->getFunction()``. In ``FunctionAST::codegen()`` we need to; update the FunctionProtos map first, then call ``getFunction()``. With this; done, we can always obtain a function declaration in the current module for any; previously declared function. We also need to update HandleDefinition and HandleExtern:. .. code-block:: c++. static void HandleDefinition() {; if (auto FnAST = ParseDefinition()) {; if (auto *FnIR = FnAST->codegen()) {; fprintf(stderr, ""Read function definition:"");; FnIR->print(errs());; fprintf(stderr, ""\n"");; ExitOnErr(TheJIT->addModule(; ThreadSafeModule(std::move(TheModule), std::move(TheContext))));; InitializeModuleAndPassManager();; }; } else {; // Skip token for error recovery.; getNextToken();; }; }. static void HandleExtern() {; if (auto ProtoAST = ParseExtern()) {; if (auto *FnIR = ProtoAST->codegen()) {; fprintf(stderr, ""Read extern: "");; FnIR->print(errs());; fprintf(stderr, ""\n"");; FunctionProtos[ProtoAST->getName()] = std::move(ProtoAST);; }; } else {; // Skip token for error recovery.; getNextToken();; }; }. In HandleDefinition, we add two lines to transfer the newly defined function to; the JIT and open a new module. In HandleExtern, we just need to add one line to; add the prototype to FunctionProtos. .. warning::; Duplication of symbols in separate modules is not allowed since LLVM-9. That means you can not redefine function in your Kaleidoscope as its shown below. Just skip this part. The reason is that the newer OrcV2 JIT APIs are trying to stay very close t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:20347,recover,recovery,20347,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['recover'],['recovery']
Safety," thread holds its own caches (using the ELF TLS); or the shared model; where threads share a fixed size pool of caches. - the Quarantine: offers a way to delay the deallocation operations, preventing; blocks to be immediately available for reuse. Blocks held will be recycled; once certain size criteria are reached. This is essentially a delayed freelist; which can help mitigate some use-after-free situations. This feature is fairly; costly in terms of performance and memory footprint, is mostly controlled by; runtime options and is disabled by default. Allocations Header; ------------------; Every chunk of heap memory returned to an application by the allocator will be; preceded by a header. This has two purposes:. - being to store various information about the chunk, that can be leveraged to; ensure consistency of the heap operations;. - being able to detect potential corruption. For this purpose, the header is; checksummed and corruption of the header will be detected when said header is; accessed (note that if the corrupted header is not accessed, the corruption; will remain undetected). The following information is stored in the header:. - the class ID for that chunk, which identifies the region where the chunk; resides for Primary backed allocations, or 0 for Secondary backed allocations;. - the state of the chunk (available, allocated or quarantined);. - the allocation type (malloc, new, new[] or memalign), to detect potential; mismatches in the allocation APIs used;. - the size (Primary) or unused bytes amount (Secondary) for that chunk, which is; necessary for reallocation or sized-deallocation operations;. - the offset of the chunk, which is the distance in bytes from the beginning of; the returned chunk to the beginning of the backend allocation (the ""block"");. - the 16-bit checksum;. This header fits within 8 bytes on all platforms supported, and contributes to a; small overhead for each allocation. The checksum is computed using a CRC32 (made faster with",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:2899,detect,detected,2899,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['detect'],['detected']
Safety," threads. To avoid further problems within ROOT some redefinition of the; ***`gPad`*** pointer was done (that's the main reason for the; recompilation). When a thread creates a **`TCanvas`**, this object is; actually created in the main thread; this should be transparent to the; user. Actions on the canvas are controlled via a function, which returns; a pointer to either thread specific data (TSD) or the main thread; pointer. This mechanism works currently only for ***`gPad`***,; ***`gDirectory`***, ***`gFile`*** and will be implemented soon for other; global Objects as e.g. ***`gVirtualX`***. #### Canceling a TThread. Canceling of a thread is a rather dangerous action. In **`TThread`**; canceling is forbidden by default. The user can change this default by; calling `TThread::SetCancelOn()`. There are two cancellation modes:; deferred and asynchronous. #### Deferred. Set by `TThread::SetCancelDeferred()` (default): When the user knows; safe places in their code where a thread can be canceled without risk for; the rest of the system, they can define these points by invoking; **`TThread`**`::CancelPoint()`. Then, if a thread is canceled, the; cancellation is deferred up to the call of; **`TThread`**`::CancelPoint()` and then the thread is canceled safely.; There are some default cancel points for `pthreads` implementation, e.g.; any call of the `TCondition::Wait()`, **`TCondition`**`::TimedWait()`,; `TThread::Join()`. #### Asynchronous. Set by `TThread::SetCancelAsynchronous()`: If the user is sure that; their application is cancel safe, they could call:. ``` {.cpp}; TThread::SetCancelAsynchronous();; TThread::SetCancelOn();; // Now cancelation in any point is allowed.; ...; // Return to default; TThread::SetCancelOff();; TThread::SetCancelDeferred();; ```. To cancel a thread `TThread* th` call:. ``` {.cpp}; th->Kill();; ```. To cancel by thread name:. ``` {.cpp}; TThread::Kill(name);; ```. To cancel a thread by ID:. ``` {.cpp}; TThread::Kill(tid);; ```. To cancel a th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:11332,safe,safe,11332,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,2,"['risk', 'safe']","['risk', 'safe']"
Safety, to be allocated on stack so we check arguments for parameters of raw pointers and references to uncounted types. Here are some examples of situations that we warn about as they *might* be potentially unsafe. The logic is that either we're able to guarantee that an argument is safe or it's considered if not a bug then bug-prone. .. code-block:: cpp. RefCountable* provide_uncounted();; void consume(RefCountable*);. // In these cases we can't make sure callee won't directly or indirectly call `deref()` on the argument which could make it unsafe from such point until the end of the call. void foo1() {; consume(provide_uncounted()); // warn; }. void foo2() {; RefCountable* uncounted = provide_uncounted();; consume(uncounted); // warn; }. Although we are enforcing member variables to be ref-counted by `webkit.NoUncountedMemberChecker` any method of the same class still has unrestricted access to these. Since from a caller's perspective we can't guarantee a particular member won't get modified by callee (directly or indirectly) we don't consider values obtained from members safe. Note: It's likely this heuristic could be made more precise with fewer false positives - for example calls to free functions that don't have any parameter other than the pointer should be safe as the callee won't be able to tamper with the member unless it's a global variable. .. code-block:: cpp. struct Foo {; RefPtr<RefCountable> member;; void consume(RefCountable*) { /* ... */ }; void bugprone() {; consume(member.get()); // warn; }; };. The implementation of this rule is a heuristic - we define a whitelist of kinds of values that are considered safe to be passed as arguments. If we can't prove an argument is safe it's considered an error. Allowed kinds of arguments:. - values obtained from ref-counted objects (including temporaries as those survive the call too). .. code-block:: cpp. RefCountable* provide_uncounted();; void consume(RefCountable*);. void foo() {; RefPtr<RefCountable> rc = makeR,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:82315,safe,safe,82315,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['safe'],['safe']
Safety," to do so. In particular, every (non-PHI) machine instruction that; defines a register must be followed by a ``DBG_VALUE`` use of that def. If; an instruction does not define a register, but can be followed by a debug inst,; MIRDebugify inserts a ``DBG_VALUE`` that references a constant. Insertion of; ``DBG_VALUE``'s can be disabled by setting ``-debugify-level=locations``. To run MIRDebugify once, simply insert ``mir-debugify`` into your ``llc``; invocation, like:. .. code-block:: bash. # Before some other pass.; $ llc -run-pass=mir-debugify,other-pass ... # After some other pass.; $ llc -run-pass=other-pass,mir-debugify ... To run MIRDebugify before each pass in a pipeline, use; ``-debugify-and-strip-all-safe``. This can be combined with ``-start-before``; and ``-start-after``. For example:. .. code-block:: bash. $ llc -debugify-and-strip-all-safe -run-pass=... <other llc args>; $ llc -debugify-and-strip-all-safe -O1 <other llc args>. If you want to check it after each pass in a pipeline, use; ``-debugify-check-and-strip-all-safe``. This can also be combined with; ``-start-before`` and ``-start-after``. For example:. .. code-block:: bash. $ llc -debugify-check-and-strip-all-safe -run-pass=... <other llc args>; $ llc -debugify-check-and-strip-all-safe -O1 <other llc args>. To check all debug info from a test, use ``mir-check-debugify``, like:. .. code-block:: bash. $ llc -run-pass=mir-debugify,other-pass,mir-check-debugify. To strip out all debug info from a test, use ``mir-strip-debug``, like:. .. code-block:: bash. $ llc -run-pass=mir-debugify,other-pass,mir-strip-debug. It can be useful to combine ``mir-debugify``, ``mir-check-debugify`` and/or; ``mir-strip-debug`` to identify backend transformations which break in; the presence of debug info. For example, to run the AArch64 backend tests; with all normal passes ""sandwiched"" in between MIRDebugify and; MIRStripDebugify mutation passes, run:. .. code-block:: bash. $ llvm-lit test/CodeGen/AArch64 -Dllc=""llc -debug",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst:18366,safe,safe,18366,interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,1,['safe'],['safe']
Safety," to fallible functions can then be wrapped with a call to ``ExitOnErr``,; turning them into non-failing calls:. .. code-block:: c++. Error mayFail();; Expected<int> mayFail2();. void foo() {; ExitOnErr(mayFail());; int X = ExitOnErr(mayFail2());; }. On failure, the error's log message will be written to ``stderr``, optionally; preceded by a string ""banner"" that can be set by calling the setBanner method. A; mapping can also be supplied from ``Error`` values to exit codes using the; ``setExitCodeMapper`` method:. .. code-block:: c++. int main(int argc, char *argv[]) {; ExitOnErr.setBanner(std::string(argv[0]) + "" error:"");; ExitOnErr.setExitCodeMapper(; [](const Error &Err) {; if (Err.isA<BadFileFormat>()); return 2;; return 1;; });. Use ``ExitOnError`` in your tool code where possible as it can greatly improve; readability. .. _err_cantfail:. Using cantFail to simplify safe callsites; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Some functions may only fail for a subset of their inputs, so calls using known; safe inputs can be assumed to succeed. The cantFail functions encapsulate this by wrapping an assertion that their; argument is a success value and, in the case of Expected<T>, unwrapping the; T value:. .. code-block:: c++. Error onlyFailsForSomeXValues(int X);; Expected<int> onlyFailsForSomeXValues2(int X);. void foo() {; cantFail(onlyFailsForSomeXValues(KnownSafeValue));; int Y = cantFail(onlyFailsForSomeXValues2(KnownSafeValue));; ...; }. Like the ExitOnError utility, cantFail simplifies control flow. Their treatment; of error cases is very different however: Where ExitOnError is guaranteed to; terminate the program on an error input, cantFail simply asserts that the result; is success. In debug builds this will result in an assertion failure if an error; is encountered. In release builds the behavior of cantFail for failure values is; undefined. As such, care must be taken in the use of cantFail: clients must be; certain that a cantFail wrapped call really can",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:32195,safe,safe,32195,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['safe'],['safe']
Safety," to include headers in the right order. With modules, the headers of a particular module will be parsed in isolation, so the module may fail to build if there are missing includes. **Headers that vend multiple APIs at different times**; Some systems have headers that contain a number of different kinds of API definitions, only some of which are made available with a given include. For example, the header may vend ``size_t`` only when the macro ``__need_size_t`` is defined before that header is included, and also vend ``wchar_t`` only when the macro ``__need_wchar_t`` is defined. Such headers are often included many times in a single translation unit, and will have no include guards. There is no sane way to map this header to a submodule. One can either eliminate the header (e.g., by splitting it into separate headers, one per actual API) or simply ``exclude`` it in the module map. To detect and help address some of these problems, the ``clang-tools-extra`` repository contains a ``modularize`` tool that parses a set of given headers and attempts to detect these problems and produce a report. See the tool's in-source documentation for information on how to check your system or library headers. Future Directions; =================; Modules support is under active development, and there are many opportunities remaining to improve it. Here are a few ideas:. **Detect unused module imports**; Unlike with ``#include`` directives, it should be fairly simple to track whether a directly-imported module has ever been used. By doing so, Clang can emit ``unused import`` or ``unused #include`` diagnostics, including Fix-Its to remove the useless imports/includes. **Fix-Its for missing imports**; It's fairly common for one to make use of some API while writing code, only to get a compiler error about ""unknown type"" or ""no function named"" because the corresponding header has not been included. Clang can detect such cases and auto-import the required module, but should provide a Fix-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:55697,detect,detect,55697,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,2,['detect'],['detect']
Safety," to the cmake invocation. If using libc++abi, you may need to configure it to use libunwind; rather than libgcc_s by passing ``-DLIBCXXABI_USE_LLVM_UNWINDER=YES``; to ``cmake``. If libc++abi is configured to use some version of; libunwind, that library will be implicitly linked into binaries that; link to libc++abi. libgcc_s (GNU); ^^^^^^^^^^^^^^. libgcc_s has an integrated unwinder, and does not need an external unwind; library to be provided. libunwind (nongnu.org); ^^^^^^^^^^^^^^^^^^^^^^. This is another implementation of the libunwind specification.; See `libunwind (nongnu.org) <https://www.nongnu.org/libunwind>`_. libunwind (PathScale); ^^^^^^^^^^^^^^^^^^^^^. This is another implementation of the libunwind specification.; See `libunwind (pathscale) <https://github.com/pathscale/libunwind>`_. Sanitizer runtime; -----------------. The instrumentation added by Clang's sanitizers (``-fsanitize=...``) implicitly; makes calls to a runtime library, in order to maintain side state about the; execution of the program and to issue diagnostic messages when a problem is; detected. The only supported implementation of these runtimes is provided by LLVM's; compiler-rt, and the relevant portion of that library; (``libclang_rt.<sanitizer>.<arch>.a``); will be implicitly linked when linking with a ``-fsanitize=...`` flag. C standard library; ------------------. Clang supports a wide variety of; `C standard library <https://en.cppreference.com/w/c>`_; implementations. C++ ABI library; ---------------. The C++ ABI library provides an implementation of the library portion of; the Itanium C++ ABI, covering both the; `support functionality in the main Itanium C++ ABI document; <https://itanium-cxx-abi.github.io/cxx-abi/abi.html>`_ and; `Level II of the exception handling support; <https://itanium-cxx-abi.github.io/cxx-abi/abi-eh.html#cxx-abi>`_.; References to the functions and objects in this library are implicitly; generated by Clang when compiling C++ code. While it is possible to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Toolchain.rst:9857,detect,detected,9857,interpreter/llvm-project/clang/docs/Toolchain.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Toolchain.rst,1,['detect'],['detected']
Safety," to true is; the result of the modifier. An expression can be empty, in which case it is always true. See the example; at the top. Otherwise, it is a series of one or more numeric conditions,; separated by "","". If any condition matches, the expression matches. Each; numeric condition can take one of three forms. * number: A simple decimal number matches if the argument is the same as the; number. Example: ``""%plural{1:mouse|:mice}0""``; * range: A range in square brackets matches if the argument is within the; range. Then range is inclusive on both ends. Example:; ``""%plural{0:none|1:one|[2,5]:some|:many}0""``; * modulo: A modulo operator is followed by a number, and equals sign and; either a number or a range. The tests are the same as for plain numbers; and ranges, but the argument is taken modulo the number first. Example:; ``""%plural{%100=0:even hundred|%100=[1,50]:lower half|:everything else}1""``. The parser is very unforgiving. A syntax error, even whitespace, will abort,; as will a failure to match the argument against any expression. **""ordinal"" format**. Example:; ``""ambiguity in %ordinal0 argument""``; Class:; Integers; Description:; This is a formatter which represents the argument number as an ordinal: the; value ``1`` becomes ``1st``, ``3`` becomes ``3rd``, and so on. Values less; than ``1`` are not supported. This formatter is currently hard-coded to use; English ordinals. **""objcclass"" format**. Example:; ``""method %objcclass0 not found""``; Class:; ``DeclarationName``; Description:; This is a simple formatter that indicates the ``DeclarationName`` corresponds; to an Objective-C class method selector. As such, it prints the selector; with a leading ""``+``"". **""objcinstance"" format**. Example:; ``""method %objcinstance0 not found""``; Class:; ``DeclarationName``; Description:; This is a simple formatter that indicates the ``DeclarationName`` corresponds; to an Objective-C instance method selector. As such, it prints the selector; with a leading ""``-``"". **""q",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:13285,abort,abort,13285,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['abort'],['abort']
Safety," to; metadata-symbolic-based regions during scanReachableSymbols() whenever a region; turns out to be reachable. This requires no work on checker side, but it sounds; performance-heavy. Approach (3): We could let checkers maintain the set of active metadata symbols; in the program state (ideally somewhere in the Store, which sounds weird but; causes the smallest amount of layering violations), so that the core knew what; to escape. This puts a stress on the checkers, but with a smart data map it; wouldn't be a problem. Approach (4): We could allow checkers to trigger pointer escapes in arbitrary; moments. If we allow doing this within ``checkPointerEscape`` callback itself, we; would be able to express facts like ""when this region escapes, that metadata; symbol attached to it should also escape"". This sounds like an ultimate freedom,; with maximum stress on the checkers - still not too much stress when we have; smart data maps. I'm personally liking the approach (2) - it should be possible to avoid; performance overhead, and clarity seems nice. **Gabor:**. At this point, I am a bit wondering about two questions. * When should something belong to a checker and when should something belong to the engine?; Sometimes we model library aspects in the engine and model language constructs in checkers. * What is the checker programming model that we are aiming for? Maximum freedom or more easy checker development?. I think if we aim for maximum freedom, we do not need to worry about the; potential stress on checkers, and we can introduce abstractions to mitigate that; later on.; If we want to simplify the API, then maybe it makes more sense to move language; construct modeling to the engine when the checker API is not sufficient instead; of complicating the API. Right now I have no preference or objections between the alternatives but there; are some random thoughts:. * Maybe it would be great to have a guideline how to evolve the analyzer and; follow it, so it can help us to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst:4579,avoid,avoid,4579,interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,1,['avoid'],['avoid']
Safety," tool; <ClangFormat>` with the goal of automatically reformatting C++ sources files; according to configurable style guides. To do so, clang-format uses Clang's; ``Lexer`` to transform an input file into a token stream and then changes all; the whitespace around those tokens. The goal is for clang-format to serve both; as a user tool (ideally with powerful IDE integrations) and as part of other; refactoring tools, e.g. to do a reformatting of all the lines changed during a; renaming. Extra Clang Tools; =================. As various categories of Clang Tools are added to the extra repository,; they'll be tracked here. The focus of this documentation is on the scope; and features of the tools for other tool developers; each tool should; provide its own user-focused documentation. ``clang-tidy``; --------------. `clang-tidy <https://clang.llvm.org/extra/clang-tidy/>`_ is a clang-based C++; linter tool. It provides an extensible framework for building compiler-based; static analyses detecting and fixing bug-prone patterns, performance,; portability and maintainability issues. Ideas for new Tools; ===================. * C++ cast conversion tool. Will convert C-style casts (``(type) value``) to; appropriate C++ cast (``static_cast``, ``const_cast`` or; ``reinterpret_cast``).; * Non-member ``begin()`` and ``end()`` conversion tool. Will convert; ``foo.begin()`` into ``begin(foo)`` and similarly for ``end()``, where; ``foo`` is a standard container. We could also detect similar patterns for; arrays.; * ``tr1`` removal tool. Will migrate source code from using TR1 library; features to C++11 library. For example:. .. code-block:: c++. #include <tr1/unordered_map>; int main(); {; std::tr1::unordered_map <int, int> ma;; std::cout << ma.size () << std::endl;; return 0;; }. should be rewritten to:. .. code-block:: c++. #include <unordered_map>; int main(); {; std::unordered_map <int, int> ma;; std::cout << ma.size () << std::endl;; return 0;; }. * A tool to remove ``auto``. Will ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangTools.rst:4317,detect,detecting,4317,interpreter/llvm-project/clang/docs/ClangTools.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangTools.rst,1,['detect'],['detecting']
Safety," transformations; are subjected to a caching mechanism due to the sometimes very large; memory requirements of logical graph expansion. The total number of; physical instances of volumes triggers the caching mechanism and the; cache manager is a client of TGeoManager. The manager class also; controls the drawing/checking package (TGeoPainter client). This; is linked with %ROOT graphical libraries loaded on demand in order to; control visualization actions. \anchor GP02; ## Navigation and Tracking. Tracking is the feature allowing the transport of a given particle; knowing its kinematics. A state is determined by any combination of the; position \f$\vec{r}\f$ and direction \f$\vec{n}\f$ with respect to the world; reference frame. The direction \f$\vec{n}\f$ must be a unit vector having as; components the director cosines. The full classification of a given; state will provide the following information: the deepest physical node; containing the position vector, the distance to the closest boundary; along the direction vector, the next physical node after propagating the; current point with this distance and the safety distance to the nearest; boundary. This information allows the propagation of particles inside a; detector geometry by taking into account both geometrical and physical; constraints. We will hereby describe the user interface of `TGeo` to access; tracking functionality. This allows either developing a tracker for; simple navigation within a given geometry, either interfacing to an; external tracking engine such as GEANT. Note that the abstract interface; for external trackers can be found in `$ROOTSYS/vmc` folder and it can; be used to run GEANT3, GEANT4 and FLUKA-based simulations (\*) by using; directly a geometry described with %ROOT. The interface methods related to tracking are incorporated into; TGeoManager class and implemented in the navigator class; TGeoNavigator. In order to be able to start tracking, one has to; define the initial state provid",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:61883,safe,safety,61883,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['safe'],['safety']
Safety," used on that analysis path. .. code-block:: c. // Marking sanitized variables safe.; // No vulnerability anymore, no warning. // User csa_mark_sanitize function is for the analyzer only; #ifdef __clang_analyzer__; void csa_mark_sanitized(const void *);; #endif. int main(int argc, char** argv) {; char cmd[2048] = ""/bin/cat "";; char filename[1024];; printf(""Filename:"");; scanf ("" %1023[^\n]"", filename);; if (access(filename,F_OK)){// Verifying user input; printf(""File does not exist\n"");; return -1;; }; #ifdef __clang_analyzer__; csa_mark_sanitized(filename); // Indicating to CSA that filename variable is safe to be used after this point; #endif; strcat(cmd, filename);; system(cmd); // No warning; }. Similarly to the previous example, you need to; define a `Filter` function in a `YAML` configuration file; and add the `csa_mark_sanitized` function. .. code-block:: YAML. Filters:; - Name: csa_mark_sanitized; Args: [0]. Then calling `csa_mark_sanitized(X)` will tell the analyzer that `X` is safe to; be used after this point, because its contents are verified. It is the; responsibility of the programmer to ensure that this verification was indeed; correct. Please note that `csa_mark_sanitized` function is only declared and; used during Clang Static Analysis and skipped in (production) builds. Further examples of injection vulnerabilities this checker can find. .. code-block:: c. void test() {; char x = getchar(); // 'x' marked as tainted; system(&x); // warn: untrusted data is passed to a system call; }. // note: compiler internally checks if the second param to; // sprintf is a string literal or not.; // Use -Wno-format-security to suppress compiler warning.; void test() {; char s[10], buf[10];; fscanf(stdin, ""%s"", s); // 's' marked as tainted. sprintf(buf, s); // warn: untrusted data used as a format string; }. void test() {; size_t ts;; scanf(""%zd"", &ts); // 'ts' marked as tainted; int *p = (int *)malloc(ts * sizeof(int));; // warn: untrusted data used as buffer size;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:69898,safe,safe,69898,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['safe'],['safe']
Safety," using a new just-in-time compilation engine called OrcJIT, a development based on MCJIT. It enables interpretation of inline assembly and exceptions; it will hopefully in the near future also support interpreting thread local storage (but doesn't at the moment). Thanks to the new JIT, cling also comes with debug symbols for interpreted code; you can enable them with "".debug"". #### Function evaluation. Function calls through TMethodCall etc have been accelerated. #### llvm / clang. llvm / clang were updated to r227800. This includes everything from the clang 3.6 release. ### Dictionary Generation. Detect usage of #pragma once for inlined headers. Turn on verbosity of genreflex if the VERBOSE environment variable is defined. Optimise forward declarations in rootmap files in order to make their interpretation faster. Propagate attributes specified in xml selection files to selected classes even when selected through typedefs. Optimise selection procedure caching selected declarations in the selection rules, therewith avoiding to query the AST twice. Include in the PCH all the STL and C headers to guarantee portability of binaries from SLC6 to CC7. ## I/O Libraries. ### I/O New functionalities. - Support for forward_list and I/O of unordered stl containers.; - Support for std::complex. ### I/O Behavior change. - The I/O now properly skip the content of base class onfile that have been removed from the in-memory class layout. - The scheduling the I/O customization rules within a StreamerInfo is now as soon as possible, i.e. after all sources have been read. One significant consequence is that now when an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:8308,avoid,avoiding,8308,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['avoid'],['avoiding']
Safety," value of a try-acquire; function. .. code-block:: c++. Mutex mu;; int a GUARDED_BY(mu);. void foo() {; bool success = mu.TryLock();; a = 0; // Warning, mu is not locked.; if (success) {; a = 0; // Ok.; mu.Unlock();; } else {; a = 0; // Warning, mu is not locked.; }; }. ASSERT_CAPABILITY(...) and ASSERT_SHARED_CAPABILITY(...); --------------------------------------------------------. *Previously:* ``ASSERT_EXCLUSIVE_LOCK``, ``ASSERT_SHARED_LOCK``. These are attributes on a function or method which asserts the calling thread; already holds the given capability, for example by performing a run-time test; and terminating if the capability is not held. Presence of this annotation; causes the analysis to assume the capability is held after calls to the; annotated function. See :ref:`mutexheader`, below, for example uses. GUARDED_VAR and PT_GUARDED_VAR; ------------------------------. Use of these attributes has been deprecated. Warning flags; -------------. * ``-Wthread-safety``: Umbrella flag which turns on the following:. + ``-Wthread-safety-attributes``: Semantic checks for thread safety attributes.; + ``-Wthread-safety-analysis``: The core analysis.; + ``-Wthread-safety-precise``: Requires that mutex expressions match precisely.; This warning can be disabled for code which has a lot of aliases.; + ``-Wthread-safety-reference``: Checks when guarded members are passed by reference. :ref:`negative` are an experimental feature, which are enabled with:. * ``-Wthread-safety-negative``: Negative capabilities. Off by default. When new features and checks are added to the analysis, they can often introduce; additional warnings. Those warnings are initially released as *beta* warnings; for a period of time, after which they are migrated into the standard analysis. * ``-Wthread-safety-beta``: New features. Off by default. .. _negative:. Negative Capabilities; =====================. Thread Safety Analysis is designed to prevent both race conditions and; deadlock. The GUARDED_BY ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:15784,safe,safety,15784,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['safe'],['safety']
Safety," values that are considered safe to be passed as arguments. If we can't prove an argument is safe it's considered an error. Allowed kinds of arguments:. - values obtained from ref-counted objects (including temporaries as those survive the call too). .. code-block:: cpp. RefCountable* provide_uncounted();; void consume(RefCountable*);. void foo() {; RefPtr<RefCountable> rc = makeRef(provide_uncounted());; consume(rc.get()); // ok; consume(makeRef(provide_uncounted()).get()); // ok; }. - forwarding uncounted arguments from caller to callee. .. code-block:: cpp. void foo(RefCountable& a) {; bar(a); // ok; }. Caller of ``foo()`` is responsible for ``a``'s lifetime. - ``this`` pointer. .. code-block:: cpp. void Foo::foo() {; baz(this); // ok; }. Caller of ``foo()`` is responsible for keeping the memory pointed to by ``this`` pointer safe. - constants. .. code-block:: cpp. foo(nullptr, NULL, 0); // ok. We also define a set of safe transformations which if passed a safe value as an input provide (usually it's the return value) a safe value (or an object that provides safe values). This is also a heuristic. - constructors of ref-counted types (including factory methods); - getters of ref-counted types; - member overloaded operators; - casts; - unary operators like ``&`` or ``*``. alpha.webkit.UncountedLocalVarsChecker; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; The goal of this rule is to make sure that any uncounted local variable is backed by a ref-counted object with lifetime that is strictly larger than the scope of the uncounted local variable. To be on the safe side we require the scope of an uncounted variable to be embedded in the scope of ref-counted object that backs it. These are examples of cases that we consider safe:. .. code-block:: cpp. void foo1() {; RefPtr<RefCountable> counted;; // The scope of uncounted is EMBEDDED in the scope of counted.; {; RefCountable* uncounted = counted.get(); // ok; }; }. void foo2(RefPtr<RefCountable> counted_param) {; RefCountable",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:83782,safe,safe,83782,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,4,['safe'],['safe']
Safety," var); -fprofile-instr-generate=<file_name_pattern>; Generate instrumented code to collect execution counts into the file whose name pattern is specified as the argument; (overridden by LLVM_PROFILE_FILE env var); -fprofile-instr-generate; Generate instrumented code to collect execution counts into default.profraw file; (overridden by '=' form of option or LLVM_PROFILE_FILE env var); -fprofile-instr-use=<value>; Use instrumentation data for coverage testing or profile-guided optimization; -fprofile-use=<value>; Use instrumentation data for profile-guided optimization; -fprofile-remapping-file=<file>; Use the remappings described in <file> to match the profile data against names in the program; -fprofile-list=<file>; Filename defining the list of functions/files to instrument; -fsanitize-address-field-padding=<value>; Level of field padding for AddressSanitizer; -fsanitize-address-globals-dead-stripping; Enable linker dead stripping of globals in AddressSanitizer; -fsanitize-address-poison-custom-array-cookie; Enable poisoning array cookies when using custom operator new[] in AddressSanitizer; -fsanitize-address-use-after-return=<mode>; Select the mode of detecting stack use-after-return in AddressSanitizer: never | runtime (default) | always; -fsanitize-address-use-after-scope; Enable use-after-scope detection in AddressSanitizer; -fsanitize-address-use-odr-indicator; Enable ODR indicator globals to avoid false ODR violation reports in partially sanitized programs at the cost of an increase in binary size; -fsanitize-ignorelist=<value>; Path to ignorelist file for sanitizers; -fsanitize-cfi-cross-dso; Enable control flow integrity (CFI) checks for cross-DSO calls.; -fsanitize-cfi-icall-generalize-pointers; Generalize pointers in CFI indirect call type signature checks; -fsanitize-coverage=<value>; Specify the type of coverage instrumentation for Sanitizers; -fsanitize-hwaddress-abi=<value>; Select the HWAddressSanitizer ABI to target (interceptor or platform, defaul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:183276,detect,detecting,183276,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,3,"['avoid', 'detect']","['avoid', 'detecting', 'detection']"
Safety," version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by default and may be enabled by setting:. ```; ROOT::TIOFeatures features;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:8614,recover,recover,8614,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['recover'],['recover']
Safety," when; values are deleted or copied, however these aren't sufficient. There are many; other ways that LLVM IR can be modified which could be relevant to; ``AliasAnalysis`` implementations which can not be expressed. The ``AliasAnalysisDebugger`` utility seems to suggest that ``AliasAnalysis``; implementations can expect that they will be informed of any relevant ``Value``; before it appears in an alias query. However, popular clients such as ``GVN``; don't support this, and are known to trigger errors when run with the; ``AliasAnalysisDebugger``. The ``AliasSetTracker`` class (which is used by ``LICM``) makes a; non-deterministic number of alias queries. This can cause debugging techniques; involving pausing execution after a predetermined number of queries to be; unreliable. Many alias queries can be reformulated in terms of other alias queries. When; multiple ``AliasAnalysis`` queries are chained together, it would make sense to; start those queries from the beginning of the chain, with care taken to avoid; infinite looping, however currently an implementation which wants to do this can; only start such queries from itself. Using alias analysis results; ============================. There are several different ways to use alias analysis results. In order of; preference, these are:. Using the ``MemoryDependenceAnalysis`` Pass; -------------------------------------------. The ``memdep`` pass uses alias analysis to provide high-level dependence; information about memory-using instructions. This will tell you which store; feeds into a load, for example. It uses caching and other techniques to be; efficient, and is used by Dead Store Elimination, GVN, and memcpy optimizations. .. _AliasSetTracker:. Using the ``AliasSetTracker`` class; -----------------------------------. Many transformations need information about alias **sets** that are active in; some scope, rather than information about pairwise aliasing. The; `AliasSetTracker <https://llvm.org/doxygen/classllvm_1_1A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:19132,avoid,avoid,19132,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['avoid'],['avoid']
Safety," with a given shape in one step; TGeoVolume *vol = gGeoManager->MakeBox(""VNAME"",ptrMed,dx,dy,dz);; TGeoVolume *vol = gGeoManager->MakeTubs(""VNAME"",ptrMed,rmin,rmax,; dz,phi1,phi2);. // See class TGeoManager for the rest of shapes.; // Making a volume with a given shape with a unique prototype; TGeoVolume *vol = gGeoManager->Volume(""VNAME"",""XXXX"",nmed,upar,; npar);. // Where XXXX stands for the first 4 letters of the specific shape; // classes, nmed is the medium number, upar is an Double_t * array; // of the shape parameters and npar is the number of parameters.; // This prototype allows (npar = 0) to define volumes with shape; // defined only at positioning time (volumes defined in this way; // need to be positioned using TGeoManager::Node() method); ~~~. \anchor GP01bc; #### Positioned Volumes (Nodes). Geometrical modeling is a difficult task when the number of different; geometrical objects is 106-108. This is more or less the case for; detector geometries of complex experiments, where a ‘flat' CSG model; description cannot scale with the current CPU performances. This is the; reason why models like GEANT [1] introduced an additional dimension; (depth) in order to reduce the complexity of the problem. This concept; is also preserved by the ROOT modeller and introduces a pure geometrical; constraint between objects (volumes in our case) - containment. This; means in fact that any positioned volume has to be contained by another.; Now what means contained and positioned?. - We will say that a volume `contains` a point if this is inside the; shape associated to the volume. For instance, a volume having a box; shape will contain all points `P=(X,Y,Z)` verifying the conditions:; `Abs(Pi)dXi`. The points on the shape boundaries are considered as; inside the volume. The volume contains a daughter if it contains all; the points contained by the daughter.; - The definition of containment works of course only with points; defined in the local coordinate system of the consid",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:26160,detect,detector,26160,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['detect'],['detector']
Safety," with a struct; layout. To handle this, a wide pointer is described as a record type in the; debug info. The type name has a special name prefix (e.g.,; ``__bounds_safety$bidi_indexable``) which can be recognized by a debug info; consumer to provide support that goes beyond showing the internal structure of; the wide pointer. There are no DWARF extensions needed to support wide pointers.; In our implementation, LLDB recognizes wide pointer types by name and; reconstructs them as wide pointer Clang AST types for use in the expression; evaluator. External bounds annotations; ---------------------------. Similar to internal bounds annotations, external bound annotations are described; as a typedef to their underlying pointer type in the debug info, and the bounds; are encoded as strings in the typedef’s name (e.g.,; ``__bounds_safety$counted_by:N``). Recognizing ``-fbounds-safety`` traps; -------------------------------------. Clang emits debug info for ``-fbounds-safety`` traps as inlined functions, where; the function name encodes the error message. LLDB implements a frame recognizer; to surface a human-readable error cause to the end user. A debug info consumer; that is unaware of this sees an inlined function whose name encodes an error; message (e.g., : ``__bounds_safety$Bounds check failed``). Expression Parsing; ------------------. In our implementation, LLDB’s expression evaluator does not enable the; ``-fbounds-safety`` language option because it’s currently unable to fully; reconstruct the pointers with external bounds annotations, and also because the; evaluator operates in C++ mode, utilizing C++ reference types, while; ``-fbounds-safety`` does not currently support C++. This means LLDB’s expression; evaluator can only evaluate a subset of the ``-fbounds-safety`` language model.; Specifically, it’s capable of evaluating the wide pointers that already exist in; the source code. All other expressions are evaluated according to C/C++; semantics. C++ support; ==",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst:9399,safe,safety,9399,interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,1,['safe'],['safety']
Safety," with their ``++`` and ``--`` operators replaced with fallible; ``Error inc()`` and ``Error dec()`` functions. E.g.:. .. code-block:: c++. class FallibleChildIterator {; public:; FallibleChildIterator(Archive &A, unsigned ChildIdx);; Archive::Child &operator*();; friend bool operator==(const ArchiveIterator &LHS,; const ArchiveIterator &RHS);. // operator++/operator-- replaced with fallible increment / decrement:; Error inc() {; if (!A.childValid(ChildIdx + 1)); return make_error<BadArchiveMember>(...);; ++ChildIdx;; return Error::success();; }. Error dec() { ... }; };. Instances of this kind of fallible iterator interface are then wrapped with the; fallible_iterator utility which provides ``operator++`` and ``operator--``,; returning any errors via a reference passed in to the wrapper at construction; time. The fallible_iterator wrapper takes care of (a) jumping to the end of the; range on error, and (b) marking the error as checked whenever an iterator is; compared to ``end`` and found to be inequal (in particular: this marks the; error as checked throughout the body of a range-based for loop), enabling early; exit from the loop without redundant error checking. Instances of the fallible iterator interface (e.g. FallibleChildIterator above); are wrapped using the ``make_fallible_itr`` and ``make_fallible_end``; functions. E.g.:. .. code-block:: c++. class Archive {; public:; using child_iterator = fallible_iterator<FallibleChildIterator>;. child_iterator child_begin(Error &Err) {; return make_fallible_itr(FallibleChildIterator(*this, 0), Err);; }. child_iterator child_end() {; return make_fallible_end(FallibleChildIterator(*this, size()));; }. iterator_range<child_iterator> children(Error &Err) {; return make_range(child_begin(Err), child_end());; }; };. Using the fallible_iterator utility allows for both natural construction of; fallible iterators (using failing ``inc`` and ``dec`` operations) and; relatively natural use of c++ iterator/loop idioms. .. _function_a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:38861,redund,redundant,38861,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['redund'],['redundant']
Safety," without memory safe interfaces:; ```c++; std::unique_ptr<RooArgSet> params{pdf.getParameters(nullptr)};; ```. Also some `virtual` RooFit functions like [RooAbsReal::createIntegral()](https://root.cern.ch/doc/master/classRooAbsReal.html#aff4be07dd6a131721daeeccf6359aea9); are returning a different type conditional on `ROOFIT_MEMORY_SAFE_INTERFACES`.; If you are overriding such a function, you need to use the `RooFit::OwningPtr`; return type, which is an alias for `std::unique_ptr` in memory-safe mode or an; alias for a raw pointer otherwise.; ```c++; RooFit::OwningPtr<RooAbsReal> RooAbsReal::createIntegral(...) const override; {; std::unique_ptr<RooAbsReal> integral;; // Prepare a std::unique_ptr as the return value; ...; // Use the RooFit::makeOwningPtr<T>() helper to translate the; // std::unique_ptr to the actual return type (either std::unique_ptr<T> or T*).; return RooFit::makeOwningPtr<RooAbsReal>(std::move(integral));; }; ```. The biggest application of the memory-safe interfaces is to spot memory leaks; in RooFit-based frameworks. If you make sure that your framework compiles both; with and without `ROOFIT_MEMORY_SAFE_INTERFACES`, you can get rid of all memory; leaks related to RooFit user error! After making the necessary changes, you can; remove the marco definition again to keep backwards compatibility. Note that the memory-safe interfaces might become the default at some point, so; doing this **backwards-compatible migration early** is strongly encouraged and; appreciated. ### Removal of some memory-unsafe interfaces. * The final `bool takeOwnership` parameter of the **RooAddition** and; **RooStats::HistFactory::PiecewiseInterpolation** constructors was removed.; This is to avoid situations where ownership is not clear to the compiler.; Now, ownership of the input RooAbsArgs is never passed in the constructor. If; you want the pass input ownership to the created object, please use; `addOwnedComponents`. If you want to be extra safe, make sure the inputs a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:10082,safe,safe,10082,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['safe'],['safe']
Safety," x O(10000) times new/delete):. ``` {.cpp}; TObjArray a(10000);; while (TEvent *ev = (TEvent *)next()) { // O(100000); for (int i = 0; i < ev->Ntracks; i++) { // O(10000); a[i] = new TTrack(x,y,z,...);; ...; }; ...; a.Delete();; }; ```. You better use a **`TClonesArray`** which reduces the number of; new/delete calls to only O(10000):. ``` {.cpp}; TClonesArray a(""TTrack"", 10000);; while (TEvent *ev = (TEvent *)next()) { // O(100000); for (int i = 0; i < ev->Ntracks; i++) { // O(10000); TTrack *track = (Track*)a.ConstructedAt(i);; track->Set(x,y,z,...);; ...; }; ...; a.Clear(); // Or Clear(""C"") if the track objects must be returned (via Track::Clear) to a default state.; }; ```. Considering that a pair of new/delete calls on average cost about 70 ms,; O(109) new/deletes will save about 19 hours. For the other collections,; see the class reference guide on the web and the test program; `$ROOTSYS/test/tcollex.cxx.`. ## Template Containers and STL. Some people dislike polymorphic containers because they are not truly; ""type safe"". In the end, the compiler leaves it the user to ensure that; the types are correct. This only leaves the other alternative: creating; a new class each time a new (container organization) / (contained; object) combination is needed. To say the least this could be very; tedious. Most people faced with this choice would, for each type of; container:. Define the class leaving a dummy name for the contained object type.; When a particular container was needed, copy the code and then do a; global search and replace for the contained class. C++ has a built in; template scheme that effectively does just this. For example:. ``` {.cpp}; template<class T>; class ArrayContainer {; private:; T *member[10];; ...; };; ```. This is an array container with a 10-element array of pointers to T, it; could hold up to 10 T objects. This array is flawed because it is static; and hard-coded, it should be dynamic. However, the important point is; that the template stat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/CollectionClasses.md:18050,safe,safe,18050,documentation/users-guide/CollectionClasses.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/CollectionClasses.md,1,['safe'],['safe']
Safety," x30, x20, [sp], #16; ret. [...]; __hwasan_check_x0_2_short_v2:; sbfx x16, x0, #4, #52 // shadow offset; ldrb w16, [x20, x16] // load shadow tag; cmp x16, x0, lsr #56 // extract address tag, compare with shadow tag; b.ne .Ltmp0 // jump to short tag handler on mismatch; .Ltmp1:; ret; .Ltmp0:; cmp w16, #15 // is this a short tag?; b.hi .Ltmp2 // if not, error; and x17, x0, #0xf // find the address's position in the short granule; add x17, x17, #3 // adjust to the position of the last byte loaded; cmp w16, w17 // check that position is in bounds; b.ls .Ltmp2 // if not, error; orr x16, x0, #0xf // compute address of last byte of granule; ldrb w16, [x16] // load tag from it; cmp x16, x0, lsr #56 // compare with pointer tag; b.eq .Ltmp1 // if matches, continue; .Ltmp2:; stp x0, x1, [sp, #-256]! // save original x0, x1 on stack (they will be overwritten); stp x29, x30, [sp, #232] // create frame record; mov x1, #2 // set x1 to a constant indicating the type of failure; adrp x16, :got:__hwasan_tag_mismatch_v2 // call runtime function to save remaining registers and report error; ldr x16, [x16, :got_lo12:__hwasan_tag_mismatch_v2] // (load address from GOT to avoid potential register clobbers in delay load handler); br x16. Heap; ----. Tagging the heap memory/pointers is done by `malloc`.; This can be based on any malloc that forces all objects to be TG-aligned.; `free` tags the memory with a different tag. Stack; -----. Stack frames are instrumented by aligning all non-promotable allocas; by `TG` and tagging stack memory in function prologue and epilogue. Tags for different allocas in one function are **not** generated; independently; doing that in a function with `M` allocas would require; maintaining `M` live stack pointers, significantly increasing register; pressure. Instead we generate a single base tag value in the prologue,; and build the tag for alloca number `M` as `ReTag(BaseTag, M)`, where; ReTag can be as simple as exclusive-or with constant `M`. Stack instrument",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:5286,avoid,avoid,5286,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,1,['avoid'],['avoid']
Safety, | |x| |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | **safe | | | | | | | | |; | points** | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *in | |v| | | | |x| | |x| | |x| | |x| | |x| |; | calls* | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *before | |v| | | | | | | |x| | |x| |; | calls* | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *for | NO | | | | | | **N** | **N** |; | loops* | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *before | |v| | | | | | | |x| | |x| |; | escape* | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | emit code | NO | | | | | | **N** | **N** |; | at safe | | | | | | | | |; | points | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | **output** | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *assembly* | |v| | | | |x| | |x| | |x| | |x| | |x| |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *JIT* | NO | | | **?** | **?** | **?** | **?** | **?** |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *obj* | NO | | | **?** | **?** | **?** | **?** | **?** |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | live | NO | | | **?** | **?** | **?** | **?** | **?** |; | analysis | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | register | NO | | | **?** | **?** | **?** | **?** | **?** ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:28533,safe,safe,28533,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['safe'],['safe']
Safety," |; +=======+===================================================+; | 0 | Set if the statepoint is a GC transition, cleared |; | | otherwise. |; +-------+---------------------------------------------------+; | 1-63 | Reserved for future use; must be cleared. |; +-------+---------------------------------------------------+. The 'call parameters' arguments are simply the arguments which need to; be passed to the call target. They will be lowered according to the; specified calling convention and otherwise handled like a normal call; instruction. The number of arguments must exactly match what is; specified in '# call args'. The types must match the signature of; 'target'. The 'call parameter' attributes must be followed by two 'i64 0' constants.; These were originally the length prefixes for 'gc transition parameter' and; 'deopt parameter' arguments, but the role of these parameter sets have been; entirely replaced with the corresponding operand bundles. In a future; revision, these now redundant arguments will be removed. Semantics:; """""""""""""""""""". A statepoint is assumed to read and write all memory. As a result,; memory operations can not be reordered past a statepoint. It is; illegal to mark a statepoint as being either 'readonly' or 'readnone'. Note that legal IR can not perform any memory operation on a 'gc; pointer' argument of the statepoint in a location statically reachable; from the statepoint. Instead, the explicitly relocated value (from a; ``gc.relocate``) must be used. '``llvm.experimental.gc.result``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare type; @llvm.experimental.gc.result(token %statepoint_token). Overview:; """""""""""""""""". ``gc.result`` extracts the result of the original call instruction; which was replaced by the ``gc.statepoint``. The ``gc.result``; intrinsic is actually a family of three intrinsics due to an; implementation limitation. Other than the type of the return value,; the semantics are the same. Ope",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:503184,redund,redundant,503184,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['redund'],['redundant']
Safety,"""""""""""""""""""""""""""""""""""""""""""""""""""; Warn on uses of inferior random number generating functions (only if arc4random function is available):; ``drand48, erand48, jrand48, lcong48, lrand48, mrand48, nrand48, random, rand_r``. .. code-block:: c. void test() {; random(); // warn; }. .. _security-insecureAPI-strcpy:. security.insecureAPI.strcpy (C); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warn on uses of the ``strcpy`` and ``strcat`` functions. .. code-block:: c. void test() {; char x[4];; char *y = ""abcd"";. strcpy(x, y); // warn; }. .. _security-insecureAPI-vfork:. security.insecureAPI.vfork (C); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warn on uses of the 'vfork' function. .. code-block:: c. void test() {; vfork(); // warn; }. .. _security-insecureAPI-DeprecatedOrUnsafeBufferHandling:. security.insecureAPI.DeprecatedOrUnsafeBufferHandling (C); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warn on occurrences of unsafe or deprecated buffer handling functions, which now have a secure variant: ``sprintf, fprintf, vsprintf, scanf, wscanf, fscanf, fwscanf, vscanf, vwscanf, vfscanf, vfwscanf, sscanf, swscanf, vsscanf, vswscanf, swprintf, snprintf, vswprintf, vsnprintf, memcpy, memmove, strncpy, strncat, memset``. .. code-block:: c. void test() {; char buf [5];; strncpy(buf, ""a"", 1); // warn; }. .. _unix-checkers:. unix; ^^^^; POSIX/Unix checkers. .. _unix-API:. unix.API (C); """"""""""""""""""""""""; Check calls to various UNIX/Posix functions: ``open, pthread_once, calloc, malloc, realloc, alloca``. .. literalinclude:: checkers/unix_api_example.c; :language: c. .. _unix-Errno:. unix.Errno (C); """""""""""""""""""""""""""". Check for improper use of ``errno``.; This checker implements partially CERT rule; `ERR30-C. Set errno to zero before calling a library function known to set errno,; and check errno only after the function returns a value indicating failure; <https://wiki.sei.cmu.edu/confluence/pages/viewpage.action?pageId=87152351>`_.; The checker can find the first read of ``errno`` after successful standard",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:25253,unsafe,unsafe,25253,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['unsafe'],['unsafe']
Safety,""""""""""""""""""". The integer operand is the loop trip count of the hardware-loop, and thus; not e.g. the loop back-edge taken count. Semantics:; """""""""""""""""""". The '``llvm.start.loop.iterations.*``' intrinsics do not perform any arithmetic; on their operand. It's a hint to the backend that can use this to set up the; hardware-loop count with a target specific instruction, usually a move of this; value to a special register or a hardware-loop instruction. '``llvm.test.set.loop.iterations.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. ::. declare i1 @llvm.test.set.loop.iterations.i32(i32); declare i1 @llvm.test.set.loop.iterations.i64(i64). Overview:; """""""""""""""""". The '``llvm.test.set.loop.iterations.*``' intrinsics are used to specify the; the loop trip count, and also test that the given count is not zero, allowing; it to control entry to a while-loop. They are placed in the loop preheader's; predecessor basic block, and are marked as ``IntrNoDuplicate`` to avoid; optimizers duplicating these instructions. Arguments:; """""""""""""""""""". The integer operand is the loop trip count of the hardware-loop, and thus; not e.g. the loop back-edge taken count. Semantics:; """""""""""""""""""". The '``llvm.test.set.loop.iterations.*``' intrinsics do not perform any; arithmetic on their operand. It's a hint to the backend that can use this to; set up the hardware-loop count with a target specific instruction, usually a; move of this value to a special register or a hardware-loop instruction.; The result is the conditional value of whether the given count is not zero. '``llvm.test.start.loop.iterations.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. ::. declare {i32, i1} @llvm.test.start.loop.iterations.i32(i32); declare {i64, i1} @llvm.test.start.loop.iterations.i64(i64). Overview:; """""""""""""""""". The '``llvm.test.start.loop.iterations.*``' intrinsics are similar to the; '`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:645816,avoid,avoid,645816,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['avoid'],['avoid']
Safety,""""""""""""""". ::. <result> = frem [fast-math flags]* <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``frem``' instruction returns the remainder from the division of; its two operands. .. note::. 	The instruction is implemented as a call to libm's '``fmod``'; 	for some targets, and using the instruction may thus require linking libm. Arguments:; """""""""""""""""""". The two arguments to the '``frem``' instruction must be; :ref:`floating-point <t_floating>` or :ref:`vector <t_vector>` of; floating-point values. Both arguments must have identical types. Semantics:; """""""""""""""""""". The value produced is the floating-point remainder of the two operands.; This is the same output as a libm '``fmod``' function, but without any; possibility of setting ``errno``. The remainder has the same sign as the; dividend.; This instruction is assumed to execute in the default :ref:`floating-point; environment <floatenv>`.; This instruction can also take any number of :ref:`fast-math; flags <fastmath>`, which are optimization hints to enable otherwise; unsafe floating-point optimizations:. Example:; """""""""""""""". .. code-block:: text. <result> = frem float 4.0, %var ; yields float:result = 4.0 % %var. .. _bitwiseops:. Bitwise Binary Operations; -------------------------. Bitwise binary operators are used to do various forms of bit-twiddling; in a program. They are generally very efficient instructions and can; commonly be strength reduced from other instructions. They require two; operands of the same type, execute an operation on them, and produce a; single value. The resulting value is the same type as its operands. .. _i_shl:. '``shl``' Instruction; ^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = shl <ty> <op1>, <op2> ; yields ty:result; <result> = shl nuw <ty> <op1>, <op2> ; yields ty:result; <result> = shl nsw <ty> <op1>, <op2> ; yields ty:result; <result> = shl nuw nsw <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``shl``' instruction returns the first opera",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:391776,unsafe,unsafe,391776,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['unsafe'],['unsafe']
Safety,""""""""". The first and only argument is the ``gc.statepoint`` which starts; the safepoint sequence of which this ``gc.result`` is a part.; Despite the typing of this as a generic token, *only* the value defined; by a ``gc.statepoint`` is legal here. Semantics:; """""""""""""""""""". The ``gc.result`` represents the return value of the call target of; the ``statepoint``. The type of the ``gc.result`` must exactly match; the type of the target. If the call target returns void, there will; be no ``gc.result``. A ``gc.result`` is modeled as a 'readnone' pure function. It has no; side effects since it is just a projection of the return value of the; previous call represented by the ``gc.statepoint``. '``llvm.experimental.gc.relocate``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <pointer type>; @llvm.experimental.gc.relocate(token %statepoint_token,; i32 %base_offset,; i32 %pointer_offset). Overview:; """""""""""""""""". A ``gc.relocate`` returns the potentially relocated value of a pointer; at the safepoint. Operands:; """""""""""""""""". The first argument is the ``gc.statepoint`` which starts the; safepoint sequence of which this ``gc.relocation`` is a part.; Despite the typing of this as a generic token, *only* the value defined; by a ``gc.statepoint`` is legal here. The second and third arguments are both indices into operands of the; corresponding statepoint's :ref:`gc-live <ob_gc_live>` operand bundle. The second argument is an index which specifies the allocation for the pointer; being relocated. The associated value must be within the object with which the; pointer being relocated is associated. The optimizer is free to change *which*; interior derived pointer is reported, provided that it does not replace an; actual base pointer with another interior derived pointer. Collectors are; allowed to rely on the base pointer operand remaining an actual base pointer if; so constructed. The third argument is an index which specify the (potentially) derived ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:505229,safe,safepoint,505229,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['safe'],['safepoint']
Safety,"""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.merge.v16i32 (<16 x i1> <condition>, <16 x i32> <on_true>, <16 x i32> <on_false>, i32 <pivot>); declare <vscale x 4 x i64> @llvm.vp.merge.nxv4i64 (<vscale x 4 x i1> <condition>, <vscale x 4 x i64> <on_true>, <vscale x 4 x i64> <on_false>, i32 <pivot>). Overview:; """""""""""""""""". The '``llvm.vp.merge``' intrinsic is used to choose one value based on a; condition vector and an index operand, without IR-level branching. Arguments:; """""""""""""""""""". The first operand is a vector of ``i1`` and indicates the condition. The; second operand is the value that is merged where the condition vector is true.; The third operand is the value that is selected where the condition vector is; false or the lane position is greater equal than the pivot. The fourth operand; is the pivot. #. The optional ``fast-math flags`` marker indicates that the merge has one or; more :ref:`fast-math flags <fastmath>`. These are optimization hints to; enable otherwise unsafe floating-point optimizations. Fast-math flags are; only valid for merges that return a floating-point scalar or vector type,; or an array (nested to any depth) of floating-point scalar or vector types. Semantics:; """""""""""""""""""". The intrinsic selects lanes from the second and third operand depending on a; condition vector and pivot value. For all lanes where the condition vector is true and the lane position is less; than ``%pivot`` the lane is taken from the second operand. Otherwise, the lane; is taken from the third operand. Example:; """""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.merge.v4i32(<4 x i1> %cond, <4 x i32> %on_true, <4 x i32> %on_false, i32 %pivot). ;;; Expansion.; ;; Lanes at and above %pivot are taken from %on_false; %atfirst = insertelement <4 x i32> undef, i32 %pivot, i32 0; %splat = shufflevector <4 x i32> %atfirst, <4 x i32> poison, <4 x i32> zeroinitializer; %pivotmask = icmp ult <4 x i32> <i32 0, i32 1, i32 2, i32 3>, <4 x i32> %splat; %m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:696163,unsafe,unsafe,696163,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['unsafe'],['unsafe']
Safety,""""". The '``llvm.va_copy``' intrinsic works just like the ``va_copy`` macro; available in C. In a target-dependent way, it copies the source; ``va_list`` element into the destination ``va_list`` element. This; intrinsic is necessary because the `` llvm.va_start`` intrinsic may be; arbitrarily complex and require, for example, memory allocation. Accurate Garbage Collection Intrinsics; --------------------------------------. LLVM's support for `Accurate Garbage Collection <GarbageCollection.html>`_; (GC) requires the frontend to generate code containing appropriate intrinsic; calls and select an appropriate GC strategy which knows how to lower these; intrinsics in a manner which is appropriate for the target collector. These intrinsics allow identification of :ref:`GC roots on the; stack <int_gcroot>`, as well as garbage collector implementations that; require :ref:`read <int_gcread>` and :ref:`write <int_gcwrite>` barriers.; Frontends for type-safe garbage collected languages should generate; these intrinsics to make use of the LLVM garbage collectors. For more; details, see `Garbage Collection with LLVM <GarbageCollection.html>`_. LLVM provides an second experimental set of intrinsics for describing garbage; collection safepoints in compiled code. These intrinsics are an alternative; to the ``llvm.gcroot`` intrinsics, but are compatible with the ones for; :ref:`read <int_gcread>` and :ref:`write <int_gcwrite>` barriers. The; differences in approach are covered in the `Garbage Collection with LLVM; <GarbageCollection.html>`_ documentation. The intrinsics themselves are; described in :doc:`Statepoints`. .. _int_gcroot:. '``llvm.gcroot``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.gcroot(ptr %ptrloc, ptr %metadata). Overview:; """""""""""""""""". The '``llvm.gcroot``' intrinsic declares the existence of a GC root to; the code generator, and allows some metadata to be associated with it. Arguments:; """""""""""""""""""". The first argument specifies the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:496056,safe,safe,496056,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['safe'],['safe']
Safety,"# Building libclang-cpp.so fails if LLVM_ENABLE_PIC=Off; if (NOT LLVM_ENABLE_PIC); return(); endif(). get_property(clang_libs GLOBAL PROPERTY CLANG_STATIC_LIBS). foreach (lib ${clang_libs}); if(XCODE); # Xcode doesn't support object libraries, so we have to trick it into; # linking the static libraries instead.; list(APPEND _DEPS ""-force_load"" ${lib}); else(); list(APPEND _OBJECTS $<TARGET_OBJECTS:obj.${lib}>); endif(); if (BUILD_SHARED_LIBS); # If we are building static libraries, then we don't need to add the static; # libraries as a dependency, because we are already linking against the; # individual object files.; list(APPEND _DEPS $<TARGET_PROPERTY:${lib},INTERFACE_LINK_LIBRARIES>); endif(). # clang libraries are redundant since we are linking all the individual; # object files into libclang-cpp.so, so filter them out from _DEPS.; # This avoids problems with LLVM global data when building with; # BUILD_SHARED_LIBS=ON; # FIXME: We could use list(FILTER) with cmake >= 3.6; # FIXME: With cmake >= 3.15 we could use the generator expression; # $<FILTER:list,INCLUDE|EXCLUDE,regex>; get_target_property(interface ${lib} LINK_LIBRARIES); if (interface); foreach(lib ${interface}); if (NOT ${lib} MATCHES ""^clang""); list(APPEND _DEPS ${lib}); endif(); endforeach(); endif(); endforeach (). if (CLANG_LINK_CLANG_DYLIB); set(INSTALL_WITH_TOOLCHAIN INSTALL_WITH_TOOLCHAIN); endif(). add_clang_library(clang-cpp; SHARED; ${INSTALL_WITH_TOOLCHAIN}; clang-shlib.cpp; ${_OBJECTS}; LINK_LIBS; ${_DEPS}); # Optimize function calls for default visibility definitions to avoid PLT and; # reduce dynamic relocations.; if (NOT APPLE AND NOT MINGW AND NOT LLVM_LINKER_IS_SOLARISLD_ILLUMOS); target_link_options(clang-cpp PRIVATE LINKER:-Bsymbolic-functions); endif(); if (MINGW OR CYGWIN); # The clang-cpp DLL is supposed to export all symbols (except for ones; # that are explicitly hidden). Normally, this is what happens anyway, but; # if there are symbols that are marked explicitly as dllexport, w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-shlib/CMakeLists.txt:728,redund,redundant,728,interpreter/llvm-project/clang/tools/clang-shlib/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-shlib/CMakeLists.txt,2,"['avoid', 'redund']","['avoids', 'redundant']"
Safety,"# C++ Modules in ROOT. Technology Overview. *Vassil Vassilev, Oksana Shadura, Yuka Takahashi and Raphael Isemann*. ## Overview. ROOT has several features which interact with libraries and require implicit; header inclusion. This can be triggered by reading or writing data on disk,; or user actions at the prompt. Often, the headers are immutable and reparsing is; redundant. C++ Modules are designed to minimize the reparsing of the same; header content by providing an efficient on-disk representation of C++ Code. The ROOT v6.16 release came with a preview of the module technology;; dedicated binaries have been built and can be reproduced by passing; `-Druntime_cxxmodules=On` as configure flag. The goals of this technology are:; * Gain feedback from early adoption -- the technology is being long anticipated; by some of the users of ROOT. It improves correctness of ROOT and improves; performance when carefully adopted.; * Study performance bottlenecks -- the feature is designed with performance; considerations in mind. In this document we describe the current performance; bottlenecks and trade-offs.; * Understand if the gradual migration policy is sufficient -- C++ Modules in; ROOT support gradual migration. In particular, ROOT can enable C++ Modules for; itself and still run in legacy mode for the third-party code (generating; rootmap files and other scaffolding). C++ Modules are here and we would like to give a brief introduction of how the; feature works, what are its pros and cons, what's the current state of the; implementation and how third-party code can use it. Read more [[1]]. C++ Modules in ROOT are default since v6.20 (Unix) and v6.22 (OSX). ## Design Goals. * Coherence with standard C++ -- C++ Modules TS is advancing and will be; likely part the upcoming C++20 standard;; * Performance -- provide performance that is competitive to ROOT with PCH and; advance further the implementation of the C++ Modules in clang to optimize; memory footprint and execution time;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:365,redund,redundant,365,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['redund'],['redundant']
Safety,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. # Test library loads during importing ROOT; # Testing only the Linux systems is sufficient to detect unwanted links to libraries at import time.; # Mac (and potentially Windows) pull in many system libraries which makes this test very complex.; if (NOT APPLE AND NOT WIN32); ROOT_ADD_PYUNITTEST(pyroot_import_load_libs import_load_libs.py); endif(). # Test ROOT module; ROOT_ADD_PYUNITTEST(pyroot_root_module root_module.py). # @pythonization decorator; ROOT_ADD_PYUNITTEST(pyroot_pyz_decorator pythonization_decorator.py). # General pythonizations; ROOT_ADD_PYUNITTEST(pyroot_pyz_pretty_printing pretty_printing.py); ROOT_ADD_PYUNITTEST(pyroot_pyz_array_interface array_interface.py PYTHON_DEPS numpy). # STL containers pythonizations; ROOT_ADD_PYUNITTEST(pyroot_pyz_stl_vector stl_vector.py); ROOT_ADD_PYUNITTEST(pyroot_pyz_stl_set stl_set.py). # TObject and subclasses pythonisations; ROOT_ADD_PYUNITTEST(pyroot_pyz_tobject_contains tobject_contains.py); ROOT_ADD_PYUNITTEST(pyroot_pyz_tobject_comparisonops tobject_comparisonops.py). # TClass pythonisations; ROOT_ADD_PYUNITTEST(pyroot_pyz_tclass_dynamiccast tclass_dynamiccast.py). # TContext pythonizations; ROOT_ADD_PYUNITTEST(pyroot_pyz_tcontext_contextmanager tcontext_contextmanager.py). # TDirectory and subclasses pythonizations; ROOT_ADD_PYUNITTEST(pyroot_pyz_tdirectory_attrsyntax tdirectory_attrsyntax.py); ROOT_ADD_PYUNITTEST(pyroot_pyz_tdirectoryfile_attrsyntax_get tdirectoryfile_attrsyntax_get.py); ROOT_ADD_PYUNITTEST(pyroot_pyz_tfile_attrsyntax_get_writeobject_open tfile_attrsyntax_get_writeobject_open.py); ROOT_ADD_PYUNITTEST(pyroot_pyz_tfile_constructor tfile_constructor.py); ROOT_ADD_PYUNITTEST(pyroot_pyz_tfile_context_manager tfile_context_manager.py). # TTree and subclasses pythonizations; file(COPY TreeHelper.h DESTINATION ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/pythonizations/test/CMakeLists.txt:289,detect,detect,289,bindings/pyroot/pythonizations/test/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/pythonizations/test/CMakeLists.txt,1,['detect'],['detect']
Safety,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ############################################################################; # CMakeLists.txt file for building ROOT graf2d/win32gdk package; # @author Pere Mato, CERN; ############################################################################. # use relative paths to avoid filtering in dictionary generator; include_directories(${FREETYPE_INCLUDE_DIRS}; ${CMAKE_CURRENT_SOURCE_DIR}/gdk/src; ${CMAKE_CURRENT_SOURCE_DIR}/gdk/src/gdk; ${CMAKE_CURRENT_SOURCE_DIR}/gdk/src/glib). set(iconvlib ${CMAKE_LIBRARY_OUTPUT_DIRECTORY}/iconv-1.3.lib); set(iconvdll ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/iconv-1.3.dll); set(iconvliba ${CMAKE_CURRENT_BINARY_DIR}/gdk/src/iconv/iconv-1.3.lib); set(iconvdlla ${CMAKE_CURRENT_BINARY_DIR}/gdk/src/iconv/iconv-1.3.dll). set(gliblib ${CMAKE_LIBRARY_OUTPUT_DIRECTORY}/glib-1.3.lib); set(glibdll ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/glib-1.3.dll); set(glibliba ${CMAKE_CURRENT_BINARY_DIR}/gdk/src/glib/glib-1.3.lib); set(glibdlla ${CMAKE_CURRENT_BINARY_DIR}/gdk/src/glib/glib-1.3.dll). set(gdklib ${CMAKE_LIBRARY_OUTPUT_DIRECTORY}/gdk-1.3.lib); set(gdkdll ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/gdk-1.3.dll); set(gdkliba ${CMAKE_CURRENT_BINARY_DIR}/gdk/src/gdk/gdk-1.3.lib); set(gdkdlla ${CMAKE_CURRENT_BINARY_DIR}/gdk/src/gdk/gdk-1.3.dll). file(GLOB iconvfiles ""gdk/src/iconv/*.*""); file(GLOB_RECURSE glibfiles ""gdk/src/glib/*.*""); file(GLOB_RECURSE gdkfiles ""gdk/src/gdk/*.*""). if(CMAKE_GENERATOR MATCHES Ninja); set(nmcxxflags ${CMAKE_CXX_FLAGS_${_BUILD_TYPE_UPPER}}); if (CMAKE_BUILD_TYPE MATCHES ""Debug""); set(nmcxxflags ""${nmcxxflags}"" DEBUG=1); endif(); else(); if(winrtdebug); set(nmcxxflags ""${CMAKE_CXX_FLAGS_DEBUG}"" DEBUG=1); else(); set(nmcxxflags ""${CMAKE_CXX_FLAGS_RELEASE}""); endif(); endif(); if(CMAKE_SIZEOF_VOID_P EQUAL 8); set(nmcxxflags ""${nmcxxflags} -D_WIN64""); end",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/win32gdk/CMakeLists.txt:467,avoid,avoid,467,graf2d/win32gdk/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/win32gdk/CMakeLists.txt,1,['avoid'],['avoid']
Safety,"# Copyright (C) 1995-2021, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ############################################################################; # CMakeLists.txt file for building TMVA SOFIE tests.; # @author Federico Sossai, Sanjiban Sengupta; ############################################################################. set(SOFIE_PARSERS_DIR ${CMAKE_SOURCE_DIR}/tmva/sofie_parsers). if (NOT ONNX_MODELS_DIR); set(ONNX_MODELS_DIR input_models); endif(). #Finding .onnx files to be parsed and creating the appropriate code to; # parse all file. It is much faster to combine all parsing in a single executable; # which will avoid initialization time (especially when using ROOT); set(CAPTURE_STR ""EmitModel( \""@1\"", \""@2\"");""); set(ALL_CAPTURES """"); # Finding .onnx files to be parsed and creating the appropriate command; file(GLOB ONNX_FILES ""${ONNX_MODELS_DIR}/*.onnx""); foreach(onnx_file ${ONNX_FILES}); 	get_filename_component(fname ${onnx_file} NAME_WE); 	get_filename_component(fdir ${onnx_file} DIRECTORY); string(REPLACE ""@1"" ${onnx_file} cap ${CAPTURE_STR}); string(REPLACE ""@2"" ${fname} cap ${cap}); list(APPEND ALL_CAPTURES ${cap}); endforeach(); string(REPLACE "";"" "";\n"" EMIT_CAPTURES ""${ALL_CAPTURES}""); configure_file(EmitFromONNX.cxx.in EmitFromONNX_all.cxx @ONLY); configure_file(EmitFromRoot.cxx.in EmitFromRoot_all.cxx @ONLY). add_executable(emitFromONNX; EmitFromONNX_all.cxx; ); target_include_directories(emitFromONNX PRIVATE; ${CMAKE_SOURCE_DIR}/tmva/sofie/inc; ${SOFIE_PARSERS_DIR}/inc; ${CMAKE_SOURCE_DIR}/tmva/inc; ${CMAKE_CURRENT_BINARY_DIR} # this is for the protobuf headerfile; ). target_link_libraries(emitFromONNX protobuf::libprotobuf ROOTTMVASofie ROOTTMVASofieParser); set_target_properties(emitFromONNX PROPERTIES POSITION_INDEPENDENT_CODE TRUE); ## silence protobuf warnings seen in version 3.0 and 3.6. Not needed from protobuf version",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/sofie/test/CMakeLists.txt:752,avoid,avoid,752,tmva/sofie/test/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/sofie/test/CMakeLists.txt,1,['avoid'],['avoid']
Safety,"# Copyright (C) 1995-2021, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ############################################################################; # CMakeLists.txt file for testing components from ROOT gui/webdisplay package; ############################################################################. # test only can be run if Firefox or Chrome are detected on the system; if (CHROME_EXECUTABLE OR FIREFOX_EXECUTABLE); ROOT_ADD_TEST(test-webgui-ping; RUN_SERIAL; COPY_TO_BUILDDIR ${CMAKE_SOURCE_DIR}/tutorials/webgui/ping/ping.cxx ${CMAKE_SOURCE_DIR}/tutorials/webgui/ping/ping.html; COMMAND root.exe -b -q -l ping.cxx; PASSREGEX ""PING-PONG TEST COMPLETED""; TIMEOUT 300); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/webdisplay/test/CMakeLists.txt:478,detect,detected,478,gui/webdisplay/test/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/webdisplay/test/CMakeLists.txt,1,['detect'],['detected']
Safety,"# Copyright (C) 1995-2022, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. # CMakeLists.txt for the ROOT test programs.; # This shows nicely how to compile and link applications; # using the ROOT libraries on all supported platforms.; #; # Author: Pere Mato, 25/10/2010; cmake_minimum_required(VERSION 3.10 FATAL_ERROR). project(test). # Sergey: make no sence while CMakeLists.txt file cannot be used separately from ROOT; # but variables like ROOT_asimage_FOUND used here and produced in ROOTConfig.cmake; find_package(ROOT REQUIRED). #---Copy the CTestCustom.cmake file into the build directory---------------------------------; configure_file(${CMAKE_CURRENT_SOURCE_DIR}/CTestCustom.cmake ${CMAKE_CURRENT_BINARY_DIR} COPYONLY); enable_testing(). if(CMAKE_SYSTEM_NAME MATCHES Darwin); # To avoid to set ld_Library_path to locate the test libraries; set(CMAKE_EXE_LINKER_FLAGS ""${CMAKE_EXE_LINKER_FLAGS} -Wl,-rpath,@loader_path/.""); endif(). if(DEFINED ROOT_SOURCE_DIR); # Testing using the binary tree; set(ROOT_root_CMD ${ROOT_BINDIR}/root.exe); include_directories(${ROOT_SOURCE_DIR}/tutorials); else(); # Testing using an installation (assuming access to ROOT CMake modules); include_directories(${ROOT_INCLUDE_DIRS}); include_directories(${ROOT_INCLUDE_DIRS}/../tutorials); add_definitions(${ROOT_DEFINITIONS}); include(RootMacros); endif(). #---environment-------------------------------------------------------------------------------; ROOT_ADD_TEST(show-environment COMMAND ${CMAKE_COMMAND} -E environment). #---hworld------------------------------------------------------------------------------------; ROOT_EXECUTABLE(hworld hworld.cxx LIBRARIES Gpad). #---event-------------------------------------------------------------------------------------; ROOT_STANDARD_LIBRARY_PACKAGE(Event; NO_INSTALL_HEADERS; HEADERS ${CMAKE_CURRENT_SOURCE_DIR}/Event.h; SOURCES Event.cxx L",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/test/CMakeLists.txt:912,avoid,avoid,912,test/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/test/CMakeLists.txt,1,['avoid'],['avoid']
Safety,"# Do not build unittest libraries automatically, they will be pulled in; # by unittests if these are built.; if (NOT ${LLVM_INSTALL_GTEST}); set (BUILDTREE_ONLY BUILDTREE_ONLY); set(EXCLUDE_FROM_ALL ON); endif(). add_llvm_library(LLVMTestingSupport; Error.cpp; SupportHelpers.cpp. ${BUILDTREE_ONLY}. ADDITIONAL_HEADER_DIRS; ${LLVM_MAIN_INCLUDE_DIR}/llvm/Testing/Support. LINK_COMPONENTS; Support; ). target_link_libraries(LLVMTestingSupport PRIVATE llvm_gtest). # This is to avoid the error in gtest-death-test-internal.h; # (150,16): error: 'Create' overrides a member function but; # is not marked 'override' [-Werror,-Wsuggest-override]; # during self-compile on Windows. if (HOST_WINNT AND ""${CMAKE_CXX_COMPILER_ID}"" MATCHES ""Clang"" ); SET(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -Wno-suggest-override""); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Support/CMakeLists.txt:475,avoid,avoid,475,interpreter/llvm-project/llvm/lib/Testing/Support/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Testing/Support/CMakeLists.txt,1,['avoid'],['avoid']
Safety,"# Histograms #. Histograms play a fundamental role in any type of physics analysis, not; only to visualise measurements but being a powerful form of data; reduction. ROOT offers many classes that represent histograms, all; inheriting from the `TH1` class. We will focus in this chapter on uni-; and bi- dimensional histograms the bin contents of which are represented by; floating point numbers [^4], the `TH1F` and `TH2F` classes respectively. ## Your First Histogram ##. Let's suppose you want to measure the counts of a Geiger detector located in; proximity of a radioactive source in a given time interval. This would; give you an idea of the activity of your source. The count distribution; in this case is a Poisson distribution. Let's see how operatively you; can fill and draw a histogram with the following example macro. ``` {.cpp .numberLines}; @ROOT_INCLUDE_FILE macros/macro5.C; ```. Which gives you the following plot (Figure [5.1](#f51)):. [f51]: figures/poisson.png ""f51""; <a name=""f51""></a>. ![The result of a counting (pseudo) experiment. Only bins corresponding; to integer values are filled given the discrete nature of the poissonian; distribution. \label{f51}][f51]. Using histograms is rather simple. The main differences with respect to; graphs that emerge from the example are:. - line *5*: The histograms have a name and a title right from the; start, no predefined number of entries but a number of bins and a; lower-upper range. - line *15*: An entry is stored in the histogram through the; `TH1F::Fill` method. - line *18* and *21*: The histogram can be drawn also normalised, ROOT; automatically takes cares of the necessary rescaling. - line *24* to *30*: This small snippet shows how easy it is to access; the moments and associated errors of a histogram. ## Add and Divide Histograms ##. Quite a large number of operations can be carried out with histograms.; The most useful are addition and division. In the following macro we; will learn how to manage these procedu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/histograms.md:530,detect,detector,530,documentation/primer/histograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/histograms.md,1,['detect'],['detector']
Safety,"# Input/Output; \index{I/O}. This chapter covers the saving and reading of objects to and from ROOT; files. It begins with an explanation of the physical layout of a ROOT; file. It includes a discussion on compression, and file recovery. Then; we explain the logical file, the class **`TFile`** and its methods. We; show how to navigate in a file, how to save objects and read them back.; We also include a discussion on `Streamers`. `Streamers` are the methods; responsible to capture an objects current state to save it to disk or; send it over the network. At the end of the chapter is a discussion on; the two specialized ROOT files: **`TNetFile`** and **`TWebFile`**. ## The Physical Layout of ROOT Files. A ROOT file is like a UNIX file directory. It can contain directories; and objects organized in unlimited number of levels. It also is stored; in machine independent format (ASCII, IEEE floating point, Big Endian; byte ordering). To look at the physical layout of a ROOT file, we first; create one. This example creates a ROOT file and 15 histograms, fills; each histogram with 1000 entries from a Gaussian distribution, and; writes them to the file. ``` {.cpp}; {; char name[10], title[20];; TObjArray Hlist(0); // create an array of Histograms; TH1F* h; // create a pointer to a histogram; // make and fill 15 histograms and add them to the object array; for (Int_t i = 0; i < 15; i++) {; sprintf(name,""h%d"",i);; sprintf(title,""histo nr:%d"",i);; h = new TH1F(name,title,100,-4,4);; Hlist.Add(h);; h->FillRandom(""gaus"",1000);; }; // open a file and write the array to the file; TFile f(""demo.root"",""recreate"");; Hlist.Write();; f.Close();; }; ```. The example begins with a call to the **`TFile`** constructor. This; class is describing the ROOT file (that has the extension ""`.root`""). In; the next section, we will cover **`TFile`** in details. The last line of; the example closes the file. To view its contents we need to open it; again, and to create a **`TBrowser`** object by:. ``` ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:228,recover,recovery,228,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['recover'],['recovery']
Safety,# Measurement of Friday 26 March; # Experiment 2 Physics Lab; # Expected points from theory predictions. 1 6 0.5; 2 12 1.; 3 18 1.5; 4 24 2.0; 5 30 3.7; 6 36 4.9; 7 42 5.4; 8 48 6.8; 9 54 7.5; 10 60 9.7,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/macros/macro2_input_expected.txt:92,predict,predictions,92,documentation/primer/macros/macro2_input_expected.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/macros/macro2_input_expected.txt,1,['predict'],['predictions']
Safety,"# Motivation and Introduction #. ***Welcome to data analysis!***. Comparison of measurements to theoretical models is one of the standard; tasks in experimental physics. In the most simple case, a ""model"" is; just a function providing predictions of measured data. Very often, the; model depends on parameters. Such a model may simply state ""the current; *I* is proportional to the voltage *U*"", and the task of the; experimentalist consists of determining the resistance, *R*, from a set; of measurements. As a first step, a visualisation of the data is needed. Next, some; manipulations typically have to be applied, e.g. corrections or; parameter transformations. Quite often, these manipulations are complex; ones, and a powerful library of mathematical functions and procedures; should be provided - think for example of an integral or peak-search or; a Fourier transformation applied to an input spectrum to obtain the; actual measurement described by the model. One specialty of experimental physics are the inevitable uncertainties; affecting each measurement, and visualisation tools have to include; these. In subsequent analysis, the statistical nature of the errors must; be handled properly. As the last step, measurements are compared to models, and free model; parameters need to be determined in this process. See Figure [1.1](#f11) for an; example of a function (model) fit to data points. Several standard methods are; available, and a data analysis tool should provide easy access to more; than one of them. Means to quantify the level of agreement between; measurements and model must also be available.; <!--; [f11]: figures/examplefit.png ""f11""; <a name=""f11""></a>. ![Measured data points with error bars and fitted quadratic; function.\label{f11}][f11]-->. Quite often, the data volume to be analyzed is large - think of; fine-granular measurements accumulated with the aid of computers. A; usable tool therefore must contain easy-to-use and efficient methods for; storing and h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/Introduction.md:235,predict,predictions,235,documentation/primer/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/Introduction.md,1,['predict'],['predictions']
Safety,"# OpenStack API: nova. Example of a CernVM instantiation using `nova`:. ``` {.bash}; nova boot \; --flavor m1.xlarge \; --image cernvm-batch-node-2.6.0-4-1-x86_64 \; --key-name my_default_keyparir \; --user-data my_vaf_context.txt \; Name-Of-My-New-VM; ```. The `--user-data` option requires the context file we've just; downloaded. ### EC2 API: euca-tools. Example of a CernVM instantiation using `euca-tools`:. ``` {.bash}; euca-run-instances \; --instance-type m1.xlarge \; --key my_default_keyparir \; --user-data-file my_vaf_context.txt \; cernvm-batch-node-2.6.0-4-1-x86_64; ```. The `--user-data-file` option is the context file we've just downloaded. ### OpenNebula. An example VM definition follows:. ``` {.ruby}; CONTEXT=[; EC2_USER_DATA=""<base64_encoded_string>"",; ]; CPU=""6""; VCPU=""6""; DISK=[; IMAGE=""cernvm-batch-node-2.6.0-4-1-x86_64"",; TARGET=""vda"" ]; MEMORY=""16000""; NAME=""CernVM-VAF-Node""; NIC=[; NETWORK=""My-OpenNebula-VNet"" ]; OS=[; ARCH=""x86_64"" ]; ```. The `<base64_encoded_string>` requires the base64 version of the whole; downloaded context definition. You can obtain it by running:. cat my_vaf_context.txt | base64 | tr -d '\n'. Network security groups; -----------------------. In order to make the Virtual Analysis Facility work properly, the; firewall of your infrastructure must be configured to allow some; connections. Some ports need to allow ""external"" connections while other ports might; be safely opened to allow only connections from other nodes of the; Virtual Analysis Facility. ### Ports to open on all nodes. HTCondor ports; : Allow **TCP and UDP range 9600-9700** only between nodes of the Virtual; Analysis Facility. Only HTCondor and PoD communication is needed between the nodes. No HTCondor; ports need to be opened to the world. ### Additional ports to open on the front end node. HTTPS; : Allow **TCP 443** from all. SSH; : Allow **TCP 22** from all. No other ports need to be opened from the outside. Your definition of; *allow from all* might vary.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:6374,safe,safely,6374,proof/doc/confman/DeployVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md,1,['safe'],['safely']
Safety,"# ROOT requirements for third-party Python packages. # PyROOT: Interoperability with numpy arrays; numpy; pandas. # TMVA: SOFIE; dm-sonnet ; python_version < ""3.13"" # used for GNNs, not available for Python 3.13 yet; graph_nets ; python_version < ""3.13"" # not available for Python 3.13 yet; onnx. # TMVA: PyMVA interfaces; scikit-learn; tensorflow<2.16 ; python_version < ""3.12""; torch<2.5 ; python_version < ""3.13"" # no torch version that fullfills version constraint available for Python 3.13; xgboost. # PyROOT: ROOT.Numba.Declare decorator; numba>=0.48 ; python_version < ""3.13"" # no numba available for Python 3.13 yet; cffi>=1.9.1. # Notebooks: ROOT C++ kernel; notebook>=4.4.1; metakernel>=0.20.0. # Distributed RDataFrame; pyspark>=2.4 # Spark backend; dask>=2022.08.1 # Dask backend; distributed>=2022.08.1 # Dask backend. # JsMVA: Jupyter notebook magic for TMVA; ipywidgets. # Look for CPU-only versions of PyTorch to avoid pulling CUDA in the CI docker images.; -f https://download.pytorch.org/whl/cpu/torch_stable.html; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/requirements.txt:929,avoid,avoid,929,requirements.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/requirements.txt,1,['avoid'],['avoid']
Safety,"# Speculative Load Hardening. ## A Spectre Variant #1 Mitigation Technique. Author: Chandler Carruth - [chandlerc@google.com](mailto:chandlerc@google.com). ## Problem Statement. Recently, Google Project Zero and other researchers have found information leak; vulnerabilities by exploiting speculative execution in modern CPUs. These; exploits are currently broken down into three variants:; * GPZ Variant #1 (a.k.a. Spectre Variant #1): Bounds check (or predicate) bypass; * GPZ Variant #2 (a.k.a. Spectre Variant #2): Branch target injection; * GPZ Variant #3 (a.k.a. Meltdown): Rogue data cache load. For more details, see the Google Project Zero blog post and the Spectre research; paper:; * https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; * https://spectreattack.com/spectre.pdf. The core problem of GPZ Variant #1 is that speculative execution uses branch; prediction to select the path of instructions speculatively executed. This path; is speculatively executed with the available data, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_off",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:903,predict,prediction,903,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['predict'],['prediction']
Safety,"# The Geometry Package; \index{Geometry}. The new ROOT geometry package is a tool for building, browsing,; navigating and visualizing detector geometries. The code works; standalone with respect to any tracking Monte-Carlo engine; therefore,; it does not contain any constraints related to physics. However, the; navigation features provided by the package are designed to optimize; particle transport through complex geometries, working in correlation; with simulation packages such as GEANT3, GEANT4 and FLUKA. ## Quick Start: Creating the ""world"". This chapter will provide a detailed description on how to build valid; geometries as well as the ways to optimize them. There are several; components gluing together the geometrical model, but for the time being; let us get used with the most basic concepts. The basic bricks for building-up the model are called; `volumes`**.**These represent the un-positioned pieces of the geometry; puzzle. The difference is just that the relationship between the pieces; is not defined by neighbors, but by `containment`. In other words,; volumes are put one inside another making an in-depth hierarchy. From; outside, the whole thing looks like a big pack that you can open finding; out other smaller packs nicely arranged waiting to be opened at their; turn. The biggest one containing all others defines the ""`world`"" of the; model. We will often call this `master reference system (MARS)`. Going; on and opening our packs, we will obviously find out some empty ones,; otherwise, something is very wrong... We will call these leaves (by; analogy with a tree structure). On the other hand, any volume is a small world by itself - what we need; to do is to take it out and to ignore all the rest since it is a; self-contained object. In fact, the modeller can act like this,; considering a given volume as temporary MARS, but we will describe this; feature later on. Let us focus on the biggest pack - it is mandatory to; define one. Consider the simplest geom",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:134,detect,detector,134,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['detect'],['detector']
Safety,"# The SOVERSION should be updated only if a change is made to the libclang; # ABI, and when it is updated, it should be updated to the current; # LLVM_VERSION_MAJOR.; # Please also see clang/tools/libclang/libclang.map. # This option defaults to CLANG_FORCE_MATCHING_LIBCLANG_SOVERSION; # to ON - which means that it by default matches CLANG_VERSION_MAJOR; #; # TODO: This should probably not be a option going forward but we; # we should commit to a way to do it. But due to getting this out; # in LLVM 15.x we opted for a option.; set(LIBCLANG_SOVERSION_ARG); if(NOT CLANG_FORCE_MATCHING_LIBCLANG_SOVERSION); set(LIBCLANG_SOVERSION_ARG SOVERSION 13); endif(). # TODO: harmonize usage of LIBCLANG_SOVERSION / LIBCLANG_LIBARY_VERSION; # below; this was added under time-pressure to avoid reverting the; # better default from LLVM 14 for LLVM 15.0.0-rc3, hence no time; # to clean up previous inconsistencies. set(SOURCES; ARCMigrate.cpp; BuildSystem.cpp; CIndex.cpp; CIndexCXX.cpp; CIndexCodeCompletion.cpp; CIndexDiagnostic.cpp; CIndexHigh.cpp; CIndexInclusionStack.cpp; CIndexUSRs.cpp; CIndexer.cpp; CXComment.cpp; CXCursor.cpp; CXExtractAPI.cpp; CXIndexDataConsumer.cpp; CXCompilationDatabase.cpp; CXLoadedDiagnostic.cpp; CXSourceLocation.cpp; CXStoredDiagnostic.cpp; CXString.cpp; CXType.cpp; Indexing.cpp; FatalErrorHandler.cpp; Rewrite.cpp. ADDITIONAL_HEADERS; CIndexDiagnostic.h; CIndexer.h; CXCursor.h; CXLoadedDiagnostic.h; CXSourceLocation.h; CXString.h; CXTranslationUnit.h; CXType.h; Index_Internal.h; ../../include/clang-c/Index.h; ). set(LIBS; clangAST; clangBasic; clangDriver; clangExtractAPI; clangFrontend; clangIndex; clangLex; clangRewrite; clangSema; clangSerialization; clangTooling; ). if (CLANG_ENABLE_ARCMT); list(APPEND LIBS clangARCMigrate); endif (). if (HAVE_LIBDL); list(APPEND LIBS ${CMAKE_DL_LIBS}); elseif (CLANG_BUILT_STANDALONE); find_library(DL_LIBRARY_PATH dl); if (DL_LIBRARY_PATH); list(APPEND LIBS dl); endif (); endif (). option(LIBCLANG_BUILD_STATIC; ""Build l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/libclang/CMakeLists.txt:782,avoid,avoid,782,interpreter/llvm-project/clang/tools/libclang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/libclang/CMakeLists.txt,1,['avoid'],['avoid']
Safety,"# This tool creates a shared library from the LLVM libraries. Generating this; # library is enabled by setting LLVM_BUILD_LLVM_DYLIB=yes on the CMake; # commandline. By default the shared library only exports the LLVM C API. set(SOURCES; libllvm.cpp; ). if(LLVM_LINK_LLVM_DYLIB AND LLVM_DYLIB_EXPORTED_SYMBOL_FILE); message(WARNING ""Using LLVM_LINK_LLVM_DYLIB with LLVM_DYLIB_EXPORTED_SYMBOL_FILE may not work. Use at your own risk.""); endif(). if(LLVM_BUILD_LLVM_DYLIB); if(MSVC); message(FATAL_ERROR ""Generating libLLVM is not supported on MSVC""); endif(); if(ZOS); message(FATAL_ERROR ""Generating libLLVM is not supported on z/OS""); endif(). llvm_map_components_to_libnames(LIB_NAMES ${LLVM_DYLIB_COMPONENTS}). # Exclude libLLVMTableGen for the following reasons:; # - it is only used by internal *-tblgen utilities;; # - it pollutes the global options space.; list(REMOVE_ITEM LIB_NAMES ""LLVMTableGen""). if(LLVM_DYLIB_EXPORTED_SYMBOL_FILE); set(LLVM_EXPORTED_SYMBOL_FILE ${LLVM_DYLIB_EXPORTED_SYMBOL_FILE}); add_custom_target(libLLVMExports DEPENDS ${LLVM_EXPORTED_SYMBOL_FILE}); endif(). if (LLVM_LINK_LLVM_DYLIB); set(INSTALL_WITH_TOOLCHAIN INSTALL_WITH_TOOLCHAIN); endif(); if (WIN32); add_llvm_library(LLVM SHARED DISABLE_LLVM_LINK_LLVM_DYLIB SONAME ${INSTALL_WITH_TOOLCHAIN} ${SOURCES}); else(); add_llvm_library(LLVM SHARED DISABLE_LLVM_LINK_LLVM_DYLIB OUTPUT_NAME LLVM ${INSTALL_WITH_TOOLCHAIN} ${SOURCES}); # Add symlink for backwards compatibility with old library name; llvm_install_library_symlink(LLVM-${LLVM_VERSION_MAJOR}${LLVM_VERSION_SUFFIX} $<TARGET_FILE_NAME:LLVM> SHARED FULL_DEST COMPONENT LLVM); endif(). list(REMOVE_DUPLICATES LIB_NAMES); if(""${CMAKE_SYSTEM_NAME}"" STREQUAL ""Darwin""); set(LIB_NAMES -Wl,-all_load ${LIB_NAMES}); else(); configure_file(; ${CMAKE_CURRENT_SOURCE_DIR}/simple_version_script.map.in; ${LLVM_LIBRARY_DIR}/tools/llvm-shlib/simple_version_script.map). # GNU ld doesn't resolve symbols in the version script.; set(LIB_NAMES -Wl,--whole-archive ${LIB_NA",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt:427,risk,risk,427,interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt,1,['risk'],['risk']
Safety,"## Tree Libraries. ### TTreePlayer and TSelectorDraw. - The option `colz` in a command like `nt->Draw(""b:a:c>>h"", """", ""colz"");`; erased the histogram `h`. (Jira report ROOT-4508).; - Make sure the number of bins for 2D histograms generated when drawing; 3 variables with option COL is the same as drawing 2 variables.; - In case of a 2D scatter plot drawing (with or without option COL) the automatically; computed lower limits of the histogram's axis might be 0. In that case it is better to set them; to the minimum of the data set (if it is >0) to avoid data cut when plotting in log scale. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v602/index.md:551,avoid,avoid,551,tree/doc/v602/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v602/index.md,1,['avoid'],['avoid']
Safety,"## Tree Libraries. ### TTreeReader. ROOT offers a new class `TTreeReader` that gives simple, safe and fast access to the content of a `TTree`.; Using it is trivial:. ``` {.cpp}; #include ""TFile.h""; #include ""TH1F.h""; #include ""TTreeReader.h""; #include ""TTreeReaderValue.h"". void hsimpleReader() {; TH1F *myHist = new TH1F(""h1"",""ntuple"",100,-4,4);; TFile *myFile = TFile::Open(""hsimple.root"");. // Create a TTreeReader for the tree, for instance by passing the; // TTree's name and the TDirectory / TFile it is in.; TTreeReader myReader(""ntuple"", myFile);. // The branch ""px"" contains floats; access them as myPx.; TTreeReaderValue<Float_t> myPx(myReader, ""px"");; // The branch ""py"" contains floats, too; access those as myPy.; TTreeReaderValue<Float_t> myPy(myReader, ""py"");. // Loop over all entries of the TTree or TChain.; while (myReader.Next()) {; // Just access the data as if myPx and myPy were iterators (note the '*'; // in front of them):; myHist->Fill(*myPx + *myPy);; }. myHist->Draw();; }; ```. TTreeReader checks whether the type that you expect can be extracted from the tree's branch and will clearly complain if not.; It reads on demand: only data that are actually needed are read, there is no need for `SetBranchStatus()`, `SetBranchAddress()`, `LoadTree()` or anything alike.; It uses the memory management of TTree, removing possible double deletions or memory leaks and relieveing you from the need to manage the memory yourself.; It turns on the tree cache, accelerating the reading of data.; It has been extensively tested on all known types of TTree branches and is thus a generic, fits-all access method for data stored in TTrees. ### TTreePlayer. - The TEntryList for ||-Coord plot was not defined correctly. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v600/index.md:93,safe,safe,93,tree/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v600/index.md,1,['safe'],['safe']
Safety,"### operator$<<$(std::ostream&, const MnUserCovariance&) ###. Prints out the MnUserCovariance. ### operator$<<$(std::ostream&, const MnGlobalCorrelationCoeff&) ###. Prints out the MnGlobalCorrelationCoeff. ### operator$<<$(std::ostream&, const MnUserParameterState&) ###. Prints out the whole MnUserParameterState: MnUserParameters,; MnUserCovariance and MnGlobalCorrelationCoeff. ### operator$<<$(std::ostream&, const MinosError&) ###. Prints out the MinosError of a given parameter. ### operator$<<$(std::ostream&, const ContoursErros&) ###. Prints out the MinosError of the two parameters and plots a line printer; graphic of the contours on the output terminal. # How to get the right answer from M #. The goal of M — to be able to minimize and analyze parameter errors for; all possible user functions with any number of variable parameters — is; of course impossible to realise, even in principle, in a finite amount; of time. In practice, some assumptions must be made about the behaviour; of the function in order to avoid evaluating it at all possible points.; In this chapter we give some hints on how the user can help M to make; the right assumptions. ## Which minimizer to use ##. One of the historically interesting advantages of M is that it was; probably the first minimization program to offer the user a choice of; several minimization algorithms. This could be taken as a reflection of; the fact that none of the algorithms known at that time were good enough; to be universal, so users were encouraged to find the one that worked; best for them. Since then, algorithms have improved considerably, but M; still offers several, mostly so that old users will not feel cheated,; but also to help the occasional user who does manage to defeat the best; algorithms. M currently offers four applications which can be used to; find a smaller function value, in addition to $\mbox{MINOS}$, which; will retain a smaller function value if it stumbles on one unexpectedly.; The objects which ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:59914,avoid,avoid,59914,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['avoid'],['avoid']
Safety,"############################################################################; # CMakeLists.txt file for building ROOT roofitcore/ZMQ package; # @author Patrick Bos, Netherlands eScience Center; ############################################################################. ROOT_LINKER_LIBRARY(RooFitZMQ; src/ZeroMQSvc.cpp; src/ZeroMQPoller.cpp; src/functions.cpp; src/ppoll.cpp; ). target_link_libraries(RooFitZMQ PUBLIC libzmq cppzmq); set(RooFitZMQ_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/res); target_include_directories(RooFitZMQ; PRIVATE ${RooFitZMQ_INCLUDE_DIR}; INTERFACE $<BUILD_INTERFACE:${RooFitZMQ_INCLUDE_DIR}>). # zmq_ppoll is still in the draft API, and RooFitZMQ relies on it; target_compile_definitions(RooFitZMQ PUBLIC ZMQ_BUILD_DRAFT_API); # to avoid leaking symbols; target_compile_definitions(RooFitZMQ PUBLIC ZMQ_NO_EXPORT). ROOT_ADD_TEST_SUBDIRECTORY(test); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitZMQ/CMakeLists.txt:762,avoid,avoid,762,roofit/roofitZMQ/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitZMQ/CMakeLists.txt,1,['avoid'],['avoid']
Safety,"#0 0x7f7893912f0b in main umr2.cc:7; #1 0x7f789249b76c in __libc_start_main libc-start.c:226. Uninitialized value was stored to memory at; #0 0x7f78938b5c25 in __msan_chain_origin msan.cc:484; #1 0x7f7893912ecd in main umr2.cc:6. Uninitialized value was created by a heap allocation; #0 0x7f7893901cbd in operator new[](unsigned long) msan_new_delete.cc:44; #1 0x7f7893912e06 in main umr2.cc:4. By default, MemorySanitizer collects both allocation points and all; intermediate stores the uninitialized value went through. Origin; tracking has proved to be very useful for debugging MemorySanitizer; reports. It slows down program execution by a factor of 1.5x-2x on top; of the usual MemorySanitizer slowdown and increases memory overhead. Clang option ``-fsanitize-memory-track-origins=1`` enables a slightly; faster mode when MemorySanitizer collects only allocation points but; not intermediate stores. Use-after-destruction detection; ===============================. MemorySanitizer includes use-after-destruction detection. After invocation of; the destructor, the object will be considered no longer readable, and using; underlying memory will lead to error reports in runtime. Refer to the standard; for `lifetime <https://eel.is/c++draft/basic.life#1>`_ definition. This feature can be disabled with either:. #. Pass addition Clang option ``-fno-sanitize-memory-use-after-dtor`` during; compilation.; #. Set environment variable `MSAN_OPTIONS=poison_in_dtor=0` before running; the program. Handling external code; ======================. MemorySanitizer requires that all program code is instrumented. This; also includes any libraries that the program depends on, even libc.; Failing to achieve this may result in false reports.; For the same reason you may need to replace all inline assembly code that writes to memory; with a pure C/C++ code. Full MemorySanitizer instrumentation is very difficult to achieve. To; make it easier, MemorySanitizer runtime library includes 70+; interceptor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MemorySanitizer.rst:5473,detect,detection,5473,interpreter/llvm-project/clang/docs/MemorySanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MemorySanitizer.rst,1,['detect'],['detection']
Safety,"' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.instrprof.mcdc.tvbitmap.update(ptr <name>, i64 <hash>,; i32 <bitmap-bytes>); i32 <bitmap-index>,; ptr <mcdc-temp-addr>). Overview:; """""""""""""""""". The '``llvm.instrprof.mcdc.tvbitmap.update``' intrinsic is used to track MC/DC; test vector execution after each boolean expression has been fully executed.; The overall value of the condition bitmap, after it has been successively; updated using the '``llvm.instrprof.mcdc.condbitmap.update``' intrinsic with; the true or false evaluation of each condition, uniquely identifies an executed; MC/DC test vector and is used as a bit index into the global test vector; bitmap. Arguments:; """""""""""""""""""". The first argument is a pointer to a global variable containing the; name of the entity being instrumented. This should generally be the; (mangled) function name for a set of counters. The second argument is a hash value that can be used by the consumer; of the profile data to detect changes to the instrumented source. The third argument is the number of bitmap bytes required by the function to; record the number of test vectors executed for each boolean expression. The fourth argument is the byte index into the global test vector bitmap; corresponding to the function. The fifth argument is the address of the condition bitmap, which contains a; value representing an executed MC/DC test vector. It is loaded and used as the; bit index of the test vector bitmap. Semantics:; """""""""""""""""""". This intrinsic represents the final operation of an MC/DC instrumentation; sequence and will cause the ``-instrprof`` pass to generate the code to; instrument an update of a function's global test vector bitmap to indicate that; a test vector has been executed. The global test vector bitmap can be consumed; by the ``llvm-profdata`` and ``llvm-cov`` tools. '``llvm.thread.pointer``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. decl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:535818,detect,detect,535818,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['detect'],['detect']
Safety,"'s the explicit lowering for the previous example for a non-relocating; collector:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj); ret i8 addrspace(1)* %obj; }. Recording On Stack Regions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. In addition to the explicit relocation form previously described, the; statepoint infrastructure also allows the listing of allocas within the gc; pointer list. Allocas can be listed with or without additional explicit gc; pointer values and relocations. An alloca in the gc region of the statepoint operand list will cause the; address of the stack region to be listed in the stackmap for the statepoint. This mechanism can be used to describe explicit spill slots if desired. It; then becomes the generator's responsibility to ensure that values are; spill/filled to/from the alloca as needed on either side of the safepoint.; Note that there is no way to indicate a corresponding base pointer for such; an explicitly specified spill slot, so usage is restricted to values for; which the associated collector can derive the object base from the pointer; itself. This mechanism can be used to describe on stack objects containing; references provided that the collector can map from the location on the; stack to a heap map describing the internal layout of the references the; collector needs to process. WARNING: At the moment, this alternate form is not well exercised. It is; recommended to use this with caution and expect to have to fix a few bugs.; In particular, the RewriteStatepointsForGC utility pass does not do; anything for allocas today. Base & Derived Pointers; ^^^^^^^^^^^^^^^^^^^^^^^. A ""base pointer"" is one which points to the starting address of an allocation; (object). A ""derived pointer"" is one which is offset from a base poin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:13021,safe,safepoint,13021,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['safe'],['safepoint']
Safety,"(%edx); 	movw $257, 8(%edx). It might be better to generate. 	movl $16843009, %eax; 	movl %eax, 4(%edx); 	movl %eax, (%edx); 	movw al, 8(%edx); 	; when we can spare a register. It reduces code size. //===---------------------------------------------------------------------===//. Evaluate what the best way to codegen sdiv X, (2^C) is. For X/8, we currently; get this:. define i32 @test1(i32 %X) {; %Y = sdiv i32 %X, 8; ret i32 %Y; }. _test1:; movl 4(%esp), %eax; movl %eax, %ecx; sarl $31, %ecx; shrl $29, %ecx; addl %ecx, %eax; sarl $3, %eax; ret. GCC knows several different ways to codegen it, one of which is this:. _test1:; movl 4(%esp), %eax; cmpl $-1, %eax; leal 7(%eax), %ecx; cmovle %ecx, %eax; sarl $3, %eax; ret. which is probably slower, but it's interesting at least :). //===---------------------------------------------------------------------===//. We are currently lowering large (1MB+) memmove/memcpy to rep/stosl and rep/movsl; We should leave these as libcalls for everything over a much lower threshold,; since libc is hand tuned for medium and large mem ops (avoiding RFO for large; stores, TLB preheating, etc). //===---------------------------------------------------------------------===//. Optimize this into something reasonable:; x * copysign(1.0, y) * copysign(1.0, z). //===---------------------------------------------------------------------===//. Optimize copysign(x, *y) to use an integer load from y. //===---------------------------------------------------------------------===//. The following tests perform worse with LSR:. lambda, siod, optimizer-eval, ackermann, hash2, nestedloop, strcat, and Treesor. //===---------------------------------------------------------------------===//. Adding to the list of cmp / test poor codegen issues:. int test(__m128 *A, __m128 *B) {; if (_mm_comige_ss(*A, *B)); return 3;; else; return 4;; }. _test:; 	movl 8(%esp), %eax; 	movaps (%eax), %xmm0; 	movl 4(%esp), %eax; 	movaps (%eax), %xmm1; 	comiss %xmm0, %xmm1; 	setae %a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:5004,avoid,avoiding,5004,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['avoid'],['avoiding']
Safety,"() {; baz(this); // ok; }. Caller of ``foo()`` is responsible for keeping the memory pointed to by ``this`` pointer safe. - constants. .. code-block:: cpp. foo(nullptr, NULL, 0); // ok. We also define a set of safe transformations which if passed a safe value as an input provide (usually it's the return value) a safe value (or an object that provides safe values). This is also a heuristic. - constructors of ref-counted types (including factory methods); - getters of ref-counted types; - member overloaded operators; - casts; - unary operators like ``&`` or ``*``. alpha.webkit.UncountedLocalVarsChecker; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; The goal of this rule is to make sure that any uncounted local variable is backed by a ref-counted object with lifetime that is strictly larger than the scope of the uncounted local variable. To be on the safe side we require the scope of an uncounted variable to be embedded in the scope of ref-counted object that backs it. These are examples of cases that we consider safe:. .. code-block:: cpp. void foo1() {; RefPtr<RefCountable> counted;; // The scope of uncounted is EMBEDDED in the scope of counted.; {; RefCountable* uncounted = counted.get(); // ok; }; }. void foo2(RefPtr<RefCountable> counted_param) {; RefCountable* uncounted = counted_param.get(); // ok; }. void FooClass::foo_method() {; RefCountable* uncounted = this; // ok; }. Here are some examples of situations that we warn about as they *might* be potentially unsafe. The logic is that either we're able to guarantee that an argument is safe or it's considered if not a bug then bug-prone. .. code-block:: cpp. void foo1() {; RefCountable* uncounted = new RefCountable; // warn; }. RefCountable* global_uncounted;; void foo2() {; RefCountable* uncounted = global_uncounted; // warn; }. void foo3() {; RefPtr<RefCountable> counted;; // The scope of uncounted is not EMBEDDED in the scope of counted.; RefCountable* uncounted = counted.get(); // warn; }. We don't warn about these ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:84592,safe,safe,84592,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['safe'],['safe']
Safety,"(),; true);. DBuilder->insertDeclare(Alloca, D, DBuilder->createExpression(),; DILocation::get(SP->getContext(), LineNo, 0, SP),; Builder->GetInsertBlock());. // Store the initial value into the alloca.; Builder->CreateStore(&Arg, Alloca);. // Add arguments to variable symbol table.; NamedValues[std::string(Arg.getName())] = Alloca;; }. Here we're first creating the variable, giving it the scope (``SP``),; the name, source location, type, and since it's an argument, the argument; index. Next, we create an ``lvm.dbg.declare`` call to indicate at the IR; level that we've got a variable in an alloca (and it gives a starting; location for the variable), and setting a source location for the; beginning of the scope on the declare. One interesting thing to note at this point is that various debuggers have; assumptions based on how code and debug information was generated for them; in the past. In this case we need to do a little bit of a hack to avoid; generating line information for the function prologue so that the debugger; knows to skip over those instructions when setting a breakpoint. So in; ``FunctionAST::CodeGen`` we add some more lines:. .. code-block:: c++. // Unset the location for the prologue emission (leading instructions with no; // location in a function are considered part of the prologue and the debugger; // will run past them when breaking on a function); KSDbgInfo.emitLocation(nullptr);. and then emit a new location when we actually start generating code for the; body of the function:. .. code-block:: c++. KSDbgInfo.emitLocation(Body.get());. With this we have enough debug information to set breakpoints in functions,; print out argument variables, and call functions. Not too bad for just a; few simple lines of code!. Full Code Listing; =================. Here is the complete code listing for our running example, enhanced with; debug information. To build this example, use:. .. code-block:: bash. # Compile; clang++ -g toy.cpp `llvm-config --cxxflags --ld",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst:14656,avoid,avoid,14656,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,1,['avoid'],['avoid']
Safety,"();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `if (condition) {` branch is mis-predicted,; there is a *data* dependency on the condition used to zero out any pointers; prior to loading through them or to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loaded in safe ways, and some regions of memory are; required to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data in the first place.; * It accumulates the predicate state, protecting even in the face of nested; *correctly* predicted control flows.; * It passes this predicate state across function boundaries to provide; [interprocedural protection](#interprocedural-checking).; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:4670,safe,safe,4670,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['safe'],['safe']
Safety,"(`TObjArray *fObjects`) that keeps; track of all referenced objects. If a referenced object has a; `fUniqueID`, a pointer to this unique object may be found using; `fObjects->At(fUniqueID)`. In the same way, when a **`TRef::GetObject`**; is called, `GetObject` uses its own `fUniqueID` to find the pointer to; the referenced object. See `TProcessID::GetObjectWithID` and; `PutObjectWithID`. #### Object Number. When an object is referenced, a unique identifier is computed and stored; in both the `fUniqueID` of the referenced and referencing object. This; `uniqueID` is computed by incrementing by one the static global in; `TProcessID::fgNumber`. The `fUniqueID` is the serial object number in; the current session. One can retrieve the current `fgNumber` value by; calling the static function `TProcessID::GetObjectCount` at any time or; can set this number by **`TProcessID::SetObjectCount`**. To avoid a; growing table of `fObjects` in `TProcessID`, in case, for example, one; processes many events in a loop, it might be necessary to reset the; object number at the end of processing of one event. See an example in; `$ROOTSYS/test/Event.cxx` (look at function `Build`). The value of; `ObjectNumber `may be saved at the beginning of one event and reset to; this original value at the end of the event. These actions may be; nested. ``` {.cpp}; saveNumber = TProcessID::GetObjectCount();; ...; TProcessID::SetObjectCount(savedNumber);; ```. ### Action on Demand. The normal behavior of a **`TRef`** has been described above. In; addition, **`TRef`** supports ""Actions on Demand"". It may happen that; the referenced object is not yet in the memory, on a separate file or; not yet computed. In this case, **`TRef`** is able to execute; automatically an action:. - Call to a compiled function (static function of member function). - Call to an interpreted function. - Execution of a Cling script. #### How to Select This Option?. In the definition of the **`TRef`** data member in the original clas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:62760,avoid,avoid,62760,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['avoid'],['avoid']
Safety,"(a * b) + c. Hardware-Loop Intrinsics; ------------------------. LLVM support several intrinsics to mark a loop as a hardware-loop. They are; hints to the backend which are required to lower these intrinsics further to target; specific instructions, or revert the hardware-loop to a normal loop if target; specific restriction are not met and a hardware-loop can't be generated. These intrinsics may be modified in the future and are not intended to be used; outside the backend. Thus, front-end and mid-level optimizations should not be; generating these intrinsics. '``llvm.set.loop.iterations.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. ::. declare void @llvm.set.loop.iterations.i32(i32); declare void @llvm.set.loop.iterations.i64(i64). Overview:; """""""""""""""""". The '``llvm.set.loop.iterations.*``' intrinsics are used to specify the; hardware-loop trip count. They are placed in the loop preheader basic block and; are marked as ``IntrNoDuplicate`` to avoid optimizers duplicating these; instructions. Arguments:; """""""""""""""""""". The integer operand is the loop trip count of the hardware-loop, and thus; not e.g. the loop back-edge taken count. Semantics:; """""""""""""""""""". The '``llvm.set.loop.iterations.*``' intrinsics do not perform any arithmetic; on their operand. It's a hint to the backend that can use this to set up the; hardware-loop count with a target specific instruction, usually a move of this; value to a special register or a hardware-loop instruction. '``llvm.start.loop.iterations.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. ::. declare i32 @llvm.start.loop.iterations.i32(i32); declare i64 @llvm.start.loop.iterations.i64(i64). Overview:; """""""""""""""""". The '``llvm.start.loop.iterations.*``' intrinsics are similar to the; '``llvm.set.loop.iterations.*``' intrinsics, used to specify the; hardware-loop trip count but also produce a value identical to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:643541,avoid,avoid,643541,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['avoid'],['avoid']
Safety,"(and assignment) from a matrix expression, like D = A*B + C. Due to the; expression template technique, no temporary objects are created in this operation. In; the case of an operation like A = A*B + C, a temporary object is needed and it is created; automatically to store the intermediary result in order to preserve the validity of; this operation.; * Constructor from a generic STL-like iterator copying the data referred by the iterator,; following its order. It is both possible to specify the _begin_ and _end_ of the iterator; or the _begin_ and the size. In case of a symmetric matrix, it is required only the; triangular block and the user can specify whether giving a block representing the lower; (default case) or the upper diagonal part.; * Constructor of a symmetric matrix NxN passing a ROOT::Math::SVector with dimension; N*(N+1)/2 containing the lower (or upper) block data elements. Here are some examples on how to create a matrix. We use _typedef's_ in the following examples; to avoid the full C++ names for the matrix classes. Notice that for a general matrix the; representation has the default value, ROOT::Math::MatRepStd, and it is not needed to be; specified. Furthermore, for a general square matrix, the number of column may be as well omitted. ~~~ {.cpp}; // typedef definitions used in the following declarations; typedef ROOT::Math::SMatrix<double,3> SMatrix33;; typedef ROOT::Math::SMatrix<double,2> SMatrix22;; typedef ROOT::Math::SMatrix<double,3,3,ROOT::Math::MatRepSym<double,3> > SMatrixSym3;; typedef ROOT::Math::SVector<double,2> SVector2;; typedef ROOT::Math::SVector<double,3> SVector3;; typedef ROOT::Math::SVector<double,6> SVector6;. SMatrix33 m0; // create a zero 3x3 matrix; // create an 3x3 identity matrix; SMatrix33 i = ROOT::Math::SMatrixIdentity();; double a[9] = {1,2,3,4,5,6,7,8,9}; // input matrix data; SMatrix33 m(a,9); // create a matrix using the a[] data; // this will produce the 3x3 matrix; // ( 1 2 3; // 4 5 6; // 7 8 9 ); ~~~. Example",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md:2916,avoid,avoid,2916,math/smatrix/doc/SMatrixClass.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md,1,['avoid'],['avoid']
Safety,"(i8* %endptr69) nounwind readonly . Which could also be constant folded. Whatever is producing this should probably; be fixed to leave this as a memcpy from a string. Further, eon also has an interesting partially redundant strlen call:. bb8: ; preds = %_ZN18eonImageCalculatorC1Ev.exit; %682 = getelementptr i8** %argv, i32 6 ; <i8**> [#uses=2]; %683 = load i8** %682, align 4 ; <i8*> [#uses=4]; %684 = load i8* %683, align 1 ; <i8> [#uses=1]; %685 = icmp eq i8 %684, 0 ; <i1> [#uses=1]; br i1 %685, label %bb10, label %bb9. bb9: ; preds = %bb8; %686 = call i32 @strlen(i8* %683) nounwind readonly ; %687 = icmp ugt i32 %686, 254 ; <i1> [#uses=1]; br i1 %687, label %bb10, label %bb11. bb10: ; preds = %bb9, %bb8; %688 = call i32 @strlen(i8* %683) nounwind readonly . This could be eliminated by doing the strlen once in bb8, saving code size and; improving perf on the bb8->9->10 path. //===---------------------------------------------------------------------===//. I see an interesting fully redundant call to strlen left in 186.crafty:InputMove; which looks like:; %movetext11 = getelementptr [128 x i8]* %movetext, i32 0, i32 0 ; . bb62: ; preds = %bb55, %bb53; %promote.0 = phi i32 [ %169, %bb55 ], [ 0, %bb53 ] ; %171 = call i32 @strlen(i8* %movetext11) nounwind readonly align 1; %172 = add i32 %171, -1 ; <i32> [#uses=1]; %173 = getelementptr [128 x i8]* %movetext, i32 0, i32 %172 . ... no stores ...; br i1 %or.cond, label %bb65, label %bb72. bb65: ; preds = %bb62; store i8 0, i8* %173, align 1; br label %bb72. bb72: ; preds = %bb65, %bb62; %trank.1 = phi i32 [ %176, %bb65 ], [ -1, %bb62 ] ; %177 = call i32 @strlen(i8* %movetext11) nounwind readonly align 1. Note that on the bb62->bb72 path, that the %177 strlen call is partially; redundant with the %171 call. At worst, we could shove the %177 strlen call; up into the bb65 block moving it out of the bb62->bb72 path. However, note; that bb65 stores to the string, zeroing out the last byte. This means that on; that path the value ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:40138,redund,redundant,40138,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['redund'],['redundant']
Safety,"(stderr, ""ready> "");; getNextToken();. Lastly we're going to disable all of the optimization passes and the JIT so; that the only thing that happens after we're done parsing and generating; code is that the LLVM IR goes to standard error:. .. code-block:: udiff. @@ -1108,17 +1108,8 @@ static void HandleExtern() {; static void HandleTopLevelExpression() {; // Evaluate a top-level expression into an anonymous function.; if (auto FnAST = ParseTopLevelExpr()) {; - if (auto *FnIR = FnAST->codegen()) {; - // We're just doing this to make sure it executes.; - TheExecutionEngine->finalizeObject();; - // JIT the function, returning a function pointer.; - void *FPtr = TheExecutionEngine->getPointerToFunction(FnIR);; -; - // Cast it to the right type (takes no arguments, returns a double) so we; - // can call it as a native function.; - double (*FP)() = (double (*)())(intptr_t)FPtr;; - // Ignore the return value for this.; - (void)FP;; + if (!FnAST->codegen()) {; + fprintf(stderr, ""Error generating code for top level expr"");; }; } else {; // Skip token for error recovery.; @@ -1439,11 +1459,11 @@ int main() {; // target lays out data structures.; TheModule->setDataLayout(TheExecutionEngine->getDataLayout());; OurFPM.add(new DataLayoutPass());; +#if 0; OurFPM.add(createBasicAliasAnalysisPass());; // Promote allocas to registers.; OurFPM.add(createPromoteMemoryToRegisterPass());; @@ -1218,7 +1210,7 @@ int main() {; OurFPM.add(createGVNPass());; // Simplify the control flow graph (deleting unreachable blocks, etc).; OurFPM.add(createCFGSimplificationPass());; -; + #endif; OurFPM.doInitialization();. // Set the global so the code gen can use this. This relatively small set of changes get us to the point that we can compile; our piece of Kaleidoscope language down to an executable program via this; command line:. .. code-block:: bash. Kaleidoscope-Ch9 < fib.ks | & clang -x ir -. which gives an a.out/a.exe in the current working directory. Compile Unit; ============. The top level co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst:4653,recover,recovery,4653,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,1,['recover'],['recovery']
Safety,"(x, 0.25)``; may be replaced with ``sqrt(sqrt(x))``, despite being an inexact result; in cases where ``x`` is ``-0.0`` or ``-inf``.; Defaults to ``-fno-approx-func``. .. option:: -f[no-]signed-zeros. Allow optimizations that ignore the sign of floating point zeros.; Defaults to ``-fsigned-zeros``. .. option:: -f[no-]associative-math. Allow floating point operations to be reassociated.; Defaults to ``-fno-associative-math``. .. option:: -f[no-]reciprocal-math. Allow division operations to be transformed into multiplication by a; reciprocal. This can be significantly faster than an ordinary division; but can also have significantly less precision. Defaults to; ``-fno-reciprocal-math``. .. option:: -f[no-]unsafe-math-optimizations. Allow unsafe floating-point optimizations.; ``-funsafe-math-optimizations`` also implies:. * ``-fapprox-func``; * ``-fassociative-math``; * ``-freciprocal-math``; * ``-fno-signed-zeros``; * ``-fno-trapping-math``; * ``-ffp-contract=fast``. ``-fno-unsafe-math-optimizations`` implies:. * ``-fno-approx-func``; * ``-fno-associative-math``; * ``-fno-reciprocal-math``; * ``-fsigned-zeros``; * ``-ftrapping-math``; * ``-ffp-contract=on``; * ``-fdenormal-fp-math=ieee``. There is ambiguity about how ``-ffp-contract``,; ``-funsafe-math-optimizations``, and ``-fno-unsafe-math-optimizations``; behave when combined. Explanation in :option:`-fno-fast-math` also applies; to these options. Defaults to ``-fno-unsafe-math-optimizations``. .. option:: -f[no-]finite-math-only. Allow floating-point optimizations that assume arguments and results are; not NaNs or +-Inf. ``-ffinite-math-only`` defines the; ``__FINITE_MATH_ONLY__`` preprocessor macro.; ``-ffinite-math-only`` implies:. * ``-fno-honor-infinities``; * ``-fno-honor-nans``. ``-ffno-inite-math-only`` implies:. * ``-fhonor-infinities``; * ``-fhonor-nans``. Defaults to ``-fno-finite-math-only``. .. option:: -f[no-]rounding-math. Force floating-point operations to honor the dynamically-set rounding mode by de",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:59491,unsafe,unsafe-math-optimizations,59491,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['unsafe'],['unsafe-math-optimizations']
Safety,") are passed to the fuzzer program,; then it will re-run those files as test inputs but will not perform any fuzzing.; In this mode the fuzzer binary can be used as a regression test (e.g. on a; continuous integration system) to check the target function and saved inputs; still work. The most important command line options are:. ``-help``; Print help message (``-help=1``).; ``-seed``; Random seed. If 0 (the default), the seed is generated.; ``-runs``; Number of individual test runs, -1 (the default) to run indefinitely.; ``-max_len``; Maximum length of a test input. If 0 (the default), libFuzzer tries to guess; a good value based on the corpus (and reports it).; ``-len_control``; Try generating small inputs first, then try larger inputs over time.; Specifies the rate at which the length limit is increased (smaller == faster).; Default is 100. If 0, immediately try inputs with size up to max_len.; ``-timeout``; Timeout in seconds, default 1200. If an input takes longer than this timeout,; the process is treated as a failure case.; ``-rss_limit_mb``; Memory usage limit in Mb, default 2048. Use 0 to disable the limit.; If an input requires more than this amount of RSS memory to execute,; the process is treated as a failure case.; The limit is checked in a separate thread every second.; If running w/o ASAN/MSAN, you may use 'ulimit -v' instead.; ``-malloc_limit_mb``; If non-zero, the fuzzer will exit if the target tries to allocate this; number of Mb with one malloc call.; If zero (default) same limit as rss_limit_mb is applied.; ``-timeout_exitcode``; Exit code (default 77) used if libFuzzer reports a timeout.; ``-error_exitcode``; Exit code (default 77) used if libFuzzer itself (not a sanitizer) reports a bug (leak, OOM, etc).; ``-max_total_time``; If positive, indicates the maximum total time in seconds to run the fuzzer.; If 0 (the default), run indefinitely.; ``-merge``; If set to 1, any corpus inputs from the 2nd, 3rd etc. corpus directories; that trigger new code ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:10778,timeout,timeout,10778,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['timeout'],['timeout']
Safety,") operator. For maximum flexibility and minimize memory; allocation, the coordinate system classes are templated on the scalar; type. To avoid exposing templated parameter to the users, typedefs are; defined for all types of vectors based on doubles. See in the examples; for all the possible types of vector classes, which can be constructed; by users with the available coordinate system types. #### Coordinate System Tag. The 2D and 3D points and vector classes can be associated to a tag; defining the coordinate system. This can be used to distinguish between; vectors of different coordinate systems like global or local vectors.; The coordinate system tag is a template parameter of the; **`ROOT::Math::`**`DisplacementVector3D` and; `ROOT::Math::PositionVector3D` (and also for 2D classes). A default tag; exists for users who do not need this functionality,; `ROOT::Math::DefaultCoordinateSystemTag`. #### Transformations. The transformations are modeled using simple (non-template) classes,; using double as the scalar type to avoid too large numerical errors. The; transformations are grouped in rotations (in 3 dimensions), Lorentz; transformations and Poincare transformations, which are; translation`/`rotation combinations. Each group has several members; which may model physically equivalent transformations but with different; internal representations. Transformation classes can operate on all type; of vectors by using the operator `() `or the operator `*` and the; transformations can be combined via the operator `*`. The available; transformations are:. - 3D rotation classes. - rotation described by a 3x3 matrix (**`ROOT::Math::Rotation3D`**). - rotation described by Euler angles (**`ROOT::Math::EulerAngles`**). - rotation described by a direction axis and an angle; (**`ROOT::Math::AxisAngle`**). - rotation described by a quaternion (**`ROOT::Math::Quaternion`**). - optimized rotation around `x` (**`ROOT::Math::RotationX`**), `y`; (**`ROOT::Math::RotationY`**) and `z` (",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:72596,avoid,avoid,72596,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['avoid'],['avoid']
Safety,");; consume(uncounted); // warn; }. Although we are enforcing member variables to be ref-counted by `webkit.NoUncountedMemberChecker` any method of the same class still has unrestricted access to these. Since from a caller's perspective we can't guarantee a particular member won't get modified by callee (directly or indirectly) we don't consider values obtained from members safe. Note: It's likely this heuristic could be made more precise with fewer false positives - for example calls to free functions that don't have any parameter other than the pointer should be safe as the callee won't be able to tamper with the member unless it's a global variable. .. code-block:: cpp. struct Foo {; RefPtr<RefCountable> member;; void consume(RefCountable*) { /* ... */ }; void bugprone() {; consume(member.get()); // warn; }; };. The implementation of this rule is a heuristic - we define a whitelist of kinds of values that are considered safe to be passed as arguments. If we can't prove an argument is safe it's considered an error. Allowed kinds of arguments:. - values obtained from ref-counted objects (including temporaries as those survive the call too). .. code-block:: cpp. RefCountable* provide_uncounted();; void consume(RefCountable*);. void foo() {; RefPtr<RefCountable> rc = makeRef(provide_uncounted());; consume(rc.get()); // ok; consume(makeRef(provide_uncounted()).get()); // ok; }. - forwarding uncounted arguments from caller to callee. .. code-block:: cpp. void foo(RefCountable& a) {; bar(a); // ok; }. Caller of ``foo()`` is responsible for ``a``'s lifetime. - ``this`` pointer. .. code-block:: cpp. void Foo::foo() {; baz(this); // ok; }. Caller of ``foo()`` is responsible for keeping the memory pointed to by ``this`` pointer safe. - constants. .. code-block:: cpp. foo(nullptr, NULL, 0); // ok. We also define a set of safe transformations which if passed a safe value as an input provide (usually it's the return value) a safe value (or an object that provides safe values).",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:82940,safe,safe,82940,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['safe'],['safe']
Safety,")` or `RooAbsPdf::createNLL()`. In case you observe any slowdowns with the new likelihood evaluation, please; open a GitHub issue about this, as such a performance regression is considered; a bug. ### Asymptotically correct uncertainties for extended unbinned likelihood fits. Added correct treatment of extended term in asymptotically correct method for uncertainty determination in the presence of weights.; This improvement will allow for extended unbinned maximum likelihood fits to use the asymptotically correct method when using the `RooFit::AsymptoticError()` command argument in [RooAbsPdf::fitTo()](https://root.cern.ch/doc/master/classRooAbsPdf.html#ab0721374836c343a710f5ff92a326ff5).; See also this [writeup on extended weighted fits](https://root.cern/files/extended_weighted_fits.pdf) that is also linked from the reference guide.; The [pull request](https://github.com/root-project/root/pull/14751) that introduced this feature might also be a good reference. ### Compile your code with memory safe interfaces. If you define the `ROOFIT_MEMORY_SAFE_INTERFACES` preprocessor macro, the; RooFit interface changes in a way such that memory leaks are avoided. The most prominent effect of this change is that many functions that used to; return an owning pointer (e.g., a pointer to an object that you need to; manually `delete`) are then returning a `std::unique_pt` for automatic memory; management. For example this code would not compile anymore, because there is the risk that; the caller forgets to `delete params`:; ```c++; RooArgSet * params = pdf.getParameters(nullptr);; ```; If you wrap such return values in a `std::unique_ptr`, then your code will; compile both with and without memory safe interfaces:; ```c++; std::unique_ptr<RooArgSet> params{pdf.getParameters(nullptr)};; ```. Also some `virtual` RooFit functions like [RooAbsReal::createIntegral()](https://root.cern.ch/doc/master/classRooAbsReal.html#aff4be07dd6a131721daeeccf6359aea9); are returning a different type co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:8411,safe,safe,8411,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['safe'],['safe']
Safety,"* (the ""reference output""). If you; do not use this option, **bugpoint** will attempt to generate a reference output; by compiling the program with the ""safe"" backend and running it. **--run-{int,jit,llc,custom}**. Whenever the test program is compiled, **bugpoint** should generate code for it; using the specified code generator. These options allow you to choose the; interpreter, the JIT compiler, the static native code compiler, or a; custom command (see **--exec-command**) respectively. **--safe-{llc,custom}**. When debugging a code generator, **bugpoint** should use the specified code; generator as the ""safe"" code generator. This is a known-good code generator; used to generate the ""reference output"" if it has not been provided, and to; compile portions of the program that as they are excluded from the testcase.; These options allow you to choose the; static native code compiler, or a custom command, (see **--exec-command**); respectively. The interpreter and the JIT backends cannot currently; be used as the ""safe"" backends. **--exec-command** *command*. This option defines the command to use with the **--run-custom** and; **--safe-custom** options to execute the bitcode testcase. This can; be useful for cross-compilation. **--compile-command** *command*. This option defines the command to use with the **--compile-custom**; option to compile the bitcode testcase. The command should exit with a; failure exit code if the file is ""interesting"" and should exit with a; success exit code (i.e. 0) otherwise (this is the same as if it crashed on; ""interesting"" inputs). This can be useful for; testing compiler output without running any link or execute stages. To; generate a reduced unit test, you may add CHECK directives to the; testcase and pass the name of an executable compile-command script in this form:. .. code-block:: sh. #!/bin/sh; llc ""$@""; not FileCheck [bugpoint input file].ll < bugpoint-test-program.s. This script will ""fail"" as long as FileCheck passes. So t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst:4993,safe,safe,4993,interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,1,['safe'],['safe']
Safety,"* `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow down when creating a Palette with; `CreateGradientColorTable`.; * In `CreateGradientColorTable` we do not need anymore to compute the highest; color index.; * In `TGraphPainter`, when graphs are painted with lines, they are split into; chunks of length `fgMaxPointsPerLine`. This allows to paint line with an ""infinite""; number of points. In some case this ""chunks painting"" technic may create artefacts; at the chunk's boundaries. For instance when zooming deeply in a PDF file. To avoid; this effect it might be necessary to increase the chunks' size using the new function:; `TGraphPainter::SetMaxPointsPerLine(20000)`.; * When using line styles different from 1 (continuous line), the behavior of TArrow; was suboptimal. The problem was that the line style is also applied to the arrow; head, which is usually not what one wants.; The arrow tip is now drawn using a continuous line.; * It is now possible to selec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:14000,avoid,avoiding,14000,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['avoid'],['avoiding']
Safety,"* ``__is_trivially_copyable``; * ``__is_union``; * ``__underlying_type``. A simplistic usage example as might be seen in standard C++ headers follows:. .. code-block:: c++. #if __has_builtin(__is_convertible_to); template<typename From, typename To>; struct is_convertible_to {; static const bool value = __is_convertible_to(From, To);; };; #else; // Emulate type trait for compatibility with other compilers.; #endif. Blocks; ======. The syntax and high level language feature description is in; :doc:`BlockLanguageSpec<BlockLanguageSpec>`. Implementation and ABI details for; the clang implementation are in :doc:`Block-ABI-Apple<Block-ABI-Apple>`. Query for this feature with ``__has_extension(blocks)``. ASM Goto with Output Constraints; ================================. Outputs may be used along any branches from the ``asm goto`` whether the; branches are taken or not. Query for this feature with ``__has_extension(gnu_asm_goto_with_outputs)``. Prior to clang-16, the output may only be used safely when the indirect; branches are not taken. Query for this difference with; ``__has_extension(gnu_asm_goto_with_outputs_full)``. When using tied-outputs (i.e. outputs that are inputs and outputs, not just; outputs) with the `+r` constraint, there is a hidden input that's created; before the label, so numeric references to operands must account for that. .. code-block:: c++. int foo(int x) {; // %0 and %1 both refer to x; // %l2 refers to err; asm goto(""# %0 %1 %l2"" : ""+r""(x) : : : err);; return x;; err:; return -1;; }. This was changed to match GCC in clang-13; for better portability, symbolic; references can be used instead of numeric references. .. code-block:: c++. int foo(int x) {; asm goto(""# %[x] %l[err]"" : [x]""+r""(x) : : : err);; return x;; err:; return -1;; }. Objective-C Features; ====================. Related result types; --------------------. According to Cocoa conventions, Objective-C methods with certain names; (""``init``"", ""``alloc``"", etc.) always return objects th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:67267,safe,safely,67267,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['safe'],['safely']
Safety,"*)malloc(sizeof(int) * nelems);; sbuf->count = nelems;; }. To implement this rule, the compiler requires a linear representation of; statements to understand the ordering and the adjacency between the two or more; assignments. The Clang CFG is used to implement this analysis as Clang CFG; provides a linear view of statements within each ``CFGBlock`` (Clang; ``CFGBlock`` represents a single basic block in a source-level CFG). Bounds check optimizations; ==========================. In ``-fbounds-safety``, the Clang frontend emits run-time checks for every; memory dereference if the type system or analyses in the frontend couldn’t; verify its bounds safety. The implementation relies on LLVM optimizations to; remove redundant run-time checks. Using this optimization strategy, if the; original source code already has bounds checks, the fewer additional checks; ``-fbounds-safety`` will introduce. The LLVM ``ConstraintElimination`` pass is; design to remove provable redundant checks (please check Florian Hahn’s; presentation in 2021 LLVM Dev Meeting and the implementation to learn more). In; the following example, ``-fbounds-safety`` implicitly adds the redundant bounds; checks that the optimizer can remove:. .. code-block:: c. void fill_array_with_indices(int *__counted_by(count) p, size_t count) {; for (size_t i = 0; i < count; ++i) {; // implicit bounds checks:; // if (p + i < p || p + i + 1 > p + count) trap();; p[i] = i;; }; }. ``ConstraintElimination`` collects the following facts and determines if the; bounds checks can be safely removed:. * Inside the for-loop, ``0 <= i < count``, hence ``1 <= i + 1 <= count``.; * Pointer arithmetic ``p + count`` in the if-condition doesn’t wrap.; * ``-fbounds-safety`` treats pointer arithmetic overflow as deterministically; two’s complement computation, not an undefined behavior. Therefore,; getelementptr does not typically have inbounds keyword. However, the compiler; does emit inbounds for ``p + count`` in this case because; ``_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst:6502,redund,redundant,6502,interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,1,['redund'],['redundant']
Safety,", ARC is not exception-safe for normal releases:. * It does not end the lifetime of ``__strong`` variables when their scopes are; abnormally terminated by an exception.; * It does not perform releases which would occur at the end of a; full-expression if that full-expression throws an exception. A program may be compiled with the option ``-fobjc-arc-exceptions`` in order to; enable these, or with the option ``-fno-objc-arc-exceptions`` to explicitly; disable them, with the last such argument ""winning"". .. admonition:: Rationale. The standard Cocoa convention is that exceptions signal programmer error and; are not intended to be recovered from. Making code exceptions-safe by; default would impose severe runtime and code size penalties on code that; typically does not actually care about exceptions safety. Therefore,; ARC-generated code leaks by default on exceptions, which is just fine if the; process is going to be immediately terminated anyway. Programs which do care; about recovering from exceptions should enable the option. In Objective-C++, ``-fobjc-arc-exceptions`` is enabled by default. .. admonition:: Rationale. C++ already introduces pervasive exceptions-cleanup code of the sort that ARC; introduces. C++ programmers who have not already disabled exceptions are; much more likely to actual require exception-safety. ARC does end the lifetimes of ``__weak`` objects when an exception terminates; their scope unless exceptions are disabled in the compiler. .. admonition:: Rationale. The consequence of a local ``__weak`` object not being destroyed is very; likely to be corruption of the Objective-C runtime, so we want to be safer; here. Of course, potentially massive leaks are about as likely to take down; the process as this corruption is if the program does try to recover from; exceptions. .. _arc.misc.interior:. Interior pointers; -----------------. An Objective-C method returning a non-retainable pointer may be annotated with; the ``objc_returns_inner_pointer`` a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:98702,recover,recovering,98702,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['recover'],['recovering']
Safety,", TEXT(""C:\\Program Files\\App -L -S""),; NULL, NULL, TRUE, 0, NULL, NULL, &si, π);; // warn; }. WinAPI.LoadLibrary; (C); The SearchPath() function is used to retrieve a path to a DLL for; a subsequent LoadLibrary() call.; Source: ; MSDN: LoadLibrary function, Security Remarks. #include <windows.h>. HINSTANCE test() {; char filePath[100];; SearchPath(NULL, ""file.dll"", NULL, 100, filePath, NULL);; return LoadLibrary(filePath); // warn; }. WinAPI.WideCharToMultiByte; (C); Buffer overrun while calling WideCharToMultiByte(). The size of; the input buffer equals the number of characters in the Unicode string, while; the size of the output buffer equals the number of bytes.; Source: ; MSDN: WideCharToMultiByte function. #include <windows.h>. void test() {; wchar_t ws[] = L""abc"";; char s[3];; WideCharToMultiByte(CP_UTF8, 0, ws, -1, s,; 3, NULL, NULL); // warn; }. optimization. Name, DescriptionExampleProgress. optimization.PassConstObjByValue; (C, C++); Optimization: It is more effective to pass constant parameter by reference to; avoid unnecessary object copying. struct A {};. void f(const struct A a); // warn. optimization.PostfixIncIter; (C++); Optimization: It is more effective to use prefix increment operator with; iterator.; Source: Scott Meyers ""More Effective C++"", item 6:; Distinguish between prefix and postfix forms of increment and decrement; operators. #include <vector>. void test() {; std::vector<int> v;; std::vector<int>::const_iterator it;; for(it = v.begin();; it != v.end(); it++) {}; // warn; }. optimization.MultipleCallsStrlen; (C); Optimization: multiple calls to strlen() for a string in an; expression. It is more effective to hold a value returned; from strlen() in a temporary variable. #include <string.h>. void test(const char* s) {; if (strlen(s) > 0 &&; strlen(s) < 7) {}; // warn; }. optimization.StrLengthCalculation; (C++); Optimization: it is more efficient to use string::length() to; calculate the length of an std::string. #include <string>; #includ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:27387,avoid,avoid,27387,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,1,['avoid'],['avoid']
Safety,", `GenVector` provides class templates for; modeling the vectors. The user can control how the vector is internally; represented. This is expressed by a choice of coordinate system, which; is supplied as a template parameter when the vector is constructed.; Furthermore, each coordinate system is itself a template, so that the; user can specify the underlying scalar type. The `GenVector` classes do not inherit from **`TObject`**, therefore; cannot be used as in the case of the physics vector classes in ROOT; collections. In addition, to optimize performances, no virtual destructors are; provided. In the following paragraphs, the main characteristics of; `GenVector` are described. A more detailed description of all the; `GenVector` classes is available also at; <http://seal.cern.ch/documents/mathlib/GenVector.pdf>. ### Main Characteristics. #### Optimal Runtime Performances. We try to minimize any overhead in the run-time performance. We have; deliberately avoided the use of any virtual function and even virtual; destructors in the classes. In addition, as much as possible functions; are defined as inline. For this reason, we have chosen to use template; classes to implement the `GenVector` concepts instead of abstract or; base classes and virtual functions. It is then recommended to avoid; using the `GenVector` classes polymorphically and developing classes; inheriting from them. #### Points and Vector Concept. Mathematically vectors and points are two distinct concepts. They have; different transformations, as vectors only rotate while points rotate; and translate. You can add two vectors but not two points and the; difference between two points is a vector. We then distinguish for the 3; dimensional case, between points and vectors, modeling them with; different classes:. - `ROOT::Math::`**`DisplacementVector2D`** and; `ROOT::Math::`**`DisplacementVector3D`** template classes describing; 2 and 3 component direction and magnitude vectors, not rooted at any; particul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:69003,avoid,avoided,69003,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['avoid'],['avoided']
Safety,", and when they are; violated, a warning is emitted. Postconditions are added to the analysis, e.g.; that the return value of a function is not greater than 255. Preconditions are; added to the analysis too, in the case when the affected values are not known; before the call. For example, if an argument to a function must be in between 0 and 255, but the; value of the argument is unknown, the analyzer will assume that it is in this; interval. Similarly, if a function mustn't be called with a null pointer and the; analyzer cannot prove that it is null, then it will assume that it is non-null. These are the possible checks on the values passed as function arguments:; - The argument has an allowed range (or multiple ranges) of values. The checker; can detect if a passed value is outside of the allowed range and show the; actual and allowed values.; - The argument has pointer type and is not allowed to be null pointer. Many; (but not all) standard functions can produce undefined behavior if a null; pointer is passed, these cases can be detected by the checker.; - The argument is a pointer to a memory block and the minimal size of this; buffer is determined by another argument to the function, or by; multiplication of two arguments (like at function ``fread``), or is a fixed; value (for example ``asctime_r`` requires at least a buffer of size 26). The; checker can detect if the buffer size is too small and in optimal case show; the size of the buffer and the values of the corresponding arguments. .. code-block:: c. #define EOF -1; void test_alnum_concrete(int v) {; int ret = isalnum(256); // \; // warning: Function argument outside of allowed range; (void)ret;; }. void buffer_size_violation(FILE *file) {; enum { BUFFER_SIZE = 1024 };; wchar_t wbuf[BUFFER_SIZE];. const size_t size = sizeof(*wbuf); // 4; const size_t nitems = sizeof(wbuf); // 4096. // Below we receive a warning because the 3rd parameter should be the; // number of elements to read, not the size in bytes. T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:32184,detect,detected,32184,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['detect'],['detected']
Safety,", i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 7, i32 7); ret i8 addrspace(1)* %obj.relocated; }. During lowering, this will result in an instruction selection DAG that looks; something like:. ::. CALLSEQ_START; ...; GC_TRANSITION_START (lowered i32 *@Flag), SRCVALUE i32* Flag; STATEPOINT; GC_TRANSITION_END (lowered i32 *@Flag), SRCVALUE i32 *Flag; ...; CALLSEQ_END. In order to generate the necessary transition code, the backend for each target; supported by ""hypothetical-gc"" must be modified to lower ``GC_TRANSITION_START``; and ``GC_TRANSITION_END`` nodes appropriately when the ""hypothetical-gc""; strategy is in use for a particular function. Assuming that such lowering has; been added for X86, the generated assembly would be:. .. code-block:: gas. 	 .globl	test1; 	 .align	16, 0x90; 	 pushq	%rax; 	 movl $1, %fs:Flag@TPOFF; 	 callq	foo; 	 movl $0, %fs:Flag@TPOFF; .Ltmp1:; 	 movq	(%rsp), %rax # This load is redundant (oops!); 	 popq	%rdx; 	 retq. Note that the design as presented above is not fully implemented: in particular,; strategy-specific lowering is not present, and all GC transitions are emitted as; as single no-op before and after the call instruction. These no-ops are often; removed by the backend during dead machine instruction elimination. Before the abstract machine model is lowered to the explicit statepoint model; of relocations by the :ref:`RewriteStatepointsForGC` pass it is possible for; any derived pointer to get its base pointer and offset from the base pointer; by using the ``gc.get.pointer.base`` and the ``gc.get.pointer.offset``; intrinsics respectively. These intrinsics are inlined by the; :ref:`RewriteStatepointsForGC` pass and must not be used after this pass. .. _statepoint-stackmap-format:. Stack Map Format; ================. Locations for each pointer value which may need read and/or updated by; the runtime or collector are provided in a separate section of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:19141,redund,redundant,19141,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['redund'],['redundant']
Safety,", it is; scanned and rebuilt according to the information in the record header.; The recovery algorithm reads the file and creates the saved objects in; memory according to the header information. It then rebuilds the; directory and file structure. If the file is opened in write mode, the; recovery makes the correction on disk when the file is closed; however; if the file is opened in read mode, the correction can not be written to; disk. You can also explicitly invoke the recovery procedure by calling; the `TFile::Recover()` method. You can recover the directory structure,; but you cannot save what you recovered to the file on disk. In the; following example, we interrupted and aborted the previous ROOT session,; causing the file not to be closed. When we start a new session and; attempt to open the file, it gives us an explanation and status on the; recovery attempt. ``` {.cpp}; root[] TFile f(""demo.root""); Warning in <TFile::TFile>: file demo.root probably not closed, trying to recover successfully recovered 15 keys; ```. ## The Logical ROOT File: TFile and TKey. We saw that the `TFile::Map()` method reads the file sequentially and; prints information about each record while scanning the file. It is not; feasible to support only sequential access and hence ROOT provides; random or direct access, i.e. reading a specified object at a time. To; do so, `TFile` keeps a list of **`TKeys`**, which is; essentially an index to the objects in the file. The **`TKey`** class; describes the record headers of objects in the file. For example, we can; get the list of keys and print them. To find a specific object on the; file we can use the **`TFile::Get()` method.**. ``` {.cpp}; root[] TFile f(""demo.root""); root[] f.GetListOfKeys()->Print(); TKey Name = h0, Title = histo nr:0, Cycle = 1; TKey Name = h1, Title = histo nr:1, Cycle = 1; TKey Name = h2, Title = histo nr:2, Cycle = 1; TKey Name = h3, Title = histo nr:3, Cycle = 1; TKey Name = h4, Title = histo nr:4, Cycle = 1; TKey",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:16236,recover,recover,16236,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,2,['recover'],"['recover', 'recovered']"
Safety,", the Clang frontend emits run-time checks for every; memory dereference if the type system or analyses in the frontend couldn’t; verify its bounds safety. The implementation relies on LLVM optimizations to; remove redundant run-time checks. Using this optimization strategy, if the; original source code already has bounds checks, the fewer additional checks; ``-fbounds-safety`` will introduce. The LLVM ``ConstraintElimination`` pass is; design to remove provable redundant checks (please check Florian Hahn’s; presentation in 2021 LLVM Dev Meeting and the implementation to learn more). In; the following example, ``-fbounds-safety`` implicitly adds the redundant bounds; checks that the optimizer can remove:. .. code-block:: c. void fill_array_with_indices(int *__counted_by(count) p, size_t count) {; for (size_t i = 0; i < count; ++i) {; // implicit bounds checks:; // if (p + i < p || p + i + 1 > p + count) trap();; p[i] = i;; }; }. ``ConstraintElimination`` collects the following facts and determines if the; bounds checks can be safely removed:. * Inside the for-loop, ``0 <= i < count``, hence ``1 <= i + 1 <= count``.; * Pointer arithmetic ``p + count`` in the if-condition doesn’t wrap.; * ``-fbounds-safety`` treats pointer arithmetic overflow as deterministically; two’s complement computation, not an undefined behavior. Therefore,; getelementptr does not typically have inbounds keyword. However, the compiler; does emit inbounds for ``p + count`` in this case because; ``__counted_by(count)`` has the invariant that p has at least as many as; elements as count. Using this information, ``ConstraintElimination`` is able; to determine ``p + count`` doesn’t wrap.; * Accordingly, ``p + i`` and ``p + i + 1`` also don’t wrap.; * Therefore, ``p <= p + i`` and ``p + i + 1 <= p + count``.; * The if-condition simplifies to false and becomes dead code that the subsequent; optimization passes can remove. ``OptRemarks`` can be utilized to provide insights into performance tuning. It; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst:7077,safe,safely,7077,interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,1,['safe'],['safely']
Safety,",1; 	blr; ; which is more efficient and can use mfocr. See PR642 for some more context. //===---------------------------------------------------------------------===//. void foo(float *data, float d) {; long i;; for (i = 0; i < 8000; i++); data[i] = d;; }; void foo2(float *data, float d) {; long i;; data--;; for (i = 0; i < 8000; i++) {; data[1] = d;; data++;; }; }. These compile to:. _foo:; 	li r2, 0; LBB1_1:	; bb; 	addi r4, r2, 4; 	stfsx f1, r3, r2; 	cmplwi cr0, r4, 32000; 	mr r2, r4; 	bne cr0, LBB1_1	; bb; 	blr ; _foo2:; 	li r2, 0; LBB2_1:	; bb; 	addi r4, r2, 4; 	stfsx f1, r3, r2; 	cmplwi cr0, r4, 32000; 	mr r2, r4; 	bne cr0, LBB2_1	; bb; 	blr . The 'mr' could be eliminated to folding the add into the cmp better. //===---------------------------------------------------------------------===//; Codegen for the following (low-probability) case deteriorated considerably ; when the correctness fixes for unordered comparisons went in (PR 642, 58871).; It should be possible to recover the code quality described in the comments. ; RUN: llvm-as < %s | llc -march=ppc32 | grep or | count 3; ; This should produce one 'or' or 'cror' instruction per function. ; RUN: llvm-as < %s | llc -march=ppc32 | grep mfcr | count 3; ; PR2964. define i32 @test(double %x, double %y) nounwind {; entry:; 	%tmp3 = fcmp ole double %x, %y		; <i1> [#uses=1]; 	%tmp345 = zext i1 %tmp3 to i32		; <i32> [#uses=1]; 	ret i32 %tmp345; }. define i32 @test2(double %x, double %y) nounwind {; entry:; 	%tmp3 = fcmp one double %x, %y		; <i1> [#uses=1]; 	%tmp345 = zext i1 %tmp3 to i32		; <i32> [#uses=1]; 	ret i32 %tmp345; }. define i32 @test3(double %x, double %y) nounwind {; entry:; 	%tmp3 = fcmp ugt double %x, %y		; <i1> [#uses=1]; 	%tmp34 = zext i1 %tmp3 to i32		; <i32> [#uses=1]; 	ret i32 %tmp34; }. //===---------------------------------------------------------------------===//; for the following code:. void foo (float *__restrict__ a, int *__restrict__ b, int n) {; a[n] = b[n] * 2.321;; }. we load b[n] to G",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt:11187,recover,recover,11187,interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,1,['recover'],['recover']
Safety,",; AddModel({GaussModel(dt,biasC[-10,10],sigmaC[0.1,3],dterr[0.01,0.2]),; GaussModel(dt,0,sigmaT[3,10]),; GaussModel(dt,0,20)},{fracC[0,1],fracT[0,1]}),; DoubleSided ),; Gaussian::sig_m( mes[5.20,5.30], mB0[5.20,5.30], sigmB0[0.01,0.05] )"". This create a double-sided Bmixing decay p.d.f. with observables dt,; per-event error dterr and all its parameters, convoluted with a triple; gaussian resolution model and multiplied with a Gaussian p.d.f. in the; energy substituted mass. (In plain RooFit this would have required at; least 23 lines of code). A series of three new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling al",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:21672,detect,detected,21672,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,1,['detect'],['detected']
Safety,",; Bool_t comp_safe=kFALSE);; ```. The meaning of the parameters here is the same as for FindNextBoundary,; but the safety value is triggered by an input flag. The output is the; node after the boundary crossing. #### Computing the Safe Radius. Other important navigation query for tracking is the computation of the; safe distance. This represents the `maximum` step that can be made from; the current point in `any direction` that assures that no boundary will; be crossed. Knowing this value gives additional freedom to the stepping; algorithm to propagate the current track on the corresponding range; `without checking` if the current state has changed. In other words, the; modeller insures that the current state does not change in any point; within the safety radius around the current point. The computation of the safe radius is `automatically` computed any time; when the next boundary is queried within a `limited step:`. ``` {.cpp}; TGeoNode *crossed = gGeoManager->FindNextBoundary(pstep);; Double_t safety = gGeoManager->GetSafeDistance();; ```. Otherwise, the computation of safety can always be forced:. ``` {.cpp}; Double_t safety = gGeoManager->Safety();; ```. #### Making a Step. The modeller is able to make steps starting from the current point along; the current direction and having the current step length. The new point; and its corresponding state will be automatically computed:. ``` {.cpp}; TGeoNode *TGeoManager::Step(Bool_t is_geom = kTRUE,; Bool_t cross = kTRUE);; ```. We will explain the method above by its use cases. The input flag; `is_geom` allows specifying if the step is limited by geometrical; reasons (a boundary crossing) or is an arbitrary step. The flag cross; can be used in case the step is made on a boundary and specifies if user; wants to cross or not the boundary. The returned node represents the new; current node after the step was made. - Making a geometrically contained step with boundary crossing; (`is_geom=kTRUE`, `cross=kTRUE`) - This is ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:119759,safe,safety,119759,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['safe'],['safety']
Safety,",; but %entry is not contained in the loop).; Note that a loop has to be in Loop Simplify Form beforehand; too for LoopRotate to be applied successfully. The main advantage of this form is that it allows hoisting; invariant instructions, especially loads, into the preheader.; That could be done in non-rotated loops as well but with; some disadvantages. Let's illustrate them with an example:. .. code-block:: C. for (int i = 0; i < n; ++i) {; auto v = *p;; use(v);; }. We assume that loading from p is invariant and use(v) is some; statement that uses v.; If we wanted to execute the load only once we could move it; ""out"" of the loop body, resulting in this:. .. code-block:: C. auto v = *p;; for (int i = 0; i < n; ++i) {; use(v);; }. However, now, in the case that n <= 0, in the initial form,; the loop body would never execute, and so, the load would; never execute. This is a problem mainly for semantic reasons.; Consider the case in which n <= 0 and loading from p is invalid.; In the initial program there would be no error. However, with this; transformation we would introduce one, effectively breaking; the initial semantics. To avoid both of these problems, we can insert a guard:. .. code-block:: C. if (n > 0) { // loop guard; auto v = *p;; for (int i = 0; i < n; ++i) {; use(v);; }; }. This is certainly better but it could be improved slightly. Notice; that the check for whether n is bigger than 0 is executed twice (and; n does not change in between). Once when we check the guard condition; and once in the first execution of the loop. To avoid that, we could; do an unconditional first execution and insert the loop condition; in the end. This effectively means transforming the loop into a do-while loop:. .. code-block:: C. if (0 < n) {; auto v = *p;; do {; use(v);; ++i;; } while (i < n);; }. Note that LoopRotate does not generally do such; hoisting. Rather, it is an enabling transformation for other; passes like Loop-Invariant Code Motion (:ref:`-licm <passes-licm>`).; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:23151,avoid,avoid,23151,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,2,['avoid'],['avoid']
Safety,",; but the safety value is triggered by an input flag. The output is the; node after the boundary crossing. \anchor GP02gc; #### Computing the Safe Radius. Other important navigation query for tracking is the computation of the; safe distance. This represents the `maximum` step that can be made from; the current point in `any direction` that assures that no boundary will; be crossed. Knowing this value gives additional freedom to the stepping; algorithm to propagate the current track on the corresponding range; `without checking` if the current state has changed. In other words, the; modeller insures that the current state does not change in any point; within the safety radius around the current point. The computation of the safe radius is `automatically` computed any time; when the next boundary is queried within a `limited step:`. ~~~{.cpp}; TGeoNode *crossed = gGeoManager->FindNextBoundary(pstep);; Double_t safety = gGeoManager->GetSafeDistance();; ~~~. Otherwise, the computation of safety can always be forced:. ~~~{.cpp}; Double_t safety = gGeoManager->Safety();; ~~~. \anchor GP02gd; #### Making a Step. The modeller is able to make steps starting from the current point along; the current direction and having the current step length. The new point; and its corresponding state will be automatically computed:. ~~~{.cpp}; TGeoNode *TGeoManager::Step(Bool_t is_geom = kTRUE,; Bool_t cross = kTRUE);; ~~~. We will explain the method above by its use cases. The input flag; `is_geom` allows specifying if the step is limited by geometrical; reasons (a boundary crossing) or is an arbitrary step. The flag cross; can be used in case the step is made on a boundary and specifies if user; wants to cross or not the boundary. The returned node represents the new; current node after the step was made. - Making a geometrically contained step with boundary crossing; (`is_geom=kTRUE`, `cross=kTRUE`) - This is the default method; behavior. In this case, the step size is supposed to be ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:80297,safe,safety,80297,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['safe'],['safety']
Safety,",DY` and `DZ `half-lengths a point will be; considered inside if:. `-DX <= point[0] <= DX`. `-DY <= point[1] <= DY`. `-DZ <= point[2] <= DZ`. ``` {.cpp}; Double_t TGeoShape::DistFromInside(Double_t *point[3],; Double_t *dir[3], Int_t iact,Double_t step,Double_t *safe);; ```. The method computes the distance to exiting a shape from a given point; `inside`, along a given direction. This direction is given by its; director cosines with respect to the local shape coordinate system. This; method provides additional information according the value of `iact`; input parameter:. - `iact = 0`computes only safe distance and fill it at the location; given by SAFE;; - `iact = 1`a proposed STEP is supplied. The safe distance is computed; first. If this is bigger than STEP than the proposed step is; approved and returned by the method since it does not cross the; shape boundaries. Otherwise, the distance to exiting the shape is; computed and returned;; - `iact = 2`computes both safe distance and distance to exiting,; ignoring the proposed step;; - `iact > 2`computes only the distance to exiting, ignoring anything; else. ``` {.cpp}; Double_t TGeoShape::DistFromOutside(Double_t *point[3],; Double_t *dir[3],Int_t iact,Double_t step,Double_t *safe);; ```. This method computes the distance to entering a shape from a given point; `outside`. It acts in the same way as the previous method. ``` {.cpp}; Double_t TGeoShape::Safety(Double_t *point[3],Bool_t inside);; ```. This computes the maximum shift of a point in any direction that does; not change its `inside/outside `state (does not cross shape boundaries).; The state of the point has to be properly supplied. ``` {.cpp}; Double_t *TGeoShape::ComputeNormal(Double_t *point[3],; Double_t *dir[3],Double_t *norm[3]);; ```. The method above computes the director cosines of normal to the crossed; shape surface from a given point towards direction. This is filled into; the `norm` array, supplied by the user. The normal vector is always; chosen ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:51561,safe,safe,51561,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['safe'],['safe']
Safety,",DY` and `DZ `half-lengths a point will be; considered inside if:. `-DX <= point[0] <= DX`. `-DY <= point[1] <= DY`. `-DZ <= point[2] <= DZ`. ~~~ {.cpp}; Double_t TGeoShape::DistFromInside(Double_t *point[3],; Double_t *dir[3], Int_t iact,Double_t step,Double_t *safe);; ~~~. The method computes the distance to exiting a shape from a given point; `inside`, along a given direction. This direction is given by its; director cosines with respect to the local shape coordinate system. This; method provides additional information according the value of `iact`; input parameter:. - `iact = 0`computes only safe distance and fill it at the location; given by SAFE;; - `iact = 1`a proposed STEP is supplied. The safe distance is computed; first. If this is bigger than STEP than the proposed step is; approved and returned by the method since it does not cross the; shape boundaries. Otherwise, the distance to exiting the shape is; computed and returned;; - `iact = 2`computes both safe distance and distance to exiting,; ignoring the proposed step;; - `iact > 2`computes only the distance to exiting, ignoring anything; else. ~~~ {.cpp}; Double_t TGeoShape::DistFromOutside(Double_t *point[3],; Double_t *dir[3],Int_t iact,Double_t step,Double_t *safe);; ~~~. This method computes the distance to entering a shape from a given point; `outside`. It acts in the same way as the previous method. ~~~ {.cpp}; Double_t TGeoShape::Safety(Double_t *point[3],Bool_t inside);; ~~~. This computes the maximum shift of a point in any direction that does; not change its `inside/outside `state (does not cross shape boundaries).; The state of the point has to be properly supplied. ~~~ {.cpp}; Double_t *TGeoShape::ComputeNormal(Double_t *point[3],; Double_t *dir[3],Double_t *norm[3]);; ~~~. The method above computes the director cosines of normal to the crossed; shape surface from a given point towards direction. This is filled into; the `norm` array, supplied by the user. The normal vector is always; chosen ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:5277,safe,safe,5277,geom/geom/doc/shapes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md,1,['safe'],['safe']
Safety,"-+--------------+-----------------------------------------------+; | Field | Size (bytes) | Description |; +===============+==============+===============================================+; | seconds | ``8`` | Seconds on absolute timescale. The starting |; | | | point is unspecified and depends on the |; | | | implementation and platform configured by the |; | | | tracer. |; +---------------+--------------+-----------------------------------------------+; | microseconds | ``4`` | The microsecond component of the time. |; +---------------+--------------+-----------------------------------------------+; | reserved | ``3`` | Unused. |; +---------------+--------------+-----------------------------------------------+. NewCpuId Records; ----------------. Each function entry invokes a routine to determine what CPU is executing.; Typically, this is done with readtscp, which reads the timestamp counter at the; same time. If the tracing detects that the execution has switched CPUs or if this is the; first instrumented entry point, the tracer will output a NewCpuId record. Its data segment is as follows. +---------------+--------------+-----------------------------------------------+; | Field | Size (bytes) | Description |; +===============+==============+===============================================+; | cpu_id | ``2`` | CPU Id. |; +---------------+--------------+-----------------------------------------------+; | absolute_tsc | ``8`` | The absolute value of the timestamp counter. |; +---------------+--------------+-----------------------------------------------+; | reserved | ``5`` | Unused. |; +---------------+--------------+-----------------------------------------------+. TSCWrap Records; ---------------. Since each function record uses a 32 bit value to represent the number of ticks; of the timestamp counter since the last reference, it is possible for this value; to overflow, particularly for sparsely instrumented binaries. When this delta would not fit into a 32 bit rep",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:11697,detect,detects,11697,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,1,['detect'],['detects']
Safety,"-----+--------+-------------------+; (MSB) (LSB). Size modifier is one of. ::. BPF_W 0x0 word; BPF_H 0x1 half word; BPF_B 0x2 byte; BPF_DW 0x3 double word. Mode modifier is one of. ::. BPF_IMM 0x0 immediate; BPF_ABS 0x1 used to access packet data; BPF_IND 0x2 used to access packet data; BPF_MEM 0x3 memory; (reserved) 0x4; (reserved) 0x5; BPF_XADD 0x6 exclusive add. Packet data access (BPF_ABS, BPF_IND); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Two non-generic instructions: (BPF_ABS | <size> | BPF_LD) and; (BPF_IND | <size> | BPF_LD) which are used to access packet data.; Register R6 is an implicit input that must contain pointer to sk_buff.; Register R0 is an implicit output which contains the data fetched; from the packet. Registers R1-R5 are scratch registers and must not; be used to store the data across BPF_ABS | BPF_LD or BPF_IND | BPF_LD; instructions. These instructions have implicit program exit condition; as well. When eBPF program is trying to access the data beyond; the packet boundary, the interpreter will abort the execution of the program. BPF_IND | BPF_W | BPF_LD is equivalent to:; R0 = ntohl(\*(u32 \*) (((struct sk_buff \*) R6)->data + src_reg + imm32)). eBPF maps; ^^^^^^^^^. eBPF maps are provided for sharing data between kernel and user-space.; Currently implemented types are hash and array, with potential extension to; support bloom filters, radix trees, etc. A map is defined by its type,; maximum number of elements, key size and value size in bytes. eBPF syscall; supports create, update, find and delete functions on maps. Function calls; ^^^^^^^^^^^^^^. Function call arguments are passed using up to five registers (R1 - R5).; The return value is passed in a dedicated register (R0). Four additional; registers (R6 - R9) are callee-saved, and the values in these registers; are preserved within kernel functions. R0 - R5 are scratch registers within; kernel functions, and eBPF programs must therefor store/restore values in; these registers if needed acro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:106320,abort,abort,106320,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['abort'],['abort']
Safety,-----+----------+-------+---------+-------------+----------+------------+; | *in | |v| | | | |x| | |x| | |x| | |x| | |x| |; | calls* | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *before | |v| | | | | | | |x| | |x| |; | calls* | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *for | NO | | | | | | **N** | **N** |; | loops* | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *before | |v| | | | | | | |x| | |x| |; | escape* | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | emit code | NO | | | | | | **N** | **N** |; | at safe | | | | | | | | |; | points | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | **output** | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *assembly* | |v| | | | |x| | |x| | |x| | |x| | |x| |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *JIT* | NO | | | **?** | **?** | **?** | **?** | **?** |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *obj* | NO | | | **?** | **?** | **?** | **?** | **?** |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | live | NO | | | **?** | **?** | **?** | **?** | **?** |; | analysis | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | register | NO | | | **?** | **?** | **?** | **?** | **?** |; | map | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | \* Derived pointers only pose a hazard to copying collections.,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:29697,hazard,hazard,29697,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['hazard'],['hazard']
Safety,-----------+----------+------------+; | initialize | |v| | |x| | |x| | |x| | |x| | |x| | |x| | |x| |; | roots | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | derived | NO | | | | | | **N**\* | **N**\* |; | pointers | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | **custom | |v| | | | | | | | |; | lowering** | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *gcroot* | |v| | |x| | |x| | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *gcwrite* | |v| | | |x| | | | |x| | | |x| |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *gcread* | |v| | | | | | | | |x| |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | **safe | | | | | | | | |; | points** | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *in | |v| | | | |x| | |x| | |x| | |x| | |x| |; | calls* | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *before | |v| | | | | | | |x| | |x| |; | calls* | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *for | NO | | | | | | **N** | **N** |; | loops* | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *before | |v| | | | | | | |x| | |x| |; | escape* | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | emit code | NO | | | | | | **N** | **N** |; | at safe | | | | | | | | |; | points | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:27648,safe,safe,27648,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['safe'],['safe']
Safety,"-----------------------------------+; | M_DECAY_TIME | Sets the release interval option to the specified |; | | value (Android only allows 0 or 1 to respectively set |; | | the interval to the minimum and maximum value as |; | | specified at compile time). |; +---------------------------+-------------------------------------------------------+; | M_PURGE | Forces immediate memory reclaiming but does not |; | | reclaim everything. For smaller size classes, there |; | | is still some memory that is not reclaimed due to the |; | | extra time it takes and the small amount of memory |; | | that can be reclaimed. |; | | The value is ignored. |; +---------------------------+-------------------------------------------------------+; | M_PURGE_ALL | Same as M_PURGE but will force release all possible |; | | memory regardless of how long it takes. |; | | The value is ignored. |; +---------------------------+-------------------------------------------------------+; | M_MEMTAG_TUNING | Tunes the allocator's choice of memory tags to make |; | | it more likely that a certain class of memory errors |; | | will be detected. The value argument should be one of |; | | the enumerators of ``scudo_memtag_tuning``. |; +---------------------------+-------------------------------------------------------+; | M_THREAD_DISABLE_MEM_INIT | Tunes the per-thread memory initialization, 0 being |; | | the normal behavior, 1 disabling the automatic heap |; | | initialization. |; +---------------------------+-------------------------------------------------------+; | M_CACHE_COUNT_MAX | Set the maximum number of entries than can be cached |; | | in the Secondary cache. |; +---------------------------+-------------------------------------------------------+; | M_CACHE_SIZE_MAX | Sets the maximum size of entries that can be cached |; | | in the Secondary cache. |; +---------------------------+-------------------------------------------------------+; | M_TSDS_COUNT_MAX | Increases the maximum number of TS",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:13479,detect,detected,13479,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['detect'],['detected']
Safety,"---------------------------------------------------+; | M_THREAD_DISABLE_MEM_INIT | Tunes the per-thread memory initialization, 0 being |; | | the normal behavior, 1 disabling the automatic heap |; | | initialization. |; +---------------------------+-------------------------------------------------------+; | M_CACHE_COUNT_MAX | Set the maximum number of entries than can be cached |; | | in the Secondary cache. |; +---------------------------+-------------------------------------------------------+; | M_CACHE_SIZE_MAX | Sets the maximum size of entries that can be cached |; | | in the Secondary cache. |; +---------------------------+-------------------------------------------------------+; | M_TSDS_COUNT_MAX | Increases the maximum number of TSDs that can be used |; | | up to the limit specified at compile time. |; +---------------------------+-------------------------------------------------------+. Error Types; ===========. The allocator will output an error message, and potentially terminate the; process, when an unexpected behavior is detected. The output usually starts with; ``""Scudo ERROR:""`` followed by a short summary of the problem that occurred as; well as the pointer(s) involved. Once again, Scudo is meant to be a mitigation,; and might not be the most useful of tools to help you root-cause the issue,; please consider `ASan <https://github.com/google/sanitizers/wiki/AddressSanitizer>`_; for this purpose. Here is a list of the current error messages and their potential cause:. - ``""corrupted chunk header""``: the checksum verification of the chunk header; has failed. This is likely due to one of two things: the header was; overwritten (partially or totally), or the pointer passed to the function is; not a chunk at all;. - ``""race on chunk header""``: two different threads are attempting to manipulate; the same header at the same time. This is usually symptomatic of a; race-condition or general lack of locking when performing operations on that; chunk;. - ``""in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:14666,detect,detected,14666,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['detect'],['detected']
Safety,"---------------------------------------------------------------------. Yes, libFuzzer now supports Windows. Initial support was added in r341082.; Any build of Clang 9 supports it. You can download a build of Clang for Windows; that has libFuzzer from; `LLVM Snapshot Builds <https://llvm.org/builds/>`_. Using libFuzzer on Windows without ASAN is unsupported. Building fuzzers with the; ``/MD`` (dynamic runtime library) compile option is unsupported. Support for these; may be added in the future. Linking fuzzers with the ``/INCREMENTAL`` link option; (or the ``/DEBUG`` option which implies it) is also unsupported. Send any questions or comments to the mailing list: libfuzzer(#)googlegroups.com. Q. When libFuzzer is not a good solution for a problem?; ---------------------------------------------------------. * If the test inputs are validated by the target library and the validator; asserts/crashes on invalid inputs, in-process fuzzing is not applicable.; * Bugs in the target library may accumulate without being detected. E.g. a memory; corruption that goes undetected at first and then leads to a crash while; testing another input. This is why it is highly recommended to run this; in-process fuzzer with all sanitizers to detect most bugs on the spot.; * It is harder to protect the in-process fuzzer from excessive memory; consumption and infinite loops in the target library (still possible).; * The target library should not have significant global state that is not; reset between the runs.; * Many interesting target libraries are not designed in a way that supports; the in-process fuzzer interface (e.g. require a file path instead of a; byte array).; * If a single test run takes a considerable fraction of a second (or; more) the speed benefit from the in-process fuzzer is negligible.; * If the target library runs persistent threads (that outlive; execution of one test) the fuzzing results will be unreliable. Q. So, what exactly this Fuzzer is good for?; ----------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:29579,detect,detected,29579,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['detect'],['detected']
Safety,"---------------------------------------------------------------------===//. With a copying garbage collector, derived pointers must not be retained across; collector safe points; the collector could move the objects and invalidate the; derived pointer. This is bad enough in the first place, but safe points can; crop up unpredictably. Consider:. %array = load { i32, [0 x %obj] }** %array_addr; %nth_el = getelementptr { i32, [0 x %obj] }* %array, i32 0, i32 %n; %old = load %obj** %nth_el; %z = div i64 %x, %y; store %obj* %new, %obj** %nth_el. If the i64 division is lowered to a libcall, then a safe point will (must); appear for the call site. If a collection occurs, %array and %nth_el no longer; point into the correct object. The fix for this is to copy address calculations so that dependent pointers; are never live across safe point boundaries. But the loads cannot be copied; like this if there was an intervening store, so may be hard to get right. Only a concurrent mutator can trigger a collection at the libcall safe point.; So single-threaded programs do not have this requirement, even with a copying; collector. Still, LLVM optimizations would probably undo a front-end's careful; work. //===---------------------------------------------------------------------===//. The ocaml frametable structure supports liveness information. It would be good; to support it. //===---------------------------------------------------------------------===//. The FIXME in ComputeCommonTailLength in BranchFolding.cpp needs to be; revisited. The check is there to work around a misuse of directives in inline; assembly. //===---------------------------------------------------------------------===//. It would be good to detect collector/target compatibility instead of silently; doing the wrong thing. //===---------------------------------------------------------------------===//. It would be really nice to be able to write patterns in .td files for copies,; which would eliminate a bunch of e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:3658,safe,safe,3658,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,1,['safe'],['safe']
Safety,"-------------------------------------------------------------------===//. This was noticed in the entryblock for grokdeclarator in 403.gcc:. %tmp = icmp eq i32 %decl_context, 4 ; %decl_context_addr.0 = select i1 %tmp, i32 3, i32 %decl_context ; %tmp1 = icmp eq i32 %decl_context_addr.0, 1 ; %decl_context_addr.1 = select i1 %tmp1, i32 0, i32 %decl_context_addr.0. tmp1 should be simplified to something like:; (!tmp || decl_context == 1). This allows recursive simplifications, tmp1 is used all over the place in; the function, e.g. by:. %tmp23 = icmp eq i32 %decl_context_addr.1, 0 ; <i1> [#uses=1]; %tmp24 = xor i1 %tmp1, true ; <i1> [#uses=1]; %or.cond8 = and i1 %tmp23, %tmp24 ; <i1> [#uses=1]. later. //===---------------------------------------------------------------------===//. [STORE SINKING]. Store sinking: This code:. void f (int n, int *cond, int *res) {; int i;; *res = 0;; for (i = 0; i < n; i++); if (*cond); *res ^= 234; /* (*) */; }. On this function GVN hoists the fully redundant value of *res, but nothing; moves the store out. This gives us this code:. bb:		; preds = %bb2, %entry; 	%.rle = phi i32 [ 0, %entry ], [ %.rle6, %bb2 ]	; 	%i.05 = phi i32 [ 0, %entry ], [ %indvar.next, %bb2 ]; 	%1 = load i32* %cond, align 4; 	%2 = icmp eq i32 %1, 0; 	br i1 %2, label %bb2, label %bb1. bb1:		; preds = %bb; 	%3 = xor i32 %.rle, 234	; 	store i32 %3, i32* %res, align 4; 	br label %bb2. bb2:		; preds = %bb, %bb1; 	%.rle6 = phi i32 [ %3, %bb1 ], [ %.rle, %bb ]	; 	%indvar.next = add i32 %i.05, 1	; 	%exitcond = icmp eq i32 %indvar.next, %n; 	br i1 %exitcond, label %return, label %bb. DSE should sink partially dead stores to get the store out of the loop. Here's another partial dead case:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12395. //===---------------------------------------------------------------------===//. Scalar PRE hoists the mul in the common block up to the else:. int test (int a, int b, int c, int g) {; int d, e;; if (a); d = b * c;; else; d = b - c;; e = b * ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:28581,redund,redundant,28581,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['redund'],['redundant']
Safety,"------------------------------------------------------===//. The hot loop of 256.bzip2 contains code that looks a bit like this:. int foo(char *P, char *Q, int x, int y) {; if (P[0] != Q[0]); return P[0] < Q[0];; if (P[1] != Q[1]); return P[1] < Q[1];; if (P[2] != Q[2]); return P[2] < Q[2];; return P[3] < Q[3];; }. In the real code, we get a lot more wrong than this. However, even in this; code we generate:. _foo: ## @foo; ## %bb.0: ## %entry; 	movb	(%rsi), %al; 	movb	(%rdi), %cl; 	cmpb	%al, %cl; 	je	LBB0_2; LBB0_1: ## %if.then; 	cmpb	%al, %cl; 	jmp	LBB0_5; LBB0_2: ## %if.end; 	movb	1(%rsi), %al; 	movb	1(%rdi), %cl; 	cmpb	%al, %cl; 	jne	LBB0_1; ## %bb.3: ## %if.end38; 	movb	2(%rsi), %al; 	movb	2(%rdi), %cl; 	cmpb	%al, %cl; 	jne	LBB0_1; ## %bb.4: ## %if.end60; 	movb	3(%rdi), %al; 	cmpb	3(%rsi), %al; LBB0_5: ## %if.end60; 	setl	%al; 	movzbl	%al, %eax; 	ret. Note that we generate jumps to LBB0_1 which does a redundant compare. The; redundant compare also forces the register values to be live, which prevents; folding one of the loads into the compare. In contrast, GCC 4.2 produces:. _foo:; 	movzbl	(%rsi), %eax; 	cmpb	%al, (%rdi); 	jne	L10; L12:; 	movzbl	1(%rsi), %eax; 	cmpb	%al, 1(%rdi); 	jne	L10; 	movzbl	2(%rsi), %eax; 	cmpb	%al, 2(%rdi); 	jne	L10; 	movzbl	3(%rdi), %eax; 	cmpb	3(%rsi), %al; L10:; 	setl	%al; 	movzbl	%al, %eax; 	ret. which is ""perfect"". //===---------------------------------------------------------------------===//. For the branch in the following code:; int a();; int b(int x, int y) {; if (x & (1<<(y&7))); return a();; return y;; }. We currently generate:; 	movb	%sil, %al; 	andb	$7, %al; 	movzbl	%al, %eax; 	btl	%eax, %edi; 	jae	.LBB0_2. movl+andl would be shorter than the movb+andb+movzbl sequence. //===---------------------------------------------------------------------===//. For the following:; struct u1 {; float x, y;; };; float foo(struct u1 u) {; return u.x + u.y;; }. We currently generate:; 	movdqa	%xmm0, %xmm1; 	pshufd	$1, %xmm0, %xmm0 # xmm0 = ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:40599,redund,redundant,40599,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['redund'],['redundant']
Safety,"----------------------------------------. In general, ARC does not perform retain or release operations when simply using; a retainable object pointer as an operand within an expression. This includes:. * loading a retainable pointer from an object with non-weak :ref:`ownership; <arc.ownership>`,; * passing a retainable pointer as an argument to a function or method, and; * receiving a retainable pointer as the result of a function or method call. .. admonition:: Rationale. While this might seem uncontroversial, it is actually unsafe when multiple; expressions are evaluated in ""parallel"", as with binary operators and calls,; because (for example) one expression might load from an object while another; writes to it. However, C and C++ already call this undefined behavior; because the evaluations are unsequenced, and ARC simply exploits that here to; avoid needing to retain arguments across a large number of calls. The remainder of this section describes exceptions to these rules, how those; exceptions are detected, and what those exceptions imply semantically. .. _arc.objects.operands.consumed:. Consumed parameters; ^^^^^^^^^^^^^^^^^^^. A function or method parameter of retainable object pointer type may be marked; as :arc-term:`consumed`, signifying that the callee expects to take ownership; of a +1 retain count. This is done by adding the ``ns_consumed`` attribute to; the parameter declaration, like so:. .. code-block:: objc. void foo(__attribute((ns_consumed)) id x);; - (void) foo: (id) __attribute((ns_consumed)) x;. This attribute is part of the type of the function or method, not the type of; the parameter. It controls only how the argument is passed and received. When passing such an argument, ARC retains the argument prior to making the; call. When receiving such an argument, ARC releases the argument at the end of the; function, subject to the usual optimizations for local values. .. admonition:: Rationale. This formalizes direct transfers of ownership from a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:16467,detect,detected,16467,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['detect'],['detected']
Safety,"---------------------------------------|----------------------------------------------------------------|; | `RooCategory cat(""cat"", ""Lepton flavour"");` | `RooCategory cat(""cat"", ""Lepton flavour"");` |; | `cat[""electron""] = 1;` | `cat.defineType(""electron"", 1);` |; | `cat[""muon""] = 2;` | `cat.defineType(""muon"", 2);` |. See also [Category reference guide](https://root.cern.ch/doc/master/classRooCategory.html). ### Type-safe proxies for RooFit objects; RooFit's proxy classes have been modernised. The class `RooTemplateProxy` allows for access to other RooFit objects; similarly to a smart pointer. In older versions of RooFit, the objects held by *e.g.* `RooRealProxy` had to be; accessed like this:; RooAbsArg* absArg = realProxy.absArg();; RooAbsPdf* pdf = dynamic_cast<RooAbsPdf*>(absArg);; assert(pdf); // This *should* work, but the proxy doesn't have a way to check; pdf->fitTo(...);; That is, a `RooRealProxy` stores a pointer to a RooAbsArg, and this pointer has to be cast. There was no type; safety, *i.e.*, any object deriving from RooAbsArg could be stored in that proxy, and the user had to take care; of ensuring that types are correct.; Now, if one uses; RooTemplateProxy<RooAbsPdf> pdfProxy;; instead of; RooRealProxy realProxy;; in RooFit classes, the above code can be simplified to; pdfProxy->fitTo(...);. Check the [doxygen reference guide](https://root.cern.ch/doc/master/classRooTemplateProxy.html) for `RooTemplateProxy` for; more information on how to modernise old code. ### HistFactory. #### Switch default statistical MC errors to Poisson; When defining HistFactory samples with statistical errors from C++, e.g.; Sample background1( ""background1"", ""background1"", InputFile );; background1.ActivateStatError();; statistical MC errors now have Poisson instead of Gaussian constraints. This better reflects the uncertainty of the MC simulations.; This can be reverted as follows:; // C++:; Channel chan(""channel1"");; chan.SetStatErrorConfig( 0.05, ""Gauss"" );; // Within <Ch",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md:4662,safe,safety,4662,README/ReleaseNotes/v622/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md,1,['safe'],['safety']
Safety,"----------------------------. *Previously:* ``ASSERT_EXCLUSIVE_LOCK``, ``ASSERT_SHARED_LOCK``. These are attributes on a function or method which asserts the calling thread; already holds the given capability, for example by performing a run-time test; and terminating if the capability is not held. Presence of this annotation; causes the analysis to assume the capability is held after calls to the; annotated function. See :ref:`mutexheader`, below, for example uses. GUARDED_VAR and PT_GUARDED_VAR; ------------------------------. Use of these attributes has been deprecated. Warning flags; -------------. * ``-Wthread-safety``: Umbrella flag which turns on the following:. + ``-Wthread-safety-attributes``: Semantic checks for thread safety attributes.; + ``-Wthread-safety-analysis``: The core analysis.; + ``-Wthread-safety-precise``: Requires that mutex expressions match precisely.; This warning can be disabled for code which has a lot of aliases.; + ``-Wthread-safety-reference``: Checks when guarded members are passed by reference. :ref:`negative` are an experimental feature, which are enabled with:. * ``-Wthread-safety-negative``: Negative capabilities. Off by default. When new features and checks are added to the analysis, they can often introduce; additional warnings. Those warnings are initially released as *beta* warnings; for a period of time, after which they are migrated into the standard analysis. * ``-Wthread-safety-beta``: New features. Off by default. .. _negative:. Negative Capabilities; =====================. Thread Safety Analysis is designed to prevent both race conditions and; deadlock. The GUARDED_BY and REQUIRES attributes prevent race conditions, by; ensuring that a capability is held before reading or writing to guarded data,; and the EXCLUDES attribute prevents deadlock, by making sure that a mutex is; *not* held. However, EXCLUDES is an optional attribute, and does not provide the same; safety guarantee as REQUIRES. In particular:. * A function wh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:16133,safe,safety-reference,16133,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['safe'],['safety-reference']
Safety,"--------------------------. ``__builtin_unpredictable`` is used to indicate that a branch condition is; unpredictable by hardware mechanisms such as branch prediction logic. **Syntax**:. .. code-block:: c++. __builtin_unpredictable(long long). **Example of use**:. .. code-block:: c++. if (__builtin_unpredictable(x > 0)) {; foo();; }. **Description**:. The ``__builtin_unpredictable()`` builtin is expected to be used with control; flow conditions such as in ``if`` and ``switch`` statements. Query for this feature with ``__has_builtin(__builtin_unpredictable)``. ``__builtin_expect``; --------------------. ``__builtin_expect`` is used to indicate that the value of an expression is; anticipated to be the same as a statically known result. **Syntax**:. .. code-block:: c++. long __builtin_expect(long expr, long val). **Example of use**:. .. code-block:: c++. if (__builtin_expect(x, 0)) {; bar();; }. **Description**:. The ``__builtin_expect()`` builtin is typically used with control flow; conditions such as in ``if`` and ``switch`` statements to help branch; prediction. It means that its first argument ``expr`` is expected to take the; value of its second argument ``val``. It always returns ``expr``. Query for this feature with ``__has_builtin(__builtin_expect)``. ``__builtin_expect_with_probability``; -------------------------------------. ``__builtin_expect_with_probability`` is similar to ``__builtin_expect`` but it; takes a probability as third argument. **Syntax**:. .. code-block:: c++. long __builtin_expect_with_probability(long expr, long val, double p). **Example of use**:. .. code-block:: c++. if (__builtin_expect_with_probability(x, 0, .3)) {; bar();; }. **Description**:. The ``__builtin_expect_with_probability()`` builtin is typically used with; control flow conditions such as in ``if`` and ``switch`` statements to help; branch prediction. It means that its first argument ``expr`` is expected to take; the value of its second argument ``val`` with probability ``p``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:114345,predict,prediction,114345,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['predict'],['prediction']
Safety,"--------------------===//. The code generated for bswap on armv4/5 (CPUs without rev) is less than ideal:. int a(int x) { return __builtin_bswap32(x); }. a:; 	mov	r1, #255, 24; 	mov	r2, #255, 16; 	and	r1, r1, r0, lsr #8; 	and	r2, r2, r0, lsl #8; 	orr	r1, r1, r0, lsr #24; 	orr	r0, r2, r0, lsl #24; 	orr	r0, r0, r1; 	bx	lr. Something like the following would be better (fewer instructions/registers):; 	eor r1, r0, r0, ror #16; 	bic r1, r1, #0xff0000; 	mov r1, r1, lsr #8; 	eor r0, r1, r0, ror #8; 	bx	lr. A custom Thumb version would also be a slight improvement over the generic; version. //===---------------------------------------------------------------------===//. Consider the following simple C code:. void foo(unsigned char *a, unsigned char *b, int *c) {; if ((*a | *b) == 0) *c = 0;; }. currently llvm-gcc generates something like this (nice branchless code I'd say):. ldrb r0, [r0]; ldrb r1, [r1]; orr r0, r1, r0; tst r0, #255; moveq r0, #0; streq r0, [r2]; bx lr. Note that both ""tst"" and ""moveq"" are redundant. //===---------------------------------------------------------------------===//. When loading immediate constants with movt/movw, if there are multiple; constants needed with the same low 16 bits, and those values are not live at; the same time, it would be possible to use a single movw instruction, followed; by multiple movt instructions to rewrite the high bits to different values.; For example:. volatile store i32 -1, i32* inttoptr (i32 1342210076 to i32*), align 4,; !tbaa; !0; volatile store i32 -1, i32* inttoptr (i32 1342341148 to i32*), align 4,; !tbaa; !0. is compiled and optimized to:. movw r0, #32796; mov.w r1, #-1; movt r0, #20480; str r1, [r0]; movw r0, #32796 @ <= this MOVW is not needed, value is there already; movt r0, #20482; str r1, [r0]. //===---------------------------------------------------------------------===//. Improve codegen for select's:; if (x != 0) x = 1; if (x == 1) x = 1. ARM codegen used to look like this:; mov r1, r0; cmp r1, #1;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:19313,redund,redundant,19313,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,1,['redund'],['redundant']
Safety,"-------------------. In some cases one may need to execute different code depending on whether; AddressSanitizer is enabled.; :ref:`\_\_has\_feature <langext-__has_feature-__has_extension>` can be used for; this purpose. .. code-block:: c. #if defined(__has_feature); # if __has_feature(address_sanitizer); // code that builds only under AddressSanitizer; # endif; #endif. Disabling Instrumentation with ``__attribute__((no_sanitize(""address"")))``; --------------------------------------------------------------------------. Some code should not be instrumented by AddressSanitizer. One may use; the attribute ``__attribute__((no_sanitize(""address"")))`` (which has; deprecated synonyms `no_sanitize_address` and; `no_address_safety_analysis`) to disable instrumentation of a; particular function. This attribute may not be supported by other; compilers, so we suggest to use it together with; ``__has_feature(address_sanitizer)``. The same attribute used on a global variable prevents AddressSanitizer; from adding redzones around it and detecting out of bounds accesses. AddressSanitizer also supports; ``__attribute__((disable_sanitizer_instrumentation))``. This attribute; works similar to ``__attribute__((no_sanitize(""address"")))``, but it also; prevents instrumentation performed by other sanitizers. Suppressing Errors in Recompiled Code (Ignorelist); --------------------------------------------------. AddressSanitizer supports ``src`` and ``fun`` entity types in; :doc:`SanitizerSpecialCaseList`, that can be used to suppress error reports; in the specified source files or functions. Additionally, AddressSanitizer; introduces ``global`` and ``type`` entity types that can be used to; suppress error reports for out-of-bound access to globals with certain; names and types (you may only specify class or struct types). You may use an ``init`` category to suppress reports about initialization-order; problems happening in certain source files or with certain global variables. .. code-block",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:9577,detect,detecting,9577,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,1,['detect'],['detecting']
Safety,"----------------. It may be desirable to reject some inputs, i.e. to not add them to the corpus. For example, when fuzzing an API consisting of parsing and other logic,; one may want to allow only those inputs into the corpus that parse successfully. If the fuzz target returns -1 on a given input,; libFuzzer will not add that input top the corpus, regardless of what coverage; it triggers. .. code-block:: c++. extern ""C"" int LLVMFuzzerTestOneInput(const uint8_t *Data, size_t Size) {; if (auto *Obj = ParseMe(Data, Size)) {; Obj->DoSomethingInteresting();; return 0; // Accept. The input may be added to the corpus.; }; return -1; // Reject; The input will not be added to the corpus.; }. Leaks; -----. Binaries built with AddressSanitizer_ or LeakSanitizer_ will try to detect; memory leaks at the process shutdown.; For in-process fuzzing this is inconvenient; since the fuzzer needs to report a leak with a reproducer as soon as the leaky; mutation is found. However, running full leak detection after every mutation; is expensive. By default (``-detect_leaks=1``) libFuzzer will count the number of; ``malloc`` and ``free`` calls when executing every mutation.; If the numbers don't match (which by itself doesn't mean there is a leak); libFuzzer will invoke the more expensive LeakSanitizer_; pass and if the actual leak is found, it will be reported with the reproducer; and the process will exit. If your target has massive leaks and the leak detection is disabled; you will eventually run out of RAM (see the ``-rss_limit_mb`` flag). Developing libFuzzer; ====================. LibFuzzer is built as a part of LLVM project by default on macos and Linux.; Users of other operating systems can explicitly request compilation using; ``-DCOMPILER_RT_BUILD_LIBFUZZER=ON`` flag.; Tests are run using ``check-fuzzer`` target from the build directory; which was configured with ``-DCOMPILER_RT_INCLUDE_TESTS=ON`` flag. .. code-block:: console. ninja check-fuzzer. FAQ; =========================. Q.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:26630,detect,detection,26630,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['detect'],['detection']
Safety,"------------. We also use a more direct form of structured fuzzing for fuzzers that take; :doc:`LLVM IR <LangRef>` as input. This is achieved through the ``FuzzMutate``; library, which was `discussed at EuroLLVM 2017`_. The ``FuzzMutate`` library is used to structurally fuzz backends in; `llvm-isel-fuzzer`_. .. _discussed at EuroLLVM 2017: https://www.youtube.com/watch?v=UBbQ_s6hNgg. Building and Running; ====================. .. _building-fuzzers:. Configuring LLVM to Build Fuzzers; ---------------------------------. Fuzzers will be built and linked to libFuzzer by default as long as you build; LLVM with sanitizer coverage enabled. You would typically also enable at least; one sanitizer to find bugs faster. The most common way to build the fuzzers is; by adding the following two flags to your CMake invocation:; ``-DLLVM_USE_SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `OSS Fuzz`_ more; instead. You can browse the `LLVM project issue list`_ for the bugs found by; `LLVM on OSS Fuzz`_. These are also mailed to the `llvm-bugs mailing; list`_. .. _OSS Fuzz: https://github.com/google/oss-fuzz; .. _LLVM project issue list:; https://bugs.chromium.org/p/oss-fuzz/issues/list?q=Proj-llvm; .. _LLVM on OSS Fuzz:; https://github.com/google/oss-fuzz/blob/master/projects/llvm; .. _llvm-bugs mailin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:8546,avoid,avoid,8546,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,1,['avoid'],['avoid']
Safety,"------------. ``LLVMContext`` is an opaque class in the LLVM API which clients can use to; operate multiple, isolated instances of LLVM concurrently within the same; address space. For instance, in a hypothetical compile-server, the compilation; of an individual translation unit is conceptually independent from all the; others, and it would be desirable to be able to compile incoming translation; units concurrently on independent server threads. Fortunately, ``LLVMContext``; exists to enable just this kind of scenario!. Conceptually, ``LLVMContext`` provides isolation. Every LLVM entity; (``Module``\ s, ``Value``\ s, ``Type``\ s, ``Constant``\ s, etc.) in LLVM's; in-memory IR belongs to an ``LLVMContext``. Entities in different contexts; *cannot* interact with each other: ``Module``\ s in different contexts cannot be; linked together, ``Function``\ s cannot be added to ``Module``\ s in different; contexts, etc. What this means is that is safe to compile on multiple; threads simultaneously, as long as no two threads operate on entities within the; same context. In practice, very few places in the API require the explicit specification of a; ``LLVMContext``, other than the ``Type`` creation/lookup APIs. Because every; ``Type`` carries a reference to its owning context, most other entities can; determine what context they belong to by looking at their own ``Type``. If you; are adding new entities to LLVM IR, please try to maintain this interface; design. .. _jitthreading:. Threads and the JIT; -------------------. LLVM's ""eager"" JIT compiler is safe to use in threaded programs. Multiple; threads can call ``ExecutionEngine::getPointerToFunction()`` or; ``ExecutionEngine::runFunction()`` concurrently, and multiple threads can run; code output by the JIT concurrently. The user must still ensure that only one; thread accesses IR in a given ``LLVMContext`` while another thread might be; modifying it. One way to do that is to always hold the JIT lock while accessing; IR outs",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:123524,safe,safe,123524,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['safe'],['safe']
Safety,"-----------. Unary operators require a single operand, execute an operation on; it, and produce a single value. The operand might represent multiple; data, as is the case with the :ref:`vector <t_vector>` data type. The; result value has the same type as its operand. .. _i_fneg:. '``fneg``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = fneg [fast-math flags]* <ty> <op1> ; yields ty:result. Overview:; """""""""""""""""". The '``fneg``' instruction returns the negation of its operand. Arguments:; """""""""""""""""""". The argument to the '``fneg``' instruction must be a; :ref:`floating-point <t_floating>` or :ref:`vector <t_vector>` of; floating-point values. Semantics:; """""""""""""""""""". The value produced is a copy of the operand with its sign bit flipped.; The value is otherwise completely identical; in particular, if the input is a; NaN, then the quiet/signaling bit and payload are perfectly preserved. This instruction can also take any number of :ref:`fast-math; flags <fastmath>`, which are optimization hints to enable otherwise; unsafe floating-point optimizations:. Example:; """""""""""""""". .. code-block:: text. <result> = fneg float %val ; yields float:result = -%var. .. _binaryops:. Binary Operations; -----------------. Binary operators are used to do most of the computation in a program.; They require two operands of the same type, execute an operation on; them, and produce a single value. The operands might represent multiple; data, as is the case with the :ref:`vector <t_vector>` data type. The; result value has the same type as its operands. There are several different binary operators:. .. _i_add:. '``add``' Instruction; ^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = add <ty> <op1>, <op2> ; yields ty:result; <result> = add nuw <ty> <op1>, <op2> ; yields ty:result; <result> = add nsw <ty> <op1>, <op2> ; yields ty:result; <result> = add nuw nsw <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``add``' instruction returns the sum of its two",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:376539,unsafe,unsafe,376539,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['unsafe'],['unsafe']
Safety,"--------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6350,detect,detection,6350,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,1,['detect'],['detection']
Safety,"--------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run into an issue in external libraries, we; recommend immediately reporting it to the library maintainer so that it; gets addressed. However, you can use the following suppression mechanism; to unblock yourself and continue on with the testing. This suppression; mechanism should only be used for suppressing issues in external code; it; does not work on code recompiled with AddressSanitizer. To suppress errors; in external",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6731,detect,detector,6731,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,1,['detect'],['detector']
Safety,"--------. This pass transforms loops by placing phi nodes at the end of the loops for all; values that are live across the loop boundary. For example, it turns the left; into the right code:. .. code-block:: c++. for (...) for (...); if (c) if (c); X1 = ... X1 = ...; else else; X2 = ... X2 = ...; X3 = phi(X1, X2) X3 = phi(X1, X2); ... = X3 + 4 X4 = phi(X3); ... = X4 + 4. This is still valid LLVM; the extra phi nodes are purely redundant, and will be; trivially eliminated by ``InstCombine``. The major benefit of this; transformation is that it makes many other loop optimizations, such as; ``LoopUnswitch``\ ing, simpler. You can read more in the; :ref:`loop terminology section for the LCSSA form <loop-terminology-lcssa>`. .. _passes-licm:. ``licm``: Loop Invariant Code Motion; ------------------------------------. This pass performs loop invariant code motion, attempting to remove as much; code from the body of a loop as possible. It does this by either hoisting code; into the preheader block, or by sinking code to the exit blocks if it is safe.; This pass also promotes must-aliased memory locations in the loop to live in; registers, thus hoisting and sinking ""invariant"" loads and stores. Hoisting operations out of loops is a canonicalization transform. It enables; and simplifies subsequent optimizations in the middle-end. Rematerialization; of hoisted instructions to reduce register pressure is the responsibility of; the back-end, which has more accurate information about register pressure and; also handles other optimizations than LICM that increase live-ranges. This pass uses alias analysis for two purposes:. #. Moving loop invariant loads and calls out of loops. If we can determine; that a load or call inside of a loop never aliases anything stored to, we; can hoist it or sink it like any other instruction. #. Scalar Promotion of Memory. If there is a store instruction inside of the; loop, we try to move the store to happen AFTER the loop instead of inside of; the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:23721,safe,safe,23721,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['safe'],['safe']
Safety,"-; Compares instruction opcodes and some important operation properties. 1. Compare opcodes, if it differs return the result. 2. Compare number of operands. If it differs – return the result. 3. Compare operation types, use *cmpType*. All the same – if types are; different, return result. 4. Compare *subclassOptionalData*, get it with ``getRawSubclassOptionalData``; method, and compare it like a numbers. 5. Compare operand types. 6. For some particular instructions, check equivalence (relation in our case) of; some significant attributes. For example, we have to compare alignment for; ``load`` instructions. O(log(N)); ---------; Methods described above implement order relationship. And latter, could be used; for nodes comparison in a binary tree. So we can organize functions set into; the binary tree and reduce the cost of lookup procedure from; O(N*N) to O(log(N)). Merging process, mergeTwoFunctions; ==================================; Once *MergeFunctions* detected that current function (*G*) is equal to one that; were analyzed before (function *F*) it calls ``mergeTwoFunctions(Function*,; Function*)``. Operation affects ``FnTree`` contents with next way: *F* will stay in; ``FnTree``. *G* being equal to *F* will not be added to ``FnTree``. Calls of; *G* would be replaced with something else. It changes bodies of callers. So,; functions that calls *G* would be put into ``Deferred`` set and removed from; ``FnTree``, and analyzed again. The approach is next:. 1. Most wished case: when we can use alias and both of *F* and *G* are weak. We; make both of them with aliases to the third strong function *H*. Actually *H*; is *F*. See below how it's made (but it's better to look straight into the; source code). Well, this is a case when we can just replace *G* with *F*; everywhere, we use ``replaceAllUsesWith`` operation here (*RAUW*). 2. *F* could not be overridden, while *G* could. It would be good to do the; next: after merging the places where overridable function were ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst:26103,detect,detected,26103,interpreter/llvm-project/llvm/docs/MergeFunctions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst,1,['detect'],['detected']
Safety,"-bit TS; respectively).; * **Does not require quarantine to detect heap-use-after-free,; or stack-use-after-return**.; The detection is similarly probabilistic. The memory overhead of HWASAN is expected to be much smaller; than that of AddressSanitizer:; `1/TG` extra memory for the shadow; and some overhead due to `TG`-aligning all objects. Supported architectures; =======================; HWASAN relies on `Address Tagging`_ which is only available on AArch64.; For other 64-bit architectures it is possible to remove the address tags; before every load and store by compiler instrumentation, but this variant; will have limited deployability since not all of the code is; typically instrumented. On x86_64, HWASAN utilizes page aliasing to place tags in userspace address; bits. Currently only heap tagging is supported. The page aliases rely on; shared memory, which will cause heap memory to be shared between processes if; the application calls ``fork()``. Therefore x86_64 is really only safe for; applications that do not fork. HWASAN does not currently support 32-bit architectures since they do not; support `Address Tagging`_ and the address space is too constrained to easily; implement page aliasing. Related Work; ============; * `SPARC ADI`_ implements a similar tool mostly in hardware.; * `Effective and Efficient Memory Protection Using Dynamic Tainting`_ discusses; similar approaches (""lock & key"").; * `Watchdog`_ discussed a heavier, but still somewhat similar; ""lock & key"" approach.; * *TODO: add more ""related work"" links. Suggestions are welcome.*. .. _Watchdog: https://www.cis.upenn.edu/acg/papers/isca12_watchdog.pdf; .. _Effective and Efficient Memory Protection Using Dynamic Tainting: https://www.cc.gatech.edu/~orso/papers/clause.doudalis.orso.prvulovic.pdf; .. _SPARC ADI: https://lazytyped.blogspot.com/2017/09/getting-started-with-adi.html; .. _AddressSanitizer paper: https://www.usenix.org/system/files/conference/atc12/atc12-final39.pdf; .. _Address Tagging: h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:11048,safe,safe,11048,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,1,['safe'],['safe']
Safety,"-cast``: Cast from ``void*`` or another; unrelated type to the wrong dynamic type.; - ``-fsanitize=cfi-nvcall``: Non-virtual call via an object whose vptr is of; the wrong dynamic type.; - ``-fsanitize=cfi-vcall``: Virtual call via an object whose vptr is of the; wrong dynamic type.; - ``-fsanitize=cfi-icall``: Indirect call of a function with wrong dynamic; type.; - ``-fsanitize=cfi-mfcall``: Indirect call via a member function pointer with; wrong dynamic type. You can use ``-fsanitize=cfi`` to enable all the schemes and use; ``-fno-sanitize`` flag to narrow down the set of schemes as desired.; For example, you can build your program with; ``-fsanitize=cfi -fno-sanitize=cfi-nvcall,cfi-icall``; to use all schemes except for non-virtual member function call and indirect call; checking. Remember that you have to provide ``-flto`` or ``-flto=thin`` if at; least one CFI scheme is enabled. Trapping and Diagnostics; ========================. By default, CFI will abort the program immediately upon detecting a control; flow integrity violation. You can use the :ref:`-fno-sanitize-trap=; <controlling-code-generation>` flag to cause CFI to print a diagnostic; similar to the one below before the program aborts. .. code-block:: console. bad-cast.cpp:109:7: runtime error: control flow integrity check for type 'B' failed during base-to-derived cast (vtable address 0x000000425a50); 0x000000425a50: note: vtable is of type 'A'; 00 00 00 00 f0 f1 41 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 20 5a 42 00; ^. If diagnostics are enabled, you can also configure CFI to continue program; execution instead of aborting by using the :ref:`-fsanitize-recover=; <controlling-code-generation>` flag. Forward-Edge CFI for Virtual Calls; ==================================. This scheme checks that virtual calls take place using a vptr of the correct; dynamic type; that is, the dynamic type of the called object must be a; derived class of the static type of the object used to make t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst:3304,abort,abort,3304,interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst,2,"['abort', 'detect']","['abort', 'detecting']"
Safety,"-overlapping; nodes as ONLY and the others MANY as in GEANT3, where this concept was; introduced:. 1. The part of a MANY node B extruding its container A will never be; ""seen"" during navigation, as if B was in fact the result of the; intersection of A and B. 2. If we have two nodes A (ONLY) and B (MANY) inside the same container,; all points in the overlapping region of A and B will be designated as; belonging to A. 3. If A an B in the above case were both MANY, points in the overlapping; part will be designated to the one defined first. Both nodes must have; the same medium. 4. The slices of a divided MANY will be as well MANY. One needs to know that navigation inside geometry parts MANY nodes is; much slower. Any overlapping part can be defined based on composite; shapes - might be in some cases a better way out. \anchor GP01bg; #### Replicating Volumes. What can we do if our chamber contains two identical wires instead of; one? What if then we would need 1000 chambers in our detector? Should we; create 2000 wires and 1000 chamber volumes? No, we will just need to; replicate the ones that we have already created. ~~~{.cpp}; chamber->AddNode(wire_co,1,new TGeoTranslation(0.2,0,0));; chamber->AddNode(wire_co,2,new TGeoTranslation(0.2,0,0));; ~~~. The 2 nodes that we have created inside chamber will both point to a; `wire_co` object, but will be completely distinct: `WIRE_CO_1` and; `WIRE_CO_2`. We will want now to place symmetrically 1000 chambers on a; pad, following a pattern of 20 rows and 50 columns. One way to do this; will be to replicate our chamber by positioning it 1000 times in; different positions of the pad. Unfortunately, this is far from being; the optimal way of doing what we want. Imagine that we would like to; find out which of the 1000 chambers is containing a `(x,y,z)` point; defined in the pad reference. You will never have to do that, since the; modeller will take care of it for you, but let's guess what it has to; do. The most simple algorithm ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:39542,detect,detector,39542,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['detect'],['detector']
Safety,"-project/root/issues/15077)] - Passing different floating point types to `RVec` utility functions; * [[#15048](https://github.com/root-project/root/issues/15048)] - [ntuple] Handling of virtual inheritance broken; * [[#15040](https://github.com/root-project/root/issues/15040)] - [RDataFrame] Inaccurate example of progress bar from documentation; * [[#15028](https://github.com/root-project/root/issues/15028)] - [RDataFrame] Unable to cacheread remote file; * [[#15027](https://github.com/root-project/root/issues/15027)] - spurrious cmake message about AfterImage with -Dminimal=ON; * [[#14981](https://github.com/root-project/root/issues/14981)] - RVecs leak memory with np.asarray in pyROOT; * [[#14964](https://github.com/root-project/root/issues/14964)] - ROOT-HEAD fails with ""cling interactive line includer >>>: fatal error: module file '[snip]/Vc.pcm' not found: module file not found""; * [[#14958](https://github.com/root-project/root/issues/14958)] - ROOT_HEAD failed with error message: Fail to detect cryptographic random generator; * [[#14921](https://github.com/root-project/root/issues/14921)] - ROOT Fails to build macOS 14.4 arm64 Xcode 15.3; * [[#14914](https://github.com/root-project/root/issues/14914)] - VecOps::Take with default argument doesn't check correctly the out of boundary condition; * [[#14910](https://github.com/root-project/root/issues/14910)] - hadd issue when using parallelization together with indirect file; * [[#14902](https://github.com/root-project/root/issues/14902)] - compilation error; * [[#14863](https://github.com/root-project/root/issues/14863)] - [hist] TH1::SaveAs missing default option argument causes compilation errors; * [[#14855](https://github.com/root-project/root/issues/14855)] - TRatioPlot crashes if loaded from the file; * [[#14842](https://github.com/root-project/root/issues/14842)] - TRatioplot gives ""different"" results with Web Graphics; * [[#14838](https://github.com/root-project/root/issues/14838)] - Problems with Confide",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:27844,detect,detect,27844,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['detect'],['detect']
Safety,"-state`). For; GFX9-GFX11 the aperture base addresses are directly available as inline; constant registers ``SRC_SHARED_BASE/LIMIT`` and ``SRC_PRIVATE_BASE/LIMIT``.; In 64-bit address mode the aperture sizes are 2^32 bytes and the base is; aligned to 2^32 which makes it easier to convert from flat to segment or; segment to flat. A global address space address has the same value when used as a flat address; so no conversion is needed. **Global and Constant**; The global and constant address spaces both use global virtual addresses,; which are the same virtual address space used by the CPU. However, some; virtual addresses may only be accessible to the CPU, some only accessible; by the GPU, and some by both. Using the constant address space indicates that the data will not change; during the execution of the kernel. This allows scalar read instructions to; be used. As the constant address space could only be modified on the host; side, a generic pointer loaded from the constant address space is safe to be; assumed as a global pointer since only the device global memory is visible; and managed on the host side. The vector and scalar L1 caches are invalidated; of volatile data before each kernel dispatch execution to allow constant; memory to change values between kernel dispatches. **Region**; The region address space uses the hardware Global Data Store (GDS). All; wavefronts executing on the same device will access the same memory for any; given region address. However, the same region address accessed by wavefronts; executing on different devices will access different memory. It is higher; performance than global memory. It is allocated by the runtime. The data; store (DS) instructions can be used to access it. **Local**; The local address space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belongin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:25196,safe,safe,25196,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['safe'],['safe']
Safety,"-style=file:<format_file_path>``, :program:`clang-format` for; each input file will use the format file located at `<format_file_path>`.; The path may be absolute or relative to the working directory. The ``.clang-format`` file uses YAML format:. .. code-block:: yaml. key1: value1; key2: value2; # A comment.; ... The configuration file can consist of several sections each having different; ``Language:`` parameter denoting the programming language this section of the; configuration is targeted at. See the description of the **Language** option; below for the list of supported languages. The first section may have no; language set, it will set the default style options for all languages.; Configuration sections for specific language will override options set in the; default section. When :program:`clang-format` formats a file, it auto-detects the language using; the file name. When formatting standard input or a file that doesn't have the; extension corresponding to its language, ``-assume-filename=`` option can be; used to override the file name :program:`clang-format` uses to detect the; language. An example of a configuration file for multiple languages:. .. code-block:: yaml. ---; # We'll use defaults from the LLVM style, but with 4 columns indentation.; BasedOnStyle: LLVM; IndentWidth: 4; ---; Language: Cpp; # Force pointers to the type for C++.; DerivePointerAlignment: false; PointerAlignment: Left; ---; Language: JavaScript; # Use 100 columns for JS.; ColumnLimit: 100; ---; Language: Proto; # Don't format .proto files.; DisableFormat: true; ---; Language: CSharp; # Use 100 columns for C#.; ColumnLimit: 100; ... An easy way to get a valid ``.clang-format`` file containing all configuration; options of a certain predefined style is:. .. code-block:: console. clang-format -style=llvm -dump-config > .clang-format. When specifying configuration in the ``-style=`` option, the same configuration; is applied for all input files. The format of the configuration is:. .. c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:2753,detect,detect,2753,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['detect'],['detect']
Safety,". ### Code Cleanups. Several definition where moved from the global or ROOT namespace to the ROOT::Internal namespace as they are not intended to be used outside of ROOT, including: `gROOTLocal` and related functions, `TSchemaHelper`, `TSchemaMatch`, `TSchemaType`, `RStl`, `ROOT::TROOTAllocator`, `TSchemaRuleProcessor`, `TStdBitsetHelper`, `TInitBehavior`, `TDefaultInitBehavior`, `DefineBehavior`, `THnBaseBrowsable`, `THnBaseBinIter`, `GenericShowMembers`, `TOperatorNewHelper` and `BranchProxy` implementations classes. Several definition where moved from the global or ROOT namespace to the ROOT::Details namespace as they are intended to be used in 'expert' level code and have a lower level of backward compatibility requirement. This includes `TCollectionProxyInfo`, `TSchemaRuleSet`. ## Interpreter. ROOT can now dump the context of STL collections, for instance `map<string,int>`. A few ROOT types print their content, too. Fixed the handling of the current directory in `#include` of system headers, avoid problem with local files named `new` or `vector`. Fixed the issue with the ROOT special variable where the objects were read from the file at each and every access by caching those object. See [ROOT-7830] for example. This release contains several bug fixes and improvements, notably in unloading and performance. > NOTE: The GCC 5 ABI is *not* supported yet, due to a lack of support in clang. ## I/O Libraries. ### hadd. We extended the `hadd` options to allow more control on the compression settings use for the; output file. In particular the new option -fk allows for a copy of the input; files with no decompressions/recompression of the TTree baskets even if they; do not match the requested compression setting. New options:. - `-ff` allows to force the compression setting to match the one from the first input; - `-fk[0-209]` allows to keep all the basket compressed as is and to compress the meta data with the given compression setting or the compression setting of the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:6312,avoid,avoid,6312,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['avoid'],['avoid']
Safety,". .. code-block:: c++. /// CurTok/getNextToken - Provide a simple token buffer. CurTok is the current; /// token the parser is looking at. getNextToken reads another token from the; /// lexer and updates CurTok with its results.; static int CurTok;; static int getNextToken() {; return CurTok = gettok();; }. This implements a simple token buffer around the lexer. This allows us; to look one token ahead at what the lexer is returning. Every function; in our parser will assume that CurTok is the current token that needs to; be parsed. .. code-block:: c++. /// LogError* - These are little helper functions for error handling.; std::unique_ptr<ExprAST> LogError(const char *Str) {; fprintf(stderr, ""Error: %s\n"", Str);; return nullptr;; }; std::unique_ptr<PrototypeAST> LogErrorP(const char *Str) {; LogError(Str);; return nullptr;; }. The ``LogError`` routines are simple helper routines that our parser will; use to handle errors. The error recovery in our parser will not be the; best and is not particular user-friendly, but it will be enough for our; tutorial. These routines make it easier to handle errors in routines; that have various return types: they always return null. With these basic helper functions, we can implement the first piece of; our grammar: numeric literals. Basic Expression Parsing; ========================. We start with numeric literals, because they are the simplest to; process. For each production in our grammar, we'll define a function; which parses that production. For numeric literals, we have:. .. code-block:: c++. /// numberexpr ::= number; static std::unique_ptr<ExprAST> ParseNumberExpr() {; auto Result = std::make_unique<NumberExprAST>(NumVal);; getNextToken(); // consume the number; return std::move(Result);; }. This routine is very simple: it expects to be called when the current; token is a ``tok_number`` token. It takes the current number value,; creates a ``NumberExprAST`` node, advances the lexer to the next token,; and finally returns. The",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst:6723,recover,recovery,6723,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst,1,['recover'],['recovery']
Safety,". .. code-block:: c++. true: false:; int a[ 5 ]; vs. int a[5];; std::unique_ptr<int[]> foo() {} // Won't be affected. .. _Standard:. **Standard** (``LanguageStandard``) :versionbadge:`clang-format 3.7` :ref:`¶ <Standard>`; Parse and format C++ constructs compatible with this standard. .. code-block:: c++. c++03: latest:; vector<set<int> > x; vs. vector<set<int>> x;. Possible values:. * ``LS_Cpp03`` (in configuration: ``c++03``); Parse and format as C++03.; ``Cpp03`` is a deprecated alias for ``c++03``. * ``LS_Cpp11`` (in configuration: ``c++11``); Parse and format as C++11. * ``LS_Cpp14`` (in configuration: ``c++14``); Parse and format as C++14. * ``LS_Cpp17`` (in configuration: ``c++17``); Parse and format as C++17. * ``LS_Cpp20`` (in configuration: ``c++20``); Parse and format as C++20. * ``LS_Latest`` (in configuration: ``Latest``); Parse and format using the latest supported language version.; ``Cpp11`` is a deprecated alias for ``Latest``. * ``LS_Auto`` (in configuration: ``Auto``); Automatic detection based on the input. .. _StatementAttributeLikeMacros:. **StatementAttributeLikeMacros** (``List of Strings``) :versionbadge:`clang-format 12` :ref:`¶ <StatementAttributeLikeMacros>`; Macros which are ignored in front of a statement, as if they were an; attribute. So that they are not parsed as identifier, for example for Qts; emit. .. code-block:: c++. AlignConsecutiveDeclarations: true; StatementAttributeLikeMacros: []; unsigned char data = 'x';; emit signal(data); // This is parsed as variable declaration. AlignConsecutiveDeclarations: true; StatementAttributeLikeMacros: [emit]; unsigned char data = 'x';; emit signal(data); // Now it's fine again. .. _StatementMacros:. **StatementMacros** (``List of Strings``) :versionbadge:`clang-format 8` :ref:`¶ <StatementMacros>`; A vector of macros that should be interpreted as complete; statements. Typical macros are expressions, and require a semi-colon to be; added; sometimes this is not the case, and this allows to mak",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:129754,detect,detection,129754,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['detect'],['detection']
Safety,". ; Networking. NET; ; TWebFile. Several pptimizations in TWebFile improving performance especially for TTree::Map() by about 35%. This has been achieved with a better caching strategy for request strings (especially avoiding to recalculate the auth base64 encoding), and with a drastic optimization in reading the response headers.; Fixes in the counting of the bytes read. TWebSystem. New implementation of TSystem allowing to use TSystem::AccessPathName() and GetPathInfo() to check if a web file exists and to get its size. Directory browsing is not available yet. NETX; ; TXNetFile. Several fixes and optimisations, mainly in the use of the cache; Fix an offset issue affecting the use of the cache with files in archives. TXNetSystem. A few optimizations in the use of retry mechanism, path locality checks, file online checks. XROOTD. Import a new version of XROOTD (20091202-0509); ; Fixes in bulk prepare and sync readv operations; Add support for 'make install' / 'make uninstall' and; other improvements in configure.classic; Several improvements / fixes:; ; reduced memory and CPU consumption;; extreme cp optimizations;; windows porting; new cache policies on the client side; new listing features implemented recently in the 'cns' module.; optimizations in cmsd and cnsd (performance improvements); support for openssl 1.0.0 (required by Fedora 12). Support for if/else if/else/fi constructs; Several portability fixes; ; Support 32-bit builds with icc on 64-bit platforms; Improved detection of libreadline and lib(n)curses. Increase the flexibility for configuring with an external xrootd; ; Add standard switches to disentangle lib and inc dirs;       --with-xrootd-incdir=<path_to dir_containing_XrdVersion.hh>;       --with-xrootd-libdir=<path_to_dir_containing_xrootd_plugins_and_libs>; ; When; passing a global xrootd dir with --with-xrootd, check both; src/XrdVersion.hh and include/xrootd/XrdVersion.hh so that both build; and install distributions are supported. Fix a problem ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v526/index.html:217,avoid,avoiding,217,net/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v526/index.html,1,['avoid'],['avoiding']
Safety,". Checker Developer Manual. This Page Is Under Construction; Checker Developer Manual; The static analyzer engine performs path-sensitive exploration of the program and; relies on a set of checkers to implement the logic for detecting and; constructing specific bug reports. Anyone who is interested in implementing their own; checker, should check out the Building a Checker in 24 Hours talk; (slides; video); and refer to this page for additional information on writing a checker. The static analyzer is a; part of the Clang project, so consult Hacking on Clang; and LLVM Programmer's Manual; for developer guidelines and post your questions and proposals to the; Static Analyzer subcategory at; the official LLVM Discourse server. Getting Started; Static Analyzer Overview. Interaction with Checkers; Representing Values. Idea for a Checker; Checker Registration; Events, Callbacks, and Checker Class Structure; Custom Program States; Bug Reports; AST Visitors; Testing; Useful Commands/Debugging Hints. Attaching the Debugger; Narrowing Down the Problem; Visualizing the Analysis; Debug Prints and Tricks. Additional Sources of Information; Useful Links. Getting Started. To check out the source code and build the project, follow steps 1-4 of; the Clang Getting Started; page.; The analyzer source code is located under the Clang source tree:; ; $ cd llvm/tools/clang. See: include/clang/StaticAnalyzer, lib/StaticAnalyzer,; test/Analysis.; The analyzer regression tests can be executed from the Clang's build; directory:; ; $ cd ../../../; cd build/tools/clang; TESTDIRS=Analysis make test. Analyze a file with the specified checker:; ; $ clang -cc1 -analyze -analyzer-checker=core.DivideZero test.c. List the available checkers:; ; $ clang -cc1 -analyzer-checker-help. See the analyzer help for different output formats, fine tuning, and; debug options:; ; $ clang -cc1 -help | grep ""analyzer"". Static Analyzer Overview; The analyzer core performs symbolic execution of the given program. All t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html:225,detect,detecting,225,interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,1,['detect'],['detecting']
Safety,". Compiler-RT library contains reference implementations of slowpath; functions, but they have unresolvable issues with correctness and; performance in the handling of dlopen(). It is recommended that; platforms provide their own implementations, usually as part of libc; or libdl. Position-independent executable requirement; -------------------------------------------. Cross-DSO CFI mode requires that the main executable is built as PIE.; In non-PIE executables the address of an external function (taken from; the main executable) is the address of that function’s PLT record in; the main executable. This would break the CFI checks. Backward-edge CFI for return statements (RCFI); ==============================================. This section is a proposal. As of March 2017 it is not implemented. Backward-edge control flow (`RET` instructions) can be hijacked; via overwriting the return address (`RA`) on stack.; Various mitigation techniques (e.g. `SafeStack`_, `RFG`_, `Intel CET`_); try to detect or prevent `RA` corruption on stack. RCFI enforces the expected control flow in several different ways described below.; RCFI heavily relies on LTO. Leaf Functions; --------------; If `f()` is a leaf function (i.e. it has no calls; except maybe no-return calls) it can be called using a special calling convention; that stores `RA` in a dedicated register `R` before the `CALL` instruction.; `f()` does not spill `R` and does not use the `RET` instruction,; instead it uses the value in `R` to `JMP` to `RA`. This flavour of CFI is *precise*, i.e. the function is guaranteed to return; to the point exactly following the call. An alternative approach is to; copy `RA` from stack to `R` in the first instruction of `f()`,; then `JMP` to `R`.; This approach is simpler to implement (does not require changing the caller); but weaker (there is a small window when `RA` is actually stored on stack). Functions called once; ---------------------; Suppose `f()` is called in just one place in the p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:24360,detect,detect,24360,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['detect'],['detect']
Safety,". Core; TString. Reimplementation of the internals of TString to not use reference counting and; copy on write, but to use a more modern and thread safe Short String; Optimization (SSO) technique. Using SSO short strings (<15 on 64-bit and; <11 on 32-bit) are contained in the TString internal data structure; without the need for mallocing the required space. TObject. In TObject::ls, add support for the option 'noaddr' which ; prevents the printing of the address of the object. This; is useful in particular in roottest. Use this in hadd; and TFileMerger. TROOT. New routine CloseFiles used automatically shortly before termination to ; insure closing of files and sockets before the unload of any library.; New collection 'ClosedObjects' holding pointers to TFile or TSocket that; have been closed but not deleted it. In the case of TSocket, they are added only; if they are closed by the CloseFiles.; Add a Close member function to TProofMgr since it is added to the list of socket.; Migrate the closing of files from various to a single place (T*System::Exit).; Fill in the implementation of TROOT::FindObjectAnyFile.; Mark TROOT as TObject::kInvalidObject as soon as its destructor starts,; in order to be able to veto some action later on (like autoloading). TSystem. Better handle the cases where the information in the rootmap file is (almost) empty. ; Avoid infinite loop if one of the dependent library is missing. Meta. Add new fast accessors to Merge routines (See the I/O package for more details.; Improve error message in case a schema evolution rule can not be loaded when the library is loaded; (from the generic 'it conflicts with one of the other rules' to 'the target member ... is unknown'.; Add the ability to explicitly forbid (or allow) the splitting of a class; (TClass::SetSplit ) so that user can inforce the use of a custom streamer in all possible split cases.; Improve the performance of TProcessUUID::AddUUID by reintroducing the THashList.; This significanly improve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v530/index.html:148,safe,safe,148,core/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v530/index.html,1,['safe'],['safe']
Safety,". FAQ and How to Deal with Common False Positives. FAQ and How to Deal with Common False Positives. How do I tell the analyzer that I do not want the bug being; reported here since my custom error handler will safely end the execution before; the bug is reached?; The analyzer reports a null dereference, but I know that the; pointer is never null. How can I tell the analyzer that a pointer can never be; null?; How do I tell the static analyzer that I don't care about a specific dead store?; How do I tell the static analyzer that I don't care about a specific unused instance variable in Objective C?; How do I tell the static analyzer that I don't care about a specific unlocalized string?; How do I tell the analyzer that my instance variable does not need to be released in -dealloc under Manual Retain/Release?; How do I decide whether a method's return type should be _Nullable or _Nonnull?; How do I tell the analyzer that I am intentionally violating nullability?; The analyzer assumes that a loop body is never entered. How can I tell it that the loop body will be entered at least once?; How can I suppress a specific analyzer warning?; How can I selectively exclude code the analyzer examines?. Q: How do I tell the analyzer that I do not want the bug being; reported here since my custom error handler will safely end the execution before; the bug is reached?. You can tell the analyzer that this path is unreachable by teaching it about your custom assertion handlers. For example, you can modify the code segment as following. void customAssert() __attribute__((analyzer_noreturn));; int foo(int *b) {; if (!b); customAssert();; return *b;; }; Q: The analyzer reports a null dereference, but I know that the; pointer is never null. How can I tell the analyzer that a pointer can never be; null?. The reason the analyzer often thinks that a pointer can be null is because the preceding code checked compared it against null. So if you are absolutely sure that it cannot be null, remove",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/faq.html:210,safe,safely,210,interpreter/llvm-project/clang/www/analyzer/faq.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/faq.html,1,['safe'],['safely']
Safety,". For example, if you're used to compiling with; ``-fsanitize=undefined``, you could enable the minimal runtime with; ``-fsanitize=undefined -fsanitize-minimal-runtime``. Stack traces and report symbolization; =====================================; If you want UBSan to print symbolized stack trace for each error report, you; will need to:. #. Compile with ``-g`` and ``-fno-omit-frame-pointer`` to get proper debug; information in your binary.; #. Run your program with environment variable; ``UBSAN_OPTIONS=print_stacktrace=1``.; #. Make sure ``llvm-symbolizer`` binary is in ``PATH``. Logging; =======. The default log file for diagnostics is ""stderr"". To log diagnostics to another; file, you can set ``UBSAN_OPTIONS=log_path=...``. Silencing Unsigned Integer Overflow; ===================================; To silence reports from unsigned integer overflow, you can set; ``UBSAN_OPTIONS=silence_unsigned_overflow=1``. This feature, combined with; ``-fsanitize-recover=unsigned-integer-overflow``, is particularly useful for; providing fuzzing signal without blowing up logs. Issue Suppression; =================. UndefinedBehaviorSanitizer is not expected to produce false positives.; If you see one, look again; most likely it is a true positive!. Disabling Instrumentation with ``__attribute__((no_sanitize(""undefined"")))``; ----------------------------------------------------------------------------. You disable UBSan checks for particular functions with; ``__attribute__((no_sanitize(""undefined"")))``. You can use all values of; ``-fsanitize=`` flag in this attribute, e.g. if your function deliberately; contains possible signed integer overflow, you can use; ``__attribute__((no_sanitize(""signed-integer-overflow"")))``. This attribute may not be; supported by other compilers, so consider using it together with; ``#if defined(__clang__)``. Suppressing Errors in Recompiled Code (Ignorelist); --------------------------------------------------. UndefinedBehaviorSanitizer supports ``src``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst:13110,recover,recover,13110,interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst,1,['recover'],['recover']
Safety,". Forwards compatibility; ----------------------. As an author of a multilib configuration, it should be possible to design the; configuration in such a way that it is likely to work well with future Clang; versions. For example, if a future version of Clang is likely to add support; for newer versions of an architecture and the architecture is known to be; designed for backwards compatibility then it should be possible to express; compatibility for such architecture versions in the multilib configuration. Not GNU spec files; ------------------. The GNU spec files standard is large and complex and there's little desire to; import that complexity to LLVM. It's also heavily oriented towards processing; command line argument strings which is hard to do correctly, hence the large; amount of logic dedicated to that task in the Clang driver. While compatibility; with GNU would bring benefits, the cost in this case is deemed too high. Avoid re-inventing feature detection in the configuration; ---------------------------------------------------------. A large amount of logic in the Clang driver is dedicated to inferring which; architectural features are available based on the given command line options.; It is neither desirable nor practical to repeat such logic in each multilib; configuration. Instead the configuration should be able to benefit from the; heavy lifting Clang already does to detect features. Low maintenance; ---------------. Multilib is a relatively small feature in the scheme of things so supporting it; should accordingly take little time. Where possible this should be achieved by; implementing it in terms of existing features in the LLVM codebase. Minimal additional API surface; ------------------------------. The greater the API surface, the greater the difficulty of keeping it stable.; Where possible the additional API surface should be kept small by defining it; in relation to existing APIs. An example of this is keeping a simple; relationship between f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst:12054,detect,detection,12054,interpreter/llvm-project/clang/docs/Multilib.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst,1,['detect'],['detection']
Safety,". GUI Libraries; TRootBrowser. Following a user request on savannah,; a filtering mechanism in the browser has been implemented. To filter the content of a file; (or a folder inside a file), simply click on the ""Filter"" button. A dialog will popup, asking; for a filtering expression string (regexp like). The filter will then be applied on the current; list tree item (folder) and will stay active until a wildcard (""*"") expression or an empty; string ("""") is entered as new filtering value. The filter button automatically reflects the; status of any selected list tree item, and if a filter is active on it, the button state is; ""engaged"" and its tooltip shows what is actually displayed in this file/folder. It is possible; to filter several files/folders, each one having its own filtering argument. TGNumberEntry. Fix a possible overflow when entering a float having its fraction part exceeding kMaxInt (e.g 9.9999999999). This fix the bug #84033, TGNumberEntryField. TTreeViewer. Make the ""Histogram"" text entry expanding in X direction (i.e. resize it when resizing the tree viewer). TGInputDialog. Implemented a hack to detect if user press cancel or if an empty string ("""") has been selected.; When the Cancel button is pressed, the first two characters are reset to 0, and if the user select; an empty string ("""") the first character is reset to 0 and the second one is set to 1. TGPrintDialog. The ""Printer"" text entry has been replaced by a combo box populated with the list of available printers on the system, and select the default one, if any. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v532/index.html:1129,detect,detect,1129,gui/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v532/index.html,1,['detect'],['detect']
Safety,". GUI; New Classes: TRecorder TGRecorder; TRecorder classes provide interface for recording and replaying events in ROOT.; Recorded events are:; Commands typed by user in command line (e.g. 'new TCanvas'); GUI events (mouse movement, button clicks, ...); All the recorded events from one session are stored in one TFile and can be replayed again anytime.; Modifications in TRootCanvas menu:; Renamed 'Inspect' menu title to 'Tools'; Added 'Event Recorder' menu entry. Here is a screenshot of TGRecorder (GUI interface of the recorder):. New Class: TGPack; New Container class for vertical and horizontal grouping of frames.; It enforces a predictable resizing behaviour on children.; For an example of how to use it, see tutorials/eve/pack.C. TRootBrowser. Make the default url for the HTML plugin of TRootBrowser configurable via rootrc. TGTab. Added a 'Close Tab' icon in TGTabElement, allowing to close a tab element, and emitting a CloseTab(Int_t id) signal. The icon is active only on the actually activated tab.; Implement CloseTab slot usage in TRootBrowser and in TGRootIDE. TGTextEditor. Allow to execute a macro without having to save it first. TGSplitFrame. Added a new signal method Docked(TGFrame*) to notify when a embedded frame has been docked.; Added a new signal method Undocked(TGFrame*) to notify when a embedded frame has been undocked.; Added a new getter method GetUndocked() returning a pointer on undocked frame, if any. TGToolTip. Added new constructor with global x, y position.; If neither fWindow nor fPad are set use global fX, fY that was passed from outside. TGSplitter. Added option to handle frame resizing externally. TGView. Added a protection against possible negative scroll values. TGTextView. Fix bottom line not being properly updated while scrolling.; Solve a problem with vertical slider (avoid negative value when scrolling). TGTextEdit. Fix blinking cursor on some platforms/compilers. TGTextEntry. Added optional parameter 'Bool_t emit' to TGTextEntry::Se",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v522/index.html:639,predict,predictable,639,gui/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v522/index.html,1,['predict'],['predictable']
Safety,". GUI; TRootCanvas. In SetWindowSize the event queue is flushed to make sure; the window size change is really done. TRootContextMenu. When creating the dialog from the context menu, skip arguments that are pointers (but not char *) and have a default value. This should avoid confusing input fields in dialog.; Implemented online help in root dialogs (the dialog boxes used with contextual menus) via a new ""Online Help"" button. This opens a Root HTML browser at the right class/method location in the Root reference guide on the web.; The base url can be changed with the Browser.StartUrl option in system.rootrc (by default: http://root.cern.ch/root/html/ClassIndex.html); Added a small '?' on the right of the context menu entries, giving access to online help. TGMenu. Add possibility to add a right aligned shortcut by using a tab character ('\t') before the shortcut string, as shown below:; fMenuFile->AddEntry(""&Open...\tCtrl+O"", kOpenFile);; Use new way of adding right aligned shortcuts in the menu entries in most of the GUI classes using shortcuts in their menu. TGSlider. Added HandleConfigureNotify() to handle resizing events. New Browser. Automatically browse ROOT files if there is any open when starting the browser.; Correct system files manipulations (copy, rename, delete) and automatic update of the list tree. GUIHTML; TGHtmlBrowser. Added ability to display single picture from the web and to open pdf files with external viewer (Windows only); Implemented anchor navigation (e.g. http://root.cern.ch/root/html/TH1.html#TH1:Multiply). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v524/index.html:271,avoid,avoid,271,gui/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v524/index.html,1,['avoid'],['avoid']
Safety,". Geometry; Improvement of the standard overlap checker. The previous method was checking points on the visual mesh of volume shape against all possible overlapping partners.; The new method checks more points (currently 1000, in future configurable) on the volume outline or surface. This minimizes the number of non-detectable overlap; configurations.; The interface to activate the new checking method is the same as before:; gGeoManager->CheckOverlaps(ovlp);; where ovlp is the overlap tolerance (default 0.01 cm); An example of overlap that was not detected before but is now:. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/doc/v522/index.html:318,detect,detectable,318,geom/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/doc/v522/index.html,2,['detect'],"['detectable', 'detected']"
Safety,". Histogram package; TGraphDelaunay. New version of the method TGraphDelaunay::Enclose(). This method; decides if a point is inside a triangle or not. The way it was implemented; produced infinite numbers and generated wrong peaks. It was visible on some; machines only (for instance MacOsX). Now this method uses; TMath::IsInside(). It is much safer, it runs faster, and the; code is simpler. The problem could be seen with a simple macro like the; following one:; ; {; TCanvas *c1 = new TCanvas(""c1"", ""c1"",0,0,600,600);; c1->SetTheta(90.);; c1->SetPhi(0.0001);; gStyle->SetPalette(1);; TGraph2D *graph2d = new TGraph2D();; graph2d->SetPoint(0, 110, 110, 0.0);; graph2d->SetPoint(1, -80, 50, 1.0);; graph2d->SetPoint(2, -70, 40, 2.0);; graph2d->SetPoint(3,-110, -50, 3.0);; graph2d->SetNpx(9);; graph2d->SetNpy(9);; graph2d->Draw(""surf1"");; graph2d->SetLineWidth(2);; graph2d->Draw("" triw p0 same"");; }; . The X and Y vectors are normalized in order to compute the triangles.; The scale factor used was the same for the X and Y axis.; This generated problems (very long triangles instead of the obvious ones); in some cases when the X and Y axis had very different ranges. Having two; scale factors, one for the X axis and one for the Y axis, cures the problem. TGraph2D. In case all the points are in the same Z-plane Z0 (zmin = zmax), the graph; minimum is set to Z0-0.01*Z0 and the maximum to Z0+0.01*Z0. This; allow to make TGraph2D like:; ; {; double *x = new double[2];; double *y = new double[2];; double *z = new double[2];; x[0] = 6215.;; x[1] = 5542.;; y[0] = 3853.;; y[1] = 5270.;; z[0] = 2723.;; z[1] = 2723.;; TGraph2D * g = new TGraph2D(2, x, y, z);; g->Draw(""LINE"");; }; . TGraph2DPainter. When a TGraph2D was painted with the option TRI1 the; color distribution in case of log scale along the Z axis was wrong. THistPainter. After executing the following macro, zooming the X axis interactively; generated the error message:; ; Error in <TGraphPainter::PaintGraphHist>: X must have N+",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v528/index.html:345,safe,safer,345,hist/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v528/index.html,1,['safe'],['safer']
Safety,". I/O Libraries; TFileCacheRead. Support for multiple TFileCacheRead per TFile.; Multiple TFileCacheRead per TFile are supported by augmenting the existing TFile::SetCacheRead() function with an optional TObject* argument specifying the owner (i.e. tree) of the cache. This function will assign a TFileCacheRead to a TFile for the given TTree. A cache can be removed by setting the pointer TFileCacheRead to 0.; Similarly, in TFile::GetCacheRead() an optional TObject* argument was added to obtain the TFileCacheRead from a TFile.; In addition to the unassigned TFileCacheRead pointer, TFile will maintain a map of tree specific cache pointers.; Backward compatibility in both functions is handled by making the TObject* argument optional. If it is not specified in the TFile::SetCacheRead() call, only the unassigned TFileCacheRead pointer is updated, otherwise the map and the unassigned cache are updated. In TFile::GetCacheRead(), if an owner is not specified or doesn't exist in the file's cache map, the unassigned cache is returned, unless it is 0 and there is exactly one entry in the cache map.; Distinguish counter for bytes read and read calls for learning phase. TFileMerger. Improve efficiency of TFileMerger when merging a single file by doing a TFile::Cp rather than a load/write of the objects.; In TFileMerger and hadd when objects can not be merged do not overwrite the last object in the set with the first!; Renable warning about not being able to merge objects in TFileMerger and hadd.; Fix hadd problem where the incremental merging fails if the TTree are stored in sub-directories.; Improve the code used for forward compatibility (record the type as TDirectory even-though the class is now TDirectoryFile) by delaying the switching of the class name until it is written (to the buffer). This avoids problem where a TKey is created (by TFile::mkdir) and then immediately used for reading (this happens in the incremental file merger). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v534/index.html:1816,avoid,avoids,1816,io/doc/v534/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v534/index.html,1,['avoid'],['avoids']
Safety,". I/O. Add support for the Chirp filesystem. To configure and build, chirp 3.2.2 must be installed.; When a TFile object is deleted, make sure that CINT also 'removes' any global variables that might point to it.; Fix support for the automatic addition to the current directory (for TTree and TH1 for example) in TKey::Read(TObject*).; In TKey, properly handle error in the I/O routines.; Explicitly check the validity of the zipped buffer before calling R__unzip, this allow for better error recovery.; When double checking whether a checksum difference is sustantial, ignore the std namespace. Use CompareContent also in the case of where; the class is versioned but the 'current' streamerInfo has not yet been built.; Prevent the I/O engine from mistakenly applying schema evolution to the TObject::fBits.; Make sure that when a streamer info of a base class is used to stream memberwise that is always not-optimized. If the StreamerInfo on file; has the same version as the StreamerInfo in memory but the one on file need to be 'not optimized' while the one in memory is not yet built, make; sure it will not be optimized.; Fix the reading of empty collection of object when reading without the library.; If the sequence of actions for streaming member-wise is not created correctly (i.e. where fReadMemberWise was null previously),; we now explicitly issue a Fatal error:. Fatal in <ReadSequence>: The sequence of actions to read AliESDVertex:7 member-wise was not initialized.; aborting. Add new optional parameter maxbuf to TXMLEngine::ParseFile() allowing the specification of the XML file size to be parsed. This fixes issue #78864.; Add function TBuffer::AutoExpand to centralize the automatic buffer extension policy. This enable the ability to tweak it later (for example instead of always doubling the size, increasing by only at most 2Mb or take hints from the number of entries already; in a TBasket).; Migrate the class TFileMerger from the proofplayer library to ROOT I/O library and ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v530/index.html:493,recover,recovery,493,io/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v530/index.html,1,['recover'],['recovery']
Safety,". I/O. Fix the order of creation of the TStreamerInfo during the opening of a ROOT file to insure that the CollectionProxy are properly setup.; Fix problem: ""recover warning when opening an empty file; created with TXNetFile"" which was due to a bad check in TFile::Recover; (line TFile.cxx:1561) where the inheritance from TFile should be checked; instead of requiring the name to be TFile.; In TBranch::File, in the case of importing the data directly from; an external TBuffer, remove 80 char limit on reading the class name; Re-enable support for the; rootrc configuration Root.ZipMode. Data Model Evolution. First step in the implemantation of the infrastructure for the new Data Model Evolution Scheme.; This Data Model Evolution is brought to your courtesy of BNL/STAR/ATLAS/Fermi/Cern; Current Capabilities. Assign values to transient data members; Rename classes; Rename data members; Change the shape of the data structures or convert one class; structure to another; Change the meaning of data members; Ability to access the TBuffer directly when needed; Ensure that the objects in collections are handled in the same; way as the ones stored separately; Supported in object-wise, member-wise and split modes. Coming soon. Make things operational also in bare ROOT mode; Ability to transform data before writing; Support for changing the class type of nested object in a split; branch; Support for access to onfile version of nested objects from; within the parent rule. LinkDef rule syntax; Setting a transient member:; #pragma read sourceClass=""ACache"" targetClass=""ACache"" source=""""; version=""[1-]"" target=""zcalc"" \; code=""{ zcalc = false; }"". Setting a new member from 2 removed members:. #pragma read sourceClass=""ACache"" targetClass=""ACache""; source=""int x; int y; char c"" version=""[8]"" target=""z"" \; code=""{ z = onfile.x*1000 + onfile.y*10; }"". Renaming a class:. #pragma read sourceClass=""ACache"" version=""[8]""; targetClass=""Axis"" \; source=""int x; int y;"" target=""z"" \; code=""{ z = o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v522/index.html:158,recover,recover,158,io/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v522/index.html,1,['recover'],['recover']
Safety,". I/O. Implement proxy support in TWebFile. The proxy URL can be sprcified either; via TWebFile::SetProxy() or via the shell variable http_proxy, as is being; used by wget, e.g.:; export http_proxy=http://pcsalo.cern.ch:3128; To bypass the proxy, the TWebFile ctor (or via TFile::Open()) supports the; option ""NOPROXY"".; Add support for streaming std::bitset STL containers; Extend the checks done in case of a StreamerInfo checksum mismatch to; avoid spurrious failures (for example because of the various possible; type names for STL containers) and to report details on the nature of; the mismatch: explicit list missing base classese, missing data members; or the actual differences in type or comments.; For example:. Warning in : The following data member of the on-file layout version 2 of class 'Tdata' differs from the in-memory layout version 2:; double mydouble; //; vs; double mydouble_two; //; Warning in : The following data member of the in-memory layout version 2 of class 'Tdata' is missing from the on-file layout version 2:; int more; //; Warning in : The following data member of the in-memory layout version 2 of class 'Tdata' is missing from the on-file layout version 2:; int three; //. Upgrade MakeProject to be able to handle ROOT files created by for ATLAS.; Allow user to provide a custom reallocator when the TBuffer is being passed; memory. If the TBuffer does not own the memory __and__ no custom memory; reallocator has been set, a Fatal error will be issued:; Fatal in : Failed to expand the data buffer because TBuffer does not own it and no custom memory reallocator was provided.; Re-allow reading empty vector< long double >, however long double is still not supported.; Upgrade TSQLFile to properly work with MySQL on MacOS.; Update to the CollectionProxyInfo interface to insure the proper creation of iterator over std containers on all platforms.; In XML and SQL output, use %e format to write float and double:; ; Conversion from float/double to string per def",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v524/index.html:446,avoid,avoid,446,io/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v524/index.html,1,['avoid'],['avoid']
Safety,". I/O. Unset the kIsReferenced bit before cloning an object in order to avoid the (incorrect/unwanted) registration of the clone. Repaired writing Foreign class in XML files. Extend TDirectoryFile so it can now be derived from. In MakeProject; properly test whether a StreamerElement describe a base class (stl container were not handled correctly).; Remove requirement to have '.' in the PATH to execute the build. Add a new optional parameter to TDirectory::Append: replace.; If replace is true (the default is false), the Append will; first remove from the directory any existing object and; print the message:. Replacing existing OldClass: thename (Potential memory leak). Add a new option parameter to TDirectory::CloneObject: 'autoadd'; If autoadd is true (the default), CloneObject will call the; object 'DirectoryAutoAdd' function (if any). In TDirectory::CloneObject add support for multiple inheritance; from TObject where TObject is not the left most base class. Schema Evolution. Fix schema evolution problem in TTree::Draw by extending support in; TStreamerInfo::ReadValueAux to 'converted' numerical types, (; see issue in ROOT forum). When reading more than one TStreamerInfo for the same versioned; class, we now use the highest possible class version as the current; version of the class. Practically, we update the class version; when reading new (higher versioned) StreamerInfo until the Class; is actually used (i.e. TClass::GetClassVersion is call directly; or indirectly). In particular, if a file has several StreamerInfos for the same; versioned class, we will use the highest version number as the; 'current' class version (as opposed to the lowest until now). For backward compatibility TStreamerInfo::BuildCheck compares the checksum of; the on-file StreamerInfo not only to the current value of the class checksum; but also to the checksum calculated using the older algorithms. This patch extends this test to also be done when comparing 2 on-file StreamerInfos. This remo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v520/index.html:72,avoid,avoid,72,io/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v520/index.html,1,['avoid'],['avoid']
Safety,". I/O; Schema Evolution. Change TExMap hash, key and values from (U)Long_t to (U)Long64_t. This makes TExMap streamable in a portable way. On 64-bit platforms there is; no difference, but on 32-bit platforms all values will now be 64-bit. This fixes a big portability issue with THnSparse which uses TExMap internally; where the versions created on a 32-bit platform could not be read on a 64-bit platform and vice versa.; Avoid reporting I/O error for members of a class that is used only for a transient member; Concrete implementation of TClassGenerator needs to be updated to also avoid the warnings.; Fix the rule lookup based on checksum; Extend support of the schema evolution rules to fixed length array.; Prevent a process abort (due to a call to Fatal) when we are missing the dictionary for (one of) the; content of an STL collection when this collection is 'only' use has a transient member.; Fix the case where the source and target of a rule have the same name.; Avoid using the 'current' StreamerInfo to read an older streamerInfo that is missing (in case of corrupted files). Misc. New TFile plugin for the Hadoop Distributed File System (protocol hdfs:); Unregister stack objects from their TDirectory when the TList tries to delete them.; When streaming a base class without StreamerNVirtual() use an external streamer if it was set.; Many improvement to the I/O run-time performance.; DCache:; Increase readahead size from 8k to 128k and make it settable via DCACHE_RA_BUFFER env var.; dCap client does not ignore ?filetpye=raw and other options, so remove it. The function TFile::GetRelOffset is now public instead of protected.; Corrected the reading of the TFile record of large files.; MakeProject: several updates to improve support for CMS and Atlas data files (add support for auto_ptr, bitset, class name longer than 255 characters, etc.). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v526/index.html:585,avoid,avoid,585,io/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v526/index.html,2,"['abort', 'avoid']","['abort', 'avoid']"
Safety,". Math Libraries. MathCore. Various fixes have been applied in the fitting classes:. Fix issue #46006 for normalization of error resulting from fitting a TGraph; Fix a problem in Chi2 calculation in case of overflow; Fix issue #46601 for avoiding crashes when a linear fit fails.; Fix in the FitData classes the bug #45909 occurring when setting a function range outside histogram range; Fix default integration method to be Gauss algorithm of MathCore instead of the GSL method, when libMathmore is not built or when the plug-in manager fails to load it.; Add a protection against negative log when fitting using the Poisson log likelihood function; Improve calculation of derivative in x for fitted function. This fixes some problem observed when fitting using the error on the coordinates.; Fitter class: add new methods for calculating the error matrix after minimization, Fitter::CalculateHessErrors() and for calculating the Minos errors Fitter::CalculateMinosErrors; FitConfig: add in the configuration the possibility to select a sub-set of the parameters for calculating the Minos errors by using the method FitConfig::SetMinosErrors( listOfParameters ). If no list is passed, by default the Minos error will be computed on all parameters.; UnBinData class: add new constructor for creating a unbin data set passing a range to select the data and copy in the internal array; FitResult: the class now stores a map of the Minos error using as key the parameter index. If the Minos error has not been calculated for the parameter, FitResult::LowerError(i) and FitResult::UpperError(i) returns the parabolic error; ; Add a new class, MinimTransformFunction to perform a transformation of the function object to deal with limited and fixed variables.; This class uses the same transformation which are also used inside Minuit, a sin transformation for double bounded variables and a sqrt transformation for single bound variable defined in the class MinimizerVariableTransformation.; These classes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v524/index.html:238,avoid,avoiding,238,math/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v524/index.html,1,['avoid'],['avoiding']
Safety,". OpenGL; Major changes. GLEW - The OpenGL Extension Wrangler Library - has been added to; facilitate detection of OpenGL version and available extensions at; run-time. This will allow usage of advanced visualization techniques; while still allowing fall-back solutions to be used on systems not; supporting the required functionality. If GLEW and GLEW-devel packages; are detected during configure, the ROOT provided GLEW is not; built. See also:; http://glew.sourceforge.net/. Latest (1.3.3) version of gl2ps has been imported (we had 1.2.6; before). See http://www.geuz.org/gl2ps/; for detailed change-log. New implementation of GL-in-TPad - instead of mixture of GL and; non-GL graphics in a pixmap all pad graphics (2D/3D) is now; done by OpenGL. To make this possible new TVirtualPadPainter,; TPadPainter, TGLPadPainter classes were introduced; and painting operations inside TPad class were modified to; use TVirtualPadPainter instead of TVirtualX.; TVirtualPadPainter is an abstract base class, interface for; drawing 2D primitives and pixmap management. TPadPainter is; a default, non-GL implementation, based on TVirtualX; (gVirtualX). TGLPadPainter is a GL; implementation. Currently, TGLPadPainter does not support; off-screen rendering (support for frame-buffer objects is planned). Current limitations:. The glpad can be saved only as PS now.; Several sub-pads with complex 3d geometry can be slow due to lack; of off-screen rendering which would allow for caching of resulting images. Future directions:. Use frame-buffer objects for off-screen rendering.; Support ""Save as"" png, jpg, pdf, etc.; With GLEW and GL-shading-language, use of hardware anti-aliasing and; shaders is possible. Prototype visualization of 5-dimensional distributions:. New option for TTree::Draw - ""gl5d"", for the case you have 5 and; more dimensional dataset.; Set of iso-surfaces created, 4-th dimension is used to select iso-level.; ""gl5d"" is now very similar to ""gliso"" option, but instead of; filling TH3 o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v524/index.html:102,detect,detection,102,graf3d/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v524/index.html,2,['detect'],"['detected', 'detection']"
Safety,". RooFit. HistFactory. One of the core classes used by HistFactory models (RooRealSumPdf) was modified leading to substantial speed improvements (for models that use the default -standard_form option). . This new version supports a few types of interpolation for the normalization of the histograms:. code = 0: piece-wise linear (old default); code = 1: piece-wise log (new default); code = 2: parabolic interp with linear extrap ( common at tevatron, avoids kink for asymmetric uncert). The piece-wise logarithmic interpolation paired with a Gaussian constraint is equivalent to a log-normal constraint in a transformed version of the nuisance parameter. The benefit of this approach is that it is easy to avoid the normalization from taking on unphysical negative values. This is the prescription used by the CMS Higgs group, and agreed upon by the LHC Higgs Combination Group. There is not yet XML-based steering for the different interpolation types, but there is a simple script to modify it. . results/example_combined_GaussExample_model.root . Near term goals for HistFactory. Utilities for dealing with Monte Carlo statistical uncertainty in the template histograms; Support for N-D histograms; A new style of histogram variations without a constraint term attached (for shapes determined from control samples); XML steering for interpolation types. RooStats; General Improvements. This release brings several speed improvements to the RooStats tools and improved stability and performance with PROOF. This comes mainly through changes to the ToyMCSampler. In addition the HypoTestInverter tool has been rewritten, leading to some changes in the HypoTestResult. Finally, a new hypothesis test new called FrequentistCalculator was written, which plays the same role as the HybridCalculator but eliminates nuisance parameters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:452,avoid,avoids,452,roofit/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html,2,['avoid'],"['avoid', 'avoids']"
Safety,". Specifying GC code generation: ``gc ""...""``; -------------------------------------------. .. code-block:: text. define <returntype> @name(...) gc ""name"" { ... }. The ``gc`` function attribute is used to specify the desired GC strategy to the; compiler. Its programmatic equivalent is the ``setGC`` method of ``Function``. Setting ``gc ""name""`` on a function triggers a search for a matching subclass; of GCStrategy. Some collector strategies are built in. You can add others; using either the loadable plugin mechanism, or by patching your copy of LLVM.; It is the selected GC strategy which defines the exact nature of the code; generated to support GC. If none is found, the compiler will raise an error. Specifying the GC style on a per-function basis allows LLVM to link together; programs that use different garbage collection algorithms (or none at all). .. _gcroot:. Identifying GC roots on the stack; ----------------------------------. LLVM currently supports two different mechanisms for describing references in; compiled code at safepoints. ``llvm.gcroot`` is the older mechanism;; ``gc.statepoint`` has been added more recently. At the moment, you can choose; either implementation (on a per :ref:`GC strategy <plugin>` basis). Longer; term, we will probably either migrate away from ``llvm.gcroot`` entirely, or; substantially merge their implementations. Note that most new development; work is focused on ``gc.statepoint``. Using ``gc.statepoint``; ^^^^^^^^^^^^^^^^^^^^^^^^; :doc:`This page <Statepoints>` contains detailed documentation for; ``gc.statepoint``. Using ``llvm.gcwrite``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.gcroot(i8** %ptrloc, i8* %metadata). The ``llvm.gcroot`` intrinsic is used to inform LLVM that a stack variable; references an object on the heap and is to be tracked for garbage collection.; The exact impact on generated code is specified by the Function's selected; :ref:`GC strategy <plugin>`. All calls to ``llvm.gcroot`` **mu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:9490,safe,safepoints,9490,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['safe'],['safepoints']
Safety,". TPDF. The following macro produced a wrong PDF file. The second page had a black; background.; ; {; gROOT->SetStyle(""Plain"");; TCanvas* canvas = new TCanvas(""canvas"", ""canvas"", 600, 700);; TH1F* h = new TH1F(""h"",""ht"", 100, -5, 5);; h->FillRandom(""gaus"",10000);; canvas->Divide(2,1);; canvas->cd(1); h->Draw();; canvas->Update();; canvas->Print(""test.pdf("");; canvas->Print(""test.pdf"");; canvas->Print(""test.pdf)"");; }; . TPostscript. Fix a precision problem in the text positionning. When the pad limits along; X or Y were very close the text position might be wrong. This was found; thanks to the test #15 in stressGraphics. The text position is now computed; using double precision variables only. TASImage. Horizontal dashed lines having a width greater than 1, were not correct. TLatex. Improve the sqrt drawing to avoid the overlapping; problem mentionned here https://savannah.cern.ch/bugs/index.php?82436. TGaxis. The following macro produced two different labelling. Label ""3"" was missing; on the axis ""b"".; ; {; TGaxis *a = new TGaxis(0.2,0.5,0.8,0.5,0.2,3.5,510,""G"");; a->SetMoreLogLabels(1); a->Draw();; TGaxis *b = new TGaxis(0.8,0.7,0.2,0.7,0.2,3.5,510,""G"");; b->SetMoreLogLabels(1); b->Draw();; }; . TPad. Add a protection in TPad:Clear() to fix the; bug report #78382. An histogram redrawing in a cloned; pad produced a segmentation fault. GX11Gui. Only call XFreeColors if we are on a <= 8 plane machine (to match calls; to XAllocColor). This solves the bug #77329: X11 error clicking; on '?' in context menus. TGWin32. Unmap the window before to destroy it, in order to properly receive; kUnmapNotify needed by gClient->WaitForUnmap(). This fixes the problem; reported on; the forum. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v530/index.html:821,avoid,avoid,821,graf2d/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v530/index.html,1,['avoid'],['avoid']
Safety,". The acknowledgement should be understanding and compassionate; but no commitment should be made on whether this is a violation or which action; will be taken. Specific guidance is in the checklist below. For in-person events that have a violation reported, the report should be sent; to the Code of Conduct committee within 24 hours by the on-site CoC response; team. . .. _Immediate Response Checklist:. Immediate Response Checklist; ============================. The CoC committee generally works, decides, and communicates together. If the; report indicates that an immediate response is required and other committee; members are not available, any committee member may take the immediate action; they think is necessary. In-person Code of Conduct response teams should use; this checklist to determine if an immediate response is needed. * If the incident involves physical danger, contact the appropriate law; enforcement or event security immediately. Ensure the reporter feels safe and; stay with them if possible until help arrives.; * If the act is ongoing and involves harassment or threats against someone in; any space (online or physical), any appropriate response (e.g., ban, physical; removal, or moderation) may be used to immediately stop it.; * For events that include talks, organizers should end talks early if the; violations include harassment or violent threats. There may be talks where; other types of code of conduct violations occur and organizers should do ; their best to determine if a talk should be ended early or not. . When undertaking an immediate response, document the action and notify the; committee within 24 hours. . Response Procedure; ==================. The following is a summary of the steps the committee takes when responding to; a reported incident. . 1. Determine if there is a need for an :ref:`immediate response<Immediate; Response Checklist>`. 2. :ref:`Acknowledge the report<Receiving a report>` within 24 hours. 3. :ref:`Discuss the incident r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ResponseGuide.rst:2394,safe,safe,2394,interpreter/llvm-project/llvm/docs/ResponseGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ResponseGuide.rst,1,['safe'],['safe']
Safety,". Translating Function Calls; --------------------------. The ``IRTranslator`` also implements the ABI's calling convention by lowering; calls, returns, and arguments to the appropriate physical register usage and; instruction sequences. This is achieved using the ``CallLowering``; implementation,. .. _irtranslator-aggregates:. Aggregates; ^^^^^^^^^^. .. caution::. This has changed since it was written and is no longer accurate. It has not; been refreshed in this pass of improving the documentation as I haven't; worked much in this part of the codebase and it should have attention from; someone more knowledgeable about it. Aggregates are lowered into multiple virtual registers, similar to; SelectionDAG's multiple vregs via ``GetValueVTs``. ``TODO``:; As some of the bits are undef (padding), we should consider augmenting the; representation with additional metadata (in effect, caching computeKnownBits; information on vregs).; See `PR26161 <https://llvm.org/PR26161>`_: [GlobalISel] Value to vreg during; IR to MachineInstr translation for aggregate type. .. _irtranslator-constants:. Translation of Constants; ------------------------. Constant operands are translated as a use of a virtual register that is defined; by a ``G_CONSTANT`` or ``G_FCONSTANT`` instruction. These instructions are; placed in the entry block to allow them to be subject to the continuous CSE; implementation (``CSEMIRBuilder``). Their debug location information is removed; to prevent this from confusing debuggers. This is beneficial as it allows us to fold constants into immediate operands; during :ref:`instructionselect`, while still avoiding redundant materializations; for expensive non-foldable constants. However, this can lead to unnecessary; spills and reloads in an -O0 pipeline, as these virtual registers can have long; live ranges. This can be mitigated by running a `localizer <https://github.com/llvm/llvm-project/blob/main/llvm/lib/CodeGen/GlobalISel/Localizer.cpp>`_; after the translator.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst:2747,avoid,avoiding,2747,interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst,2,"['avoid', 'redund']","['avoiding', 'redundant']"
Safety,". Tree. Changed the MaxTreeSize default from 1.9 GBytes to 100 GBytes.; Add new special functions in TTreeFormula (and hence TTree::Draw and TTree::Scan) to calculate the minimun and maximum with an entry:; ; Min$(formula),Max$(formula):return the minimun/maximum (within one TTree entry) of the value of the; elements of the formula given as a parameter.; MinIf$(formula,condition),MaxIf$(formula,condition):return the minimum (maximum) (within one TTree entry); of the value of the elements of the formula given as a parameter; if they match the condition. If not element match the condition, the result is zero. To avoid the; the result is zero. To avoid the consequent peak a zero, use the; pattern:; tree->Draw(""MinIf$(formula,condition)"",""condition"");; which will avoid calculation MinIf$ for the entries that have no match; for the condition. Add support in TTreeFormula (and hence TTree::Draw and TTree::Scan) for the ternary condition operator ( cond ? if_expr : else_expr ).; Significantly (by 2 order of magnitude) improved the performance of TTree::Draw calling C++ functions.; Replace the function TSelectorDraw::MakeIndex and TSelectorDraw::GetNameByIndex; with the function TSelectorDraw::SplitNames. ; Add a return value to SetBranchAddress, a return value greater or equal to zero indicate success, a negative; value indicates failure (in both case, the address is still updated). Example:; if (tree->SetBranchAddress(mybranch,&myvar) < 0) {; cerr << ""Something went wrong\n"";; return;; }; The possible return values are:; kMissingBranch (-5) : Missing branch; kInternalError (-4) : Internal error (could not find the type corresponding to a data type number.; kMissingCompiledCollectionProxy (-3) : Missing compiled collection proxy for a compiled collection.; kMismatch (-2) : Non-Class Pointer type given does not match the type expected by the branch.; kClassMismatch (-1) : Class Pointer type given does not match the type expected by the branch.; kMatch (0) : perfect match.; kM",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:618,avoid,avoid,618,tree/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html,3,['avoid'],['avoid']
Safety,". Tree. Restore support for IsAutoDelete in a TBranchElement (IsAutoDelete is an explicit request by the user to have the object deleted/newed each time GetEntry is called).; Allow .root in the name of directory in TChain::Add and TChain::AddFile (however in this case the root file must be ending .root.); Improve support for circular TTree friendship in LoadTree.; Insure that the in-memory tree (not attached to a file) are saved in their new style (i.e. each basket saved separately) and prevent the printing of the misleading error message:; Error in : Cannot create key without file ; Repaired TTreeSQL:; The existing code was not compatible with the change made in TTree to reduce the number of baskets in memory.; If the TreeFriend is entered via a TTree*, properly detect that it is in the same file and do not record the filename (since we will alway know where to find it.); Add "","" in the list of special characters replaced by ""_"" in the TTree::MakeClass; and TTree::MakeCode functions.; The fast cloning now explicitly rejects trying to merge TTrees with different split level; The fast cloning now supports the case where one of the branch in the output tree in; not present and also supports the case where branch are not the same order.; New bit flag kMapObject [mybranch->ResetBit(kMapObject)] to explicitly disable the; object registration during streaming within a branch (Use only if you are sure that there; is not a pointer pointing back to the nesting object within this branch). Fix tree->Draw(""s1.value"");; when the top level branch does not have a trailing dot; (and hence the real branch name is only 'value'). Fixed support for vector<bool> and vector<string> ; Added support for top level object that do not inherit from TObject _AND_ have a custom streamer (like std::string and TString);; Tree Viewer. In TParallelCoordVar the ""average marker"" for candle plots was not painted at; the right place in case of horizontal view.; Protection added in:; TParallelCoord::TPara",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html:774,detect,detect,774,tree/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html,1,['detect'],['detect']
Safety,". Tree. Significantly improve performance of TTree Proxy.; Improve read performance of sub-branch containing vector of single types.; Fix TTree::LoadBasket to properly handle the (new) case where no basket is stored with the TTree object.; Fix the axis used for an histogram created by TTree::Draw for a branch of TString or std::string objects.; MakeProxy now correctly support branches that created with a leaflist with more than one leaf; (usually used for C-struct).; TTree::CloneTree and TChain::Merge in fast mode now can recover from some mismatch errors between; the input and output TTrees by falling back to using the 'slow' mode. In particular this allow; a 'fast cloning' to handle files that requires schema evolution (albeit it is of course much slower).; Make sure that the TTreeCache is not attempting to cache (wrongly) the content of branches that are in an auxiliary files.; Make sure that FillBuffer does it work when the learning phase is over even if the entry number is 'low' for the 'current' file of a chain.; If TTree::SetEventList is called, TTree::GetEntryList no longer relinquish ownership of the automatically created TEntryList; Add the ability to see the TTree UserInfo list from the TBrowser; Fix the case of reading a TTree containing an 'old' class layout that contained a std::vector that is no longer part of the current class layout; Implement direct interfaces from TTree to the result of TSelector::Draw; TTree:GetVal(int) and TTree::GetVar(int); In TTree::ReadFile add the possibility to read multiple input files and add support for large/wide Trees definition.; Added support for ""5-D"" plotting.; Added support for std::bitset; Reduce the memory used by the mechanism keeping track of the entry of variables sizes within a basket (fEntryOffset).; The memory used now automatically decrease if the number of entries in the basket is less than 1/4 oflength of fEntryOffset.; Also the default length fEntryOffset can be set via TTree::SetDefaultEntryOffsetLen ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html:528,recover,recover,528,tree/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html,1,['recover'],['recover']
Safety,". Understanding Collections. Understanding Collections. A collection is a group of related objects. You will find it easier to; manage a large number of items as a collection. For example, collections of; points and lines might be managed by a graphics pad. A vertex will have a; collection of tracks. A detector geometry contains collections of shapes,; materials, rotation matrices and sub-detectors.; Collections act as flexible alternatives to traditional data structures; of computer science such as arrays, lists, and trees. Collections can be thought of as polymorphic containers that can contain; different types of elements. For this release of the ROOT system, elements; to be placed in collections must be instances of classes.; These may be classes defined by you or provided by ROOT. Collection elements; must be instances of classes descending from ; TObject. The dependence of collections on TObject may disappear; in the future when all C++ compilers used with the ROOT system fully; support templates. In the mean time, knowing the; role TObject plays in collections can be helpful. In general you don't need to worry about TObject. Many ROOT; classes have TObject as an ancestor. In fact, collections themselves; are descendants of TObject. This makes it possible for collections to; contain other collections (subcollections) in a tree structure. Such trees; are used in the ROOT system to implement components of the graphics system; (graphics pads containing pads), geometries (detectors in detectors), etc. The basic protocol TObject defines for collection elements is shown below:. IsEqual(); Compare(); IsSortable(); Hash(). How to use and override these member functions is shown in the; example program. Types of Collections. The ROOT system implements the following type of collections:; arrays, lists, sorted lists, B-trees, hashtables and maps.; The figure below shows the inheritance hierarchy for the primary; collection classes. Ordered Collections (Sequences). Sequenc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/cont/doc/Understanding_Collections.html:304,detect,detector,304,core/cont/doc/Understanding_Collections.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/cont/doc/Understanding_Collections.html,2,['detect'],"['detector', 'detectors']"
Safety,"., 3.);; TH1F * h2 = new TH1F(""h2"", ""h2"", 100, -3., 3.);; h1->FillRandom(""gaus"", 5000);; h2->FillRandom(""gaus"", 4000);; h1->SetMaximum(100);; h1->Draw();; h2->Draw(""same"");; }; . In some case, when a graph had some vertical parts, the exclusion; zone was not drawn correctly. The following small example shows the; problem:; ; {; TCanvas *c1 = new TCanvas();; gPad->DrawFrame(-1,-1,3,3);. TGraph * graph=new TGraph(3);; graph->SetFillColor(3);; graph->SetFillStyle(3001);; graph->SetLineWidth(2000);. graph->SetPoint(0,1.,1.);; graph->SetPoint(1,1.,0);; graph->SetPoint(2,0.,0.);; graph->Draw(""*L"");; }; . TUnfold. Add a new version. A new class TUnfoldSys provides support for the propagation of systematic errors.; Some bugs were also fixed due to multiplication of addition of sparse matrices. Fitting Methods. Introduce a better treatment of the step size used when fitting an object with a TF1. Use now by default is not zero the error provided by TF1. In case of limits use an appropriate step size to avoid Minuit to go over the limits.; Fix bug https://savannah.cern.ch/bugs/?45909 when fitting with bad range values (outside the histogram range).; detect the case when the data set is empty and don't perform any minimizationin this case but exits from fitting and produce a warning message; Fix a bug when fitting histograms with option W and the bin errors are = 0.; Fix a bug in the InitGaus function when having only one data point (see https://savannah.cern.ch/bugs/?48936); Fix a bug in calculating the error on the integral after having fitted when fix parameters were present; Fix a bug in calculating the confidence intervas when the number of bins for the given object is different from the number of bins of the fitted object.; ; FitPanel. Add support for drawing the fit function confidence levels.; Make gaus the default function when fitting 1D objects.; Add GSL minimizer and use now a new widget for showing and selecting the list of available algorithms according to the min",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v524/index.html:8216,avoid,avoid,8216,hist/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v524/index.html,1,['avoid'],['avoid']
Safety,".. _loop-terminology:. ===========================================; LLVM Loop Terminology (and Canonical Forms); ===========================================. .. contents::; :local:. Loop Definition; ===============. Loops are an important concept for a code optimizer. In LLVM, detection; of loops in a control-flow graph is done by :ref:`loopinfo`. It is based; on the following definition. A loop is a subset of nodes from the control-flow graph (CFG; where; nodes represent basic blocks) with the following properties:. 1. The induced subgraph (which is the subgraph that contains all the; edges from the CFG within the loop) is strongly connected; (every node is reachable from all others). 2. All edges from outside the subset into the subset point to the same; node, called the **header**. As a consequence, the header dominates; all nodes in the loop (i.e. every execution path to any of the loop's; node will have to pass through the header). 3. The loop is the maximum subset with these properties. That is, no; additional nodes from the CFG can be added such that the induced; subgraph would still be strongly connected and the header would; remain the same. In computer science literature, this is often called a *natural loop*.; In LLVM, a more generalized definition is called a; :ref:`cycle <cycle-terminology>`. Terminology; -----------. The definition of a loop comes with some additional terminology:. * An **entering block** (or **loop predecessor**) is a non-loop node; that has an edge into the loop (necessarily the header). If there is; only one entering block, and its only edge is to the; header, it is also called the loop's **preheader**. The preheader; dominates the loop without itself being part of the loop. * A **latch** is a loop node that has an edge to the header. * A **backedge** is an edge from a latch to the header. * An **exiting edge** is an edge from inside the loop to a node outside; of the loop. The source of such an edge is called an **exiting block**, i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:278,detect,detection,278,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,1,['detect'],['detection']
Safety,".. _transformation-metadata:. ============================; Code Transformation Metadata; ============================. .. contents::; :local:. Overview; ========. LLVM transformation passes can be controlled by attaching metadata to; the code to transform. By default, transformation passes use heuristics; to determine whether or not to perform transformations, and when doing; so, other details of how the transformations are applied (e.g., which; vectorization factor to select).; Unless the optimizer is otherwise directed, transformations are applied; conservatively. This conservatism generally allows the optimizer to; avoid unprofitable transformations, but in practice, this results in the; optimizer not applying transformations that would be highly profitable. Frontends can give additional hints to LLVM passes on which; transformations they should apply. This can be additional knowledge that; cannot be derived from the emitted IR, or directives passed from the; user/programmer. OpenMP pragmas are an example of the latter. If any such metadata is dropped from the program, the code's semantics; must not change. Metadata on Loops; =================. Attributes can be attached to loops as described in :ref:`llvm.loop`.; Attributes can describe properties of the loop, disable transformations,; force specific transformations and set transformation options. Because metadata nodes are immutable (with the exception of; ``MDNode::replaceOperandWith`` which is dangerous to use on uniqued; metadata), in order to add or remove a loop attributes, a new ``MDNode``; must be created and assigned as the new ``llvm.loop`` metadata. Any; connection between the old ``MDNode`` and the loop is lost. The; ``llvm.loop`` node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attribut",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:627,avoid,avoid,627,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst,1,['avoid'],['avoid']
Safety,".. raw:: html. <style type=""text/css"">; .none { background-color: #FFCCCC }; .part { background-color: #FFFF99 }; .good { background-color: #CCFF99 }; </style>. .. role:: none; .. role:: part; .. role:: good. .. contents::; :local:. ==============; OpenMP Support; ==============. Clang fully supports OpenMP 4.5, almost all of 5.0 and most of 5.1/2.; Clang supports offloading to X86_64, AArch64, PPC64[LE], NVIDIA GPUs (all models) and AMD GPUs (all models). In addition, the LLVM OpenMP runtime `libomp` supports the OpenMP Tools; Interface (OMPT) on x86, x86_64, AArch64, and PPC64 on Linux, Windows, and macOS.; OMPT is also supported for NVIDIA and AMD GPUs. For the list of supported features from OpenMP 5.0 and 5.1; see `OpenMP implementation details`_ and `OpenMP 51 implementation details`_. General improvements; ====================; - New collapse clause scheme to avoid expensive remainder operations.; Compute loop index variables after collapsing a loop nest via the; collapse clause by replacing the expensive remainder operation with; multiplications and additions. - When using the collapse clause on a loop nest the default behavior; is to automatically extend the representation of the loop counter to; 64 bits for the cases where the sizes of the collapsed loops are not; known at compile time. To prevent this conservative choice and use; at most 32 bits, compile your program with the; `-fopenmp-optimistic-collapse`. GPU devices support; ===================. Data-sharing modes; ------------------. Clang supports two data-sharing models for Cuda devices: `Generic` and `Cuda`; modes. The default mode is `Generic`. `Cuda` mode can give an additional; performance and can be activated using the `-fopenmp-cuda-mode` flag. In; `Generic` mode all local variables that can be shared in the parallel regions; are stored in the global memory. In `Cuda` mode local variables are not shared; between the threads and it is user responsibility to share the required data; between the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst:879,avoid,avoid,879,interpreter/llvm-project/clang/docs/OpenMPSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst,1,['avoid'],['avoid']
Safety,"..; ->; tmp = *P; for () {; tmp += 1;; if () {; *P = tmp;; call();; tmp = *P;; } else ...; }; *P = tmp;. We now hoist the reload after the call (Transforms/GVN/lpre-call-wrap.ll), but; we don't sink the store. We need partially dead store sinking. //===---------------------------------------------------------------------===//. [LOAD PRE CRIT EDGE SPLITTING]. GCC PR37166: Sinking of loads prevents SROA'ing the ""g"" struct on the stack; leading to excess stack traffic. This could be handled by GVN with some crazy; symbolic phi translation. The code we get looks like (g is on the stack):. bb2:		; preds = %bb1; ..; 	%9 = getelementptr %struct.f* %g, i32 0, i32 0		; 	store i32 %8, i32* %9, align bel %bb3. bb3:		; preds = %bb1, %bb2, %bb; 	%c_addr.0 = phi %struct.f* [ %g, %bb2 ], [ %c, %bb ], [ %c, %bb1 ]; 	%b_addr.0 = phi %struct.f* [ %b, %bb2 ], [ %g, %bb ], [ %b, %bb1 ]; 	%10 = getelementptr %struct.f* %c_addr.0, i32 0, i32 0; 	%11 = load i32* %10, align 4. %11 is partially redundant, an in BB2 it should have the value %8. GCC PR33344 and PR35287 are similar cases. //===---------------------------------------------------------------------===//. [LOAD PRE]. There are many load PRE testcases in testsuite/gcc.dg/tree-ssa/loadpre* in the; GCC testsuite, ones we don't get yet are (checked through loadpre25):. [CRIT EDGE BREAKING]; predcom-4.c. [PRE OF READONLY CALL]; loadpre5.c. [TURN SELECT INTO BRANCH]; loadpre14.c loadpre15.c . actually a conditional increment: loadpre18.c loadpre19.c. //===---------------------------------------------------------------------===//. [LOAD PRE / STORE SINKING / SPEC HACK]. This is a chunk of code from 456.hmmer:. int f(int M, int *mc, int *mpp, int *tpmm, int *ip, int *tpim, int *dpp,; int *tpdm, int xmb, int *bp, int *ms) {; int k, sc;; for (k = 1; k <= M; k++) {; mc[k] = mpp[k-1] + tpmm[k-1];; if ((sc = ip[k-1] + tpim[k-1]) > mc[k]) mc[k] = sc;; if ((sc = dpp[k-1] + tpdm[k-1]) > mc[k]) mc[k] = sc;; if ((sc = xmb + bp[k]) > mc[k]) mc[k] = s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:33230,redund,redundant,33230,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['redund'],['redundant']
Safety,"..; }. return 0;; }. This code has several problems if the body of the ``'if'`` is large. When; you're looking at the top of the function, it isn't immediately clear that this; *only* does interesting things with non-terminator instructions, and only; applies to things with the other predicates. Second, it is relatively difficult; to describe (in comments) why these predicates are important because the ``if``; statement makes it difficult to lay out the comments. Third, when you're deep; within the body of the code, it is indented an extra level. Finally, when; reading the top of the function, it isn't clear what the result is if the; predicate isn't true; you have to read to the end of the function to know that; it returns null. It is much preferred to format the code like this:. .. code-block:: c++. Value *doSomething(Instruction *I) {; // Terminators never need 'something' done to them because ...; if (I->isTerminator()); return 0;. // We conservatively avoid transforming instructions with multiple uses; // because goats like cheese.; if (!I->hasOneUse()); return 0;. // This is really just here for example.; if (!doOtherThing(I)); return 0;. ... some long code ....; }. This fixes these problems. A similar problem frequently happens in ``for``; loops. A silly example is something like this:. .. code-block:: c++. for (Instruction &I : BB) {; if (auto *BO = dyn_cast<BinaryOperator>(&I)) {; Value *LHS = BO->getOperand(0);; Value *RHS = BO->getOperand(1);; if (LHS != RHS) {; ...; }; }; }. When you have very, very small loops, this sort of structure is fine. But if it; exceeds more than 10-15 lines, it becomes difficult for people to read and; understand at a glance. The problem with this sort of code is that it gets very; nested very quickly. Meaning that the reader of the code has to keep a lot of; context in their brain to remember what is going immediately on in the loop,; because they don't know if/when the ``if`` conditions will have ``else``\s etc.; It is strongl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:36823,avoid,avoid,36823,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['avoid'],['avoid']
Safety,".; ============================= ====================================================================. Examples:. .. parsed-literal::. offset:-1; offset:0xfffff; offset:-x. VINTRP/VINTERP/LDSDIR Modifiers; -------------------------------. .. _amdgpu_synid_high:. high; ~~~~. Specifies which half of the LDS word to use. Low half of LDS word is used by default. ======================================== ================================; Syntax Description; ======================================== ================================; high Use the high half of LDS word.; ======================================== ================================. neg; ~~~. See a description :ref:`here<amdgpu_synid_neg>`. .. _amdgpu_synid_wait_exp:. wait_exp; ~~~~~~~~. Specifies a wait on the EXP counter before issuing the current instruction.; The counter must be less than or equal to this value before the instruction is issued.; If set to 7, no wait is performed. The default value is zero. This is a safe value, but it may be suboptimal. ================ ======================================================; Syntax Description; ================ ======================================================; wait_exp:{0..7} An additional wait on the EXP counter before; issuing this instruction.; ================ ======================================================. .. _amdgpu_synid_wait_vdst:. wait_vdst; ~~~~~~~~~. Specifies a wait on the VA_VDST counter before issuing the current instruction.; The counter must be less than or equal to this value before the instruction is issued.; If set to 15, no wait is performed. The default value is zero. This is a safe value, but it may be suboptimal. ================== ======================================================; Syntax Description; ================== ======================================================; wait_vdst:{0..15} An additional wait on the VA_VDST counter before; issuing this instruction.; ================== ================================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:36023,safe,safe,36023,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,1,['safe'],['safe']
Safety,".; Implement a new function in the MnUserTransformation class, FindIndex(name), which returns -1 when the parameter name does not exist.; Implement new methods in Minuit2Minimizer as requested by the Minimizer interface:; SetPrecision(double eps) to change the precision value used internally in Minuit2 (in MnPrecision), VariableName(index) to return the name of a variable (parameter) given an index, and VariableIndex(name) to return the index of a variable given a name.; Set a status code in Minuit2Minimizer according to the following convention:; status = minimizeStatus + 10 * minosStatus + 100 * hesseStatus.; See the Minuit2Minimizer reference documentation for the possible values of minimizeStatus , minosStatus and hesseStatus.; In MnHesse. when the inversion of the hessian matrix failed, return MnInvertFailed instead of MnHesseFailed. Mathcore Fitting classes. Fix the fitting with the integral option in multi-dimensions.; Force the gradient calculation when requested in the minimizer; classes and avoid to perform the check when using TMinuit. This was; already the case in Minuit2.; Add new class ROOT::Fit::SparseData for dealing with binned sparse data. This class automatically merges the empty region, so they can be considered, whenever possible as a larger single bin. This improves the performances when doing likelihood fits on the sparse data.; Fix the likelihood fits for variable bin histograms. Now a correct normalization is applied according to the bin volume.; Add new methods in Minimizer class :. Minimizer::SetPrecision(double eps) to change in the minimizer the precision on which the objective functions are evaluated. By default the numerical double precision is used inside the minimizers. This method should be used only if the precision in the function evaluation is worse than the double precision.; std::string Minimizer::VariableName (unsigned int index) to return a name of the minimizer variable (i.e. a fitting parameter) given the integer index. Ret",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v526/index.html:2814,avoid,avoid,2814,math/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v526/index.html,1,['avoid'],['avoid']
Safety,".] ] [dir1 [dir2 ...] ]. If a list of files (rather than directories) are passed to the fuzzer program,; then it will re-run those files as test inputs but will not perform any fuzzing.; In this mode the fuzzer binary can be used as a regression test (e.g. on a; continuous integration system) to check the target function and saved inputs; still work. The most important command line options are:. ``-help``; Print help message (``-help=1``).; ``-seed``; Random seed. If 0 (the default), the seed is generated.; ``-runs``; Number of individual test runs, -1 (the default) to run indefinitely.; ``-max_len``; Maximum length of a test input. If 0 (the default), libFuzzer tries to guess; a good value based on the corpus (and reports it).; ``-len_control``; Try generating small inputs first, then try larger inputs over time.; Specifies the rate at which the length limit is increased (smaller == faster).; Default is 100. If 0, immediately try inputs with size up to max_len.; ``-timeout``; Timeout in seconds, default 1200. If an input takes longer than this timeout,; the process is treated as a failure case.; ``-rss_limit_mb``; Memory usage limit in Mb, default 2048. Use 0 to disable the limit.; If an input requires more than this amount of RSS memory to execute,; the process is treated as a failure case.; The limit is checked in a separate thread every second.; If running w/o ASAN/MSAN, you may use 'ulimit -v' instead.; ``-malloc_limit_mb``; If non-zero, the fuzzer will exit if the target tries to allocate this; number of Mb with one malloc call.; If zero (default) same limit as rss_limit_mb is applied.; ``-timeout_exitcode``; Exit code (default 77) used if libFuzzer reports a timeout.; ``-error_exitcode``; Exit code (default 77) used if libFuzzer itself (not a sanitizer) reports a bug (leak, OOM, etc).; ``-max_total_time``; If positive, indicates the maximum total time in seconds to run the fuzzer.; If 0 (the default), run indefinitely.; ``-merge``; If set to 1, any corpus inpu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:10698,timeout,timeout,10698,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['timeout'],['timeout']
Safety,".g.: multiplication on 2; and 'shl 1'). It could happen due to several reasons: mainly, the usage of; templates and automatic code generators. Though, sometimes the user itself could; write the same thing twice :-). The main purpose of this pass is to recognize such functions and merge them. This document is the extension to pass comments and describes the pass logic. It; describes the algorithm that is used in order to compare functions and; explains how we could combine equal functions correctly to keep the module; valid. Material is brought in a top-down form, so the reader could start to learn pass; from high level ideas and end with low-level algorithm details, thus preparing; him or her for reading the sources. The main goal is to describe the algorithm and logic here and the concept. If; you *don't want* to read the source code, but want to understand pass; algorithms, this document is good for you. The author tries not to repeat the; source-code and covers only common cases to avoid the cases of needing to; update this document after any minor code changes. What should I know to be able to follow along with this document?; -----------------------------------------------------------------. The reader should be familiar with common compile-engineering principles and; LLVM code fundamentals. In this article, we assume the reader is familiar with; `Single Static Assignment; <http://en.wikipedia.org/wiki/Static_single_assignment_form>`_; concept and has an understanding of; `IR structure <https://llvm.org/docs/LangRef.html#high-level-structure>`_. We will use terms such as; ""`module <https://llvm.org/docs/LangRef.html#high-level-structure>`_"",; ""`function <https://llvm.org/docs/ProgrammersManual.html#the-function-class>`_"",; ""`basic block <http://en.wikipedia.org/wiki/Basic_block>`_"",; ""`user <https://llvm.org/docs/ProgrammersManual.html#the-user-class>`_"",; ""`value <https://llvm.org/docs/ProgrammersManual.html#the-value-class>`_"",; ""`instruction; <https://llvm.o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst:1294,avoid,avoid,1294,interpreter/llvm-project/llvm/docs/MergeFunctions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst,1,['avoid'],['avoid']
Safety,".value`` intrinsics essentially form an; imperative program embedded in the IR, with each intrinsic defining a variable; location. This *could* be converted to an SSA form by mem2reg, in the same way; that it uses use-def chains to identify control flow merges and insert phi; nodes for IR Values. However, because debug variable locations are defined for; every machine instruction, in effect every IR instruction uses every variable; location, which would lead to a large number of debugging intrinsics being; generated. Examining the example above, variable ``!30`` is assigned ``%input`` on both; conditional paths through the function, while ``!23`` is assigned differing; constant values on either path. Where control flow merges in ``%bb1`` we would; want ``!30`` to keep its location (``%input``), but ``!23`` to become undefined; as we cannot determine at runtime what value it should have in %bb1 without; inserting a PHI node. mem2reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.values; to avoid adding very large numbers of intrinsics. Instead, LiveDebugValues determines variable locations when control; flow merges. A dataflow analysis is used to propagate locations between blocks:; when control flow merges, if a variable has the same location in all; predecessors then that location is propagated into the successor. If the; predecessor locations disagree, the location becomes undefined. Once LiveDebugValues has run, every block should have all valid variable; locations described by DBG_VALUE instructions within the block. Very little; effort is then required by supporting classes (such as; DbgEntityHistoryCalculator) to build a map of each instruction to every; valid variable location, without the need to consider control flow. From; the example above, it is otherwise difficult to determine that the location; of variable ``!30`` should flow ""up"" into block ``%bb1``, but that the location; of variab",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:39229,avoid,avoid,39229,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['avoid'],['avoid']
Safety,"/ ...; }. // my_source2.c (enables -fbounds-safety); #include <stdio.h>; void example_forge_single(void) {; FILE *fp = __unsafe_forge_single(FILE *, fopen(""mypath"", ""rb""));; // ...; }. * Function ``example_forge_single`` takes a file handle by calling fopen defined; in system header ``stdio.h``. Assuming ``stdio.h`` did not adopt; ``-fbounds-safety``, the return type of ``fopen`` would implicitly be ``FILE; *__unsafe_indexable`` and thus it cannot be directly assigned to ``FILE *fp``; in the bounds-safe source. To allow this operation, ``__unsafe_forge_single``; is used to create a ``__single`` from the return value of ``fopen``. * Similar to ``__unsafe_indexable``, any non-pointer type (including ``int``,; ``intptr_t``, ``uintptr_t``, etc.) cannot be converted to any safe pointer; type because these don't have bounds information. ``__unsafe_forge_single`` or; ``__unsafe_forge_bidi_indexable`` must be used to force the conversion. * Any safe pointer types can cast to ``__unsafe_indexable`` because it doesn't; have any invariant to maintain. * ``__single`` casts to ``__bidi_indexable`` if the pointee type has a known; size. After the conversion, the resulting ``__bidi_indexable`` has the size of; a single object of the pointee type of ``__single``. ``__single`` cannot cast; to ``__bidi_indexable`` if the pointee type is incomplete or sizeless. For; example, ``void *__single`` cannot convert to ``void *__bidi_indexable``; because void is an incomplete type and thus the compiler cannot correctly; determine the upper bound of a single void pointer. * Similarly, ``__single`` can cast to ``__indexable`` if the pointee type has a; known size. The resulting ``__indexable`` has the size of a single object of; the pointee type. * ``__single`` casts to ``__counted_by(E)`` only if ``E`` is 0 or 1. * ``__single`` can cast to ``__single`` including when they have different; pointee types as long as it is allowed in the underlying C standard.; ``-fbounds-safety`` doesn't guarantee",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:42013,safe,safe,42013,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['safe'],['safe']
Safety,"/ Representing sign/zero extension of function results; //===----------------------------------------------------------------------===//. Mar 25, 2009 - Initial Revision. Most ABIs specify that functions which return small integers do so in a; specific integer GPR. This is an efficient way to go, but raises the question:; if the returned value is smaller than the register, what do the high bits hold?. There are three (interesting) possible answers: undefined, zero extended, or; sign extended. The number of bits in question depends on the data-type that; the front-end is referencing (typically i1/i8/i16/i32). Knowing the answer to this is important for two reasons: 1) we want to be able; to implement the ABI correctly. If we need to sign extend the result according; to the ABI, we really really do need to do this to preserve correctness. 2); this information is often useful for optimization purposes, and we want the; mid-level optimizers to be able to process this (e.g. eliminate redundant; extensions). For example, lets pretend that X86 requires the caller to properly extend the; result of a return (I'm not sure this is the case, but the argument doesn't; depend on this). Given this, we should compile this:. int a();; short b() { return a(); }. into:. _b:; 	subl	$12, %esp; 	call	L_a$stub; 	addl	$12, %esp; 	cwtl; 	ret. An optimization example is that we should be able to eliminate the explicit; sign extension in this example:. short y();; int z() {; return ((int)y() << 16) >> 16;; }. _z:; 	subl	$12, %esp; 	call	_y; 	;; movswl %ax, %eax -> not needed because eax is already sext'd; 	addl	$12, %esp; 	ret. //===----------------------------------------------------------------------===//; // What we have right now.; //===----------------------------------------------------------------------===//. Currently, these sorts of things are modelled by compiling a function to return; the small type and a signext/zeroext marker is used. For example, we compile; Z into:. define i32 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendedIntegerResults.txt:1077,redund,redundant,1077,interpreter/llvm-project/llvm/docs/ExtendedIntegerResults.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendedIntegerResults.txt,1,['redund'],['redundant']
Safety,"/* comment */; public:; foo() {}; private:; protected:; };. * ``ELBAMS_Leave`` (in configuration: ``Leave``); Keep existing empty lines before access modifiers. * ``ELBAMS_LogicalBlock`` (in configuration: ``LogicalBlock``); Add empty line only when access modifier starts a new logical block.; Logical block is a group of one or more member fields or functions. .. code-block:: c++. struct foo {; private:; int i;. protected:; int j;; /* comment */; public:; foo() {}. private:; protected:; };. * ``ELBAMS_Always`` (in configuration: ``Always``); Always add empty line before access modifiers unless access modifier; is at the start of struct or class definition. .. code-block:: c++. struct foo {; private:; int i;. protected:; int j;; /* comment */. public:; foo() {}. private:. protected:; };. .. _ExperimentalAutoDetectBinPacking:. **ExperimentalAutoDetectBinPacking** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <ExperimentalAutoDetectBinPacking>`; If ``true``, clang-format detects whether function calls and; definitions are formatted with one parameter per line. Each call can be bin-packed, one-per-line or inconclusive. If it is; inconclusive, e.g. completely on one line, but a decision needs to be; made, clang-format analyzes whether there are other bin-packed cases in; the input file and act accordingly. .. note::. This is an experimental flag, that might go away or be renamed. Do; not use this in config files, etc. Use at your own risk. .. _FixNamespaceComments:. **FixNamespaceComments** (``Boolean``) :versionbadge:`clang-format 5` :ref:`¶ <FixNamespaceComments>`; If ``true``, clang-format adds missing namespace end comments for; namespaces and fixes invalid existing ones. This doesn't affect short; namespaces, which are controlled by ``ShortNamespaceLines``. .. code-block:: c++. true: false:; namespace longNamespace { vs. namespace longNamespace {; void foo(); void foo();; void bar(); void bar();; } // namespace a }; namespace shortNamespace { namespace shor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:63015,detect,detects,63015,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['detect'],['detects']
Safety,"//===----------------------------------------------------------------------===//; // C Language Family Front-end; //===----------------------------------------------------------------------===//; Chris Lattner. I. Introduction:; ; clang: noun; 1. A loud, resonant, metallic sound.; 2. The strident call of a crane or goose.; 3. C-language family front-end toolkit. The world needs better compiler tools, tools which are built as libraries. This; design point allows reuse of the tools in new and novel ways. However, building; the tools as libraries isn't enough: they must have clean APIs, be as; decoupled from each other as possible, and be easy to modify/extend. This; requires clean layering, decent design, and avoiding tying the libraries to a; specific use. Oh yeah, did I mention that we want the resultant libraries to; be as fast as possible? :). This front-end is built as a component of the LLVM toolkit that can be used; with the LLVM backend or independently of it. In this spirit, the API has been; carefully designed as the following components:; ; libsupport - Basic support library, reused from LLVM. libsystem - System abstraction library, reused from LLVM.; ; libbasic - Diagnostics, SourceLocations, SourceBuffer abstraction,; file system caching for input source files. This depends on; libsupport and libsystem. libast - Provides classes to represent the C AST, the C type system,; builtin functions, and various helpers for analyzing and; manipulating the AST (visitors, pretty printers, etc). This; library depends on libbasic. liblex - C/C++/ObjC lexing and preprocessing, identifier hash table,; pragma handling, tokens, and macros. This depends on libbasic. libparse - C (for now) parsing and local semantic analysis. This library; invokes coarse-grained 'Actions' provided by the client to do; stuff (e.g. libsema builds ASTs). This depends on liblex. libsema - Provides a set of parser actions to build a standardized AST; for programs. AST's are 'streamed' out a top-le",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2007-OriginalClangReadme.txt:717,avoid,avoiding,717,interpreter/llvm-project/llvm/docs/HistoricalNotes/2007-OriginalClangReadme.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2007-OriginalClangReadme.txt,1,['avoid'],['avoiding']
Safety,"//===---------------------------------------------------------------------===//; // Random ideas for the ARM backend (Thumb specific).; //===---------------------------------------------------------------------===//. * Add support for compiling functions in both ARM and Thumb mode, then taking; the smallest. * Add support for compiling individual basic blocks in thumb mode, when in a ; larger ARM function. This can be used for presumed cold code, like paths; to abort (failure path of asserts), EH handling code, etc. * Thumb doesn't have normal pre/post increment addressing modes, but you can; load/store 32-bit integers with pre/postinc by using load/store multiple; instrs with a single register. * Make better use of high registers r8, r10, r11, r12 (ip). Some variants of add; and cmp instructions can use high registers. Also, we can use them as; temporaries to spill values into. * In thumb mode, short, byte, and bool preferred alignments are currently set; to 4 to accommodate ISA restriction (i.e. add sp, #imm, imm must be multiple; of 4). //===---------------------------------------------------------------------===//. Potential jumptable improvements:. * If we know function size is less than (1 << 16) * 2 bytes, we can use 16-bit; jumptable entries (e.g. (L1 - L2) >> 1). Or even smaller entries if the; function is even smaller. This also applies to ARM. * Thumb jumptable codegen can improve given some help from the assembler. This; is what we generate right now:. 	.set PCRELV0, (LJTI1_0_0-(LPCRELL0+4)); LPCRELL0:; 	mov r1, #PCRELV0; 	add r1, pc; 	ldr r0, [r0, r1]; 	mov pc, r0 ; 	.align	2; LJTI1_0_0:; 	.long	 LBB1_3; ... Note there is another pc relative add that we can take advantage of.; add r1, pc, #imm_8 * 4. We should be able to generate:. LPCRELL0:; 	add r1, LJTI1_0_0; 	ldr r0, [r0, r1]; 	mov pc, r0 ; 	.align	2; LJTI1_0_0:; 	.long	 LBB1_3. if the assembler can translate the add to:; add r1, pc, #((LJTI1_0_0-(LPCRELL0+4))&0xfffffffc). Note the assembler also doe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README-Thumb.txt:466,abort,abort,466,interpreter/llvm-project/llvm/lib/Target/ARM/README-Thumb.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README-Thumb.txt,1,['abort'],['abort']
Safety,"/TProcessExecutor. ### Thread safety; - Resolved several race conditions, dead-locks, performance and order of initialization/destruction issues still lingering because of or despite the new read-write lock mechanism. ## Interpreter. - Enabled use of multi-threaded code from the interpreter.; - Previouslyl multi-threaded code could be run from the interpreter as long as the call starting the threada was the same code that initialized the ROOT global lock, any other uses, including attempting to run the same code a second time in the same session would lead to a dead lock (if any other thread attempted to take on the ROOT lock).; - The interpreter now suspend the ROOT lock (which is taken to protect the interpreter global state) during user code execution. ## I/O Libraries; - LZ4 (with compression level 4) is now the default compression algorithm for new ROOT files (LZ4 is lossless data compression algorithm that is focused on compression and decompression speed, while in ROOT case providing benefit in faster decompression at the price of a bit worse compression ratio comparing to ZLIB); - If two or more files have an identical streamer info record, this is only treated once therewith avoiding to take the global lock.; - Allow writing temporary objects (with same address) in the same TBuffer(s). A new flag to TBuffer*::WriteObject allows to skip the mechanism that prevent the 2nd streaming of an object. This allows the (re)use of temporary objects to store different data in the same buffer.; - Reuse branch proxies internally used by TTreeReader{Value,Array} therewith increasing performance when having multiple readers pointing to the same branch.; - Implement reading of objects data from JSON; - Provide TBufferJSON::ToJSON() and TBufferJSON::FromJSON() methods; - Provide TBufferXML::ToXML() and TBufferXML::FromXML() methods; - Converts NaN and Infinity values into null in JSON, there are no other direct equivalent. ## TTree Libraries; - Enable the TTreeCache by defaul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:3706,avoid,avoiding,3706,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['avoid'],['avoiding']
Safety,"/WLCG-AuthZ-WG/bearer-token-discovery/blob/master/specification.md). Short overview:. 1. If the `BEARER_TOKEN` environment variable is set, then the value is taken to be the token contents.; 2. If the `BEARER_TOKEN_FILE` environment variable is set, then its value is interpreted as a filename. The contents of the specified file are taken to be the token contents.; 3. If the `XDG_RUNTIME_DIR` environment variable is set, then take the token from the contents of `$XDG_RUNTIME_DIR/bt_u$ID`(this additional location is intended to provide improved security for shared login environments as `$XDG_RUNTIME_DIR` is defined to be user-specific as opposed to a system-wide directory.).; 4. Otherwise, take the token from `/tmp/bt_u$ID`. ## GUI Libraries. ### RBrowser improvements. - central factory methods to handle browsing, editing and drawing of different classes; - simple possibility to extend RBrowser on user-defined classes; - support of web-based geometry viewer; - better support of TTree drawing; - server-side handling of code editor and image viewer widgets; - rbrowser content is fully recovered when web-browser is reloaded; - load of widgets code only when really required (shorter startup time for RBrowser). ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ## JavaScript ROOT. ### Major JSROOT update to version 6. - update all used libraries `d3.js`, `three.js`, `MathJax.js`, openui5; - change to Promise based interface for all async methods, remove call-back arguments; - change scripts names, core scripts name now `JSRoot.core.js`; - unify function/methods naming conventions, many changes in method names; - provide central code loader via `JSROOT.require`, supporting 4 different loading engines; - many nice features and many bug fixes; see JSROOT v6 release notes. ## Tutorials. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. - a new cmake variable, `CMAKE_INSTALL_PYTHONDIR`, has been added: it allows customization of the i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:27140,recover,recovered,27140,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['recover'],['recovered']
Safety,"/a.out; WARNING: MemorySanitizer: use-of-uninitialized-value; #0 0x7f7893912f0b in main umr2.cc:7; #1 0x7f789249b76c in __libc_start_main libc-start.c:226. Uninitialized value was stored to memory at; #0 0x7f78938b5c25 in __msan_chain_origin msan.cc:484; #1 0x7f7893912ecd in main umr2.cc:6. Uninitialized value was created by a heap allocation; #0 0x7f7893901cbd in operator new[](unsigned long) msan_new_delete.cc:44; #1 0x7f7893912e06 in main umr2.cc:4. By default, MemorySanitizer collects both allocation points and all; intermediate stores the uninitialized value went through. Origin; tracking has proved to be very useful for debugging MemorySanitizer; reports. It slows down program execution by a factor of 1.5x-2x on top; of the usual MemorySanitizer slowdown and increases memory overhead. Clang option ``-fsanitize-memory-track-origins=1`` enables a slightly; faster mode when MemorySanitizer collects only allocation points but; not intermediate stores. Use-after-destruction detection; ===============================. MemorySanitizer includes use-after-destruction detection. After invocation of; the destructor, the object will be considered no longer readable, and using; underlying memory will lead to error reports in runtime. Refer to the standard; for `lifetime <https://eel.is/c++draft/basic.life#1>`_ definition. This feature can be disabled with either:. #. Pass addition Clang option ``-fno-sanitize-memory-use-after-dtor`` during; compilation.; #. Set environment variable `MSAN_OPTIONS=poison_in_dtor=0` before running; the program. Handling external code; ======================. MemorySanitizer requires that all program code is instrumented. This; also includes any libraries that the program depends on, even libc.; Failing to achieve this may result in false reports.; For the same reason you may need to replace all inline assembly code that writes to memory; with a pure C/C++ code. Full MemorySanitizer instrumentation is very difficult to achieve. To; make it eas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MemorySanitizer.rst:5382,detect,detection,5382,interpreter/llvm-project/clang/docs/MemorySanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MemorySanitizer.rst,1,['detect'],['detection']
Safety,/atoi.h; libc/src/stdlib/atol.cpp; libc/src/stdlib/atol.h; libc/src/stdlib/atoll.cpp; libc/src/stdlib/atoll.h; libc/src/stdlib/bsearch.cpp; libc/src/stdlib/bsearch.h; libc/src/stdlib/div.cpp; libc/src/stdlib/div.h; libc/src/stdlib/exit.cpp; libc/src/stdlib/exit.h; libc/src/stdlib/getenv.cpp; libc/src/stdlib/getenv.h; libc/src/stdlib/labs.cpp; libc/src/stdlib/labs.h; libc/src/stdlib/ldiv.cpp; libc/src/stdlib/ldiv.h; libc/src/stdlib/llabs.cpp; libc/src/stdlib/llabs.h; libc/src/stdlib/lldiv.cpp; libc/src/stdlib/lldiv.h; libc/src/stdlib/qsort.cpp; libc/src/stdlib/qsort.h; libc/src/stdlib/strtod.cpp; libc/src/stdlib/strtod.h; libc/src/stdlib/strtof.cpp; libc/src/stdlib/strtof.h; libc/src/stdlib/strtol.cpp; libc/src/stdlib/strtol.h; libc/src/stdlib/strtold.cpp; libc/src/stdlib/strtold.h; libc/src/stdlib/strtoll.cpp; libc/src/stdlib/strtoll.h; libc/src/stdlib/strtoul.cpp; libc/src/stdlib/strtoul.h; libc/src/stdlib/strtoull.cpp; libc/src/stdlib/strtoull.h; libc/src/stdlib/_Exit.h; libc/src/stdlib/linux/abort.cpp; libc/src/stdlib/linux/_Exit.cpp; libc/src/string/bcmp.cpp; libc/src/string/bcmp.h; libc/src/string/bzero.cpp; libc/src/string/bzero.h; libc/src/string/memccpy.cpp; libc/src/string/memccpy.h; libc/src/string/memchr.cpp; libc/src/string/memchr.h; libc/src/string/memcmp.cpp; libc/src/string/memcmp.h; libc/src/string/memcpy.cpp; libc/src/string/memcpy.h; libc/src/string/memmove.cpp; libc/src/string/memmove.h; libc/src/string/mempcpy.cpp; libc/src/string/mempcpy.h; libc/src/string/memrchr.cpp; libc/src/string/memrchr.h; libc/src/string/memset.cpp; libc/src/string/memset.h; libc/src/string/stpcpy.cpp; libc/src/string/stpcpy.h; libc/src/string/stpncpy.cpp; libc/src/string/stpncpy.h; libc/src/string/strcat.cpp; libc/src/string/strcat.h; libc/src/string/strchr.cpp; libc/src/string/strchr.h; libc/src/string/strcmp.cpp; libc/src/string/strcmp.h; libc/src/string/strcpy.cpp; libc/src/string/strcpy.h; libc/src/string/strcspn.cpp; libc/src/string/strcspn.h; libc/src/string/strdup.,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:142273,abort,abort,142273,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['abort'],['abort']
Safety,"/interleaved loop; Stmt(i:i+3);; }; for (; i < n; i+=1) // epilogue loop; Stmt(i);. where ``rtc`` is a generated runtime check. ``llvm.loop.vectorize.followup_vectorized`` will set the attributes for; the vectorized loop. If not specified, ``llvm.loop.isvectorized`` is; combined with the original loop's attributes to avoid it being; vectorized multiple times. ``llvm.loop.vectorize.followup_epilogue`` will set the attributes for; the remainder loop. If not specified, it will have the original loop's; attributes combined with ``llvm.loop.isvectorized`` and; ``llvm.loop.unroll.runtime.disable`` (unless the original loop already; has unroll metadata). The attributes specified by ``llvm.loop.vectorize.followup_all`` are; added to both loops. When using a follow-up attribute, it replaces any automatically deduced; attributes for the generated loop in question. Therefore it is; recommended to add ``llvm.loop.isvectorized`` to; ``llvm.loop.vectorize.followup_all`` which avoids that the loop; vectorizer tries to optimize the loops again. Loop Unrolling; --------------. Unrolling is interpreted as forced any ``!{!""llvm.loop.unroll.enable""}``; metadata or option (``llvm.loop.unroll.count``, ``llvm.loop.unroll.full``); is present. Unrolling can be full unrolling, partial unrolling of a loop; with constant trip count or runtime unrolling of a loop with a trip; count unknown at compile-time. If the loop has been unrolled fully, there is no followup-loop. For; partial/runtime unrolling, the original loop of. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; Stmt(i);. is transformed into (using an unroll factor of 4):. .. code-block:: c. int i = 0;; for (; i + 3 < n; i+=4) { // unrolled loop; Stmt(i);; Stmt(i+1);; Stmt(i+2);; Stmt(i+3);; }; for (; i < n; i+=1) // remainder loop; Stmt(i);. ``llvm.loop.unroll.followup_unrolled`` will set the loop attributes of; the unrolled loop. If not specified, the attributes of the original loop; without the ``llvm.loop.unroll.*``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:7037,avoid,avoids,7037,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst,1,['avoid'],['avoids']
Safety,"/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections to workers: OK (12 workers); Setting up worker servers: OK (12 workers); PROOF set to parallel mode (12 workers). ### Stop or restart your PoD cluster. At the end of your session, remember to free the workers by stopping; your PoD server:. vafctl --stop. > PoD will stop the PROOF master and the workers after detecting they've; > been idle for a certain amount of time anyway, but it is a good habit; > to stop it for yourself when you're finished using it, so that you are; > immediately freeing resources and let them be available for other; > users. In case of a major PROOF failure (i.e., crash), you can simply restart; your personal PROOF cluster by running:. vafctl --start. PoD will stop and restart the PROOF master. You'll need to request the; workers again at this point.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:12287,detect,detecting,12287,proof/doc/confman/UsingVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md,1,['detect'],['detecting']
Safety,"/utf-8 Set source and runtime encoding to UTF-8 (default); /U <macro> Undefine macro; /vd<value> Control vtordisp placement; /vmb Use a best-case representation method for member pointers; /vmg Use a most-general representation for member pointers; /vmm Set the default most-general representation to multiple inheritance; /vms Set the default most-general representation to single inheritance; /vmv Set the default most-general representation to virtual inheritance; /volatile:iso Volatile loads and stores have standard semantics; /volatile:ms Volatile loads and stores have acquire and release semantics; /W0 Disable all warnings; /W1 Enable -Wall; /W2 Enable -Wall; /W3 Enable -Wall; /W4 Enable -Wall and -Wextra; /Wall Enable -Weverything; /WX- Do not treat warnings as errors; /WX Treat warnings as errors; /w Disable all warnings; /X Don't add %INCLUDE% to the include search path; /Y- Disable precompiled headers, overrides /Yc and /Yu; /Yc<filename> Generate a pch file for all code up to and including <filename>; /Yu<filename> Load a pch file and use it instead of all code up to and including <filename>; /Z7 Enable CodeView debug information in object files; /Zc:char8_t Enable C++20 char8_t type; /Zc:char8_t- Disable C++20 char8_t type; /Zc:dllexportInlines- Don't dllexport/dllimport inline member functions of dllexport/import classes; /Zc:dllexportInlines dllexport/dllimport inline member functions of dllexport/import classes (default); /Zc:sizedDealloc- Disable C++14 sized global deallocation functions; /Zc:sizedDealloc Enable C++14 sized global deallocation functions; /Zc:strictStrings Treat string literals as const; /Zc:threadSafeInit- Disable thread-safe initialization of static variables; /Zc:threadSafeInit Enable thread-safe initialization of static variables; /Zc:trigraphs- Disable trigraphs (default); /Zc:trigraphs Enable trigraphs; /Zc:twoPhase- Disable two-phase name lookup in templates; /Zc:twoPhase Enable two-phase name lookup in templates; /Zi Alias for /Z7.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:177026,safe,safe,177026,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,['safe'],['safe']
Safety,"0 public: static const char *Class_Name();; (compiled) (NA):(NA) 0 public: static Version_t Class_Version();; (compiled) (NA):(NA) 0 public: static void Dictionary();; (compiled) (NA):(NA) 0 public: virtual class TClass *IsA() const;; (compiled) (NA):(NA) 0 public: virtual void ShowMembers(class TMemberInspector &insp) const;; (compiled) (NA):(NA) 0 public: virtual void Streamer(class TBuffer &);; (compiled) (NA):(NA) 0 public: void StreamerNVirtual(class TBuffer &ClassDef_StreamerNVirtual_b);; (compiled) (NA):(NA) 0 public: static const char *DeclFileName();; (compiled) (NA):(NA) 0 public: static int ImplFileLine();; (compiled) (NA):(NA) 0 public: static const char *ImplFileName();; (compiled) (NA):(NA) 0 public: static int DeclFileLine();; root [] .> test.log; root [] l.Dump();; root [] .>; root [] ?; ```. Here we see:. - Use `.class` as quick help and reference; - Unix like I/O redirection using `.> out.txt` and unredirection with `.>`; - Use `?` to get help on all ‘‘raw'' interpreter commands; - Use @ to abort a multi-line command. Now let us execute a multi-line command:. ``` {.cpp}; root [] {; root [] ? TLine l;; root [] ? for (int i = 0; i < 5; i++) {; root [] ? l.SetX1(i);; root [] ? l.SetY1(i+1);; root [] ? l.Print();; root [] ? }; root [] ? }; TLine X1=0.000000 Y1=1.000000 X2=0.000000 Y2=0.000000; TLine X1=1.000000 Y1=2.000000 X2=0.000000 Y2=0.000000; TLine X1=2.000000 Y1=3.000000 X2=0.000000 Y2=0.000000; TLine X1=3.000000 Y1=4.000000 X2=0.000000 Y2=0.000000; TLine X1=4.000000 Y1=5.000000 X2=0.000000 Y2=0.000000; root [] .q; ```. Here we note:. - A multi-line command starts with a { and ends with a }.; - Inside continuation, every line has to be correctly terminated with a ; (like in ""real''; C++).; - All objects are created in *global* scope.; - There is no way to back up; you are better off writing a script.; - Use `.q` to exit root. ## Feeding Sources Files To ROOT: C++ Scripts. ROOT script files (often called ""Macros"") contain pure C++ code. They can co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md:6634,abort,abort,6634,documentation/users-guide/Cling.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md,1,['abort'],['abort']
Safety,"0, i32 0; %3073 = call i8* @strcpy(i8* %3072, i8* %3071) nounwind; %strlen = call i32 @strlen(i8* %3072) ; uses = 1; %endptr = getelementptr [100 x i8]* %tempString, i32 0, i32 %strlen; call void @llvm.memcpy.i32(i8* %endptr, ; i8* getelementptr ([5 x i8]* @""\01LC42"", i32 0, i32 0), i32 5, i32 1); %3074 = call i32 @strlen(i8* %endptr) nounwind readonly ; ; This is interesting for a couple reasons. First, in this:. The memcpy+strlen strlen can be replaced with:. %3074 = call i32 @strlen([5 x i8]* @""\01LC42"") nounwind readonly . Because the destination was just copied into the specified memory buffer. This,; in turn, can be constant folded to ""4"". In other code, it contains:. %endptr6978 = bitcast i8* %endptr69 to i32* ; store i32 7107374, i32* %endptr6978, align 1; %3167 = call i32 @strlen(i8* %endptr69) nounwind readonly . Which could also be constant folded. Whatever is producing this should probably; be fixed to leave this as a memcpy from a string. Further, eon also has an interesting partially redundant strlen call:. bb8: ; preds = %_ZN18eonImageCalculatorC1Ev.exit; %682 = getelementptr i8** %argv, i32 6 ; <i8**> [#uses=2]; %683 = load i8** %682, align 4 ; <i8*> [#uses=4]; %684 = load i8* %683, align 1 ; <i8> [#uses=1]; %685 = icmp eq i8 %684, 0 ; <i1> [#uses=1]; br i1 %685, label %bb10, label %bb9. bb9: ; preds = %bb8; %686 = call i32 @strlen(i8* %683) nounwind readonly ; %687 = icmp ugt i32 %686, 254 ; <i1> [#uses=1]; br i1 %687, label %bb10, label %bb11. bb10: ; preds = %bb9, %bb8; %688 = call i32 @strlen(i8* %683) nounwind readonly . This could be eliminated by doing the strlen once in bb8, saving code size and; improving perf on the bb8->9->10 path. //===---------------------------------------------------------------------===//. I see an interesting fully redundant call to strlen left in 186.crafty:InputMove; which looks like:; %movetext11 = getelementptr [128 x i8]* %movetext, i32 0, i32 0 ; . bb62: ; preds = %bb55, %bb53; %promote.0 = phi i32 [ %169, %bb55",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:39356,redund,redundant,39356,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['redund'],['redundant']
Safety,"0, i32 2; store i32 %inc, ptr %inc.spill.addr; call void @print(i32 %n). ret ptr %frame; }. Outlined resume part of the coroutine will reside in function `f.resume`:. .. code-block:: llvm. define internal fastcc void @f.resume(ptr %frame.ptr.resume) {; entry:; %inc.spill.addr = getelementptr %f.frame, ptr %frame.ptr.resume, i64 0, i32 2; %inc.spill = load i32, ptr %inc.spill.addr, align 4; %inc = add i32 %inc.spill, 1; store i32 %inc, ptr %inc.spill.addr, align 4; tail call void @print(i32 %inc); ret void; }. Whereas function `f.destroy` will contain the cleanup code for the coroutine:. .. code-block:: llvm. define internal fastcc void @f.destroy(ptr %frame.ptr.destroy) {; entry:; tail call void @free(ptr %frame.ptr.destroy); ret void; }. Avoiding Heap Allocations; -------------------------. A particular coroutine usage pattern, which is illustrated by the `main`; function in the overview section, where a coroutine is created, manipulated and; destroyed by the same calling function, is common for coroutines implementing; RAII idiom and is suitable for allocation elision optimization which avoid; dynamic allocation by storing the coroutine frame as a static `alloca` in its; caller. In the entry block, we will call `coro.alloc`_ intrinsic that will return `true`; when dynamic allocation is required, and `false` if dynamic allocation is; elided. .. code-block:: llvm. entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %need.dyn.alloc = call i1 @llvm.coro.alloc(token %id); br i1 %need.dyn.alloc, label %dyn.alloc, label %coro.begin; dyn.alloc:; %size = call i32 @llvm.coro.size.i32(); %alloc = call ptr @CustomAlloc(i32 %size); br label %coro.begin; coro.begin:; %phi = phi ptr [ null, %entry ], [ %alloc, %dyn.alloc ]; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %phi). In the cleanup block, we will make freeing the coroutine frame conditional on; `coro.free`_ intrinsic. If allocation is elided, `coro.free`_ returns `null`; thus skipping t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:16498,avoid,avoid,16498,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['avoid'],['avoid']
Safety,"000010 andl $0x0000ffff,%eax; 00000015 cvtsi2ss %eax,%xmm1; 00000019 mulss 0x00000078,%xmm0; 00000021 addss %xmm1,%xmm0; 00000025 movss %xmm0,(%esp,1); 0000002a flds (%esp,1); 0000002d addl $0x04,%esp; 00000030 ret. //===---------------------------------------------------------------------===//. When using fastcc abi, align stack slot of argument of type double on 8 byte; boundary to improve performance. //===---------------------------------------------------------------------===//. GCC's ix86_expand_int_movcc function (in i386.c) has a ton of interesting; simplifications for integer ""x cmp y ? a : b"". //===---------------------------------------------------------------------===//. Consider the expansion of:. define i32 @test3(i32 %X) {; %tmp1 = urem i32 %X, 255; ret i32 %tmp1; }. Currently it compiles to:. ...; movl $2155905153, %ecx; movl 8(%esp), %esi; movl %esi, %eax; mull %ecx; ... This could be ""reassociated"" into:. movl $2155905153, %eax; movl 8(%esp), %ecx; mull %ecx. to avoid the copy. In fact, the existing two-address stuff would do this; except that mul isn't a commutative 2-addr instruction. I guess this has; to be done at isel time based on the #uses to mul?. //===---------------------------------------------------------------------===//. Make sure the instruction which starts a loop does not cross a cacheline; boundary. This requires knowning the exact length of each machine instruction.; That is somewhat complicated, but doable. Example 256.bzip2:. In the new trace, the hot loop has an instruction which crosses a cacheline; boundary. In addition to potential cache misses, this can't help decoding as I; imagine there has to be some kind of complicated decoder reset and realignment; to grab the bytes from the next cacheline. 532 532 0x3cfc movb (1809(%esp, %esi), %bl <<<--- spans 2 64 byte lines; 942 942 0x3d03 movl %dh, (1809(%esp, %esi); 937 937 0x3d0a incl %esi; 3 3 0x3d0b cmpb %bl, %dl; 27 27 0x3d0d jnz 0x000062db <main+11707>. //===----------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:10181,avoid,avoid,10181,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['avoid'],['avoid']
Safety,"1 <https://github.com/llvm/llvm-project/pull/76671>`_,; `#71373 <https://github.com/llvm/llvm-project/pull/71373>`_,; `#76557 <https://github.com/llvm/llvm-project/pull/76557>`_,; `#71392 <https://github.com/llvm/llvm-project/pull/71392>`_). - Fixed a false negative for when accessing a nonnull property (ObjC).; (`1dceba3a3684 <https://github.com/llvm/llvm-project/commit/1dceba3a3684d12394731e09a6cf3efcebf07a3a>`_). - ``security.insecureAPI.DeprecatedOrUnsafeBufferHandling`` now considers; ``fprintf`` calls unsafe.; `Documentation <https://clang.llvm.org/docs/analyzer/checkers.html#security-insecureapi-deprecatedorunsafebufferhandling-c>`__. - Improved the diagnostics of the ``optin.core.EnumCastOutOfRange`` checker.; It will display the name and the declaration of the enumeration along with; the concrete value being cast to the enum.; (`#74503 <https://github.com/llvm/llvm-project/pull/74503>`_). - Improved the ``alpha.security.ArrayBoundV2`` checker for detecting buffer; accesses prior the buffer; and also reworked the diagnostic messages.; (`3e014038b373 <https://github.com/llvm/llvm-project/commit/3e014038b373e5a4a96d89d46cea17e4d2456a04>`_,; `#70056 <https://github.com/llvm/llvm-project/pull/70056>`_,; `#72107 <https://github.com/llvm/llvm-project/pull/72107>`_). - Improved the ``alpha.unix.cstring.OutOfBounds`` checking both ends of the; buffers in more cases.; (`c3a87ddad62a <https://github.com/llvm/llvm-project/commit/c3a87ddad62a6cc01acaccc76592bc6730c8ac3c>`_,; `0954dc3fb921 <https://github.com/llvm/llvm-project/commit/0954dc3fb9214b994623f5306473de075f8e3593>`_). - Improved the ``alpha.unix.Stream`` checker by modeling more functions; ``fputs``, ``fputc``, ``fgets``, ``fgetc``, ``fdopen``, ``ungetc``, ``fflush``,; ``getdelim``, ``getline`` and no not recognize alternative; ``fopen`` and ``tmpfile`` implementations.; (`#78693 <https://github.com/llvm/llvm-project/pull/78693>`_,; `#76776 <https://github.com/llvm/llvm-project/pull/76776>`_,; `#74296 <https:/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:73896,detect,detecting,73896,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['detect'],['detecting']
Safety,"1 − Sampling is used for the first 'SamplingEpoch' epochs, afterwards, all events are taken for training. SamplingImportance No 1 − The sampling weights of events in epochs which successful (worse estimator than before) are multiplied with SamplingImportance, else they are divided. SamplingTraining No True − The training sample is sampled. SamplingTesting No False − The testing sample is sampled. ResetStep No 50 − How often BFGS should reset history. Tau No 3 − LineSearch size step. BPMode No sequential sequential, batch Back-propagation learning mode: sequential or batch. BatchSize No -1 − Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events. ConvergenceImprove No 1e-30 − Minimum improvement which counts as improvement (<0 means automatic convergence check is turned off). ConvergenceTests No -1 − Number of steps (without improvement) required for convergence (<0 means automatic convergence check is turned off). UseRegulator No False − Use regulator to avoid over-training. UpdateLimit No 10000 − Maximum times of regulator update. CalculateErrors No False − Calculates inverse Hessian matrix at the end of the training to be able to calculate the uncertainties of an MVA value. WeightRange No 1 − Take the events for the estimator calculations from small deviations from the desired value to large deviations only over the weight range. Configuration options for MVA method :. Configuration options reference for MVA method: Cuts. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all even",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:23806,avoid,avoid,23806,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,1,['avoid'],['avoid']
Safety,"1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim assignment; * Support tuple-based indexing for multi-dim arrays; * Direct support for C's _Complex (_Complex_double/_float on Windows); * sizeof() forwards to ctypes.sizeof() for ctypes' types; * Upgrade cmake fragments for Clang9; * Prevent clash with Julia's LLVM when loading cppyy into PyCall; * Upgrade to latest Cling patch release. 2021-05-14: 2.0.0; -----------------. * Upgrade to latest Cling based on Clang/LLVM 9; * Make C++17 the default standard on Windows. 2021-04-28: 1.9.6; -----------------. * Reverse operators for ``std::complex`` targeting Python's ``complex``; * Version the precompiled header with the ``cppyy-cling`` package version; * Cover more iterator protocol use cases; * Add missing cppyy/__pyinstaller pkg to sdist; * Single-inheritance support for cross-inherited templated constructors; * Disallow ``float`` -> ``const long long&`` conversion; * Capture python exception message string in PyException from callbacks; * Thread safety in enum lookups. 2021-03-22: 1.9.5; -----------------. * Do not regulate direct smart pointers (many to one can lead to double deletion); * Use pkg_resources of ``CPyCppyy``, if available, to find the API include path. 2021-03-17: 1.9.4; -----------------. * Fix for installing into a directory that has a space in the name; * Fix empty collection printing through Cling on 64b Windows; * Fix accidental shadowing of derived class typedefs by same names in base; * Streamlined templated function lookups in namespaces; * Fix edge cases when decomposing std::function template arguments; * Enable multi-cross inheritance with non-C++ python bases; * Support Bound C++ functions as template argument; * Python functions as template arguments from ``__annotations__`` or ``__cpp_nam",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:6742,safe,safety,6742,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['safe'],['safety']
Safety,"143; bne cr0, LBB1_83 ;bb420.i. The CBE manages to produce:. 	li r0, 143; 	mtctr r0; loop:; 	lbzx r2, r2, r11; 	stbx r0, r2, r9; 	addi r2, r2, 1; 	bdz later; 	b loop. This could be much better (bdnz instead of bdz) but it still beats us. If we; produced this with bdnz, the loop would be a single dispatch group. ===-------------------------------------------------------------------------===. Lump the constant pool for each function into ONE pic object, and reference; pieces of it as offsets from the start. For functions like this (contrived; to have lots of constants obviously):. double X(double Y) { return (Y*1.23 + 4.512)*2.34 + 14.38; }. We generate:. _X:; lis r2, ha16(.CPI_X_0); lfd f0, lo16(.CPI_X_0)(r2); lis r2, ha16(.CPI_X_1); lfd f2, lo16(.CPI_X_1)(r2); fmadd f0, f1, f0, f2; lis r2, ha16(.CPI_X_2); lfd f1, lo16(.CPI_X_2)(r2); lis r2, ha16(.CPI_X_3); lfd f2, lo16(.CPI_X_3)(r2); fmadd f1, f0, f1, f2; blr. It would be better to materialize .CPI_X into a register, then use immediates; off of the register to avoid the lis's. This is even more important in PIC ; mode. Note that this (and the static variable version) is discussed here for GCC:; http://gcc.gnu.org/ml/gcc-patches/2006-02/msg00133.html. Here's another example (the sgn function):; double testf(double a) {; return a == 0.0 ? 0.0 : (a > 0.0 ? 1.0 : -1.0);; }. it produces a BB like this:; LBB1_1: ; cond_true; lis r2, ha16(LCPI1_0); lfs f0, lo16(LCPI1_0)(r2); lis r2, ha16(LCPI1_1); lis r3, ha16(LCPI1_2); lfs f2, lo16(LCPI1_2)(r3); lfs f3, lo16(LCPI1_1)(r2); fsub f0, f0, f1; fsel f1, f0, f2, f3; blr . ===-------------------------------------------------------------------------===. PIC Code Gen IPO optimization:. Squish small scalar globals together into a single global struct, allowing the ; address of the struct to be CSE'd, avoiding PIC accesses (also reduces the size; of the GOT on targets with one). Note that this is discussed here for GCC:; http://gcc.gnu.org/ml/gcc-patches/2006-02/msg00133.html. ===----",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt:1842,avoid,avoid,1842,interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,1,['avoid'],['avoid']
Safety,"1F * h2 = new TH1F(""h2"", ""h2"", 100, -3., 3.);; h1->FillRandom(""gaus"", 5000);; h2->FillRandom(""gaus"", 4000);; h1->SetMaximum(100);; h1->Draw();; h2->Draw(""same"");; }; . In some case, when a graph had some vertical parts, the exclusion; zone was not drawn correctly. The following small example shows the; problem:; ; {; TCanvas *c1 = new TCanvas();; gPad->DrawFrame(-1,-1,3,3);. TGraph * graph=new TGraph(3);; graph->SetFillColor(3);; graph->SetFillStyle(3001);; graph->SetLineWidth(2000);. graph->SetPoint(0,1.,1.);; graph->SetPoint(1,1.,0);; graph->SetPoint(2,0.,0.);; graph->Draw(""*L"");; }; . TUnfold. Add a new version. A new class TUnfoldSys provides support for the propagation of systematic errors.; Some bugs were also fixed due to multiplication of addition of sparse matrices. Fitting Methods. Introduce a better treatment of the step size used when fitting an object with a TF1. Use now by default is not zero the error provided by TF1. In case of limits use an appropriate step size to avoid Minuit to go over the limits.; Fix bug https://savannah.cern.ch/bugs/?45909 when fitting with bad range values (outside the histogram range).; detect the case when the data set is empty and don't perform any minimizationin this case but exits from fitting and produce a warning message; Fix a bug when fitting histograms with option W and the bin errors are = 0.; Fix a bug in the InitGaus function when having only one data point (see https://savannah.cern.ch/bugs/?48936); Fix a bug in calculating the error on the integral after having fitted when fix parameters were present; Fix a bug in calculating the confidence intervas when the number of bins for the given object is different from the number of bins of the fitted object.; ; FitPanel. Add support for drawing the fit function confidence levels.; Make gaus the default function when fitting 1D objects.; Add GSL minimizer and use now a new widget for showing and selecting the list of available algorithms according to the minimizer.; ; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v524/index.html:8365,detect,detect,8365,hist/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v524/index.html,1,['detect'],['detect']
Safety,"1]; 	%tmp345 = zext i1 %tmp3 to i32		; <i32> [#uses=1]; 	ret i32 %tmp345; }. define i32 @test2(double %x, double %y) nounwind {; entry:; 	%tmp3 = fcmp one double %x, %y		; <i1> [#uses=1]; 	%tmp345 = zext i1 %tmp3 to i32		; <i32> [#uses=1]; 	ret i32 %tmp345; }. define i32 @test3(double %x, double %y) nounwind {; entry:; 	%tmp3 = fcmp ugt double %x, %y		; <i1> [#uses=1]; 	%tmp34 = zext i1 %tmp3 to i32		; <i32> [#uses=1]; 	ret i32 %tmp34; }. //===---------------------------------------------------------------------===//; for the following code:. void foo (float *__restrict__ a, int *__restrict__ b, int n) {; a[n] = b[n] * 2.321;; }. we load b[n] to GPR, then move it VSX register and convert it float. We should ; use vsx scalar integer load instructions to avoid direct moves. //===----------------------------------------------------------------------===//; ; RUN: llvm-as < %s | llc -march=ppc32 | not grep fneg. ; This could generate FSEL with appropriate flags (FSEL is not IEEE-safe, and ; ; should not be generated except with -enable-finite-only-fp-math or the like).; ; With the correctness fixes for PR642 (58871) LowerSELECT_CC would need to; ; recognize a more elaborate tree than a simple SETxx. define double @test_FNEG_sel(double %A, double %B, double %C) {; %D = fsub double -0.000000e+00, %A ; <double> [#uses=1]; %Cond = fcmp ugt double %D, -0.000000e+00 ; <i1> [#uses=1]; %E = select i1 %Cond, double %B, double %C ; <double> [#uses=1]; ret double %E; }. //===----------------------------------------------------------------------===//; The save/restore sequence for CR in prolog/epilog is terrible:; - Each CR subreg is saved individually, rather than doing one save as a unit.; - On Darwin, the save is done after the decrement of SP, which means the offset; from SP of the save slot can be too big for a store instruction, which means we; need an additional register (currently hacked in 96015+96020; the solution there; is correct, but poor).; - On SVR4 the same thing can",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt:12533,safe,safe,12533,interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,1,['safe'],['safe']
Safety,"2 * 2; ; return callee(arg2, (int64)local); ; }. [arg1] [!arg2 no longer valid since we moved local onto it]; [arg2] -> [(int64); [RETADDR] local ]. Moving arg1 onto the stack slot of callee function would overwrite; arg2 of the caller. Possible optimizations:. - Analyse the actual parameters of the callee to see which would; overwrite a caller parameter which is used by the callee and only; push them onto the top of the stack. int callee (int32 arg1, int32 arg2);; int caller (int32 arg1, int32 arg2) {; return callee(arg1,arg2);; }. Here we don't need to write any variables to the top of the stack; since they don't overwrite each other. int callee (int32 arg1, int32 arg2);; int caller (int32 arg1, int32 arg2) {; return callee(arg2,arg1);; }. Here we need to push the arguments because they overwrite each; other. //===---------------------------------------------------------------------===//. main (); {; int i = 0;; unsigned long int z = 0;. do {; z -= 0x00004000;; i++;; if (i > 0x00040000); abort ();; } while (z > 0);; exit (0);; }. gcc compiles this to:. _main:; 	subl	$28, %esp; 	xorl	%eax, %eax; 	jmp	L2; L3:; 	cmpl	$262144, %eax; 	je	L10; L2:; 	addl	$1, %eax; 	cmpl	$262145, %eax; 	jne	L3; 	call	L_abort$stub; L10:; 	movl	$0, (%esp); 	call	L_exit$stub. llvm:. _main:; 	subl	$12, %esp; 	movl	$1, %eax; 	movl	$16384, %ecx; LBB1_1:	# bb; 	cmpl	$262145, %eax; 	jge	LBB1_4	# cond_true; LBB1_2:	# cond_next; 	incl	%eax; 	addl	$4294950912, %ecx; 	cmpl	$16384, %ecx; 	jne	LBB1_1	# bb; LBB1_3:	# bb11; 	xorl	%eax, %eax; 	addl	$12, %esp; 	ret; LBB1_4:	# cond_true; 	call	L_abort$stub. 1. LSR should rewrite the first cmp with induction variable %ecx.; 2. DAG combiner should fold; leal 1(%eax), %edx; cmpl $262145, %edx; =>; cmpl $262144, %eax. //===---------------------------------------------------------------------===//. define i64 @test(double %X) {; 	%Y = fptosi double %X to i64; 	ret i64 %Y; }. compiles to:. _test:; 	subl	$20, %esp; 	movsd	24(%esp), %xmm0; 	movsd	%xmm0, 8(%esp); 	",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:19487,abort,abort,19487,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['abort'],['abort']
Safety,"2. ExprEngine takes over (in processCallExit) and finds the return value of the; function, if it has one. This is bound to the expression that triggered the; call. (In the case of calls without origin expressions, such as destructors,; this step is skipped.). 3. Dead symbols and bindings are cleaned out from the state, including any local; bindings. 4. A CallExitEnd node is generated, which marks the transition back to the; caller's LocationContext. 5. Custom post-call checks are processed and the final nodes are pushed back; onto the work list, so that evaluation of the caller can continue. Retry Without Inlining; ^^^^^^^^^^^^^^^^^^^^^^. In some cases, we would like to retry analysis without inlining a particular; call. Currently, we use this technique to recover coverage in case we stop; analyzing a path due to exceeding the maximum block count inside an inlined; function. When this situation is detected, we walk up the path to find the first node; before inlining was started and enqueue it on the WorkList with a special; ReplayWithoutInlining bit added to it (ExprEngine::replayWithoutInlining). The; path is then re-analyzed from that point without inlining that particular call. Deciding When to Inline; ^^^^^^^^^^^^^^^^^^^^^^^. In general, the analyzer attempts to inline as much as possible, since it; provides a better summary of what actually happens in the program. There are; some cases, however, where the analyzer chooses not to inline:. - If there is no definition available for the called function or method. In; this case, there is no opportunity to inline. - If the CFG cannot be constructed for a called function, or the liveness; cannot be computed. These are prerequisites for analyzing a function body,; with or without inlining. - If the LocationContext chain for a given ExplodedNode reaches a maximum cutoff; depth. This prevents unbounded analysis due to infinite recursion, but also; serves as a useful cutoff for performance reasons. - If the function is var",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst:6658,detect,detected,6658,interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,1,['detect'],['detected']
Safety,"20 : Total Size= 582 bytes File Size = 92 *; *Baskets : 1 : Basket Size= 16000 bytes Compression= 1.00 *. Add a new function TBranch::SetStatus It is much faster to call this function in case of a Tree with many branches; instead of calling TTree::SetBranchStatus.; Implement TTreeCache::Print that shows information like:; // ******TreeCache statistics for file: cms2.root ******; // Number of branches in the cache ...: 1093; // Cache Efficiency ..................: 0.997372; // Cache Efficiency Rel...............: 1.000000; // Learn entries......................: 100; // Reading............................: 72761843 bytes in 7 transactions; // Readahead..........................: 256000 bytes with overhead = 0 bytes; // Average transaction................: 10394.549000 Kbytes; // Number of blocks in current cache..: 210, total size: 6280352; This function can be called directly from TTree: T->PrintCacheStats();. Add support for variable size array of object in a TTree (when the owner of the array is split.); And many other bug fixes, security fixes, thread safety and performance improvements ; see the svn log for details. TTree Scan and Draw. Insured that the generated histogram as an integral bin width when plotting a string or integer.; Improved the output of TTree::Scan by inserting a blank space whenever a value is not available because there is no proper row in a friend.; (Previously it was re-printing the previous value). This required changes in ; When the draw option to TTree::Draw contains ""norm"" the output histogram is normalized to 1.; Improve the selection of the leaf used for size of an array in a leaflist by giving preference; for the leaf inside the same branch and by adding support for explicit full path name. For example the following now works properly:; tree->Branch(""JET1"", &JET1, ""njets/I:et[njets]/F:pt[njets]/F"");; tree->BranchBranch(""JET2"", &JET2, ""njets/I:et[njets]/F:pt[njets]/F"");; ...; tree->Scan(""njets/I:et[JETS1.njets]/F:pt[JETS1.njets]"");. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:6447,safe,safety,6447,tree/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html,1,['safe'],['safety']
Safety,"26000 was deallocated by thread 31027 here:; | ...; | #7 ./a.out(main+0x83) [0x55585c0af7b3]; | #8 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #9 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | 0x7feccab26000 was allocated by thread 31027 here:; | ...; | #12 ./a.out(main+0x57) [0x55585c0af787]; | #13 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #14 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | *** End GWP-ASan report ***; | Segmentation fault. To symbolize these stack traces, some care has to be taken. Scudo currently uses; GNU's ``backtrace_symbols()`` from ``<execinfo.h>`` to unwind. The unwinder; provides human-readable stack traces in ``function+offset`` form, rather than; the normal ``binary+offset`` form. In order to use addr2line or similar tools to; recover the exact line number, we must convert the ``function+offset`` to; ``binary+offset``. A helper script is available at; ``compiler-rt/lib/gwp_asan/scripts/symbolize.sh``. Using this script will; attempt to symbolize each possible line, falling back to the previous output if; anything fails. This results in the following output:. .. code:: console. $ cat my_gwp_asan_error.txt | symbolize.sh; |; | *** GWP-ASan detected a memory error ***; | Use after free at 0x7feccab26000 (0 bytes into a 41-byte allocation at 0x7feccab26000) by thread 31027 here:; | ...; | #9 /usr/lib/gcc/x86_64-linux-gnu/8.0.1/../../../../include/c++/8.0.1/string_view:547; | #10 /tmp/buggy_code.cpp:8; |; | 0x7feccab26000 was deallocated by thread 31027 here:; | ...; | #7 /tmp/buggy_code.cpp:8; | #8 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #9 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | 0x7feccab26000 was allocated by thread 31027 here:; | ...; | #12 /tmp/buggy_code.cpp:7; | #13 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #14 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | *** End GWP-ASan report ***; | Segmentation fault; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:11540,detect,detected,11540,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['detect'],['detected']
Safety,"2; 	shufps	$132, %xmm2, %xmm0; 	movaps	%xmm0, (%eax); 	ret. Would it be better to generate:. _test:; movl 8(%esp), %ecx; movaps (%ecx), %xmm0; 	xor %eax, %eax; pinsrw $6, %eax, %xmm0; pinsrw $7, %eax, %xmm0; movaps %xmm0, (%ecx); ret. ?. //===---------------------------------------------------------------------===//. Some useful information in the Apple Altivec / SSE Migration Guide:. http://developer.apple.com/documentation/Performance/Conceptual/; Accelerate_sse_migration/index.html. e.g. SSE select using and, andnot, or. Various SSE compare translations. //===---------------------------------------------------------------------===//. Add hooks to commute some CMPP operations. //===---------------------------------------------------------------------===//. Apply the same transformation that merged four float into a single 128-bit load; to loads from constant pool. //===---------------------------------------------------------------------===//. Floating point max / min are commutable when -enable-unsafe-fp-path is; specified. We should turn int_x86_sse_max_ss and X86ISD::FMIN etc. into other; nodes which are selected to max / min instructions that are marked commutable. //===---------------------------------------------------------------------===//. We should materialize vector constants like ""all ones"" and ""signbit"" with ; code like:. cmpeqps xmm1, xmm1 ; xmm1 = all-ones. and:; cmpeqps xmm1, xmm1 ; xmm1 = all-ones; psrlq xmm1, 31 ; xmm1 = all 100000000000... instead of using a load from the constant pool. The later is important for; ABS/NEG/copysign etc. //===---------------------------------------------------------------------===//. These functions:. #include <xmmintrin.h>; __m128i a;; void x(unsigned short n) {; a = _mm_slli_epi32 (a, n);; }; void y(unsigned n) {; a = _mm_slli_epi32 (a, n);; }. compile to ( -O3 -static -fomit-frame-pointer):; _x:; movzwl 4(%esp), %eax; movd %eax, %xmm0; movaps _a, %xmm1; pslld %xmm0, %xmm1; movaps %xmm1, _a; ret; _y:; movd 4(%esp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:9623,unsafe,unsafe-fp-path,9623,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,1,['unsafe'],['unsafe-fp-path']
Safety,"36c343a710f5ff92a326ff5).; See also this [writeup on extended weighted fits](https://root.cern/files/extended_weighted_fits.pdf) that is also linked from the reference guide.; The [pull request](https://github.com/root-project/root/pull/14751) that introduced this feature might also be a good reference. ### Compile your code with memory safe interfaces. If you define the `ROOFIT_MEMORY_SAFE_INTERFACES` preprocessor macro, the; RooFit interface changes in a way such that memory leaks are avoided. The most prominent effect of this change is that many functions that used to; return an owning pointer (e.g., a pointer to an object that you need to; manually `delete`) are then returning a `std::unique_pt` for automatic memory; management. For example this code would not compile anymore, because there is the risk that; the caller forgets to `delete params`:; ```c++; RooArgSet * params = pdf.getParameters(nullptr);; ```; If you wrap such return values in a `std::unique_ptr`, then your code will; compile both with and without memory safe interfaces:; ```c++; std::unique_ptr<RooArgSet> params{pdf.getParameters(nullptr)};; ```. Also some `virtual` RooFit functions like [RooAbsReal::createIntegral()](https://root.cern.ch/doc/master/classRooAbsReal.html#aff4be07dd6a131721daeeccf6359aea9); are returning a different type conditional on `ROOFIT_MEMORY_SAFE_INTERFACES`.; If you are overriding such a function, you need to use the `RooFit::OwningPtr`; return type, which is an alias for `std::unique_ptr` in memory-safe mode or an; alias for a raw pointer otherwise.; ```c++; RooFit::OwningPtr<RooAbsReal> RooAbsReal::createIntegral(...) const override; {; std::unique_ptr<RooAbsReal> integral;; // Prepare a std::unique_ptr as the return value; ...; // Use the RooFit::makeOwningPtr<T>() helper to translate the; // std::unique_ptr to the actual return type (either std::unique_ptr<T> or T*).; return RooFit::makeOwningPtr<RooAbsReal>(std::move(integral));; }; ```. The biggest application of th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:9112,safe,safe,9112,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['safe'],['safe']
Safety,"3; C99; Meaning of __STDC_ISO_10646__. Yes; The compiler portion of this DR is implemented in Clang, but the; __STDC_ISO_10646__ macro is not defined by Clang; the; standard library behavior factors into whether this macro can or cannot; be defined.; . 274; C99; Meaning of ""character"" in <string.h> functions; N/A. 275; C99; Bitwise-OR of nothing; N/A. 276; C99; Orientation of perror; N/A. 277; NAD; Declarations within iteration statements; No. 278; C99; Lacuna in character encodings; Yes. 279; C99; Wide character code values for members of the basic character set; Yes. 280; NAD; struct tm, member tm_isdst, and mktime() in <time.h>; N/A. 281; C99; CLOCKS_PER_SEC should not be a constant expression; N/A. 282; C99; Flexible array members & struct padding; Yes. 283; C99; Accessing a non-current union member (""type punning""); Unknown. 284; NAD; Does <math.h> define INT_MIN and INT_MAX?; N/A. 285; C99; Conversion of an imaginary type to _Bool. Partial; Clang detects use of the _Imaginary keyword but does not otherwise; support the type yet.; . 286; C99; Correctly rounded and rounding direction/mode; N/A. 287; Dup; Floating-point status flags and sequence points; Duplicate of 87. 288; NAD; Deficiency on multibyte conversions; N/A. 289; C99; Function prototype with [restrict]; Yes. 290; C99; FLT_EVAL_METHOD and extra precision and/or range; Unknown. 291; C99; Corrections to requirements on inexact floating-point exceptions; Unknown. 292; C99; Use of the word variable; Yes. 293; C99; Typo in Standard - double complex instead of complex in an example; Yes. 294; NAD; Technical question on C99 restrict keyword; Unknown. 295; C99; Incomplete types for function parameters; Yes. 296; C99; Is exp(INFINITY) overflow? A range error? A divide-by-zero exception? INFINITY without any errors?; N/A. 297; C99; May FE_* floating-point exception flags have bits in common?; N/A. 298; C99; Validity of constant in unsigned long long range. Partial; Clang defines the behavior in this situation by",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html:16997,detect,detects,16997,interpreter/llvm-project/clang/www/c_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html,1,['detect'],['detects']
Safety,"483648 by -1. If the ``exact`` keyword is present, the result value of the ``sdiv`` is; a :ref:`poison value <poisonvalues>` if the result would be rounded. Example:; """""""""""""""". .. code-block:: text. <result> = sdiv i32 4, %var ; yields i32:result = 4 / %var. .. _i_fdiv:. '``fdiv``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = fdiv [fast-math flags]* <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``fdiv``' instruction returns the quotient of its two operands. Arguments:; """""""""""""""""""". The two arguments to the '``fdiv``' instruction must be; :ref:`floating-point <t_floating>` or :ref:`vector <t_vector>` of; floating-point values. Both arguments must have identical types. Semantics:; """""""""""""""""""". The value produced is the floating-point quotient of the two operands.; This instruction is assumed to execute in the default :ref:`floating-point; environment <floatenv>`.; This instruction can also take any number of :ref:`fast-math; flags <fastmath>`, which are optimization hints to enable otherwise; unsafe floating-point optimizations:. Example:; """""""""""""""". .. code-block:: text. <result> = fdiv float 4.0, %var ; yields float:result = 4.0 / %var. .. _i_urem:. '``urem``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = urem <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``urem``' instruction returns the remainder from the unsigned; division of its two arguments. Arguments:; """""""""""""""""""". The two arguments to the '``urem``' instruction must be; :ref:`integer <t_integer>` or :ref:`vector <t_vector>` of integer values. Both; arguments must have identical types. Semantics:; """""""""""""""""""". This instruction returns the unsigned integer *remainder* of a division.; This instruction always performs an unsigned division to get the; remainder. Note that unsigned integer remainder and signed integer remainder are; distinct operations; for signed integer remainder, use '``srem``'. Taking the remainder of a division ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:387612,unsafe,unsafe,387612,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['unsafe'],['unsafe']
Safety,"4ca; #### Clipping Ray-traced Images. A ray-traced view can be `clipped` with any shape known by the modeller.; This means that the region inside the clipping shape is subtracted from; the current drawn geometry (become invisible). In order to activate; clipping, one has to first define the clipping shape(s):. 1. `TGeoShape *clip1, *clip2, ...`; One might switch between several clipping shapes. Note that these; shapes are considered defined in the current `MARS`. Composite shapes; may be used.; 2. `gGeoManager->SetClippingShape(clip1);`; One can activate or deactivate clipping at any time:; `gGeoManager->SetClipping(flag);`; 3. Perform ray-tracing:` gGeoManager->GetTopVolume()->Raytrace();`. One can redo the steps 2-3 as many times as needed. Let us look how the; rootgeom.C example looks clipped with a tube. \image html geometry014.png ""Ray-tracing example with box-clipping"". \anchor GP05; ## Representing Misalignments of the Ideal Geometry. The ideal positioning of a detector does not match its position in the; experimental hall. This generally happens not only for the detector; modules, but also for their components. The accurate knowledge of the; detector real misalignments can be extremely important for getting close; to its designed resolution and the expected tracking efficiency.; `TGeo` offers tools for representing positioning misalignments,; applying them to the ideal geometry and performing navigation under; these conditions. Detector tracking algorithms can then directly query; the geometry for navigation purposes or for retrieving actual; misalignment information. \anchor GP05a; ### Physical Nodes. Physical nodes are the actual ""touchable"" objects in the geometry,; representing actually a path of positioned volumes starting with the; top node: `path=/TOP/A_1/B_4/C_3` , where `A`, `B`, `C` represent names; of volumes. The number of physical nodes is given by the total number of; possible of branches in the geometry hierarchy. In case of detector; geometrie",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:106052,detect,detector,106052,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['detect'],['detector']
Safety,"5.4.3.3 Type Conversion Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.6. .. _amdgpu-dwarf-general-operations:. A.2.5.4.3.4 Special Value Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces parts of DWARF Version 5 sections 2.5.1.2, 2.5.1.3, and; 2.5.1.7. There are these special value operations currently defined:. 1. ``DW_OP_regval_type``. ``DW_OP_regval_type`` has two operands. The first is an unsigned LEB128; integer that represents a register number R. The second is an unsigned; LEB128 integer DR that represents the byte offset of a debugging information; entry D relative to the beginning of the current compilation unit, that; provides the type T of the register value. The operation is equivalent to performing ``DW_OP_regx R; DW_OP_deref_type; DR``. .. note::. Should DWARF allow the type T to be a larger size than the size of the; register R? Restricting a larger bit size avoids any issue of conversion; as the, possibly truncated, bit contents of the register is simply; interpreted as a value of T. If a conversion is wanted it can be done; explicitly using a ``DW_OP_convert`` operation. GDB has a per register hook that allows a target specific conversion on a; register by register basis. It defaults to truncation of bigger registers.; Removing use of the target hook does not cause any test failures in common; architectures. If the compiler for a target architecture did want some; form of conversion, including a larger result type, it could always; explicitly use the ``DW_OP_convert`` operation. If T is a larger type than the register size, then the default GDB; register hook reads bytes from the next register (or reads out of bounds; for the last register!). Removing use of the target hook does not cause; any test failures in common architectures (except an illegal hand written; assembly test). If a target architecture requires this behavior, these; extensions",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:87577,avoid,avoids,87577,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['avoid'],['avoids']
Safety,"5585c0af7cf]; | #11 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #12 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | 0x7feccab26000 was deallocated by thread 31027 here:; | ...; | #7 ./a.out(main+0x83) [0x55585c0af7b3]; | #8 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #9 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | 0x7feccab26000 was allocated by thread 31027 here:; | ...; | #12 ./a.out(main+0x57) [0x55585c0af787]; | #13 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #14 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | *** End GWP-ASan report ***; | Segmentation fault. To symbolize these stack traces, some care has to be taken. Scudo currently uses; GNU's ``backtrace_symbols()`` from ``<execinfo.h>`` to unwind. The unwinder; provides human-readable stack traces in ``function+offset`` form, rather than; the normal ``binary+offset`` form. In order to use addr2line or similar tools to; recover the exact line number, we must convert the ``function+offset`` to; ``binary+offset``. A helper script is available at; ``compiler-rt/lib/gwp_asan/scripts/symbolize.sh``. Using this script will; attempt to symbolize each possible line, falling back to the previous output if; anything fails. This results in the following output:. .. code:: console. $ cat my_gwp_asan_error.txt | symbolize.sh; |; | *** GWP-ASan detected a memory error ***; | Use after free at 0x7feccab26000 (0 bytes into a 41-byte allocation at 0x7feccab26000) by thread 31027 here:; | ...; | #9 /usr/lib/gcc/x86_64-linux-gnu/8.0.1/../../../../include/c++/8.0.1/string_view:547; | #10 /tmp/buggy_code.cpp:8; |; | 0x7feccab26000 was deallocated by thread 31027 here:; | ...; | #7 /tmp/buggy_code.cpp:8; | #8 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #9 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | 0x7feccab26000 was allocated by thread 31027 here:; | ...; | #12 /tmp/buggy_code.cpp:7; | #13 /lib/x86_64-linux-gnu/l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:11121,recover,recover,11121,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['recover'],['recover']
Safety,"6 %tmp98 to i32		; <i32> [#uses=1]; 	%tmp585 = sub i32 32, %tmp583584		; <i32> [#uses=1]; 	%tmp614615 = sext i16 %tmp101 to i32		; <i32> [#uses=1]; 	%tmp621622 = sext i16 %tmp104 to i32		; <i32> [#uses=1]; 	%tmp623 = sub i32 32, %tmp621622		; <i32> [#uses=1]; 	br label %bb114. produces:. LBB3_5:	# bb114.preheader; 	movswl	-68(%ebp), %eax; 	movl	$32, %ecx; 	movl	%ecx, -80(%ebp); 	subl	%eax, -80(%ebp); 	movswl	-52(%ebp), %eax; 	movl	%ecx, -84(%ebp); 	subl	%eax, -84(%ebp); 	movswl	-70(%ebp), %eax; 	movl	%ecx, -88(%ebp); 	subl	%eax, -88(%ebp); 	movswl	-50(%ebp), %eax; 	subl	%eax, %ecx; 	movl	%ecx, -76(%ebp); 	movswl	-42(%ebp), %eax; 	movl	%eax, -92(%ebp); 	movswl	-66(%ebp), %eax; 	movl	%eax, -96(%ebp); 	movw	$0, -98(%ebp). This appears to be bad because the RA is not folding the store to the stack ; slot into the movl. The above instructions could be:; 	movl $32, -80(%ebp); ...; 	movl $32, -84(%ebp); ...; This seems like a cross between remat and spill folding. This has redundant subtractions of %eax from a stack slot. However, %ecx doesn't; change, so we could simply subtract %eax from %ecx first and then use %ecx (or; vice-versa). //===---------------------------------------------------------------------===//. This code:. 	%tmp659 = icmp slt i16 %tmp654, 0		; <i1> [#uses=1]; 	br i1 %tmp659, label %cond_true662, label %cond_next715. produces this:. 	testw	%cx, %cx; 	movswl	%cx, %esi; 	jns	LBB4_109	# cond_next715. Shark tells us that using %cx in the testw instruction is sub-optimal. It; suggests using the 32-bit register (which is what ICC uses). //===---------------------------------------------------------------------===//. We compile this:. void compare (long long foo) {; if (foo < 4294967297LL); abort();; }. to:. compare:; subl $4, %esp; cmpl $0, 8(%esp); setne %al; movzbw %al, %ax; cmpl $1, 12(%esp); setg %cl; movzbw %cl, %cx; cmove %ax, %cx; testb $1, %cl; jne .LBB1_2 # UnifiedReturnBlock; .LBB1_1: # ifthen; call abort; .LBB1_2: # UnifiedReturnBlock; addl $4, %esp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:16522,redund,redundant,16522,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['redund'],['redundant']
Safety,"65,30,-3,6);. //process cases with event list; fillList = kFALSE;; useList = kFALSE;; fChain->SetEventList(0);; delete gDirectory->GetList()->FindObject(""elist"");. // case when one creates/fills the event list; if (option.Contains(""fillList"")) {; fillList = kTRUE;; elist = new TEventList(""elist"",""selection from Cut"",5000);; }; // case when one uses the event list generated in a previous call; if (option.Contains(""useList"")) {; useList = kTRUE;; TFile f(""elist.root"");; elist = (TEventList*)f.Get(""elist"");; if (elist) elist->SetDirectory(0);; //otherwise the file destructor will delete elist; fChain->SetEventList(elist);; }; }; //_________________________________________________________; Bool_t h1analysis::ProcessCut(Int_t entry); { // Selection function to select D* and D0. //in case one event list is given in input,; //the selection has already been done.; if (useList) return kTRUE;; // Read only the necessary branches to select entries.; // return as soon as a bad entry is detected; b_md0_d->GetEntry(entry);; if (TMath::Abs(md0_d-1.8646) >= 0.04) return kFALSE;; b_ptds_d->GetEntry(entry);; if (ptds_d <= 2.5) return kFALSE;; b_etads_d->GetEntry(entry);; if (TMath::Abs(etads_d) >= 1.5) return kFALSE;; b_ik->GetEntry(entry); ik--;; //original ik used f77 convention starting at 1; b_ipi->GetEntry(entry);; ipi--;; b_ntracks->GetEntry(entry);; b_nhitrp->GetEntry(entry);; if (nhitrp[ik]*nhitrp[ipi] <= 1) return kFALSE;; b_rend->GetEntry(entry);; b_rstart->GetEntry(entry);; if (rend[ik]-rstart[ik] <= 22) return kFALSE;; if (rend[ipi]-rstart[ipi] <= 22) return kFALSE;; b_nlhk->GetEntry(entry);; if (nlhk[ik] <= 0.1) return kFALSE;; b_nlhpi->GetEntry(entry);; if (nlhpi[ipi] <= 0.1) return kFALSE;; b_ipis->GetEntry(entry);; ipis--;; if (nlhpi[ipis] <= 0.1) return kFALSE;; b_njets->GetEntry(entry);; if (njets < 1) return kFALSE;. // if option fillList, fill the event list; if (fillList) elist->Enter(fChain->GetChainEntryNumber(entry));. return kTRUE;; }. //_____________________",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/ExampleAnalysis.md:8025,detect,detected,8025,documentation/users-guide/ExampleAnalysis.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/ExampleAnalysis.md,1,['detect'],['detected']
Safety,"68; Open; Consistency of the C Standard (Defect Report UK 016); Not resolved. 169; NAD; Trigraphs; Yes. 170; C89; Operators and punctuators; Not resolved. 171; Open; Ranges of integral types; Not resolved. 172; Open; Relational and equality operators; Not resolved. 173; Open; Line numbers; Not resolved. 174; Open; Implicit conversions; Not resolved. 175; Open; Correction to Technical Corrigendum 1; Not resolved. 176; Open; Diagnostics for #error; Not resolved. 177; Open; Preprocessing directives; Not resolved. 178; Open; Conformance with array members and allocations; Not resolved. 201; NAD; Integer types longer than long; Yes. 202; C99; Change return type of certain <fenv.h> functions; N/A. 203; C99; C locale conflict with ISO/IEC 9945-2; N/A. 204; C99; size_t and ptrdiff_t as a long long type; Yes. 205; NAD; New keyword __at_least; Yes. 206; NAD; Default argument conversion of float _Complex; Yes. 207; C99; Handling of imaginary types. Partial; Clang detects use of the _Imaginary keyword but does not otherwise; support the type yet.; . 208; C99; Ambiguity in initialization; Yes. 209; C99; Problem implementing INTN_C macros. Partial; Clang provides these definitions in a freestanding compilation, but the; type of the value produced by UINT8_C and UINT16_C; is not the type after integer promotion per C99 7.18.4p3.; . 210; C99; 'fprintf' %a and %A conversions recommended practice; N/A. 211; C99; Accuracy of decimal string to/from ""binary"" (non-decimal) floating-point conversions; Yes. 212; NAD; Binding of multibyte conversion state objects; N/A. 213; C99; Lacuna in 'mbrtowc'; N/A. 214; NAD; 'atexit' function registration; N/A. 215; C99; Equality operators; Yes. 216; C99; Source character encodings; Yes. 217; NAD; 'asctime' limits; N/A. 218; C99; Signs of non-numeric floating point values; Yes. 219; NAD; Effective types; Yes. 220; C99; Definition of ""decimal integer""; N/A. 221; NAD; Lacuna in pointer arithmetic; Yes. 222; C99; Partially initialized structures; Yes. 223",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html:12051,detect,detects,12051,interpreter/llvm-project/clang/www/c_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html,1,['detect'],['detects']
Safety,":"");; scanf ("" %1023[^\n]"", filename); // The attacker can inject a shell escape here; strcat(cmd, filename);; system(cmd); // Warning: Untrusted data is passed to a system call; }. The program prints the content of any user specified file.; Unfortunately the attacker can execute arbitrary commands; with shell escapes. For example with the following input the `ls` command is also; executed after the contents of `/etc/shadow` is printed.; `Input: /etc/shadow ; ls /`. The analysis implemented in this checker points out this problem. One can protect against such attack by for example checking if the provided; input refers to a valid file and removing any invalid user input. .. code-block:: c. // No vulnerability anymore, but we still get the warning; void sanitizeFileName(char* filename){; if (access(filename,F_OK)){// Verifying user input; printf(""File does not exist\n"");; filename[0]='\0';; }; }; int main(int argc, char** argv) {; char cmd[2048] = ""/bin/cat "";; char filename[1024];; printf(""Filename:"");; scanf ("" %1023[^\n]"", filename); // The attacker can inject a shell escape here; sanitizeFileName(filename);// filename is safe after this point; if (!filename[0]); return -1;; strcat(cmd, filename);; system(cmd); // Superfluous Warning: Untrusted data is passed to a system call; }. Unfortunately, the checker cannot discover automatically that the programmer; have performed data sanitation, so it still emits the warning. One can get rid of this superfluous warning by telling by specifying the; sanitation functions in the taint configuration file (see; :doc:`user-docs/TaintAnalysisConfiguration`). .. code-block:: YAML. Filters:; - Name: sanitizeFileName; Args: [0]. The clang invocation to pass the configuration file location:. .. code-block:: bash. clang --analyze -Xclang -analyzer-config -Xclang alpha.security.taint.TaintPropagation:Config=`pwd`/taint_config.yml ... If you are validating your inputs instead of sanitizing them, or don't want to; mention each sanitizin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:67840,safe,safe,67840,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['safe'],['safe']
Safety,":. Formatting strings (the ``formatv`` function); ---------------------------------------------; While LLVM doesn't necessarily do a lot of string manipulation and parsing, it; does do a lot of string formatting. From diagnostic messages, to llvm tool; outputs such as ``llvm-readobj`` to printing verbose disassembly listings and; LLDB runtime logging, the need for string formatting is pervasive. The ``formatv`` is similar in spirit to ``printf``, but uses a different syntax; which borrows heavily from Python and C#. Unlike ``printf`` it deduces the type; to be formatted at compile time, so it does not need a format specifier such as; ``%d``. This reduces the mental overhead of trying to construct portable format; strings, especially for platform-specific types like ``size_t`` or pointer types.; Unlike both ``printf`` and Python, it additionally fails to compile if LLVM does; not know how to format the type. These two properties ensure that the function; is both safer and simpler to use than traditional formatting methods such as; the ``printf`` family of functions. Simple formatting; ^^^^^^^^^^^^^^^^^. A call to ``formatv`` involves a single **format string** consisting of 0 or more; **replacement sequences**, followed by a variable length list of **replacement values**.; A replacement sequence is a string of the form ``{N[[,align]:style]}``. ``N`` refers to the 0-based index of the argument from the list of replacement; values. Note that this means it is possible to reference the same parameter; multiple times, possibly with different style and/or alignment options, in any order. ``align`` is an optional string specifying the width of the field to format; the value into, and the alignment of the value within the field. It is specified as; an optional **alignment style** followed by a positive integral **field width**. The; alignment style can be one of the characters ``-`` (left align), ``=`` (center align),; or ``+`` (right align). The default is right aligned. ``s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:12109,safe,safer,12109,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['safe'],['safer']
Safety,":; """""""""""""". ::. declare void @llvm.trap() cold noreturn nounwind. Overview:; """""""""""""""""". The '``llvm.trap``' intrinsic. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". This intrinsic is lowered to the target dependent trap instruction. If; the target does not have a trap instruction, this intrinsic will be; lowered to a call of the ``abort()`` function. '``llvm.debugtrap``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.debugtrap() nounwind. Overview:; """""""""""""""""". The '``llvm.debugtrap``' intrinsic. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". This intrinsic is lowered to code which is intended to cause an; execution trap with the intention of requesting the attention of a; debugger. '``llvm.ubsantrap``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.ubsantrap(i8 immarg) cold noreturn nounwind. Overview:; """""""""""""""""". The '``llvm.ubsantrap``' intrinsic. Arguments:; """""""""""""""""""". An integer describing the kind of failure detected. Semantics:; """""""""""""""""""". This intrinsic is lowered to code which is intended to cause an execution trap,; embedding the argument into encoding of that trap somehow to discriminate; crashes if possible. Equivalent to ``@llvm.trap`` for targets that do not support this behaviour. '``llvm.stackprotector``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.stackprotector(ptr <guard>, ptr <slot>). Overview:; """""""""""""""""". The ``llvm.stackprotector`` intrinsic takes the ``guard`` and stores it; onto the stack at ``slot``. The stack slot is adjusted to ensure that it; is placed on the stack before local variables. Arguments:; """""""""""""""""""". The ``llvm.stackprotector`` intrinsic requires two pointer arguments.; The first argument is the value loaded from the stack guard; ``@__stack_chk_guard``. The second variable is an ``alloca`` that has; enough space to hold the value of the guard. Semantics:; """""""""""""""""""". This intrinsic causes the p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:929274,detect,detected,929274,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['detect'],['detected']
Safety,":desc(""<Input files>""), cl::OneOrMore);; ... This variable works just like a ""``vector<string>``"" object. As such, accessing; the list is simple, just like above. In this example, we used the; `cl::OneOrMore`_ modifier to inform the CommandLine library that it is an error; if the user does not specify any ``.o`` files on our command line. Again, this; just reduces the amount of checking we have to do. Collecting options as a set of flags; ------------------------------------. Instead of collecting sets of options in a list, it is also possible to gather; information for enum values in a **bit vector**. The representation used by the; `cl::bits`_ class is an ``unsigned`` integer. An enum value is represented by a; 0/1 in the enum's ordinal value bit position. 1 indicating that the enum was; specified, 0 otherwise. As each specified value is parsed, the resulting enum's; bit is set in the option's bit vector:. .. code-block:: c++. bits |= 1 << (unsigned)enum;. Options that are specified multiple times are redundant. Any instances after; the first are discarded. Reworking the above list example, we could replace `cl::list`_ with `cl::bits`_:. .. code-block:: c++. cl::bits<Opts> OptimizationBits(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. To test to see if ``instsimplify`` was specified, we can use the ``cl:bits::isSet``; function:. .. code-block:: c++. if (OptimizationBits.isSet(instsimplify)) {; ...; }. It's also possible to get the raw bit vector using the ``cl::bits::getBits``; function:. .. code-block:: c++. unsigned bits = OptimizationBits.getBits();. Finally, if external storage is used, then the location specified must be of; **type** ``unsigned``. In all other ways a `cl::bits`_ option is equivalent to a; `cl::list`_ option. .. _additional extra text:. Adding f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:22001,redund,redundant,22001,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,1,['redund'],['redundant']
Safety,"; # Foreword #. ## What M is intended to do ##. M is conceived as a tool to find the minimum value of a multi-parameter; function (the ""$\mbox{FCN}$"") and analyze the shape of the function; around the minimum. The principal application is foreseen for; statistical analysis, working on chisquare or log-likelihood functions,; to compute the best-fit parameter values and uncertainties, including; correlations between the parameters. It is especially suited to handle; difficult problems, including those which may require guidance in order; to find the correct solution. ## What M is not intended to do ##. Although M will of course solve easy problems faster than complicated; ones, it is not intended for the repeated solution of identically; parametrized problems (such as track fitting in a detector) where a; specialized program will in general be much more efficient. ## Further remarks ##. M was initially written in Fortran around 1975-1980 at CERN by Fred; James @bib-MINUIT. Its main field of usage is statistical data analysis; of experimental data recorded at CERN, but it is also used by people; doing data analysis outside CERN or outside high energy physics (HEP).; In 2002 Fred James started a project aiming to re-implement M in an; object-oriented way using . More information about recent developments, releases and installation; can be obtained from the M homepage @bib-C++MINUIT. The names of M applications are written in capital letters (e.g.; $\mbox{MIGRAD}$, $\mbox{MINOS}$, $\mbox{CONTOURS}$), the; corresponding names of the classes are written using sans-serif font; type (MnMigrad, MnMinos, MnContours). # Introduction: M basic concepts #. [sec:intro]. ## The organization of M ##. The M package acts on a multiparameter *objective function* which is; called — for historical reasons — the $\mbox{FCN}$ function (see; [howto:fcn]). This function is usually a chisquared or a log–likelihood,; but it could also be a mathematical function. The $\mbox{FCN}$; function needs ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:796,detect,detector,796,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['detect'],['detector']
Safety,"; $$. Remarkable feature of algorithm is the technique for step restriction.; For an initial value of parameter ${\vec\theta}^0$ a parallelepiped; $P_0$ is built with the center at ${\vec\theta}^0$ and axes parallel; to coordinate axes $\theta_i$. The lengths of parallelepiped sides; along i-th axis is $2b_i$, where $b_i$ is such a value that the; functions $f_j(\vec\theta)$ are quasi-linear all over the; parallelepiped. FUMILI takes into account simple linear inequalities in the form:. $$ \theta_i^{min}\le\theta_i\le\theta^{max}_i$$. They form parallelepiped $P$ ($P_0$ may be deformed by $P$). Very; similar step formulae are used in FUMILI for negative logarithm of; the likelihood function with the same idea - linearization of function; argument. ## Neural Networks. ### Introduction. Neural Networks are used in various fields for data analysis and; classification, both for research and commercial institutions. Some; randomly chosen examples are image analysis, financial movements'; predictions and analysis, or sales forecast and product shipping; optimization. In particles physics neural networks are mainly used for; classification tasks (signal over background discrimination). A vast; majority of commonly used neural networks are multilayer perceptrons.; This implementation of multilayer perceptrons is inspired from the; `MLPfit` package, which remains one of the fastest tools for neural; networks studies. ### The MLP. The multilayer perceptron is a simple feed-forward network with the; following structure showed on the left. ![](pictures/0300008D.png). It is made of neurons characterized by a bias and weighted links in; between - let's call those links synapses. The input neurons receive; the inputs, normalize them and forward them to the first hidden layer.; Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being linear for; output ne",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:70048,predict,predictions,70048,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['predict'],['predictions']
Safety,"; (int) 1; root [2] _file0->GetCompressionLevel(); (int) 1; root [3] _file0->GetCompressionSettings(); (int) 101; root [4]; ```. ## TTree Libraries; ### RDataFrame; - Optimise the creation of the set of branch names of an input dataset, doing the work once and caching it in the RInterface.; - Add [StdDev](https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#a482c4e4f81fe1e421c016f89cd281572) action.; - Add [Display](https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#aee68f4411f16f00a1d46eccb6d296f01) action and [tutorial](https://github.com/root-project/root/blob/master/tutorials/dataframe/df024_Display.C).; - Add [Graph](https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#a804b466ebdbddef5c7e3400cc6b89301) action and [tutorial](https://github.com/root-project/root/blob/master/tutorials/dataframe/df021_createTGraph.C).; - Improve [GetColumnNames](https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#a951fe60b74d3a9fda37df59fd1dac186) to have no redundancy in the returned names.; - Add [Kahan Summation tutorial](https://github.com/root-project/root/blob/master/tutorials/dataframe/df022_useKahan.C) to subscribe a Kahan summation action to the RDataFrame.; - Add [Aggregate tutorial](https://github.com/root-project/root/blob/master/tutorials/dataframe/df019_Cache.C) [Python version](https://github.com/root-project/root/blob/master/tutorials/dataframe/df019_Cache.py).; - Add [Cache tutorial](https://github.com/root-project/root/commit/cd3e2fdc4baa99111f57240bf8012dcc5f1b5dc6).; - Fix ambiguous call on Cache() with one or two columns as parameters.; - Add [GetFilterNames](https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#a25026681111897058299161a70ad9bb2).; - Improve RDF node ownership model. The net effect is that users do not have to worry about keeping the first node of a computation graph in scope anymore.; - Make RResultPtr copy/move-assignable and copy/move-constructible.; - Add [GetColumnType](https:/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md:7370,redund,redundancy,7370,README/ReleaseNotes/v616/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md,1,['redund'],['redundancy']
Safety,"; * Any other information you believe we should have. If you are unable to provide all of this information, please still make the; report and include as much information as you have. When handling a report, we follow our :doc:`Response Guide <ResponseGuide>`. Confidentiality; ===============. All reports will be kept confidential with details shared only with the Code of; Conduct committee members. In the case that a CoC committee member is involved; in a report, the member will be asked to recuse themselves from ongoing; conversations, and they will not have access to any reports at any time.; Resolution action may also include removal of that member from the CoC; committee. Some incidents happen in one-on-one interactions, and though details are; anonymized, the reported person may be able to guess who made the report. If; you have concerns about retaliation or your personal safety, please note those; concerns in your report. You are still encouraged to report the incident so; that we can support you while keeping our community members safe. In some; cases, we can compile several anonymized reports into a pattern of behavior,; and take action on that pattern. . Transparency reports will be published but will retain confidentiality. See the; :doc:`Response Guide <ResponseGuide>`. for details on this. Following Up With Reporter(s); =============================. Once a report is filed, the Code of Conduct committee will handle the review; and follow up according to the procedures in the :doc:`Response Guide; <ResponseGuide>`. . Thanks!; =======. This guide was created and inspired by the following: the `Django Project`_,; `Carpentries Response Guide`_, and the `Write The Docs Response Guide`_. License; =======. All content on this page is licensed under a `Creative Commons Attribution 3.0; Unported License`_. .. _Django Project: https://www.djangoproject.com/conduct/; .. _Carpentries Response Guide: https://docs.carpentries.org/topic_folders/policies/enforcement-gui",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReportingGuide.rst:4362,safe,safe,4362,interpreter/llvm-project/llvm/docs/ReportingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReportingGuide.rst,1,['safe'],['safe']
Safety,"; * ``strcmp``; * ``strlen``; * ``strncmp``; * ``wcschr``; * ``wcscmp``; * ``wcslen``; * ``wcsncmp``; * ``wmemchr``; * ``wmemcmp``. In each case, the builtin form has the name of the C library function prefixed; by ``__builtin_``. Example:. .. code-block:: c. void *p = __builtin_memchr(""foobar"", 'b', 5);. In addition to the above, one further builtin is provided:. .. code-block:: c. char *__builtin_char_memchr(const char *haystack, int needle, size_t size);. ``__builtin_char_memchr(a, b, c)`` is identical to; ``(char*)__builtin_memchr(a, b, c)`` except that its use is permitted within; constant expressions in C++11 onwards (where a cast from ``void*`` to ``char*``; is disallowed in general). Constant evaluation support for the ``__builtin_mem*`` functions is provided; only for arrays of ``char``, ``signed char``, ``unsigned char``, or ``char8_t``,; despite these functions accepting an argument of type ``const void*``. Support for constant expression evaluation for the above builtins can be detected; with ``__has_feature(cxx_constexpr_string_builtins)``. Variadic function builtins; --------------------------. Clang provides several builtins for working with variadic functions from the C; standard library ``<stdarg.h>`` header:. * ``__builtin_va_list``. A predefined typedef for the target-specific ``va_list`` type. * ``void __builtin_va_start(__builtin_va_list list, <parameter-name>)``. A builtin function for the target-specific ``va_start`` function-like macro.; The ``parameter-name`` argument is the name of the parameter preceding the; ellipsis (``...``) in the function signature. Alternatively, in C23 mode or; later, it may be the integer literal ``0`` if there is no parameter preceding; the ellipsis. This function initializes the given ``__builtin_va_list`` object.; It is undefined behavior to call this function on an already initialized; ``__builin_va_list`` object. * ``void __builtin_va_end(__builtin_va_list list)``. A builtin function for the target-specific ``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:134965,detect,detected,134965,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['detect'],['detected']
Safety,"; * code 7: ``naked``; * code 8: ``nest``; * code 9: ``noalias``; * code 10: ``nobuiltin``; * code 11: ``nocapture``; * code 12: ``nodeduplicate``; * code 13: ``noimplicitfloat``; * code 14: ``noinline``; * code 15: ``nonlazybind``; * code 16: ``noredzone``; * code 17: ``noreturn``; * code 18: ``nounwind``; * code 19: ``optsize``; * code 20: ``readnone``; * code 21: ``readonly``; * code 22: ``returned``; * code 23: ``returns_twice``; * code 24: ``signext``; * code 25: ``alignstack(<n>)``; * code 26: ``ssp``; * code 27: ``sspreq``; * code 28: ``sspstrong``; * code 29: ``sret``; * code 30: ``sanitize_address``; * code 31: ``sanitize_thread``; * code 32: ``sanitize_memory``; * code 33: ``uwtable``; * code 34: ``zeroext``; * code 35: ``builtin``; * code 36: ``cold``; * code 37: ``optnone``; * code 38: ``inalloca``; * code 39: ``nonnull``; * code 40: ``jumptable``; * code 41: ``dereferenceable(<n>)``; * code 42: ``dereferenceable_or_null(<n>)``; * code 43: ``convergent``; * code 44: ``safestack``; * code 45: ``argmemonly``; * code 46: ``swiftself``; * code 47: ``swifterror``; * code 48: ``norecurse``; * code 49: ``inaccessiblememonly``; * code 50: ``inaccessiblememonly_or_argmemonly``; * code 51: ``allocsize(<EltSizeParam>[, <NumEltsParam>])``; * code 52: ``writeonly``; * code 53: ``speculatable``; * code 54: ``strictfp``; * code 55: ``sanitize_hwaddress``; * code 56: ``nocf_check``; * code 57: ``optforfuzzing``; * code 58: ``shadowcallstack``; * code 59: ``speculative_load_hardening``; * code 60: ``immarg``; * code 61: ``willreturn``; * code 62: ``nofree``; * code 63: ``nosync``; * code 64: ``sanitize_memtag``; * code 65: ``preallocated``; * code 66: ``no_merge``; * code 67: ``null_pointer_is_valid``; * code 68: ``noundef``; * code 69: ``byref``; * code 70: ``mustprogress``; * code 74: ``vscale_range(<Min>[, <Max>])``; * code 75: ``swiftasync``; * code 76: ``nosanitize_coverage``; * code 77: ``elementtype``; * code 78: ``disable_sanitizer_instrumentation``; * code 79: `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:39016,safe,safestack,39016,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,1,['safe'],['safestack']
Safety,"; - The deprecated function `ROOT::Detail::RDF::RActionImpl<Helper>::GetDataBlockCallback()` is removed; please use `GetSampleCallback()` instead.; - The deprecated RooFit containers `RooHashTable`, `RooNameSet`, `RooSetPair`, and `RooList` are removed. Please use STL container classes instead, like `std::unordered_map`, `std::set`, and `std::vector`.; - The `RooFit::FitOptions(const char*)` command to steer [RooAbsPdf::fitTo()](https://root.cern.ch/doc/v628/classRooAbsPdf.html) with an option string was removed. This way of configuring the fit was deprecated since at least since ROOT 5.02.; Subsequently, the `RooMinimizer::fit(const char*)` function and the [RooMCStudy](https://root.cern.ch/doc/v628/classRooMCStudy.html) constructor that takes an option string were removed as well.; - The overload of `RooAbsData::createHistogram` that takes integer parameters for the bin numbers is now deprecated and will be removed in ROOT 6.30.; This was done to avoid confusion with inconsistent behavior when compared to other `createHistogram` overloads.; Please use the verson of `createHistogram` that takes RooFit command arguments.; - The `RooAbsData::valid()` method to cache valid entries in the variable range; was removed. It was not implemented in RooDataSet, so it never worked as; intended. Related to it was the `RooDataHist::cacheValidEntries()` function, which is removed as well.; The preferred way to reduce RooFit datasets to subranges is [RooAbsData::reduce()](https://root.cern.ch/doc/v628/classRooAbsData.html#acfa7b31e5cd751eec1bc4e95d2796390).; - The longtime-deprecated `RooStats::HistFactory::EstimateSummary` class is removed, including the functions that use it. The information that it was meant to store is managed by the `RooStats::HistFactory::Measurement` object since many years.; - The `RooSuperCategory::MakeIterator()` function that was deprecated since 6.22 is now removed. Please use range-based loops to iterate over the category states.; - The `HybridCalculat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:3055,avoid,avoid,3055,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,1,['avoid'],['avoid']
Safety,"; ------------------------------------------------------. This pass, only available in ``opt``, prints the SCCs of the call graph to; standard error in a human-readable form. ``print-cfg-sccs``: Print SCCs of each function CFG; ---------------------------------------------------. This pass, only available in ``opt``, printsthe SCCs of each function CFG to; standard error in a human-readable fom. ``print-function``: Print function to stderr; --------------------------------------------. The ``PrintFunctionPass`` class is designed to be pipelined with other; ``FunctionPasses``, and prints out the functions of the module as they are; processed. ``print-module``: Print module to stderr; ----------------------------------------. This pass simply prints out the entire module when it is executed. ``regions``: Detect single entry single exit regions; ----------------------------------------------------. The ``RegionInfo`` pass detects single entry single exit regions in a function,; where a region is defined as any subgraph that is connected to the remaining; graph at only two spots. Furthermore, a hierarchical region tree is built. .. _passes-scalar-evolution:. ``scalar-evolution``: Scalar Evolution Analysis; -----------------------------------------------. The ``ScalarEvolution`` analysis can be used to analyze and categorize scalar; expressions in loops. It specializes in recognizing general induction; variables, representing them with the abstract and opaque ``SCEV`` class.; Given this analysis, trip counts of loops and other important properties can be; obtained. This analysis is primarily useful for induction variable substitution and; strength reduction. ``scev-aa``: ScalarEvolution-based Alias Analysis; -------------------------------------------------. Simple alias analysis implemented in terms of ``ScalarEvolution`` queries. This differs from traditional loop dependence analysis in that it tests for; dependencies within a single iteration of a loop, rather than de",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:10131,detect,detects,10131,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['detect'],['detects']
Safety,"; ---------------------. ABI visibility and default annotations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Requiring ``-fbounds-safety`` adopters to add bounds annotations to all pointers; in the codebase would be a significant adoption burden. To avoid this and to; secure all pointers by default, ``-fbounds-safety`` applies default bounds; annotations to pointer types.; Default annotations apply to pointer types of declarations. ``-fbounds-safety`` applies default bounds annotations to pointer types used in; declarations. The default annotations are determined by the ABI visibility of; the pointer. A pointer type is ABI-visible if changing its size or; representation affects the ABI. For instance, changing the size of a type used; in a function parameter will affect the ABI and thus pointers used in function; parameters are ABI-visible pointers. On the other hand, changing the types of; local variables won't have such ABI implications. Hence, ``-fbounds-safety``; considers the outermost pointer types of local variables as non-ABI visible. The; rest of the pointers such as nested pointer types, pointer types of global; variables, struct fields, and function prototypes are considered ABI-visible. All ABI-visible pointers are treated as ``__single`` by default unless annotated; otherwise. This default both preserves ABI and makes these pointers safe by; default. This behavior can be controlled with macros, i.e.,; ``__ptrcheck_abi_assume_*ATTR*()``, to set the default annotation for; ABI-visible pointers to be either ``__single``, ``__bidi_indexable``,; ``__indexable``, or ``__unsafe_indexable``. For instance,; ``__ptrcheck_abi_assume_unsafe_indexable()`` will make all ABI-visible pointers; be ``__unsafe_indexable``. Non-ABI visible pointers — the outermost pointer; types of local variables — are ``__bidi_indexable`` by default, so that these; pointers have the bounds information necessary to perform bounds checks without; the need for a manual annotation. All ``const cha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:20927,safe,safety,20927,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['safe'],['safety']
Safety,"; // #5: error: implicit loading of libA is currently unsupported. ```. This pattern is not only used in the ROOT prompt but in I/O hotspots such as; `ShowMembers` and `TClass::IsA`. A naive implementation of this feature would require inclusion of all reachable; library descriptors (aka header files) at ROOT startup time. Of course this is; not feasible and ROOT inserts a set of optimizations to fence itself from the; costly full header inclusion. Unfortunately, several of them are home-grown and; in a few cases inaccurate (eg line #5) causing a noticeable technical debt. Here we will briefly describe the three common layers of optimizations: ROOT PCH,; ROOTMAP and RDICT. The ROOT precompiled header (PCH) reduces the CPU and memory cost for ROOT's; most used libraries. The precompiled header technology is well-understood since; decades [[4]]. It is an efficient on-disk representation of the state of the; compiler after parsing a set of headers. It can be loaded before starting the; next instance to avoid doing redundant work. At build time, rootcling (ROOT's; dictionary generator) creates such PCH file which is attached at ROOT startup; time. Its major drawback is the fact that if third-party users want to include; their libraries, they have to recompile it every time there is a change. RDICT files store some useful information (in particular about class offsets) in; ROOT files to avoid the potentially expensive call to the interpreter if the; information is not the PCH. For example, ROOT's libGeom and other third-party; code. This is done to circumvent the costly call to `ShowMembers` which will; require parsing. ROOTMAP files reduce parsing for code which is not in the PCH. Consider; `foo::bar` and `S` are defined in `libFoo`'s `Foo.h`:; ```cpp; // Foo.h; namespace foo { struct bar{}; }; struct S{};; ```. ```bash; # libFoo.rootmap; { decls }; namespace foo { }; struct S;; ; [ libFoo.so ]; # List of selected classes; class bar; struct S; ```. ```cpp; // G__Foo.cxx ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:6201,avoid,avoid,6201,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,2,"['avoid', 'redund']","['avoid', 'redundant']"
Safety,"; ======================; Thread Safety Analysis; ======================. Introduction; ============. Clang Thread Safety Analysis is a C++ language extension which warns about; potential race conditions in code. The analysis is completely static (i.e.; compile-time); there is no run-time overhead. The analysis is still; under active development, but it is mature enough to be deployed in an; industrial setting. It is being developed by Google, in collaboration with; CERT/SEI, and is used extensively in Google's internal code base. Thread safety analysis works very much like a type system for multi-threaded; programs. In addition to declaring the *type* of data (e.g. ``int``, ``float``,; etc.), the programmer can (optionally) declare how access to that data is; controlled in a multi-threaded environment. For example, if ``foo`` is; *guarded by* the mutex ``mu``, then the analysis will issue a warning whenever; a piece of code reads or writes to ``foo`` without first locking ``mu``.; Similarly, if there are particular routines that should only be called by; the GUI thread, then the analysis will warn if other threads call those; routines. Getting Started; ----------------. .. code-block:: c++. #include ""mutex.h"". class BankAccount {; private:; Mutex mu;; int balance GUARDED_BY(mu);. void depositImpl(int amount) {; balance += amount; // WARNING! Cannot write balance without locking mu.; }. void withdrawImpl(int amount) REQUIRES(mu) {; balance -= amount; // OK. Caller must have locked mu.; }. public:; void withdraw(int amount) {; mu.Lock();; withdrawImpl(amount); // OK. We've locked mu.; } // WARNING! Failed to unlock mu. void transferFrom(BankAccount& b, int amount) {; mu.Lock();; b.withdrawImpl(amount); // WARNING! Calling withdrawImpl() requires locking b.mu.; depositImpl(amount); // OK. depositImpl() has no requirements.; mu.Unlock();; }; };. This example demonstrates the basic concepts behind the analysis. The; ``GUARDED_BY`` attribute declares that a thread must lo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:544,safe,safety,544,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['safe'],['safety']
Safety,"; ==========================================. Introduction; ============. The :ref:`inalloca <attr_inalloca>` attribute is designed to allow; taking the address of an aggregate argument that is being passed by; value through memory. Primarily, this feature is required for; compatibility with the Microsoft C++ ABI. Under that ABI, class; instances that are passed by value are constructed directly into; argument stack memory. Prior to the addition of inalloca, calls in LLVM; were indivisible instructions. There was no way to perform intermediate; work, such as object construction, between the first stack adjustment; and the final control transfer. With inalloca, all arguments passed in; memory are modelled as a single alloca, which can be stored to prior to; the call. Unfortunately, this complicated feature comes with a large; set of restrictions designed to bound the lifetime of the argument; memory around the call. For now, it is recommended that frontends and optimizers avoid producing; this construct, primarily because it forces the use of a base pointer.; This feature may grow in the future to allow general mid-level; optimization, but for now, it should be regarded as less efficient than; passing by value with a copy. Intended Usage; ==============. The example below is the intended LLVM IR lowering for some C++ code; that passes two default-constructed ``Foo`` objects to ``g`` in the; 32-bit Microsoft C++ ABI. .. code-block:: c++. // Foo is non-trivial.; struct Foo { int a, b; Foo(); ~Foo(); Foo(const Foo &); };; void g(Foo a, Foo b);; void f() {; g(Foo(), Foo());; }. .. code-block:: text. %struct.Foo = type { i32, i32 }; declare void @Foo_ctor(%struct.Foo* %this); declare void @Foo_dtor(%struct.Foo* %this); declare void @g(<{ %struct.Foo, %struct.Foo }>* inalloca %memargs). define void @f() {; entry:; %base = call i8* @llvm.stacksave(); %memargs = alloca <{ %struct.Foo, %struct.Foo }>; %b = getelementptr <{ %struct.Foo, %struct.Foo }>* %memargs, i32 1; call voi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst:1072,avoid,avoid,1072,interpreter/llvm-project/llvm/docs/InAlloca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst,1,['avoid'],['avoid']
Safety,; CD2; Value of preprocessing numbers; Unknown. 833; CD2; Explicit conversion of a scoped enumeration value to a floating type; Unknown. 834; CD2; What is an “ordinary string literal”?; Unknown. 835; CD2; Scoped enumerations and the “usual arithmetic conversions”; Unknown. 836; NAD; [[noreturn]] applied to function types; Unknown. 837; C++11; Constexpr functions and return braced-init-list; Unknown. 838; C++11; Use of this in a brace-or-equal-initializer; Unknown. 839; dup; sizeof with opaque enumerations; Unknown. 840; CD2; Rvalue references as nontype template parameters; Unknown. 842; CD2; Casting to rvalue reference type; Unknown. 845; CD2; What is the “first declaration” of an explicit specialization?; Unknown. 846; CD2; Rvalue references to functions; Unknown. 847; CD2; Error in rvalue reference deduction example; Unknown. 850; CD2; Restrictions on use of non-static data members; Unknown. 852; CD6; using-declarations and dependent base classes; Unknown. 853; CD2; Support for relaxed pointer safety; Unknown. 854; CD2; Left shift and unsigned extended types; Unknown. 855; CD2; Incorrect comments in braced-init-list assignment example; Unknown. 858; CD2; Example binding an rvalue reference to an lvalue; Unknown. 860; C++11; Explicit qualification of constexpr member functions; Unknown. 861; CD2; Unintended ambiguity in inline namespace lookup; Unknown. 862; CD2; Undefined behavior with enumerator value overflow; Unknown. 863; CD2; Rvalue reference cast to incomplete type; Unknown. 864; C++11; braced-init-list in the range-based for statement; Unknown. 865; CD2; Initializing a std::initializer_list; Unknown. 869; CD2; Uninitialized thread_local objects; Unknown. 872; CD2; Lexical issues with raw strings; Unknown. 873; C++11; Deducing rvalue references in declarative contexts; Clang 3.0. 874; CD2; Class-scope definitions of enumeration types; Unknown. 876; CD2; Type references in rvalue reference deduction specification; Unknown. 877; CD2; Viable functions and bindi,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:57255,safe,safety,57255,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,1,['safe'],['safety']
Safety,"; CPUs). At the moment, SafeStack assumes that the compiler's implementation is correct.; This has not been verified except through manual code inspection, and could; always regress in the future. It's therefore desirable to have a separate; static or dynamic binary verification tool that would check the correctness of; the SafeStack instrumentation in final binaries. Usage; =====. To enable SafeStack, just pass ``-fsanitize=safe-stack`` flag to both compile; and link command lines. Supported Platforms; -------------------. SafeStack was tested on Linux, NetBSD, FreeBSD and macOS. Low-level API; -------------. ``__has_feature(safe_stack)``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. In some rare cases one may need to execute different code depending on; whether SafeStack is enabled. The macro ``__has_feature(safe_stack)`` can; be used for this purpose. .. code-block:: c. #if __has_feature(safe_stack); // code that builds only under SafeStack; #endif. ``__attribute__((no_sanitize(""safe-stack"")))``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Use ``__attribute__((no_sanitize(""safe-stack"")))`` on a function declaration; to specify that the safe stack instrumentation should not be applied to that; function, even if enabled globally (see ``-fsanitize=safe-stack`` flag). This; attribute may be required for functions that make assumptions about the; exact layout of their stack frames. All local variables in functions with this attribute will be stored on the safe; stack. The safe stack remains unprotected against memory errors when accessing; these variables, so extra care must be taken to manually ensure that all such; accesses are safe. Furthermore, the addresses of such local variables should; never be stored on the heap, as it would leak the location of the SafeStack. ``__builtin___get_unsafe_stack_ptr()``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. This builtin function returns current unsafe stack pointer of the current; thread. ``__builtin___get_unsafe_stack_bottom()``; ~~~~~~",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst:6584,safe,safe-stack,6584,interpreter/llvm-project/clang/docs/SafeStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst,1,['safe'],['safe-stack']
Safety,"; Root.Html.Root: http://root.cern.ch/root/html; ```. Filesystem output directory for generated web pages (default:; `htmldoc)`. ``` {.cpp}; Root.Html.OutputDir: htmldoc/; ```. Address of the package's home page (default: <http://root.cern.ch>):. ``` {.cpp}; Root.Html.HomePage:; ```. Location of user defined header and footer files, see; <http://root.cern.ch/root/html/THtml#conf:header> (defaults are `""""`,; example: `../header.txt`, `../footer.txt`):. ``` {.cpp}; Root.Html.Header:; Root.Html.Footer:; ```. Tag for detecting class description comments (default value is set; below). ``` {.cpp}; Root.Html.Description: //____________________; ```. Tag for detecting ""Author"" comment (default value is set below). ``` {.cpp}; Root.Html.Author: // Author:; ```. Tag for detecting ""last updated"" comment. **`THtml`** uses the current; date if this tag is not found in a class source file (default value is; set below). ``` {.cpp}; Root.Html.LastUpdate: // @(#); ```. Tag for detecting ""Copyright"" comment (default value is set below). ``` {.cpp}; Root.Html.Copyright: * Copyright; ```. ### GUI Specific Settings. Set the ""`native`"" ROOT GUI interface to be used in a ROOT session. ``` {.cpp}; Gui.Backend: native; Gui.Factory: native; ```. GUI default fonts in use:. ``` {.cpp}; Gui.DefaultFont: -adobe-helvetica-medium-r-*-*-12-*-*-*-*-*-iso8859-1; Gui.MenuFont: -adobe-helvetica-medium-r-*-*-12-*-*-*-*-*-iso8859-1; Gui.MenuHiFont: -adobe-helvetica-bold-r-*-*-12-*-*-*-*-*-iso8859-1; Gui.DocFixedFont: -adobe-courier-medium-r-*-*-12-*-*-*-*-*-iso8859-1; Gui.DocPropFont: -adobe-helvetica-medium-r-*-*-12-*-*-*-*-*-iso8859-1; Gui.IconFont: -adobe-helvetica-medium-r-*-*-10-*-*-*-*-*-iso8859-1; Gui.StatusFont: -adobe-helvetica-medium-r-*-*-10-*-*-*-*-*-iso8859-1; ```. Regular background and foreground colors in use:. ``` {.cpp}; Gui.BackgroundColor: #c0c0c0; Gui.ForegroundColor: black; ```. Selection background and foreground colors in use:. ``` {.cpp}; Gui.SelectBackgroundColor: #000080; Gui.S",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InstallandBuild.md:9840,detect,detecting,9840,documentation/users-guide/InstallandBuild.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InstallandBuild.md,1,['detect'],['detecting']
Safety,"; T = i + X; load [T + 4]; ...; load [T + 7]; ...; load [T + 15]; //===---------------------------------------------------------------------===//. It's not always a good idea to choose rematerialization over spilling. If all; the load / store instructions would be folded then spilling is cheaper because; it won't require new live intervals / registers. See 2003-05-31-LongShifts for; an example. //===---------------------------------------------------------------------===//. With a copying garbage collector, derived pointers must not be retained across; collector safe points; the collector could move the objects and invalidate the; derived pointer. This is bad enough in the first place, but safe points can; crop up unpredictably. Consider:. %array = load { i32, [0 x %obj] }** %array_addr; %nth_el = getelementptr { i32, [0 x %obj] }* %array, i32 0, i32 %n; %old = load %obj** %nth_el; %z = div i64 %x, %y; store %obj* %new, %obj** %nth_el. If the i64 division is lowered to a libcall, then a safe point will (must); appear for the call site. If a collection occurs, %array and %nth_el no longer; point into the correct object. The fix for this is to copy address calculations so that dependent pointers; are never live across safe point boundaries. But the loads cannot be copied; like this if there was an intervening store, so may be hard to get right. Only a concurrent mutator can trigger a collection at the libcall safe point.; So single-threaded programs do not have this requirement, even with a copying; collector. Still, LLVM optimizations would probably undo a front-end's careful; work. //===---------------------------------------------------------------------===//. The ocaml frametable structure supports liveness information. It would be good; to support it. //===---------------------------------------------------------------------===//. The FIXME in ComputeCommonTailLength in BranchFolding.cpp needs to be; revisited. The check is there to work around a misuse of direct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:3229,safe,safe,3229,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,1,['safe'],['safe']
Safety,"; TSQLMonitoringWriter::SendParameters, drop ''' around field names in; the INSERT string; also use TString::Format(...) instead of Form(...); where relevant.  In TPerfStats: call 'proofgroup' instead of; 'group' the field with the PROOF group (interference with the 'group'; keyword in SQL); add new field 'querytag' VARCHAR(64) with the unique; query tag; in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:4709,abort,abort,4709,proof/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html,1,['abort'],['abort']
Safety,"; This sort of check cannot identify all possible overlapping topologies,; but it works for more than 95% and is much faster than the usual; shape-to-shape comparison. For a 100% reliability, one can perform the; check at the level of a single volume by using `option`=""`d`"" or; `option`=""`d<number>`"" to perform overlap checking by sampling the; volume with \<`number`\> random points (default 1 million). This; produces also a picture showing in red the overlapping region and; estimates the volume of the overlaps. An extrusion *A)* is declared in any of the following cases:. - At least one of the vertices of the daughter mesh representation is; outside the mother volume (in fact its shape) and having a safety; distance to the mother greater than the desired value;; - At least one of the mother vertices is contained also by one of its; daughters, in the same conditions. An overlap *B)* is declared if:. - At least one vertex of a positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. Once; the checking tool is fired-up inside a volume or at top level, the list; of overlaps (visible as Illegal overlaps inside a TBrowser) held; by the manager class will be filled with TGeoOverlap objects; containing a full description of the detected overlaps. The list is; sorted in the decreasing order of the overlapping distance, extrusions; coming first. An overlap object name represents the full description of; the overlap, containing both candidate node names and a letter; (x-extrusion, o-overlap) representing the type. Double-clicking an; overlap item in a TBrowser produces a picture of the overlap; containing only the two overlapping nodes (one in blue and one in green); and having the critical ve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:94547,safe,safety,94547,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['safe'],['safety']
Safety,"; Yes. 476; C11; volatile semantics for lvalues; Unknown. 477; C11; nan should take a string argument; N/A. 478; NAD; Valid uses of the main function; Yes. 479; Dup; Unclear specification of mtx_trylock on non-recursive muteness; Duplicate of 269. 480; C11; cnd_wait and cnd_timewait should allow spurious wake-ups; N/A. 481; C11; Controlling expression of _Generic primary expression; Clang 3.8. 482; NAD; Macro invocation split over many files; Unknown. 483; NAD; __LINE__ and __FILE__ in macro replacement list; Yes. 484; NAD; invalid characters in strcoll(); N/A. 485; C11; Problem with the specification of ATOMIC_VAR_INIT; Yes. 486; NAD; Inconsistent specification for arithmetic on atomic objects; Unknown. 487; C11; timespec vs. tm; N/A. 488; C11; c16rtomb() on wide characters encoded as multiple char16_t; N/A. 489; NAD; Integer Constant Expression. Partial; Clang inconsistently diagnoses folding a constan expression into an ICE; as an extension.; . 490; NAD; Unwritten Assumptions About if-then; Yes. 491; C11; Concern with Keywords that Match Reserved Identifiers. Partial; Clang issues a reserved identifier diagnostic when the identifier leads; with an underscore followed by a capital letter or double underscores,; even if the identifier is used for a macro definition.; . 492; NAD; Named Child struct-union with no Member; Clang 3.6. 493; Dup; Mutex Initialization Underspecified; Duplicate of 469. 494; C11; Part 1: Alignment specifier expression evaluation; Yes. 495; C11; Part 2: Atomic specifier expression evaluation; Not resolved. 496; NAD; offsetof questions; Yes. 497; C11; ""white-space character"" defined in two places; N/A. 498; C11; mblen, mbtowc, and wctomb thread-safety; N/A. 499; C17; Anonymous structure in union behavior; Yes. 500; C17; Ambiguous specification for FLT_EVAL_METHOD; Unknown. 501; C17; Can DECIMAL_DIG be larger than necessary?; N/A. 502; NAD; Flexible array member in an anonymous struct; Yes. 503; NAD; Hexadecimal floating-point and strtod; N/A. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html:27865,safe,safety,27865,interpreter/llvm-project/clang/www/c_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html,1,['safe'],['safety']
Safety,"; ^^^^^^^^^^^^^^^^^^^^^^. This option controls whether constructors and destructors of ""container"" types; should be considered for inlining. ``-analyzer-config c++-container-inlining=[true | false]``. Currently, these constructors and destructors are NOT considered for inlining; by default. The current implementation of this setting checks whether a type has a member; named 'iterator' or a member named 'begin'; these names are idiomatic in C++,; with the latter specified in the C++11 standard. The analyzer currently does a; fairly poor job of modeling certain data structure invariants of container-like; objects. For example, these three expressions should be equivalent:. .. code-block:: cpp. std::distance(c.begin(), c.end()) == 0; c.begin() == c.end(); c.empty(). Many of these issues are avoided if containers always have unknown, symbolic; state, which is what happens when their constructors are treated as opaque.; In the future, we may decide specific containers are ""safe"" to model through; inlining, or choose to model them directly using checkers instead. Basics of Implementation; ------------------------. The low-level mechanism of inlining a function is handled in; ExprEngine::inlineCall and ExprEngine::processCallExit. If the conditions are right for inlining, a CallEnter node is created and added; to the analysis work list. The CallEnter node marks the change to a new; LocationContext representing the called function, and its state includes the; contents of the new stack frame. When the CallEnter node is actually processed,; its single successor will be an edge to the first CFG block in the function. Exiting an inlined function is a bit more work, fortunately broken up into; reasonable steps:. 1. The CoreEngine realizes we're at the end of an inlined call and generates a; CallExitBegin node. 2. ExprEngine takes over (in processCallExit) and finds the return value of the; function, if it has one. This is bound to the expression that triggered the; call. (In the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst:4901,safe,safe,4901,interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,1,['safe'],['safe']
Safety,"; ```; Error in <ROOT::Internal::TCheckHashRecursiveRemoveConsistency::CheckRecursiveRemove>: The class SomeName overrides TObject::Hash but does not call TROOT::RecursiveRemove in its destructor.; ```; - When a container relies on TObject::Hash and RecursiveRemove, for example THashTable, the container uses ```TObject::CheckedHash()``` instead of ```TObject::Hash``` during insertion operation to record in the object whether the Hash/RecursiveRemove setup is done properly (as explain above). It this is not the case ```TObject::HasInconsistentHash()``` will return true. This can then be used to select, in RecursiveRemove, whether the call to Hash can be trusted or if one needs to do a linear search (as was done in v6.10 and earlier).; - In TClass::GetMissingDictionaries activate the search through the base classes.; - Added a TStatusBitsChecker to avoid Status Bits overlap in class hierarchy deriving from TObject (and resolved a handful of conflicts).; - Introduced support for type safe range-for-loop for ROOT collection. The typical use is:. ```; for(auto bcl : TRangeDynCast<TBaseClass>( * cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; for(auto bcl : TRangeDynCast<TBaseClass>( cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; ```; - ClassDefInline has been enhanced even for some compiled class (without a dictionary). ClassDefInline can still not be used for class template instance using Double32_t or Float16_t as a template parameter or for class or class template that do not have a public default constructor.; - ROOT's backport of `std::string_view` has been updated to follow what's available in C++17, notably its `to_string` member function has been removed. ### Thread safety. Resolved the race conditions inherent to the use of the RecursiveRemove mechanism. - Introduced ```ROOT::TReentrantRWLock```, an implementation of a reentrant read-write lock with a configurable internal mutex/lock and a condit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:3524,safe,safe,3524,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['safe'],['safe']
Safety,"; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_queue_ptr""; A global memory address space pointer to the ROCm runtime; ``struct amd_queue_t`` structure for the HSA queue of the; associated dispatch AQL packet. It is only required for pre-GFX9; devices for the trap handler ABI (see :ref:`amdgpu-amdhsa-trap-handler-abi`). ====================== ============== ========= ================================. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to control the dispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compati",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:149368,detect,detecting,149368,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['detect'],['detecting']
Safety,"; below. They are still listed as ""experimental"" to indicate that no forward or backward; compatibility guarantees are offered across versions. If your use case is such; that you need some form of forward compatibility guarantee, please raise the; issue on the llvm-dev mailing list. LLVM still supports an alternate mechanism for conservative garbage collection; support using the ``gcroot`` intrinsic. The ``gcroot`` mechanism is mostly of; historical interest at this point with one exception - its implementation of; shadow stacks has been used successfully by a number of language frontends and; is still supported. Overview & Core Concepts; ========================. To collect dead objects, garbage collectors must be able to identify; any references to objects contained within executing code, and,; depending on the collector, potentially update them. The collector; does not need this information at all points in code - that would make; the problem much harder - but only at well-defined points in the; execution known as 'safepoints' For most collectors, it is sufficient; to track at least one copy of each unique pointer value. However, for; a collector which wishes to relocate objects directly reachable from; running code, a higher standard is required. One additional challenge is that the compiler may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:1504,safe,safepoints,1504,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['safe'],['safepoints']
Safety,"; check at the level of a single volume by using `option`=""`d`"" or; `option`=""`d<number>`"" to perform overlap checking by sampling the; volume with \<`number`\> random points (default 1 million). This; produces also a picture showing in red the overlapping region and; estimates the volume of the overlaps. An extrusion A) is declared in any of the following cases:. - At least one of the vertices of the daughter mesh representation is; outside the mother volume (in fact its shape) and having a safety; distance to the mother greater than the desired value;; - At least one of the mother vertices is contained also by one of its; daughters, in the same conditions. An overlap B) is declared if:. - At least one vertex of a positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. Once; the checking tool is fired-up inside a volume or at top level, the list; of overlaps (visible as Illegal overlaps inside a **`TBrowser`**) held; by the manager class will be filled with **`TGeoOverlap`** objects; containing a full description of the detected overlaps. The list is; sorted in the decreasing order of the overlapping distance, extrusions; coming first. An overlap object name represents the full description of; the overlap, containing both candidate node names and a letter; (x-extrusion, o-overlap) representing the type. Double-clicking an; overlap item in a **`TBrowser`** produces a picture of the overlap; containing only the two overlapping nodes (one in blue and one in green); and having the critical vertices represented by red points. The picture; can be rotated/zoomed or drawn in X3d as any other view. Calling; `gGeoManager->PrintOverlaps()` prints the list of overlaps. ### Graphical Checking M",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:134253,avoid,avoid,134253,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['avoid'],['avoid']
Safety,"; consume(provide_uncounted()); // warn; }. void foo2() {; RefCountable* uncounted = provide_uncounted();; consume(uncounted); // warn; }. Although we are enforcing member variables to be ref-counted by `webkit.NoUncountedMemberChecker` any method of the same class still has unrestricted access to these. Since from a caller's perspective we can't guarantee a particular member won't get modified by callee (directly or indirectly) we don't consider values obtained from members safe. Note: It's likely this heuristic could be made more precise with fewer false positives - for example calls to free functions that don't have any parameter other than the pointer should be safe as the callee won't be able to tamper with the member unless it's a global variable. .. code-block:: cpp. struct Foo {; RefPtr<RefCountable> member;; void consume(RefCountable*) { /* ... */ }; void bugprone() {; consume(member.get()); // warn; }; };. The implementation of this rule is a heuristic - we define a whitelist of kinds of values that are considered safe to be passed as arguments. If we can't prove an argument is safe it's considered an error. Allowed kinds of arguments:. - values obtained from ref-counted objects (including temporaries as those survive the call too). .. code-block:: cpp. RefCountable* provide_uncounted();; void consume(RefCountable*);. void foo() {; RefPtr<RefCountable> rc = makeRef(provide_uncounted());; consume(rc.get()); // ok; consume(makeRef(provide_uncounted()).get()); // ok; }. - forwarding uncounted arguments from caller to callee. .. code-block:: cpp. void foo(RefCountable& a) {; bar(a); // ok; }. Caller of ``foo()`` is responsible for ``a``'s lifetime. - ``this`` pointer. .. code-block:: cpp. void Foo::foo() {; baz(this); // ok; }. Caller of ``foo()`` is responsible for keeping the memory pointed to by ``this`` pointer safe. - constants. .. code-block:: cpp. foo(nullptr, NULL, 0); // ok. We also define a set of safe transformations which if passed a safe value as ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:82875,safe,safe,82875,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['safe'],['safe']
Safety,"; each loop the status of the managed transfers. Defaults to **30; seconds**. dsmgrd.scandseveryloops *n*; : Every `n` loops, the dataset repository is checked for newly; incoming staging requests. Defaults to **10**. dsmgrd.parallelxfrs *n*; : Number of concurrent transfers. Defaults to **8**. dsmgrd.stagecmd *shell\_command*; : Command to run in order to stage each file. It might be whatever you; want (executable, shell script...). If you add `$URLTOSTAGE` and/or; `$TREENAME` in the *shell\_command*, they'll be substituted; respectively with the destination URL and the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4305,timeout,timeout,4305,proof/doc/confman/DatasetStager.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md,1,['timeout'],['timeout']
Safety,"; each; level includes all the guarantees of the previous level except for; Acquire/Release. (See also `LangRef Ordering <LangRef.html#ordering>`_.). .. _NotAtomic:. NotAtomic; ---------. NotAtomic is the obvious, a load or store which is not atomic. (This isn't; really a level of atomicity, but is listed here for comparison.) This is; essentially a regular load or store. If there is a race on a given memory; location, loads from that location return undef. Relevant standard; This is intended to match shared variables in C/C++, and to be used in any; other context where memory access is necessary, and a race is impossible. (The; precise definition is in `LangRef Memory Model <LangRef.html#memmodel>`_.). Notes for frontends; The rule is essentially that all memory accessed with basic loads and stores; by multiple threads should be protected by a lock or other synchronization;; otherwise, you are likely to run into undefined behavior. If your frontend is; for a ""safe"" language like Java, use Unordered to load and store any shared; variable. Note that NotAtomic volatile loads and stores are not properly; atomic; do not try to use them as a substitute. (Per the C/C++ standards,; volatile does provide some limited guarantees around asynchronous signals, but; atomics are generally a better solution.). Notes for optimizers; Introducing loads to shared variables along a codepath where they would not; otherwise exist is allowed; introducing stores to shared variables is not. See; `Optimization outside atomic`_. Notes for code generation; The one interesting restriction here is that it is not allowed to write to; bytes outside of the bytes relevant to a store. This is mostly relevant to; unaligned stores: it is not allowed in general to convert an unaligned store; into two aligned stores of the same width as the unaligned store. Backends are; also expected to generate an i8 store as an i8 store, and not an instruction; which writes to surrounding bytes. (If you are writing a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:6765,safe,safe,6765,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['safe'],['safe']
Safety,"; formats: tar | deb | nsis | rpm | dmg | pkg; --tarball-tag TARBALL_TAG; Package the snapshot of a given tag in a tarball; (.tar.bz2); --deb-tag DEB_TAG Package the snapshot of a given tag in a Debian; package (.deb); --rpm-tag RPM_TAG Package the snapshot of a given tag in an RPM package; (.rpm); --nsis-tag NSIS_TAG Package the snapshot of a given tag in an NSIS; installer (.exe); --dmg-tag DMG_TAG Package the snapshot of a given tag in a DMG package; (.dmg); --with-llvm-url WITH_LLVM_URL; Specify an alternate URL of LLVM repo; --with-clang-url WITH_CLANG_URL; Specify an alternate URL of Clang repo; --with-cling-url WITH_CLING_URL; Specify an alternate URL of Cling repo; --no-test Do not run test suite of Cling; --create-dev-env CREATE_DEV_ENV; Set up a release/debug environment; --with-workdir WITH_WORKDIR; Specify an alternate working directory for CPT; --make-proper MAKE_PROPER; Internal option to support calls from build system. ```; If you want CPT to build a package by detecting your platform automatically,; use the value 'pkg'.; ```sh; ./cpt.py --current-dev=pkg; ```; or; ```sh; ./cpt.py --last-stable=pkg; ```; ### Overriding Default Variables; There are a select number of variables which can be set to make CPT work; differently. This eliminates the need to manually edit the script.; You can overrride variables by using the following syntax:; ```$ ./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --current-dev=tar```. List of variables in CPT which can be overridden:; - **CLING_GIT_URL**; * Specify the URL of the Git repository of Cling to be used by CPT; * **Default value:** ""http://root.cern.ch/git/cling.git""; * **Usage:** ```./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --last-stable=deb```. - **CLANG_GIT_URL**; * Specify the URL of the Git repository of Clang to be used by CPT; * **Default value:** ""http://root.cern.ch/git/clang.git""; * **Usage:** ```./cpt.py --with-clang-url=""http://github.com/ani07nov/clang"" --last-stable=tar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:8068,detect,detecting,8068,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,1,['detect'],['detecting']
Safety,; libc/src/math/generic/sinf.cpp; libc/src/math/generic/sqrt.cpp; libc/src/math/generic/sqrtf.cpp; libc/src/math/generic/sqrtl.cpp; libc/src/math/generic/trunc.cpp; libc/src/math/generic/truncf.cpp; libc/src/math/generic/truncl.cpp; libc/src/math/x86_64/cos.cpp; libc/src/math/x86_64/sin.cpp; libc/src/math/x86_64/tan.cpp; libc/src/signal/raise.h; libc/src/signal/sigaction.h; libc/src/signal/sigaddset.h; libc/src/signal/sigdelset.h; libc/src/signal/sigemptyset.h; libc/src/signal/sigfillset.h; libc/src/signal/signal.h; libc/src/signal/sigprocmask.h; libc/src/signal/linux/raise.cpp; libc/src/signal/linux/sigaction.cpp; libc/src/signal/linux/sigaddset.cpp; libc/src/signal/linux/sigdelset.cpp; libc/src/signal/linux/sigemptyset.cpp; libc/src/signal/linux/sigfillset.cpp; libc/src/signal/linux/signal.cpp; libc/src/signal/linux/signal.h; libc/src/signal/linux/sigprocmask.cpp; libc/src/signal/linux/__restore.cpp; libc/src/stdio/FILE.h; libc/src/stdio/fwrite.cpp; libc/src/stdio/fwrite.h; libc/src/stdlib/abort.h; libc/src/stdlib/abs.cpp; libc/src/stdlib/abs.h; libc/src/stdlib/atexit.cpp; libc/src/stdlib/atexit.h; libc/src/stdlib/atof.cpp; libc/src/stdlib/atof.h; libc/src/stdlib/atoi.cpp; libc/src/stdlib/atoi.h; libc/src/stdlib/atol.cpp; libc/src/stdlib/atol.h; libc/src/stdlib/atoll.cpp; libc/src/stdlib/atoll.h; libc/src/stdlib/bsearch.cpp; libc/src/stdlib/bsearch.h; libc/src/stdlib/div.cpp; libc/src/stdlib/div.h; libc/src/stdlib/exit.cpp; libc/src/stdlib/exit.h; libc/src/stdlib/getenv.cpp; libc/src/stdlib/getenv.h; libc/src/stdlib/labs.cpp; libc/src/stdlib/labs.h; libc/src/stdlib/ldiv.cpp; libc/src/stdlib/ldiv.h; libc/src/stdlib/llabs.cpp; libc/src/stdlib/llabs.h; libc/src/stdlib/lldiv.cpp; libc/src/stdlib/lldiv.h; libc/src/stdlib/qsort.cpp; libc/src/stdlib/qsort.h; libc/src/stdlib/strtod.cpp; libc/src/stdlib/strtod.h; libc/src/stdlib/strtof.cpp; libc/src/stdlib/strtof.h; libc/src/stdlib/strtol.cpp; libc/src/stdlib/strtol.h; libc/src/stdlib/strtold.cpp; libc/src/stdlib/strtold.h;,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:141061,abort,abort,141061,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['abort'],['abort']
Safety,"; line options to enable various optimizations. To see the new complete list of; optimizations, use the **-help** and **--load** options together; for example:. .. code-block:: bash. bugpoint --load myNewPass.so -help. **--mlimit** *megabytes*. Specifies an upper limit on memory usage of the optimization and codegen. Set; to zero to disable the limit. **--output** *filename*. Whenever the test program produces output on its standard output stream, it; should match the contents of *filename* (the ""reference output""). If you; do not use this option, **bugpoint** will attempt to generate a reference output; by compiling the program with the ""safe"" backend and running it. **--run-{int,jit,llc,custom}**. Whenever the test program is compiled, **bugpoint** should generate code for it; using the specified code generator. These options allow you to choose the; interpreter, the JIT compiler, the static native code compiler, or a; custom command (see **--exec-command**) respectively. **--safe-{llc,custom}**. When debugging a code generator, **bugpoint** should use the specified code; generator as the ""safe"" code generator. This is a known-good code generator; used to generate the ""reference output"" if it has not been provided, and to; compile portions of the program that as they are excluded from the testcase.; These options allow you to choose the; static native code compiler, or a custom command, (see **--exec-command**); respectively. The interpreter and the JIT backends cannot currently; be used as the ""safe"" backends. **--exec-command** *command*. This option defines the command to use with the **--run-custom** and; **--safe-custom** options to execute the bitcode testcase. This can; be useful for cross-compilation. **--compile-command** *command*. This option defines the command to use with the **--compile-custom**; option to compile the bitcode testcase. The command should exit with a; failure exit code if the file is ""interesting"" and should exit with a; success exit c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst:4463,safe,safe,4463,interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,1,['safe'],['safe']
Safety,"; make the AST mirror the languages as closely as possible: you have your friendly; if statement, for statement, parenthesis expression, structs, unions, etc, all; represented in a simple and explicit way.; In addition to a simple design, we work to make the source base approachable; by commenting it well, including citations of the language standards where; appropriate, and designing the code for simplicity. Beyond that, clang offers; a set of AST dumpers, printers, and visualizers that make it easy to put code in; and see how it is represented. A single unified parser for C, Objective C, C++,; and Objective C++. Clang is the ""C Language Family Front-end"", which means we intend to support; the most popular members of the C family. We are convinced that the right; parsing technology for this class of languages is a hand-built recursive-descent; parser. Because it is plain C++ code, recursive descent makes it very easy for; new developers to understand the code, it easily supports ad-hoc rules and other; strange hacks required by C/C++, and makes it straight-forward to implement; excellent diagnostics and error recovery.; We believe that implementing C/C++/ObjC in a single unified parser makes the; end result easier to maintain and evolve than maintaining a separate C and C++; parser which must be bugfixed and maintained independently of each other. Conformance with C/C++/ObjC and their; variants. When you start work on implementing a language, you find out that there is a; huge gap between how the language works and how most people understand it to; work. This gap is the difference between a normal programmer and a (scary?; super-natural?) ""language lawyer"", who knows the ins and outs of the language; and can grok standardese with ease.; In practice, being conformant with the languages means that we aim to support; the full language, including the dark and dusty corners (like trigraphs,; preprocessor arcana, C99 VLAs, etc). Where we support extensions above and; beyo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html:13328,recover,recovery,13328,interpreter/llvm-project/clang/www/features.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html,1,['recover'],['recovery']
Safety,"; operations which define that it causes wrap-around. Having the offset operations allows ``DW_OP_push_object_address`` to push a; location description that may be in a register, or be an implicit value. The; DWARF expression of ``DW_TAG_ptr_to_member_type`` can use the offset operations; without regard to what kind of location description was pushed. Since; :ref:`amdgpu-dwarf-allow-location-description-on-the-dwarf-evaluation-stack` has; generalized location storage to be bit indexable, ``DW_OP_LLVM_bit_offset``; generalizes DWARF to work with bit fields. This is generally not possible in; DWARF Version 5. The ``DW_OP_*piece`` operations only allow literal indices. A way to use a; computed offset of an arbitrary location description (such as a vector register); is required. The offset operations provide this ability since they can be used; to compute a location description on the stack. It could be possible to define ``DW_OP_plus``, ``DW_OP_plus_uconst``, and; ``DW_OP_minus`` to operate on location descriptions to avoid needing; ``DW_OP_LLVM_offset`` and ``DW_OP_LLVM_offset_uconst``. However, this is not; proposed since currently the arithmetic operations are defined to require values; of the same base type and produces a result with the same base type. Allowing; these operations to act on location descriptions would permit the first operand; to be a location description and the second operand to be an integral value; type, or vice versa, and return a location description. This complicates the; rules for implicit conversions between default address space memory location; descriptions and generic base type values. Currently the rules would convert; such a location description to the memory address value and then perform two's; compliment wrap around arithmetic. If the result was used as a location; description, it would be implicitly converted back to a default address space; memory location description. This is different to the overflow rules on location; descriptio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:13241,avoid,avoid,13241,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['avoid'],['avoid']
Safety,"; prefix. For example, ``%foo``, ``@DivisionByZero``,; ``%a.really.long.identifier``. The actual regular expression used is; '``[%@][-a-zA-Z$._][-a-zA-Z$._0-9]*``'. Identifiers that require other; characters in their names can be surrounded with quotes. Special; characters may be escaped using ``""\xx""`` where ``xx`` is the ASCII; code for the character in hexadecimal. In this way, any character can; be used in a name value, even quotes themselves. The ``""\01""`` prefix; can be used on global values to suppress mangling.; #. Unnamed values are represented as an unsigned numeric value with; their prefix. For example, ``%12``, ``@2``, ``%44``.; #. Constants, which are described in the section Constants_ below. LLVM requires that values start with a prefix for two reasons: Compilers; don't need to worry about name clashes with reserved words, and the set; of reserved words may be expanded in the future without penalty.; Additionally, unnamed identifiers allow a compiler to quickly come up; with a temporary variable without having to avoid symbol table; conflicts. Reserved words in LLVM are very similar to reserved words in other; languages. There are keywords for different opcodes ('``add``',; '``bitcast``', '``ret``', etc...), for primitive type names ('``void``',; '``i32``', etc...), and others. These reserved words cannot conflict; with variable names, because none of them start with a prefix character; (``'%'`` or ``'@'``). Here is an example of LLVM code to multiply the integer variable; '``%X``' by 8:. The easy way:. .. code-block:: llvm. %result = mul i32 %X, 8. After strength reduction:. .. code-block:: llvm. %result = shl i32 %X, 3. And the hard way:. .. code-block:: llvm. %0 = add i32 %X, %X ; yields i32:%0; %1 = add i32 %0, %0 ; yields i32:%1; %result = add i32 %1, %1. This last way of multiplying ``%X`` by 8 illustrates several important; lexical features of LLVM:. #. Comments are delimited with a '``;``' and go until the end of line.; #. Unnamed temporaries a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:4046,avoid,avoid,4046,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['avoid'],['avoid']
Safety,"; privileges. The default behavior is to emit a call to ``__clear_cache`` from the run; time library. This intrinsic does *not* empty the instruction pipeline. Modifications; of the current function are outside the scope of the intrinsic. '``llvm.instrprof.increment``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.instrprof.increment(ptr <name>, i64 <hash>,; i32 <num-counters>, i32 <index>). Overview:; """""""""""""""""". The '``llvm.instrprof.increment``' intrinsic can be emitted by a; frontend for use with instrumentation based profiling. These will be; lowered by the ``-instrprof`` pass to generate execution counts of a; program at runtime. Arguments:; """""""""""""""""""". The first argument is a pointer to a global variable containing the; name of the entity being instrumented. This should generally be the; (mangled) function name for a set of counters. The second argument is a hash value that can be used by the consumer; of the profile data to detect changes to the instrumented source, and; the third is the number of counters associated with ``name``. It is an; error if ``hash`` or ``num-counters`` differ between two instances of; ``instrprof.increment`` that refer to the same name. The last argument refers to which of the counters for ``name`` should; be incremented. It should be a value between 0 and ``num-counters``. Semantics:; """""""""""""""""""". This intrinsic represents an increment of a profiling counter. It will; cause the ``-instrprof`` pass to generate the appropriate data; structures and the code to increment the appropriate value, in a; format that can be written out by a compiler runtime and consumed via; the ``llvm-profdata`` tool. '``llvm.instrprof.increment.step``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.instrprof.increment.step(ptr <name>, i64 <hash>,; i32 <num-counters>,; i32 <index>, i64 <step>). Overview:; """""""""""""""""". The '``llvm.instrprof.increment.step``' intri",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:527540,detect,detect,527540,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['detect'],['detect']
Safety,"; reaches ``R``. Dynamic instances of ``S`` executed by threads in set; ``M`` are not converged with those executed in set ``N`` due to the; presence of ``R``. Informally, threads that diverge at ``Q``; reconverge in the same iteration of the outer cycle ``C``, but they; may have executed the inner cycle ``C'`` differently. .. table::; :align: left. +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+; | | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+; | Thread1 | Entry | P1 | Q1 | | | | R1 | S1 | P3 | ... | Exit |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+; | Thread2 | Entry | P2 | Q2 | S2 | P4 | Q4 | R2 | S4 | | | Exit |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+. In the table above, ``S2`` is not converged with ``S1`` due to ``R1``. |. - If ``R`` does not exist, or if any node other than ``R`` is the; header of ``C``, then no such child cycle ``C'`` is detected.; Threads that diverge at ``Q`` execute converged dynamic instances of; ``S`` since they do not encounter the cycle header on any path from; ``Q`` to ``S``. Informally, threads that diverge at ``Q``; reconverge at ``S`` in the same iteration of ``C``. .. table::; :align: left. +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+------+; | | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+------+; | Thread1 | Entry | P1 | Q1 | R1 | S1 | P3 | Q3 | R3 | S3 | Exit |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+------+; | Thread2 | Entry | P2 | Q2 | | S2 | P4 | Q4 | R2 | S4 | Exit |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+------+. |. .. note::. In general, the cycle ``C`` in the above statements is not; expected to be the same cycle for different headers. Cycles and; their headers are tightly coupled; f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:23993,detect,detected,23993,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,1,['detect'],['detected']
Safety,"; register spills, and local variables that are always accessed in a safe way,; while the unsafe stack stores everything else. This separation ensures that; buffer overflows on the unsafe stack cannot be used to overwrite anything; on the safe stack. SafeStack is a part of the `Code-Pointer Integrity (CPI) Project; <https://dslab.epfl.ch/research/cpi/>`_. Performance; -----------. The performance overhead of the SafeStack instrumentation is less than 0.1% on; average across a variety of benchmarks (see the `Code-Pointer Integrity; <https://dslab.epfl.ch/pubs/cpi.pdf>`__ paper for details). This is mainly; because most small functions do not have any variables that require the unsafe; stack and, hence, do not need unsafe stack frames to be created. The cost of; creating unsafe stack frames for large functions is amortized by the cost of; executing the function. In some cases, SafeStack actually improves the performance. Objects that end up; being moved to the unsafe stack are usually large arrays or variables that are; used through multiple stack frames. Moving such objects away from the safe; stack increases the locality of frequently accessed values on the stack, such; as register spills, return addresses, and small local variables. Compatibility; -------------. Most programs, static libraries, or individual files can be compiled; with SafeStack as is. SafeStack requires basic runtime support, which, on most; platforms, is implemented as a compiler-rt library that is automatically linked; in when the program is compiled with SafeStack. Linking a DSO with SafeStack is not currently supported. Known compatibility limitations; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Certain code that relies on low-level stack manipulations requires adaption to; work with SafeStack. One example is mark-and-sweep garbage collection; implementations for C/C++ (e.g., Oilpan in chromium/blink), which must be; changed to look for the live pointers on both safe and unsafe stacks. SafeStack supports ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst:1371,unsafe,unsafe,1371,interpreter/llvm-project/clang/docs/SafeStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst,1,['unsafe'],['unsafe']
Safety,"; return 0;}"" found_arc4). if(found_arc4); message(STATUS ""Found arc4random_buf in stdlib.h""); target_compile_definitions(Core PRIVATE R__ARC4_STDLIB); else(); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); if(DEFINED LIBBSDROOT); set(CMAKE_REQUIRED_INCLUDES ${LIBBSDROOT}/include); set(CMAKE_REQUIRED_LIBRARIES ${LIBBSDROOT}/lib/libbsd.so); endif(); CHECK_CXX_SOURCE_COMPILES(""#include <bsd/stdlib.h>; int main() { char buf[32]; arc4random_buf(buf, 32); return 0;}"" found_arc4_bsd); set(CMAKE_REQUIRED_INCLUDES ${OLD_CMAKE_REQUIRED_INCLUDES}); set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQUIRED_LIBRARIES}); if(found_arc4_bsd); message(STATUS ""Found arc4random_buf in bsd/stdlib.h""); target_compile_definitions(Core PRIVATE R__ARC4_BSDLIB); if(DEFINED LIBBSDROOT); target_include_directories(Core PRIVATE ${LIBBSDROOT}/include); target_link_libraries(Core PRIVATE ${LIBBSDROOT}/lib/libbsd.so); endif(); else(); CHECK_CXX_SOURCE_COMPILES(""#include <sys/random.h>; int main() { char buf[32]; int res = getrandom(buf, 32, GRND_NONBLOCK); return 0;}"" found_getrandom); if(found_getrandom); message(STATUS ""Found getrandom in sys/random.h""); target_compile_definitions(Core PRIVATE R__GETRANDOM_CLIB); else(); CHECK_CXX_SOURCE_RUNS(""; #include <fstream>. int main() {; std::ifstream urandom{\""/dev/urandom\""};; if (!urandom) {; // This will make the CMake command fail; return 1;; }; ; constexpr int len{32};; char buf[len];; for (int n = 0; n < len; n++) buf[n] = 0;; urandom.read(buf, len);; ; int nmatch = 0;; for (int n = 0; n < len; n++); if (buf[n] == 0) nmatch++;; ; // Fail if no values have changed; return nmatch != len ? 0 : 1;; }"" found_urandom); if(found_urandom); message(STATUS ""Found random device in /dev/urandom""); target_compile_definitions(Core PRIVATE R__USE_URANDOM); else(); message(FATAL_ERROR ""Fail to detect cryptographic random generator""); endif(); endif(); endif(); endif(). ROOT_INSTALL_HEADERS(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/unix/CMakeLists.txt:2718,detect,detect,2718,core/unix/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/unix/CMakeLists.txt,1,['detect'],['detect']
Safety,"; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made GC parseable by wrapping the; call into a statepoint. This makes it possible to take a safepoint during; copy operation. Note that a GC parseable copy operation is not required to; take a safepoint. For example, a short copy operation may be performed without; taking a safepoint. GC parseable calls to '``llvm.memcpy.element.unordered.atomic.*``',; '``llvm.memmove.element.unordered.atomic.*``' intrinsics are lowered to calls; to '``__llvm_memcpy_element_unordered_atomic_safepoint_*``',; '``__llvm_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This requires the corresponding base; pointers to be available in the copy operation. In order to make the base; pointers available RewriteS",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:30134,safe,safepoint,30134,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['safe'],['safepoint']
Safety,"; }; uint32 : Padding (only if required to align to 8 byte); }. The first byte of each location encodes a type that indicates how to; interpret the ``RegNum`` and ``Offset`` fields as follows:. ======== ========== =================== ===========================; Encoding Type Value Description; -------- ---------- ------------------- ---------------------------; 0x1 Register Reg Value in a register; 0x2 Direct Reg + Offset Frame index value; 0x3 Indirect [Reg + Offset] Spilled value; 0x4 Constant Offset Small constant; 0x5 ConstIndex Constants[Offset] Large constant; ======== ========== =================== ===========================. In the common case, a value is available in a register, and the; ``Offset`` field will be zero. Values spilled to the stack are encoded; as ``Indirect`` locations. The runtime must load those values from a; stack address, typically in the form ``[BP + Offset]``. If an; ``alloca`` value is passed directly to a stack map intrinsic, then; LLVM may fold the frame index into the stack map as an optimization to; avoid allocating a register or stack slot. These frame indices will be; encoded as ``Direct`` locations in the form ``BP + Offset``. LLVM may; also optimize constants by emitting them directly in the stack map,; either in the ``Offset`` of a ``Constant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subregister information. Instead the runtime must interpret; this information conservatively. For example, if the stackmap reports; one byte at ``%r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:14128,avoid,avoid,14128,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['avoid'],['avoid']
Safety,"</style>. .. role:: none; .. role:: partial; .. role:: good. ==================; MSVC compatibility; ==================. When Clang compiles C++ code for Windows, it attempts to be compatible with; MSVC. There are multiple dimensions to compatibility. First, Clang attempts to be ABI-compatible, meaning that Clang-compiled code; should be able to link against MSVC-compiled code successfully. However, C++; ABIs are particularly large and complicated, and Clang's support for MSVC's C++; ABI is a work in progress. If you don't require MSVC ABI compatibility or don't; want to use Microsoft's C and C++ runtimes, the mingw32 toolchain might be a; better fit for your project. Second, Clang implements many MSVC language extensions, such as; ``__declspec(dllexport)`` and a handful of pragmas. These are typically; controlled by ``-fms-extensions``. Third, MSVC accepts some C++ code that Clang will typically diagnose as; invalid. When these constructs are present in widely included system headers,; Clang attempts to recover and continue compiling the user's program. Most; parsing and semantic compatibility tweaks are controlled by; ``-fms-compatibility`` and ``-fdelayed-template-parsing``, and they are a work; in progress. Finally, there is :ref:`clang-cl`, a driver program for clang that attempts to; be compatible with MSVC's cl.exe. ABI features; ============. The status of major ABI-impacting C++ features:. * Record layout: :good:`Complete`. We've tested this with a fuzzer and have; fixed all known bugs. * Class inheritance: :good:`Mostly complete`. This covers all of the standard; OO features you would expect: virtual method inheritance, multiple; inheritance, and virtual inheritance. Every so often we uncover a bug where; our tables are incompatible, but this is pretty well in hand. This feature; has also been fuzz tested. * Name mangling: :good:`Ongoing`. Every new C++ feature generally needs its own; mangling. For example, member pointer template arguments have an interes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MSVCCompatibility.rst:1174,recover,recover,1174,interpreter/llvm-project/clang/docs/MSVCCompatibility.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MSVCCompatibility.rst,1,['recover'],['recover']
Safety,"<https://github.com/llvm/llvm-project/issues/56035>`_).; - Clang constexpr evaluator now diagnoses compound assignment operators against; uninitialized variables as a read of uninitialized object.; (`#51536 <https://github.com/llvm/llvm-project/issues/51536>`_); - Clang's ``-Wformat-truncation`` now diagnoses ``snprintf`` call that is known to; result in string truncation.; (`#64871 <https://github.com/llvm/llvm-project/issues/64871>`_).; Existing warnings that similarly warn about the overflow in ``sprintf``; now falls under its own warning group ```-Wformat-overflow`` so that it can; be disabled separately from ``Wfortify-source``.; These two new warning groups have subgroups ``-Wformat-truncation-non-kprintf``; and ``-Wformat-overflow-non-kprintf``, respectively. These subgroups are used when; the format string contains ``%p`` format specifier.; Because Linux kernel's codebase has format extensions for ``%p``, kernel developers; are encouraged to disable these two subgroups by setting ``-Wno-format-truncation-non-kprintf``; and ``-Wno-format-overflow-non-kprintf`` in order to avoid false positives on; the kernel codebase.; Also clang no longer emits false positive warnings about the output length of; ``%g`` format specifier and about ``%o, %x, %X`` with ``#`` flag.; - Clang now emits ``-Wcast-qual`` for functional-style cast expressions.; - Clang no longer emits irrelevant notes about unsatisfied constraint expressions; on the left-hand side of ``||`` when the right-hand side constraint is satisfied.; (`#54678 <https://github.com/llvm/llvm-project/issues/54678>`_).; - Clang now prints its 'note' diagnostic in cyan instead of black, to be more compatible; with terminals with dark background colors. This is also more consistent with GCC.; - Clang now displays an improved diagnostic and a note when a defaulted special; member is marked ``constexpr`` in a class with a virtual base class; (`#64843 <https://github.com/llvm/llvm-project/issues/64843>`_).; - ``-Wfixed-enu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:24626,avoid,avoid,24626,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['avoid'],['avoid']
Safety,"<https://llvm.org/docs/CMake.html>`_. Usage; =====. Simply compile and link your program with ``-fsanitize=memory`` flag.; The MemorySanitizer run-time library should be linked to the final; executable, so make sure to use ``clang`` (not ``ld``) for the final; link step. When linking shared libraries, the MemorySanitizer run-time; is not linked, so ``-Wl,-z,defs`` may cause link errors (don't use it; with MemorySanitizer). To get a reasonable performance add ``-O1`` or; higher. To get meaningful stack traces in error messages add; ``-fno-omit-frame-pointer``. To get perfect stack traces you may need; to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat umr.cc; #include <stdio.h>. int main(int argc, char** argv) {; int* a = new int[10];; a[5] = 0;; if (a[argc]); printf(""xx\n"");; return 0;; }. % clang -fsanitize=memory -fno-omit-frame-pointer -g -O2 umr.cc. If a bug is detected, the program will print an error message to; stderr and exit with a non-zero exit code. .. code-block:: console. % ./a.out; WARNING: MemorySanitizer: use-of-uninitialized-value; #0 0x7f45944b418a in main umr.cc:6; #1 0x7f45938b676c in __libc_start_main libc-start.c:226. By default, MemorySanitizer exits on the first detected error. If you; find the error report hard to understand, try enabling; :ref:`origin tracking <msan-origins>`. ``__has_feature(memory_sanitizer)``; ------------------------------------. In some cases one may need to execute different code depending on; whether MemorySanitizer is enabled. :ref:`\_\_has\_feature; <langext-__has_feature-__has_extension>` can be used for this purpose. .. code-block:: c. #if defined(__has_feature); # if __has_feature(memory_sanitizer); // code that builds only under MemorySanitizer; # endif; #endif. ``__attribute__((no_sanitize(""memory"")))``; -----------------------------------------------. Some code should not be checked by MemorySanitizer. One may use the function; at",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MemorySanitizer.rst:1307,detect,detected,1307,interpreter/llvm-project/clang/docs/MemorySanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MemorySanitizer.rst,1,['detect'],['detected']
Safety,"= ""[8]"" \; source = ""Int_t *fArray; Int_t fN;"" \; target = ""fArray"" \; code = ""{ fArray = new Char_t[onfile.fN]; Char_t* gtc=fArray; Int_t* gti=onfile.fArray; \; for(Int_t i=0; i<onfile.fN; i++) *(gtc+i) = *(gti+i)+10; }""; #pragma read sourceClass = ""ACache"" targetClass = ""ACache"" version = ""[8]"" \; source = ""float fValues[3]"" \; target = ""fValues"" \; code = ""{ for(Int_t i=0; i<3; i++) fValues[i] = 1+onfile.fValues[i]; }"". Allow the seamless schema evolution from map<a,b> to vector<pair<a,b> >.; Avoid dropping information when reading a long written on a 64 bits platforms; and being read into a long long on a 32 bits platform (previously the higher; bits were lost due to passing through a 32 bits temporary long).; Migrate the functionality of TStreamerInfo::TagFile to a new interface TBuffer::TagStreamerInfo; so that TMessage can customize the behavior. TMessage now relies on this new interface; instead of TBuffer::IncrementLevel.; New option to hadd, -O requesting the (re)optimization of the basket size (by avoid the fast merge technique). The equivalent in TFileMerger is to call; merger->SetFastMethod(kFALSE); To make sure that the class emulation layer of ROOT does not double delete an object,; tell the StreamerElement representing one of the pointers pointing to the object; to never delete the object. For example:. TClass::AddRule(""HepMC::GenVertex m_event attributes=NotOwner"");. The handling of memory by the collection proxy has been improved in the case of a; collection of pointers which can now become owner of its content. The default, for backward compatibility reasons and to avoid double delete (at the expense; of memory leaks), the container of pointers are still not owning their content; unless they are a free standing container (i.e. itself not contained in another; object).; To make a container of pointers become owner of its content do something like:. TClass::AddRule(""ObjectVector<LHCb::MCRichDigitSummary> m_vector options=Owner"");. Added TKey::Reset ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:10957,avoid,avoid,10957,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,1,['avoid'],['avoid']
Safety,"= AP.getPointerSize();. // Put this in the data section.; OS.switchSection(AP.getObjFileLowering().getDataSection());. // For each function...; for (iterator FI = begin(), FE = end(); FI != FE; ++FI) {; GCFunctionInfo &MD = **FI;. // A compact GC layout. Emit this data structure:; //; // struct {; // int32_t PointCount;; // void *SafePointAddress[PointCount];; // int32_t StackFrameSize; // in words; // int32_t StackArity;; // int32_t LiveCount;; // int32_t LiveOffsets[LiveCount];; // } __gcmap_<FUNCTIONNAME>;. // Align to address width.; AP.emitAlignment(IntPtrSize == 4 ? 2 : 3);. // Emit PointCount.; OS.AddComment(""safe point count"");; AP.emitInt32(MD.size());. // And each safe point...; for (GCFunctionInfo::iterator PI = MD.begin(),; PE = MD.end(); PI != PE; ++PI) {; // Emit the address of the safe point.; OS.AddComment(""safe point address"");; MCSymbol *Label = PI->Label;; AP.emitLabelPlusOffset(Label/*Hi*/, 0/*Offset*/, 4/*Size*/);; }. // Stack information never change in safe points! Only print info from the; // first call-site.; GCFunctionInfo::iterator PI = MD.begin();. // Emit the stack frame size.; OS.AddComment(""stack frame size (in words)"");; AP.emitInt32(MD.getFrameSize() / IntPtrSize);. // Emit stack arity, i.e. the number of stacked arguments.; unsigned RegisteredArgs = IntPtrSize == 4 ? 5 : 6;; unsigned StackArity = MD.getFunction().arg_size() > RegisteredArgs ?; MD.getFunction().arg_size() - RegisteredArgs : 0;; OS.AddComment(""stack arity"");; AP.emitInt32(StackArity);. // Emit the number of live roots in the function.; OS.AddComment(""live root count"");; AP.emitInt32(MD.live_size(PI));. // And for each live root...; for (GCFunctionInfo::live_iterator LI = MD.live_begin(PI),; LE = MD.live_end(PI);; LI != LE; ++LI) {; // Emit live root's offset within the stack frame.; OS.AddComment(""stack index (offset / wordsize)"");; AP.emitInt32(LI->StackOffset);; }; }; }. References; ==========. .. _appel89:. [Appel89] Runtime Tags Aren't Necessary. Andrew W. Appel. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:38081,safe,safe,38081,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['safe'],['safe']
Safety,"= call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj, i8 addrspace(1)* %gep); %obj.relocated = call i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %token, i32 7, i32 7); %gep.relocated = call i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %token, i32 7, i32 8); %p = getelementptr i8, i8 addrspace(1)* %gep, i64 -20000; ret i8 addrspace(1)* %p; }. Note that in this example %p and %obj.relocate are the same address and we; could replace one with the other, potentially removing the derived pointer; from the live set at the safepoint entirely. .. _gc_transition_args:. GC Transitions; ^^^^^^^^^^^^^^^^^^. As a practical consideration, many garbage-collected systems allow code that is; collector-aware (""managed code"") to call code that is not collector-aware; (""unmanaged code""). It is common that such calls must also be safepoints, since; it is desirable to allow the collector to run during the execution of; unmanaged code. Furthermore, it is common that coordinating the transition from; managed to unmanaged code requires extra code generation at the call site to; inform the collector of the transition. In order to support these needs, a; statepoint may be marked as a GC transition, and data that is necessary to; perform the transition (if any) may be provided as additional arguments to the; statepoint. Note that although in many cases statepoints may be inferred to be GC; transitions based on the function symbols involved (e.g. a call from a; function with GC strategy ""foo"" to a function with GC strategy ""bar""),; indirect calls that are also GC transitions must also be supported. This; requirement is the driving force behind the decision to require that GC; transitions are explicitly marked. Let's revisit the sample given above, this time treating the call to ``@foo``; as a GC transition. Depending on our target, the transition co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:16499,safe,safepoints,16499,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['safe'],['safepoints']
Safety,"=0 or PSTATE.SM=1. The value of PSTATE.SM is not controlled by the feature flags, but rather by the; function attributes. This means that we can compile for '``+sme``' and the compiler; will code-generate any instructions, even if they are not legal under the requested; streaming mode. The compiler needs to use the function attributes to ensure the; compiler doesn't do transformations under the assumption that certain operations; are available at runtime. We made a conscious choice not to model this with feature flags, because we; still want to support inline-asm in either mode (with the user placing; smstart/smstop manually), and this became rather complicated to implement at the; individual instruction level (see `D120261 <https://reviews.llvm.org/D120261>`_; and `D121208 <https://reviews.llvm.org/D121208>`_) because of limitations in; TableGen. As a first step, this means we'll disable vectorization (LoopVectorize/SLP); entirely when the a function has either of the ``aarch64_pstate_sm_enabled``,; ``aarch64_pstate_sm_body`` or ``aarch64_pstate_sm_compatible`` attributes,; in order to avoid the use of vector instructions. Later on we'll aim to relax these restrictions to enable scalable; auto-vectorization with a subset of streaming-compatible instructions, but that; requires changes to the CostModel, Legalization and SelectionDAG lowering. We will also emit diagnostics in Clang to prevent the use of; non-streaming(-compatible) operations, e.g. through ACLE intrinsics, when a; function is decorated with the streaming mode attributes. Other things to consider; ------------------------. * Inlining must be disabled when the call-site needs to toggle PSTATE.SM or; when the callee's function body is executed in a different streaming mode than; its caller. This is needed because function calls are the boundaries for; streaming mode changes. * Tail call optimization must be disabled when the call-site needs to toggle; PSTATE.SM, such that the caller can restore the origi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst:15867,avoid,avoid,15867,interpreter/llvm-project/llvm/docs/AArch64SME.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst,1,['avoid'],['avoid']
Safety,"====. We use here the command-line, non-interactive CMake interface. #. `Download <http://www.cmake.org/cmake/resources/software.html>`_ and install; CMake. Version 3.20.0 is the minimum required. #. Open a shell. Your development tools must be reachable from this shell; through the PATH environment variable. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake will use default values; for all build parameters. See the `Options and variables`_ section for; a list of build parameters that you can modify. This can fail if CMake can't detect your toolset, or if it thinks that the; environment is not sane enough. In this case, make sure that the toolset that; you intend to use is the only one reachable from the shell, and that the shell; itself is the correct one for your development environment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the build directory:. .. code-block:: console. $ cmake --build . The ``--build`` option tells ``cmake`` to invoke the underlying build; tool (``make``, ``ninja``, ``xcodebuild``, ``msbuild``, etc.). The underlying build tool can be invoked directly, of course, but; the ``--bu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:2174,detect,detect,2174,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['detect'],['detect']
Safety,"========. :doc:`LLVM Language Reference Manual <LangRef>`; Defines the LLVM intermediate representation and the assembly form of the; different nodes. :doc:`InAlloca`; Description of the ``inalloca`` argument attribute. :doc:`BitCodeFormat`; This describes the file format and encoding used for LLVM ""bc"" files. :doc:`Machine IR (MIR) Format Reference Manual <MIRLangRef>`; A reference manual for the MIR serialization format, which is used to test; LLVM's code generation passes. :doc:`GlobalISel/index`; This describes the prototype instruction selection replacement, GlobalISel. :doc:`ConvergentOperations`; Description of ``convergent`` operation semantics and related intrinsics. =====================; Testing and Debugging; =====================. :doc:`LLVM Testing Infrastructure Guide <TestingGuide>`; A reference manual for using the LLVM testing infrastructure. :doc:`TestSuiteGuide`; Describes how to compile and run the test-suite benchmarks. :doc:`GwpAsan`; A sampled heap memory error detection toolkit designed for production use. ====; XRay; ====. :doc:`XRay`; High-level documentation of how to use XRay in LLVM. :doc:`XRayExample`; An example of how to debug an application with XRay. =================; Additional Topics; =================. :doc:`FaultMaps`; LLVM support for folding control flow into faulting machine instructions. :doc:`Atomics`; Information about LLVM's concurrency model. :doc:`ExceptionHandling`; This document describes the design and implementation of exception handling; in LLVM. :doc:`Extensions`; LLVM-specific extensions to tools and formats LLVM seeks compatibility with. :doc:`HowToSetUpLLVMStyleRTTI`; How to make ``isa<>``, ``dyn_cast<>``, etc. available for clients of your; class hierarchy. :doc:`BlockFrequencyTerminology`; Provides information about terminology used in the ``BlockFrequencyInfo``; analysis pass. :doc:`BranchWeightMetadata`; Provides information about Branch Prediction Information. :doc:`GetElementPtr`; Answers to some very fr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Reference.rst:3211,detect,detection,3211,interpreter/llvm-project/llvm/docs/Reference.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Reference.rst,1,['detect'],['detection']
Safety,"=========. SafeStack is an instrumentation pass that protects programs against attacks; based on stack buffer overflows, without introducing any measurable performance; overhead. It works by separating the program stack into two distinct regions:; the safe stack and the unsafe stack. The safe stack stores return addresses,; register spills, and local variables that are always accessed in a safe way,; while the unsafe stack stores everything else. This separation ensures that; buffer overflows on the unsafe stack cannot be used to overwrite anything; on the safe stack. SafeStack is a part of the `Code-Pointer Integrity (CPI) Project; <https://dslab.epfl.ch/research/cpi/>`_. Performance; -----------. The performance overhead of the SafeStack instrumentation is less than 0.1% on; average across a variety of benchmarks (see the `Code-Pointer Integrity; <https://dslab.epfl.ch/pubs/cpi.pdf>`__ paper for details). This is mainly; because most small functions do not have any variables that require the unsafe; stack and, hence, do not need unsafe stack frames to be created. The cost of; creating unsafe stack frames for large functions is amortized by the cost of; executing the function. In some cases, SafeStack actually improves the performance. Objects that end up; being moved to the unsafe stack are usually large arrays or variables that are; used through multiple stack frames. Moving such objects away from the safe; stack increases the locality of frequently accessed values on the stack, such; as register spills, return addresses, and small local variables. Compatibility; -------------. Most programs, static libraries, or individual files can be compiled; with SafeStack as is. SafeStack requires basic runtime support, which, on most; platforms, is implemented as a compiler-rt library that is automatically linked; in when the program is compiled with SafeStack. Linking a DSO with SafeStack is not currently supported. Known compatibility limitations; ~~~~~~~~~~~~~~~~~~~~~~~~",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst:1083,unsafe,unsafe,1083,interpreter/llvm-project/clang/docs/SafeStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst,2,['unsafe'],['unsafe']
Safety,"=========; SafeStack; =========. .. contents::; :local:. Introduction; ============. SafeStack is an instrumentation pass that protects programs against attacks; based on stack buffer overflows, without introducing any measurable performance; overhead. It works by separating the program stack into two distinct regions:; the safe stack and the unsafe stack. The safe stack stores return addresses,; register spills, and local variables that are always accessed in a safe way,; while the unsafe stack stores everything else. This separation ensures that; buffer overflows on the unsafe stack cannot be used to overwrite anything; on the safe stack. SafeStack is a part of the `Code-Pointer Integrity (CPI) Project; <https://dslab.epfl.ch/research/cpi/>`_. Performance; -----------. The performance overhead of the SafeStack instrumentation is less than 0.1% on; average across a variety of benchmarks (see the `Code-Pointer Integrity; <https://dslab.epfl.ch/pubs/cpi.pdf>`__ paper for details). This is mainly; because most small functions do not have any variables that require the unsafe; stack and, hence, do not need unsafe stack frames to be created. The cost of; creating unsafe stack frames for large functions is amortized by the cost of; executing the function. In some cases, SafeStack actually improves the performance. Objects that end up; being moved to the unsafe stack are usually large arrays or variables that are; used through multiple stack frames. Moving such objects away from the safe; stack increases the locality of frequently accessed values on the stack, such; as register spills, return addresses, and small local variables. Compatibility; -------------. Most programs, static libraries, or individual files can be compiled; with SafeStack as is. SafeStack requires basic runtime support, which, on most; platforms, is implemented as a compiler-rt library that is automatically linked; in when the program is compiled with SafeStack. Linking a DSO with SafeStack is not curr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst:326,safe,safe,326,interpreter/llvm-project/clang/docs/SafeStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst,7,"['safe', 'unsafe']","['safe', 'unsafe']"
Safety,"==========. **EXPERIMENTAL**. The basic CFI mode described above assumes that the application is a; monolithic binary; at least that all possible virtual/indirect call; targets and the entire class hierarchy are known at link time. The; cross-DSO mode, enabled with **-f[no-]sanitize-cfi-cross-dso** relaxes; this requirement by allowing virtual and indirect calls to cross the; DSO boundary. Assuming the following setup: the binary consists of several; instrumented and several uninstrumented DSOs. Some of them may be; dlopen-ed/dlclose-d periodically, even frequently. - Calls made from uninstrumented DSOs are not checked and just work.; - Calls inside any instrumented DSO are fully protected.; - Calls between different instrumented DSOs are also protected, with; a performance penalty (in addition to the monolithic CFI; overhead).; - Calls from an instrumented DSO to an uninstrumented one are; unchecked and just work, with performance penalty.; - Calls from an instrumented DSO outside of any known DSO are; detected as CFI violations. In the monolithic scheme a call site is instrumented as. .. code-block:: none. if (!InlinedFastCheck(f)); abort();; call *f. In the cross-DSO scheme it becomes. .. code-block:: none. if (!InlinedFastCheck(f)); __cfi_slowpath(CallSiteTypeId, f);; call *f. CallSiteTypeId; --------------. ``CallSiteTypeId`` is a stable process-wide identifier of the; call-site type. For a virtual call site, the type in question is the class; type; for an indirect function call it is the function signature. The; mapping from a type to an identifier is an ABI detail. In the current,; experimental, implementation the identifier of type T is calculated as; follows:. - Obtain the mangled name for ""typeinfo name for T"".; - Calculate MD5 hash of the name as a string.; - Reinterpret the first 8 bytes of the hash as a little-endian; 64-bit integer. It is possible, but unlikely, that collisions in the; ``CallSiteTypeId`` hashing will result in weaker CFI checks that wo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:19666,detect,detected,19666,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['detect'],['detected']
Safety,"===========. Introduction; ============. This document contains information about adding a build configuration and; buildbot-worker to private worker builder to LLVM Buildbot Infrastructure. Buildmasters; ============. There are two buildmasters running. * The main buildmaster at `<https://lab.llvm.org/buildbot>`_. All builders; attached to this machine will notify commit authors every time they break; the build.; * The staging buildmaster at `<https://lab.llvm.org/staging>`_. All builders; attached to this machine will be completely silent by default when the build; is broken. This buildmaster is reconfigured every two hours with any new; commits from the llvm-zorg repository. In order to remain connected to the main buildmaster (and thus notify; developers of failures), a builbot must:. * Be building a supported configuration. Builders for experimental backends; should generally be attached to staging buildmaster.; * Be able to keep up with new commits to the main branch, or at a minimum; recover to tip of tree within a couple of days of falling behind. Additionally, we encourage all bot owners to point their bots towards the; staging master during maintenance windows, instability troubleshooting, and; such. Roles & Expectations; ====================. Each buildbot has an owner who is the responsible party for addressing problems; which arise with said buildbot. We generally expect the bot owner to be; reasonably responsive. For some bots, the ownership responsibility is split between a ""resource owner""; who provides the underlying machine resource, and a ""configuration owner"" who; maintains the build configuration. Generally, operational responsibility lies; with the ""config owner"". We do expect ""resource owners"" - who are generally; the contact listed in a workers attributes - to proxy requests to the relevant; ""config owner"" in a timely manner. Most issues with a buildbot should be addressed directly with a bot owner; via email. Please CC `Galina Kistanova <mai",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:1200,recover,recover,1200,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['recover'],['recover']
Safety,"============. Some attributes describe code transformations (unrolling, vectorizing,; loop distribution, etc.). They can either be a hint to the optimizer; that a transformation might be beneficial, instruction to use a specific; option, , or convey a specific request from the user (such as; ``#pragma clang loop`` or ``#pragma omp simd``). If a transformation is forced but cannot be carried-out for any reason,; an optimization-missed warning must be emitted. Semantic information; such as a transformation being safe (e.g.; ``llvm.mem.parallel_loop_access``) can be unused by the optimizer; without generating a warning. Unless explicitly disabled, any optimization pass may heuristically; determine whether a transformation is beneficial and apply it. If; metadata for another transformation was specified, applying a different; transformation before it might be inadvertent due to being applied on a; different loop or the loop not existing anymore. To avoid having to; explicitly disable an unknown number of passes, the attribute; ``llvm.loop.disable_nonforced`` disables all optional, high-level,; restructuring transformations. The following example avoids the loop being altered before being; vectorized, for instance being unrolled. .. code-block:: llvm. br i1 %exitcond, label %for.exit, label %for.header, !llvm.loop !0; ...; !0 = distinct !{!0, !1, !2}; !1 = !{!""llvm.loop.vectorize.enable"", i1 true}; !2 = !{!""llvm.loop.disable_nonforced""}. After a transformation is applied, follow-up attributes are set on the; transformed and/or new loop(s). This allows additional attributes; including followup-transformations to be specified. Specifying multiple; transformations in the same metadata node is possible for compatibility; reasons, but their execution order is undefined. For instance, when; ``llvm.loop.vectorize.enable`` and ``llvm.loop.unroll.enable`` are; specified at the same time, unrolling may occur either before or after; vectorization. As an example, the following instru",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:3104,avoid,avoid,3104,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst,1,['avoid'],['avoid']
Safety,"===============. Introduction; ============. For benchmarking a patch we want to reduce all possible sources of; noise as much as possible. How to do that is very OS dependent. Note that low noise is required, but not sufficient. It does not; exclude measurement bias. See; https://www.cis.upenn.edu/~cis501/papers/producing-wrong-data.pdf for; example. General; ================================. * Use a high resolution timer, e.g. perf under linux. * Run the benchmark multiple times to be able to recognize noise. * Disable as many processes or services as possible on the target system. * Disable frequency scaling, turbo boost and address space; randomization (see OS specific section). * Static link if the OS supports it. That avoids any variation that; might be introduced by loading dynamic libraries. This can be done; by passing ``-DLLVM_BUILD_STATIC=ON`` to cmake. * Try to avoid storage. On some systems you can use tmpfs. Putting the; program, inputs and outputs on tmpfs avoids touching a real storage; system, which can have a pretty big variability. To mount it (on linux and freebsd at least)::. mount -t tmpfs -o size=<XX>g none dir_to_mount. Linux; =====. * Disable address space randomization::. echo 0 > /proc/sys/kernel/randomize_va_space. * Set scaling_governor to performance::. for i in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do; echo performance > /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; done. * Use https://github.com/lpechacek/cpuset to reserve cpus for just the; program you are benchmarking. If using perf, leave at least 2 cores; so that perf runs in one and your program in another::. cset shield -c N1,N2 -k on. This will move all threads out of N1 and N2. The ``-k on`` means; that even kernel threads are moved out. * Disable the SMT pair of the cpus you will use for the benchmark. The; pair of cpu N can be found in; ``/sys/devices/system/cpu/cpuN/topology/thread_siblings_list`` and; disabled with::. echo 0 > /sys/devices/system/c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Benchmarking.rst:1060,avoid,avoids,1060,interpreter/llvm-project/llvm/docs/Benchmarking.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Benchmarking.rst,1,['avoid'],['avoids']
Safety,"================; AddressSanitizer; ================. .. contents::; :local:. Introduction; ============. AddressSanitizer is a fast memory error detector. It consists of a compiler; instrumentation module and a run-time library. The tool can detect the; following types of bugs:. * Out-of-bounds accesses to heap, stack and globals; * Use-after-free; * Use-after-return (clang flag ``-fsanitize-address-use-after-return=(never|runtime|always)`` default: ``runtime``); * Enable with: ``ASAN_OPTIONS=detect_stack_use_after_return=1`` (already enabled on Linux).; * Disable with: ``ASAN_OPTIONS=detect_stack_use_after_return=0``.; * Use-after-scope (clang flag ``-fsanitize-address-use-after-scope``); * Double-free, invalid free; * Memory leaks (experimental). Typical slowdown introduced by AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:146,detect,detector,146,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,2,['detect'],"['detect', 'detector']"
Safety,"================; LeakSanitizer; ================. .. contents::; :local:. Introduction; ============. LeakSanitizer is a run-time memory leak detector. It can be combined with; :doc:`AddressSanitizer` to get both memory error and leak detection, or; used in a stand-alone mode. LSan adds almost no performance overhead; until the very end of the process, at which point there is an extra leak; detection phase. Usage; =====. :doc:`AddressSanitizer`: integrates LeakSanitizer and enables it by default on; supported platforms. .. code-block:: console. $ cat memory-leak.c; #include <stdlib.h>; void *p;; int main() {; p = malloc(7);; p = 0; // The memory is leaked here.; return 0;; }; % clang -fsanitize=address -g memory-leak.c ; ASAN_OPTIONS=detect_leaks=1 ./a.out; ==23646==ERROR: LeakSanitizer: detected memory leaks; Direct leak of 7 byte(s) in 1 object(s) allocated from:; #0 0x4af01b in __interceptor_malloc /projects/compiler-rt/lib/asan/asan_malloc_linux.cc:52:3; #1 0x4da26a in main memory-leak.c:4:7; #2 0x7f076fd9cec4 in __libc_start_main libc-start.c:287; SUMMARY: AddressSanitizer: 7 byte(s) leaked in 1 allocation(s). To use LeakSanitizer in stand-alone mode, link your program with; ``-fsanitize=leak`` flag. Make sure to use ``clang`` (not ``ld``) for the; link step, so that it would link in proper LeakSanitizer run-time library; into the final executable. Supported Platforms; ===================. * Android aarch64/i386/x86_64; * Fuchsia aarch64/x86_64; * Linux arm/aarch64/mips64/ppc64/ppc64le/riscv64/s390x/i386/x86\_64; * macOS aarch64/i386/x86\_64; * NetBSD i386/x86_64. More Information; ================. `<https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer>`_; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LeakSanitizer.rst:143,detect,detector,143,interpreter/llvm-project/clang/docs/LeakSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LeakSanitizer.rst,4,['detect'],"['detected', 'detection', 'detector']"
Safety,"================; MemTagSanitizer; ================. .. contents::; :local:. Introduction; ============. **Note:** this page describes a tool under development. Part of this; functionality is planned but not implemented. Hardware capable of; running MemTagSanitizer does not exist as of Oct 2019. MemTagSanitizer is a fast memory error detector and **a code hardening; tool** based on the Armv8.5-A `Memory Tagging Extension`_. It; detects a similar class of errors as `AddressSanitizer`_ or `HardwareAssistedAddressSanitizer`_, but with; **much** lower overhead. MemTagSanitizer overhead is expected to be in low single digits, both; CPU and memory. There are plans for a debug mode with slightly higher; memory overhead and better diagnostics. The primary use case of; MemTagSanitizer is code hardening in production binaries, where it is; expected to be a strong mitigation for both stack and heap-based; memory bugs. Usage; =====. Compile and link your program with ``-fsanitize=memtag`` flag. This; will only work when targeting AArch64 with MemTag extension. One; possible way to achieve that is to add ``-target; aarch64-linux -march=armv8+memtag`` to compilation flags. Implementation; ==============. See `HardwareAssistedAddressSanitizer`_ for a general overview of a; tag-based approach to memory safety. MemTagSanitizer follows a; similar implementation strategy, but with the tag storage (shadow); provided by the hardware. A quick overview of MTE hardware capabilities:. * Every 16 aligned bytes of memory can be assigned a 4-bit Allocation Tag.; * Every pointer can have a 4-bit Address Tag that is in its most significant byte.; * Most memory access instructions generate an exception if Address Tag != Allocation Tag.; * Special instructions are provided for fast tag manipulation. Stack instrumentation; =====================. Stack-based memory errors are detected by updating Allocation Tag for; each local variable to a random value at the start of its lifetime,; and resetting it",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemTagSanitizer.rst:336,detect,detector,336,interpreter/llvm-project/llvm/docs/MemTagSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemTagSanitizer.rst,2,['detect'],"['detector', 'detects']"
Safety,"================; MemorySanitizer; ================. .. contents::; :local:. Introduction; ============. MemorySanitizer is a detector of uninitialized reads. It consists of a; compiler instrumentation module and a run-time library. Typical slowdown introduced by MemorySanitizer is **3x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>`_. Usage; =====. Simply compile and link your program with ``-fsanitize=memory`` flag.; The MemorySanitizer run-time library should be linked to the final; executable, so make sure to use ``clang`` (not ``ld``) for the final; link step. When linking shared libraries, the MemorySanitizer run-time; is not linked, so ``-Wl,-z,defs`` may cause link errors (don't use it; with MemorySanitizer). To get a reasonable performance add ``-O1`` or; higher. To get meaningful stack traces in error messages add; ``-fno-omit-frame-pointer``. To get perfect stack traces you may need; to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat umr.cc; #include <stdio.h>. int main(int argc, char** argv) {; int* a = new int[10];; a[5] = 0;; if (a[argc]); printf(""xx\n"");; return 0;; }. % clang -fsanitize=memory -fno-omit-frame-pointer -g -O2 umr.cc. If a bug is detected, the program will print an error message to; stderr and exit with a non-zero exit code. .. code-block:: console. % ./a.out; WARNING: MemorySanitizer: use-of-uninitialized-value; #0 0x7f45944b418a in main umr.cc:6; #1 0x7f45938b676c in __libc_start_main libc-start.c:226. By default, MemorySanitizer exits on the first detected error. If you; find the error report hard to understand, try enabling; :ref:`origin tracking <msan-origins>`. ``__has_feature(memory_sanitizer)``; ------------------------------------. In some cases one may need to execute different code depending on; whether MemorySanitizer is enabled. :ref:`\_\_has\_feature; <langext-__has_feature-__has_extension>` can b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MemorySanitizer.rst:126,detect,detector,126,interpreter/llvm-project/clang/docs/MemorySanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MemorySanitizer.rst,1,['detect'],['detector']
Safety,"=================; DataFlowSanitizer; =================. .. toctree::; :hidden:. DataFlowSanitizerDesign. .. contents::; :local:. Introduction; ============. DataFlowSanitizer is a generalised dynamic data flow analysis. Unlike other Sanitizer tools, this tool is not designed to detect a; specific class of bugs on its own. Instead, it provides a generic; dynamic data flow analysis framework to be used by clients to help; detect application-specific issues within their own code. How to build libc++ with DFSan; ==============================. DFSan requires either all of your code to be instrumented or for uninstrumented; functions to be listed as ``uninstrumented`` in the `ABI list`_. If you'd like to have instrumented libc++ functions, then you need to build it; with DFSan instrumentation from source. Here is an example of how to build; libc++ and the libc++ ABI with data flow sanitizer instrumentation. .. code-block:: console. mkdir libcxx-build; cd libcxx-build. # An example using ninja; cmake -GNinja -S <monorepo-root>/runtimes \; -DCMAKE_C_COMPILER=clang \; -DCMAKE_CXX_COMPILER=clang++ \; -DLLVM_USE_SANITIZER=""DataFlow"" \; -DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi"". ninja cxx cxxabi. Note: Ensure you are building with a sufficiently new version of Clang. Usage; =====. With no program changes, applying DataFlowSanitizer to a program; will not alter its behavior. To use DataFlowSanitizer, the program; uses API functions to apply tags to data to cause it to be tracked, and to; check the tag of a specific data item. DataFlowSanitizer manages; the propagation of tags through the program according to its data flow. The APIs are defined in the header file ``sanitizer/dfsan_interface.h``.; For further information about each function, please refer to the header; file. .. _ABI list:. ABI List; --------. DataFlowSanitizer uses a list of functions known as an ABI list to decide; whether a call to a specific function should use the operating system's native; ABI or whether it ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst:280,detect,detect,280,interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst,2,['detect'],['detect']
Safety,"==================; Vectorization Plan; ==================. .. contents::; :local:. Abstract; ========; The vectorization transformation can be rather complicated, involving several; potential alternatives, especially for outer-loops [1]_ but also possibly for; innermost loops. These alternatives may have significant performance impact,; both positive and negative. A cost model is therefore employed to identify the; best alternative, including the alternative of avoiding any transformation; altogether. The Vectorization Plan is an explicit model for describing vectorization; candidates. It serves for both optimizing candidates including estimating their; cost reliably, and for performing their final translation into IR. This; facilitates dealing with multiple vectorization candidates. High-level Design; =================. Vectorization Workflow; ----------------------; VPlan-based vectorization involves three major steps, taking a ""scenario-based; approach"" to vectorization planning:. 1. Legal Step: check if a loop can be legally vectorized; encode constraints and; artifacts if so.; 2. Plan Step:. a. Build initial VPlans following the constraints and decisions taken by; Legal Step 1, and compute their cost.; b. Apply optimizations to the VPlans, possibly forking additional VPlans.; Prune sub-optimal VPlans having relatively high cost.; 3. Execute Step: materialize the best VPlan. Note that this is the only step; that modifies the IR. Design Guidelines; -----------------; In what follows, the term ""input IR"" refers to code that is fed into the; vectorizer whereas the term ""output IR"" refers to code that is generated by the; vectorizer. The output IR contains code that has been vectorized or ""widened""; according to a loop Vectorization Factor (VF), and/or loop unroll-and-jammed; according to an Unroll Factor (UF).; The design of VPlan follows several high-level guidelines:. 1. Analysis-like: building and manipulating VPlans must not modify the input IR.; In particular,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:467,avoid,avoiding,467,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,1,['avoid'],['avoiding']
Safety,"===================; Misexpect; ===================; .. contents::. .. toctree::; :maxdepth: 1. When developers use ``llvm.expect`` intrinsics, i.e., through use of; ``__builtin_expect(...)``, they are trying to communicate how their code is; expected to behave at runtime to the optimizer. These annotations, however, can; be incorrect for a variety of reasons: changes to the code base invalidate them; silently, the developer mis-annotated them (e.g., using ``LIKELY`` instead of; ``UNLIKELY``), or perhaps they assumed something incorrectly when they wrote; the annotation. Regardless of why, it is useful to detect these situations so; that the optimizer can make more useful decisions about the code. MisExpect diagnostics are intended to help developers identify and address; these situations, by comparing the branch weights added by the ``llvm.expect``; intrinsic to those collected through profiling. Whenever these values are; mismatched, a diagnostic is surfaced to the user. Details on how the checks; operate in the LLVM backed can be found in LLVM's documentation. By default MisExpect checking is quite strict, because the use of the; ``llvm.expect`` intrinsic is designed for specialized cases, where the outcome; of a condition is severely skewed. As a result, the optimizer can be extremely; aggressive, which can result in performance degradation if the outcome is less; predictable than the annotation suggests. Even when the annotation is correct; 90% of the time, it may be beneficial to either remove the annotation or to use; a different intrinsic that can communicate the probability more directly. Because this may be too strict, MisExpect diagnostics are not enabled by; default, and support an additional flag to tolerate some deviation from the; exact thresholds. The ``-fdiagnostic-misexpect-tolerance=N`` accepts; deviations when comparing branch weights within ``N%`` of the expected values.; So passing ``-fdiagnostic-misexpect-tolerance=5`` will not report diagnosti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MisExpect.rst:613,detect,detect,613,interpreter/llvm-project/clang/docs/MisExpect.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MisExpect.rst,1,['detect'],['detect']
Safety,"===================; Misexpect; ===================; .. contents::. .. toctree::; :maxdepth: 1. When developers use ``llvm.expect`` intrinsics, i.e., through use of; ``__builtin_expect(...)``, they are trying to communicate how their code is; expected to behave at runtime to the optimizer. These annotations, however, can; be incorrect for a variety of reasons: changes to the code base invalidate them; silently, the developer mis-annotated them (e.g., using ``LIKELY`` instead of; ``UNLIKELY``), or perhaps they assumed something incorrectly when they wrote; the annotation. Regardless of why, it is useful to detect these situations so; that the optimizer can make more useful decisions about the code. MisExpect; diagnostics are intended to help developers identify and address these; situations, by comparing the use of the ``llvm.expect`` intrinsic to the ground; truth provided by a profiling input. The MisExpect checks in the LLVM backend follow a simple procedure: if there is; a mismatch between the branch weights collected during profiling and those; supplied by an ``llvm.expect`` intrinsic, then it will emit a diagnostic; message to the user. The most natural place to perform the verification is just prior to when; branch weights are assigned to the target instruction in the form of; branch weight metadata. There are 3 key places in the LLVM backend where branch weights are; created and assigned based on profiling information or the use of the; ``llvm.expect`` intrinsic, and our implementation focuses on these; places to perform the verification. We calculate the threshold for emitting MisExpect related diagnostics; based on the values the compiler assigns to ``llvm.expect`` intrinsics,; which can be set through the ``-likely-branch-weight`` and; ``-unlikely-branch-weight`` LLVM options. During verification, if the; profile weights mismatch the calculated threshold, then we will emit a; remark or warning detailing a potential performance regression. The; diagnostic al",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MisExpect.rst:613,detect,detect,613,interpreter/llvm-project/llvm/docs/MisExpect.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MisExpect.rst,1,['detect'],['detect']
Safety,"====================; Objective-C Literals; ====================. Introduction; ============. Three new features were introduced into clang at the same time:; *NSNumber Literals* provide a syntax for creating ``NSNumber`` from; scalar literal expressions; *Collection Literals* provide a short-hand; for creating arrays and dictionaries; *Object Subscripting* provides a; way to use subscripting with Objective-C objects. Users of Apple; compiler releases can use these features starting with the Apple LLVM; Compiler 4.0. Users of open-source LLVM.org compiler releases can use; these features starting with clang v3.1. These language additions simplify common Objective-C programming; patterns, make programs more concise, and improve the safety of; container creation. This document describes how the features are implemented in clang, and; how to use them in your own programs. NSNumber Literals; =================. The framework class ``NSNumber`` is used to wrap scalar values inside; objects: signed and unsigned integers (``char``, ``short``, ``int``,; ``long``, ``long long``), floating point numbers (``float``,; ``double``), and boolean values (``BOOL``, C++ ``bool``). Scalar values; wrapped in objects are also known as *boxed* values. In Objective-C, any character, numeric or boolean literal prefixed with; the ``'@'`` character will evaluate to a pointer to an ``NSNumber``; object initialized with that value. C's type suffixes may be used to; control the size of numeric literals. Examples; --------. The following program illustrates the rules for ``NSNumber`` literals:. .. code-block:: objc. void main(int argc, const char *argv[]) {; // character literals.; NSNumber *theLetterZ = @'Z'; // equivalent to [NSNumber numberWithChar:'Z']. // integral literals.; NSNumber *fortyTwo = @42; // equivalent to [NSNumber numberWithInt:42]; NSNumber *fortyTwoUnsigned = @42U; // equivalent to [NSNumber numberWithUnsignedInt:42U]; NSNumber *fortyTwoLong = @42L; // equivalent to [NSNumber n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst:741,safe,safety,741,interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst,1,['safe'],['safety']
Safety,"=====================. A program is in Loop Closed SSA Form if it is in SSA form; and all values that are defined in a loop are used only inside; this loop. Programs written in LLVM IR are always in SSA form but not necessarily; in LCSSA. To achieve the latter, for each value that is live across the; loop boundary, single entry PHI nodes are inserted to each of the exit blocks; [#lcssa-construction]_ in order to ""close"" these values inside the loop.; In particular, consider the following loop:. .. code-block:: C. c = ...;; for (...) {; if (c); X1 = ...; else; X2 = ...; X3 = phi(X1, X2); // X3 defined; }. ... = X3 + 4; // X3 used, i.e. live; // outside the loop. In the inner loop, the X3 is defined inside the loop, but used; outside of it. In Loop Closed SSA form, this would be represented as follows:. .. code-block:: C. c = ...;; for (...) {; if (c); X1 = ...; else; X2 = ...; X3 = phi(X1, X2);; }; X4 = phi(X3);. ... = X4 + 4;. This is still valid LLVM; the extra phi nodes are purely redundant,; but all LoopPass'es are required to preserve them.; This form is ensured by the LCSSA (:ref:`-lcssa <passes-lcssa>`); pass and is added automatically by the LoopPassManager when; scheduling a LoopPass.; After the loop optimizations are done, these extra phi nodes; will be deleted by :ref:`-instcombine <passes-instcombine>`. Note that an exit block is outside of a loop, so how can such a phi ""close""; the value inside the loop since it uses it outside of it ? First of all,; for phi nodes, as; `mentioned in the LangRef <https://llvm.org/docs/LangRef.html#id311>`_:; ""the use of each incoming value is deemed to occur on the edge from the; corresponding predecessor block to the current block"". Now, an; edge to an exit block is considered outside of the loop because; if we take that edge, it leads us clearly out of the loop. However, an edge doesn't actually contain any IR, so in source code,; we have to choose a convention of whether the use happens in; the current block or in the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:11713,redund,redundant,11713,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,1,['redund'],['redundant']
Safety,"=====================; Test-Suite Extensions; =====================. .. contents::; :depth: 1; :local:. Abstract; ========. These are ideas for additional programs, benchmarks, applications and; algorithms that could be added to the LLVM Test-Suite.; The test-suite could be much larger than it is now, which would help us; detecting compiler errors (crashes, miscompiles) during development. Most probably, the reason why the programs below have not been added to; the test-suite yet is that nobody has found time to do it. But there; might be other issues as well, such as. * Licensing (Support can still be added as external module,; like for the SPEC benchmarks). * Language (in particular, there is no official LLVM frontend; for FORTRAN yet). * Parallelism (currently, all programs in test-suite use; one thread only). Benchmarks; ==========. SPEC CPU 2017; -------------; https://www.spec.org/cpu2017/. The following have not been included yet because they contain Fortran; code. In case of cactuBSSN only a small portion is Fortran. The hosts's; Fortran compiler could be used for these parts. Note that CMake's Ninja generator has difficulties with Fortran. See the; `CMake documentation <https://cmake.org/cmake/help/v3.13/generator/Ninja.html#fortran-support>`_; for details. * 503.bwaves_r/603.bwaves_s; * 507.cactuBSSN_r; * 521.wrf_r/621.wrf_s; * 527.cam4_r/627.cam4_s; * 628.pop2_s; * 548.exchange2_r/648.exchange2_s; * 549.fotonik3d_r/649.fotonik3d_s; * 554.roms_r/654.roms_s. SPEC OMP2012; ------------; https://www.spec.org/omp2012/. * 350.md; * 351.bwaves; * 352.nab; * 357.bt331; * 358.botsalgn; * 359.botsspar; * 360.ilbdc; * 362.fma3d; * 363.swim; * 367.imagick; * 370.mgrid331; * 371.applu331; * 372.smithwa; * 376.kdtree. OpenCV; ------; https://opencv.org/. OpenMP 4.x SIMD Benchmarks; --------------------------; https://github.com/flwende/simd_benchmarks. PWM-benchmarking; ----------------; https://github.com/tbepler/PWM-benchmarking. SLAMBench; ---------; https://github.c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:324,detect,detecting,324,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,1,['detect'],['detecting']
Safety,"======================; Control Flow Integrity; ======================. .. toctree::; :hidden:. ControlFlowIntegrityDesign. .. contents::; :local:. Introduction; ============. Clang includes an implementation of a number of control flow integrity (CFI); schemes, which are designed to abort the program upon detecting certain forms; of undefined behavior that can potentially allow attackers to subvert the; program's control flow. These schemes have been optimized for performance,; allowing developers to enable them in release builds. To enable Clang's available CFI schemes, use the flag ``-fsanitize=cfi``.; You can also enable a subset of available :ref:`schemes <cfi-schemes>`.; As currently implemented, all schemes rely on link-time optimization (LTO);; so it is required to specify ``-flto``, and the linker used must support LTO,; for example via the `gold plugin`_. To allow the checks to be implemented efficiently, the program must; be structured such that certain object files are compiled with CFI; enabled, and are statically linked into the program. This may preclude; the use of shared libraries in some cases. The compiler will only produce CFI checks for a class if it can infer hidden; LTO visibility for that class. LTO visibility is a property of a class that; is inferred from flags and attributes. For more details, see the documentation; for :doc:`LTO visibility <LTOVisibility>`. The ``-fsanitize=cfi-{vcall,nvcall,derived-cast,unrelated-cast}`` flags; require that a ``-fvisibility=`` flag also be specified. This is because the; default visibility setting is ``-fvisibility=default``, which would disable; CFI checks for classes without visibility attributes. Most users will want; to specify ``-fvisibility=hidden``, which enables CFI checks for such classes. Experimental support for :ref:`cross-DSO control flow integrity; <cfi-cross-dso>` exists that does not require classes to have hidden LTO; visibility. This cross-DSO support has unstable ABI at this time. .. _g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst:285,abort,abort,285,interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst,2,"['abort', 'detect']","['abort', 'detecting']"
Safety,"=======================; LLVM Common CMake Utils; =======================. What goes here; --------------. These are CMake modules to be shared between LLVM projects strictly at build; time. In other words, they must not be included from an installed CMake module,; such as the ``Add*.cmake`` ones. Modules that are reachable from installed; modules should instead go in ``${project}/cmake/modules`` of the most upstream; project that uses them. The advantage of not putting these modules in an existing location like; ``llvm/cmake/modules`` is two-fold:. - Since they are not installed, we don't have to worry about any out-of-tree; downstream usage, and thus there is no need for stability. - Since they are available as part of the source at build-time, we don't have; to do the usual stand-alone vs combined-build dances, avoiding much; complexity. How to use; ----------. For tools, please do:. .. code-block:: cmake. if(NOT DEFINED LLVM_COMMON_CMAKE_UTILS); set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake); endif(). # Add path for custom modules.; list(INSERT CMAKE_MODULE_PATH 0; # project-specific module dirs first; ""${LLVM_COMMON_CMAKE_UTILS}/Modules""; ). Notes:. - The ``if(NOT DEFINED ...)`` guard is there because in combined builds, LLVM; will set this variable. This is useful for legacy builds where projects are; found in ``llvm/tools`` instead. - ``INSERT ... 0`` ensures these new entries are prepended to the front of the; module path, so nothing might shadow them by mistake. For runtime libs, we skip the ``if(NOT DEFINED`` part:. .. code-block:: cmake. set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake). ... # same as before. If ``llvm/tools`` legacy-style combined builds are deprecated, we should then; skip it everywhere, bringing the tools and runtimes boilerplate back in line.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst:826,avoid,avoiding,826,interpreter/llvm-project/cmake/README.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst,1,['avoid'],['avoiding']
Safety,"=========================; Compiling CUDA with clang; =========================. .. contents::; :local:. Introduction; ============. This document describes how to compile CUDA code with clang, and gives some; details about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following com",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:631,detect,detects,631,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,2,['detect'],"['detected', 'detects']"
Safety,"==========================; Exception Handling in LLVM; ==========================. .. contents::; :local:. Introduction; ============. This document is the central repository for all information pertaining to; exception handling in LLVM. It describes the format that LLVM exception; handling information takes, which is useful for those interested in creating; front-ends or dealing directly with the information. Further, this document; provides specific examples of what exception handling information is used for in; C and C++. Itanium ABI Zero-cost Exception Handling; ----------------------------------------. Exception handling for most programming languages is designed to recover from; conditions that rarely occur during general use of an application. To that end,; exception handling should not interfere with the main flow of an application's; algorithm by performing checkpointing tasks, such as saving the current pc or; register state. The Itanium ABI Exception Handling Specification defines a methodology for; providing outlying data in the form of exception tables without inlining; speculative exception handling code in the flow of an application's main; algorithm. Thus, the specification is said to add ""zero-cost"" to the normal; execution of an application. A more complete description of the Itanium ABI exception handling runtime; support of can be found at `Itanium C++ ABI: Exception Handling; <http://itanium-cxx-abi.github.io/cxx-abi/abi-eh.html>`_. A description of the; exception frame format can be found at `Exception Frames; <http://refspecs.linuxfoundation.org/LSB_3.0.0/LSB-Core-generic/LSB-Core-generic/ehframechpt.html>`_,; with details of the DWARF 4 specification at `DWARF 4 Standard; <http://dwarfstd.org/Dwarf4Std.php>`_. A description for the C++ exception; table formats can be found at `Exception Handling Tables; <http://itanium-cxx-abi.github.io/cxx-abi/exceptions.pdf>`_. Setjmp/Longjmp Exception Handling; ---------------------------------. Setjmp/Lon",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:681,recover,recover,681,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,1,['recover'],['recover']
Safety,"==========================; UndefinedBehaviorSanitizer; ==========================. .. contents::; :local:. Introduction; ============. UndefinedBehaviorSanitizer (UBSan) is a fast undefined behavior detector.; UBSan modifies the program at compile-time to catch various kinds of undefined; behavior during program execution, for example:. * Array subscript out of bounds, where the bounds can be statically determined; * Bitwise shifts that are out of bounds for their data type; * Dereferencing misaligned or null pointers; * Signed integer overflow; * Conversion to, from, or between floating-point types which would; overflow the destination. See the full list of available :ref:`checks <ubsan-checks>` below. UBSan has an optional run-time library which provides better error reporting.; The checks have small runtime cost and no impact on address space layout or ABI. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>`_. Usage; =====. Use ``clang++`` to compile and link your program with the ``-fsanitize=undefined``; option. Make sure to use ``clang++`` (not ``ld``) as a linker, so that your; executable is linked with proper UBSan runtime libraries, unless all enabled; checks use trap mode. You can use ``clang`` instead of ``clang++`` if you're; compiling/linking C code. .. code-block:: console. % cat test.cc; int main(int argc, char **argv) {; int k = 0x7fffffff;; k += argc;; return 0;; }; % clang++ -fsanitize=undefined test.cc; % ./a.out; test.cc:3:5: runtime error: signed integer overflow: 2147483647 + 1 cannot be represented in type 'int'. You can use ``-fsanitize=...`` and ``-fno-sanitize=`` to enable and disable one; check or one check group. For an individual check, the last option that enabling; or disabling it wins. .. code-block:: console. # Enable all checks in the ""undefined"" group, but disable ""alignment"".; % clang -fsanitize=undefined -fno-sanitize=alignment a.c. # Enable just ""alignment"".; % clang -fsanitize=alignment ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst:200,detect,detector,200,interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst,1,['detect'],['detector']
Safety,"============================; Taint Analysis Configuration; ============================. The Clang Static Analyzer uses taint analysis to detect security-related issues in code.; The backbone of taint analysis in the Clang SA is the `GenericTaintChecker`, which the user can access via the :ref:`alpha-security-taint-TaintPropagation` checker alias and this checker has a default taint-related configuration.; The built-in default settings are defined in code, and they are always in effect once the checker is enabled, either directly or via the alias.; The checker also provides a configuration interface for extending the default settings by providing a configuration file in `YAML <http://llvm.org/docs/YamlIO.html#introduction-to-yaml>`_ format.; This documentation describes the syntax of the configuration file and gives the informal semantics of the configuration options. .. contents::; :local:. .. _clangsa-taint-configuration-overview:. Overview; ________. Taint analysis works by checking for the occurrence of special operations during the symbolic execution of the program.; Taint analysis defines sources, sinks, and propagation rules. It identifies errors by detecting a flow of information that originates from a taint source, reaches a taint sink, and propagates through the program paths via propagation rules.; A source, sink, or an operation that propagates taint is mainly domain-specific knowledge, but there are some built-in defaults provided by :ref:`alpha-security-taint-TaintPropagation`.; It is possible to express that a statement sanitizes tainted values by providing a ``Filters`` section in the external configuration (see :ref:`clangsa-taint-configuration-example` and :ref:`clangsa-taint-filter-details`).; There are no default filters defined in the built-in settings.; The checker's documentation also specifies how to provide a custom taint configuration with command-line options. .. _clangsa-taint-configuration-example:. Example configuration file; __________",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst:139,detect,detect,139,interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst,1,['detect'],['detect']
Safety,"==============================; FaultMaps and implicit checks; ==============================. .. contents::; :local:; :depth: 2. Motivation; ==========. Code generated by managed language runtimes tend to have checks that; are required for safety but never fail in practice. In such cases, it; is profitable to make the non-failing case cheaper even if it makes; the failing case significantly more expensive. This asymmetry can be; exploited by folding such safety checks into operations that can be; made to fault reliably if the check would have failed, and recovering; from such a fault by using a signal handler. For example, Java requires null checks on objects before they are read; from or written to. If the object is ``null`` then a; ``NullPointerException`` has to be thrown, interrupting normal; execution. In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:241,safe,safety,241,interpreter/llvm-project/llvm/docs/FaultMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst,3,"['recover', 'safe']","['recovering', 'safety']"
Safety,"==============================; LLVM Language Reference Manual; ==============================. .. contents::; :local:; :depth: 3. Abstract; ========. This document is a reference manual for the LLVM assembly language. LLVM; is a Static Single Assignment (SSA) based representation that provides; type safety, low-level operations, flexibility, and the capability of; representing 'all' high-level languages cleanly. It is the common code; representation used throughout all phases of the LLVM compilation; strategy. Introduction; ============. The LLVM code representation is designed to be used in three different; forms: as an in-memory compiler IR, as an on-disk bitcode representation; (suitable for fast loading by a Just-In-Time compiler), and as a human; readable assembly language representation. This allows LLVM to provide a; powerful intermediate representation for efficient compiler; transformations and analysis, while providing a natural means to debug; and visualize the transformations. The three different forms of LLVM are; all equivalent. This document describes the human readable; representation and notation. The LLVM representation aims to be light-weight and low-level while; being expressive, typed, and extensible at the same time. It aims to be; a ""universal IR"" of sorts, by being at a low enough level that; high-level ideas may be cleanly mapped to it (similar to how; microprocessors are ""universal IR's"", allowing many source languages to; be mapped to them). By providing type information, LLVM can be used as; the target of optimizations: for example, through pointer analysis, it; can be proven that a C automatic variable is never accessed outside of; the current function, allowing it to be promoted to a simple SSA value; instead of a memory location. .. _wellformed:. Well-Formedness; ---------------. It is important to note that this document describes 'well formed' LLVM; assembly language. There is a difference between what the parser accepts; and what is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:302,safe,safety,302,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['safe'],['safety']
Safety,"==================================; Benchmarking tips; ==================================. Introduction; ============. For benchmarking a patch we want to reduce all possible sources of; noise as much as possible. How to do that is very OS dependent. Note that low noise is required, but not sufficient. It does not; exclude measurement bias. See; https://www.cis.upenn.edu/~cis501/papers/producing-wrong-data.pdf for; example. General; ================================. * Use a high resolution timer, e.g. perf under linux. * Run the benchmark multiple times to be able to recognize noise. * Disable as many processes or services as possible on the target system. * Disable frequency scaling, turbo boost and address space; randomization (see OS specific section). * Static link if the OS supports it. That avoids any variation that; might be introduced by loading dynamic libraries. This can be done; by passing ``-DLLVM_BUILD_STATIC=ON`` to cmake. * Try to avoid storage. On some systems you can use tmpfs. Putting the; program, inputs and outputs on tmpfs avoids touching a real storage; system, which can have a pretty big variability. To mount it (on linux and freebsd at least)::. mount -t tmpfs -o size=<XX>g none dir_to_mount. Linux; =====. * Disable address space randomization::. echo 0 > /proc/sys/kernel/randomize_va_space. * Set scaling_governor to performance::. for i in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do; echo performance > /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; done. * Use https://github.com/lpechacek/cpuset to reserve cpus for just the; program you are benchmarking. If using perf, leave at least 2 cores; so that perf runs in one and your program in another::. cset shield -c N1,N2 -k on. This will move all threads out of N1 and N2. The ``-k on`` means; that even kernel threads are moved out. * Disable the SMT pair of the cpus you will use for the benchmark. The; pair of cpu N can be found in; ``/sys/devices/system/cpu/cpuN/topology/t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Benchmarking.rst:808,avoid,avoids,808,interpreter/llvm-project/llvm/docs/Benchmarking.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Benchmarking.rst,2,['avoid'],"['avoid', 'avoids']"
Safety,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:209,safe,safe,209,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,4,"['avoid', 'safe']","['avoid', 'safe']"
Safety,"=======================================. Reading an object with RNTuple should be seen as _overwriting_ its persistent data members.; Given a properly constructed and valid object, the object must ensure that it stays valid when overwriting its persistent data members.; However, the object should not rely on its transient state to remain unchanged during reading:; it may be destructed and constructed again when it is read as part of a collection (see below). An object that is being read from disk may have been constructed by `RField::CreateValue()`.; In this case, the deleter returned by `RField::GetDeleter()` releases the resources. When reading collections of type `T` (`std::vector<T>`, `ROOT::RVec<T>`, ...), RNTuple uses `RField::CreateValue()` to construct elements of the inner type `T`.; As the size of a collection changes from event to event, this has the following effect on its elements; - If the collection shrinks, cut-off elements are destructed; - If the collection grows, new elements are constructed before reading them; - If the array buffer of the collection is reallocated (may happen for both shrinking and growing depending on the collection), all elements are destructed first in the old buffer; and the new number of elements is constructed in the new buffer. So unless the collection buffer needs to be reallocated, RNTuple tries to avoid unnecessary destruction/construction but instead overwrites existing objects.; Note that RNTuple currently does not copy or move existing objects when the collection buffer is reallocated. Naming Conventions; ==================. For byte arrays and collections of things, the RNTuple code uses the following variable name suffixes:; - `XyzSize` denotes the size of Xyz in bytes on disk, i.e. after compression. Example: `fPageListSize`.; - `XyzLength` denotes the size of Xyz in bytes in memory, i.e. uncompressed. Example: `fPageListLength`.; - `NXyz` denotes the number of Xyz items in a collection. Example: `fNPageLists`.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:31425,avoid,avoid,31425,tree/ntuple/v7/doc/Architecture.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md,1,['avoid'],['avoid']
Safety,"============================================; Implementation plans for ``-fbounds-safety``; ============================================. .. contents::; :local:. External bounds annotations; ===========================. The bounds annotations are C type attributes appertaining to pointer types. If; an attribute is added to the position of a declaration attribute, e.g., ``int; *ptr __counted_by(size)``, the attribute appertains to the outermost pointer; type of the declaration (``int *``). New sugar types; ===============. An external bounds annotation creates a type sugar of the underlying pointer; types. We will introduce a new sugar type, ``DynamicBoundsPointerType`` to; represent ``__counted_by`` or ``__sized_by``. Using ``AttributedType`` would not; be sufficient because the type needs to hold the count or size expression as; well as some metadata necessary for analysis, while this type may be implemented; through inheritance from ``AttributedType``. Treating the annotations as type; sugars means two types with incompatible external bounds annotations may be; considered canonically the same types. This is sometimes necessary, for example,; to make the ``__counted_by`` and friends not participate in function; overloading. However, this design requires a separate logic to walk through the; entire type hierarchy to check type compatibility of bounds annotations. Late parsing for C; ==================. A bounds annotation such as ``__counted_by(count)`` can be added to type of a; struct field declaration where count is another field of the same struct; declared later. Similarly, the annotation may apply to type of a function; parameter declaration which precedes the parameter count in the same function.; This means parsing the argument of bounds annotations must be done after the; parser has the whole context of a struct or a function declaration. Clang has; late parsing logic for C++ declaration attributes that require late parsing,; while the C declaration attribut",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst:82,safe,safety,82,interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,1,['safe'],['safety']
Safety,"================================================; Hardware-assisted AddressSanitizer Design Documentation; =======================================================. This page is a design document for; **hardware-assisted AddressSanitizer** (or **HWASAN**); a tool similar to :doc:`AddressSanitizer`,; but based on partial hardware assistance. Introduction; ============. :doc:`AddressSanitizer`; tags every 8 bytes of the application memory with a 1 byte tag (using *shadow memory*),; uses *redzones* to find buffer-overflows and; *quarantine* to find use-after-free.; The redzones, the quarantine, and, to a less extent, the shadow, are the; sources of AddressSanitizer's memory overhead.; See the `AddressSanitizer paper`_ for details. AArch64 has `Address Tagging`_ (or top-byte-ignore, TBI), a hardware feature that allows; software to use the 8 most significant bits of a 64-bit pointer as; a tag. HWASAN uses `Address Tagging`_; to implement a memory safety tool, similar to :doc:`AddressSanitizer`,; but with smaller memory overhead and slightly different (mostly better); accuracy guarantees. Intel's `Linear Address Masking`_ (LAM) also provides address tagging for; x86_64, though it is not widely available in hardware yet. For x86_64, HWASAN; has a limited implementation using page aliasing instead. Algorithm; =========; * Every heap/stack/global memory object is forcibly aligned by `TG` bytes; (`TG` is e.g. 16 or 64). We call `TG` the **tagging granularity**.; * For every such object a random `TS`-bit tag `T` is chosen (`TS`, or tag size, is e.g. 4 or 8); * The pointer to the object is tagged with `T`.; * The memory for the object is also tagged with `T` (using a `TG=>1` shadow memory); * Every load and store is instrumented to read the memory tag and compare it; with the pointer tag, exception is raised on tag mismatch. For a more detailed discussion of this approach see https://arxiv.org/pdf/1802.09517.pdf. Short granules; --------------. A short granule is a granule of s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:963,safe,safety,963,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,1,['safe'],['safety']
Safety,"==================================================; ``-fbounds-safety``: Enforcing bounds safety for C; ==================================================. .. contents::; :local:. Overview; ========. ``-fbounds-safety`` is a C extension to enforce bounds safety to prevent; out-of-bounds (OOB) memory accesses, which remain a major source of security; vulnerabilities in C. ``-fbounds-safety`` aims to eliminate this class of bugs; by turning OOB accesses into deterministic traps. The ``-fbounds-safety`` extension offers bounds annotations that programmers can; use to attach bounds to pointers. For example, programmers can add the; ``__counted_by(N)`` annotation to parameter ``ptr``, indicating that the pointer; has ``N`` valid elements:. .. code-block:: c. void foo(int *__counted_by(N) ptr, size_t N);. Using this bounds information, the compiler inserts bounds checks on every; pointer dereference, ensuring that the program does not access memory outside; the specified bounds. The compiler requires programmers to provide enough bounds; information so that the accesses can be checked at either run time or compile; time — and it rejects code if it cannot. The most important contribution of ``-fbounds-safety`` is how it reduces the; programmer's annotation burden by reconciling bounds annotations at ABI; boundaries with the use of implicit wide pointers (a.k.a. ""fat"" pointers) that; carry bounds information on local variables without the need for annotations. We; designed this model so that it preserves ABI compatibility with C while; minimizing adoption effort. The ``-fbounds-safety`` extension has been adopted on millions of lines of; production C code and proven to work in a consumer operating system setting. The; extension was designed to enable incremental adoption — a key requirement in; real-world settings where modifying an entire project and its dependencies all; at once is often not possible. It also addresses multiple of other practical; challenges that have made",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:63,safe,safety,63,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,6,['safe'],['safety']
Safety,"====================================================; Using -opt-bisect-limit to debug optimization errors; ====================================================; .. contents::; :local:; :depth: 1. Introduction; ============. The -opt-bisect-limit option provides a way to disable all optimization passes; above a specified limit without modifying the way in which the Pass Managers; are populated. The intention of this option is to assist in tracking down; problems where incorrect transformations during optimization result in incorrect; run-time behavior. This feature is implemented on an opt-in basis. Passes which can be safely; skipped while still allowing correct code generation call a function to; check the opt-bisect limit before performing optimizations. Passes which; either must be run or do not modify the IR do not perform this check and are; therefore never skipped. Generally, this means analysis passes, passes; that are run at CodeGenOptLevel::None and passes which are required for register; allocation. The -opt-bisect-limit option can be used with any tool, including front ends; such as clang, that uses the core LLVM library for optimization and code; generation. The exact syntax for invoking the option is discussed below. This feature is not intended to replace other debugging tools such as bugpoint.; Rather it provides an alternate course of action when reproducing the problem; requires a complex build infrastructure that would make using bugpoint; impractical or when reproducing the failure requires a sequence of; transformations that is difficult to replicate with tools like opt and llc. Getting Started; ===============. The -opt-bisect-limit command line option can be passed directly to tools such; as opt, llc and lli. The syntax is as follows:. ::. <tool name> [other options] -opt-bisect-limit=<limit>. If a value of -1 is used the tool will perform all optimizations but a message; will be printed to stderr for each optimization that could be skipped; in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst:627,safe,safely,627,interpreter/llvm-project/llvm/docs/OptBisect.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst,1,['safe'],['safely']
Safety,"======================================================; How to set up LLVM-style RTTI for your class hierarchy; ======================================================. .. contents::. Background; ==========. LLVM avoids using C++'s built in RTTI. Instead, it pervasively uses its; own hand-rolled form of RTTI which is much more efficient and flexible,; although it requires a bit more work from you as a class author. A description of how to use LLVM-style RTTI from a client's perspective is; given in the `Programmer's Manual <ProgrammersManual.html#isa>`_. This; document, in contrast, discusses the steps you need to take as a class; hierarchy author to make LLVM-style RTTI available to your clients. Before diving in, make sure that you are familiar with the Object Oriented; Programming concept of ""`is-a`_"". .. _is-a: http://en.wikipedia.org/wiki/Is-a. Basic Setup; ===========. This section describes how to set up the most basic form of LLVM-style RTTI; (which is sufficient for 99.9% of the cases). We will set up LLVM-style; RTTI for this class hierarchy:. .. code-block:: c++. class Shape {; public:; Shape() {}; virtual double computeArea() = 0;; };. class Square : public Shape {; double SideLength;; public:; Square(double S) : SideLength(S) {}; double computeArea() override;; };. class Circle : public Shape {; double Radius;; public:; Circle(double R) : Radius(R) {}; double computeArea() override;; };. The most basic working setup for LLVM-style RTTI requires the following; steps:. #. In the header where you declare ``Shape``, you will want to ``#include; ""llvm/Support/Casting.h""``, which declares LLVM's RTTI templates. That; way your clients don't even have to think about it. .. code-block:: c++. #include ""llvm/Support/Casting.h"". #. In the base class, introduce an enum which discriminates all of the; different concrete classes in the hierarchy, and stash the enum value; somewhere in the base class. Here is the code after introducing this change:. .. code-block:: c++. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst:212,avoid,avoids,212,interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,1,['avoid'],['avoids']
Safety,">);. This will produce IR like the following fragment:. .. code-block:: llvm. define void @foo() gc ""<collector description name>"" { ... }. When generating LLVM IR for your functions, you will need to:. * Use ``@llvm.gcread`` and/or ``@llvm.gcwrite`` in place of standard load and; store instructions. These intrinsics are used to represent load and store; barriers. If you collector does not require such barriers, you can skip; this step. * Use the memory allocation routines provided by your garbage collector's; runtime library. * If your collector requires them, generate type maps according to your; runtime's binary interface. LLVM is not involved in the process. In; particular, the LLVM type system is not suitable for conveying such; information though the compiler. * Insert any coordination code required for interacting with your collector.; Many collectors require running application code to periodically check a; flag and conditionally call a runtime function. This is often referred to; as a safepoint poll. You will need to identify roots (i.e. references to heap objects your collector; needs to know about) in your generated IR, so that LLVM can encode them into; your final stack maps. Depending on the collector strategy chosen, this is; accomplished by using either the ``@llvm.gcroot`` intrinsics or an; ``gc.statepoint`` relocation sequence. Don't forget to create a root for each intermediate value that is generated when; evaluating an expression. In ``h(f(), g())``, the result of ``f()`` could; easily be collected if evaluating ``g()`` triggers a collection. Finally, you need to link your runtime library with the generated program; executable (for a static compiler) or ensure the appropriate symbols are; available for the runtime linker (for a JIT compiler). Introduction; ============. What is Garbage Collection?; ---------------------------. Garbage collection is a widely used technique that frees the programmer from; having to know the lifetimes of heap object",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:1892,safe,safepoint,1892,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['safe'],['safepoint']
Safety,">; Subject: Re: a few thoughts. Okay... here are a few of my thoughts on this (it's good to know that we; think so alike!):. > 1. We need to be clear on our goals for the VM. Do we want to emphasize; > portability and safety like the Java VM? Or shall we focus on the; > architecture interface first (i.e., consider the code generation and; > processor issues), since the architecture interface question is also; > important for portable Java-type VMs?. I forsee the architecture looking kinda like this: (which is completely; subject to change). 1. The VM code is NOT guaranteed safe in a java sense. Doing so makes it; basically impossible to support C like languages. Besides that,; certifying a register based language as safe at run time would be a; pretty expensive operation to have to do. Additionally, we would like; to be able to statically eliminate many bounds checks in Java; programs... for example. 2. Instead, we can do the following (eventually): ; * Java bytecode is used as our ""safe"" representation (to avoid; reinventing something that we don't add much value to). When the; user chooses to execute Java bytecodes directly (ie, not; precompiled) the runtime compiler can do some very simple; transformations (JIT style) to convert it into valid input for our; VM. Performance is not wonderful, but it works right.; * The file is scheduled to be compiled (rigorously) at a later; time. This could be done by some background process or by a second; processor in the system during idle time or something...; * To keep things ""safe"" ie to enforce a sandbox on Java/foreign code,; we could sign the generated VM code with a host specific private; key. Then before the code is executed/loaded, we can check to see if; the trusted compiler generated the code. This would be much quicker; than having to validate consistency (especially if bounds checks have; been removed, for example). > This is important because the audiences for these two goals are very; > different. Architects and ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:1117,safe,safe,1117,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,2,"['avoid', 'safe']","['avoid', 'safe']"
Safety,">GetEntry(i);; params[0] = msumf; params[1] = ptsumf;; params[2] = acolin; params[3] = acopl;; bg->Fill(mlp->Evaluate(0,params));; }; for (i = 0; i < signal->GetEntries(); i++) {; signal->GetEntry(i);; params[0] = msumf;; params[1] = ptsumf;; params[2] = acolin;; params[3] = acopl;; sig->Fill(mlp->Evaluate(0,params));; }; TCanvas *cv = new TCanvas(""NNout_cv"",""Neural net output"");; bg->SetFillStyle(3008);; bg->SetFillColor(kBlue);; sig->SetFillStyle(3003);; sig->SetFillColor(kRed);; bg->SetStats(0);; sig->SetStats(0);; bg->Draw();; sig->Draw(""same"");; TLegend *legend = new TLegend(.75,.80,.95,.95);; legend->AddEntry(bg,""Background(WW)"");; legend->AddEntry(sig,""Signal(Higgs)"");; legend->Draw();; ```. The neural net output is then used to display the final difference; between background and signal events. The figure ""The neural net; output"" shows this plot. ![The neural net output](pictures/image144.png). As it can be seen, this is a quite efficient technique. As mentioned; earlier, neural networks are also used for fitting function. For some; application with a cylindrical symmetry, a magnetic field simulation; gives as output the angular component of the potential vector `A`, as; well as the radial and `z` components of the `B` field. One wants to fit those distributions with a function in order to plug; them into the `Geant` simulation code. Polynomial fits could be tried,; but it seems difficult to reach the desired precision over the full; range. One could also use a `spline` interpolation between known; points. In all cases, the resulting field would not be `C`-infinite. An example of output (for Br) is shown. First the initial function can; be seen as the target. Then, the resulting (normalized) neural net; output. In order to ease the learning, the ""normalize output"" was used; here. The initial amplitude can be recovered by multiplying by the; original RMS and then shifting by the original mean. ![The original and the neural net for Br](pictures/image145.jpg); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:81350,recover,recovered,81350,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['recover'],['recovered']
Safety,"ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR; REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,; INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING; OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED; TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY; YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER; PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE; POSSIBILITY OF SUCH DAMAGES. END OF TERMS AND CONDITIONS. How to Apply These Terms to Your New Programs. If you develop a new program, and you want it to be of the greatest; possible use to the public, the best way to achieve this is to make it; free software which everyone can redistribute and change under these terms. To do so, attach the following notices to the program. It is safest; to attach them to the start of each source file to most effectively; convey the exclusion of warranty; and each file should have at least; the ""copyright"" line and a pointer to where the full notice is found. <one line to give the program's name and a brief idea of what it does.>; Copyright (C) <year> <name of author>. This program is free software; you can redistribute it and/or modify; it under the terms of the GNU General Public License as published by; the Free Software Foundation; either version 2 of the License, or; (at your option) any later version. This program is distributed in the hope that it will be useful,; but WITHOUT ANY WARRANTY; without even the implied warranty of; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the; GNU General Public License for more details. You should have received a copy of the GNU General Public License along; with this program; if not, write to the Free Software Foundation, Inc.,; 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA. Also add information on how to contact you by electronic and paper mail. If the program is ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/misc/rootql/LICENSE.txt:15361,safe,safest,15361,misc/rootql/LICENSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/misc/rootql/LICENSE.txt,2,['safe'],['safest']
Safety,"AST files is simpler:; we do not need to track modifications made to AST nodes imported from AST; files and serialize separate ""update records"". There are unfortunately exceptions to this general approach, such as:. * The first declaration of a redeclarable entity maintains a pointer to the; most recent declaration of that entity, which naturally needs to change as; more declarations are parsed.; * Name lookup tables in declaration contexts change after the namespace; declaration is formed.; * We attempt to maintain only a single declaration for an instantiation of a; template, rather than having distinct declarations for an instantiation of; the declaration versus the definition, so template instantiation often; updates parts of existing declarations.; * Some parts of declarations are required to be instantiated separately (this; includes default arguments and exception specifications), and such; instantiations update the existing declaration. These cases tend to be fragile; mutable AST state should be avoided where; possible. As a consequence of this design principle, we typically do not provide setters; for AST state. (Some are provided for short-term modifications intended to be; used immediately after an AST node is created and before it's ""published"" as; part of the complete AST, or where language semantics require after-the-fact; updates.). Faithfulness; ^^^^^^^^^^^^. The AST intends to provide a representation of the program that is faithful to; the original source. We intend for it to be possible to write refactoring tools; using only information stored in, or easily reconstructible from, the Clang AST.; This means that the AST representation should either not desugar source-level; constructs to simpler forms, or -- where made necessary by language semantics; or a clear engineering tradeoff -- should desugar minimally and wrap the result; in a construct representing the original source form. For example, ``CXXForRangeStmt`` directly represents the syntactic ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:59517,avoid,avoided,59517,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['avoid'],['avoided']
Safety,"Arch64 / ARMv8 64-bit - thanks, David Abdurachmanov!. ROOT supports GCC 5.0 (using the GCC4 ABI) and XCode 6.3, Mac OSX 10.10.3. #### Thread-Safety. A lot of effort went into improving the thread-safety of Core and Meta classes / functions. A special thanks to Chris Jones from CMS!. #### std::string_view. Introduce a preview of C++17's std::string_view. To take advantage of this new; class use:; ```{.cpp}; #include ""RStringView.h""; ```; The documentation of this can be found at `http://en.cppreference.com/w/cpp/experimental/basic_string_view`; The implementation provided is extracted from libcxx. Whenever the current; compiler and standard library provide an implmentation, it is used. The type string_view describes an object that can refer to a constant contiguous sequence of char-like objects with the first element of the sequence at position zero. This type is used throughout the ROOT code to avoid copying strings when a; sub-string is needed and to extent interfaces that uses to take a const char*; to take a std::string_view as thus be able to be directly directly passed a; TString, a std::string or a std::string_view. Usage example:. ``` {.cpp}; // With SetName(std::string_view); std::string str; …; obj.SetName( str );; obj.SetName( {str.data()+pos, len} );; ```. ### Meta library. #### Backward Incompatibilities. TIsAProxy's constructor no longer take the optional and unused 2nd argument which was reserved for a 'context'. This context was unused in TIsAProxy itself and was not accessible from derived classes. #### Interpreter. The new interface `TInterpreter::Declare(const char* code)` will declare the; code to the interpreter with all interpreter extensions disabled, i.e. as; ""proper"" C++ code. No autoloading or synamic lookup will be performed. A new R__LOAD_LIBRARY(libWhatever) will load libWhatever at parse time. This allows ROOT to resolve symbols from this library very early on. It is a work-around for the following code from ROOT 5:. ``` {.cpp}; // ROOT ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:2066,avoid,avoid,2066,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['avoid'],['avoid']
Safety,"B (1), kLZMA (2), kOldCompressionAlgo (3), and kUseGlobalSetting; (0). The last option refers to an older interface used to control the; algorithm that is maintained for backward compatibility. The following; function is defined in core/zip/inc/Bits.h and it set the global; variable. R__SetZipMode(int algorithm);. If the algorithm is set to kUseGlobalSetting (0), the global variable; controls the algorithm for compression operations. This is the; default and the default value for the global variable is kZLIB. gDirectory; gDirectory is now a thread local!. The value of gDirectory and gFile are now all accessed via a static function of their respective class. The access is made transparent via a CPP macro. Note: Whenever a thread has an associated TThread object, the value of gDirectory is now thread local, i.e. all modifications direct or indirect of gDirectory will not be seen by the other thread. In particular this means that several I/O operations (including TDirectory::Write) are thread safe (as long as all the required TClass and TStreamerInfo has been previously setup).; Note: This model does not support sharing TFile amongst threads (i.e. a TFile must be accessed from exactly one thread). This means that whenever a TFile's control is passed from a thread to another, the code must explicitly reset gDirectory to another value or there is a risk for this gDirectory to point to a stale pointer if the other thread deletes the TFile object. A TFile deletion will only affect the value of the local gDirectory and gFile. TMemFile; Introduce TMemFile and update TFileMerger to support incremental merges. Add new tutorials (net/treeClient.C + net/fastMergeServer.C); demonstrating how a TMemFile can be used to do parallel merge; from many clients. (TMemFile still needs to be better integrated; with TMessage and TSocket). The new TMemFile class support the TFile interface but only store; the information in memory. This version is limited to 32MB. TMessage mess;; ...; mess->R",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html:3402,safe,safe,3402,io/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html,1,['safe'],['safe']
Safety,"B; controlled by 'ProofServ.MsgSizeHWM');; this limits the number of transfers in the case of large numbers of; small objects.; Reasonably small histograms (GetSize() <; MsgSizeHWM) are merged in one-go at the end instead of one-by-one to; exploit, for example, the better performance of TH1::Merge on the full; list of histos.; Add possibility to compress the messages; this is; controlled by ProofServ.CompressMessage; <compression_level>; The default is still 'no compression' but this will allow to study the; impact of compression. Add sort of 'progress' counter for merging is now shown; on the client:;  ;     root [n] p->Process(...);       ... ;       Mst-0: merging output objects ... / (4; workers still sending). This asserts socket activity and fixes the timeout; problems during long merging phases reported in a few cases.; In TFileMerger, create directly the output file at the; final destination do not make a local copy in the temp directory first; (if needed, one can always set the temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full handshake.; In test/stressProof.cxx, avoid interferences between the; settings used for the PROOF tutorial and possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:7859,avoid,avoid,7859,proof/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html,1,['avoid'],['avoid']
Safety,"BY(mu);. void depositImpl(int amount) {; balance += amount; // WARNING! Cannot write balance without locking mu.; }. void withdrawImpl(int amount) REQUIRES(mu) {; balance -= amount; // OK. Caller must have locked mu.; }. public:; void withdraw(int amount) {; mu.Lock();; withdrawImpl(amount); // OK. We've locked mu.; } // WARNING! Failed to unlock mu. void transferFrom(BankAccount& b, int amount) {; mu.Lock();; b.withdrawImpl(amount); // WARNING! Calling withdrawImpl() requires locking b.mu.; depositImpl(amount); // OK. depositImpl() has no requirements.; mu.Unlock();; }; };. This example demonstrates the basic concepts behind the analysis. The; ``GUARDED_BY`` attribute declares that a thread must lock ``mu`` before it can; read or write to ``balance``, thus ensuring that the increment and decrement; operations are atomic. Similarly, ``REQUIRES`` declares that; the calling thread must lock ``mu`` before calling ``withdrawImpl``.; Because the caller is assumed to have locked ``mu``, it is safe to modify; ``balance`` within the body of the method. The ``depositImpl()`` method does not have ``REQUIRES``, so the; analysis issues a warning. Thread safety analysis is not inter-procedural, so; caller requirements must be explicitly declared.; There is also a warning in ``transferFrom()``, because although the method; locks ``this->mu``, it does not lock ``b.mu``. The analysis understands; that these are two separate mutexes, in two different objects. Finally, there is a warning in the ``withdraw()`` method, because it fails to; unlock ``mu``. Every lock must have a corresponding unlock, and the analysis; will detect both double locks, and double unlocks. A function is allowed to; acquire a lock without releasing it, (or vice versa), but it must be annotated; as such (using ``ACQUIRE``/``RELEASE``). Running The Analysis; --------------------. To run the analysis, simply compile with the ``-Wthread-safety`` flag, e.g. .. code-block:: bash. clang -c -Wthread-safety example.cpp.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:2295,safe,safe,2295,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['safe'],['safe']
Safety,"BugReporterVisitors to emit additional notes that explain the warning; to the user better. There are some existing visitors that might be useful for your check,; e.g. trackNullOrUndefValue. For example, SimpleStreamChecker should highlight; the event of opening the file when reporting a file descriptor leak. If the check tracks anything in the program state, it needs to implement the; checkDeadSymbolscallback to clean the state up.; The check should conservatively assume that the program is correct when a tracked symbol; is passed to a function that is unknown to the analyzer.; checkPointerEscape callback could help you handle that case.; Use safe and convenient APIs!. Always use CheckerContext::generateErrorNode and; CheckerContext::generateNonFatalErrorNode for emitting bug reports.; Most importantly, never emit report against CheckerContext::getPredecessor.; Prefer checkPreCall and checkPostCall to; checkPreStmt<CallExpr> and checkPostStmt<CallExpr>.; Use CallDescription to detect hardcoded API calls in the program.; Simplify C.getState()->getSVal(E, C.getLocationContext()) to C.getSVal(E). Common sources of crashes:. CallEvent::getOriginExpr is nullable - for example, it returns null for an; automatic destructor of a variable. The same applies to some values generated while the; call was modeled, eg. SymbolConjured::getStmt is nullable.; CallEvent::getDecl is nullable - for example, it returns null for a; call of symbolic function pointer.; addTransition, generateSink, generateNonFatalErrorNode,; generateErrorNode are nullable because you can transition to a node that you have already visited.; Methods of CallExpr/FunctionDecl/CallEvent that; return arguments crash when the argument is out-of-bounds. If you checked the function name,; it doesn't mean that the function has the expected number of arguments!; Which is why you should use CallDescription.; Nullability of different entities within different kinds of symbols and regions is usually; documented via assert",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html:24401,detect,detect,24401,interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,1,['detect'],['detect']
Safety,"Builder`` when generating code like this. It has no ""syntactic; overhead"" for its use (you don't have to uglify your compiler with; constant checks everywhere) and it can dramatically reduce the amount of; LLVM IR that is generated in some cases (particular for languages with a; macro preprocessor or that use a lot of constants). On the other hand, the ``IRBuilder`` is limited by the fact that it does; all of its analysis inline with the code as it is built. If you take a; slightly more complex example:. ::. ready> def test(x) (1+2+x)*(x+(1+2));; ready> Read function definition:; define double @test(double %x) {; entry:; %addtmp = fadd double 3.000000e+00, %x; %addtmp1 = fadd double %x, 3.000000e+00; %multmp = fmul double %addtmp, %addtmp1; ret double %multmp; }. In this case, the LHS and RHS of the multiplication are the same value.; We'd really like to see this generate ""``tmp = x+3; result = tmp*tmp;``""; instead of computing ""``x+3``"" twice. Unfortunately, no amount of local analysis will be able to detect and; correct this. This requires two transformations: reassociation of; expressions (to make the add's lexically identical) and Common; Subexpression Elimination (CSE) to delete the redundant add instruction.; Fortunately, LLVM provides a broad range of optimizations that you can; use, in the form of ""passes"". LLVM Optimization Passes; ========================. LLVM provides many optimization passes, which do many different sorts of; things and have different tradeoffs. Unlike other systems, LLVM doesn't; hold to the mistaken notion that one set of optimizations is right for; all languages and for all situations. LLVM allows a compiler implementor; to make complete decisions about what optimizations to use, in which; order, and in what situation. As a concrete example, LLVM supports both ""whole module"" passes, which; look across as large of body of code as they can (often a whole file,; but if run at link time, this can be a substantial portion of the whole; pro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:2965,detect,detect,2965,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['detect'],['detect']
Safety,"CERN/EP-SFT,\; Alja Mrak Tadel, UCSD/CMS,\; Axel Naumann, CERN/EP-SFT,\; Dante Niewenhuis, VU Amsterdam\; Luis Antonio Obis Aparicio, University of Zaragoza,; Ianna Osborne, Princeton University,\; Vincenzo Eduardo Padulano, CERN/EP-SFT,\; Danilo Piparo, CERN/EP-SFT,\; Fons Rademakers, CERN/IT,\; Jonas Rembser, CERN/EP-SFT,\; Andrea Rizzi, University of Pisa,\; Andre Sailer, CERN/EP-SFT,\; Garima Singh, ETH,\; Juraj Smiesko, CERN/RCS-PRJ-FC,; Pavlo Svirin, National Technical University of Ukraine,\; Maciej Szymanski, Argonne,\; Christian Tacke, Darmstadt University,\; Matevz Tadel, UCSD/CMS,\; Alvaro Tolosa Delgado, CERN/RCS-PRJ-FC,\; Devajith Valaparambil Sreeramaswamy, CERN/EP-SFT,\; Peter Van Gemmeren, Argonne,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/ATLAS,; Stefan Wunsch. ## Deprecation and Removal; - The RooFit legacy iterators are deprecated and will be removed in ROOT 6.34 (see section ""RooFit libraries""); - Some memory-unsafe RooFit interfaces were removed; - Some redundant **RooDataSet** constructors are deprecated and will be removed in ROOT 6.34.; Please use the RooDataSet constructors that take RooFit command arguments instead; - ROOT does not longer support Python 2. The minimum required Python version to build ROOT is 3.8.; - Support for wildcard imports like `from ROOT import *` is dropped from PyROOT; - Support for external (ie. non-builtin) libAfterImage is now deprecated and it will be removed in next release 6.34.; - The `TList::TList(TObject*)` constructor is deprecated and will be removed in ROOT 6.34; - The deprecated `TProofOutputList::TProofOutputList(TObject *o)` constructor was removed. ## Core Libraries. The Cling interpreter now relies on LLVM version 16. ## I/O Libraries. ### hadd respects compression settings. Fixed a bug that was previously changing the compression settings to a single digit number instead of the full value; (by default 101). ## TTree Libraries; ### Add files from subdirectories with `TChain::Add` g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:2300,unsafe,unsafe,2300,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,2,"['redund', 'unsafe']","['redundant', 'unsafe']"
Safety,"CFI for indirect function calls, each unique function; type has its own bit vector, and at each call site we need to check that the; function pointer is a member of the function type's bit vector. This scheme; works in a similar way to forward-edge CFI for virtual calls, the distinction; being that we need to build bit vectors of function entry points rather than; of virtual tables. Unlike when re-arranging global variables, we cannot re-arrange functions; in a particular order and base our calculations on the layout of the; functions' entry points, as we have no idea how large a particular function; will end up being (the function sizes could even depend on how we arrange; the functions). Instead, we build a jump table, which is a block of code; consisting of one branch instruction for each of the functions in the bit; set that branches to the target function, and redirect any taken function; addresses to the corresponding jump table entry. In this way, the distance; between function entry points is predictable and controllable. In the object; file's symbol table, the symbols for the target functions also refer to the; jump table entries, so that addresses taken outside the module will pass; any verification done inside the module. In more concrete terms, suppose we have three functions ``f``, ``g``,; ``h`` which are all of the same type, and a function foo that returns their; addresses:. .. code-block:: none. f:; mov 0, %eax; ret. g:; mov 1, %eax; ret. h:; mov 2, %eax; ret. foo:; mov f, %eax; mov g, %edx; mov h, %ecx; ret. Our jump table will (conceptually) look like this:. .. code-block:: none. f:; jmp .Ltmp0 ; 5 bytes; int3 ; 1 byte; int3 ; 1 byte; int3 ; 1 byte. g:; jmp .Ltmp1 ; 5 bytes; int3 ; 1 byte; int3 ; 1 byte; int3 ; 1 byte. h:; jmp .Ltmp2 ; 5 bytes; int3 ; 1 byte; int3 ; 1 byte; int3 ; 1 byte. .Ltmp0:; mov 0, %eax; ret. .Ltmp1:; mov 1, %eax; ret. .Ltmp2:; mov 2, %eax; ret. foo:; mov f, %eax; mov g, %edx; mov h, %ecx; ret. Because the addresses of ``f``,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:17308,predict,predictable,17308,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['predict'],['predictable']
Safety,"CMake <https://llvm.org/docs/CMake.html>`_. Supported Platforms; -------------------. ThreadSanitizer is supported on the following OS:. * Android aarch64, x86_64; * Darwin arm64, x86_64; * FreeBSD; * Linux aarch64, x86_64, powerpc64, powerpc64le; * NetBSD. Support for other 64-bit architectures is possible, contributions are welcome.; Support for 32-bit platforms is problematic and is not planned. Usage; -----. Simply compile and link your program with ``-fsanitize=thread``. To get a; reasonable performance add ``-O1`` or higher. Use ``-g`` to get file names; and line numbers in the warning messages. Example:. .. code-block:: console. % cat projects/compiler-rt/lib/tsan/lit_tests/tiny_race.c; #include <pthread.h>; int Global;; void *Thread1(void *x) {; Global = 42;; return x;; }; int main() {; pthread_t t;; pthread_create(&t, NULL, Thread1, NULL);; Global = 43;; pthread_join(t, NULL);; return Global;; }. $ clang -fsanitize=thread -g -O1 tiny_race.c. If a bug is detected, the program will print an error message to stderr.; Currently, ThreadSanitizer symbolizes its output using an external; ``addr2line`` process (this will be fixed in future). .. code-block:: bash. % ./a.out; WARNING: ThreadSanitizer: data race (pid=19219); Write of size 4 at 0x7fcf47b21bc0 by thread T1:; #0 Thread1 tiny_race.c:4 (exe+0x00000000a360). Previous write of size 4 at 0x7fcf47b21bc0 by main thread:; #0 main tiny_race.c:10 (exe+0x00000000a3b4). Thread T1 (running) created at:; #0 pthread_create tsan_interceptors.cc:705 (exe+0x00000000c790); #1 main tiny_race.c:9 (exe+0x00000000a3a4). ``__has_feature(thread_sanitizer)``; ------------------------------------. In some cases one may need to execute different code depending on whether; ThreadSanitizer is enabled.; :ref:`\_\_has\_feature <langext-__has_feature-__has_extension>` can be used for; this purpose. .. code-block:: c. #if defined(__has_feature); # if __has_feature(thread_sanitizer); // code that builds only under ThreadSanitizer; # endif;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSanitizer.rst:1360,detect,detected,1360,interpreter/llvm-project/clang/docs/ThreadSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSanitizer.rst,1,['detect'],['detected']
Safety,COMPONENT compiler-rt). # Add top-level targets that build specific compiler-rt runtimes.; set(COMPILER_RT_RUNTIMES fuzzer asan builtins dfsan lsan msan profile tsan ubsan ubsan-minimal); foreach(runtime ${COMPILER_RT_RUNTIMES}); get_ext_project_build_command(build_runtime_cmd ${runtime}); add_custom_target(${runtime}; COMMAND ${build_runtime_cmd}; DEPENDS compiler-rt-configure; WORKING_DIRECTORY ${BINARY_DIR}; VERBATIM USES_TERMINAL); endforeach(). if(LLVM_INCLUDE_TESTS); # Add binaries that compiler-rt tests depend on.; set(COMPILER_RT_TEST_DEPENDENCIES; FileCheck count not llvm-nm llvm-objdump llvm-symbolizer llvm-jitlink lli split-file). # Add top-level targets for various compiler-rt test suites.; set(COMPILER_RT_TEST_SUITES; check-asan; check-asan-dynamic; check-cfi; check-cfi-and-supported; check-dfsan; check-fuzzer; check-gwp_asan; check-hwasan; check-lsan; check-msan; check-profile; check-safestack; check-sanitizer; check-tsan; check-ubsan; check-ubsan-minimal; ); foreach(test_suite ${COMPILER_RT_TEST_SUITES}); get_ext_project_build_command(run_test_suite ${test_suite}); add_custom_target(${test_suite}; COMMAND ${run_test_suite}; DEPENDS compiler-rt-build ${COMPILER_RT_TEST_DEPENDENCIES}; WORKING_DIRECTORY ${BINARY_DIR}; VERBATIM; USES_TERMINAL; ); endforeach(). # Add special target to run all compiler-rt test suites.; get_ext_project_build_command(run_check_compiler_rt check-all); add_custom_target(check-compiler-rt; COMMAND ${run_check_compiler_rt}; DEPENDS compiler-rt-build ${COMPILER_RT_TEST_DEPENDENCIES}; WORKING_DIRECTORY ${BINARY_DIR}; VERBATIM USES_TERMINAL). # Add special target to run all compiler-rt test suites.; get_ext_project_build_command(run_check_compiler_rt compiler-rt-test-depends); add_custom_target(compiler-rt-test-depends; COMMAND ${run_check_compiler_rt}; DEPENDS compiler-rt-build ${COMPILER_RT_TEST_DEPENDENCIES}; WORKING_DIRECTORY ${BINARY_DIR}; VERBATIM USES_TERMINAL); set_property(GLOBAL APPEND PROPERTY LLVM_ALL_ADDITIONAL_TEST_DEPE,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/runtime/CMakeLists.txt:5226,safe,safestack,5226,interpreter/llvm-project/clang/runtime/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/runtime/CMakeLists.txt,1,['safe'],['safestack']
Safety,"Cling interprets C++; ====================. .. figure:: images/fig1.jpeg. **Cling** is an interactive C++ interpreter built on top of `Clang; <https://clang.llvm.org/>`_ and `LLVM <https://llvm.org/>`_. It uses LLVM's; *Just-In-Time* (`JIT <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_); compiler to provide a fast and optimized compilation pipeline. Cling uses the; `read-eval-print-loop; <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) approach, making rapid application development in C++ possible,; avoiding the classic edit-compile-run-debug cycle approach. Cling's last release, download instructions, dependencies, and any other useful; information for developers can be found on `Cling's GitHub webpage; <https://github.com/vgvassilev/cling>`_. Find out more about **Interpreting C++** on the `Compiler Research Group; <https://compiler-research.org/>`_'s webpage.; . Table of Contents; -----------------. .. toctree::; :numbered:; ; chapters/background; chapters/interactivity; chapters/why_interpreting; chapters/implementation; chapters/REPL; chapters/grammar; chapters/applications; chapters/conclusion; chapters/references; . .. note::. This project is under active development.; Cling has its documentation hosted on Read the Docs. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst:551,avoid,avoiding,551,interpreter/cling/docs/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst,1,['avoid'],['avoiding']
Safety,"Cling is (also, but not only) REPL; -----------------------------------. A `read-eval-print-loop <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) is an interactive programming environment that takes user inputs,; executes them, and returns the result to the user. In order to enable; interactivity in C++, Cling provides several extensions to the C++ language:. 1. **Defining functions in the global scope:** Cling redefines expressions at a; global level. C++ provides limited support for this, Cling possesses the; necessary semantics to re-define code while the program is running,; minimizing the impedance mismatch between the **REPL** and the C++ codebase,; and allowing for a seamlessly interactive programing experience. 2. **Allows for implementation of commands** that provide information about the; current state of the environment. e.g., has an `Application Programming; Interface <https://en.wikipedia.org/wiki/API>`_ (**API**) to provide; information about the current state of the environment. 3. **Error recovery:** Cling has an efficient error recovery system which allows; it to handle the errors made by the user without restarting or having to redo; everything from the beginning. 4. **Tight feedback loop:** It provides feedback about the results of the; developer’s choices that is both accurate and fast. 5. **Facilitates debugging:** The programmer can inspect the printed result; before deciding what expression to provide for the next line of code.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst:1054,recover,recovery,1054,interpreter/cling/docs/chapters/REPL.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst,2,['recover'],['recovery']
Safety,"ConcurrentIRCompiler utility as our compiler,; which we construct using this constructor's JITTargetMachineBuilder argument.; The ConcurrentIRCompiler utility will use the JITTargetMachineBuilder to build; llvm TargetMachines (which are not thread safe) as needed for compiles. After; this, we initialize our supporting members: ``DL``, ``Mangler`` and ``Ctx`` with; the input DataLayout, the ExecutionSession and DL member, and a new default; constructed LLVMContext respectively. Now that our members have been initialized,; so the one thing that remains to do is to tweak the configuration of the; *JITDylib* that we will store our code in. We want to modify this dylib to; contain not only the symbols that we add to it, but also the symbols from our; REPL process as well. We do this by attaching a; ``DynamicLibrarySearchGenerator`` instance using the; ``DynamicLibrarySearchGenerator::GetForCurrentProcess`` method. .. code-block:: c++. static Expected<std::unique_ptr<KaleidoscopeJIT>> Create() {; auto JTMB = JITTargetMachineBuilder::detectHost();. if (!JTMB); return JTMB.takeError();. auto DL = JTMB->getDefaultDataLayoutForTarget();; if (!DL); return DL.takeError();. return std::make_unique<KaleidoscopeJIT>(std::move(*JTMB), std::move(*DL));; }. const DataLayout &getDataLayout() const { return DL; }. LLVMContext &getContext() { return *Ctx.getContext(); }. Next we have a named constructor, ``Create``, which will build a KaleidoscopeJIT; instance that is configured to generate code for our host process. It does this; by first generating a JITTargetMachineBuilder instance using that classes'; detectHost method and then using that instance to generate a datalayout for; the target process. Each of these operations can fail, so each returns its; result wrapped in an Expected value [3]_ that we must check for error before; continuing. If both operations succeed we can unwrap their results (using the; dereference operator) and pass them into KaleidoscopeJIT's constructor on the;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst:8724,detect,detectHost,8724,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst,1,['detect'],['detectHost']
Safety,"Custom could; be removed. .. rubric:: Footnotes. .. [#legalizer-legacy-footnote] An API is broadly similar to; SelectionDAG/TargetLowering is available but is not recommended as a more; powerful API is available. Rule Processing and Declaring Rules; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The ``getActionDefinitionsBuilder`` function generates a ruleset for the given; opcode(s) that rules can be added to. If multiple opcodes are given, they are; all permanently bound to the same ruleset. The rules in a ruleset are executed; from top to bottom and will start again from the top if an instruction is; legalized as a result of the rules. If the ruleset is exhausted without; satisfying any rule, then it is considered unsupported. When it doesn't declare the instruction legal, each pass over the rules may; request that one type changes to another type. Sometimes this can cause multiple; types to change but we avoid this as much as possible as making multiple changes; can make it difficult to avoid infinite loops where, for example, narrowing one; type causes another to be too small and widening that type causes the first one; to be too big. In general, it's advisable to declare instructions legal as close to the top of; the rule as possible and to place any expensive rules as low as possible. This; helps with performance as testing for legality happens more often than; legalization and legalization can require multiple passes over the rules. As a concrete example, consider the rule::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legalFor({s32, s64, v2s32, v4s32, v2s64}); .clampScalar(0, s32, s64); .widenScalarToNextPow2(0);. and the instruction::. %2:_(s7) = G_ADD %0:_(s7), %1:_(s7). this doesn't meet the predicate for the :ref:`.legalFor() <legalfor>` as ``s7``; is not one of the listed types so it falls through to the; :ref:`.clampScalar() <clampscalar>`. It does meet the predicate for this rule; as the type is smaller than the ``s32`` and ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:4456,avoid,avoid,4456,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,2,['avoid'],['avoid']
Safety,"D lego drawings; 11. Implement ""nomargins"" draw option for pad/canvas; 12. Support custom mouse click/dblcklick handlers in lego plots; 13. Implement marker styles 35 - 49; 14. Let switch orthographic camera in geometry via control gui (#217); 15. Fix drawing of custom markers on 3D, also in node.js (#205). ## Changes in 6.1.1; 1. Fix bug in TFrame drawing, some interactive features was not properly working. ## Changes in 6.1.0; 1. Support drawing produced by TRatioPlot, including interactive zooming; 2. Fix problem with TF1 drawing from histogram list of primitives; 3. Let disable showing of StreamerInfo in the GUI by adding &skipsi to URL; 4. Provide tooltips when TH1 drawn with ""E"" or ""P"" option; 5. Fix problem with zooming of many overlayed histograms; 6. API change -> PadPainter.zoom function returns Promise now; 7. Support gridx/y, tickx/y, logx/y options for (multi) graphs painter; 8. Provide simple Rebin functionality for TH1 (#210); 9. Use jQuery dialog to input values, avoid prompt() which not always supported (#216). ## Changes in 6.0.2; 1. Fix ZSTD size limitation, use streaming API (#214); 2. Prevent endless recursion in JSROOT.parse() function. ## Changes in 6.0.1; 1. Fix problem with matrix calculations in Eve classes (#206); 2. Fix errors in TNodejsFile (#208); 3. Fix TGraph tooltips handling; 4. Fix TH2Poly tooltips handling. ## Changes in 6.0.0; 1. Major release with:; - incompatible changes in API; - heavy use of Promise class; - upgrade all used packages; 2. Use generic naming convention - all class names always starts from; capital letter like ""ObjectPainter"", all function names starts from small; letter like ""painter.getObjectHint()""; 3. Rename JSRootCore.js -> JSRoot.core.js, eliminate all URL parameters.; Loading of extra JSROOT functionality should be done via JSROOT.require() method; All other scripts uses similar naming convention.; 4. JSROOT.draw()/JSROOT.redraw() functions returns Promise, deprecate callback parameter; 5. Introduce JSROOT",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:24208,avoid,avoid,24208,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['avoid'],['avoid']
Safety,"DED in the scope of counted.; {; RefCountable* uncounted = counted.get(); // ok; }; }. void foo2(RefPtr<RefCountable> counted_param) {; RefCountable* uncounted = counted_param.get(); // ok; }. void FooClass::foo_method() {; RefCountable* uncounted = this; // ok; }. Here are some examples of situations that we warn about as they *might* be potentially unsafe. The logic is that either we're able to guarantee that an argument is safe or it's considered if not a bug then bug-prone. .. code-block:: cpp. void foo1() {; RefCountable* uncounted = new RefCountable; // warn; }. RefCountable* global_uncounted;; void foo2() {; RefCountable* uncounted = global_uncounted; // warn; }. void foo3() {; RefPtr<RefCountable> counted;; // The scope of uncounted is not EMBEDDED in the scope of counted.; RefCountable* uncounted = counted.get(); // warn; }. We don't warn about these cases - we don't consider them necessarily safe but since they are very common and usually safe we'd introduce a lot of false positives otherwise:; - variable defined in condition part of an ```if``` statement; - variable defined in init statement condition of a ```for``` statement. For the time being we also don't warn about uninitialized uncounted local variables. Debug Checkers; ---------------. .. _debug-checkers:. debug; ^^^^^. Checkers used for debugging the analyzer.; :doc:`developer-docs/DebugChecks` page contains a detailed description. .. _debug-AnalysisOrder:. debug.AnalysisOrder; """"""""""""""""""""""""""""""""""""""; Print callbacks that are called during analysis in order. .. _debug-ConfigDumper:. debug.ConfigDumper; """"""""""""""""""""""""""""""""""""; Dump config table. .. _debug-DumpCFG Display:. debug.DumpCFG Display; """"""""""""""""""""""""""""""""""""""""""; Control-Flow Graphs. .. _debug-DumpCallGraph:. debug.DumpCallGraph; """"""""""""""""""""""""""""""""""""""; Display Call Graph. .. _debug-DumpCalls:. debug.DumpCalls; """"""""""""""""""""""""""""""; Print calls as they are traversed by the engine. .. _debug-DumpDominators:. debug.DumpDominators; """"""""""""""""""""""""""""""""""""""""; Print t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:85615,safe,safe,85615,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,2,['safe'],['safe']
Safety,"DataFlowSanitizer Design Document; =================================. This document sets out the design for DataFlowSanitizer, a general; dynamic data flow analysis. Unlike other Sanitizer tools, this tool is; not designed to detect a specific class of bugs on its own. Instead,; it provides a generic dynamic data flow analysis framework to be used; by clients to help detect application-specific issues within their; own code. DataFlowSanitizer is a program instrumentation which can associate; a number of taint labels with any data stored in any memory region; accessible by the program. The analysis is dynamic, which means that; it operates on a running program, and tracks how the labels propagate; through that program. Use Cases; ---------. This instrumentation can be used as a tool to help monitor how data; flows from a program's inputs (sources) to its outputs (sinks).; This has applications from a privacy/security perspective in that; one can audit how a sensitive data item is used within a program and; ensure it isn't exiting the program anywhere it shouldn't be. Interface; ---------. A number of functions are provided which will attach taint labels to; memory regions and extract the set of labels associated with a; specific memory region. These functions are declared in the header; file ``sanitizer/dfsan_interface.h``. .. code-block:: c. /// Sets the label for each address in [addr,addr+size) to \c label.; void dfsan_set_label(dfsan_label label, void *addr, size_t size);. /// Sets the label for each address in [addr,addr+size) to the union of the; /// current label for that address and \c label.; void dfsan_add_label(dfsan_label label, void *addr, size_t size);. /// Retrieves the label associated with the given data.; ///; /// The type of 'data' is arbitrary. The function accepts a value of any type,; /// which can be truncated or extended (implicitly or explicitly) as necessary.; /// The truncation/extension operations will preserve the label of the original; //",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst:226,detect,detect,226,interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,2,['detect'],['detect']
Safety,"Date: Sat, 18 Nov 2000 09:19:35 -0600 (CST); From: Vikram Adve <vadve@cs.uiuc.edu>; To: Chris Lattner <lattner@cs.uiuc.edu>; Subject: a few thoughts. I've been mulling over the virtual machine problem and I had some; thoughts about some things for us to think about discuss:. 1. We need to be clear on our goals for the VM. Do we want to emphasize; portability and safety like the Java VM? Or shall we focus on the; architecture interface first (i.e., consider the code generation and; processor issues), since the architecture interface question is also; important for portable Java-type VMs?. This is important because the audiences for these two goals are very; different. Architects and many compiler people care much more about; the second question. The Java compiler and OS community care much more; about the first one. Also, while the architecture interface question is important for; Java-type VMs, the design constraints are very different. 2. Design issues to consider (an initial list that we should continue; to modify). Note that I'm not trying to suggest actual solutions here,; but just various directions we can pursue:. a. A single-assignment VM, which we've both already been thinking about. b. A strongly-typed VM. One question is do we need the types to be; explicitly declared or should they be inferred by the dynamic compiler?. c. How do we get more high-level information into the VM while keeping; to a low-level VM design?. o Explicit array references as operands? An alternative is; to have just an array type, and let the index computations be; separate 3-operand instructions. o Explicit instructions to handle aliasing, e.g.s:; -- an instruction to say ""I speculate that these two values are not; aliased, but check at runtime"", like speculative execution in; EPIC?; -- or an instruction to check whether two values are aliased and; execute different code depending on the answer, somewhat like; predicated code in EPIC. o (This one is a difficult but powerful idea.); A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeas.txt:365,safe,safety,365,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeas.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeas.txt,1,['safe'],['safety']
Safety,"Date: Sun, 19 Nov 2000 16:23:57 -0600 (CST); From: Chris Lattner <sabre@nondot.org>; To: Vikram Adve <vadve@cs.uiuc.edu>; Subject: Re: a few thoughts. Okay... here are a few of my thoughts on this (it's good to know that we; think so alike!):. > 1. We need to be clear on our goals for the VM. Do we want to emphasize; > portability and safety like the Java VM? Or shall we focus on the; > architecture interface first (i.e., consider the code generation and; > processor issues), since the architecture interface question is also; > important for portable Java-type VMs?. I forsee the architecture looking kinda like this: (which is completely; subject to change). 1. The VM code is NOT guaranteed safe in a java sense. Doing so makes it; basically impossible to support C like languages. Besides that,; certifying a register based language as safe at run time would be a; pretty expensive operation to have to do. Additionally, we would like; to be able to statically eliminate many bounds checks in Java; programs... for example. 2. Instead, we can do the following (eventually): ; * Java bytecode is used as our ""safe"" representation (to avoid; reinventing something that we don't add much value to). When the; user chooses to execute Java bytecodes directly (ie, not; precompiled) the runtime compiler can do some very simple; transformations (JIT style) to convert it into valid input for our; VM. Performance is not wonderful, but it works right.; * The file is scheduled to be compiled (rigorously) at a later; time. This could be done by some background process or by a second; processor in the system during idle time or something...; * To keep things ""safe"" ie to enforce a sandbox on Java/foreign code,; we could sign the generated VM code with a host specific private; key. Then before the code is executed/loaded, we can check to see if; the trusted compiler generated the code. This would be much quicker; than having to validate consistency (especially if bounds checks have; been remo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:337,safe,safety,337,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,3,['safe'],"['safe', 'safety']"
Safety,"Date: Wed, 31 Jan 2001 12:04:33 -0600; From: Vikram S. Adve <vadve@cs.uiuc.edu>; To: Chris Lattner <lattner@cs.uiuc.edu>; Subject: another thought. I have a budding idea about making LLVM a little more ambitious: a; customizable runtime system that can be used to implement language-specific; virtual machines for many different languages. E.g., a C vm, a C++ vm, a; Java vm, a Lisp vm, .. The idea would be that LLVM would provide a standard set of runtime features; (some low-level like standard assembly instructions with code generation and; static and runtime optimization; some higher-level like type-safety and; perhaps a garbage collection library). Each language vm would select the; runtime features needed for that language, extending or customizing them as; needed. Most of the machine-dependent code-generation and optimization; features as well as low-level machine-independent optimizations (like PRE); could be provided by LLVM and should be sufficient for any language,; simplifying the language compiler. (This would also help interoperability; between languages.) Also, some or most of the higher-level; machine-independent features like type-safety and access safety should be; reusable by different languages, with minor extensions. The language; compiler could then focus on language-specific analyses and optimizations. The risk is that this sounds like a universal IR -- something that the; compiler community has tried and failed to develop for decades, and is; universally skeptical about. No matter what we say, we won't be able to; convince anyone that we have a universal IR that will work. We need to; think about whether LLVM is different or if has something novel that might; convince people. E.g., the idea of providing a package of separable; features that different languages select from. Also, using SSA with or; without type-safety as the intermediate representation. One interesting starting point would be to discuss how a JVM would be; implemented on top of LLV",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-01-31-UniversalIRIdea.txt:607,safe,safety,607,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-01-31-UniversalIRIdea.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-01-31-UniversalIRIdea.txt,1,['safe'],['safety']
Safety,"E_BUILD_TYPE=RelWithDebInfo`` instead of; ``-DCMAKE_BUILD_TYPE=Release``. This will grant better coverage of; debug info pieces of clang, but will take longer to complete and will; result in a much larger build directory. It's recommended to build the ``all`` target with your instrumented Clang,; since more coverage is often better. b. You should now have a few ``*.profraw`` files in; ``path/to/stage2/profiles/``. You need to merge these using; ``llvm-profdata`` (even if you only have one! The profile merge transforms; profraw into actual profile data, as well). This can be done with; ``/path/to/stage1/llvm-profdata merge; -output=/path/to/output/profdata.prof path/to/stage2/profiles/*.profraw``. 4. Now, build your final, PGO-optimized Clang. To do this, you'll want to pass; the following additional arguments to CMake. - ``-DLLVM_PROFDATA_FILE=/path/to/output/profdata.prof`` - Use the PGO; profile from the previous step.; - ``-DCMAKE_C_COMPILER=/path/to/stage1/clang`` - Use the Clang we built in; step 1.; - ``-DCMAKE_CXX_COMPILER=/path/to/stage1/clang++`` - Same as above. From here, you can build whatever targets you need. .. note::; You may see warnings about a mismatched profile in the build output. These; are generally harmless. To silence them, you can add; ``-DCMAKE_C_FLAGS='-Wno-backend-plugin'; -DCMAKE_CXX_FLAGS='-Wno-backend-plugin'`` to your CMake invocation. Congrats! You now have a Clang built with profile-guided optimizations, and you; can delete all but the final build directory if you'd like. If this worked well for you and you plan on doing it often, there's a slight; optimization that can be made: LLVM and Clang have a tool called tblgen that's; built and run during the build process. While it's potentially nice to build; this for coverage as part of step 3, none of your other builds should benefit; from building it. You can pass the CMake option; ``-DLLVM_NATIVE_TOOL_DIR=/path/to/stage1/bin``; to steps 2 and onward to avoid these useless rebuilds.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWithPGO.rst:7240,avoid,avoid,7240,interpreter/llvm-project/llvm/docs/HowToBuildWithPGO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWithPGO.rst,1,['avoid'],['avoid']
Safety,"FENV_ACCESS`` is disabled. This option; setting behaves as though ``#pragma STDC FENV_ACCESS ON`` appeared at the; top of the source file.; * ``fast`` Behaves identically to specifying both ``-ffast-math`` and; ``ffp-contract=fast``. Note: If your command line specifies multiple instances; of the ``-ffp-model`` option, or if your command line option specifies; ``-ffp-model`` and later on the command line selects a floating point; option that has the effect of negating part of the ``ffp-model`` that; has been selected, then the compiler will issue a diagnostic warning; that the override has occurred. .. option:: -ffp-exception-behavior=<value>. Specify the floating-point exception behavior. Valid values are: ``ignore``, ``maytrap``, and ``strict``.; The default value is ``ignore``. Details:. * ``ignore`` The compiler assumes that the exception status flags will not be read and that floating point exceptions will be masked.; * ``maytrap`` The compiler avoids transformations that may raise exceptions that would not have been raised by the original code. Constant folding performed by the compiler is exempt from this option.; * ``strict`` The compiler ensures that all transformations strictly preserve the floating point exception semantics of the original code. .. option:: -ffp-eval-method=<value>. Specify the floating-point evaluation method for intermediate results within; a single expression of the code. Valid values are: ``source``, ``double``, and ``extended``.; For 64-bit targets, the default value is ``source``. For 32-bit x86 targets; however, in the case of NETBSD 6.99.26 and under, the default value is; ``double``; in the case of NETBSD greater than 6.99.26, with NoSSE, the; default value is ``extended``, with SSE the default value is ``source``.; Details:. * ``source`` The compiler uses the floating-point type declared in the source program as the evaluation method.; * ``double`` The compiler uses ``double`` as the floating-point evaluation method for all float",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:63766,avoid,avoids,63766,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['avoid'],['avoids']
Safety,"FIx; a few issues in libXrdProofd.so with handling of connection used for; admin operation: this should solve some cases where the daemon was not; responding. ; Fix a few memory leaks showing up when; running several queries in the same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not correctly filled on the client; the values on the master,; displayed by TProof::Print were correct).; Fix several small issues affecting the handling of global; package directories; Fix an issue with socket handling in the main event-loop; while sendign or receiving files via TProofMgr.; Fix; a problem counting valid nodes in sequential or 'masteronly' mode,; generating the fake error message ""GoParallel: attaching to candidate!""; Fix a few issues with the length of Unix socket paths; affecting PROOF-Lite and xproofd on MacOsX ; Fix an issue with the release of file descriptors when; recovering sessions .; Fix an issue with a fake error message (""Error in; <TROOT::cd>: No such file root:/"") in PROOF-Lite when; issuing TProof::SetParallel().; Fix a problem with negative values for 'workers still; sending' in PROOF-Lite .; Fix locking issue while building packages locally.; Fix issue setting permission and ownership of the dataset; user directories.Fix; a subtle bug affecting the (possibly rare) case when not all entries; are required and # entries does not correspond to an complete subset of; files (e.g. # entries = 1001000 with files of 100000 entries each). The; effect was uncomplete processing (skipped events, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:10695,recover,recovering,10695,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,1,['recover'],['recovering']
