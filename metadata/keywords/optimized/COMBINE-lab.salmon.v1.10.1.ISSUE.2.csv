quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Deployability,"It's now fixed in latest stable release, closing the issue but feel free to reopen if you have any issues.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/413#issuecomment-548614992:32,release,release,32,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/413#issuecomment-548614992,1,['release'],['release']
Deployability,"I’ve noticed the same thing, and have been hard-masking any repetitive sequences in my pipeline (which I’ve been late to open-source and should be available soon): http://mattshirley.com/uploads/2017/11/2017-11-01_Genome_Informatics.pdf",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/217#issuecomment-385393689:87,pipeline,pipeline,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/217#issuecomment-385393689,1,['pipeline'],['pipeline']
Deployability,"Jumping on this thread. I received similar Seg faults with conda install on OSX. I tried the binary you posted, but receive this error when I try to execute. dyld: Library not loaded: @rpath/libtbbmalloc_proxy.dylib; Referenced from: /Users/dnb14/Documents/salmon_0.11.4-pre_OSX/./bin/salmon; Reason: image not found; Trace/BPT trap: 5",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421407796:65,install,install,65,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421407796,1,['install'],['install']
Deployability,"Just a bit more information:. I installed through conda salmon=0.11.3 and executed command on two different fastq files. The first one was on a single lane of the data and the second was on a concatenated file across 4 lanes. I managed to run the single lane file but got a seg dump error for the ""big""er file. Both times it seems to output the correct files. . Single lane:; ```; salmon alevin -l ISR -1 hgmm_100_S1_L001_001.fastq.1.gz -2 hgmm_100_S1_L001_001.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index/ -o salmon.dir/ --tgMap transcript2geneMap.tsv --dumpCsvCounts; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of Salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to salmon.dir/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { hgmm_100_S1_L001_001.fastq.1.gz }; ### [ mates2 ] => { hgmm_100_S1_L001_001.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:54:57.898] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:54:57.916] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 0 Million barcodes. [2019-01-29 09:54:59.693] [alevinLog] [info] Done barcode density calculation.; [2019-01-29 09:54:59.693] [alevinLog] [info] # Barcodes Used: 902561 / 912145.; [2019-01-29 09:55:04.490] [alevinLog] [info] Knee found left boundary at 391 ; [2019-01-29 09:55:04.817] [alevinLog] [info] Gauss Corrected Boundary at 99 ; [2019-01-29 09:55:04.81",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:32,install,installed,32,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,4,"['UPGRADE', 'install', 'release', 'upgrade']","['UPGRADE', 'installed', 'releases', 'upgrade']"
Deployability,"Just a heads up, issue #266 has been added and the solution is currently available in the source build from the develop branch. We will include this to master with the next planned release of Salmon v0.11.3. Thanks again for the useful feedbacks and comments.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-412352411:181,release,release,181,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-412352411,1,['release'],['release']
Deployability,Just an update in case anyone else is encountering this issue. I was able to install salmon using these instructions: CONDA_SUBDIR=osx-64 conda create -n rosetta; conda activate rosetta; conda env config vars set CONDA_SUBDIR=osx-64; conda install salmon,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/912#issuecomment-1954908448:8,update,update,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/912#issuecomment-1954908448,3,"['install', 'update']","['install', 'update']"
Deployability,"LIBNOVASEQ_M001_R1.fastq.gz -2 INDEXLIBNOVASEQ_M001_R2.fastq.gz --rhapsody -i /mnt/ufds/salmon/gencode_M23/salmon_1.4.0_decoy_M23 -p 10 -o alevin_output --tgMap /mnt/ufds/salmon/gencode_M23/txp2gene_gencode.vM23.tsv; Exception : [unrecognised option '--rhapsody']. Exiting. **Expected behavior**. Logs will be written to alevin_output/logs; [2021-02-10 12:57:59.773] [jointLog] [info] setting maxHashResizeThreads to 10; [2021-02-10 12:57:59.773] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-02-10 12:57:59.773] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2021-02-10 12:57:59.774] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-02-10 12:57:59.774] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; [2021-02-10 12:57:59.774] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-02-10 12:57:59.774] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; ...; [etc.]. **Desktop**. - OS: Debian Linux; - Version: Linux elegans 5.6.0-1-amd64 #1 SMP Debian 5.6.7-1 (2020-04-29) x86_64 GNU/Linux; $ lsb_release -a; No LSB modules are available.; Distributor ID: Debian; Description: Debian GNU/Linux bullseye/sid; Release: unstable; Codename: sid. **Additional context**. This is my first run with BD Rhapsody data (and our own single cell data, for that matter). We're currently using SevenBridges for generating gene count tables, but I don't like the black-box nature of that service. I'm much more comfortable when I know what's going on under the hood, and can tweak things when I notice oddness.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/628:3824,Release,Release,3824,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/628,1,['Release'],['Release']
Deployability,"Looking back to the [earlier post](https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-640962684), I wonder if this stems from CMake not being able to properly find Boost on its own. Granted, the CMake / Boost infrastructure has never been great, partly due to the complexity of salmon's CMake configuration, and partly due to the strange way that CMake, itself, handles Boost versions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641546215:304,configurat,configuration,304,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641546215,1,['configurat'],['configuration']
Deployability,"Looks like I have some sort of conflict going on:. UnsatisfiableError: The following specifications were found to be in conflict:; - libboost -> libcxx >=4.0.1 -> clangdev ==5.0.0 -> llvmdev ==5.0.0; - libcxx 4.0.0* -> clangdev ==4.0.0 -> llvmdev ==4.0.0; Use ""conda info <package>"" to see the dependencies for each package. [https://sites.google.com/site/ummslogos/_/rsrc/1489610858836/home/apple-icon-76x76.png]. Javier E. Irazoqui, PhD; Associate Professor; Department of Microbiology and Physiological Systems; UMass Medical School. 368 Plantation Street; Albert Sherman Center; Room AS8.1053; Worcester, MA 01605. (774) 455-3797; Skype: javierirazoqui. Confidentiality Notice:; This e-mail message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential, proprietary and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender immediately and destroy or permanently delete all copies of the original message. On Feb 11, 2018, at 11:01 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. I can't seem to reproduce this locally (OSX 10.13.1). However, what happens if you try:. > conda install salmon=0.9.1. do you see this version as available? Does it try to install it?. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364824034>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AiohHaDPT6VtnW3toOd9kEKLLo2Zjvvcks5tT7e0gaJpZM4SAonB>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364941997:1274,install,install,1274,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364941997,2,['install'],['install']
Deployability,"Looks like some progress has been made leading up to 1.6.0. The only thing cmake insists on embedding in the build now is pufferfish. Seems like it should be relatively easy to tweak cmake to use a separate install of this since it's already a separate Github project. However, it appears to use a COMBINE-lab fork of staden-io, which makes it impractical to install that as a separate package, since it would conflict with the mainstream version. The Debian package for staden-io_lib is from [https://github.com/jkbonfield/io_lib](https://github.com/jkbonfield/io_lib). I did get a successful build under FreeBSD ports: [https://github.com/outpaddling/freebsd-ports-wip/tree/master/salmon](https://github.com/outpaddling/freebsd-ports-wip/tree/master/salmon).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/502#issuecomment-989318706:207,install,install,207,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/502#issuecomment-989318706,2,['install'],['install']
Deployability,"Me too! . I tried the commands they suggest at anaconda (https://anaconda.org/bioconda/salmon), but even after installing everything I got with these commands, salmon still wants its update... (my current version after installing and updating via conda (with the channels conda-forge, bioconda, and default) is salmon 0.12.0). Is there an easy way to install it ""manually"" (I just started using Linux and haven't quite figured out how to install stuff on my own yet)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/483#issuecomment-774540738:111,install,installing,111,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/483#issuecomment-774540738,5,"['install', 'update']","['install', 'installing', 'update']"
Deployability,Merge develop into main for 1.10.2 release.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/857:35,release,release,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/857,1,['release'],['release']
Deployability,Merge develop into master with patch to enable linux-ARM build on bioconda.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/917:31,patch,patch,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/917,1,['patch'],['patch']
Deployability,"Mine reports:. ```; ~/S/s/build ❯❯❯ otool -L ../bin/salmon; ../bin/salmon:; /usr/lib/libz.1.dylib (compatibility version 1.0.0, current version 1.2.5); /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1226.10.1); /usr/lib/libbz2.1.0.dylib (compatibility version 1.0.0, current version 1.0.5); @rpath/libtbb.dylib (compatibility version 0.0.0, current version 0.0.0); @rpath/libtbbmalloc.dylib (compatibility version 0.0.0, current version 0.0.0); /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 120.1.0); ```. I think the difference may be that in my build, the salmon build system d/l and installed libtbb (which it does if it's not present on the system already).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239594781:636,install,installed,636,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239594781,1,['install'],['installed']
Deployability,"My current version of salmon is 0.14.1 and I need to upgrade to version 1.1.0, I'v tried the command; ""conda update salmon"" but the version remains 0.14.1.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/483:53,upgrade,upgrade,53,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/483,2,"['update', 'upgrade']","['update', 'upgrade']"
Deployability,"My guess, and this is a long shot, is that it's a bug in the `tar` library of `cmake`, that's made evident because my system at work has up-to-date Linux headers and glibc but is running an eight-year-old Linux kernel (CentOS 5.10). I can upgrade everything with Linuxbrew except the running kernel. I've seen this situation show bugs before when the software uses compile time kernel feature checks like `HAVE_PIPE2` when it should be using a run time check, namely checking whether the call to `pipe2` fails with `ENOSYS`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-127341230:239,upgrade,upgrade,239,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-127341230,1,['upgrade'],['upgrade']
Deployability,"My issue was resolved. Thanks. On Sun, Dec 30, 2018 at 12:07 PM Rob Patro <notifications@github.com> wrote:. > Hi @phickner <https://github.com/phickner>,; >; > Any update on this? How does the BAM file look under ValidateSamFile or; > some such?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-450573944>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/APvI3l_civHZCPEisrvMD2azctC_EEM1ks5u-PLngaJpZM4Y4K_L>; > .; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-450704257:165,update,update,165,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-450704257,1,['update'],['update']
Deployability,"NAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", O_RDONLY) = 4; read(4, ""{\n \""indexVersion\"": 2,\n \""ha""..., 8191) = 96; read(4, """", 8191) = 0; close(4) = 0; stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", {st_mode=S_IFREG|0775, st_size=96, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", O_RDONLY) = 4; read(4, ""{\n \""indexVersion\"": 2,\n \""ha""..., 8191) = 96; read(4, """", 8191) = 0; close(4) = 0; clock_gettime(CLOCK_REALTIME, {1491424830, 69887706}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/header.json"", O_RDONLY) = 4; read(4, ""{\n \""value0\"": {\n \""Index""..., 8191) = 357; read(4, """", 8191) = 0; close(4) = 0; clock_gettime(CLOCK_REALTIME, {1491424830, 139950818}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/header.json"", O_RDONLY) = 4; read(4, ""{\n \""value0\"": {\n \""Index""..., 8191) = 357; read(4, """", 8191) = 0; close(4) = 0; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffe7e5e8000; mprotect(0x7ffe7e5e8000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffebe5e7ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffebe5e89d0, tls=0x7ffebe5e8700, child_tidptr=0x7ffebe5e89d0) = 14677; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/sa.bin"", O_RDONLY) = 4; clock_gettime(CLOCK_REALTIME, {1491424830, 149197282}) = 0; read(4, ""l\n\221\21\0\0\0\0k\n\221\21\373\25\343\20\17\254\r\1\36\27\227\n\37\371\270\4\250\210\307\f""..., 8191) = 8191; mmap(NULL, 1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:165933,pipeline,pipeline,165933,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"NC00337-001|LINC00337|1302|l""..., 8191) = 8191; read(4, ""\0\0\0\0ENST00000377728.7|ENSG000001""..., 8191) = 8191; read(4, ""|z\0\0\0\0\0\0\0ENST00000470648.5|ENSG0""..., 8191) = 8191; read(4, [1m[2017-04-05 16:40:33.297] [stderrLog] [info] Loading Transcript Info ; [00mread(4, ""35271.1|ENSG00000234546.3|OTTHUM""..., 8191) = 8191; read(4, ""00005018.1|UBE4B-003|UBE4B|2299|""..., 8191) = 8191; read(4, ""ding|x\0\0\0\0\0\0\0ENST00000468348.1|E""..., 8191) = 8191; read(4, ""005558.1|MTOR-001|MTOR|8677|prot""..., 8191) = 8191; read(4, ""rotein_coding|x\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""|\177\0\0\0\0\0\0\0ENST00000439324.2|ENSG0""..., 8191) = 8191; read(4, ""36.1|OTTHUMG00000009500.2|OTTHUM""..., 8191) = 8191; read(4, ""G00000175147.11|OTTHUMG000000020""..., 8191) = 8191; read(4, ""rotein_coding|}\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""ed_transcript|z\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""1|549|processed_transcript|{\0\0\0\0""..., 8191) = 8191; read(4, ""0006250.3|CROCC-002|CROCC|3931|p""..., 8191) = 8191; read(4, ""nscript|y\0\0\0\0\0\0\0ENST00000466151.""..., 8191) = 8191; read(4, ""R4|536|processed_transcript|q\0\0\0""..., 8191) = 8191; read(4, "".13|OTTHUMG00000002712.2|OTTHUMT""..., 8191) = 8191; read(4, ""0375079.6|ENSG00000158816.15|OTT""..., 8191) = 8191; ```. (First 500 lines, job is running well). ## Next steps. We are hoping that this info will give you an idea on what could be the source of the problem. Maybe `Salmon` requires a newer version of its dependencies than those that we have installed at JHPCE. . Under a scenario where `Salmon` doesn't change (and it's not a dependency issue), we could try running `Salmon` with increasing amounts of memory until we find a point where it doesn't fail for any of our samples (fastq files go to to 13 GB per read in a read pair, so 26 GB total for this particular dataset). We know that 90 GB total memory works, but like I've said before it's a pretty inefficient use of our cluster resources. Best,; Leo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:170255,install,installed,170255,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['install'],['installed']
Deployability,"NO BUG! I am presenting bulk RNA seq to non-bioinformaticians and wanted to go over how Salmon works in simple terms. . I tried understanding all the algorithms and models underlying the tool, but need help in explaining it more simply to a crowd of non-mathematicians. How would you explain the quasi mapping and quantification broadly and in simple terms? No need to get into deeper details. Just want an overview of a complicated mathematical pipeline. Presentation is on Monday so would really appreciate a timely response.; Thanks!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/926:446,pipeline,pipeline,446,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/926,1,['pipeline'],['pipeline']
Deployability,"NULL, msg_iov(1)=[{""HTTP/1.1 200 OK\r\nServer: GitHub.""..., 512}], msg_controllen=0, msg_flags=0}, 0) = 512; recvmsg(6, {msg_name(0)=NULL, msg_iov(1)=[{""Accept-Encoding\r\nX-Fastly-Reques""..., 512}], msg_controllen=0, msg_flags=0}, 0) = 125; epoll_wait(5, {}, 128, 0) = 0; recvmsg(6, {msg_name(0)=NULL, msg_iov(1)=[{""Server: GitHub.com\r\nContent-Type""..., 1024}], msg_controllen=0, msg_flags=0}, 0) = 0; epoll_wait(5, {}, 128, 0) = 0; close(6) = 0; futex(0x7fffbee4613c, FUTEX_CMP_REQUEUE_PRIVATE, 1, 2147483647, 0x7fffbee46110, 2) = 1; futex(0x7fffbee46110, FUTEX_WAKE_PRIVATE, 1) = 1; futex(0x7fffbedff9d0, FUTEX_WAIT, 10739, NULL) = 0; munmap(0x7fff7edff000, 1073745920) = 0; close(5) = 0; close(3) = 0; close(4) = 0; write(2, ""Version Info: This is the most r""..., 57Version Info: This is the most recent version of Salmon.; ) = 57; write(2, ""### salmon (mapping-based) v0.8.""..., 594### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:66162,pipeline,pipeline,66162,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"NULL, msg_iov(1)=[{""HTTP/1.1 200 OK\r\nServer: GitHub.""..., 512}], msg_controllen=0, msg_flags=0}, 0) = 512; recvmsg(6, {msg_name(0)=NULL, msg_iov(1)=[{""Accept-Encoding\r\nX-Fastly-Reques""..., 512}], msg_controllen=0, msg_flags=0}, 0) = 125; epoll_wait(5, {}, 128, 0) = 0; recvmsg(6, {msg_name(0)=NULL, msg_iov(1)=[{""Server: GitHub.com\r\nContent-Type""..., 1024}], msg_controllen=0, msg_flags=0}, 0) = 0; epoll_wait(5, {}, 128, 0) = 0; close(6) = 0; futex(0x7fffbee4813c, FUTEX_CMP_REQUEUE_PRIVATE, 1, 2147483647, 0x7fffbee48110, 4) = 1; futex(0x7fffbee48110, FUTEX_WAKE_PRIVATE, 1) = 1; futex(0x7fffbedff9d0, FUTEX_WAIT, 32682, NULL) = 0; munmap(0x7fff7edff000, 1073745920) = 0; close(5) = 0; close(3) = 0; close(4) = 0; write(2, ""Version Info: This is the most r""..., 57Version Info: This is the most recent version of Salmon.; ) = 57; write(2, ""### salmon (mapping-based) v0.8.""..., 594### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); s",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:29396,pipeline,pipeline,29396,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"NULL, msg_iov(1)=[{""HTTP/1.1 200 OK\r\nServer: GitHub.""..., 512}], msg_controllen=0, msg_flags=0}, 0) = 512; recvmsg(6, {msg_name(0)=NULL, msg_iov(1)=[{""ccept-Encoding\r\nX-Fastly-Request""..., 512}], msg_controllen=0, msg_flags=0}, 0) = 124; epoll_wait(5, {}, 128, 0) = 0; recvmsg(6, {msg_name(0)=NULL, msg_iov(1)=[{""Server: GitHub.com\r\nContent-Type""..., 1024}], msg_controllen=0, msg_flags=0}, 0) = 0; epoll_wait(5, {}, 128, 0) = 0; close(6) = 0; futex(0x7fffbee4413c, FUTEX_CMP_REQUEUE_PRIVATE, 1, 2147483647, 0x7fffbee44110, 4) = 1; futex(0x7fffbee44110, FUTEX_WAKE_PRIVATE, 1) = 1; futex(0x7fffbedff9d0, FUTEX_WAIT, 51997, NULL) = 0; munmap(0x7fff7edff000, 1073745920) = 0; close(5) = 0; close(3) = 0; close(4) = 0; write(2, ""Version Info: This is the most r""..., 57Version Info: This is the most recent version of Salmon.; ) = 57; write(2, ""### salmon (mapping-based) v0.8.""..., 594### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:104744,pipeline,pipeline,104744,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"No updates right now. Consider this issue not reproduced yet, as I haven't had time to dig into the details. Hopefully it's an issue on my end, but expect an update in the next couple of days.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-296880535:3,update,updates,3,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-296880535,2,['update'],"['update', 'updates']"
Deployability,"No worries; thanks for looping back around. As a side-note, v1.0.0 is quite a few releases old and it’s probably worth updating to the latest (v1.9.0) if that’s not too difficult on your end.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/804#issuecomment-1271477486:82,release,releases,82,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/804#issuecomment-1271477486,1,['release'],['releases']
Deployability,"No, I believe that config.h was it. Otherwise, I just use the already installed headers and the pre-compiled library `libjellyfish-2.0`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195466899:70,install,installed,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195466899,1,['install'],['installed']
Deployability,"No, I take that back. Boost isn't installed in `/usr/` of this system. There's only one boost install.; Perhaps it's mixing compilers GCC 4.8.4 for some modules and 5.3 for others.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-193964440:34,install,installed,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-193964440,2,['install'],"['install', 'installed']"
Deployability,"No, there are no changes here. Further, indices built from version 1.0.0 are *forward-compatible* up through the current release. There is no need to rebuild any indices. Also, though 1.2.1 added a new flag, it made no changes to defaults, so quantifications between 1.2.0 and 1.2.1 are directly comparable.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-617940367:121,release,release,121,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-617940367,1,['release'],['release']
Deployability,"Nope; nothing special. Once you've installed conda, you simply do:. ```; $ conda config --add channels conda-forge; $ conda config --add channels bioconda; $ conda create -n salmon salmon=0.10.1; ```. then it will give you instructions on how to activate the environment to run salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394755128:35,install,installed,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394755128,1,['install'],['installed']
Deployability,"Not a problem @roryk , yes in my understanding of v3 things directly effecting Alevin is just the Umi length increment. Other noticeable changes downstream of Alevin I have observed and seen some comments from @LTLA would be:; * Read length changes from 98 to 91; * The output format of cellranger has changed, [this](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/matrices) might give full overview.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/324#issuecomment-443237933:387,pipeline,pipelines,387,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/324#issuecomment-443237933,1,['pipeline'],['pipelines']
Deployability,"Note that I do (now) have `cereal` installed, so there is no need for `salmon` to download and build it. It would be nice if this were an option to use the system-provided `cereal` library.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-127342739:35,install,installed,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-127342739,1,['install'],['installed']
Deployability,"Now I am, and I still have the issue.. ; `git clone -b develop https://github.com/COMBINE-lab/salmon`; `git branch -l`; `* develop`. and then I just followed the tutorial: ; ```; cd salmon; mkdir build; cd build; cmake ..; make install; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443514886:228,install,install,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443514886,1,['install'],['install']
Deployability,Now I get some fq data from bd rhapsody platform: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE212212; ![image](https://github.com/COMBINE-lab/salmon/assets/52995448/8a5b47a4-b041-4a6f-9ba4-3fba21a08028). And it used the sample_tag.fq data to store the sample information. I notice that the bd rhapsody pipeline can generate a sample tag file:; ![image](https://github.com/COMBINE-lab/salmon/assets/52995448/9d1c4031-60c6-446a-982a-8e00f6f031a0). it can tell you which sample the cell from in a single batch:; ![image](https://github.com/COMBINE-lab/salmon/assets/52995448/ab9c2577-6a13-4370-8e93-e3efed574b89). Does alevin also provide flag to handle the tag.fq?. Thank you.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/879:312,pipeline,pipeline,312,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/879,1,['pipeline'],['pipeline']
Deployability,"OENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64"", {st_mode=S_IFDIR|0755, st_size=7, ...}) = 0; open(""/etc/ld.so.cache"", O_RDONLY) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=100319, ...}) = 0; mmap(NULL, 100319, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fffbffe4000; close(3) = 0; open(""/lib64/libpthread.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\340]@\3427\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=145896, ...}) = 0; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbffe3000; mmap(0x37e2400000, 2212848, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x37e2400000; mprotect(0x37e2417000, 2097152, PROT_NONE) = 0; mmap(0x37e2617000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x17000) = 0x37e2617000; mmap(0x37e2619000, 13296, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x37e2619000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/liblzma.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0 %\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=130728, ...}) = 0; mmap(NULL, 2226056, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbfdc3000; mprotect(0x7fffbfde2000, 2097152, PROT_NONE) = 0; mmap(0x7fffbffe2000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1f000) = 0x7fffbffe2000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libtbb.so.2"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\320v\1\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_si",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:91950,pipeline,pipeline,91950,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"OENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:8664,pipeline,pipeline,8664,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"OK --- I think I fixed it; can you re-download the v0.6.0 binary and see if the segfault goes away for you? I think it was the result of failing to give a particular class a default constructor --- a certain variable was being initialized properly on my newer compiler, but that was not the case on the older compiler on the VM where I build the binary. ~~If this resolves the issue for you, I'll probably bump to v0.6.1 just in case anyone tries to build from the source tarball on an older compiler.~~ (I already moved the v0.6.0 tag to point to the new commit and updated the binaries. Hopefully nobody fell through the cracks with the old source tarball, but this doesn't seem like something worth bumping a release for --- assuming my minor change fixes the issue for you as well).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168364366:567,update,updated,567,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168364366,2,"['release', 'update']","['release', 'updated']"
Deployability,"OK, I will try. Do I need to do anything to the binary before installing salmon via bioconda.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394753571:62,install,installing,62,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394753571,1,['install'],['installing']
Deployability,"OK. I successfully installed conda and entered the salmon env and then created the index (I hope correctly, as I am new to the conda env), but now I want to run my samples on our cluster at the university where I do not have permissions to install from source, and therefore the binary version of salmon is installed there. Will there be an incompatibility problem, if I indexed the trasncriptome on my local computer and run salmon using the binary?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-395002738:19,install,installed,19,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-395002738,3,['install'],"['install', 'installed']"
Deployability,"OS: ubuntu 16.04; Salmon was installed using conda. Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.10.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /work/yu_liu/resource/salmon_gencodev28_index/ }; ### [ libType ] => { U }; ### [ unmatedReads ] => { /work/yu_liu/NEPC_david/data_source/Output.Fastqs/HS_1-1_S1_R1_001.fastq.gz }; ### [ threads ] => { 8 }; ### [ output ] => { /scratch/yu_liu/HS_1-1_quant }; Logs will be written to /scratch/yu_liu/HS_1-1_quant/logs; [2018-07-13 20:04:48.086] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-13 20:04:48.086] [jointLog] [info] parsing read library format; [2018-07-13 20:04:48.086] [jointLog] [info] There is 1 library.; Exception : [rapidjson internal assertion failure: IsObject()]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/251:29,install,installed,29,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/251,1,['install'],['installed']
Deployability,"Oh wow; I had no idea about libgff :). Regarding Jellyfish, there's not a source ""change"" required upstream, rather the fact that I seem to require the `config.h` file that is not installed during the ""normal"" Jellyfish install process. I don't know if you have any idea how one might get around that. Regarding staden, thanks for brining this to my attention. It will probably take a bit for me to wrap my head around the right way to access this information in CMake, but I'll see what I can manage to cobble together on that front (I really wish there was something better, with a less horrendous ""language"" than CMake, but nothing I know of exists that works nearly as well ""out of the box"").",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195436157:180,install,installed,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195436157,2,['install'],"['install', 'installed']"
Deployability,"Oh, I also missed that `$prefix/bin/salmon` is marked executable, even for the use who install it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/761#issuecomment-1067229426:87,install,install,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/761#issuecomment-1067229426,1,['install'],['install']
Deployability,"Oh, great, was making a small example data set. I'll stop that then. I was trying to compile, but I can't get Boost installed with linuxbrew for some reason.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168354205:116,install,installed,116,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168354205,1,['install'],['installed']
Deployability,Ok - I will give this a try with` k 31` and `not have keepDuplicates` . Will update soon,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613226597:77,update,update,77,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613226597,1,['update'],['update']
Deployability,Ok --- The sailfish docs should be updated as well [http://sailfish.readthedocs.org/en/master/](http://sailfish.readthedocs.org/en/master/). Let me know if you see something different (i.e. if you still see the salmon instructions over there).,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/27#issuecomment-152844121:35,update,updated,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/27#issuecomment-152844121,1,['update'],['updated']
Deployability,"Ok @DarwinAwardWinner, I think it's fixed for real this time. The issue was stemming from an uninitialized prior value in the Gibbs sampler under VBOpt mode (the initialization code was updated on the develop branch, which is where the bug was introduced). This, in turn, was leading to `nan` being passed as the alpha parameter of `std::gamma_distribution`. With the `-Ofast` optimization flags, at least, this leads `std::gamma_distribution()` to hang forever in an infinite loop. Clearly, `nan` should not be passed to `std::gamma_distribution()`, but I'd argue the behavior of looping forever here is not great. Anyway, I fixed the initialization bug, so that this nan should never pop up. Just to be safe, I also changed the default optimization flag to `-O3` so that at least `nan` and `inf` can be properly tested. Since the TBB code and the parallel sampling weren't causing the issue, I've added them back in. Could you please test the latest push (40584e62859fb65463188b50d132c1eb622b21f0) and verify that this resolves the issue for you (*hopefully*!)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253:186,update,updated,186,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253,1,['update'],['updated']
Deployability,"Ok @curtisd0886, it should be fixed now! Sorry for the mixup. Everything else (bioconda, docker, etc.) were cut from the tag, but the pre-compiled excitable was mistakenly copied over from the master branch (before the changes were merged in) rather than the tag. I've updated the executable.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860947066:269,update,updated,269,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860947066,1,['update'],['updated']
Deployability,"Ok all; another update. The issue I raise above still exists (differences between calls to `ksw_extz` and `ksw_extz2sse`). *However*, I think that what is happening in this case is actually explained more simply. That is, the positions being reported by salmon are _correct_ given the optimal alignment. Specifically, salmon is performing an end-to-end alignment of the read, and the optimal alignment here includes an indel of length 3 in the initial portion of the read. If we were outputting the CIGAR string along with the position, then the bases would line up because the ""off by 3"" issue that happens above for the reads would be addressed when walking the CIGAR. However, we don't (currently) output the CIGAR — rather, we output a decoy CIGAR that does not represent the optimal alignment as computed by ksw2. So, if we assume all matches / mismatches (an indel-free prefix for this read), then we see the position shift noted in the initial bug report. I think the easiest solution, for the time being at least, is to report the position as if the prefix before the first MEM is indel free under the optimal alignment (even if it is not and the optimal score reflects that). However, if there are other suggestions for the best way to address this, I'm open to those as well.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574719940:16,update,update,16,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574719940,1,['update'],['update']
Deployability,"Ok so 0.8.0 contains the option to turn off all length correction, but I've pushed back the milestone for fully supporting the barcoding. This is because there's already a lot of new stuff in 0.8.0 and I needed to cut a release to coincide with the paper. Just dropping in here to explain the modified milestone and re-iterate my interest in and commitment to this feature ;P.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-274638652:220,release,release,220,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-274638652,1,['release'],['release']
Deployability,"Ok, I was able to reproduce your issue. Interestingly, it happens for me _only_ with the pre-compiled binary. My guess is that it's a problem with using both default and implicit options with the older version of boost with which the pre-compiled binary was made (I make the binary under a docker image with an old version of CentOS to maximize compatibility). A temporary work-around is to use the form `--writeMapping=test_output/mappings_info`, which seems to solve the issue that was occurring. I'll make a note of this on the release page and see if I can find a way around this when building the next binary release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244935740:531,release,release,531,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244935740,2,['release'],['release']
Deployability,"Ok, I will update that with a bioconda install under the Docker image, I am also unable to reproduce the issue. I imagine there must be some other difference causing this issue. Might you be able to try inside a docker image on your environment? This would isolate potential library differences, I think.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404315458:11,update,update,11,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404315458,2,"['install', 'update']","['install', 'update']"
Deployability,"Ok, I've tracked down and fixed the bug. I'll be tagging a new release with the fix soon. I'll ping back here and close this issue when the new release is out.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287431196:63,release,release,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287431196,2,['release'],['release']
Deployability,"Ok, I've updated the docs and added an explicit note about this in commit 95866337bde0feb57a0c3231efdfa26c847ba141. It has propagated to the documentation now. Thanks again for reporting this and offering this suggestion.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/118#issuecomment-278133154:9,update,updated,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/118#issuecomment-278133154,1,['update'],['updated']
Deployability,"Ok, in fact, when I check with the ""older"" reference (from ftp://ftp.ensembl.org/pub/release-79/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz), I get that these transcripts are _not_ duplicates of each other. To verify it's not salmon's problem, I also checked with [seqkit's rmdup command](https://bioinf.shenwei.me/seqkit/usage/#rmdup), and, in fact, in the older cdna file, these transcripts appear to have distinct sequence.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429504101:85,release,release-,85,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429504101,1,['release'],['release-']
Deployability,"Ok, not urgent. I installed 0.8.2 from source with no problem, so I'll just use that for now. I have just come to take homebrew's convenience for granted!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/142#issuecomment-315820645:18,install,installed,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/142#issuecomment-315820645,1,['install'],['installed']
Deployability,"Ok, pushed to [bioconda](https://github.com/bioconda/bioconda-recipes/pull/17922/checks?check_run_id=248588035), should be available in a couple of hours. Once it's available I'll make the official release too on the github. It'd be great if you can quickly test the new release for the bug once it's available. Thanks again !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-538581395:198,release,release,198,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-538581395,2,['release'],['release']
Deployability,"Ok, salmon V1.0.0 finished in 5H 15 min, so about 5 times faster, the exact same library and parameters, and achieved almost the same mapping rate (85.1058% with V1.2.0 vs 84.6341% with V1.0.0) attaching log. I must add I did not trim this library for adapters nor quality, nor did anything to it. Just mapped as is. But fastQC showed excellent levels of quality even at the ends and no or minimal adapter content. ; Also no changes have been done one my OS other than regular updates, but still Ubuntu 18.04. I don't remember any specific changes I've done to it. ; Pearson's correlation in transcript abundance (isoform lelvel) is 0.9984013. Spearman's is 0.9899048. ; Also, I did checked that salmon was actually using 4 threads in both cases, and it was fully using those.; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4707443/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127:477,update,updates,477,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127,1,['update'],['updates']
Deployability,"Ok, so this mapping rate looks perfectly normal. Can you share some of these reads so I can see if I can reproduce the error on my end? Also, do you see this issue when / if you use the pre-compiled binary included on the GitHub release page (i.e. just to make sure the problem isn't specific to the bioconda executable)?. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409428971:229,release,release,229,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409428971,1,['release'],['release']
Deployability,"Ok, so using your `while true; do salmon; done` paradigm, I was able to reproduce the issue on your original dataset after a few runs each time. This has made working on the issue much easier. After a lot of debugging and walking through the stack, I'm almost certain the issue is a ""rare"" deadlock bug in the Intel TBB library. They mention having fixed this in the latest release. So, I've updated our CMake file to fetch [that release](https://github.com/01org/tbb/releases/tag/2017_U3). After upgrading to this version of TBB, I've let the data set run all night long (~8 hours so far) and have not seen the hanging behavior. I'll let it keep running for a while, but could you try pulling the latest commit from develop and see if that resolves the problem for you? You'll need to make sure you clean the build directory and remove the previous `CMakeCache.txt` files so that it will pull in and build the new TBB. You'll also need to make sure that these TBB libraries are the ones that are being used by Salmon. Please let me know if this fixes the hanging for you as well (and I'll let you know if I see it again).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267766795:374,release,release,374,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267766795,4,"['release', 'update']","['release', 'releases', 'updated']"
Deployability,"Ok, when I attempt the build the way you say above, I get the following error during CMake:. ```; -- fetch PUFFERFISH exit code 127; CMake Error at CMakeLists.txt:317 (message):; Could not fetch pufferfish source [fetchPufferfish.sh returned exit code; 127]. -- Configuring incomplete, errors occurred!; See also ""/salmon-1.10.0/build/CMakeFiles/CMakeOutput.log"".; ```. It seems `wget`, `curl` and `unzip` were missing, and I had to install them. After that, I was able to build and install. At that point, I was able to reproduce the issue! So, it seems to me the underlying problem is coming from one of the upstream dependencies (i.e. libraries being linked to). I will try see if I can find the offender. In general, we like to statically link salmon for exactly this reason. Outside of package systems with which I am familiar (e.g. conda), we don't have a lot of experience in specifying dependent package version constrains, which I believe to be at fault here.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463973824:433,install,install,433,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463973824,2,['install'],['install']
Deployability,"Okay, now I am on a physical Ubuntu 19.04. I am leaving out most travails. [Don't allow ubuntu gui to install conda.]. Salmon (in the conda evironment) is going differently ! Skip to Try 2. below for success; Try 1.; Index seemed to go the same as before, using the command [from a script]; salmon index -t decoys/gentrome.fa -d decoys/decoys.txt -i salmonIndexDecoyMouse; but then command; salmon quant -p 3 -i salmonIndexDecoyMouse -l A -1 SRR1818187_2.fastq.gz -2 SRR1818187_1.fastq.gz --validateMappings -o Salmontranscripts_quant; Fails as follows, saying it cannot find a .json file(s); ---------------------------------------------------------------------; (salmon) wayne@Ubuntu19:~/rnaseq$ sh salmonQuantDecoy.sh ; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 3 }; ### [ index ] => { salmonIndexDecoyMouse }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR1818187_2.fastq.gz }; ### [ mates2 ] => { SRR1818187_1.fastq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { Salmontranscripts_quant }; Logs will be written to Salmontranscripts_quant/logs; [2019-08-25 11:40:44.518] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-08-25 11:40:44.518] [jointLog] [info] parsing read library format; [2019-08-25 11:40:44.518] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file salmonIndexDeco",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435:102,install,install,102,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435,1,['install'],['install']
Deployability,"Okay, so I've made some progress. After deleting the Cache.txt file I tried to build again at which point I noticed the following:; **WARNING: Target ""salmon"" requests linking to directory ""/users/work/jake/bin/zlib-1.2.11/"". Targets may link only to libraries. CMake is dropping the item.**; **WARNING: Target ""unitTests"" requests linking to directory ""/users/work/jake/bin/zlib-1.2.11/"". Targets may link only to libraries. CMake is dropping the item.**. So I actually went back a step and check my initial cmake command in the ../salmon-0.8.2/build/ directory. It also had the same issue and therefore wasn't building correctly. I started the install again from ../salmon-0.8.2/build/ using the following: . cmake -DBOOST_ROOT=/users/work/jake/bin/boost_1_64_0/ -DZLIB_LIBRARY=/users/work/jake/bin/zlib-1.2.11/zlib.h .. . It seemed to work nicely and I got all the build files to propagate into the ../salmon-0.8.2/build/ directory. From here I ran 'make' which did a whole bunch of things I hadn't seen it do yet, so assumably it was working as intended. This is until it got to the following stage:. Scanning dependencies of target libbwa; [ 48%] Creating directories for 'libbwa'; [ 49%] Performing download step for 'libbwa'; % Total % Received % Xferd Average Speed Time Time Time Current; Dload Upload Total Spent Left Speed; 100 125 0 125 0 0 167 0 --:--:-- --:--:-- --:--:-- 167; 0 0 0 219k 0 0 123k 0 --:--:-- 0:00:01 --:--:-- 326k; bwa-master.tar.gz: OK; bwa-0.7.12.3/.gitignore; bwa-0.7.12.3/.travis.yml; bwa-0.7.12.3/COPYING; bwa-0.7.12.3/ChangeLog; bwa-0.7.12.3/Makefile; bwa-0.7.12.3/NEWS.md; bwa-0.7.12.3/QSufSort.c; bwa-0.7.12.3/QSufSort.h; bwa-0.7.12.3/README-alt.md; bwa-0.7.12.3/README.md; bwa-0.7.12.3/bamlite.c; bwa-0.7.12.3/bamlite.h; bwa-0.7.12.3/bntseq.c; bwa-0.7.12.3/bntseq.h; bwa-0.7.12.3/bwa.1; bwa-0.7.12.3/bwa.c; bwa-0.7.12.3/bwa.h; bwa-0.7.12.3/bwakit/; bwa-0.7.12.3/bwakit/README.md; bwa-0.7.12.3/bwakit/bwa-postalt.js; bwa-0.7.12.3/bwakit/run-HLA; bwa-0.7.12.3/bwak",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873:646,install,install,646,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873,1,['install'],['install']
Deployability,"Oki, so I have updated a couple of things in the latest commit on the develop branch, which should make the things more streamlined. . * `maxNumBarcodes`: As you have initially used `maxNumBarcodes` which is by default set to 100k it means. by default alevin quantifies 100k CBs which includes both the low and high confidence CB count. You can change this number accordingly to set the universe of the top CB to quantify.; * `KeepCBFraction` : It defines what fraction of `maxNumBarcodes` to be used as the high confidence barcodes and should definitely generate the quants for. If set to 1 then everything is high confidence and the whitelisting cannot be performed. Thanks to this issue, alevin will not fail without error when there is no low confidence CB is found instead it checks if the number of low confidence CB is less than `lowRegionMinBarcodes` (default to 200), alevin will warn and not perform the whitelisting.; * `freqThreshold`: This is used to filter out most obvious cases to filter out CB with frequency less than set by the parameter (default to 10). Hope this help ! I am also testing on my end for any other potential bug. Please let me know if you get a chance to check the develop branch .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503396823:15,update,updated,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503396823,1,['update'],['updated']
Deployability,"On a fresh conda install,. ```; conda create -n slm2 -y -c bioconda salmon; ```; yields a broken salmon:; ```; $ conda activate slm2; (slm2) ggg298-43@farm:~$ salmon; salmon: error while loading shared libraries: libboost_iostreams.so.1.60.0: cannot open shared object file: No such file or directory; ```. This seems to be because I'm missing conda-forge; this:. ```; conda create -n slm3 -y -c conda-forge -c bioconda salmon; conda activate slm3; salmon; ```; works fine!. Nothing needs to be done, and I will update as I debug, but I wanted to put this here for google bait.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/480:17,install,install,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/480,2,"['install', 'update']","['install', 'update']"
Deployability,"On my system, `cmake` found (somehow, I didn't tell it) TBB that is installed in `/usr/local/opt/tbb/lib/libtbb.dylib`. What does `otool -L salmon` report on your system after `make install`?. ``` sh; ❯❯❯ otool -L ~/tmp/salmon/bin/salmon; /Users/sjackman/tmp/salmon/bin/salmon:; /usr/lib/libz.1.dylib (compatibility version 1.0.0, current version 1.2.5); /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1226.10.1); /usr/lib/libbz2.1.0.dylib (compatibility version 1.0.0, current version 1.0.5); /usr/local/opt/tbb/lib/libtbb.dylib (compatibility version 0.0.0, current version 0.0.0); /usr/local/opt/tbb/lib/libtbbmalloc.dylib (compatibility version 0.0.0, current version 0.0.0); /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 120.1.0); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239594511:68,install,installed,68,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239594511,2,['install'],"['install', 'installed']"
Deployability,"On the system I'm trying to install Salmon 0.4.2 on, downloading from `ftp://` is blocked for security reasons. Therefore, the automagic download the Jellyfish 2.1.3 source tarball fails. I tried adjusting the `CMakeLists.txt` files to use the latest Jellyfish 2.2.3 instead, but this leads to an issue with a Jellyfish include file not being found:. ```; checking whether we are using the GNU C compiler... In file included from /tmp/Salmon/0.4.2/intel-2015a/salmon-0.4.2/src/merge_files.cc(17):; /tmp/Salmon/0.4.2/intel-2015a/salmon-0.4.2/include/merge_files.hpp(21): catastrophic error: cannot open source file ""jellyfish/err.hpp""; #include <jellyfish/err.hpp>; ^. compilation aborted for /tmp/Salmon/0.4.2/intel-2015a/salmon-0.4.2/src/merge_files.cc (code 4); make[2]: *** [src/CMakeFiles/salmon_core.dir/merge_files.cc.o] Error 4; ```. This is weird, because the correct `include` directory is shown in the compiler command, and the file is there!. Here's my patch. Any idea what may be wrong with it, or which different approach I could try to get this to work?; I also tried using the `2.1.3.tar.gz` tarball from GitHub, but after adding `autoreconf -i` to the `CONFIGURE_COMMAND`, this leads to the same problem. ``` diff; --- salmon-0.4.2/CMakeLists.txt.orig 2015-06-15 02:31:09.000000000 +0200; +++ salmon-0.4.2/CMakeLists.txt 2015-08-18 21:13:29.684010359 +0200; @@ -357,14 +366,14 @@; message(""==================================================================""); ExternalProject_Add(libjellyfish; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; - URL ftp://ftp.genome.umd.edu/pub/jellyfish/jellyfish-2.1.3.tar.gz; - SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.1.3; + URL https://github.com/gmarcais/Jellyfish/releases/download/v2.2.3/jellyfish-2.2.3.tar.gz; + SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.2.3; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; - CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.1.3/configure --p",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/11:28,install,install,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/11,2,"['install', 'patch']","['install', 'patch']"
Deployability,"One fast way using pseudo-alignments should be Kallisto+[Manta|Pizzly], but I haven't tried that myself. We decided to go with full transcriptome alignments instead and integrated EricScript into bcbio. We'd still be interested in something more modern, though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-280827732:169,integrat,integrated,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-280827732,1,['integrat'],['integrated']
Deployability,"Oops. Just saw that `master` is already pointing at boost 1_59. What branch should one use for a new install ? master, 0.5.0 ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/23#issuecomment-153149314:101,install,install,101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/23#issuecomment-153149314,1,['install'],['install']
Deployability,Or it should honour `$MAKEFLAGS` somehow. Patching now in brew: https://github.com/brewsci/homebrew-bio/pull/747. `CMakelist.txt =~ s/-d0 -j2/\$MAKEFLAGS/`,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/412#issuecomment-525503233:42,Patch,Patching,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/412#issuecomment-525503233,1,['Patch'],['Patching']
Deployability,"Our lab makes heavy use of Salmon. Its a great tool we use it almost daily. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; Salmon. **Describe the bug**; While digging through the log files to try and figure out why some of our biologic samples have low mapping rates I discovered a warning. . [2021-06-22 12:39:41.282] [jointLog] [warning] Only 1920342 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2021-06-22 12:39:41.282] [jointLog] [info] Mapping rate = 55.5444%. about half of our samples have over 90% mapping rates. . Any idea what this warning means?. **To Reproduce**; Steps and data to reproduce the behavior:. salmon 1.4.0 ; Linux mustard 3.10.0-862.6.3.el7.x86_64 #1 SMP Tue Jun 26 16:32:21 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux. $ cat /etc/redhat-release; CentOS Linux release 7.5.1804 (Core) . I think when I installed salmon I could not install the 1.5.x version. I forgot why; ```; function runSalmon() {; # runs salmon on one sample and outputs to that directory ; salmonIndexDir=""$1""; rightReads=""$2""; leftReads=""$3""; outputDir=""$4"". #set -x # turn debug on ; # set +x # turn debug off . if [[ ! -f ""$outputDir""/quant.sf ]]; then. 	mkdir -p ""$outputDir"". # printf ""##############\n"" ; # printf ""warning --minAssignedFrags is set to $minNumFrags to enable test data set\n"" ; # minNumFrags=1 ; # --minAssignedFrags=$minNumFrags \ ; # printf ""##############\n"" . #if [[ -f ""$inputDir""/output_single_end.fq.gz ]]; then . numThr=12; salmon quant \; -i $salmonIndexDir \; --libType A \; -1 ""${rightReads}"" \; -2 ""${leftReads}"" \; -p $numThr \; --recoverOrphans \; --validateMappings \; --gcBias \; --seqBias \; --rangeFactorizationBins 4 \; --writeUnmappedNames \; --output ${outputDir}. salmonRet=$?; if [ $salmonRet -ne 0 ]; then; echo ERROR salmon ""$rightReads"" returned exit status ""$exitStatus""; continue; fi. #fi ; else; echo ""[INFO] skip",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/677:905,release,release,905,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/677,4,"['install', 'release']","['install', 'installed', 'release']"
Deployability,"P_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 10740; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda00000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffefe5ea000; mprotect(0x7ffefe5ea000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff3e5e9ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff3e5ea9d0, tls=0x7fff3e5ea700, child_tidptr=0x7fff3e5ea9d0) = 10741; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbd200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffebe5e9000; mprotect(0x7ffebe5e9000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffefe5e8ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffefe5e99d0, tls=0x7ffefe5e9700, child_tidptr=0x7ffefe5e99d0) = 10742; clock_gettime(CLOCK_REALTIME, {1491423878, 504035343}) = 0; gettid() = 10693; clock_gettime(CLOCK_REALTIME, {1491423878, 507735356}) = 0; stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", {st_mode=S_IFREG|0775, st_size=96, ...}) = ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:70962,pipeline,pipeline,70962,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"P_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 14650; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda00000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffefe5ea000; mprotect(0x7ffefe5ea000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff3e5e9ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff3e5ea9d0, tls=0x7fff3e5ea700, child_tidptr=0x7fff3e5ea9d0) = 14651; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbd200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffebe5e9000; mprotect(0x7ffebe5e9000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffefe5e8ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffefe5e99d0, tls=0x7ffefe5e9700, child_tidptr=0x7ffefe5e99d0) = 14652; clock_gettime(CLOCK_REALTIME, {1491424829, 790500042}) = 0; gettid() = 14648; clock_gettime(CLOCK_REALTIME, {1491424829, 791313810}) = 0; stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", {st_mode=S_IFREG|0775, st_size=96, ...}) = ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:151863,pipeline,pipeline,151863,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"P_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 32683; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda00000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffefe5ea000; mprotect(0x7ffefe5ea000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff3e5e9ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff3e5ea9d0, tls=0x7fff3e5ea700, child_tidptr=0x7fff3e5ea9d0) = 32684; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbd200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffebe5e9000; mprotect(0x7ffebe5e9000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffefe5e8ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffefe5e99d0, tls=0x7ffefe5e9700, child_tidptr=0x7ffefe5e99d0) = 32685; clock_gettime(CLOCK_REALTIME, {1491423877, 940907968}) = 0; gettid() = 32681; clock_gettime(CLOCK_REALTIME, {1491423877, 941299576}) = 0; stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", {st_mode=S_IFREG|0775, st_size=96, ...}) = ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:34186,pipeline,pipeline,34186,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"P_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 51998; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda00000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffefe5ea000; mprotect(0x7ffefe5ea000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff3e5e9ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff3e5ea9d0, tls=0x7fff3e5ea700, child_tidptr=0x7fff3e5ea9d0) = 51999; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbd200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffebe5e9000; mprotect(0x7ffebe5e9000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffefe5e8ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffefe5e99d0, tls=0x7ffefe5e9700, child_tidptr=0x7ffefe5e99d0) = 52000; clock_gettime(CLOCK_REALTIME, {1491424815, 587265106}) = 0; gettid() = 51996; clock_gettime(CLOCK_REALTIME, {1491424815, 588110132}) = 0; stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", {st_mode=S_IFREG|0775, st_size=96, ...}) = ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:109544,pipeline,pipeline,109544,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"Packed] 10 iterations done. 87569268 characters processed.; [BWTIncConstructFromPacked] 20 iterations done. 164630980 characters processed.; [BWTIncConstructFromPacked] 30 iterations done. 233119636 characters processed.; [BWTIncConstructFromPacked] 40 iterations done. 293988548 characters processed.; [BWTIncConstructFromPacked] 50 iterations done. 348084948 characters processed.; [BWTIncConstructFromPacked] 60 iterations done. 396161956 characters processed.; [BWTIncConstructFromPacked] 70 iterations done. 438888868 characters processed.; [BWTIncConstructFromPacked] 80 iterations done. 476860644 characters processed.; [BWTIncConstructFromPacked] 90 iterations done. 510606036 characters processed.; [BWTIncConstructFromPacked] 100 iterations done. 540594980 characters processed.; [BWTIncConstructFromPacked] 110 iterations done. 567245236 characters processed.; [BWTIncConstructFromPacked] 120 iterations done. 590928020 characters processed.; [bwa_index] 279.06 seconds elapse.; [bwa_index] Update BWT... 1.72 sec; [bwa_index] Pack forward-only FASTA... 1.90 sec; [bwa_index] Construct SA from BWT and Occ... 59.56 sec; [2018-06-25 19:34:53.084] [jLog] [info] done building index; ```. Doh, something unexpected from the logs, isn't it?. ```; $ ls -latr ftp.ensembl.org/pub/release-92/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all; total 8374704; drwx------. 3 mmokrejs mmokrejs 4096 Jun 25 19:25 ..; -rw-r--r--. 1 mmokrejs mmokrejs 36158409 Jun 25 19:26 rsd.bin; -rw-r--r--. 1 mmokrejs mmokrejs 423777 Jun 25 19:26 duplicate_clusters.tsv; -rw-r--r--. 1 mmokrejs mmokrejs 294997212 Jun 25 19:26 txpInfo.bin; -rw-r--r--. 1 mmokrejs mmokrejs 1157068836 Jun 25 19:26 sa.bin; -rw-r--r--. 1 mmokrejs mmokrejs 1779709484 Jun 25 19:29 hash.bin; -rw-r--r--. 1 mmokrejs mmokrejs 75 Jun 25 19:29 refInfo.json; -rw-r--r--. 1 mmokrejs mmokrejs 9816 Jun 25 19:29 quasi_index.log; -rw-r--r--. 1 mmokrejs mmokrejs 666 Jun 25 19:29 header.json; -rw-r--r--. 1 mmokrejs mmokrejs 304768324 Jun 25 19:33",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/242:15091,Update,Update,15091,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/242,1,['Update'],['Update']
Deployability,"Perfect, thank you for the quick update!; Emily",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/118#issuecomment-278461497:33,update,update,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/118#issuecomment-278461497,1,['update'],['update']
Deployability,Please see attached patch here. I did not realized my writing was stylized which; wiped out correct syntax. Nadya; [salmon-1.1.0.patch.txt](https://github.com/COMBINE-lab/salmon/files/4382067/salmon-1.1.0.patch.txt),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-603936569:20,patch,patch,20,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-603936569,3,['patch'],['patch']
Deployability,"Presumably in part because of the conda-forge packages, if working from a relatively clean miniconda install:. conda install r-essential; followed by; conda install salmon. causes R to fail to start, throwing the error:; ""/home/timp/miniconda3/lib/R/bin/exec/R: symbol lookup error: /home/timp/miniconda3/lib/R/bin/exec/../../lib/../../libreadline.so.6: undefined symbol: PC"". This seems to be a relatively known ncurses/readline linked bug (https://github.com/conda-forge/rpy2-feedstock/issues/1) - but it seems solved in normal channels. Not sure exactly why it's cropping up here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/147:101,install,install,101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/147,3,['install'],['install']
Deployability,Problem Installing From Source,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/309:8,Install,Installing,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/309,1,['Install'],['Installing']
Deployability,Problem Installing Salmon,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/778:8,Install,Installing,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/778,1,['Install'],['Installing']
Deployability,Problem installing salmon,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/936:8,install,installing,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/936,1,['install'],['installing']
Deployability,"R17122012 --tgMap transcriptome_splici_fl52/transcriptome_splici_fl52_t2g.tsv -p 28 --sciseq3 --justAlign`; I then took the output into alevin-fry to create a generate-permit-list and it gives me the error that salmon hasn't added the extra bps to account for the chemistry; ""thread 'main' panicked at 'assertion failed: `(left == right)`; left: `20`,; right: `19`: found barcodes of different lenghts 20 and 19', src/cellfilter.rs:203:13; note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace""; Thus I re-ran salmon alevin without the --justAlign flag and it seems to hit a different error; ""### alevin (dscRNA-seq quantification) v1.9.0; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ index ] => { af_splici/dm6_splici_idx/ }; ### [ libType ] => { ISR }; ### [ mates1 ] => { data/SRR17122012_1.fastq }; ### [ mates2 ] => { data/SRR17122012_2.fastq }; ### [ output ] => { SRR17122012 }; ### [ tgMap ] => { transcriptome_splici_fl52/transcriptome_splici_fl52_t2g.tsv }; ### [ threads ] => { 28 }; ### [ sciseq3 ] => { }. [2022-11-28 21:13:57.772] [alevinLog] [info] Found all transcripts to gene mappings; [2022-11-28 21:13:57.781] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 10 Million barcodes. [2022-11-28 21:14:01.454] [alevinLog] [info] Done barcode density calculation.; [2022-11-28 21:14:01.454] [alevinLog] [info] # Barcodes Used: 1 / 10285890.; [2022-11-28 21:14:01.455] [alevinLog] [error] Can't find left Boundary.; Please Report this issue on github."". Specifically, please provide at least the following information:. * Which version of salmon was used? salmon (1.9.0); alevin-fry (0.8.0) ; * How was salmon installed (compiled, downloaded executable, through bioconda)? Conda install; * Which reference (e.g. transcriptome) was used? Drosophila melanogaster (BDGP6.32 (GCA_000001215.4)); ; **Desktop (please complete the following information):**; - OS: Ubuntu Linux. Thanks in advance for all your help regarding this!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/813:2073,install,installed,2073,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/813,2,['install'],"['install', 'installed']"
Deployability,"RCm38.86.gtf.gz. all from ensembl version 86. ## Workflow; - I built a STAR index with the GTF and genome FASTA files listed above. ; - The FASTQ files were extracted from the SRA experiment with [fastq-dump](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=toolkit_doc&f=fastq-dump).; - Reads were aligned with STAR to the index and `unsorted` alignments to the transcriptome were returned (this keeps the paired-ends next to each other). I noticed that the cDNA FASTA files from ensembl include the transcript version, e.g. `ENSMUST00000178537.1` in the FASTA header. The GTF file specifies the transcript id and its version in different fields. Therefore, the STAR index does not include the version suffix. Instead, only the transcript ids are listed, e.g. `ENSMUST00000178537`. To provide a FASTA file with transcript identifiers that match those in STAR's BAM file, I pre-processed Ensembl's FASTA file with the following command:. ```; wget ftp://ftp.ensembl.org/pub/release-86/fasta/mus_musculus/cdna/Mus_musculus.GRCm38.cdna.all.fa.gz; gunzip Mus_musculus.GRCm38.cdna.all.fa.gz; cut -f1 -d ""."" Mus_musculus.GRCm38.cdna.all.fa > transcripts_unversioned.fa. head transcripts_unversioned.fa; >ENSMUST00000178537; GGGACAGGGGGC; >ENSMUST00000178862; GGGACTGGGGGGGC; >ENSMUST00000196221; ATGGCATAT; >ENSMUST00000179664; ATGGCATATCA; >ENSMUST00000177564; ATCGGAGGGATACGAG; [truncated]; ```. Then I try to run `salmon`:. ```; wget ftp://ftp.ensembl.org/pub/release-86/gtf/mus_musculus/Mus_musculus.GRCm38.86.gtf.gz; gunzip Mus_musculus.GRCm38.86.gtf.gz; salmon quant -t transcripts_unversioned.fa -g Mus_musculus.GRCm38.86.gtf -l IU -p 1 -o quantitation -a subsample.bam --seqBias --gcBias; ```. but get the segmentation fault. Omitting the `--seqBias --gcBias` options makes it work. Perhaps you can already spot where I am doing something wrong? If not, you can find the subsample.bam file [here](https://drive.google.com/open?id=0BzX9viKJksNtak0xako0VXptLW8). (The other files are publicall",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261744459:1890,release,release-,1890,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261744459,1,['release'],['release-']
Deployability,"RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:8330,pipeline,pipeline,8330,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:9100,install,install,9100,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,8,"['install', 'pipeline']","['install', 'pipeline']"
Deployability,"Rather than hang you up in any way waiting on a release that adds ancillary improvements, I'm just putting an updated binary right here that addresses this issue. Please let me know if this allows you to run your dataset on the large index successfully.; [SalmonBeta-0.6.5-pre_CentOS5.tar.gz](https://github.com/COMBINE-lab/salmon/files/197982/SalmonBeta-0.6.5-pre_CentOS5.tar.gz)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-203990167:48,release,release,48,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-203990167,2,"['release', 'update']","['release', 'updated']"
Deployability,ReadTheDoc not updated for Salmon 1.0.0?,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/456:15,update,updated,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/456,1,['update'],['updated']
Deployability,"Regarding the last point, cc @Gaura. Regarding a description of the read geometry, it can be found in the release notes for salmon 1.4.0 [here](https://github.com/COMBINE-lab/salmon/releases/tag/v1.4.0). Though, we should certainly add something to the full docs.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/816#issuecomment-1344442434:106,release,release,106,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/816#issuecomment-1344442434,2,['release'],"['release', 'releases']"
Deployability,Released in v1.9.0 🎉 ! Let us know if you have any questions about or trouble with the feature.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/756#issuecomment-1164760347:0,Release,Released,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/756#issuecomment-1164760347,1,['Release'],['Released']
Deployability,"Rhapsody has introduced a new, shorter cell barcode specification to work with 51bp R1, which looks like this:. ```; 5' PFX - CLS1 - L1 - CLS2 - L2 - CLS3 - UMI - poly(T); 9 4 9 4 9 8 8; [1-9] [14-22] [27-35][36-43]; ```. The linker sequences are as follows:. L1: `GTGA`; L2: `GACA`. In other words,. --umi-geometry '1[36-43]' --bc-geometry '1[1-9,14-22,27-35]' --read-geometry '2[1-end]'. **However...** [update]. In order to remove the need for Lambda spike-ins on Illumina runs, Rhapsody has included a 0-3bp cell barcode prefix, where either nothing, or `A/GT/TCA` are added to the front of some cell barcodes. Here are the full descriptions:. ```; # Long sequence:; # 0123456789012345678901234567890123456789012345678901234567890123456789012345; # [--BC1--][----L1----][--BC2--][----L02----][--BC3--][-UMI1-][TTTTTTTTTTTTTT]; # L1 = ACTGGCCTGCGA; L2 = GGTAGCGGTGACA; # Short sequence:; # 012345678901234567890123456789012345678901234567890; # [--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTTTT]; # L1 = GTGA; L2 = GACA; # Note: short sequence can also be prepended with A/GT/TCA to improve Illumina base; # call distributions, i.e.; # [--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTTTT]; # A[--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTTT]; # GT[--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTT]; # TCA[--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTT]; ```. This means that the regions defined in the geometry specification above can appear up to 3bp away from their expected region. I've updated my barcode squishing script ([here](https://gitlab.com/gringer/bioinfscripts/-/blob/master/synthSquish.pl)) to account for this. The script identifies the cell barcode regions, corrects cell barcode sequences according to the Rhapsody Bioinformatics manual, and then shifts the linker sequences to after the UMI region, i.e.:. # 012345678901234567890123456789012345678901234567890...; # [--BC1--][--BC2--][--BC3--][-UMI1-][L1][L2][TTTTTT...]. [The prefix sequence is discarded]. After using this scr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-1277030250:406,update,update,406,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-1277030250,1,['update'],['update']
Deployability,"Right I've been checking it without the trailing character as well, I changed to leaving that out. . Oddly, my index doesn't have the decimals at all, just continuous ENSTxx, unlike the examples you and Rob provided. I redownloaded the new release, same result. No duplicate in my grep query, which would lead to getting the quant for both transcripts. Not being filtered by salmon as duplicates. I also downloaded the same version in Rob's example above, indexed with latest salmon, with the same result. At a loss right now. I don't know why this is.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429501783:156,continuous,continuous,156,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429501783,2,"['continuous', 'release']","['continuous', 'release']"
Deployability,"Right, in short `salmon index -t txome_fasta -i txome_index` should work and both the versions of salmon (v0.15 and v1.0) is available on bioconda, check [here](https://bioconda.github.io/recipes/salmon/README.html), you may wanna try [force](https://docs.conda.io/projects/conda/en/latest/commands/update.html) update of conda. I think the confusion is you are thinking of the concept of Selective Alignment as the same as aligning to transcriptome w/ decoys (can be genome or mashmap based). Although they are related methods but the concept of Selective Alignment predates the idea of decoy based alignment, checkout [this](https://dl.acm.org/citation.cfm?id=3233589) paper from our lab where we discuss how Selectively Aligning difficult reads to just the transcriptome itself can result in improved quantification estimates compared to quasi or pseduo alignment. To summarize: ; In version 1.0; A) SA: The mashmap and bedtools based pipeline which follows old SalmonTools based pipeline.; B) SAF: Inbuilt salmon pipeline to consume genome and follows this pipeline.; C) If you don't provide any decoys, salmon will do Selective Alignment just on the transcriptome. The Release notes you quoted just means you cannot disable this feature i.e. you cannot fall back to quasi-mapping (in quasi mapping there is no alignment of the reads at all). In version 0.15.0; You cannot provide decoys and the transcriptome based mapping performed in this version would be quasi-mapping i.e. no Alignment of reads. Hope it helps .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195321:299,update,update,299,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195321,7,"['Release', 'pipeline', 'update']","['Release', 'pipeline', 'update']"
Deployability,"Right, so at the end of the quantification pipeline you should have the file `whitelist.txt` which you can use as a high confidence barcodes and filter the full matrix file.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/739#issuecomment-1024658484:43,pipeline,pipeline,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/739#issuecomment-1024658484,1,['pipeline'],['pipeline']
Deployability,"Right, the issue seems to be that the right binary is not getting created. My (re)compilation using the same script you shared above seems to be giving different help.; ```; alevin-specific Options:; -v [ --version ] print version string; -h [ --help ] produce help message; -o [ --output ] arg Output quantification directory.; -p [ --threads ] arg (=1) The number of threads to use; concurrently.; --tgMap arg transcript to gene map tsv file; --dropseq Use DropSeq Single Cell protocol for; the library; --chromiumV3 Use 10x chromium v3 Single Cell; protocol for the library.; --chromium Use 10x chromium v2 Single Cell; protocol for the library.; --gemcode Use 10x gemcode v1 Single Cell protocol; for the library.; --celseq Use CEL-Seq Single Cell protocol for; the library.; --celseq2 Use CEL-Seq2 Single Cell protocol for; the library.; ```. May I suggest removing the `CMakeCache.txt` file from the build folder of salmon and running `make -j 4 install` again. After recompilation using the `salmon` binary inside the `bin` folder should ideally give you the above updated help. However, If it doesn't resolve after that, I am compiling a linux binary and will share it to you to be used directly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443518366:952,install,install,952,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443518366,2,"['install', 'update']","['install', 'updated']"
Deployability,"Right; so this has been fixed upstream and the limitation will be removed in the next release. As @k3yavi says, one option is to modify the reference input names to be of length <255. The other option is to make use of the 0.15.0 release, which does not have this limitation, until the next release that fixes this under the pufferfish-based index.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/451#issuecomment-558449963:86,release,release,86,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/451#issuecomment-558449963,3,['release'],['release']
Deployability,Rob mentioned to us at some point that this was possibly on the roadmap. It would really be a very useful feature. Any updates on this?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/138#issuecomment-585340775:119,update,updates,119,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/138#issuecomment-585340775,1,['update'],['updates']
Deployability,"Rob, thank you very much for your response. I am already patching the source as i need to work; with stable and not development versions. Best regards, Nadya.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/496#issuecomment-603335132:57,patch,patching,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/496#issuecomment-603335132,1,['patch'],['patching']
Deployability,"Rob,. 	I let you know on the forum page, but just ot make sure it worked and I was ; able to index my transcriptome. Thank you!. Best wishes,; Rich; > On Apr 17, 2018, at 9:44 AM, Rob Patro <notifications@github.com> wrote:; > ; > Hi Rich,; > ; > The issue with pre-compiled OSX binaries is that they are difficult to make portable across OSX versions. This is why we strongly suggest installing Salmon (especially for OSX) through Bioconda. This greatly eases installation and updating, and doesn't require admin privileges. On OSX, you can try the following:; > ; > $ conda config --add channels conda-forge; > $ conda config --add channels bioconda; > $ conda create -n salmon salmon=0.9.1; > ; > This should take care of all relevant dependencies as well as e.g. library locations and placement. Could you please give this a try and let me know if it works for you?; > ; > Best,; > Rob; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.; > . Richard A. Friedman, PhD; Associate Research Scientist,; Biomedical Informatics Shared Resource; Herbert Irving Comprehensive Cancer Center (HICCC); Lecturer,; Department of Biomedical Informatics (DBMI); Room 825; Irving Cancer Research Center ; Columbia University Herbert and Florence Irving Medical Center; 1130 St. Nicholas Ave; New York, NY 10032; (212)851-4765 (voice); raf4@cumc.columbia.edu. http://www.columbia.edu/~raf4/index.html. “Will there still be ""Classics Illustrated” by the time I have children? I cannot; imagine raising kids without ""Classics Illustrated” .” -Rose Friedman, age 20",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-382031768:385,install,installing,385,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-382031768,2,['install'],"['installation', 'installing']"
Deployability,"Rob,. Brilliant - I forgot that I built the boost libraries from whatever version of gcc was on the standard distribution. I have included -DFETCH_BOOST=TRUE, do you know why I am receiving the following error regarding a missing when executing make?. [ 5%] Performing configure step for 'libboost'; Building Boost.Build engine with toolset gcc... tools/build/src/engine/bin.linuxx86_64/b2; Detecting Python version... 2.7; Detecting Python root... /usr; Unicode/ICU support for Boost.Regex?... not found.; Generating Boost.Build configuration in project-config.jam... Bootstrapping is done. To build, run:. ./b2. To adjust configuration, edit 'project-config.jam'.; Further information:. - Command line help:; ./b2 --help. - Getting started guide:; http://www.boost.org/more/getting_started/unix-variants.html. - Boost.Build documentation:; http://www.boost.org/build/doc/html/index.html. using gcc : : /opt/gcc-8.2.0/bin/g++ ); [ 6%] Performing build step for 'libboost'; opt.jam: No such file or directory; /opt/salmon/external/boost_1_66_0/tools/build/src/build/toolset.jam:43: in toolset.using; ERROR: rule ""opt.init"" unknown in module ""toolset"".; /opt/salmon/external/boost_1_66_0/tools/build/src/build-system.jam:461: in process-explicit-toolset-requests; /opt/salmon/external/boost_1_66_0/tools/build/src/build-system.jam:527: in load; /opt/salmon/external/boost_1_66_0/tools/build/src/kernel/modules.jam:295: in import; /opt/salmon/external/boost_1_66_0/tools/build/src/kernel/bootstrap.jam:139: in boost-build; /opt/salmon/external/boost_1_66_0/boost-build.jam:17: in module scope; make[2]: *** [libboost-prefix/src/libboost-stamp/libboost-build] Error 1; make[1]: *** [CMakeFiles/libboost.dir/all] Error 2; make: *** [all] Error 2. Thanks for all your help!. Nate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436834099:530,configurat,configuration,530,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436834099,2,['configurat'],['configuration']
Deployability,SE=''; COND_INTERNAL_SHA256_TRUE=''; COND_LZMADEC_FALSE='#'; COND_LZMADEC_TRUE=''; COND_LZMAINFO_FALSE='#'; COND_LZMAINFO_TRUE=''; COND_LZMALINKS_FALSE='#'; COND_LZMALINKS_TRUE=''; COND_MAIN_DECODER_FALSE='#'; COND_MAIN_DECODER_TRUE=''; COND_MAIN_ENCODER_FALSE='#'; COND_MAIN_ENCODER_TRUE=''; COND_SCRIPTS_FALSE='#'; COND_SCRIPTS_TRUE=''; COND_SHARED_FALSE=''; COND_SHARED_TRUE=''; COND_SMALL_FALSE=''; COND_SMALL_TRUE='#'; COND_SYMVERS_FALSE=''; COND_SYMVERS_TRUE='#'; COND_THREADS_FALSE=''; COND_THREADS_TRUE=''; COND_W32_FALSE=''; COND_W32_TRUE='#'; COND_XZDEC_FALSE='#'; COND_XZDEC_TRUE=''; COND_XZ_FALSE='#'; COND_XZ_TRUE=''; CPP=''; CPPFLAGS=''; CYGPATH_W='echo'; DEFS=''; DEPDIR='.deps'; DLLTOOL=''; DSYMUTIL=''; DUMPBIN=''; ECHO_C='\c'; ECHO_N=''; ECHO_T=''; EGREP=''; EXEEXT=''; FGREP=''; GETOPT_H=''; GETTEXT_MACRO_VERSION=''; GMSGFMT=''; GMSGFMT_015=''; GREP=''; HAVE_VISIBILITY=''; INSTALL_DATA='${INSTALL} -m 644'; INSTALL_PROGRAM='${INSTALL}'; INSTALL_SCRIPT='${INSTALL}'; INSTALL_STRIP_PROGRAM='$(install_sh) -c -s'; INTLLIBS=''; INTL_MACOSX_LIBS=''; LD=''; LDFLAGS=''; LIBICONV=''; LIBINTL=''; LIBOBJS=''; LIBS=''; LIBTOOL=''; LIPO=''; LN_EXEEXT='$(EXEEXT)'; LN_S='ln -s'; LTLIBICONV=''; LTLIBINTL=''; LTLIBOBJS=''; LT_SYS_LIBRARY_PATH=''; MAKEINFO='${SHELL} /Users/jeremybono/Downloads/salmon-1.10.1/external/xz-5.2.2/build-aux/missing makeinfo'; MANIFEST_TOOL=''; MKDIR_P='build-aux/install-sh -c -d'; MSGFMT=''; MSGFMT_015=''; MSGMERGE=''; NM=''; NMEDIT=''; OBJDUMP=''; OBJEXT=''; OTOOL64=''; OTOOL=''; PACKAGE='xz'; PACKAGE_BUGREPORT='lasse.collin@tukaani.org'; PACKAGE_NAME='XZ Utils'; PACKAGE_STRING='XZ Utils 5.2.2'; PACKAGE_TARNAME='xz'; PACKAGE_URL='http://tukaani.org/xz/'; PACKAGE_VERSION='5.2.2'; PATH_SEPARATOR=':'; POSIX_SHELL='/bin/sh'; POSUB=''; PREFERABLY_POSIX_SHELL='/bin/sh'; PTHREAD_CC=''; PTHREAD_CFLAGS=''; PTHREAD_LIBS=''; RANLIB=''; RC=''; SED=''; SET_MAKE=''; SHELL='/bin/sh'; STRIP=''; USE_NLS=''; VERSION='5.2.2'; XGETTEXT=''; XGETTEXT_015=''; XGETTEXT_EXT,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/912:13042,INSTALL,INSTALL,13042,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/912,3,['INSTALL'],['INSTALL']
Deployability,"SRR898/009/SRR8985039/SRR8985039_1.fastq.gz	ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR898/009/SRR8985039/SRR8985039_2.fastq.gz; ```; (renamed to cdna*.fastq.gz and barcodes.fastq.gz internal to workflow). * Which which program options were used?. ```; # Do a pre-run to derive a starting whitelist, see https://github.com/COMBINE-lab/salmon/issues/362. salmon alevin -l ISR -1 $(ls barcodes*.fastq.gz | tr '\n' ' ') -2 $(ls cdna*.fastq.gz | tr '\n' ' ') --chromium -i salmon_index -p 12 -o SAMN11526602_pre --tgMap transcript_to_gene.txt --dumpFeatures --noQuant. # Derive a relaxed whitelist, removing only the most obvious junk . if [ $? -eq 0 ]; then ; awk '{ if ($2 > 10) { print $1} }' SAMN11526602_pre/alevin/raw_cb_frequency.txt > pre_whitelist.txt; fi. # Supply the whitelist to the main Alevin run. salmon alevin -l ISR -1 $(ls barcodes*.fastq.gz | tr '\n' ' ') -2 $(ls cdna*.fastq.gz | tr '\n' ' ') --chromium -i salmon_index -p 12 -o SAMN11526602_tmp --tgMap transcript_to_gene.txt --whitelist pre_whitelist.txt --forceCells $(cat pre_whitelist.txt | wc -l | tr -d '\n') --dumpMtx; ```. **Expected behavior**; MTX files without references to out-of-range columns. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. ```; Linux hx-noah-63-15.ebi.ac.uk 3.10.0-693.5.2.el7.x86_64 #1 SMP Fri Oct 13 10:46:25 EDT 2017 x86_64 GNU/Linux. LSB Version:	:core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch; Distributor ID:	RedHatEnterpriseServer; Description:	Red Hat Enterprise Linux Server release 7.4 (Maipo); Release:	7.4; Codename:	Maipo; ```. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/431:3997,release,release,3997,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/431,2,"['Release', 'release']","['Release', 'release']"
Deployability,Salmon 1.1.0 auto update check stalled,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486:18,update,update,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486,1,['update'],['update']
Deployability,Salmon homebrew install broken,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/142:16,install,install,16,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/142,1,['install'],['install']
Deployability,Salmon in MetaWrap needs to be updated,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/423:31,update,updated,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/423,1,['update'],['updated']
Deployability,Salmon installation error,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/551:7,install,installation,7,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/551,1,['install'],['installation']
Deployability,Salmon installation problem,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/915:7,install,installation,7,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/915,1,['install'],['installation']
Deployability,"Salmon version: 0.13.1 (installed via pre-compiled binary). I used salmon to quantify some samples and wanted to use the `quantmerge` command to produce a combined table. However, the merged table I got as output only contained 17 lines (of 52228 in the quant.genes.sf files). I was able to identify that the problem was related somehow to the ""Name"" column itself, although I didn't find any obvious pattern for failure. For example, if I rename all the genes to simply ""1"", ""2"", ... and then `quantmerge`, I get a properly combined table with all samples/genes. Looking back at the ""original"" data with the gene names, I find that the truncated merged table consistently/always truncates immediately *after* processing some gene names. For example, the 16th gene name in my ""quant.genes.sf"" table happens to be ""Erdr1"". If this line is moved to the top of that file, then the merged table will truncate at 2 (the header counting for one of those, obviously). Unfortunately, it's not just ""Erdr1"". If that line is moved to the end of the file, or deleted entirely, there is another failure at gene ""Gm28674"", which happens to be the 19th gene. And so on for a very large number of names (I gave up after removing ~30 one at a time). I've now tested with a few different samples and with a number of randomly selected subsets of the original quant files and the behavior is consistent. I can't figure out what the pattern is, but ""Erdr1"", ""Gm28674"", and all the other genes I discovered with my ad-hoc process above, always cause `quantmerge` to truncate the output.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/356:24,install,installed,24,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/356,1,['install'],['installed']
Deployability,Salom 0.9.1 gives errors when configuring and doesn't find installed libraries,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181:59,install,installed,59,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181,1,['install'],['installed']
Deployability,"Same error here, with a fresh (this morning) install of anaconda3-4.40 on Linux64-bit and a first-time install of salmon through bioconda. This may be premature / just plain incorrect, but [this post](https://github.com/ContinuumIO/anaconda-recipes/issues/56) mentioned issues with the default version of readline, so on a hunch I installed readline from conda-forge and then reinstalled salmon. The above errors disappear (still waiting on other errors).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/147#issuecomment-324627178:45,install,install,45,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/147#issuecomment-324627178,3,['install'],"['install', 'installed']"
Deployability,"Seems like a similar issue to #480, where the boost-cpp depenendency is supposed to be installed from the conda-forge channel. When you installed salmon, did you have the conda-forge channel installed?. Solution _*may*_ be: `conda uninstall -n salmon salmon && conda install -n salmon -c conda-forge -c bioconda salmon`",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/915#issuecomment-2000571627:87,install,installed,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/915#issuecomment-2000571627,4,['install'],"['install', 'installed']"
Deployability,Segmentation fault in bioconda installation,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/268:31,install,installation,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/268,1,['install'],['installation']
Deployability,Seurat parser outdated and needs an EDS based update,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/436:46,update,update,46,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/436,1,['update'],['update']
Deployability,"Since 0.10.2 is now out (and salmon is updated in bioconda), I'm going to close this issue.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-395790180:39,update,updated,39,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-395790180,1,['update'],['updated']
Deployability,"Slight Correction on the above statement ""It looks like one of the whitelisted CB ended up having no read at all after ~deduplicating~ mapping."" We might have to tweak a bit in the current version of Alevin for use cases like yours where we don't wan't pipeline to fail if the whitelisted CB are either w/ less frequency / mapping rate / deduplication rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406657183:253,pipeline,pipeline,253,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406657183,1,['pipeline'],['pipeline']
Deployability,"So after struggling, and failing for a little bit I looked into linuxbrew - its pretty much the best thing ever. I'm honestly not sure what my original issue was derived from but using linuxbrew to install the dependancies and then salmon itself worked perfectly. Honestly much easier to install it this way. . Salmon seems to be working now so I'd say my install issues are resolved. Thanks for your help, and an extra thanks for introducing me to linuxbrew, its going to make my work a lot easier.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314548472:198,install,install,198,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314548472,3,['install'],['install']
Deployability,"So which --chemistry flag in Cell Ranger does the change to -lISF correspond to? Is it `SC5P-R2` or `fiveprime`? https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/using/count. Also since salmon/alevin can detect the library type automatically, would detect the correct library in the case of 5'-tagged scRNAseq 10X Feature barcode?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/439#issuecomment-622019385:182,pipeline,pipelines,182,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/439#issuecomment-622019385,1,['pipeline'],['pipelines']
Deployability,"So, I've already updated the docs _here_ (i.e. the doc tag in the ReadMe should should point to the link I give above). I believe the right thing to do over in the Sailfish docs is to just remove any documentation about Salmon (since the projects are now maintained in separate repos each with their own docs).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/27#issuecomment-152843180:17,update,updated,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/27#issuecomment-152843180,1,['update'],['updated']
Deployability,"So, on a fresh docker image of ubuntu 16.04.4, I was not able to reproduce this yet. Here is my current output:. ```; [100%] Linking CXX executable salmon; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xec4): warning: the use of `tempnam' is dangerous, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:171,install,install,171,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,7,"['Install', 'Release', 'configurat', 'install']","['Install', 'Installing', 'Release', 'configuration', 'install']"
Deployability,"Solved with ; `-DFETCH_STADEN=TRUE`. to recap, installing on an Ubuntu 20.04: ; ```; git clone --depth=1 https://github.com/COMBINE-lab/salmon.git; cd salmon; git checkout tags/v1.5.2. apt-get build-dep -y salmon; cmake -DFETCH_BOOST=FALSE --log-level=VERBOSE -DCMAKE_INSTALL_PREFIX=/directory_to_place/salmon/1.5.2 -DFETCH_STADEN=TRUE -DNO_IPO=TRUE && make && make install; ```. Please note you can't mkdir build and cd build as the cmake files are bundled under the git's root dir. You'll need to move the files (but i'm not familiar with cmake so i just run it from the git root). Compilation is required as the distributed binaries use the older libc (GLIBC_2.29)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/425#issuecomment-962540229:47,install,installing,47,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/425#issuecomment-962540229,2,['install'],"['install', 'installing']"
Deployability,"Some progress. Found a src rpm for cereal, rebuilt that into an RPM and installed. Then this (ROOT_* env variables come from the respective module load commands):. ```; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_09.log; ```; found everything. The ""make"" went along pretty well until here:; ```; [100%] Linking CXX executable salmon; cd /usr/common/src/salmon-1.2.1/build/src && /usr/common/src/cmake-3.17.1/bin/cmake -E cmake_link_script CMakeFiles/salmon.dir/link.txt --verbose=1; /usr/lib64/ccache/c++ -O3 -DNDEBUG -flto -fno-fat-lto-objects CMakeFiles/salmon.dir/EMUtils.cpp.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedCellOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/Graph.cpp.o CMakeFiles/salmon.dir/DedupUMI.cpp.o CMakeFiles/salmon.dir/Alevin.cpp.o CMakeFiles/salmon.dir/AlevinHash.cpp.o CMakeFiles/salmon.dir/SalmonAlevin.cpp.o CMakeFiles/salmon.dir/WhiteList.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/SalmonQuantMerge.cpp.o CMakeFiles/salmon.dir/ProgramOptionsGenerator.cpp.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o CMakeFiles/salmon.dir/BAMUtils.cpp.o -o salmon -L/usr/common/src/salmon-1.2.1/lib -L/usr/common/src/salmon-1.2.1/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" ../external/pufferfish/src/libpuffer.a libs",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162:72,install,installed,72,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162,1,['install'],['installed']
Deployability,Sorry @k3yavi - was away on leave. Seems to be lots of helpful titbits in this release- thank you.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-501591974:79,release,release,79,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-501591974,1,['release'],['release']
Deployability,Sorry I missed this! It's been on that branch (and committed) since Gaurav's PR. It's now been merged into master and included in the latest release (1.10.0).,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/813#issuecomment-1444418892:141,release,release,141,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/813#issuecomment-1444418892,1,['release'],['release']
Deployability,Sorry it took me so long to get around to this. Thanks for the PR! I merged into develop instead of master since I'm working on a new release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/92#issuecomment-249087178:134,release,release,134,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/92#issuecomment-249087178,1,['release'],['release']
Deployability,"Sorry,. > Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; # salmon (alignment-based) v0.9.1; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { transcripts.fa }; # [ libType ] => { A }; # [ alignments ] => { A549_S1_001.bam }; # [ output ] => { A549_S1_quant }; Logs will be written to A549_S1_quant/logs; Malformed key:value pair at line 44017: ""@PG ID:OSA IsCdna:True ReferenceLibraryID:Human.B37.3_RefGene20121217 VN:7.2""; ============; Exception : [ERROR: Failed to open file A549_S1_001.bam, exiting!]; ============; ./bin/salmon alignment-quant was invoked improperly.; For usage information, try ./bin/salmon quant --help-alignments; Exiting.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497883:42,upgrade,upgrade,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497883,2,['upgrade'],"['upgrade', 'upgrades']"
Deployability,"Sounds good! Once it’s in the next release, we can see if we can get the Homebrew formula working.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-473479367:35,release,release,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-473479367,1,['release'],['release']
Deployability,"Sounds good, I will report back as soon as we have the next release. ; Just a quick correction the useful percentage is less than 1% (not 1-4% it's 0.1 - 0.4%), I was off by a magnitude in the percentage reported above.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490864673:60,release,release,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490864673,1,['release'],['release']
Deployability,"Sounds good, just wanted to give you the heads up, as we are working on some other part of the salmon pipeline, currently I can't give you an ETA when would the new version of salmon be available. If For the time being the choice are either you can compile the develop branch of salmon or I can forward you a linux usable salmon binary.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-523090214:102,pipeline,pipeline,102,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-523090214,1,['pipeline'],['pipeline']
Deployability,Strange the updated error message has @PG not @pg,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387498610:12,update,updated,12,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387498610,1,['update'],['updated']
Deployability,"Success???. ```; $ gdb -ex ""attach $(pgrep salmon | head -1)"" -ex bt -ex detach -ex quit; GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.04) 7.11.1; Copyright (C) 2016 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>.; For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word"".; Attaching to process 29332; [New LWP 29334]; [New LWP 29335]; [New LWP 29336]; [New LWP 21224]; [New LWP 21225]; [New LWP 21226]; [New LWP 21227]; [New LWP 21228]; [New LWP 21229]; [New LWP 21230]; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; 0x00007fcb8cf73789 in __ieee754_log_avx (x=<optimized out>) at ../sysdeps/ieee754/dbl-64/e_log.c:193; 193	../sysdeps/ieee754/dbl-64/e_log.c: No such file or directory.; #0 0x00007fcb8cf73789 in __ieee754_log_avx (x=<optimized out>) at ../sysdeps/ieee754/dbl-64/e_log.c:193; #1 0x0000000000637ccc in double std::gamma_distribution<double>::operator()<pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> > >(pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> >&, std::gamma_distribution<double>::param_type const&) (); #2 0x0000000000634b8d in tbb::inter",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267488748:503,configurat,configuration,503,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267488748,2,['configurat'],['configuration']
Deployability,Successfully installed and ran salmon on Arch Linux using the AUR binary package. Works great[link](https://aur.archlinux.org/packages/salmon),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/268#issuecomment-2118895156:13,install,installed,13,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/268#issuecomment-2118895156,1,['install'],['installed']
Deployability,"Sure thing, thanks for your help. It's entirely possible the issue is user error, rather than something wrong with the bioconda build. I had to install and run in a py3 env, since our server defaults to py2. Not sure if that's related, but I've used successfully in the past one a server with py3 as the default.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409779737:144,install,install,144,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409779737,1,['install'],['install']
Deployability,Sure!; >wget ftp://ftp.ensembl.org/pub/release-87/fasta/homo_sapiens/ncrna/Homo_sapiens.GRCh38.ncrna.fa.gz; >wget ftp://ftp.ensembl.org/pub/release-87/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz; # Combine the above two files; >zcat Homo_sapiens.GRCh38.cdna.all.fa.gz Homo_sapiens.GRCh38.ncrna.fa.gz > Homo_sapiens.GRCh38.87.cdna.ncrna.fa; # Get annotation only on known chr; >wget ftp://ftp.ensembl.org/pub/release-87/gtf/homo_sapiens/Homo_sapiens.GRCh38.87.chr.gtf.gz; # Get all annotation; >wget ftp://ftp.ensembl.org/pub/release-87/gtf/homo_sapiens/Homo_sapiens.GRCh38.87.gtf.gz,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-283466423:39,release,release-,39,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-283466423,4,['release'],['release-']
Deployability,"Sure, thanks for letting me know you were able to install via bioconda. I'll try to make these build errors more informative.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447963407:50,install,install,50,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447963407,1,['install'],['install']
Deployability,"Sure, thanks for pointing this out, we have updated the document now !; We are gonna do testing at our end too, but let us know if you have any other issue.; Happy Weekend !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395912965:44,update,updated,44,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395912965,1,['update'],['updated']
Deployability,"Sure, works for me. Is it possible to add an argument that indicates that the dependencies (like `xz`) should be provided by the host, and any missing dependencies are an error, rather than installing them automatically?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193944377:190,install,installing,190,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193944377,1,['install'],['installing']
Deployability,"T (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:7543,pipeline,pipeline,7543,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"T (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/cm/shared/apps/sge/current/lib/linux-x64"", {st_mode=S_IFDIR|0755, st_size=7, ...}) = 0; open(""/etc/ld.so.cache"", O_RDONLY) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=101124, ...}) = 0; mmap(NULL, 101124, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fffbffe4000; close(3) = 0; open(""/lib64/libpthread.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\340]\200\316;\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=145896, ...}) = 0; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbffe3000; mmap(0x3bce800000, 2212848, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x3bce800000; mprotect(0x3bce817000, 2097152, PROT_NONE) = 0; mmap(0x3bcea17000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x17000) = 0x3bcea17000; mmap(0x3bcea19000, 13296, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x3bcea19000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/liblzma.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0 %\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=130728, ...}) = 0; mmap(NULL, 2226056, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbfdc3000; mprotect(0x7fffbfde2000, 2097152, PROT_NONE) = 0; mmap(0x7fffbffe2000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1f000) = 0x7fffbffe2000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libtbb.so.2"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\320v\1\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_si",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:53490,pipeline,pipeline,53490,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['pipeline'],['pipeline']
Deployability,"TYPE=Debug -DCMAKE_INSTALL_PREFIX=../stage .. =============At last, getting these:; -- Configuring done; -- Generating done; -- Build files have been written to: /root/salmon/build. 5. In directory salmon/build, I type; make. ===========Then crashed here; [ 86%] Built target unitTests; Scanning dependencies of target salmon; [ 86%] Building CXX object src/CMakeFiles/salmon.dir/EMUtils.cpp.o; c++: error: -pg and -fomit-frame-pointer are incompatible; src/CMakeFiles/salmon.dir/build.make:62: recipe for target 'src/CMakeFiles/salmon.dir/EMUtils.cpp.o' failed; make[2]: *** [src/CMakeFiles/salmon.dir/EMUtils.cpp.o] Error 1; CMakeFiles/Makefile2:790: recipe for target 'src/CMakeFiles/salmon.dir/all' failed; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; Makefile:162: recipe for target 'all' failed; make: *** [all] Error 2. Specifically, please provide at least the following information:. * Which version of salmon was used? v1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? compiled; * Which reference (e.g. transcriptome) was used? Encountered compile error, so not to index/quant step yet; * Which read files were used? same as above; * Which which program options were used? same as above. **Expected behavior**; A clear and concise description of what you expected to happen.; I expect to finish ""make"" command without encountering compile error while using debug mode(""-DCMAKE_BUILD_TYPE=Debug"" ). **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; ![image](https://user-images.githubusercontent.com/24876498/103148237-98daa880-4798-11eb-9944-a104c41f75cf.png). **Desktop (please complete the following information):**; - OS: CentOS7; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; ""uname -a""; Linux 3.10.0-1062.18.1.el7.x86_64 #1 SMP Tue Mar 17 23:49:17 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. ""lsb_release -a""; LSB V",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/608:2571,install,installed,2571,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/608,1,['install'],['installed']
Deployability,"Thank *you* for providing this software to the community.; BTW, it seems you're making an effort to support externally installed dependencies, for which I'm grateful. I did have to patch around a few bundled deps (e.g. libgff), which are downloaded unconditionally. Many package managers (e.g. FreeBSD ports, Gentoo Portage, MacPorts, pkgsrc, ...) do not allow manual downloads by upstream build systems, for obvious security reasons. I'm hoping it will be possible to avoid all such downloads without patching in the future, by preinstalling and having them discovered by find_package(), as you're already doing for things like bzip2. This will make it easier to package salmon in many of the numerous package managers out there (and eliminate the need for you to install dependencies via cmake). Cheers!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420352699:119,install,installed,119,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420352699,4,"['install', 'patch']","['install', 'installed', 'patch', 'patching']"
Deployability,Thank you both very much for working on this issue! I'm looking forward to having Salmon updated in Brewsci/bio. Enjoy your weekend!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-473483470:89,update,updated,89,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-473483470,1,['update'],['updated']
Deployability,"Thank you for this wonderful pipeline. I have some human bulk RNAseq samples that were aligned in STAR against the genome with the soft-masked primary assembly (Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa). . I want to run Salmon with the full genome decoy to compare, and would like to use the same reference files for consistency. Does Salmon (like STAR) ignore the lower case for these sequences? Or since its the decoy, does it make a big difference?. Thanks.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/934:29,pipeline,pipeline,29,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/934,1,['pipeline'],['pipeline']
Deployability,"Thank you for verifying @zhangchipku, and thank you very much for the kind words! We appreciate the feedback and input from our users like yourself. We'll prioritize the soft-clipping functionality for upcoming releases (maybe even the next if we can make that work in time). For the time being, I can recommend `fastp` as a fairly efficient / fast trimmer that. It might even be able to work in a streaming fashion so that you could pipe the trimmed reads directly to salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586548443:211,release,releases,211,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586548443,1,['release'],['releases']
Deployability,"Thank you so much! We are going to use the new version. Of course, we will share you some results of comparing Q2 pipeline with Alevin. We usually used the drop-seq pipeline.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-522866012:114,pipeline,pipeline,114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-522866012,2,['pipeline'],['pipeline']
Deployability,"Thanks ! ; When you release the apple silocon version. Is it possible to upload to brew ? Do you want to take in account the gpu with metal or the neural engine ? . > Le 30 juin 2022 à 05:58, Rob Patro ***@***.***> a écrit :; > ; > ﻿; > Hi @BenjaminDEMAILLE,; > ; > I think brew is a bit behind bioconda on this front, and, indeed, the M1 being a completely new architecture complicates things. I have an M1 Max and so there are plans to get a native compile going soon.; > ; > For the time being, the recommended way to get salmon on an M1 (or M2) Mac is as suggested here. Basically, you create an x86 conda environment (running under rosetta2) and install the latest version of salmon there. Rosetta2 is pretty amazing, and everything seems to run without a hitch, with nary a performance hit for the x86 -> ARM translation.; > ; > Best,; > Rob; > ; > —; > Reply to this email directly, view it on GitHub, or unsubscribe.; > You are receiving this because you were mentioned.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/787#issuecomment-1170808558:20,release,release,20,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/787#issuecomment-1170808558,2,"['install', 'release']","['install', 'release']"
Deployability,"Thanks @A-N-Other! I changed the base branch to develop, as we generally pull everything through that branch before it makes it to master. Otherwise, these changes look good. Hopefully we'll get around to pushing out a patch release with this change soon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/856#issuecomment-1607761575:219,patch,patch,219,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/856#issuecomment-1607761575,2,"['patch', 'release']","['patch', 'release']"
Deployability,"Thanks @ACastanza , I think it's a good idea. I have marked it as a feature request and we'd update you here once we have some progress into the next release. A bit tangential though, I find [refgenie](http://refgenomes.databio.org/) very useful as it has pre-built salmon indices with all the other relevant metadata (such as gtf to generate tgMap file) needed by salmon/alevin for quantifiation, but I agree saving the tgMap while indexing through GTF would be great for consistency.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738166102:93,update,update,93,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738166102,2,"['release', 'update']","['release', 'update']"
Deployability,"Thanks @Ryan-Zhu for your feedbacks and the suggestion.; I apologize for the trouble you had to face while working with the alevin output.; We will prepare better from the next release and try updating the external dependencies first before making an official release. ; Just wanted to give you the heads up that I have also updated the bug for the scientific notation in the `mtx` format. It's in the develop branch of alevin, if you have time please let me know if it works for you. Thanks again.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-502828416:177,release,release,177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-502828416,3,"['release', 'update']","['release', 'updated']"
Deployability,"Thanks @Tj-Idowu,. So, indeed, it looks like this is the problem. The mapping is completing, but you seem to be encountering a segmentation fault at the end of the run (before the abundance estimation finishes). Could you tell me what OS and version you're using, and how you installed Salmon? My guess is a binary incompatibility somewhere. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/239#issuecomment-400009534:276,install,installed,276,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/239#issuecomment-400009534,1,['install'],['installed']
Deployability,Thanks @dritoshi for the data and info. Let me play a bit with the data over the weekend. It should be very straightforward to add but I might have to check some unit test. I'll keep you updated.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521863053:187,update,updated,187,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521863053,1,['update'],['updated']
Deployability,"Thanks @jdrnevich for the heads up, I'll update the docs too.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/391#issuecomment-508132261:41,update,update,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/391#issuecomment-508132261,1,['update'],['update']
Deployability,"Thanks @juugii for the detailed response and clarifying my doubts.; It surely is possible to lose some information when projecting the data on lower dimensional space since none of the methods, CCA and MNN, are lossless. I do see your point and would like to understand more about the depth normalization problem you are facing with different experiments. . I tried to search the algorithm used by cellranger to aggregate the counts and it looks like the following:; * As I was saying earlier aggregation step was happening downstream of count/quantification of the gene count matrix, at least in cellranger pipeline.; > When doing large studies involving multiple biological samples (or multiple libraries or replicates of the same sample), it is best to run cellranger count on each of the libraries individually, and then pool the results using cellranger aggr. * It looks like they have three different modes to normalize the libraries; > There are three normalization modes:; mapped: (default) Subsample reads from higher-depth libraries until they all have an equal number of confidently mapped reads per cell.; raw: Subsample reads from higher-depth libraries until they all have an equal number of total (i.e. raw, mapping-independent) reads per cell.; none: Do not normalize at all. * Although it's not clear, what do they mean by `equal number of confidently mapped reads per cell`, does it mean median reads per cell ? Like you tried to show in the above plot the distribution can be very uneven. But the part that troubles me more is once `count` information has been generated it has lost the read level information, since we have deduplicated them, then how do they use the read counts to normalize. Unless that is dumped too, not clear. Quoting your text from above:; > Alternatively, could a subsampling covariate be added to the probabilistic quantification model of alevin. I think we can definitely work on correcting the subsampling bias in the probabilistic model of Alevin but we",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433453155:608,pipeline,pipeline,608,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433453155,1,['pipeline'],['pipeline']
Deployability,Thanks @k3yavi - I think those options would really help us use Alevin in production- look forward to the next release. . I'll do some more testing in the meantime.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490859077:111,release,release,111,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490859077,1,['release'],['release']
Deployability,"Thanks @k3yavi - do I need to assume that all of our existing matrices could be corrupted? . We've built Alevin into our production processes, so I'm loath to hack my way to a solution. When is the 0.99 release due?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-537071575:203,release,release,203,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-537071575,1,['release'],['release']
Deployability,"Thanks @k3yavi and @rob-p . . Regarding the number of mapped reads, everything looks good in aux_info/meta_info.json. That number was indeed an artifact. However, I still could not figure out why there is such a discrepancy between the read counts of these replicates. . How would it be the best way to share my data/pipeline? The data are coming from the Roadmap project (GSM1112836 and GSM916094). I am getting the fasta files from the bed files with `bedtools getfasta`, aligning them to the transcriptome with bowtie2, and then running salmon on the resulting bam files using alignment-based mode. Does it seem to be the correct way to process these data?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/368#issuecomment-504560952:317,pipeline,pipeline,317,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/368#issuecomment-504560952,1,['pipeline'],['pipeline']
Deployability,Thanks @mathog : I've chosen another color that is readable on both light and dark backgrounds. These changes are on develop and will make it into the next release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/541#issuecomment-650568147:156,release,release,156,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/541#issuecomment-650568147,1,['release'],['release']
Deployability,"Thanks @mcfwoodruff,. The good news is I was able to reproduce this using the conda install in my OSX environment. I can also verify that using a salmon executable compiled on this machine itself, the segfault goes away. This means there is probably some binary incompatibility issue with the specific versions of the libraries being used / pulled in under bioconda. I'll see if I can dig deeper (and maybe also provide a pre-compiled binary from OSX to see if that works for you).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421393355:84,install,install,84,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421393355,1,['install'],['install']
Deployability,"Thanks @mikelove . > we had some people using txi$counts alone and not using the countsFromAbundance argument. Based on the above, I assume that **_doing something like this is wrong_** as DESeqDataSetFromMatrix is being used after countsFromAbundance = ""no"". ```; txi = tximport(files, type=""salmon"", tx2gene=tx2gene,; countsFromAbundance = ""no""). dds <- DESeqDataSetFromMatrix (countData = txi$counts,; colData = coldata, ~ condition); ```. @rob-p and @mikelove -- While on this topic, how would you use salmon quant and DESeq2 for QuantSeq data (which would be 3' tagged RNA-seq)? Would you use `salmon quant without --noLengthCorrection` or would you use` salmon quant with ; --noLengthCorrection`. 1. call salmon quant as before (and **_do not use --noLengthCorrection_**) and then do as suggested/stated in these 2 links ; - https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html#Downstream_DGE_in_Bioconductor and https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html#3%E2%80%99_tagged_RNA-seq; - Do not manually pass the original gene-level counts to downstream methods without an offset. The only case where this would make sense is if there is no length bias to the counts, as happens in 3’ tagged RNA-seq data (see section below). The original gene-level counts are in txi$counts when tximport was run with countsFromAbundance=""no"". ; - If you have 3’ tagged RNA-seq data, then correcting the counts for gene length will induce a bias in your analysis, because the counts do not have length bias. Instead of using the default full-transcript-length pipeline, we recommend to use the original counts, e.g. txi$counts as a counts matrix , e.g. providing to DESeqDataSetFromMatrix",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719946865:1625,pipeline,pipeline,1625,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719946865,1,['pipeline'],['pipeline']
Deployability,Thanks @patrickvdb! I'm re-basing on this branch because this will be merged into master soon for a new patch release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/257#issuecomment-408428738:104,patch,patch,104,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/257#issuecomment-408428738,2,"['patch', 'release']","['patch', 'release']"
Deployability,"Thanks @rfarouni for the updates. > With --minScoreFraction 0.607 I get a way much better mapping rate. I wonder if there is way to determine the optimal value empirically?. Glad to hear that, may I ask what percent of the reads are mapping now ? It's not clear from the alevin logs you shared but I think the total number of deduplicated UMIs are similar to your baseline experiment. I think defining an optimal empirical threshold is a great idea but the issue is that 21 length barcodes are kind of in the middle i.e. a tad longer than the regular barcodes and somewhat smaller than a full read. The full read alignment process indeed allows more erroneous reads to map but 21 is a bit too short to work with. @rob-p might have more thoughts on this one. > But now there are a lot of barcodes that are not in the whitelist. Thanks again for checking this, it is indeed concerning. However, as I was mentioning earlier in a regular single-cell experiment we end up throwing away almost all of these very low frequency count cellular barcodes. I'd say even 45 reads CBs are most probably a noise and will be filtered away, because only a fraction of the reads will map and after deduplication it'll result in significantly low count in 1 cellular barcode. > Also with the default setting of --freqThreshold, no CB correction gets done. I can check why is this happening, let me know once you have a toy dataset to play with.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640093397:25,update,updates,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640093397,1,['update'],['updates']
Deployability,"Thanks @rob-p and Thanks in advance @mikelove . The original question pertained to using salmon with say ILMN RNA-Seq followed by DGE with DESeq2. @rob-p - I will also use this opportunity to indulge myself on a related question (how to use salmon with QuantSeq and then downstream with DESeq2). I have asked many QuantSeq related questions on this GH forum and I am yet to find the correct recipe for using salmon with quantseq and downstream DGE; - https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848; - https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499732849; - and many others (do not want to get into a infinite loop here :) . @rob-p @mikelove - Here is my thought process (for salmon-QuantSeq-DESeq):; - I know salmon has the `--noLengthCorrection` feature and the help text says it is ""experimental"" for QuantSeq; - Probably, I should not use `--noLengthCorrection` feature when running salmon quant and just get the counts. ; - One might be wondeing why not to use `--noLengthCorrection` as it was introduced by @rob-p exclusively for QuantSeq -- that idea is based on what I see on [the tximport vignette for 3' tagged RNA-seq](https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html#3%E2%80%99_tagged_RNA-seq) which has this to state; ```; If you have 3’ tagged RNA-seq data, then correcting the counts for gene length will induce a bias in your analysis, ; because the counts do not have length bias. Instead of using the default full-transcript-length pipeline, ; we recommend to use the original counts, e.g. txi$counts as a counts matrix, e.g. ; providing to DESeqDataSetFromMatrix or to the edgeR or limma functions ; without calculating an offset and without using countsFromAbundance.; ```. Let me know if you would approach the salmon-QuantSeq-DESeq puzzle differently. Thanks in advance.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719150287:1531,pipeline,pipeline,1531,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719150287,1,['pipeline'],['pipeline']
Deployability,"Thanks @roryk and @k3yavi . The issue we have is that we're trying to run a pipeline in a fairly high-throughput manner to get a sensible 'enough' matrix without too much manual intervention. So I'm trying to avoid anything that requires an eyeballing step, accepting that the matrix we get will be less optimal than one you'd get from manual optimisation. Where possible, our curators are extracting the expected cell numbers from publications, so sometimes I have at least a general idea of where to look for an elbow/ feature. @roryk - have you used your alternate view on the data to automatically derive cutoffs? Does it work well?. @k3yavi:. As I say, first point is that this is for cases where I have a rough idea of the target cell number- we're generally working with pre-published data (though cell numbers per run are not always available). . From https://github.com/COMBINE-lab/salmon/issues/340 I'd inferred that --expectCells gives Alevin ballpark to look for a knee within, while --forceCells is a strict cuttoff. Is that correct? . That being the case, my thought was to try --expectCells first, and failing that --forceCells. The problem is that I need to parse the STDOUT/ERR to detect the boundary error from --expectCells, which is not a very robust way of doing things. If you returned informative error codes (anything but 1) on this and other errors, I could detect the error and implement the logic I describe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490157428:76,pipeline,pipeline,76,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490157428,1,['pipeline'],['pipeline']
Deployability,"Thanks @roryk for the code and @pinin4fjords for the suggestion.; That's correct, `--expectCells` and `--forceCells` flags are designed to use the way you described above. ; re: error codes, It's a good suggestion. Based on the timeline either we can make this into the next release of alevin or we can edit it in a different branch and then you can compile or I can give you a linux binary. Let us know what works for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490161277:275,release,release,275,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490161277,1,['release'],['release']
Deployability,"Thanks Jeremy! Yes, that's what I was hinting at with different v1/v2 protocols. From their code, you can see differences in amplicon sequences:; - For v1: 'NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGAGGCCAGAGCATTCGIIIIIIII'; - For v2: 'NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGACTGTGGIIIIIIII'; where the `IIIIIIII` sequence corresponds to barcode. This is from the pipeline code I mentioned earlier used for [this paper](https://www.nature.com/articles/s41593-021-00872-y). Do you have a the pairing file for the BC1 barcodes? Is it the Supp Table S12 in the Rosenberg paper? It is needed for development and testing.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951080577:425,pipeline,pipeline,425,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951080577,1,['pipeline'],['pipeline']
Deployability,"Thanks Matt for the response and fix, unfortunately the error persists;; Might need to re-align using a different pipeline?. > Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; # salmon (alignment-based) v0.9.1; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { transcripts.fa }; # [ libType ] => { A }; # [ alignments ] => { A549_S1_001.bam }; # [ output ] => { A549_S1_quant }; Logs will be written to A549_S1_quant/logs; Malformed key:value pair at line 44017: ""@PG ID:OSA IsCdna:True ReferenceLibraryID:Human.B37.3_RefGene20121217 VN:7.2""; ============; Exception : [ERROR: Failed to open file A549_S1_001.bam, exiting!]; ============; ./bin/salmon alignment-quant was invoked improperly.; For usage information, try ./bin/salmon quant --help-alignments; Exiting.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497579:114,pipeline,pipeline,114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497579,3,"['pipeline', 'upgrade']","['pipeline', 'upgrade', 'upgrades']"
Deployability,"Thanks Rob! I won't be able to get to it until later this week at the earliest because of helping to finish a manuscript, but I'll let you know as soon as I get to it! Looking forward to the new release!. Best,; Warren",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-241538721:195,release,release,195,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-241538721,1,['release'],['release']
Deployability,Thanks again @alexvpickering .; We have fixed this in the develop branch and it will be part of the salmon from the next release which we plan to release very soon.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/366#issuecomment-497391366:121,release,release,121,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/366#issuecomment-497391366,2,['release'],['release']
Deployability,"Thanks again @jdrnevich for sharing the data for debugging purposes. For anyone seeing similar behavior or following this issue, the resolution is as follows:. The mapping rate difference for between 100bp and 150bp reads (for both single-end and paired-end) becomes very small, and consistent with the ""high"" mapping rate of ~76-79% when using salmon v0.13.1 with `--validateMappings`. Thus, the recommendation here (and in general) is to process the data using the latest version of salmon and ensuring to use the `--validateMappings` option. Also, thanks to @jdrnevich for suggesting that the importance of this feature be highlighted in the documentation to the same extent it is in the release notes.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/349#issuecomment-472994215:691,release,release,691,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/349#issuecomment-472994215,1,['release'],['release']
Deployability,"Thanks for nice tool!. I performed alevin with 10X Chromium (v3) data and it seems to be nice result. By the way, I followed the Alevin-Tutorial and Ipython Notebook as below,; but generating txp2gene.tsv took some time.; https://combine-lab.github.io/alevin-tutorial/2018/running-alevin/; https://gist.github.com/k3yavi/c501705ed2d29b12b0d10cf78b3ed001. Especially, bioawk is not installed in any machine by default, and also just copy & past of the bioawk code could not run in my machine. For the above reason, I would like to suggest an alternative code to process this task. For example, I modified the code by using only grep, awk, sed, and uniq as below.; Is this also okay?. ```; wget -P data ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_32/gencode.v32.primary_assembly.annotation.gtf.gz; gunzip -c data/gencode.v32.primary_assembly.annotation.gtf.gz | grep transcript | awk '{print $12,$10}' | sed -e 's|""||g' -e 's|;||g' | uniq > data/txp2gene.tsv; ```. Otherwise, I appreciate it if you could support this task by implementing the subcommand of salmon as bellow. ```; salmon t2g [GTFfile]; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/467:381,install,installed,381,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/467,1,['install'],['installed']
Deployability,"Thanks for reporting this @alexdhill. There was a bug addressed in version 1.10 (the first bug in the release notes [here](https://github.com/COMBINE-lab/salmon/releases/tag/v1.10.0)) that could be related to this. If you *do* encounter this in any samples under 1.10, please let us know. In which case, keeping track of the offending sample might be the most useful way to try and dig into it further. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/876#issuecomment-1739843386:102,release,release,102,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/876#issuecomment-1739843386,2,['release'],"['release', 'releases']"
Deployability,"Thanks for reporting this. It seems there is an osx bioconda issue (likely related to their massive backend upgrade). Hopefully we can fix this upstream in the next release. I. The meantime, can you see if [this](https://github.com/COMBINE-lab/salmon/files/2383948/salmon_0.11.4-pre_OSX.tar.gz) OSX binary works for you?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/303#issuecomment-432468434:108,upgrade,upgrade,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/303#issuecomment-432468434,2,"['release', 'upgrade']","['release', 'upgrade']"
Deployability,"Thanks for so much for tracking down that issue so quickly! These problems have plagued me for years with different tools. There always seems to be a library that does this. I'll try the patched version this weekend and let you know how it goes. Finally, thanks for pointing out the issue about process substitution issue. I usually have 4-12 fastq files per sample and was following the [Alevin documentation](http://salmon.readthedocs.io/en/latest/alevin.html), which had the gzipped example using process substitution.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395911670:187,patch,patched,187,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395911670,1,['patch'],['patched']
Deployability,Thanks for the bug report. This has been fixed in develop and should work properly in the next release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/501#issuecomment-611822688:95,release,release,95,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/501#issuecomment-611822688,1,['release'],['release']
Deployability,"Thanks for the detailed report @idinsmore1,. These are quite different versions of ensembl, and so changes in the underlying transcriptome can absolutely have an effect on estimated abundances. Specifically, as the newer releases of ensemble tend to annotate more and more isoforms, there are more potential explanations for the reads. Reads that may have been previously assigned to an isoform in the old annotation may better match to a new isoform in the new annotation, etc. This will affect the read assignment and TPM both to the isoform to which the reads were originally being assigned and the new isoform to which the reads are now being assigned. . One thing to look at would be to see how much things change at the gene level, where we'd expect mapping uncertainty to be much lower. Once there's an idea of the types of things that are changing, it will be possible to drill down a bit more to try and figure out exactly what's going on. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/653#issuecomment-823560566:221,release,releases,221,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/653#issuecomment-823560566,1,['release'],['releases']
Deployability,"Thanks for the details, David. I wanted to get a broader perspective of what was going on mapping-wise, so I ran the first sample through a STAR->salmon pipeline (the [brand new one in nf-core](https://github.com/nf-core/rnaseq/releases/tag/3.0)). This will also let us get a notion of what is happening in terms of mapping to the genome versus the annotated transcripts. Here's what I found:. The STAR mapping report shows:. ```; Started job on | Dec 15 18:01:41; Started mapping on | Dec 15 18:12:46; Finished on | Dec 15 18:25:37; Mapping speed, Million of reads per hour | 103.29. Number of input reads | 22120369; Average input read length | 290; UNIQUE READS:; Uniquely mapped reads number | 18500061; Uniquely mapped reads % | 83.63%; Average mapped length | 284.22; Number of splices: Total | 5999311; Number of splices: Annotated (sjdb) | 5961890; Number of splices: GT/AG | 5905895; Number of splices: GC/AG | 41312; Number of splices: AT/AC | 11584; Number of splices: Non-canonical | 40520; Mismatch rate per base, % | 0.36%; Deletion rate per base | 0.01%; Deletion average length | 1.46; Insertion rate per base | 0.01%; Insertion average length | 1.72; MULTI-MAPPING READS:; Number of reads mapped to multiple loci | 1805463; % of reads mapped to multiple loci | 8.16%; Number of reads mapped to too many loci | 3745; % of reads mapped to too many loci | 0.02%; UNMAPPED READS:; % of reads unmapped: too many mismatches | 0.00%; % of reads unmapped: too short | 8.07%; % of reads unmapped: other | 0.12%; CHIMERIC READS:; Number of chimeric reads | 0; % of chimeric reads | 0.00%; ```. *yet, only `9,310,303` reads* were determined by STAR to project properly to annotated transcripts (slightly _less_ than are mapped to the transcriptome by salmon, at least without the decoy sequence included). So, there is a very high fraction of the reads that align to the genome, but a much smaller fraction ~45%-50% that align to the transcriptome. There are many reasons something like this cou",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-745768992:153,pipeline,pipeline,153,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-745768992,2,"['pipeline', 'release']","['pipeline', 'releases']"
Deployability,"Thanks for the fast reply (and detailed explanation). The seg fault is produced regardless of the type (or lack thereof). In case the error below is somehow related to tbb: I haven't had it pre-installed, so the c- / make procedure 'took care of it'. Following output is generated by gdb:. ```Starting program: /usr/local/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; [New Thread 0x7ffff62b0700 (LWP 17488)]; Version Info: This is the most recent version of Salmon.; [Thread 0x7ffff62b0700 (LWP 17488) exited]. Thread 1 ""salmon"" received signal SIGSEGV, Segmentation fault.; __GI___libc_free (mem=0x7fff00000002) at malloc.c:2951; 2951	malloc.c: No such file or directory.; ``` ; and the backtrace:; ```; #0 __GI___libc_free (mem=0x7fff00000002) at malloc.c:2951; #1 0x00007ffff79b775d in operator delete[] (ptr=0x7fff00000002); at ../../src/tbbmalloc/proxy.cpp:256; #2 0x0000000000792272 in salmonIndex(int, char**) (); #3 0x000000000065baca in main (); ```. Edit: Similar things happen with conda installation, though the traceback details are slightly different:; `Temporary breakpoint 1 at 0x7ffff6cf2512: file malloc.c, line 2951. `",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404232467:194,install,installed,194,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404232467,2,['install'],"['installation', 'installed']"
Deployability,"Thanks for the fast reply, after many tries I was able to install it with Bioconda.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447960701:58,install,install,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447960701,1,['install'],['install']
Deployability,"Thanks for the report @arrowandbead,. Can you say something about the machine that you're running the indexing command on, and the FASTA file you're trying to index? We've seen poor behavior before specifically on cluster nodes with slow (networked) disk, but this should be largely mitigated in recent releases. --Rob. Edit: I saw that you closed the issue and identified the problem. Thanks for closing and for changing the title!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/554#issuecomment-668140567:303,release,releases,303,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/554#issuecomment-668140567,1,['release'],['releases']
Deployability,Thanks for the speedy replies. I tried running alevin with 8 threads and it ends up leading to the same error and backtrace. I can see a large number of threads still spawning through GDB. I have had these kinds of issues before with OpenMP and I usually had to specify an environment variable to limit the threads. I compiled salmon with the download boost etc option:. ```; linux-vdso.so.1 (0x00007ffc90379000); libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f859b069000); libtbbmalloc_proxy.so.2 => /u/user/tmp/salmon/build-debug/src/../../external/install/lib/libtbbmalloc_proxy.so.2 (0x00007f859ae66000); libtbbmalloc.so.2 => /u/user/tmp/salmon/build-debug/src/../../external/install/lib/libtbbmalloc.so.2 (0x00007f859ac36000); libtbb.so.2 => /u/user/tmp/salmon/build-debug/src/../../external/install/lib/libtbb.so.2 (0x00007f859aa08000); libgomp.so.1 => /u/user/local/lib64/libgomp.so.1 (0x00007f859a7e7000); librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f859a5df000); libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f859a2de000); libgcc_s.so.1 => /u/user/local/lib64/libgcc_s.so.1 (0x00007f859a0c8000); libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f8599d1d000); /lib64/ld-linux-x86-64.so.2 (0x00007f859b286000); libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f8599b19000); libstdc++.so.6 => /u/user/local/lib64/libstdc++.so.6 (0x00007f859979f000); ```. The linux version and g++ version are listed below:; ```; cat /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enab,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:570,install,install,570,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,3,['install'],['install']
Deployability,"Thanks for the super-detailed report, @allyhawkins. We'll fix this in the next point release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/691#issuecomment-921865678:85,release,release,85,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/691#issuecomment-921865678,1,['release'],['release']
Deployability,"Thanks for the thorough suggestions. Actually, we fall into the easier case since Salmon does not support mixing single and paired-end reads in a single BAM file. When performing quantification on a single sample, the reads for that sample must follow a uniform library type. For paired-end reads, the BAM file can contain paired-end and single-end alignments (i.e. orphans), but the reads must all have been paired _in sequencing_. Mixing different library types in the BAM file makes it difficult to assess the compatibility of a fragment with the expected library type, especially if fragments from the different library types are expected to exist in a specific ratio in the input. Anyway, my main motivation for having the separate `AS` and `AP` types was to prevent the need to ""peek"" in the file, since, currently, there is not an easy way to peek the first read without opening the first file twice. However, I've decided that the benefit of having the same uniform (and simpler) interface of `A` always representing automatic library type detection is probably worth it, so I've pushed this implementation (commit 6116b2a). So, when the user provides the `A` library type, Salmon will peek into the first record in the BAM file to determine if the fragment was paired in sequencing or not, and will then set the single / paired-end status on that basis. The only corollary to this is that, in alignment-based mode, the `A` flag is not compatible with an input stream (i.e. the input must be a regular file). I will be sure to document this when I update the docs for the version bump.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463:1556,update,update,1556,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463,1,['update'],['update']
Deployability,"Thanks for the update!. I'll try out the updated version and let you know if that helped. Your new preprint sounds very interesting, I'll give it a read",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-498787748:15,update,update,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-498787748,2,['update'],"['update', 'updated']"
Deployability,"Thanks for the update, and I'm glad to hear that you were able to find a local fix!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/710#issuecomment-1165663420:15,update,update,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/710#issuecomment-1165663420,1,['update'],['update']
Deployability,"Thanks fornthe details, @silvanopiazza! I wonder if it would be fixed if you *removed* the copy of `libm` in the `lib` subdirectory of the salmon install folder?. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1145876082:146,install,install,146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1145876082,1,['install'],['install']
Deployability,"Thanks sir. On Thu, Nov 21, 2019 at 9:27 PM Rob Patro <notifications@github.com> wrote:. > Hi @shanmugavadivelps <https://github.com/shanmugavadivelps>,; >; > This is because, to properly find and link libiconv, the build requires a; > version of CMake that ships with FindIConv.cmake. So, to build salmon from; > source, you should have at least CMake version 3.12. Internally and on our; > continuous integration servers, we use version 3.15.; >; > Also, I'll mention that it may not be essential to build from source.; > Salmon is available via Bioconda, and a docker image is available via; > DockerHub. Also, we have a pre-compiled binary that should work on many; > linux distributions available under our releases; > <https://github.com/COMBINE-lab/salmon/releases>.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/453?email_source=notifications&email_token=AN2V7HW3GLUZR52T4BJKOFLQU2VYHA5CNFSM4JP7NHKKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEE2W3DI#issuecomment-557149581>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AN2V7HTVJB3TCKRKDY6YKI3QU2VYHANCNFSM4JP7NHKA>; > .; >. -- ; *Shanmugavadivel, P. S.*; *Scientist (Agricultural Biotechnology),*. *#216, Block A,*; *ICAR-Indian Institute of Pulses Research,*. *Min. of Agriculture & Farmers Welfare,*. *Govt. of India,Kanpur - 208 024.*; *email: shanmugavadivel.ps@icar.gov.in <shanmugavadivel.ps@icar.gov.in>*; *www.iipr.res.in <http://www.iipr.res.in>*",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557774568:392,continuous,continuous,392,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557774568,4,"['continuous', 'integrat', 'release']","['continuous', 'integration', 'releases']"
Deployability,"Thanks! I don't have a CentOS 5 setup anywhere where I could test, but if it should be fixed then I'll go ahead and update the formula and bug you about it if anyone runs into problems.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/89#issuecomment-245930320:116,update,update,116,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/89#issuecomment-245930320,1,['update'],['update']
Deployability,"Thanks, I was good with linking against external jemalloc after your first reply. Mainly interested in knowing the details of your concern, so thanks for elaborating. We use pkgsrc for most of our CentOS installs, and now I feel safe using devel/jemalloc as a dependency. We also use FreeBSD, and in this case, I just patched out the dependency altogether, since jemalloc is FreeBSD's default allocator. Cheers!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420343097:204,install,installs,204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420343097,2,"['install', 'patch']","['installs', 'patched']"
Deployability,"Thanks, Rob! Much appreciated. ~brian. On Mon, Mar 20, 2017 at 9:06 AM, Rob Patro <notifications@github.com> wrote:. > Hi @brianjohnhaas <https://github.com/brianjohnhaas> --- I know it's been; > a while (but I didn't gain access to an older OSX machine in that time).; > However, you should now be able to get the latest Salmon release on any OSX; > >= 10.8 via its Bioconda release; > <https://bioconda.github.io/recipes/salmon/README.html>. Let me know if; > this works for you.; >; > Best,; > Rob; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-287753410>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AHMVX9ed1SrEG30OgxTLVaHzGtq20WI0ks5rnnnngaJpZM4L3UvG>; > .; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-287756041:329,release,release,329,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-287756041,2,['release'],['release']
Deployability,"Thanks, Rob!. I'm running Yosemite 10.10.5. I can look into upgrading my mac, which is overdue. Our primary deployment; is on linux and I'm sure that'll be fine. thx again!. ~b. On Sat, Feb 4, 2017 at 8:49 PM, Rob Patro <notifications@github.com> wrote:. > Hi Brian,; >; > What version of OS X are you running on? The issue you mention with the; > pre-compiled binary is one that arises because of a bug in jemalloc, due; > to Apple trying to be clever; > <https://github.com/Homebrew/homebrew-core/pull/6625>. But that binary; > should be built along with a newer version of jemalloc. While I have a nice; > setup for building widely-compatible linux binaries, I unfortunately, just; > have to build the OS X binaries on one of my 2 Macs (both of which are; > 10.12).; >; > --Rob; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-277491570>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AHMVX7Cn4cuE6h0zAgfI0AK0P6ka8Oahks5rZSqqgaJpZM4L3UvG>; > .; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-277493942:108,deploy,deployment,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-277493942,1,['deploy'],['deployment']
Deployability,"Thanks, that's super helpful!. I've been trying to install and compile from source using; `; git clone https://github.com/COMBINE-lab/salmon.git --branch develop; cd salmon; mkdir build; cd build; cmake ..; make install; `. but it's not working. I might just have to wait until the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/324#issuecomment-443354098:51,install,install,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/324#issuecomment-443354098,3,"['install', 'release']","['install', 'release']"
Deployability,"Thanks. I noticed that you forked BWA. I'm guessing my substitution of mainline BWA for your forked version is behind the last error. If we get int64_t defined, that might resolve it. I'd be happy to test, and can submit some patches for my other edits to CMakefiles.txt . I will try the Docker image. I was hesitant to use it because it relies on ZFS, and I'm not sure how ZFS will interact with my jail. Probably the easier path right now though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337616760:226,patch,patches,226,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337616760,1,['patch'],['patches']
Deployability,"Thanks. The ref genie thing might be a little big for me to download to be honest. I talked to my PI and he said it was to be expected that the RNA might be low quality. I ran it against mouse DNA as well and the mouse was multiples worse so I guess that's a good sign. The decoy hits also outnumber the mapped hits by about 6:1. But they never exceed about 7%. Does this indicate something wrong with my indexing?. I also tried mapping indexing against human CDS and NCRNA files from ftp://ftp.ensembl.org/pub/release-100/fasta/homo_sapiens/ and the human genome from the same source. Those had even lower hit rates. That was odd because rRNA wasn't filtered out for this RNA seq, so I would have expected the rRNA parts of the NCRNA to have a lot of hits. But alas.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/558#issuecomment-673153902:511,release,release-,511,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/558#issuecomment-673153902,1,['release'],['release-']
Deployability,"That does not seem very likely in this case. The default C++ compiler mode is C++14 and pretty much everything on the system is compiled that way. Still, I'm not sure how boost169 was compiled (the src.rpm is not available at the moment, waiting for email from the builder). It was used with other packages though, and if it had an incompatible ABI they should not have worked either. Checking my notes there are a couple of specific programs which had to be compiled with older C++ standards, but none of those are linked to Salmon. Also, if that was the problem, shouldn't these have shown up as unresolved references because of the ABI_TAG (""cxx11"" or ""_cxx11"", according to this:. https://developers.redhat.com/blog/2015/02/05/gcc5-and-the-c11-abi/. ) ?. ccache was installed and was active for the salmon build. It was removed and salmon rebuilt. No difference, it still segfaults.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641652976:770,install,installed,770,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641652976,1,['install'],['installed']
Deployability,"That seems to fix it! Any thoughts on these other incantations I have there?. ```; ##; # This ensures that the salmon executable should work with or without `make install`; ##; # Grumble grumble . . . OSX; if (APPLE); # only attempt install_name_tool for tbb if we installed it; if (${TBB_LIBRARY_DIRS} MATCHES ${GAT_SOURCE_DIR}/external/install/lib); add_custom_command(TARGET salmon; POST_BUILD; COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/salmon; COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/salmon; COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/salmon; COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/salmon; ); add_custom_command(TARGET unitTests; POST_BUILD; COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/unitTests; ); endif(); else(); # related to complete static linking --- on hold ; set (BOOST_THREAD_LIBRARY); endif(). ```. i.e. is this incantation necessary, or not?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239542406:163,install,install,163,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239542406,5,['install'],"['install', 'installed']"
Deployability,"That would be great. I will upgrade to Mojave now. I don't know if it is helpful, but the last binary of Salmon I could get to work on MacOS 10.12.6 was the provided Salmon-0.8.2_macOX_10.12.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/318#issuecomment-442944958:28,upgrade,upgrade,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/318#issuecomment-442944958,1,['upgrade'],['upgrade']
Deployability,"That's amazing @Gaura. This feature has been frequently requested by multiple users but I never got a chance to work on this, thanks a lot for the PR. Give me some time to go over the PR and if everything looks Ok, we can merge it in into the next release cycle. May I ask previous version of inDrop had an issue with variable length barcodes, did they solved that issue in v2 ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/703#issuecomment-920921204:248,release,release,248,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/703#issuecomment-920921204,1,['release'],['release']
Deployability,That's not to say I don't see the utility of having this built in. I'll try and add this command to the next release ;).,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-299711727:109,release,release,109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-299711727,1,['release'],['release']
Deployability,"That's what I thought... But no. Updating conda did not solve the problem. Best wishes,; Javier; (Sent from my iPhone). On Feb 9, 2018, at 6:34 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. This is really strange; the latest version for Mac should be 0.9.1 (see here<https://anaconda.org/bioconda/salmon>). Does anything change if you do a conda update/upgrade?. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364599820>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AiohHfqVY_pmlr_ho7ab77WhaqSIVP-mks5tTNYAgaJpZM4SAonB>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364609365:382,update,update,382,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364609365,2,"['update', 'upgrade']","['update', 'upgrade']"
Deployability,"The ""effective"" mapping rate is the true mapping rate that is used e.g. in the TPM / estimated number of reads calculations. The overall mapping rate, in addition to being poorly named, is a historical artifact. The proposal here (which should be implemented in the next release) is to report only a single ""mapping rate"" (which will be equal to what is currently the ""effective"" mapping rate), that represents the quantities used in comping the TPM and estimated number of reads columns.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/14:271,release,release,271,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/14,1,['release'],['release']
Deployability,The Arabidopsis example in the getting started guide ([https://combine-lab.github.io/salmon/getting_started/](https://combine-lab.github.io/salmon/getting_started/)) seems to work fine on FreeBSD 13.0 with salmon installed via miniconda per instructions above.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-989865038:213,install,installed,213,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-989865038,1,['install'],['installed']
Deployability,"The answer here could simply be 'no' 😄 but as this question came up recently for me, and it is one I've seen mentioned on the `nf-core/scrna` slack, I figured I'd raise it here to get your thoughts. . There is a standard CellRanger workflow for the 10x V(D)J approach (https://support.10xgenomics.com/single-cell-vdj/software/pipelines/latest/using/vdj). Is this something remotely achievable with `alevin/alevin-fry`? It would be great for those who have matched 10x scRNA-seq to be able to process everything with the same package!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/861:326,pipeline,pipelines,326,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/861,1,['pipeline'],['pipelines']
Deployability,"The gencode option behaves described above, and is implemented as of commit d44df88, so it should make it into the next tagged release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/15#issuecomment-241235707:127,release,release,127,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/15#issuecomment-241235707,1,['release'],['release']
Deployability,The git clone doesn't work. ```; git clone git@github.com:COMBINE-lab/salmon.git; cd salmon; mkdir build; cd build; cmake ..; make install; ```. This should work:; ```; git clone https://github.com/COMBINE-lab/salmon.git; ```,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/244:131,install,install,131,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/244,1,['install'],['install']
Deployability,"The implementation to output mapping information from within salmon (not yet full alignments) is almost complete. The feature needs some testing, but it will definitely make it into the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-242924562:191,release,release,191,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-242924562,1,['release'],['release']
Deployability,"The jellyfish is installed in a non standard place. How to tell cmake where jellyfish is installed?. I tried the ""-DJELLYFISH_ROOT"" parameter but it didn't work. My best regards.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/225:17,install,installed,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/225,2,['install'],['installed']
Deployability,The lack of openMP on osx has been terrible so I completely appreciate not requiring it. It looks like your hotfix solved the threading problems now and Alevin ran to completion for me! . Thanks so much for the speedy replies and fixes!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396325275:108,hotfix,hotfix,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396325275,1,['hotfix'],['hotfix']
Deployability,The languages of both autotools and CMake are pretty terrible. I actually like the Make language; I think it gets a bad wrap. Other than `config.h` was there any other files of Jellyfish that were missing from the install that you needed?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195461547:214,install,install,214,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195461547,1,['install'],['install']
Deployability,"The last patch display the error with `std::cerr << ...`, because `log->critical(...)` does not seem to work. Not sure how to fix it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/617#issuecomment-835404939:9,patch,patch,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/617#issuecomment-835404939,1,['patch'],['patch']
Deployability,"The pre-compiled Release now finally seems to work, so nevermind!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/729#issuecomment-993410585:17,Release,Release,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/729#issuecomment-993410585,1,['Release'],['Release']
Deployability,"The same with version 1.2.0. Is there a way to disable version check by default, completely? I install Salmon as a module and I wouldn't let it update itself automatically, anyway.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-590911530:95,install,install,95,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-590911530,2,"['install', 'update']","['install', 'update']"
Deployability,The script was running `cmake && make install` with no `make`. Could that be it? I've added `make` before `make install`. I'll get that log file for you.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367756380:38,install,install,38,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367756380,2,['install'],['install']
Deployability,"The soft-clipping feature is improved in this pull request and accurate CIGAR calculation can be done by passing the corresponding user flag to salmon. This PR uses a new version of pufferfish repository that has these new features implemented. Here's a summary of the changes:; - The soft-clipping can be enabled by `--softclip` flag in the selective-alignment mode of the quant command, same as before. ; - `--softclipOverhangs` flag is deprecated and in this release will have the same effect as `--softclip`.; - Accurate CIGAR calculation can be enabled by the new `--computeCIGAR` flag in the selective-alignment mode of the quant command.; - Another new argument `--maxSoftclipFraction` restricts the fraction of the soft-clipped part of a read. An alignment is reported if and only if `alignment_score >= minScoreFraction * max_alignment_score` where `max_alignment_score = match_score * (read_length – softclip_length)`. This threshold applies separately to the mates of a paired-end read and the soft-clip length on a mate will not affect the maximum allowed soft-clip length on the other mate. ; - If the total length of the soft-clipped regions on a read (in the beginning and the end of the read) is greater than maxSoftclipFraction * read_length, another chance will be given to the read to be aligned end-to-end. If the end-to-end alignment is acceptable based on its score, it will be reported. ; - The new `--endBonus` argument specifies how strict the soft-clipping decisions are made in the program. It specifies the extra bonus score that is added to the end-to-end alignment score, when the alignment reaches the end of query. The larger this value is set, the more likely that soft-clipping is not reported as part of the alignment of a particular query because getting to the end of the query would be preferred. . ** Note that pufferfish library is installed from a branch at the moment and it should be set to the new version of pufferfish once it is released.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/692:462,release,release,462,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/692,3,"['install', 'release']","['installed', 'release', 'released']"
Deployability,"The specific error message seems to be coming from [the serialization library we use](https://github.com/USCiLab/cereal/blob/master/include/cereal/archives/portable_binary.hpp#L245). This was upgraded recently, so I'm hoping that they didn't introduce a new bug upstream. As soon as I can reproduce this, I can test if rolling back the version of the serialization library fixes the issue (which I don't believe occurred in 0.7.2).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287255919:192,upgrade,upgraded,192,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287255919,2,"['rolling', 'upgrade']","['rolling', 'upgraded']"
Deployability,"The virtual memory should also be greatly reduced in 1.2.0 (which I am working on finalizing the release of at the moment). There will be detailed release notes describing the improvements. However, getting the pre-built index is probably worth it if it's the right organism and annotation.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/503#issuecomment-612193221:97,release,release,97,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/503#issuecomment-612193221,2,['release'],['release']
Deployability,"There has been a small amount of discussion about the BD Rhapsody barcode / sequence format (e.g. see [here](https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-551083490)), but it would be great if the option could be integrated into the code. BD has produced a [Single Cell Genomics Bioinformatics Handbook](https://www.bd.com/documents/guides/user-guides/GMX_BD-Rhapsody-genomics-informatics_UG_EN.pdf) which has the following information about the R1 read structure on pg 14:. 5' CLS1 - L1 - CLS2 - L2 - CLS3 - UMI - poly(T); 9 12 9 13 9 8 18; [1-9] [22-30] [44-52][53-60]. > **Cell Label** Information of the cell label is captured by bases in three sections (CLS1, CLS2, CLS3) along each R1 read. Two common sequences (L1, L2) separate the three CLSs, and the presence of L1 and L2 relates to the way the capture oligonucleotide probes on the beads are constructed. By design, each CLS has one of 96 predefined sequences, which has a Hamming distance of at least four bases and an edit distance of at least two bases apart. A cell label is defined by the unique combination of predefined sequences in the three CLSs. Thus, the maximum possible number of cell labels is 96^3 (884,736). A cell label is represented by an index between 1–96^3. > Reads are first checked for perfect matches in all three pre-designed CLS sequences at the expected locations, CLS1:; position 1–9, CLS2: position 22–30, and CLS3: position 44–52. Reads with perfect matches are kept. In other words...; - Concatenate subsequences 1-9, 22-30, and 44-52 to form a 27-base cell label; - Extract subsequence 53-60 as the UMI . > **UMI** By design, the UMI is a string of eight randomers immediately downstream of CLS3. If the CLSs have perfect matches or base substitutions, the UMI sequence is at position 53–60. For reads with insertions or deletions within the CLSs, the UMI sequence is eight bases immediately following the end of the identified CLS3. R2 reads are transcript-only, and are expected to match a",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/628:229,integrat,integrated,229,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/628,1,['integrat'],['integrated']
Deployability,"There is not a known bug here, but this is certainly strange. Given that version 0.14.1 is very old now, I think the best thing to do is just put a caveat on the release page.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/652#issuecomment-1138630790:162,release,release,162,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/652#issuecomment-1138630790,1,['release'],['release']
Deployability,"There is nothing obvious about the command you provided that looks incorrect. Can you please check if the segmentation fault still occurs with the most recent release of salmon (either 1.10 or 1.10.1)?. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/847#issuecomment-1533935566:159,release,release,159,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/847#issuecomment-1533935566,1,['release'],['release']
Deployability,"There is now more stringent checking of the input to the digamma function, and so these issues should be resolved in the current release. Please report back (and re-open this) if you still encounter this issue.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/48#issuecomment-303617709:129,release,release,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/48#issuecomment-303617709,1,['release'],['release']
Deployability,"There was previously a bug that could lead to this behavior if the transcript to gene mapping was incomplete (i.e. if there were transcripts without an appropriately mapping gene). This is fixed in the latest release. Nonetheless, I'll note that [tximport](http://bioconductor.org/packages/release/bioc/html/tximport.html) is now the preferred way to aggregate abundances to the gene level.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/60#issuecomment-281436353:209,release,release,209,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/60#issuecomment-281436353,2,['release'],['release']
Deployability,"There's been some issues with compiling salmon on macOS for some time now (see also https://github.com/brewsci/homebrew-bio/pull/528). In the current version, I was running into two compile errors on macOS:. 1) problems with staden & Clang; 2) problems with linking to boost static libraries. I could fix (1) by installing staden separately and then using that install in salmon. I've included the respective Find***.cmake files. (2) is an easy fix by modifying the `CMakeLists.txt`. Is there any particular preference for using static libraries? This is a rather small patch and could be done in a Homebrew formula, if you prefer static boost libraries. Otherwise, this PR are just suggestions. If you have changes that better conform to you style, that's fine by me. Thanks,; Gabriel",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348:312,install,installing,312,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348,3,"['install', 'patch']","['install', 'installing', 'patch']"
Deployability,These 1800 transcripts have a degradation signal we are looking to allow other researchers to model. The thought was we could build a pipeline to do so and that by restricting it to the 1800 for salmon it might not be computationally inaccessible.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/681#issuecomment-873058012:134,pipeline,pipeline,134,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/681#issuecomment-873058012,1,['pipeline'],['pipeline']
Deployability,These are resolved in develop and will be fixed in the next release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/149#issuecomment-335952935:60,release,release,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/149#issuecomment-335952935,1,['release'],['release']
Deployability,"Thinking more about it, we can actually throw away a whitelisted CB with 0 frequency w/ a warning .; Once we discuss this w/ the alevin team, I'd happy to add this filter to the alevin pipeline . Thanks again @habilzare for pointing this out .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406460828:185,pipeline,pipeline,185,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406460828,1,['pipeline'],['pipeline']
Deployability,"This *usually* means that the version of the boost library you have was not compiled with a C++11-compatible ABI. There is a incompatibility between pre C++11 and post C++11 `std::string` representations, and since salmon uses modern C++ (C++14 as of this writing), you need a version of boost compiled in a compatible way. How was boost installed on your system?. Of course, if you don't need to compile from source, it's *much* easier to install via conda, or to grab the pre-built executable (1.10.0 is feature and bugfix identical to 1.10.1). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/551#issuecomment-1577237260:338,install,installed,338,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/551#issuecomment-1577237260,2,['install'],"['install', 'installed']"
Deployability,"This PR introduces a new feature that will allow users to specify custom single cell protocols and use with alevin. Custom Geometry (--custom-geo) should be used when:; 1. Barcode or umi have variable lengths; 2. There is known fixed sequence in the reads; 3. There is some sequence to be excluded; From the input peglib spec it creates a regex. Boost regex library is used to parse the reads. Apart from small tests on multiple outlier cases, it was tested on a sci-RNA-seq3 sample SRR7827207 for speed. For this the spec is `--custom-geo 1{b[9-10]f[CAGAGC]u[8]b[10]}2{r}`. It says:; - Read 1 starts with barcode of variable length 9-10 bp, followed by; - A fixed sequence CAGAGC, then; - A umi of length 8, and lastly; - barcode of length 10.; - The second read is all biological. The barcodes are concatenated in the output and a padding sequence is added to make the length as max length + 1. The extra base is added so that we don't introduce spurious matches in barcode. For example, if the barcodes have length 3-4 bp and the two barcodes are `ATG` and `ATGA`, after padding they will be `ATGAC` and `ATGAA` resp. Adding just `A` to shorter barcode would result in a spurious match. . Since `--custom-geo` uses regex, it is slower than protocol specific flag. The time with 8 threads on a large Ubuntu 20 machine:. 1. Using `--sciseq3`:; ```; real 1m0.425s; user 7m21.501s; sys 0m2.964s; ```; 2. Using `--custom-geo`; ```; real 1m39.887s; user 11m55.602s; sys 0m6.839s; ```; Notably, it is about 66% slower. However, it allows support for almost all current and future protocols. . There will be a tutorial shortly on how and when to use this and how is it different from other flags such as `--umi-geometry`, `--read-geometry` and `--bc-geomtery`. There is scope of speed improvement in the future along with integration of all custom geometry processing protocols.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734:1817,integrat,integration,1817,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734,1,['integrat'],['integration']
Deployability,"This PR is related to https://github.com/COMBINE-lab/salmon/pull/276#issue-210022241 . It is to add lintcheck for cmake files. ## How to use. ```; $ pip3 install cmakelint. $ which cmakelint; /path/to/cmakelint. $ ./scripts/lint.sh; ```. Every CMakeLists.txt or *.cmake file in this repository is target for the check.; Right now I only modified `./CMakeLists.txt` to show for the example, and changed the permission of the executable bit file. Maybe the executable bit is not necessary.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/293:154,install,install,154,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/293,1,['install'],['install']
Deployability,This PR updates the version of stadenio_libs and htscodecs.; These versions introduce changes that make them more amenable to be compiled for ARM.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/916:8,update,updates,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/916,1,['update'],['updates']
Deployability,"This bug is primarily related to salmon (bulk mode). **Describe the bug**; I followed your instructions to create a `mm10` indexed transcriptome with decoys, but I encounter a weird error called:. ```; [puff::index::jointLog] [error] The fixFasta phase failed with exit code 1; ```. **To Reproduce**. First install `salmon` and `mashmap` (`awk` and `bedtools` are already installed).; ```; conda create -n salmon salmon; conda activate salmon; conda install -c bioconda mashmap; ```. ```; salmon -v; salmon 1.6.0; ```; Download transcriptome from ensembl:; ````; mkdir /no_backup/transcriptome_seqs; cd transcriptome_seqs; wget http://ftp.ensembl.org/pub/release-102/fasta/mus_musculus/cdna/Mus_musculus.GRCm38.cdna.all.fa.gz; # Rename the file to make more sense for my in the future; mv Mus_musculus.GRCm38.cdna.all.fa.gz Mus_musculus_ENSEMBL_v_102_GRCm38_cdna_all.fa.gz; ````. Build a *decoy-aware* transcriptome file as recommended:; download script with:; ```; wget https://raw.githubusercontent.com/COMBINE-lab/SalmonTools/master/scripts/generateDecoyTranscriptome.sh; ```; Run with:; ```; ./generateDecoyTranscriptome.sh \; -a /no_backup/genome_annots/Mus_musculus_ENSEMBL_v_102_GRCm38.gtf \; -g /no_backup/genome_seqs/Mmu10_gDNA.fasta \; -t /no_backup/transcriptome_seqs/Mus_musculus_ENSEMBL_v_102_GRCm38_cdna_all.fa.gz \; -o /no_backup/indexes/salmon/mm10; ```; It takes a bit to finish and once done I can do:. List the fasta headers of the decoy sequences; ```; head decoys.txt ; GL456210.1; chrX; chrY; GL456221.1; JH584304.1; ```. While this shows the the new hybrid (genome + transcriptome) fasta file which contains the decoy sequences from the genome, concatenated with the transcriptome (`gentrome.fa`) for a total of 119414 sequences.; ```; zcat gentrome.fa | grep ""^>"" | wc -l; gzip: gentrome.fa: decompression OK, trailing garbage ignored; 119414; ```. To create a salmon index do the following:; ```; salmon index \; -t /no_backup/indexes/salmon/mm10/gentrome.fa \; -i /no_backup/",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731:307,install,install,307,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731,4,"['install', 'release']","['install', 'installed', 'release-']"
Deployability,This command is implemented in develop and will be in the next release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-335956508:63,release,release,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-335956508,1,['release'],['release']
Deployability,This commit uses multi-stage builds to minimize the Docker image size.; The uncompressed size is down to 101 MB from 1.38 GB. The second ; stage of the build begins with a fresh ubuntu:18.04 image and copies in; the compiled salmon binaries. It also installs one system library that; is linked by one of the salmon shared libraries.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/771:250,install,installs,250,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/771,1,['install'],['installs']
Deployability,This fix is in the newest release (v0.8.0).,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/105#issuecomment-281438049:26,release,release,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/105#issuecomment-281438049,1,['release'],['release']
Deployability,"This is an installation problem. I am getting a link-time error building Salmon 1.0.0 with GCC 7.3.0 and CMake 3.12.1. The error occurs immediately after ""[100%] Linking CXX executable salmon"". The OS is RHEL6. Here's the output:. ```; /software/Core/GCCcore/7.3.0/include/c++/7.3.0/bits/shared_ptr_base.h:522: error: undefined reference to 'vtable for std::_Sp_counted_ptr_inplace<spdlog::logger, std::allocator<spdlog::logger>, (__gnu_cxx::_Lock_policy)2>'; /software/Compiler/GCCcore/7.3.0/binutils/2.30/bin/ld.gold: the vtable symbol may be undefined because the class is missing its key function; /software/Compiler/GCCcore/7.3.0/binutils/2.30/bin/ld.gold: the symbol should have been defined by a plugin; /software/Core/GCCcore/7.3.0/include/c++/7.3.0/bits/shared_ptr_base.h:522: error: undefined reference to 'vtable for std::_Sp_counted_ptr_inplace<spdlog::async_logger, std::allocator<spdlog::async_logger>, (__gnu_cxx::_Lock_policy)2>'; /software/Compiler/GCCcore/7.3.0/binutils/2.30/bin/ld.gold: the vtable symbol may be undefined because the class is missing its key function; /software/Compiler/GCCcore/7.3.0/binutils/2.30/bin/ld.gold: the symbol should have been defined by a plugin; ```. Googling this error implies an issue with the code, not a missing library.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/455:11,install,installation,11,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/455,1,['install'],['installation']
Deployability,"This is concerned with alevin, using a cite-seq like method with a different UMI barcode length. I believe this is similar to #531. running the command like this:. ```; salmon alevin \; -l ISR \; -i ${PROJECT}/adt_index \; -1 $R1_ADT \; -2 $R2_ADT \; --end 5 \; --umiLength 10 \; --barcodeLength 16 \; -o $PROJECT/alevin_adt \; -p 24 \; --featureStart 1 --featureLength 15 \; --naiveEqclass \; --citeseq; ```; Produces the error `ERROR: Please specify one and only one scRNA protocol;`. whereas removing the `--citeseq` argument like this:; ```; salmon alevin \; -l ISR \; -i ${PROJECT}/adt_index \; -1 $R1_ADT \; -2 $R2_ADT \; --end 5 \; --umiLength 10 \; --barcodeLength 16 \; -o $PROJECT/alevin_adt \; -p 24 \; --featureStart 1 --featureLength 15 \; --naiveEqclass; ```; Produces the error `[alevinLog] [critical] Transcript to Gene Map File not provided. Exiting Now.`. This is based on salmon 1.8.0 installed via bioconda on ubuntu 18.04",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/770:904,install,installed,904,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/770,1,['install'],['installed']
Deployability,"This is failing on our local drone CI during runtime. The log output is :. ```; + echo ""[Testing quant]""; [Testing quant]; + ./.drone/test_quant.sh; Holy build box activated; Prefix: /hbb_exe; CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; LDFLAGS: -L/hbb_exe/lib -static-libstdc++; STATICLIB_CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; SHLIB_CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; SHLIB_LDFLAGS: -L/hbb_exe/lib -static-libstdc++; [Drone test] current path : /drone/src/github.com/COMBINE-lab/salmon; [Drone test] making quant test directory; [Drone test] run nextflow pipeline; N E X T F L O W ~ version 0.29.1; Launching `tests/test_quant.nf` [curious_gilbert] - revision: 4f25b30301; [warm up] executor > local; [91/922fac] Submitted process > buildIndex; ERROR ~ Error executing process > 'buildIndex'; Caused by:; Process `buildIndex` terminated with an error exit status (127); Command executed:; /drone/src/github.com/COMBINE-lab/salmon/bin/salmon index -t Homo_sapiens.GRCh37.75.cdna.pc.fa -i nfindex; Command exit status:; 127; Command output:; (empty); Command error:; /drone/src/github.com/COMBINE-lab/salmon/bin/salmon: error while loading shared libraries: libjemalloc.so.2: cannot open shared object file: No such file or directory; Work dir:; /drone/src/github.com/COMBINE-lab/salmon/work/91/922facec25da43edd4a2ce82f2289d; Tip: when you have fixed the problem you can continue the execution appending to the nextflow command line the option `-resume`; -- Check '.nextflow.log' file for detail; ```. So, it seems to be due to failure to find the dynamic shared library for jemalloc. Any idea why that might be?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472495264:607,pipeline,pipeline,607,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472495264,1,['pipeline'],['pipeline']
Deployability,"This is fixed in https://github.com/COMBINE-lab/pufferfish/commit/e7fb924850e2a04793cdd2ace628afa8cf37885c, and should show up in the next (shortly coming) release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/591#issuecomment-733761227:156,release,release,156,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/591#issuecomment-733761227,1,['release'],['release']
Deployability,"This is not exactly a bug, but a comment and a question regarding how Salmon uses the positioning data in fastq files. We had a series a RNASeq samples where the majority of the reads were listed at 0:0 in the fastq file. We think this is some obscure issue with one of the trimming/demultiplexing pipelines. No one noticed, as this data is not generally used, but it did throw an error with rsem. Luckily, this error had been previously [reported](https://groups.google.com/forum/#!topic/rsem-users/qXDCpSbEn6Q). Notably, Salmon using quasi mapping was fine. It was only when I tried again using STAR aligned bam files that I noticed that only those reads not listed at 0:0 were used by Salmon (STAR does not seem to care one way or the other). Obviously, badly formated fastq files do not constitute a bug and we are working on fixing them, but we were curious why the positioning data was being used in alignment mode but not quasi mode. Moreover, why is it being used at all? Is it used to weed out potential artifacts?. Many thanks and happy to share an example file if your are interested.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/101:298,pipeline,pipelines,298,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/101,1,['pipeline'],['pipelines']
Deployability,This is really strange; the latest version for Mac should be 0.9.1 (see [here](https://anaconda.org/bioconda/salmon)). Does anything change if you do a conda update/upgrade?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364599820:158,update,update,158,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364599820,2,"['update', 'upgrade']","['update', 'upgrade']"
Deployability,"This is related to the way `--useFSPD` was implemented (see #64). This flag has been deprecated, and a replacement (`--posBias`) has been introduced as of 0.7.0. This should not exhibit the same behavior. The `--posBias` flag is currently experimental, but will move out of that status in the next major release after it has been in the wild for a bit. Please let me know if the [latest release](https://github.com/COMBINE-lab/salmon/releases/tag/v0.7.1) resolves this issue for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-241465777:304,release,release,304,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-241465777,3,['release'],"['release', 'releases']"
Deployability,This is resolved in develop and will make it into the next release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/148#issuecomment-335953142:59,release,release,59,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/148#issuecomment-335953142,1,['release'],['release']
Deployability,"This isn't strictly speaking a bug with salmon per-se, but when installing salmon from conda, its impossible to have both R 4.0.3 and Salmon 1.3.0 installed in the same environment (which is frustrating due to the downstream analysis of Salmon data with wasabi/sleuth then requiring a separate environment). The core incompatibility seems to be with the International Components for Unicode package. Salmon requires; ""icu >=64.2,<65.0a0"",; Whereas in one of the R dependencies when installing 4.0.3 in the environment solve the following is specified; ""icu >=67.1,<68.0a0"",. This seems to be the only conflict I could identify.; This seems to be a new incompatibility introduced with R 4.0.3 and Salmon can coexist alongside R 4.0.2 without issue, so this isn't a huge problem but something I thought should probably be on your radar if it isn't already. Output from the conda dry-run as follows: ; [salmon_solve.txt](https://github.com/COMBINE-lab/salmon/files/5619618/salmon_solve.txt); [r-base_solve.txt](https://github.com/COMBINE-lab/salmon/files/5619619/r-base_solve.txt)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/594:64,install,installing,64,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/594,3,['install'],"['installed', 'installing']"
Deployability,"This issue is related to salmon (bulk mode). When running salmon quant, everything seems to run normally until the very end, when there is suddenly ""Segmentation fault (core dumped)"" and then a quant file is not written. Started with --gcBias, then tried with --seqBias, then without either and get the same error. Have run Salmon in the past with no issues. Have updated to the latest version but problem persists. The version is salmon (mapping-based) v0.11.1 and was installed through bioconda.; The command being run is:. ```; salmon quant -i /data2/csijcs/hg38/hg38.transcriptome.index -l A \; -1 ${dir}/${samp}/${samp}_R1_001.fastq.gz \; -2 ${dir}/${samp}/${samp}_R2_001.fastq.gz \; -p 16 -o ${dir}/salmon_quants/${samp}; ```. The output is:; ```; Processing sample PBMC_AML_BM_001; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.11.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /data2/csijcs/hg38/hg38.transcriptome.index }; ### [ libType ] => { A }; ### [ mates1 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/PBMC_AML_BM_001/PBMC_AML_BM_001_R1_001.fastq.gz }; ### [ mates2 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/PBMC_AML_BM_001/PBMC_AML_BM_001_R2_001.fastq.gz }; ### [ threads ] => { 16 }; ### [ output ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/PBMC_AML_BM_001 }; Logs will be written to /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/PBMC_AML_BM_001/logs; [2018-07-30 15:41:42.232] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-30 15:41:42.232] [jointLog] [info] parsing read library format; [2018-07-30 15:41:42.232] [jointLog] [info] There is 1 library.; [2018-07-30 15:41:45.840] [jointLog] [info] Loading Quasi index; [2018-07-30 15:41:45.840] [jointLog] [info] Loading 32-bit quasi index; [2018-07-30 15:41:45.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261:364,update,updated,364,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261,2,"['install', 'update']","['installed', 'updated']"
Deployability,"This seems to be a separate issue than the other (and a more informative exception). Once I've resolved the other issue, I would probably try to bug you for a sample that causes this --- though I have a reasonable idea about how to fix it. It would be nice to have the fix for both issues in the same hotfix. To be more specific : this is, as the exception says, a numeric underflow issue when evaluating the digamma function. The solution here is just to bump up the value that is required before evaluating this function. This should be straightforward, but I suspect the issue is also related to this log message:. > [2018-05-31 17:08:11.488] [jointLog] [info] Marked 1 weighted equivalence classes as degenerate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393571565:301,hotfix,hotfix,301,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393571565,1,['hotfix'],['hotfix']
Deployability,This small patch adds two options to quant merge:; - --genes to force use of quant.genes.sf instead of quant.sf ;; - --missing <arg> to change the default value in case of missing value.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/344:11,patch,patch,11,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/344,1,['patch'],['patch']
Deployability,"This was caught by an end-user, reporting that `salmon` was not found. I just [patched our installation script](https://github.com/HenrikBengtsson/CBI-software/blob/c0ed7c62446b8b26559bb71ff5f55c7d8e751296/CBI/salmon/Makefile#L24-L29) to do:. ```sh; chmod -R go+r $(PREFIX); chmod ugo+x $(PREFIX)/{bin,lib,bin/salmon}; ```. which I decided on looking at what salmon 1.7.0 had, except I skipped setting executable on the `lib/*.so` files (which 1.7.0 has for some of them).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/761#issuecomment-1067244078:79,patch,patched,79,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/761#issuecomment-1067244078,2,"['install', 'patch']","['installation', 'patched']"
Deployability,"To authentic-zz:; You mean you have get the counts into a data frame. I don't know how to transfer the salmon data frame into DESeq2，and I fail to handle data frame from salmon, too. So I have these recommendations to you: ; 1. Get the salmon raw results, the sf files, as the tximport input files.; 2. Run the salmon again or choose other pipeline like HISAT2-Stringtie/featurecounts/HTseq.; 3. Try to generate the salmon sf file. The sf file's row name is ""Name Length EffectiveLength TPM NumReads"". You have the gene ID and counts, so fill the length, effect length, and TPM by tab or something. But I do not sure if this handle is correct. https://salmon.readthedocs.io/en/latest/file_formats.html#fileformats",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-782990393:340,pipeline,pipeline,340,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-782990393,1,['pipeline'],['pipeline']
Deployability,To reproduce this error:. ``` sh; docker run linuxbrew/linuxbrew brew install gcc homebrew/science/salmon; ```,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-193897441:70,install,install,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-193897441,1,['install'],['install']
Deployability,"To whom it may concern,. I have been using Salmon to quantify RNA-seq data using a new long-read RNA sequencing-based GTF I have developed. When I run Salmon on RNA-seq samples from TCGA (read length = 50 bp, kmer length = 21), I tend to get ~95% of reads mapping to my transcriptome. However, when I use the same script to run my pipeline on in-house sequenced data (read length = 150 bp, kmer length = 21), I am getting only around 80-85% of reads mapping to my transcriptome. According to STAR, >90% (usually >95%) of these same in-house samples mapped to the genome. Why am I getting lower mapping rates? Could read length have something to do with it? Thanks so much for any advice or guidance you can provide. Script: ; [5_runSalmon.sh.zip](https://github.com/COMBINE-lab/salmon/files/10262688/5_runSalmon.sh.zip); (The only difference between my TCGA and in-house runs are that for TCGA I use ""-i IU"" and for my in-house samples I use ""-i ISR"" due to differences in the strandedness of the prep protocols). Yours most sincerely,; Ryan Englander",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/819:331,pipeline,pipeline,331,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/819,1,['pipeline'],['pipeline']
Deployability,Trying to generate salmon indexes in WSL with Ubuntu 22.04.01 LTS either hangs after the contig count for validation step or throws a segmentation fault. . Using Salmon 1.9 installed through bioconda; Custom annotation of S. cerevisiae R64-3-1 downloaded from SGD. The whole genome was appended as a decoy,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/829:173,install,installed,173,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/829,1,['install'],['installed']
Deployability,"UPDATE: On @rob-p 's suggestion, I removed the `--recoverOrphans` option and then all 60 samples did finished without segfaulting. Perhaps there were too many orphans to handle - alignments rates were a dismal 0.5-23%. These were heavily degraded samples that the sequencing center recommended not to sequence but the PI wanted to try it anyway. If you want a pair of fastq files (full or cutdown to ~5 M reads) to test this weird edge case, I can see about getting them to you. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/668#issuecomment-862525216:0,UPDATE,UPDATE,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/668#issuecomment-862525216,1,['UPDATE'],['UPDATE']
Deployability,"UPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -rdynamic CMakeFiles/unitTests.dir/__/tests/UnitTests.cpp.o CMakeFiles/unitTests.dir/FragmentLengthDistribution.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/bit_array.c.o -o unitTests -L/home/mathog/src/salmon/lib -L/home/mathog/src/salmon/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" libsalmon_core.a libalevin_core.a -lgff -lpthread ../external/install/lib/libstaden-read.a -lz ../external/install/lib/libdivsufsort.a ../external/install/lib/libdivsufsort64.a ../external/install/lib/libbwa.a -lm -llzma -lbz2 -ltbb -lgomp -lrt ../external/install/lib/libjemalloc.a -lrt -ldl ../external/install/lib/libjemalloc.a -ldl`. Oh, I also had to update automake and autoconf because the 2 year old versions on this system were not new enough. Is there a static binary version of salmon available for download, Linux 64 bit? It looks like the default links are that way anyway, and that would save me what looks like at least another day of fighting with Cmake to force it to actually build a working make file. . You are developing on something like a recent Fedora or Ubuntu? In my experience packages which use boost and cmake inevitably cause a great great deal of pain when they are built on platforms like Centos or RHEL where long term support is one of the goals. They work fine ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:3063,install,install,3063,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['install'],['install']
Deployability,"URE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE; $ make; $ tar xaf sample_data.tgz; $ src/salmon index -t sample_data/transcripts.fasta -i sample_salmon_quasi_index; Version Info: This is the most recent version of salmon.; [2023-03-08 17:30:38.873] [jLog] [warning] The salmon index is being built without any decoy sequences. It is recommended that decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be provided during indexing. Further details can be found at https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indices-mapping-based-mode.; [2023-03-08 17:30:38.873] [jLog] [info] building index; out : sample_salmon_quasi_index; [2023-03-08 17:30:38.873] [puff::index::jointLog] [info] Running fixFasta; ; [Step 1 of 4] : counting k-mers; ; [2023-03-08 17:30:38.879] [puff::index::jointLog] [info] Replaced 0 non-ATCG nucleotides; [2023-03-08 17:30:38.879] [puff::index::jointLog] [info] Clipped poly-A tails from 0 transcripts; wrote 15 cleaned references; Segmentation fault. * Version 1.9.0 as well as version 1.10.0 are affected. Unfortunately we did not managed to package version 1.7.0 and 1.8.0 but I confirm that version 1.6.0 was not affected by the described problem.; * Salmon was build as Debian package as well as built from source (see above); * The reference was taken from the `sample_data` shipped with the release tarball. **Expected behavior**; Clean processing without SEGFAULT. **Desktop (please complete the following information):**; - OS: Debian (testing or unstable). **Additional context**; * You can find some debug logs inside the [Debian bug log](https://bugs.debian.org/1028713). ; * There is a build log which includes the said salmon call above as [build time test](https://salsa.debian.org/med-team/salmon/-/jobs/4031000); * When ignoring the package build time test the [Continuous Integration log](https://salsa.debian.org/med-team/salmon/-/jobs/3980059) might be interesting as well. Kind regards, Andreas.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835:2263,release,release,2263,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835,3,"['Continuous', 'Integrat', 'release']","['Continuous', 'Integration', 'release']"
Deployability,"Ubuntu 20.04 LTS, with gcc version 9.3.0 (Ubuntu 9.3.0-17ubuntu1~20.04) ; fails to compile salmon due to an internal compiler error.; The problem occurs for both the 1.4.0 release as well as the current; git master branch during the final linking of the salmon executable:. ```; git clone https://github.com/COMBINE-lab/salmon.git; mkdir salmon/build; cd salmon/build ; cmake -DFETCH_BOOST=TRUE -DCMAKE_INSTALL_PREFIX=${PREFIX} ..; make; ```. ```; [100%] Linking CXX executable salmon; /usr/bin/ld: ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): in function `find_file_url':; open_trace_file.c:(.text+0xf4e): warning: the use of `tempnam' is dangerous, better use `mkstemp'; during IPA pass: icf; lto1: internal compiler error: Segmentation fault; Please submit a full bug report,; with preprocessed source if appropriate.; See <file:///usr/share/doc/gcc-9/README.Bugs> for instructions.; lto-wrapper: fatal error: /usr/bin/c++ returned 1 exit status; compilation terminated.; /usr/bin/ld: error: lto-wrapper failed; collect2: error: ld returned 1 exit status; make[2]: *** [src/CMakeFiles/salmon.dir/build.make:456: src/salmon] Error 1; make[1]: *** [CMakeFiles/Makefile2:689: src/CMakeFiles/salmon.dir/all] Error 2; make: *** [Makefile:163: all] Error 2; ```. With VERBOSE=1, this is the final command that fails:; ```; /usr/bin/c++ -O3 -DNDEBUG -flto -fno-fat-lto-objects CMakeFiles/salmon.dir/EMUtils.cpp.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedCellOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/Graph.cpp.o CMakeFiles/salmon.dir/DedupUMI.cpp.o CMakeFiles/salmon.dir/Alevin.cpp.o CMakeFiles/salmon.dir/AlevinHash.cpp.o CMakeFiles/salmon.dir/SalmonAlevin.cpp.o CMakeFiles/salmon.dir/WhiteList.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMa",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/664:172,release,release,172,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/664,2,"['install', 'release']","['install', 'release']"
Deployability,"Uh, why then does ""make test"" fail if the root directory name is changed? That was using the binary/libraries in $WHEREVER, after bin and lib below the root directory were removed. Typically that sort of operation doesn't care what the top level is named. For some future release, perhaps the run time dynamic loading of libraries could look up the path to libtbb.so.2 and try that first, before falling back to LD_LIBRARY_PATH? On my system ldd of salmon shows a link to libtbb.so.2, no LD_LIBRARY_PATH needed. ldd does not show any links to libtbb.malloc*. The program will do at least ""salmon --help' that way without any errors or warnings. That isn't sufficient to pass ""make test"" though (even when the directory has not been renamed). It seems that libtbb.malloc* libraries are used during that test, and that use requires LD_LIBRARY_PATH. Only when they are found that way does ""make test"" work.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397063656:272,release,release,272,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397063656,1,['release'],['release']
Deployability,Unfortunately I can't use apt-get/brew/yum to install zlib since I'm not root on my cluster. This is why I installed zlib-1.2.11 separately. . Make doesn't seem to allow the same commands as cmake so `-DZLIB_LIBRARY=/users/work/jake/bin/zlib-1.2.11/` or any variation of it isn't accepted. I guess I'll keep plugging away to see if I can resolve the issue. There isn't any build files that I could modify to include the directory path to zlib?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314459160:46,install,install,46,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314459160,2,['install'],"['install', 'installed']"
Deployability,"Unfortunately I don't have much thoughts about the low mapping rates of Drop-seq technology. ; Although, it doesn't necessarily have to be associated with the mapping rate, from what I remember a lot CB are more than one-edit distance away from the high quality barcodes which are excluded from the mapping phase of the pipeline.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/738#issuecomment-1024672260:320,pipeline,pipeline,320,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/738#issuecomment-1024672260,1,['pipeline'],['pipeline']
Deployability,"Unfortunately it's getting into a little under explored territory. ; Retrospectively, it does makes sense to have such a threshold but sadly in the current version we don't have that option. If it may help, I just got some stats for 10x data and generally it's around top < 1% of the data which is useful, which should be even lower in dropseq. Although it's possible my sample size of 5 below dataset is too small. ```; useful -> total; 4k -> 1,239,476; 8k -> 1,877,718; 900 -> 657,180; 2k -> 1,653,795; 9k -> 2,812,291; ```. My guess is keeping the `keepCBFraction` even to 0.1 (i.e. 10%) would get you decent number of empty/low confidence CB to correct for downstream but you might have to explore a little. Another caveat is, having too many CB blows up the memory for downstream whitelisting of alevin and currently there is no option to disable that whitelisting, again a must have feature which is missing. Thanks for this very useful discussion, we will definitely improve/add these options into alevin with the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490857399:1026,release,release,1026,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490857399,1,['release'],['release']
Deployability,"Untar salmon tarball:; ```; $ tar xzvf Salmon-0.9.1_linux_x86_64.tar.gz; ```; Verify binary file is executable:; ```; $ cd Salmon-latest_linux_x86_64/bin && ls -l; total 25336; -rwxr-xr-x 1 bgarchow staff 12971263 Nov 28 22:30 salmon; ```; Try to run salmon:; ```; bin $ ./salmon -h; -bash: ./salmon: cannot execute binary file: Exec format error; ```. BASH version:; ```; $ bash --version; GNU bash, version 4.4.18(1)-release (x86_64-apple-darwin16.7.0); Copyright (C) 2016 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/192:419,release,release,419,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/192,1,['release'],['release']
Deployability,Update .travis.yml to add test case easily.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/273:0,Update,Update,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/273,1,['Update'],['Update']
Deployability,Update CMakeLists.txt,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/23:0,Update,Update,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/23,1,['Update'],['Update']
Deployability,Update Ocean Genomics contact,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/623:0,Update,Update,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/623,1,['Update'],['Update']
Deployability,Update README.md,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/63:0,Update,Update,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/63,2,['Update'],['Update']
Deployability,Update alevin.rst,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/257:0,Update,Update,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/257,1,['Update'],['Update']
Deployability,Update library_type.rst,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/35:0,Update,Update,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/35,1,['Update'],['Update']
Deployability,Update salmon in conda,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/622:0,Update,Update,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/622,1,['Update'],['Update']
Deployability,"Updated Expected behavior: ; A clear and concise description of what you expected to happen.; I aim to retain all gene IDs, and for those represented by multiple lines, I intend to calculate the sum of values for each unique gene ID. I came across a few posts regarding this issue, but have not found a good solution for salmon quantmerge yet",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/910#issuecomment-1918166379:0,Update,Updated,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/910#issuecomment-1918166379,1,['Update'],['Updated']
Deployability,Updated README.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/63:0,Update,Updated,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/63,1,['Update'],['Updated']
Deployability,Updated documentation to explicitly show --chromiumV3 option,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/421:0,Update,Updated,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/421,1,['Update'],['Updated']
Deployability,"Updated error model for ONT reads -- uses a markov model to model mismatches, indels, and homopolymer regions. Kmer size and step size for the markov model are set at 50 in ONTAlignmentModel.hpp, but could be adjusted (50 was found to be the best out of the values of k I tried).",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/868:0,Update,Updated,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/868,1,['Update'],['Updated']
Deployability,Updated reference genome causes different transcripts quantification,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/809:0,Update,Updated,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/809,1,['Update'],['Updated']
Deployability,Updated to resolve a short options conflict and fix issue #111 (which only occurred on the develop branch with the combination of `--useVBOpt` and `--numGibbsSamples`). [Salmon-0.7.3-pre_OSX_10.12.tar.gz](https://github.com/COMBINE-lab/salmon/files/665033/Salmon-0.7.3-pre_OSX_10.12.tar.gz),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-268402355:0,Update,Updated,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-268402355,1,['Update'],['Updated']
Deployability,Use installed cereal and stadenio libraries if available.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348:4,install,installed,4,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348,1,['install'],['installed']
Deployability,"Using the rest of the same configure flags without `-DUSE_SHARED_LIBS=TRUE`, the build does not link properly. I think you should try building without these extra flags. Since the LTO seems not to be a problem on this system, a simple `cmake .. && make` should work. In the mean time, I'll try and pare back the configure command line to find the maximum viable interpolation between our different configurations. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464012294:398,configurat,configurations,398,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464012294,1,['configurat'],['configurations']
Deployability,Verification that I'm running with the right version of TBB:. ```; $ ls ~/src/salmon/external/tbb* -d; /home/ryan/src/salmon/external/tbb-2017_U3 /home/ryan/src/salmon/external/tbb-2017_U3.tgz; $ ldd `which salmon`; linux-vdso.so.1 => (0x00007ffc739fd000); libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f5745a93000); libtbb.so.2 => /home/ryan/src/salmon/external/install/lib/libtbb.so.2 (0x00007f5745864000); libgomp.so.1 => /usr/lib/x86_64-linux-gnu/libgomp.so.1 (0x00007f5745642000); librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f574543a000); libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f5745130000); libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f5744f1a000); libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f5744b51000); /lib64/ld-linux-x86-64.so.2 (0x000055d36c7b0000); libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f574494c000); libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f57445ca000); ```,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267773540:382,install,install,382,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267773540,1,['install'],['install']
Deployability,"WTIncConstructFromPacked] 50 iterations done. 348084948 characters processed.; [BWTIncConstructFromPacked] 60 iterations done. 396161956 characters processed.; [BWTIncConstructFromPacked] 70 iterations done. 438888868 characters processed.; [BWTIncConstructFromPacked] 80 iterations done. 476860644 characters processed.; [BWTIncConstructFromPacked] 90 iterations done. 510606036 characters processed.; [BWTIncConstructFromPacked] 100 iterations done. 540594980 characters processed.; [BWTIncConstructFromPacked] 110 iterations done. 567245236 characters processed.; [BWTIncConstructFromPacked] 120 iterations done. 590928020 characters processed.; [bwa_index] 279.06 seconds elapse.; [bwa_index] Update BWT... 1.72 sec; [bwa_index] Pack forward-only FASTA... 1.90 sec; [bwa_index] Construct SA from BWT and Occ... 59.56 sec; [2018-06-25 19:34:53.084] [jLog] [info] done building index; ```. Doh, something unexpected from the logs, isn't it?. ```; $ ls -latr ftp.ensembl.org/pub/release-92/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all; total 8374704; drwx------. 3 mmokrejs mmokrejs 4096 Jun 25 19:25 ..; -rw-r--r--. 1 mmokrejs mmokrejs 36158409 Jun 25 19:26 rsd.bin; -rw-r--r--. 1 mmokrejs mmokrejs 423777 Jun 25 19:26 duplicate_clusters.tsv; -rw-r--r--. 1 mmokrejs mmokrejs 294997212 Jun 25 19:26 txpInfo.bin; -rw-r--r--. 1 mmokrejs mmokrejs 1157068836 Jun 25 19:26 sa.bin; -rw-r--r--. 1 mmokrejs mmokrejs 1779709484 Jun 25 19:29 hash.bin; -rw-r--r--. 1 mmokrejs mmokrejs 75 Jun 25 19:29 refInfo.json; -rw-r--r--. 1 mmokrejs mmokrejs 9816 Jun 25 19:29 quasi_index.log; -rw-r--r--. 1 mmokrejs mmokrejs 666 Jun 25 19:29 header.json; -rw-r--r--. 1 mmokrejs mmokrejs 304768324 Jun 25 19:33 bwaidx.bwt; -rw-r--r--. 1 mmokrejs mmokrejs 76192062 Jun 25 19:33 bwaidx.pac; -rw-r--r--. 1 mmokrejs mmokrejs 50007825 Jun 25 19:33 bwaidx.ann; -rw-r--r--. 1 mmokrejs mmokrejs 89 Jun 25 19:33 bwaidx.amb; drwxr-xr-x. 2 mmokrejs mmokrejs 4096 Jun 25 19:34 .; -rw-r--r--. 1 mmokrejs mmokrejs 95 Jun 25 19:3",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/242:15374,release,release-,15374,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/242,1,['release'],['release-']
Deployability,"We do no have access to BSD-based systems (apart from the extent to which OSX can be said to be BSD-based) on which to test during development. Bioconda works on many linux distributions; though I do not have a comprehensive list. For example, we regularly run on Ubuntu, CentOS, RedHat and Debian. If you have the facilities to use Docker on this machine, you can also pull down a docker image of the latest release from https://hub.docker.com/r/combinelab/salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522628674:409,release,release,409,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522628674,1,['release'],['release']
Deployability,"We have a partly assembled genome with some almost identical gene modes which can be either allele or paralogs. Usually there are only a few nuclear tide differences between them. We expected Salmon return similar expression levels for these similar genes. However, it came out one gene had normal counts(in my case it was roughly 12,000 mapping reads) and another gene got zero in mapping read counts. I guess Salmon re-assigned read counts between highly similarly genes based on estimated mapping quality. In addition, the same gene model would get significantly different counts across runs due to the re-assignment, which made thing worse. I also tested RSEM and found the similar problem. I noticed the RSEM set the column #5 (mapping quality) in BAM from upstream mapping pipeline which might be reason for this issue. The third software I tried is eXpress which assigns mapping counts evenly between similar genes. . My suggestion is to allow users to switch off the re-assignment between similar genes.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/107:779,pipeline,pipeline,779,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/107,1,['pipeline'],['pipeline']
Deployability,"We have updated the docs. Thanks for the heads up . We are closing this issue for now,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/367#issuecomment-498038312:8,update,updated,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/367#issuecomment-498038312,1,['update'],['updated']
Deployability,We just discovered that Salmon build removes/collapses identical transcripts. This is very problematic that Salmon does this as many genes are duplicated throughout the genome. By concatenating them in the build index one of these is arbitrary selected (the others removed) meaning all downstream analysis will assume all expression originate from one genomic region instead of many. In the most r[ecent Gencode mouse release](https://www.gencodegenes.org/mouse_releases/current.html) this problem affects 1563 sequences annotated as 13812 and covers all transcript types (incl 840 protein coding - although the major once are lincRNA (n=3658) and snoRNAs (n=2622)). We strongly believe that if one want to analyse these duplicated regions jointly this should be done just like one would sum all transcripts from a particular gene to get the gene expression.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214:418,release,release,418,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214,1,['release'],['release']
Deployability,"We tried to run salmon with broken linked files (as in, we accidently linked to the wrong directory). This led to salmon getting to the kmer counting stage and then permanently pausing there (see output below). You can see a version of the broken protocol here: https://github.com/ngs-docs/2017-ucsc-metagenomics/blob/cd417dc4b384b668eda2a477fd805ebb3b30cd00/salmon_tutorial.rst. So, it would be nice if salmon could compensate for this misstep on our part and notify us if a broken linked file is given as input, rather than just pausing. . `tx160085@js-104-35:~/Salmon-0.7.2_linux_x86_64/data$ salmon index -t metagG.ffn -i transcript_index -; -type quasi -k 31; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and minor bug fixes; please upgrade at your; earliest convenience.; ###; index [""transcript_index""] did not previously exist . . . creating it; [2017-04-23 17:02:32.614] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers`. Thank you!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/134:805,release,releases,805,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/134,2,"['release', 'upgrade']","['releases', 'upgrade']"
Deployability,"We use Salmon a lot in my lab. It's a great tool. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; I am running salmon quant using dockerImg ""quay.io/biocontainers/salmon:1.4.0--hf69c8f4_0"", i.e. salmon (selective-alignment-based) v1.4.0. **Describe the bug**; When I run salmon I exits with an error code of 137. any idea what this means? I also noticed that the output directory is not created. **To Reproduce**; I am running the container on app.terra.bio, unfortunately, I can not share the workspace because the data is from identifiable human subjects. Bellow, I include the log file showing how I ran salmon. I think the bug may have something to do with the run time environment. Know what salmon exit codes mean would really help me figure out where my bug is. Specifically, please provide at least the following information:. * Which version of salmon was used?; 1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; dockerImg ""quay.io/biocontainers/salmon:1.4.0--hf69c8f4_0"",; * Which reference (e.g. transcriptome) was used?; we have a custom reference based on g35. ; * Which read files were used?; * Which which program options were used?; * . **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here. ```; + mkdir -p salmon.out; + salmon quant -i sel.align.gencode.v35.ucsc.rmsk.salmon.v1.3.0.sidx --libType A -1 /cromwell_root/fc-secure-519db2bc-049f-43a0-ab75-a2eb9c2cb059/6a6c9b92-3026-47d3-8944-60f0842c566e/samToFastqTest/5f578d2f-7e74-4402-955a-4d4623b83ead/call-samToFastq/GTEX-111CU-0526-SM-5EGHK.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/641:934,install,installed,934,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/641,1,['install'],['installed']
Deployability,"We were given some test data - ~400,000 150 PE on two samples from a MiSeq run on a mosquito. They wanted to know recommended sequencing depth and whether they needed 150 PE or if they could get away with 100 SE. There is a decent-ish genome and transcriptome for the species (https://www.ncbi.nlm.nih.gov/genome/?term=aedes+albopictus), so we ran the 150 PE and artificially created 100 SE from R1 through our pipeline, which includes STAR plus Salmon. The STAR results were expected: 100 SE had ~40% mulitmapping / ~48% unique in genes and 150 BP improved to ~30% multimapping / ~57% unique in genes. Surprisingly, Salmon showed the opposite: 100 SE had a ~70% mapping rate while 150 PE has only a ~57% mapping rate. . We thought at first that Salmon maybe wasn't counting fragments if both ends didn't map but the answer in issue #31 says Salmon should be counting single-end mapped towards quantification. The first line in the salmon_quant.log file says ""Fragment incompatibility prior below threshold. Incompatible fragments will be ignored."" I couldn't find much in salmon quant --help-reads about fragment priors and then I found it was in pretty much all salmon_quant.logs we have, so that may not be the problem. We also thought the trouble may have something to do with the small number of fragments, so we ran through some mouse 150 PE + artificial 100 SE, that had 40M reads and also subsampled to 400K reads, but the salmon mapping rates were pretty much the same (~75%) regardless of type/length of reads or sequencing depth. So what do you think could be going on? I am worried that Salmon's ""better"" mapping percentage of 100 SE is not accurately measuring expression. We didn't test 150 SE because that is not a sequencing option with NovaSeq, but we could try it if you think it would help to figure out what is going on. Thanks,; Jenny",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/349:411,pipeline,pipeline,411,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/349,1,['pipeline'],['pipeline']
Deployability,"Well, I was just in the middle of writing a comment saying ""it's been running for 6 hours with no hang, I don't think it's gonna happen"", and then it just hung. Here's the backtrace from gdb:. ```; $ gdb -ex ""attach $(pgrep salmon | head -1)"" -ex bt -ex detach -ex quit; GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.04) 7.11.1; Copyright (C) 2016 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>.; For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word"".; Attaching to process 29153; [New LWP 29155]; [New LWP 29156]; [New LWP 29157]; [New LWP 18084]; [New LWP 18085]; [New LWP 18086]; [New LWP 18087]; [New LWP 18088]; [New LWP 18089]; [New LWP 18090]; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; 0x0000000000578b90 in __log_finite@plt (); #0 0x0000000000578b90 in __log_finite@plt (); #1 0x0000000000637ccc in double std::gamma_distribution<double>::operator()<pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> > >(pcg_detail::engine<unsigned int, unsigned long, pcg_detail::xsh_rr_mixin<unsigned int, unsigned long>, true, pcg_detail::unique_stream<unsigned long>, pcg_detail::default_multiplier<unsigned long> >&, std::gamma_distribution<double>::param_type const&) (); #2 0x0000000000634b8d in tbb::interface",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267534520:684,configurat,configuration,684,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267534520,2,['configurat'],['configuration']
Deployability,What is the usage for `quantmerge`? I just installed from the develop branch..,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-303569258:43,install,installed,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-303569258,1,['install'],['installed']
Deployability,"When I do with proxy I got : . ```; Last login: Thu Jun 30 15:10:26 on ttys001; Benjamin@u932-ulm-2-57030119-6834 ~ % all_proxy= url:port conda install salmon; Collecting package metadata (current_repodata.json): failed. # >>>>>>>>>>>>>>>>>>>>>> ERROR REPORT <<<<<<<<<<<<<<<<<<<<<<. Traceback (most recent call last):; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/exceptions.py"", line 1082, in __call__; return func(*args, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/main.py"", line 87, in _main; exit_code = do_call(args, p); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/conda_argparse.py"", line 84, in do_call; return getattr(module, func_name)(args, parser); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/main_install.py"", line 20, in execute; install(args, parser, 'install'); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/install.py"", line 260, in install; unlink_link_transaction = solver.solve_for_transaction(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 152, in solve_for_transaction; unlink_precs, link_precs = self.solve_for_diff(update_modifier, deps_modifier,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 195, in solve_for_diff; final_precs = self.solve_final_state(update_modifier, deps_modifier, prune, ignore_pinned,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 300, in solve_final_state; ssc = self._collect_all_metadata(ssc); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/common/io.py"", line 88, in decorated; return f(*args, **kwds); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 463, in _collect_all_metadata; index, r = self._prepare(prepared_specs); File ""/usr/local/Ca",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:144,install,install,144,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,4,['install'],['install']
Deployability,"When you compile the program, the last few lines tell you to make links to; the salmon executable and the LIB file. I forgot the lib file and was; getting this error. You can run the executable from the area of install; (works fine) or create a path to /urs/local/bin or any other folder you; want to install. You need to do this for both the files. For making path in linux:; https://stackoverflow.com/questions/14637979/how-to-permanently-set-path-on-linux. Hope this helps. On Mon, May 22, 2017 at 7:03 AM, Darlingfuer <notifications@github.com>; wrote:. > @sudeep71 <https://github.com/sudeep71> Hi there, I run into the same; > error when I use salmon. Would please tell me what you did to set a correct; > PATH ? Thanks!; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/135#issuecomment-303068916>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGcbqM0Z1aeqPtMmppyF51gj9DvEJh5Vks5r8WtpgaJpZM4NT7ex>; > .; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/135#issuecomment-303152754:211,install,install,211,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/135#issuecomment-303152754,2,['install'],['install']
Deployability,"Whenever I run any command with latest official docker image of salmon, as an example:; ```; docker run combinelab/salmon:latest salmon swim; ```; I get; ```; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/277:191,upgrade,upgrade,191,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/277,2,['upgrade'],"['upgrade', 'upgrades']"
Deployability,"Where does `extract-libdivsufsort.cmake` live? I don't find it in the `salmon` repository. Is it generated automatically by `cmake`? The following patch/hack using `unzip` works around the `cmake -E tar xfz` bug for me. It seems to only affect extracting the `libdivsufsort.zip`, perhaps because it's a `.zip`. If that is the case, and there's a `.tar.gz` distribution of `libdivsufsort`, then there may be a simple fix. ``` diff; --- libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake.orig 2016-03-07 22:02:35.000000000 -0800; +++ libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake 2016-03-07 22:06:49.000000000 -0800; @@ -23,7 +23,7 @@; # Extract it:; #; message(STATUS ""extracting... [tar xfz]""); -execute_process(COMMAND ${CMAKE_COMMAND} -E tar xfz ${filename}; +execute_process(COMMAND unzip ${filename}; WORKING_DIRECTORY ${ut_dir}; RESULT_VARIABLE rv). ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193623757:147,patch,patch,147,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193623757,1,['patch'],['patch']
Deployability,While Bioconda is working on resolving the issue for osx deployment of salmon (>v10.2). the following binary can be used for osx based testing of Salmon/Alevin. Note: The code has been compiled on Osx High Sierra (v 10.13.2) and can potentially create problem with other versions of osx.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/260:57,deploy,deployment,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/260,1,['deploy'],['deployment']
Deployability,"While I definitely trust the jemalloc devs, I do know that such things are possible, as a release is simply associated with a tagged commit, which _can_ be changed via a forced update to the tags. I know because, in my early days using git + GitHub, I did such a foolish thing. So, while I'm sure that the jemalloc devs wouldn't change the file associated with a tag, and while there are safeguards (e.g. check that the file we get matches the SHA of what we expect), simply pulling from a fork is a convenient way to handle this ""generally"" (for packages not as production-quality as jemalloc, or where the developers might not have tagged a release corresponding to what we need). I completely understand that you don't want to link against a standard jemalloc if we compile some strange version with custom modifications. However, here, we simply want to use the vanilla jemalloc. In fact, when salmon is built under bioconda, this is exactly what we do (we link against the conda jemalloc >= 5.1.0).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420339510:90,release,release,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420339510,3,"['release', 'update']","['release', 'update']"
Deployability,"Why am I seeing much higher values for this gene with FeatureCounts?. I have now run FeatureCounts several times with different overlaps (minOverlap =25, minOverlap =50, minOverlap =75min Overlap =100) and indeed the counts have decreased (again the psbI example: 8685 , 6011, 4237, 1805 accordingly). Again, this is a good argument for the hypothesis put forward. >Why does running Salmon outside nf-core lead to much higher values?. Hopefully, after I run Decoy mode, this problem is solved. I also tried mapping mode with the --softclipOverhangs option. That increased the counts (psbI : 4696 counts); playing around with the --minScoreFraction flag in addition to the --softclipOverhangs flag also increased the numbers ( minScoreFraction= 0 ->psbI = 8496; minScoreFraction= 0.5 ->psbI = 5633; minScoreFraction= 0.7 ->psbI =3627 ). . So, in summary, your explanation seems to be completely correct. ; In the case that decoy mode resolves the difference between the pipeline and the run outside the pipeline, I would not give this to the nf-core people. But I will if there are still large discrepancies after the run. I'm still not sure what the best parameters are for my analysis, but the --softclipOverhangs flag seems to be the best option for me now.; So thanks again!. @drpatelh. Thank you very much for your quick reply as well. ; I was a bit inaccurate when I said I used the FeatureCounts from the pipeline. I actually wasn't able to use the resulting .txt files. Instead, I used the resulting bam file from the pipeline to perform a FeatureCounts analysis on R. I hope this information answers the question of how I can compare the two results?; My genome and gtf file are from [EnsemblPlants](https://plants.ensembl.org/Arabidopsis_thaliana/Info/Index), so they should be fine. In the MultiQC file, the vast majority of reads align to protein coding regions according to FeatureCounts, so I hope my primary files are fine. . Thanks again for your help and time!. All the best ; Florian",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1238043213:2365,pipeline,pipeline,2365,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1238043213,2,['pipeline'],['pipeline']
Deployability,"Why is salmon using a fork of jemalloc instead of the official release from the jemalloc project?. From CMakeLists.txt:; ```; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/jemalloc/arch; ive/5.1.0.tar.gz -o jemalloc-5.1.0.tar.gz; ```; This seems to potentially conflict with; ` find_package(Jemalloc)`; which might locate an installation from a different build.; I want to ensure a consistent installation across all of our systems, whether or not jemalloc has been installed separately.; Thanks,; Jason",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288:63,release,release,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288,4,"['install', 'release']","['installation', 'installed', 'release']"
Deployability,With the release of `v1.0` we don't need the gtf/gff any more. Closing this issue.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/384#issuecomment-549141221:9,release,release,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/384#issuecomment-549141221,1,['release'],['release']
Deployability,"Wow. Thanks for getting back so fast. I’ll update more info about the machine. It’s got 16GB of RAM and only 3GB of swap, so I do think it was memory pressure. In fact, I just looked through the system kernel messages and found the OOM routine killed my process:. ```Out of memory: Kill process 12997 (R) score 846 or sacrifice child │10-03 22:39 INFO Encountered FastxParser destructor while parser was still marked active (or while parsing threads were ; Killed process 12997, UID 1506502601, (R) total-vm:17105100kB, anon-rss:15306012kB, file-rss:12kB ; ```. Sorry I didn’t check this earlier!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538606398:43,update,update,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538606398,1,['update'],['update']
Deployability,"Yea I looked into `10.12.6`, it looks like Sierra. I just upgraded to mojave. I can ask somebody in the lab tomorrow if they have Sierra to compile and make a binary .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/318#issuecomment-442682687:58,upgrade,upgraded,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/318#issuecomment-442682687,1,['upgrade'],['upgraded']
Deployability,Yeah! Salmon compiled! Using Ubuntu Trusty with GCC 4.8.4 and Salmon 0.6.0. No luck with GCC 5.3. My guess as to this issue (undefined reference) is that it's possibly mixing boost headers from one installation of boost that it found in /usr and boost libraries from another installation installed by Linuxbrew.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-193963209:198,install,installation,198,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-193963209,3,['install'],"['installation', 'installed']"
Deployability,"Yes ! it's other error that I can't find . but I try : . ```; Last login: Thu Jun 30 15:14:51 on ttys002; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --add channels defaults; conda config --add channels bioconda; conda config --add channels conda-forge; Warning: 'conda-forge' already in 'channels' list, moving to the top; Benjamin@u932-ulm-2-57030119-6834 ~ % conda install salmon; Collecting package metadata (current_repodata.json): failed. CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/osx-arm64/current_repodata.json>; Elapsed: -. An HTTP error occurred when trying to retrieve this URL.; HTTP errors are often intermittent, and a simple retry will get you on your way.; 'https://conda.anaconda.org/conda-forge/osx-arm64'; ```. ```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --show channels ; channels:; - conda-forge; - bioconda; - defaults; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171223414:375,install,install,375,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171223414,1,['install'],['install']
Deployability,"Yes, I'm aware of refgenie however, I was unable to identify for the hg38 salmon indices which specific transcriptome source (and additionally which version of said source) was used to build them.; Additionally, my use case here isn't entirely personal, I work for GSEA-MSigDB and GenePattern, we're in the process of improving the end-to-end analysis pipeline we offer to users, and one of the things we've been working on were wrapping the Salmon indexer, Salmon quant, and Alevin into GenePattern modules so that we can offer them to users who may want to run them on arbitrary transcriptomes in addition to the ones we offer specifically for GSEA compatibility. This issue was something we encountered when considering potential sources of inconsistency at different points in the pipeline.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738180982:352,pipeline,pipeline,352,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738180982,2,['pipeline'],['pipeline']
Deployability,"Yes, it is in the previous post.. https://www.gencodegenes.org/releases/current.html -> PRI.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410709037:63,release,releases,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410709037,1,['release'],['releases']
Deployability,"Yes, shared volumes :( - thanks @rob-p for the update - I'll give it a shot on our large index and hopefully feel the benefit!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204206663:47,update,update,47,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204206663,1,['update'],['update']
Deployability,"Yes, will update it too. Thank you :)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/804#issuecomment-1271753132:10,update,update,10,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/804#issuecomment-1271753132,1,['update'],['update']
Deployability,"You can pull from this commit sha on develop to test the equivalent changes on that branch `bd7096e0fa055e0a71ab03a52d99977bcb61c905`. If this works, I think I'm pretty much good to go for the release. Just doing some last minute clean up and finishing up the release notes.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632891:193,release,release,193,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632891,2,['release'],['release']
Deployability,You can try `sudo apt-get install zlib1g-dev`.; If you don't have root privilege then you might have to provide the path to the library file of the zlib.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314423408:26,install,install,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314423408,1,['install'],['install']
Deployability,"You can try installing from bioconda, or compiling from source. In the cases above, I presume this has to be resolved via the module system on the cluster / server where this is being run. In the pre-compiled binaries, salmon attempts to link against a specific, old version of libm to maximize compatibility among the operating systems on which it will run. However, given it's availability on bioconda, Dockerhub, and compiled via source, the pre-compiled executable for linux is probably the least preferred way to obtain and run salmon on linux.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/710#issuecomment-1165611828:12,install,installing,12,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/710#issuecomment-1165611828,1,['install'],['installing']
Deployability,Yup --- I see the source of the bug. I will push a fix and cut a patch release.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/123#issuecomment-283458128:65,patch,patch,65,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/123#issuecomment-283458128,2,"['patch', 'release']","['patch', 'release']"
Deployability,"[ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1922,Install,Installing,1922,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Install'],['Installing']
Deployability,"[2018-07-19 18:26:18.301] [alevinLog] [info] Total Unique barcodes found: 978816; [2018-07-19 18:26:18.301] [alevinLog] [info] Used Barcodes except Whitelist: 26208; [2018-07-19 18:26:18.504] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-07-19 18:26:18.505] [alevinLog] [info] parsing read library format; [2018-07-19 18:26:18.632] [stderrLog] [info] Loading Suffix Array ; [2018-07-19 18:26:18.641] [stderrLog] [info] Loading Transcript Info ; [2018-07-19 18:26:18.647] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-19 18:26:18.648] [stderrLog] [info] There were 179 set bits in the bit array; [2018-07-19 18:26:18.648] [stderrLog] [info] Computing transcript lengths; [2018-07-19 18:26:18.648] [stderrLog] [info] Waiting to finish loading hash; [2018-07-19 18:26:18.720] [stderrLog] [info] Done loading index; [2018-07-19 18:26:18.506] [jointLog] [info] There is 1 library.; [2018-07-19 18:26:18.629] [jointLog] [info] Loading Quasi index; [2018-07-19 18:26:18.631] [jointLog] [info] Loading 32-bit quasi index; [2018-07-19 18:26:18.720] [jointLog] [info] done; [2018-07-19 18:26:18.720] [jointLog] [info] Index contained 179 targets; [2018-07-19 18:26:18.728] [alevinLog] [error] Barcode not found in frequency table. **Desktop (please complete the following information):**; - OS: Linux; - Version:; `$ uname -a; Linux login1 3.0.101-0.47.86.1.11753.0.PTF-default #1 SMP Wed Oct 19 14:11:00 UTC 2016 (56c73f1) x86_64 x86_64 x86_64 GNU/Linux`; `$ lsb_release -a; LSB Version:	core-2.0-noarch:core-3.2-noarch:core-4.0-noarch:core-2.0-x86_64:core-3.2-x86_64:core-4.0-x86_64:desktop-4.0-amd64:desktop-4.0-noarch:graphics-2.0-amd64:graphics-2.0-noarch:graphics-3.2-amd64:graphics-3.2-noarch:graphics-4.0-amd64:graphics-4.0-noarch; Distributor ID:	SUSE LINUX; Description:	SUSE Linux Enterprise Server 11 (x86_64); Release:	11; Codename:	n/a`. **Additional context**; I included a 10K subset of reads in the tarball, which leads to the same behavior by Alevin.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253:6555,Release,Release,6555,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253,1,['Release'],['Release']
Deployability,"[2021-12-30 00:46:19.915] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000229312.1|ENSMUSG00000056486.18|OTTMUSG00000013428.7|OTTMUST00000171565.1|Chn1-211|Chn1|20|processed_transcript|], had length less than equal to the k-mer length of 29 (perhaps after poly-A clipping). # [omissis]. [2021-12-30 00:46:27.227] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000226172.1|ENSMUSG00000002249.21|OTTMUSG00000024245.6|OTTMUST00000167695.2|Tead3-208|Tead3|11|processed_transcript|], had length less than equal to the k-mer length of 29 (perhaps after poly-A clipping); [2021-12-30 00:46:28.327] [puff::index::jointLog] [warning] Removed 1612 transcripts that were sequence duplicates of indexed transcripts.; [2021-12-30 00:46:28.327] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2021-12-30 00:46:28.327] [puff::index::jointLog] [critical] The decoy file contained the names of 55 decoy sequences, but 0 were matched by sequences in the reference file provided. To prevent unintentional errors downstream, please ensure that the decoy file exactly matches with the fasta file that is being indexed.; [2021-12-30 00:46:28.449] [puff::index::jointLog] [error] The fixFasta phase failed with exit code 1; ```. I believe; - [x] version is correct; - [x] file paths exists; - [x] It is not the k-mer number as now I get the same error with `-k 29`. For the files I've used:; The GTF file I've used for `./generateDecoyTranscriptome.sh ` I've downloaded it from ensembl with:. ```; wget http://ftp.ensembl.org/pub/release-102/gtf/mus_musculus/Mus_musculus.GRCm38.102.gtf.gz; ```; and just renamed it with `mv`. While the genome file I something already present in my lab folder structure. I could download a new original genome fasta file for mm10 if you think it's worth for the troubleshooting. Otherwise I'm not really sure how I could share this file with you. Thanks a lot for your support, ; Nicco",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1002817868:2440,release,release-,2440,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1002817868,1,['release'],['release-']
Deployability,[CI-SKIP] Update .lgtm.yml,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/470:10,Update,Update,10,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/470,1,['Update'],['Update']
Deployability,"[alevinLog] [info] Done importing order of barcodes ""quants_mat_rows.txt"" file.; [2019-01-29 09:55:59.107] [alevinLog] [info] Total 138 barcodes found; [2019-01-29 09:55:59.107] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [info] Starting to make feature Matrix; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making regular featues; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making feature Matrix; [2019-01-29 09:55:59.123] [alevinLog] [info] Finished white listing; [2019-01-29 09:55:59.126] [alevinLog] [info] Finished optimizer; ``` . Concat fastq:; ```; salmon alevin -l ISR -1 big.fastq.1.gz -2 big.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index/ -o salmon.dir/ --tgMap transcript2geneMap.tsv --dumpCsvCounts; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of Salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to salmon.dir/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { big.fastq.1.gz }; ### [ mates2 ] => { big.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:56:37.731] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:56:37.749] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 2 Million barcodes. [2019-01-29 09:56:43.029",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:6049,UPGRADE,UPGRADE,6049,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['UPGRADE'],['UPGRADE']
Deployability,"\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\320v\1\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=2271767, ...}) = 0; mmap(NULL, 2500784, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbfb60000; mprotect(0x7fffbfbac000, 2097152, PROT_NONE) = 0; mmap(0x7fffbfdac000, 16384, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x4c000) = 0x7fffbfdac000; mmap(0x7fffbfdb0000, 75952, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7fffbfdb0000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libgomp.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\2405\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=56344, ...}) = 0; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfb5f000; mmap(NULL, 2151616, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf951000; mprotect(0x7fffbf95e000, 2097152, PROT_NONE) = 0; mmap(0x7fffbfb5e000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0xd000) = 0x7fffbfb5e000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/librt.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0 \""\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=50288, ...}) = 0; mmap(NULL, 2132936, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf748000; mprotect(0x7fffbf74f000, 2097152, PROT_NONE) = 0; mmap(0x7fffbf94f000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x7000) = 0x7fffbf94f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libm.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0`>\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=611736, ...}) = 0; mmap(NULL, 2629816, PROT_READ|PROT_EXEC, ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:18455,pipeline,pipeline,18455,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"]\200\316;\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=145896, ...}) = 0; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbffe3000; mmap(0x3bce800000, 2212848, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x3bce800000; mprotect(0x3bce817000, 2097152, PROT_NONE) = 0; mmap(0x3bcea17000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x17000) = 0x3bcea17000; mmap(0x3bcea19000, 13296, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x3bcea19000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/liblzma.so.0"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0 %\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=130728, ...}) = 0; mmap(NULL, 2226056, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbfdc3000; mprotect(0x7fffbfde2000, 2097152, PROT_NONE) = 0; mmap(0x7fffbffe2000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1f000) = 0x7fffbffe2000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libtbb.so.2"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\320v\1\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=2271767, ...}) = 0; mmap(NULL, 2500784, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbfb60000; mprotect(0x7fffbfbac000, 2097152, PROT_NONE) = 0; mmap(0x7fffbfdac000, 16384, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x4c000) = 0x7fffbfdac000; mmap(0x7fffbfdb0000, 75952, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7fffbfdb0000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libgomp.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\2405\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:54033,pipeline,pipeline,54033,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['pipeline'],['pipeline']
Deployability,"__________; From: tamuanand <notifications@github.com>; Sent: Saturday, 14 December 2019 10:53 AM; To: COMBINE-lab/salmon <salmon@noreply.github.com>; Cc: Susan Corley <s.corley@unsw.edu.au>; Mention <mention@noreply.github.com>; Subject: Re: [COMBINE-lab/salmon] Salmon SAF method - Read mapping issue with Lexogen/QuantSeq data?? (#449). Hi @s1corley<https://github.com/s1corley>. As @rob-p<https://github.com/rob-p> mentions, your paper could help assess different methodologies for quantification and also help optimize salmon further for QuantSeq. I would still like you to check if you have used salmon quant command line correctly for QuantSeq data analysis. Your paper briefly alludes to QuantSeq Forward in the Introduction section of the paper. The QuantSeq Forward kit has an oligo (dT) primer which contains the Illumina-specific Read 2 linker ... but the Methods section of your paper does not specify if you have used QuantSeq FWD or REV. Page 14 of the PDF from the Lexogen Website data analysis pipeline for QuantSeq FWD<https://www.bluebee.com/wp-content/uploads/2018/11/015UG108V0201-QuantSeq-Data-Analysis-Pipeline_2018-10-18.pdf> recommends using the below htseq command line. htseq-count -m intersection-nonempty -s yes -f bam -r pos $bam; $resource_dir/annotation.gtf > $bam_dir/read_counts.txt. QuantSeq is a stranded protocol. For the QuantSeq FWD pipeline the argument -s yes indicates; stranded in the sense orientation. For the QuantSeq REV pipeline -s reverse is used. Similar to the above htseq command line arguments, I think if you are using QuantSeq FWD, the libType argument from salmon quant should have been SF. One way I checked these with my datasets was to run the salmon quant command 3 times - once with libType A, once with libType SF and once with libType SR -- with QuantSeq FWD the estimated counts will be almost same with libType A and libType SF. I echo what @rob-p<https://github.com/rob-p> says - Congratulations once again on the paper. —; You are rec",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565684552:1620,pipeline,pipeline,1620,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565684552,1,['pipeline'],['pipeline']
Deployability,"_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 14:51:10 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110315; Job name: step6-salmon_test3.gsk_phaseII; Hostname: compute-061; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:51:11.533] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 14:51:11.545] [jointLog] [info] There is 1 library.; [00mterminate called without an active exception; /cm/local/apps/sge/var/spool/compute-061/job_scripts/110315: line 31: 54922 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:2166,pipeline,pipeline,2166,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['pipeline'],['pipeline']
Deployability,"_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 23:27:11 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110632; Job name: step6-salmon_test5.gsk_phaseII; Hostname: compute-066; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/logs; [1m[2017-03-29 23:59:18.699] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 23:59:18.721] [jointLog] [info] There is 1 library.; [00m[1m[2017-03-30 00:43:17.278] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-03-30 00:43:17.237] [jointLog] [info] Loading Quasi index; [00m[1m[2017-03-30 00:43:17.273] [jointLog] [info] Loading 32-bit quasi index; [00m[1m[2017-03-30",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:9081,pipeline,pipeline,9081,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['pipeline'],['pipeline']
Deployability,"_data}/ref/transcriptome/transcriptome_splici_fl86.fa""; output:; ""{out_data}/ref/idx/complete_ref_lens.bin"",; ""{out_data}/ref/idx/ctable.bin"",; ""{out_data}/ref/idx/ctg_offsets.bin"",; ""{out_data}/ref/idx/duplicate_clusters.tsv"",; ""{out_data}/ref/idx/info.json"",; ""{out_data}/ref/idx/mphf.bin"",; ""{out_data}/ref/idx/pos.bin"",; ""{out_data}/ref/idx/pre_indexing.log"",; ""{out_data}/ref/idx/rank.bin"",; ""{out_data}/ref/idx/refAccumLengths.bin"",; ""{out_data}/ref/idx/ref_indexing.log"",; ""{out_data}/ref/idx/reflengths.bin"",; ""{out_data}/ref/idx/refseq.bin"",; ""{out_data}/ref/idx/seq.bin"",; ""{out_data}/ref/idx/versionInfo.json""; params:; job_name = ""build_idx"",; memory = ""select[mem>64] rusage[mem=64]"",; out_dir = ""{out_data}/ref/idx""; log:; ""logs/build_idx.out""; threads:; 16; shell:; """"""; salmon index \; -t {input.fasta} \; -i {params.out_dir} \; -p {threads}; """"""; ```. Running this rule does generate all the expected output files, including `versionInfo.json`. My pipeline crashes during the next step, where I am attempting to map reads. Again, I followed the code as outlined by the alevin-fry tutorial (tweaked slightly) and my snakemake rule is as follows (apologies that I am still using the deprecated --end, --barcodeLength and --umiLength options; my intention was to update those once I had my pipeline working, but I've gotten stuck on the index build):. ```; rule map_reads: ; # map reads and generate a RAD (Reduced Alignment Data) file; input:; R1 = ""{out_data}/preprocessed_fastqs/{sample}_R1.fastq.gz"",; R2 = ""{out_data}/preprocessed_fastqs/{sample}_R2.fastq.gz"",; idx = rules.build_idx.output,; tgmap = ""{out_data}/ref/transcriptome/transcriptome_splici_fl86_t2g.tsv""; output:; ""{out_data}/{sample}/map/alevin/alevin.log"",; ""{out_data}/{sample}/map/aux_info/meta_info.json"",; ""{out_data}/{sample}/map/cmd_info.json"",; ""{out_data}/{sample}/map/libParams"",; ""{out_data}/{sample}/map/logs/salmon_quant.log"",; ""{out_data}/{sample}/map/map.rad"",; ""{out_data}/{sample}/map/unmapped_bc_coun",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:2928,pipeline,pipeline,2928,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,1,['pipeline'],['pipeline']
Deployability,"_fmd_index --type fmd; GNU gdb (GDB) Red Hat Enterprise Linux 8.2-6.el8; Copyright (C) 2018 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law.; Type ""show copying"" and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of EL",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:2259,install,install,2259,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['install'],['install']
Deployability,"_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=19, ...}) = 0; open(""/jhpce/shared/community/core/j",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:9834,install,install,9834,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['install'],['install']
Deployability,"`Transcript chr19 appeared in the BAM header, but was not in the provided FASTA file`; (note here that it's an entire chromosome??? And these are the only ""transcripts"" that don't appear in the fasta- they're all just the chromosome names.); This happened regardless of whether I used the Stringtie fasta or the SQNATI-annotated fasta. This is the salmon command I had run:; `$salmon quant --ont -t $transcriptome -l SF -a $bam -o $outdir/$name`. As suggested, I used gffread to generate a new transcriptome fasta as follows:; `gffread -w salmon_fix.fa -g chm13v2.0.fa chm13v2.0_RefSeq_Liftoff_v5.1.gff3`. I reran the above salmon command using this new fasta file, but got the same error and warnings: there are transcripts in the BAM not in the fasta and vice versa. Again, the ""transcripts"" not in the fasta were chromosome names. I also tried with the short read SAM files, and still got the same error. I'm not sure how to fix either the warnings or the errors and would really appreciate your help. ### Software information; I used salmon v1.10.0 (though I also tried v1.10.1). In the case of v1.10.0, I had downloaded the pre-compiled binary, and in the case of v1.10.1, the admins of the HPC cluster I used installed it- not sure how. Regardless, all the runs were on HPC clusters, which run on Linux CentOS (I use two different HPC clusters, depending on their availability). Cluster1:; ```; $ uname -a; Linux rescomp1.hpc.in.bmrc.ox.ac.uk 3.10.0-1160.92.1.el7.x86_64 #1 SMP Tue Jun 20 11:48:01 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux; $ lsb_release -a; -bash: lsb_release: command not found; ```. Cluster2:; ```; $ uname -a; Linux htc-login02 4.18.0-348.7.1.el8_5.x86_64 #1 SMP Wed Dec 22 13:25:12 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux; $ lsb_release -a; LSB Version: :core-4.1-amd64:core-4.1-noarch; Distributor ID: CentOS; Description: CentOS Linux release 8.5.2111; Release: 8.5.2111; Codename: n/a; ```. Please let me know if I need to provide any more information. Thank you so much!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/863:2742,install,installed,2742,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/863,3,"['Release', 'install', 'release']","['Release', 'installed', 'release']"
Deployability,"```. Secondly, I created a new transcriptome-only salmon index (`singularity run -B /data $SALMON_SIMG salmon index -t genome.transcripts.fa -i salmon_index -k 31`), then ran `salmon quant` again (as above) but using the new transcriptome-only index. Note: 'genome.transcripts.fa' is the transcripts file created during the `nf-core/rnaseq` pipeline. Again, this analysis completed properly in a reasonable time. Seems like there is something very wrong with the 'gentrome.fa' file that's being created by `nf-core/rnaseq`! It's just so odd that _some_ samples would work and others wouldn't. 2. It's definitely worth noting that I originally opted against using `star_salmon` with the following command:. ```; nextflow run nf-core/rnaseq --max_memory 55.GB --fasta /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz --gtf /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.106.gtf.gz --skip_alignment --pseudo_aligner salmon --seq_center 'Ramaciotti Centre for Genomics' --input samplesheet.csv --outdir nf-core_results --save_merged_fastq true --skip_markduplicates true --extra_salmon_quant_args '--seqBias --gcBias --posBias' -profile singularity; ```. I'll re-run (a) using the refgenie salmon index specified; (b) with the `star_salmon` pathway to see if the decoy-aware index created that way is appropriate. 3. Other; I've installed `piscem` and can give it a go, although it does seem more like a salmon index issue with `nf-core/rnaseq` from the debugging above. Do you agree? If so, I'll raise an issue there. Considering this, would it still be useful to have access to the reads? I've got the green light to share them if need be. If so, what's a good contact address to share a OneDrive link?. Thanks!; Charles. p.s. something else odd that I can dig into further later if need be is that the singularity version of salmon created an index in about 5 minutes, yet the conda version has been creating the index for nearly 20 minutes so far with no change...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948:2446,install,installed,2446,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948,1,['install'],['installed']
Deployability,"```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda install salmon; Collecting package metadata (current_repodata.json): failed. CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/osx-arm64/current_repodata.json>; Elapsed: -. An HTTP error occurred when trying to retrieve this URL.; HTTP errors are often intermittent, and a simple retry will get you on your way.; 'https://conda.anaconda.org/conda-forge/osx-arm64'; ```. ```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --show channels; channels:; - conda-forge; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171204474:49,install,install,49,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171204474,1,['install'],['install']
Deployability,`cmake && make install` _should_ work --- the fetching should happen during the configuration (i.e. `cmake`) phase.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367760156:15,install,install,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367760156,2,"['configurat', 'install']","['configuration', 'install']"
Deployability,`cmake` fails when extracting external dependencies for me. See #10. I'd also like to be able to use the existing installed versions of dependencies. For me they're installed by Linuxbrew.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193514127:114,install,installed,114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193514127,2,['install'],['installed']
Deployability,"`cmake` is being run with the default Homebrew flags, which are…; ```sh; cmake . -DCMAKE_C_FLAGS_RELEASE=-DNDEBUG -DCMAKE_CXX_FLAGS_RELEASE=-DNDEBUG -DCMAKE_INSTALL_PREFIX=/home/linuxbrew/.linuxbrew/Cellar/salmon/0.9.1 -DCMAKE_BUILD_TYPE=Release -DCMAKE_FIND_FRAMEWORK=LAST -DCMAKE_VERBOSE_MAKEFILE=ON -Wno-dev; ```; Are any of those options related?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367735487:238,Release,Release,238,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367735487,1,['Release'],['Release']
Deployability,"`extract-libdivsufsort.cmake` is auto-generated during configuration. However, the zip itself is grabbed as part of RapMap (specifically, it resides [here](https://github.com/COMBINE-lab/RapMap/tree/master/external)). I can take a look at what would be required to make it a tarball there (or, conversely, if there is a way to force CMake to use `unzip` rather than `cmake -E tar xfz`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193784017:55,configurat,configuration,55,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193784017,1,['configurat'],['configuration']
Deployability,"`salmon` is found from `bioconda` but ... ```; $ conda search salmon; Loading channels: done; # Name Version Build Channel; salmon 0.5.1 0 bioconda; salmon 0.6.0 0 bioconda; salmon 0.6.0 1 bioconda; salmon 0.6.0 boost1.60_1 bioconda; salmon 0.6.0 boost1.60_2 bioconda; salmon 0.7.2 boost1.60_2 bioconda; salmon 0.7.2 boost1.60_3 bioconda; salmon 0.7.2 boost1.61_3 bioconda; salmon 0.8.0 boost1.60_0 bioconda; salmon 0.8.0 boost1.61_0 bioconda; salmon 0.8.1 0 bioconda; salmon 0.8.2 0 bioconda; salmon 0.8.2 1 bioconda; salmon 0.9.0 0 bioconda; salmon 0.9.1 0 bioconda; salmon 0.9.1 1 bioconda; salmon 0.10.0 1 bioconda; salmon 0.10.1 1 bioconda; salmon 0.10.2 1 bioconda; salmon 0.11.0 h445c947_0 bioconda; salmon 0.11.1 h445c947_0 bioconda; salmon 0.11.2 h445c947_0 bioconda; salmon 0.11.3 h86b0361_1 bioconda; salmon 0.11.3 h86b0361_2 bioconda; ```. When I try to install, I get `PackageNotFoundError`.; ```; $ conda create -n salmon salmon=0.11.3; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - salmon=0.11.3; - jemalloc[version='>=5.1.0']; - salmon=0.11.3; - libcxx. Current channels:. - https://conda.anaconda.org/bioconda/linux-64; - https://conda.anaconda.org/bioconda/noarch; - https://repo.anaconda.com/pkgs/main/linux-64; - https://repo.anaconda.com/pkgs/main/noarch; - https://repo.anaconda.com/pkgs/free/linux-64; - https://repo.anaconda.com/pkgs/free/noarch; - https://repo.anaconda.com/pkgs/r/linux-64; - https://repo.anaconda.com/pkgs/r/noarch; - https://repo.anaconda.com/pkgs/pro/linux-64; - https://repo.anaconda.com/pkgs/pro/noarch. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org. and use the search bar at the top of the page.; ```. It is weird because I am installing on `linux64`.; ```; $ lsb_release -a; LSB Version:	:base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/308:866,install,install,866,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/308,1,['install'],['install']
Deployability,"a and with the same ""salmon quant"" command (See below) that works on the old version, I get a ""segmentation fault 11"" error and it never actually quantifies any reads. Do you know why this would happen?. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; 0.11.3; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Bioconda; * Which reference (e.g. transcriptome) was used?; gencode.v27.transcripts.fa; * Which read files were used?; fastq; * Which which program options were used?; -l A, single end . **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. ```; salmon quant -i ~/Reference_indexes/humangencodev27_transcripts_index_20181023 -l A -r ~/Downloads/ENCFF600FYP.fastq.gz -o ./salmon_test/ENCFF600FYP_quant; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.11.3; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { ~/Reference_indexes/humangencodev27_transcripts_index_20181023 }; ### [ libType ] => { A }; ### [ unmatedReads ] => { ~/Downloads/ENCFF600FYP.fastq.gz }; ### [ output ] => { ./salmon_test/ENCFF600FYP_quant }; Logs will be written to ./salmon_test/ENCFF600FYP_quant/logs; [2018-10-23 20:11:13.424] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-10-23 20:11:13.425] [jointLog] [info] parsing read library format; [2018-10-23 20:11:13.425] [jointLog] [info] There is 1 library.; [2018-10-23 20:11:13.513] [stderrLog] [info] Loading Suffix Array ; [2018-10-23 20:11:13.513] [jointLog] [info] Loading Quasi index; [2018-10-23 20:11:13.513] [jointLog] [info] Loading 32-bit quasi index; [2018-10-23 20:11:14.645] [stderrLog] [info] Loading Transcript Info ; [2018-10-23 20:11:14.975] [s",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/303:1311,upgrade,upgrades,1311,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/303,1,['upgrade'],['upgrades']
Deployability,"above snakemake rule code for program options, which closely follow the options used in the alevin-fry tutorial. **Expected behavior**; A clear and concise description of what you expected to happen. I expected my reads to be mapped and a RAD file to be generated. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Linux (university cluster); - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; ; Output of `uname -a`:; ```; Linux amc-bodhi 3.10.0-514.21.1.el7.x86_64 #1 SMP Thu May 25 17:04:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux; ```. Output of `lsb_release -a`:; ```; LSB Version:	:core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch; Distributor ID:	CentOS; Description:	CentOS Linux release 7.4.1708 (Core) ; Release:	7.4.1708; Codename:	Core; ```. **Additional context**; Add any other context about the problem here. I have attached subsampled fastq files for one of my samples as an example:; [sub_R1.fastq.gz](https://github.com/COMBINE-lab/salmon/files/7331798/sub_R1.fastq.gz); [sub_R2.fastq.gz](https://github.com/COMBINE-lab/salmon/files/7331799/sub_R2.fastq.gz). This is the error log after attempting to run the map reads step, which indicates an issue with the index build:; [B13_MeOH_cells_Jurkat_Cas9_EGR1_1_stimulated.out.err.txt](https://github.com/COMBINE-lab/salmon/files/7331816/B13_MeOH_cells_Jurkat_Cas9_EGR1_1_stimulated.out.err.txt). This is the error log after building the index, which seems to have run successfully (though maybe I am missing something):; [build_idx.out.err.txt](https://github.com/COMBINE-lab/salmon/files/7331817/build_idx.out.err.txt). This is the versionInfo.json file that is successfully generated after buildi",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:6186,release,release,6186,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,1,['release'],['release']
Deployability,"agittal_Anterior_Section_1_S7_L001_R2_001.fastq.gz], [ /users/nklimper/data/nklimper/permexp/output_genome/V1_Mouse_Brain_Sagittal_Anterior_Section_1_fastqs/V1_Mouse_Brain_Sagittal_Anterior_Section_1_S7_L002_R1_001.fastq.gz, /users/nklimper/data/nklimper/permexp/output_genome/V1_Mouse_Brain_Sagittal_Anterior_Section_1_fastqs/V1_Mouse_Brain_Sagittal_Anterior_Section_1_S7_L002_R2_001.fastq.gz] ]"",; ""expected_format"": ""ISR"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 250325422,; ""num_assigned_fragments"": 250325422,; ""num_frags_with_concordant_consistent_mappings"": 0,; ""num_frags_with_inconsistent_or_orphan_mappings"": 630613407,; ""strand_mapping_bias"": 0.0,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 0,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 0,; ""SF"": 0,; ""SR"": 0,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```. I used the gzipped fastq files directly from the 10X website, and have tried with different indexes. I am using Salmon-1.9.0. Any idea what could be going wrong? Thanks!. --------; UPDATE; --------. I am unable to reproduce the results of the Spatial Alevin tutorial using the 10X Visium example. I used the same version of Salmon (1.1.0) as the tutorial, same refgenie mouse index, and generated the txp2gene.tsv file as described. Below is my script:. ```bash; #!/bin/bash; #SBATCH --account=carney-afleisc2-condo; #SBATCH -n 16; #SBATCH --mem=64G; #SBATCH -t 48:00:00; #SBATCH -J alevin; #SBATCH -o tutorial-out; #SBATCH -e tutorial-err. salmon alevin -l ISR -i ./salmon_partial_sa_index \; -1 ./V1_Mouse_Brain_Sagittal_Anterior_Section_1_fastqs/V1_Mouse_Brain_Sagittal_Anterior_Section_1_S7_L001_R1_001.fastq.gz \; ./V1_Mouse_Brain_Sagittal_Anterior_Section_1_fastqs/V1_Mouse_Brain_Sagittal_Anterior_Section_1_S7_L002_R1_001.fastq.gz \; -2 ./V1_Mouse_Brain_Sagittal_Anterior_Section_1_fastqs/V1_Mouse_Brain_Sagittal_Anterior_Section_1_S7_L001_R2_001.fastq.gz \; ./V1_Mouse_Brain_Sagittal_Anterior_Section_1_fastqs/V1_Mouse_Brain_Sagittal_Anterior_Section_1_S7_L002_R2_001.fastq.gz",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/827:3007,UPDATE,UPDATE,3007,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/827,1,['UPDATE'],['UPDATE']
Deployability,"ainly be interested in hearing about this and understanding the likely source of this kind of discrepancy. From what you've explained, here is my current hypothesis of what's going on. * Why are the salmon counts much lower for this gene when using alignment-mode and mapping mode under nf-core?. * Though the behavior you observe is similar, I think the cause is somewhat different. **In alignment mode**, STAR is used for alignment. The alignments are made against the genome and then _projected_ onto the annotated transcriptome. STAR has many internal rules for when an alignment can be successfully projected or not. In this case, STAR limits the number of soft clips it will permit in an alignment that it reports to be valid with respect to the annotated transcriptome. I am guessing that many alignments overhang the end of the annotated transcripts, and so STAR does not project them to the transcriptome and so salmon cannot count them. **In mapping mode**, the nf-core pipeline makes use of salmon's selective-alignment _with decoy sequences_. The main purpose of this is to avoid spurious mapping to transcriptomic sequences that may be similar to other unannotated sequences in the genome that are nonetheless a better match for the read (e.g. an unannotated possibly transcribed pseudogene). The way this works in practice is that both the transcript sequences themselves *and the full genome* are indexed. Any read that aligns _strictly better_ to the genome than the transcriptome is considered to map to a decoy, and is not used for the purposes of quantification. Consistent with the behavior I hypothesized above for STAR, if you have many softclipped bases at the end of the read that nonetheless match what is in the genome downstream of the end of the annotated transcript, you'll likely see these reads assigned as decoys. To check this, you can look at salmon's `meta_info.json` output file to see how many reads were mapped best to decoys. * Why do I see much higher counts f",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883:1118,pipeline,pipeline,1118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883,1,['pipeline'],['pipeline']
Deployability,"ake CMakeFiles/libstadenio.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib && ./configure --enable-shared=no --without-libcurl --prefix=/Users/gabriel/Projects/salmon-0.13.1/external/install LDFLAGS= CFLAGS= CC=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc CXX=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++; checking for a BSD-compatible install... /usr/local/bin/ginstall -c; checking whether build environment is sane... yes; checking for a thread-safe mkdir -p... /usr/local/bin/gmkdir -p; checking for gawk... gawk; checking whether make sets $(MAKE)... yes; checking whether make supports nested variables... yes; checking whether to enable maintainer-specific portions of Makefiles... no; checking for gcc... /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc; checking whether the C compiler works... yes; checking for C compiler default output file name... a.out; checking for suffix of executables...; checking whether we are cross compiling... configure: error: in `/Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib':; configure: error: cannot run C compiled programs.; If you meant to cross compile, use `--host'.; See `config.log' for more details; make[2]: *** [libstadenio-prefix/src/libstadenio-stamp/libstadenio-configure] Error 1; make[1]: *** [CMa",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:2403,install,install,2403,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,1,['install'],['install']
Deployability,"al/install/src/rapmap/rank9b.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/bit_array.c.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_chrono.a /opt/boost/boost_1_57_0/lib/libboost_program_options.a /opt/boost/boost_1_57_0/lib/libboost_serialization.a ../../external/install/lib/libstaden-read.a -lz ../../external/install/lib/libdivsufsort.a ../../external/install/lib/libdivsufsort64.a ../../external/install/lib/libjellyfish-2.0.a ../../external/install/lib/libbwa.a -lm ../../external/install/lib/liblzma.a -lbz2 -ltbb -ltbbmalloc -lgomp -lrt ../../external/install/lib/libjemalloc.a -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib""; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xd26): warning: the use of `tempnam' is dangerous, better use `mkstemp'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `tbb::strict_ppl::internal::concurrent_queue_base_v3<UnpairedRead*>::internal_push(void const*, void (*)(UnpairedRead**, void const*)) [clone .constprop.1465]':; SalmonQuantifyAlignments.cpp:(.text+0x136d): undefined reference to `tbb::internal::throw_exception_v4(tbb::internal::exception_id)'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `tbb::strict_ppl::internal::concurrent_queue_base_v3<ReadPair*>::internal_push(void const*",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:2719,install,install,2719,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,"all/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/commu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:9469,install,install,9469,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,8,"['install', 'pipeline']","['install', 'pipeline']"
Deployability,"all; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1442,Install,Installing,1442,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installing']
Deployability,"almon.; Exception : [Error: FMD indexing is not supported in this version of salmon.]; /usr/common/src/salmon-latest_linux_x86_64/bin/salmon index was invoked improperly.; For usage information, try /usr/common/src/salmon-latest_linux_x86_64/bin/salmon index --help; Exiting.; #this worked OK; /usr/common/src/salmon-latest_linux_x86_64/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type puff. ```; Here is what happens in gdb for the version I built:. ```; gdb --args salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; GNU gdb (GDB) Red Hat Enterprise Linux 8.2-6.el8; Copyright (C) 2018 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law.; Type ""show copying"" and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; Type ""show configuration"" for configuration details.; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>.; Find the GDB manual and other documentation resources online at:; <http://www.gnu.org/software/gdb/documentation/>. For help, type ""help"".; Type ""apropos word"" to search for commands related to ""word""...; Reading symbols from salmon...done.; (gdb) r; Starting program: /home/common/modules/el8/x86_64/software/salmon/1.2.1-CentOS-vanilla/bin/salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-72.el8_1.1.x86_64; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable secti",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:1666,configurat,configuration,1666,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,2,['configurat'],['configuration']
Deployability,"alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 16 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 14:53:43 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110316; Job name: step6-salmon_test4.gsk_phaseII; Hostname: compute-067; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 16 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:56:39.675] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 14:56:39.733] [jointLog] [info] There is 1 library.; [00mterminate called without an active exception; /cm/local/apps/sge/var/spool/compute-067/job_scripts/110316: line 31: 64339 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:5575,pipeline,pipeline,5575,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['pipeline'],['pipeline']
Deployability,"am ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:30.080] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; [2019-07-24 13:33:30.080] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:30.080] [jointLog] [info] parsing read library format; [2019-07-24 13:33:30.080] [jointLog] [info] There is 1 library.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:30.175] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [20",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:14774,release,release,14774,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['release'],['release']
Deployability,"anager.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/bit_array.c.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_chrono.a /opt/boost/boost_1_57_0/lib/libboost_program_options.a /opt/boost/boost_1_57_0/lib/libboost_serialization.a ../../external/install/lib/libstaden-read.a -lz ../../external/install/lib/libdivsufsort.a ../../external/install/lib/libdivsufsort64.a ../../external/install/lib/libjellyfish-2.0.a ../../external/install/lib/libbwa.a -lm ../../external/install/lib/liblzma.a -lbz2 -ltbb -ltbbmalloc -lgomp -lrt ../../external/install/lib/libjemalloc.a -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib""; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xd26): warning: the use of `tempnam' is dangerous, better use `mkstemp'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `tbb::strict_ppl::internal::concurrent_queue_base_v3<UnpairedRead*>::internal_push(void const*, void (*)(UnpairedRead**, void const*)) [clone .constprop.1465]':; SalmonQuantifyAlignments.cpp:(.text+0x136d): undefined reference to `tbb::internal::throw_exception_v4(tbb::internal::exception_id)'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `tbb::strict_ppl::internal::concurrent_queue_",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:2674,install,install,2674,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,"annotate them in the duplicate_clusters.tsv file, so I indexed my reference with the flag --keepDuplicates.; The duplicate_clusters.tsv file is still produced but i don't mind since all the transcripts seem to be in the quant.sf file. If I've understood well from this issue https://github.com/COMBINE-lab/salmon/issues/255, the duplicate transcripts (that belongs to the same cluster obviously) should have the same expression level, am I wrong?; Unfortunately, I see some differences.; Here I'm reporting couples of genes that belong to the same cluster:; ` ENST00000434122.2	613	416.835	163.866448	3639.758`; ` ENST00000439602.6	613	416.835	163.500291	3631.625 `. ` ENST00000409379.7	4502	4305.622	0.143089	32.829 `; ` ENST00000647028.1	4502	4305.622	0.000000	0.000 `. In both cases the differences are minimal, but I wanted to be sure if it is normal to see differences.; I used tximport to calculare the ""per-gene"" expression.; I tried the same pipeline with and without the --keepDuplicates flag, and the tximport output was very different, so I checked the quant.sf file and it was different too, for one transcript without the flag i had 818.439918, the same transcript with the flag was 163.866448, since 818 is more or less 5 times 163 i presume that, by default, the total TPM has been divided by the number of duplicate transcripts (i checked in the duplicate_clusters.tsv file and in total there are 5 transcript in that cluster), am I right? does salmon work like this?; Does it explain the little differences I see in the transcript quantification?; Correct me if I'm wrong, salmon tries to assign the reads as equally as possible to every duplicate transcript, but of course if we have for example 21 reads and 4 transcript, they will have respectively 5,5,5 and 6 reads, which can explain the small differences I see. ; Is it correct?; (anyway, in this way i can explain the first two genes which have respectively a read count of 3639 and 3631, but for the last two genes a differenc",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/310:1345,pipeline,pipeline,1345,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/310,1,['pipeline'],['pipeline']
Deployability,"ar='$${TAR-tar} xf -'; ax_pthread_config=''; bindir='${exec_prefix}/bin'; build='arm-apple-darwin22.6.0'; build_alias=''; build_cpu='arm'; build_os='darwin22.6.0'; build_vendor='apple'; datadir='${datarootdir}'; datarootdir='${prefix}/share'; docdir='${datarootdir}/doc/${PACKAGE_TARNAME}'; dvidir='${docdir}'; exec_prefix='NONE'; host='arm-apple-darwin22.6.0'; host_alias=''; host_cpu='arm'; host_os='darwin22.6.0'; host_vendor='apple'; htmldir='${docdir}'; includedir='${prefix}/include'; infodir='${datarootdir}/info'; install_sh='${SHELL} /Users/jeremybono/Downloads/salmon-1.10.1/external/xz-5.2.2/build-aux/install-sh'; libdir='${exec_prefix}/lib'; libexecdir='${exec_prefix}/libexec'; localedir='${datarootdir}/locale'; localstatedir='${prefix}/var'; mandir='${datarootdir}/man'; mkdir_p='$(MKDIR_P)'; oldincludedir='/usr/include'; pdfdir='${docdir}'; prefix='/Users/jeremybono/Downloads/salmon-1.10.1/external/install'; program_transform_name='s,x,x,'; psdir='${docdir}'; sbindir='${exec_prefix}/sbin'; sharedstatedir='${prefix}/com'; sysconfdir='${prefix}/etc'; target_alias=''; xz=''. ## ----------- ##; ## confdefs.h. ##; ## ----------- ##. /* confdefs.h */; #define PACKAGE_NAME ""XZ Utils""; #define PACKAGE_TARNAME ""xz""; #define PACKAGE_VERSION ""5.2.2""; #define PACKAGE_STRING ""XZ Utils 5.2.2""; #define PACKAGE_BUGREPORT ""lasse.collin@tukaani.org""; #define PACKAGE_URL ""http://tukaani.org/xz/""; #define NDEBUG 1; #define HAVE_ENCODER_LZMA1 1; #define HAVE_ENCODER_LZMA2 1; #define HAVE_ENCODER_DELTA 1; #define HAVE_ENCODER_X86 1; #define HAVE_ENCODER_POWERPC 1; #define HAVE_ENCODER_IA64 1; #define HAVE_ENCODER_ARM 1; #define HAVE_ENCODER_ARMTHUMB 1; #define HAVE_ENCODER_SPARC 1; #define HAVE_DECODER_LZMA1 1; #define HAVE_DECODER_LZMA2 1; #define HAVE_DECODER_DELTA 1; #define HAVE_DECODER_X86 1; #define HAVE_DECODER_POWERPC 1; #define HAVE_DECODER_IA64 1; #define HAVE_DECODER_ARM 1; #define HAVE_DECODER_ARMTHUMB 1; #define HAVE_DECODER_SPARC 1; #define HAVE_MF_HC3 1; #define HAVE_",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/912:15430,install,install,15430,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/912,1,['install'],['install']
Deployability,"astq/R10002_C29P7ACXX.fastq.gz"", {st_mode=S_IFREG|0644, st_size=4862610444, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz"", {st_mode=S_IFREG|0644, st_size=5004102866, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz"", {st_mode=S_IFREG|0644, st_size=5004102866, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz"", {st_mode=S_IFREG|0644, st_size=5004102866, ...}) = 0; stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", {st_mode=S_IFREG|0775, st_size=96, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", O_RDONLY) = 4; read(4, ""{\n \""indexVersion\"": 2,\n \""ha""..., 8191) = 96; read(4, """", 8191) = 0; close(4) = 0; stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", {st_mode=S_IFREG|0775, st_size=96, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", O_RDONLY) = 4; read(4, ""{\n \""indexVersion\"": 2,\n \""ha""..., 8191) = 96; read(4, """", 8191) = 0; close(4) = 0; clock_gettime(CLOCK_REALTIME, {1491424830, 69887706}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/header.json"", O_RDONLY) = 4; read(4, ""{\n \""value0\"": {\n \""Index""..., 8191) = 357; read(4, """", 8191) = 0; close(4) = 0; clock_gettime(CLOCK_REALTIME, {1491424830, 139950818}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/header.json"", O_RDONLY) = 4; read(4, ""{\n \""value0\"": {\n \""Index""..., 8191) = 357; read(4, """", 8191",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:165136,pipeline,pipeline,165136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"at my transcript fasta, I noticed a problem with it, as you suggested. Long story short, half the premature transcripts had the wrong orientation and complementarity. Long story:. Oddly, the mature sequences were fine even though I used an identical approach to subset premature and mature transcripts from the genome reference!. Briefly my approach relied on three R packages rtracklayer, GenomicRanges, and Biostrings. 1. I used rtracklayer to load a gtf formatted exon annotations acquired from Ensembl. The file is loaded as a GenomicRanges object which essentially describes the locus of each exon (the transcribed strand [+ or -], chromosome, start and end positions relative to the reference strand) and its associated gene and transcript. 2. I used the GRanges object to generate pre-RNA coordinates that span all exons of a transcript. 3. I loaded the reference genome fasta acquired from Ensembl using the Biostrings package. GRanges and Biostrings are tightly integrated, allowing me to subset sequences from a Biostrings object using the GRanges object. **I believe the problem lies here.** It appears that when subsetting the mature exonic sequences from Biostrings using GRanges, the strand field in the GRanges object **was not** utilized. I.e., I needed to get the reverse complement of the extracted sequences for transcripts on the minus strand. I had done that and assumed that this behaviour would be consistent. However, for reasons I have not been able to pinpoint (potentially a bug), the strand information **was accounted for** when I used GRanges to subset the premature sequences. I **did not** need to get the reverse complement of the premature sequences on the minus strand as I had to do for the mature sequences. Yet, I did that anyway. I initially did test my protocol to ensure it produced identical transcript sequences to Gencode, but I only did this for mature sequences. All seemed fine for both + and - strand transcripts. After your feedback, I compared the pr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:1514,integrat,integrated,1514,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['integrat'],['integrated']
Deployability,"ata}/{sample}/map/cmd_info.json"",; ""{out_data}/{sample}/map/libParams"",; ""{out_data}/{sample}/map/logs/salmon_quant.log"",; ""{out_data}/{sample}/map/map.rad"",; ""{out_data}/{sample}/map/unmapped_bc_count.bin"",; params:; job_name = ""map_reads"",; memory = ""select[mem>64] rusage[mem=64]"",; library_type = ""ISR"",; end = 5,; barcodeLength = 16,; umiLength = 8,; out_dir = ""{out_data}/{sample}/map""; log:; ""logs/map_reads/{sample}.out""; threads:; 16; shell:; """"""; salmon alevin \; -l {params.library_type} \; -1 {input.R1} \; -2 {input.R2} \; -i {input.idx} \; -p {threads} \; -o {params.out_dir} \; --tgMap {input.tgmap} \; --end {params.end} \; --barcodeLength {params.barcodeLength} \; --umiLength {params.umiLength} \; --keepCBFraction 1 \; --sketch; """"""; ```. Specifically, please provide at least the following information:. * Which version of salmon was used? v1.5.2; * How was salmon installed (compiled, downloaded executable, through bioconda)? Downloaded [this](https://github.com/COMBINE-lab/salmon/releases/tag/v1.5.2) binary; * Which reference (e.g. transcriptome) was used? Human reference (GRCh38) (from the alevin-fry tutorial [here](https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz)); * Which read files were used? See attached subsampled sub_R1.fastq.gz and sub_R2.fastq.gz from one sample as representative reads.; * Which which program options were used? See above snakemake rule code for program options, which closely follow the options used in the alevin-fry tutorial. **Expected behavior**; A clear and concise description of what you expected to happen. I expected my reads to be mapped and a RAD file to be generated. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Linux (university cluster); - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:4767,release,releases,4767,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,1,['release'],['releases']
Deployability,"ated to salmon (bulk mode) or alevin (single-cell mode)?**; This is related to salmon. **Describe the bug**; When building Salmon 1.10.3 from source, I'm seeing the following error.; ```; [ 63%] Building CXX object src/CMakeFiles/salmon_core.dir/GenomicFeature.cpp.o; In file included from /usr/include/pthread.h:33,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/x86_64-pc-linux-gnu/bits/gthr-default.h:35,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/x86_64-pc-linux-gnu/bits/gthr.h:148,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/ext/atomicity.h:35,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/bits/ios_base.h:39,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/ios:44,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/ostream:40,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/system/error_code.hpp:17,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/system/system_error.hpp:11,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/exceptions.hpp:22,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/pthread/thread_data.hpp:10,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread_only.hpp:17,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread.hpp:12,; from /gpfs/projects/hpc_support/salmon/include/GenomicFeature.hpp:25,; from /gpfs/projects/hpc_support/salmon/src/GenomicFeature.cpp:22:; /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/pthread/thread_data.hpp:60:5: error: missing binary operator before token ""(""; 60 | #if PTHREAD_STACK_MIN > 0; | ^~~~~~~~~~~~~~~~~; In file included from /gpfs/projects/hpc_support/salmon/external/install/include/boost/functional/hash.hpp:6,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/detail/thread.hpp:41,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread_only.hpp:",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/953:1035,install,install,1035,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/953,1,['install'],['install']
Deployability,"atible with the appropriate strand type (which may be unstranded if that is the protocol). Salmon is pretty conservative about reporting when there is any ambiguity. By default, if the strand bias is stronger than a few percent. In a stranded protocol, it will report and if it infers more than a few percent of fragments no having a valid alignment. So you can always double-check samples where the strandedness is at all ambiguous. > In addition, if a transcript was aligned in a unstranded manner and ended up aligning to the wrong location due to ambiguity between the positive orientation of one transcript and the negative orientation of another, can salmon correct this by reassigning it to the right transcript based on the joint probability of all the other alignments (if you can't tell I'm at the edge of my BS zone)?. If there is not an alignment to the correct location _in addition to_ the wrong location, then no. If you run salmon in alignment mode, it will assign each fragment probabilistically to the set of transcripts to which it aligns. There is, by definition, a probability of 0 for a fragment being assigned to a location where it doesn't align. That is, the reported alignment positions should contain the true alignment. STAR is pretty good at reporting all equally good alignments, but you could see some corner cases (e.g. if there is an alignment to a pseudogene location that looks _very_ similar to a gene, etc.). However, these are the issues that arise due to the inherent difficulty of spliced alignment. Salmon's built-in [selective alignment](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8) is quite sensitive, but if you're using the STAR alignments for other tasks apart from transcript quantification, it may not be worth it to align the reads twice. Overall, STAR unstranded (using the `--quantMode TranscriptomeSAM`) -> salmon with `-l A` and then checking samples where there are any warnings should be a pretty robust pipeline.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/590#issuecomment-733417813:2822,pipeline,pipeline,2822,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/590#issuecomment-733417813,1,['pipeline'],['pipeline']
Deployability,"ation of the GRCh38.p13 transcripts and the repeatmasker annotation from UCSC, with the GRCh38.p13 primary assembly as decoys.; * Which read files were used?: Paired forward and reverse reads (trimmed by Trimmomatic); * Which which program options were used?:; - [--libType A, --validateMappings, --seqBias, --gcBias, --recoverOrphans, --writeUnmappedNames, -p 8, --rangeFactorizationBins 4]. **Expected behavior**; A clear and concise description of what you expected to happen. Salmon quant to produce quant.sf file. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-based) v1.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { references/salmon/sel.align.gencode.v39.ucsc.rmsk.salmon.v1.9.0.sidx/ }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR14506785_output_forward_paired.fq.gz }; ### [ mates2 ] => { SRR14506785_output_reverse_paired.fq.gz }; ### [ threads ] => { 8 }; ### [ validateMappings ] => { }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; ### [ recoverOrphans ] => { }; ### [ rangeFactorizationBins ] => { 4 }; ### [ output ] => { SRR14506785.salmon.rmsk.out }; ### [ writeUnmappedNames ] => { }; Logs will be written to SRR14506785.salmon.rmsk.out/logs; [2023-09-28 04:51:02.450] [jointLog] [info] setting maxHashResizeThreads to 8; [2023-09-28 04:51:02.450] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-09-28 04:51:02.450] [jointLog] [info] Us",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/876:1544,update,updates,1544,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/876,1,['update'],['updates']
Deployability,"azy symbol binding failed: Symbol not found: _os_unfair_lock_lock. Referenced from: /Users/douglasbarrows/Tools/salmon_0.11.4-pre_OSX/bin/./salmon (which was built for Mac OS X 10.13). Expected in: /usr/lib/libSystem.B.dylib. dyld: Symbol not found: _os_unfair_lock_lock. Referenced from: /Users/douglasbarrows/Tools/salmon_0.11.4-pre_OSX/bin/./salmon (which was built for Mac OS X 10.13). Expected in: /usr/lib/libSystem.B.dylib. Trace/BPT trap: 5. Is that something you have seen before?. From: Rob Patro <notifications@github.com>; Reply-To: COMBINE-lab/salmon <reply@reply.github.com>; Date: Tuesday, October 23, 2018 at 8:25 PM; To: COMBINE-lab/salmon <salmon@noreply.github.com>; Cc: dougbarrows <dbarrows@mail.rockefeller.edu>, Author <author@noreply.github.com>; Subject: Re: [COMBINE-lab/salmon] Segmentation fault 11 with bioconda build (#303). Thanks for reporting this. It seems there is an osx bioconda issue (likely related to their massive backend upgrade). Hopefully we can fix this upstream in the next release. I. The meantime, can you see if this<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_files_2383948_salmon-5F0.11.4-2Dpre-5FOSX.tar.gz&d=DwMFaQ&c=JeTkUgVztGMmhKYjxsy2rfoWYibK1YmxXez1G3oNStg&r=AcsC5BcigO3PFsA0uPOPf6vTyS2zaocuu4GaWSrIemY&m=wLNfpc7aJ_B1oE6XAqYsYKk5m7_TsLrkikeQql9eerg&s=40WTo4E4Odm5ZPLtYzGnDNBOb05l6L5woT7ke2vQ1L4&e=> OSX binary works for you?. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_303-23issuecomment-2D432468434&d=DwMFaQ&c=JeTkUgVztGMmhKYjxsy2rfoWYibK1YmxXez1G3oNStg&r=AcsC5BcigO3PFsA0uPOPf6vTyS2zaocuu4GaWSrIemY&m=wLNfpc7aJ_B1oE6XAqYsYKk5m7_TsLrkikeQql9eerg&s=2d8a8eiQ0LuIlgyxoiTnsiwesaQ16X9sju0l7tT1WAw&e=>, or mute the thread<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AYXm7zC7E77igQqcLnRZ1ABIhoVmQ9n",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/303#issuecomment-432469726:1141,release,release,1141,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/303#issuecomment-432469726,1,['release'],['release']
Deployability,"b"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fff",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:8173,pipeline,pipeline,8173,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"b/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/jhpce/shared/community/core/pcre/8.36/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or dire",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:9771,pipeline,pipeline,9771,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"bType"": ""U"",; ""unmatedReads"": ""./single.fastq"",; ""output"": ""./output"",; ""allowOrphansFMD"": [],; ""threads"": ""8"",; ""incompatPrior"": ""1e-20"",; ""biasSpeedSamp"": ""1"",; ""fldMax"": ""1000"",; ""fldMean"": ""200"",; ""fldSD"": ""80"",; ""forgettingFactor"": ""0.65"",; ""maxOcc"": ""200"",; ""maxReadOcc"": ""100"",; ""numBiasSamples"": ""2000000"",; ""numAuxModelSamples"": ""5000000"",; ""numPreAuxModelSamples"": ""1000000"",; ""numGibbsSamples"": ""0"",; ""numBootstraps"": ""0"",; ""vbPrior"": ""0.001"",; ""auxDir"": ""aux_info""; }; ``` . **Expected behavior**; For `salmon quant` to run to completion. **Desktop (please complete the following information):**; ```; Ubuntu Linux; Linux ip-172-31-24-127.ec2.internal 3.13.0-100-generic #147-Ubuntu SMP Tue Oct 18 16:48:51 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux; Distributor ID:	Ubuntu; Description:	Ubuntu 14.04.5 LTS; Release:	14.04; Codename:	trusty; ```. **Additional context**; - This SLURM cluster is managed by [Galaxy Cloudman](https://galaxyproject.org/cloudman/), and my installation of Salmon is currently constrained to a conda install. . - I've fiddled with many different CPU/Memory requirements for each of these `salmon` jobs I've run and have only had successful runs while using a single thread on a single node (`--ntasks=1 --nodes=1`), but even then there were segfaults observed intermittently. - The current Galaxy Tool wrapper for Salmon runs `salmon index ... && salmon quant ...` for every input fastq by default, but I've also generated and pointed `salmon quant` to a common index and have observed the same segfault behavior. I've also tried out the `--perfectHash` flag in both of these scenarios to no avail. - I have the ability to specify/wrap another version of Salmon to be compatible with Galaxy if the thought is that a more recent release could help. - I'm happy to provide any context past this that could help solve the issue!. - Also, I lack any biological insight so I'll ping my colleague @gmnelson for backup in that space. **Terminal Output**; <details>; <sum",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271:2024,install,installation,2024,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271,2,['install'],"['install', 'installation']"
Deployability,"ber of cell labels is 96^3 (884,736). A cell label is represented by an index between 1–96^3. > Reads are first checked for perfect matches in all three pre-designed CLS sequences at the expected locations, CLS1:; position 1–9, CLS2: position 22–30, and CLS3: position 44–52. Reads with perfect matches are kept. In other words...; - Concatenate subsequences 1-9, 22-30, and 44-52 to form a 27-base cell label; - Extract subsequence 53-60 as the UMI . > **UMI** By design, the UMI is a string of eight randomers immediately downstream of CLS3. If the CLSs have perfect matches or base substitutions, the UMI sequence is at position 53–60. For reads with insertions or deletions within the CLSs, the UMI sequence is eight bases immediately following the end of the identified CLS3. R2 reads are transcript-only, and are expected to match a transcript's forward strand, with matches starting within the first five nucleotides (and not match PhiX174). **To Reproduce**. Using Salmon v1.4.0, installed via Debian / apt:. $ salmon alevin -l ISR -1 INDEXLIBNOVASEQ_M001_R1.fastq.gz -2 INDEXLIBNOVASEQ_M001_R2.fastq.gz --rhapsody -i /mnt/ufds/salmon/gencode_M23/salmon_1.4.0_decoy_M23 -p 10 -o alevin_output --tgMap /mnt/ufds/salmon/gencode_M23/txp2gene_gencode.vM23.tsv; Exception : [unrecognised option '--rhapsody']. Exiting. **Expected behavior**. Logs will be written to alevin_output/logs; [2021-02-10 12:57:59.773] [jointLog] [info] setting maxHashResizeThreads to 10; [2021-02-10 12:57:59.773] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-02-10 12:57:59.773] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2021-02-10 12:57:59.774] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-02-10 12:57:59.774] [jointLog] [info] The use of range",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/628:2151,install,installed,2151,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/628,1,['install'],['installed']
Deployability,bioconda install doesn't work if channels aren't set up correctly,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/480:9,install,install,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/480,1,['install'],['install']
Deployability,"ble difference is because (1) the reads are assumed to arrive in a random order (2) this is only a very small fraction of the total data and (3) if the unoriented reads map to a target in the ""wrong"" direction, they will also align to the proper target in the ""right"" direction and, once the orientation filter is applied for future reads, the weight of evidence should turn the probability of assignment of these unoriented reads toward the proper target. However, I'm guessing there is an edge case you're seeing here where the conditions don't induce this behavior. So, there are 2 immediate solutions to the problem. First, if you know the library type explicitly, you can use that. Second (and some other folks have discussed this here for other reasons), you can do a ""throw-away"" run of salmon on a small prefix of the read file (e.g. `salmon quant ... -lA --skipQuant -r <(gunzip -c reads.fq.gz | head -n 400000)`) to get the output of the automatic library type determination, and then run the full dataset with that library type. Finally, moving forward, I'm happy to consider working on modifying this default behavior. That is, we could (though it would be a little bit of work) modify the default behavior. The idea here is to basically run as we do now for the first 10,000 aligned reads to get the library type and then ""reset"" the whole quantification pipeline. The main challenge here is that salmon is designed to work with streaming FASTQ input, and we don't want to break that. So we can't do something as easy as ""reset the file pointer"". I think the best option is to make a copy of the first X reads in memory, detection the library type with them, and then start quantifying them and continue with the rest of the file. That complicates the logic a bit, because now the input source for reads changes dynamically during quantification --- but I think it could be done. Please let me know if you both have interest in this feature and it's worth putting on the list. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738830213:2669,pipeline,pipeline,2669,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738830213,1,['pipeline'],['pipeline']
Deployability,"bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon; **Describe the bug**; is been running like an order of magnitude slower than when I last used it ; **A clear and concise description of what the bug is.**; So I am aligning reads against Arabidopsis Thaliana, using Araport 11 annotation. I usually had 20 M reads aligned within an hour or 2. I am aligning a 46M reads library and it has been running for 20 hours using 4 threads of my humble i5-3210M and is barely on 38.5M, after 20 hours! Index was constructed with default kmer size and no decoys. I have had this problem with other libraries since upgraded from V1.0.0, . **To Reproduce**; I guess just try to align stuff against araport11, this particular problem comes with any fq.gz. It will take hours and hours and hours to align. **Specifically, please provide at least the following information:**. * Which version of salmon was used?; 1.2.1; * How was salmon installed (compiled, downloaded executable, through bioconda)?; downloaded executable; * Which reference (e.g. transcriptome) was used?; Araport 11, from A. thaliana; * Which read files were used?; regular fastq.gz ( SRR7985407); * Which which program options were used?; --validateMappings; -p 4; --seqBias; --gcBias ; --posBias. **Expected behavior**; Much faster alignment, it is Salmon !!; **Screenshots**; this is the run info so far:. Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v1.2.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/jaimealaniz/Documents/indexes/salmon/ara11/ }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR7985407_1.fq.gz }; ### [ mates2 ] => { SRR7985407_2.fq.gz }; ### [ validateMappings ] => { }; ### [ threads ] => { 4 }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ posBias ] => { }; ### [ output ] => { /home/jaimealaniz/Documents/salmon.embryo/SRR7985407/ }; Logs will be written to /home/jaimealaniz/Documents/salmon.embryo/",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527:965,install,installed,965,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527,1,['install'],['installed']
Deployability,"bug**; When building Salmon 1.10.3 from source, I'm seeing the following error.; ```; [ 63%] Building CXX object src/CMakeFiles/salmon_core.dir/GenomicFeature.cpp.o; In file included from /usr/include/pthread.h:33,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/x86_64-pc-linux-gnu/bits/gthr-default.h:35,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/x86_64-pc-linux-gnu/bits/gthr.h:148,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/ext/atomicity.h:35,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/bits/ios_base.h:39,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/ios:44,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/ostream:40,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/system/error_code.hpp:17,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/system/system_error.hpp:11,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/exceptions.hpp:22,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/pthread/thread_data.hpp:10,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread_only.hpp:17,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread.hpp:12,; from /gpfs/projects/hpc_support/salmon/include/GenomicFeature.hpp:25,; from /gpfs/projects/hpc_support/salmon/src/GenomicFeature.cpp:22:; /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/pthread/thread_data.hpp:60:5: error: missing binary operator before token ""(""; 60 | #if PTHREAD_STACK_MIN > 0; | ^~~~~~~~~~~~~~~~~; In file included from /gpfs/projects/hpc_support/salmon/external/install/include/boost/functional/hash.hpp:6,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/detail/thread.hpp:41,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread_only.hpp:22:; /gpfs/projects/hpc_support/salmon/external/install/include/boost/container_hash/hash.hpp:130:33:",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/953:1132,install,install,1132,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/953,1,['install'],['install']
Deployability,can you try `make install` before `make test`?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393690468:18,install,install,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393690468,1,['install'],['install']
Deployability,"cc : @k3yavi . Hi @xuesoso, I know that Avi (tagged above) has implemented a flag for this, but I'm not certain if it is exposed in the current release. I'm tagging him here to chime in.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/567#issuecomment-695004138:144,release,release,144,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/567#issuecomment-695004138,1,['release'],['release']
Deployability,"cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] => { ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz }; ### [ mates2 ] => { ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz }; ### [ maxHashResizeThreads ] => { 2 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ### [ tgMap ] => { tx2gene.txt }. [2018-06-10 16:07:09.798] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [New Thread 0x7ffcfcffb700 (LWP 21657)]; [Thread 0x7ffcfcffb700 (LWP 21657) exited]; [New Thread 0x7ffc7cffa700 (LWP 21658)]; [New Thread 0x",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:2456,upgrade,upgrades,2456,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['upgrade'],['upgrades']
Deployability,"cessed 283000000 positions^M^Mprocessed 284000000 positions^M^Mprocessed 285000000 positions^M^Mprocessed 286000000 positions^M^Mprocessed 287000000 positions^M^Mprocessed 288000000 positions^M^Mprocessed 289000000 positions; khash had 109134690 keys; saving hash to disk . . . done; Elapsed time: 12.6069s; [2018-06-25 19:29:02.297] [jLog] [info] done building index; ```. It would be more interesting to see what filename is used for the index. Showing the ""basename"" of the index file is not very helpful. I would prefer to see the filename(s) on the beginning and end lines:. ```; index [""Homo_sapiens.GRCh38.cdna.all""] did not previously exist . . . creating it; [2018-06-25 19:25:57.122] [jLog] [info] building index; ...; [2018-06-25 19:29:02.297] [jLog] [info] done building index; ```. 5. The duplicates have same sequence or ID or both? The message should be clearer. I wonder what are these duplicates in a human cdna predicted, as available from `ftp://ftp.ensembl.org/pub/release-92/fasta/homo_sapiens/cdna`; :. ```; [2018-06-25 19:26:07.480] [jointLog] [warning] Removed 11768 transcripts that were sequence duplicates of indexed transcripts.; ```. 6. For the bwa-based index again, the logs are too verbose on one hand and on the second, they do not say what files were created. I doubt any file with *prefix* `Homo_sapiens.GRCh38.cdna.all/bwaidx` was created. ```; + salmon index -t Homo_sapiens.GRCh38.cdna.all.fa -i Homo_sapiens.GRCh38.cdna.all --type fmd; outputPrefix = ""Homo_sapiens.GRCh38.cdna.all/bwaidx""; [2018-06-25 19:29:02.497] [jLog] [info] building index; [bwa_index] Pack FASTA... 2.87 sec; [bwa_index] Construct BWT for the packed sequence...; [BWTIncCreate] textLength=609536484, availableWord=54888760; [BWTIncConstructFromPacked] 10 iterations done. 87569268 characters processed.; [BWTIncConstructFromPacked] 20 iterations done. 164630980 characters processed.; [BWTIncConstructFromPacked] 30 iterations done. 233119636 characters processed.; [BWTIncConstructFromPac",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/242:13318,release,release-,13318,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/242,1,['release'],['release-']
Deployability,"cl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test2/${ID}. echo ""**** Job ends ****""; date; ```. and the log file for task 2:. ```bash; $ more logs/salmon_test2.2.txt; **** Job starts ****; Wed Mar 8 11:53:17 EST 2017; **** JHPCE info ****; User: lcollado; Job id: 9987283; Job name: step6-salmon_test2.gsk_phaseII; Hostname: compute-060; Task id:; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and minor bug fixes; please upgrade at your; earliest convenience.; ###; ### salmon (mapping-based) v0.7.2; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test2/R10002_C29P7ACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test2/R10002_C29P7ACXX/logs; [2017-03-08 11:53:36.762] [jointLog] [info] parsing read library format; [2017-03-08 11:53:36.763] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-060/job_scripts/9987283: line 31: 1629 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Softw; are/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:28883,pipeline,pipeline,28883,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['pipeline'],['pipeline']
Deployability,"cl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID} 2> logs/strace_test12_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. Again, here is the `strace` output for task 1 (411 lines):. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/li",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:79725,pipeline,pipeline,79725,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"clude/c++/13.2.0/ext/atomicity.h:35,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/bits/ios_base.h:39,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/ios:44,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/ostream:40,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/system/error_code.hpp:17,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/system/system_error.hpp:11,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/exceptions.hpp:22,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/pthread/thread_data.hpp:10,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread_only.hpp:17,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread.hpp:12,; from /gpfs/projects/hpc_support/salmon/include/GenomicFeature.hpp:25,; from /gpfs/projects/hpc_support/salmon/src/GenomicFeature.cpp:22:; /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/pthread/thread_data.hpp:60:5: error: missing binary operator before token ""(""; 60 | #if PTHREAD_STACK_MIN > 0; | ^~~~~~~~~~~~~~~~~; In file included from /gpfs/projects/hpc_support/salmon/external/install/include/boost/functional/hash.hpp:6,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/detail/thread.hpp:41,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread_only.hpp:22:; /gpfs/projects/hpc_support/salmon/external/install/include/boost/container_hash/hash.hpp:130:33: warning: ‘template<class _Arg, class _Result> struct std::unary_function’ is deprecated [-Wdeprecated-declarations]; 130 | struct hash_base : std::unary_function<T, std::size_t> {};; | ^~~~~~~~~~~~~~; In file included from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/string:49,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/exceptions.hpp:20:; /gpfs/software/gcc/13.2.0/include/c++/13.2.0/bits/stl_f",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/953:1562,install,install,1562,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/953,1,['install'],['install']
Deployability,"code prefix, where either nothing, or `A/GT/TCA` are added to the front of some cell barcodes. Here are the full descriptions:. ```; # Long sequence:; # 0123456789012345678901234567890123456789012345678901234567890123456789012345; # [--BC1--][----L1----][--BC2--][----L02----][--BC3--][-UMI1-][TTTTTTTTTTTTTT]; # L1 = ACTGGCCTGCGA; L2 = GGTAGCGGTGACA; # Short sequence:; # 012345678901234567890123456789012345678901234567890; # [--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTTTT]; # L1 = GTGA; L2 = GACA; # Note: short sequence can also be prepended with A/GT/TCA to improve Illumina base; # call distributions, i.e.; # [--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTTTT]; # A[--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTTT]; # GT[--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTTT]; # TCA[--BC1--][L1][--BC2--][L2][--BC3--][-UMI1-][TTT]; ```. This means that the regions defined in the geometry specification above can appear up to 3bp away from their expected region. I've updated my barcode squishing script ([here](https://gitlab.com/gringer/bioinfscripts/-/blob/master/synthSquish.pl)) to account for this. The script identifies the cell barcode regions, corrects cell barcode sequences according to the Rhapsody Bioinformatics manual, and then shifts the linker sequences to after the UMI region, i.e.:. # 012345678901234567890123456789012345678901234567890...; # [--BC1--][--BC2--][--BC3--][-UMI1-][L1][L2][TTTTTT...]. [The prefix sequence is discarded]. After using this script to pre-process R1, with both the old and new cell barcode format (both use 9x9x9 cell barcodes), the following geometry can be used for `salmon alevin`:. --umi-geometry '1[28-35]' --bc-geometry '1[1-27]' --read-geometry '2[1-end]'. I've attached files containing the 96 barcodes from each region from my most recent Rhapsody single cell sequencing run (with 51bp R1 reads). These were collected by processing reads 2M-12M from R1 of one of our files, and choosing the most abundant sequences:. ```; zgrep '^[ACGT]\+$",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-1277030250:1494,update,updated,1494,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-1277030250,1,['update'],['updated']
Deployability,"common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; THELUA=/usr/common/modules/el8/x86_64/modules/all/${package}/${pversion}-CentOS-vanilla.lua; cd /usr/common/src; git clone -b develop https://github.com/COMBINE-lab/salmon.git; mv ${package} ${package}-${pversion}; cd ${package}-${pversion}; cp CMakeLists.txt CMakeLists.txt.dist; cat >mypatch <<'EOD'; --- CMakeLists.txt.dist	2020-04-21 22:31:07.000000000 -0700; +++ CMakeLists.txt	2020-06-09 14:55:02.733885772 -0700; @@ -419,6 +419,10 @@; find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); +message(""Forcing Boost_FOUND to TRUE""); +set(Boost_FOUND TRUE); +set(Boost_LIBRARY_DIRS ""/usr/lib64/boost169""); +set(Boost_LIBRARIES -lboost_iostreams -lboost_filesystem -lboost_system -lboost_timer -lboost_chrono -lboost_program_options); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; EOD; patch -p0 <mypatch; module load cmake; module load io_lib; module load libgff; module load libtbb; # module load pufferfish #ignored even if set; mkdir build; cd build; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_23.log; make -j 4 2>&1 | tee build_2020_06_23.log; make test # both passed; make install 2>&1 | tee install_2020_06_23.log; cd ..; cp sample_data.tgz $TOPDIR; module_generate_from_directory.sh \; $package \; $pversion \; CentOS/vanilla \; $TOPDIR \; ""Fast highly-accurate, transcript-level quantification estimates from RNA-seq data."" \; ""https://github.com/COMBINE-lab/salmon""; ```. When the following commands are run in an XFCE4 terminal or an uxterm (black text, white background) using the sample data provid",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/541:1123,patch,patch,1123,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/541,1,['patch'],['patch']
Deployability,conda installs v 0.8.2 (Mac),MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194:6,install,installs,6,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194,1,['install'],['installs']
Deployability,constant Version Info: Could not resolve upgrade information in the alotted time.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/277:41,upgrade,upgrade,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/277,1,['upgrade'],['upgrade']
Deployability,"ctory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356A\316;\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=1926760, ...}) = 0; mmap(0x3bce400000, 3750152, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x3bce400000; mprotect(0x3bce58a000, 2097152, PROT_NONE) = 0; mmap(0x3bce78a000, 20480, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x18a000) = 0x3bce78a000; mmap(0x3bce78f000, 18696, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x3bce78f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:58778,pipeline,pipeline,58778,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['pipeline'],['pipeline']
Deployability,"d counts as well as TPM much faster than any other tool. Can you tell me what is the problem. . Command line used; `salmon index -t /path_to/genome.fa -i salmonquasi-indexes --type quasi -k 31`. Here is the error message while using the Ram-Map. ```; Version Info: This is the most recent version of Salmon.; index [""salmonquasi-indexes""] did not previously exist . . . creating it; [2016-03-17 10:41:34.655] [jointLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; Elapsed time: 53.9731s. Replaced 96385738 non-ATCG nucleotides; Clipped poly-A tails from 0 transcripts; Building rank-select dictionary and saving to disk done; Elapsed time: 0.196609s; Writing sequence data to file . . . done; Elapsed time: 1.56391s; [info] Building 64-bit suffix array (length of generalized text is 2654911539 ); Building suffix array . . . success; saving to disk . . . done; Elapsed time: 126.003s; done; Elapsed time: 883.472s; processed 615000000 positionssalmon: /home/vagrant/salmon/external/install/include/sparsehash/internal/densehashtable.h:782: void google::dense_hashtable<Value, Key, HashFcn, ExtractKey, SetKey, EqualKey, Alloc>::clear_to_size(google::dense_hashtable<Value, Key, HashFcn, ExtractKey, SetKey, EqualKey, Alloc>::size_type) [with Value = std::pair<const long unsigned int, rapmap::utils::SAInterval<long int> >; Key = long unsigned int; HashFcn = rapmap::utils::KmerKeyHasher; ExtractKey = google::dense_hash_map<long unsigned int, rapmap::utils::SAInterval<long int>, rapmap::utils::KmerKeyHasher, std::equal_to<long unsigned int>, google::libc_allocator_with_realloc<std::pair<const long unsigned int, rapmap::utils::SAInterval<long int> > > >::SelectKey; SetKey = google::dense_hash_map<long unsigned int, rapmap::utils::SAInterval<long int>, rapmap::utils::KmerKeyHasher, std::equal_to<long unsigned int>, google::libc_allocator_with_realloc<std::pair<const long unsigned int, rapmap::utils::SAInterval<long int> > > >::SetKey; EqualKey = std::equal_to<lo",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/49:1611,install,install,1611,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/49,1,['install'],['install']
Deployability,"d on GitHub.com; your repository will automatically benefit from the most recently released version. #### The analysis doesn’t seem to be working; If you get an error in GitHub Actions that indicates that CodeQL wasn’t able to analyze your code, please [follow the instructions here](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/troubleshooting-the-codeql-workflow) to debug the analysis. #### How do I disable LGTM.com?; If you have LGTM’s automatic pull request analysis enabled, then you can [follow these steps to disable the LGTM pull request analysis](https://lgtm.com/help/lgtm/managing-automated-code-review#disabling-pr-integration). You don’t actually need to remove your repository from LGTM.com; it will automatically be removed in the next few months as part of the deprecation of LGTM.com ([more info here](https://github.blog/2022-08-15-the-next-step-for-lgtm-com-github-code-scanning/)). #### Which source code hosting platforms does code scanning support?; GitHub code scanning is deeply integrated within GitHub itself. If you’d like to scan source code that is hosted elsewhere, we suggest that you create a mirror of that code on GitHub. #### How do I know this PR is legitimate?; This PR is filed by the official LGTM.com GitHub App, in line with the [deprecation timeline that was announced on the official GitHub Blog](https://github.blog/2022-08-15-the-next-step-for-lgtm-com-github-code-scanning/). The proposed GitHub Action workflow uses the [official open source GitHub CodeQL Action](https://github.com/github/codeql-action/). If you have any other questions or concerns, please join the discussion [here](https://github.com/orgs/community/discussions/29534) in the official GitHub community!. #### I have another question / how do I get in touch?; Please join the discussion [here](https://github.com/orgs/community/discussions/29534) to ask further questions and send us suggestions!. </details>",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/815:4365,integrat,integrated,4365,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/815,1,['integrat'],['integrated']
Deployability,"d using gffread (command used: ""gffread -g BY4742.fa -o wt-syn-transcriptome.gff -w wt-syn-transcriptome.fa -v -C BY4742.gff"").; * Which read files were used? Paired end fastq files (trimmed by fastp).; * Which which program options were used? ""--validateMappings --threads 1 --libType A --index transcriptome-index --mates1 sample1_R1_001.trimmed.fastq.gz --mates2 sample1_R2_001.trimmed.fastq.gz --output sample1"". **Expected behavior**; A clear and concise description of what you expected to happen.; Salmon quant to generate quant.sf file. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with bug fixes is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ###; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ validateMappings ] => { }; ### [ threads ] => { 1 }; ### [ libType ] => { A }; ### [ index ] => { transcriptome-index }; ### [ mates1 ] => { sample1_R1_001.trimmed.fastq.gz }; ### [ mates2 ] => { sample1_R2_001.trimmed.fastq.gz }; ### [ output ] => { sample1 }; Logs will be written to sample1/logs; [2023-10-11 16:03:44.489] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-10-11 16:03:44.490] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2023-10-11 16:03:44.490] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2023-10-11 16:03:44.490] [jointLog] [info] Usage of --va",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/881:1765,update,updates,1765,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/881,1,['update'],['updates']
Deployability,"d# make install; [ 7%] Built target libcereal; [ 13%] Built target libtbb; [ 16%] Built target ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ................",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1777,Install,Installing,1777,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,"['Install', 'release']","['Installing', 'release']"
Deployability,"d; #$ -pe local 2; #$ -l mem_free=7G,h_vmem=8G,h_fsize=100G; #$ -N step6-salmon_test11.gsk_phaseII; #$ -o ./logs/salmon_test11.$TASK_ID.txt; #$ -e ./logs/salmon_test11.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID} 2> logs/strace_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. This requests SGE 2 cores with a total free memory of 2 * 7 = 14 GB and a maximum memory of 16 GB. This is the `strace` output for task 1:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; re",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:3339,pipeline,pipeline,3339,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"dSalmonIndex.cpp.o CMakeFiles/salmon.dir/Graph.cpp.o CMakeFiles/salmon.dir/DedupUMI.cpp.o CMakeFiles/salmon.dir/Alevin.cpp.o CMakeFiles/salmon.dir/AlevinHash.cpp.o CMakeFiles/salmon.dir/SalmonAlevin.cpp.o CMakeFiles/salmon.dir/WhiteList.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/SalmonQuantMerge.cpp.o CMakeFiles/salmon.dir/ProgramOptionsGenerator.cpp.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/ONTAlignmentModel.cpp.o CMakeFiles/salmon.dir/AlignmentCommon.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o CMakeFiles/salmon.dir/BAMUtils.cpp.o -o salmon -L/vol/mgx-sw/src/tools/salmon/lib -L/vol/mgx-sw/lib -L/vol/mgx-sw/src/tools/salmon/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" ../external/pufferfish/src/libpuffer.a libsalmon_core.a ../external/pufferfish/external/twopaco/graphconstructor/libtwopaco.a ../external/pufferfish/external/twopaco/graphdump/libgraphdump.a ../external/pufferfish/external/ntcard/libntcard.a -lgff /usr/lib/x86_64-linux-gnu/libboost_iostreams.a /usr/lib/x86_64-linux-gnu/libboost_filesystem.a /usr/lib/x86_64-linux-gnu/libboost_system.a /usr/lib/x86_64-linux-gnu/libboost_timer.a /usr/lib/x86_64-linux-gnu/libboost_chrono.a /usr/lib/x86_64-linux-gnu/libboost_program_options.a /usr/lib/x86_64-linux-gnu/libboost_locale.a ../../external/install/lib/libstaden-read.a /usr/lib/x86_64-linux-gnu/libcurl.a /usr/lib/x86_64-linux-gnu/libz.a -lm /usr/lib/x86_64-linux-gnu/liblzma.a /usr/lib/x86_64-linux-gnu/libbz2.a -lgomp ../external/pufferfish/src/libksw2pp.a libalevin_core.a ../../external/install/lib/libjemalloc.a -ltbbmalloc_proxy -ltbbmalloc -ltbb -lrt -ldl /usr/lib/x86_64-linux-gnu/libboost_system.a /usr/lib/x86_64-linux-gnu/libboost_c",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/664:2655,install,install,2655,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/664,1,['install'],['install']
Deployability,"dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID} 2> logs/strace_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. This requests SGE 2 cores with a total free memory of 2 * 7 = 14 GB and a maximum memory of 16 GB. This is the `strace` output for task 1:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/li",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:4392,pipeline,pipeline,4392,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev. $ git clone https://github.com/COMBINE-lab/salmon.git; $ cd salmon; $ mkdir build && cd build; $ cmake -DNO_IPO=TRUE .. # GCC still doesn't handle LTO robustly; $ make -j8; $ make install; $ make test; ```. which leads to the output. ```; root@fd877e359439:/salmon/build# make install; [ 7%] Built target libcereal; [ 13%] Built target libtbb; [ 16%] Built target ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; =================================================",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1439,Install,Installing,1439,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,"['Install', 'release']","['Installing', 'release']"
Deployability,"dex of the C. elegans Wormbase WS265 transcriptome with the following settings:. `salmon index -k 21 -p 24 -t ${txome_reference} -i ${index_path}`. but upon running quant with the following command:. `salmon quant -i ${index_path} -o ${out_prefix} -l IU -1 ${mate1_reads} -2 ${mate2_reads}; `. I get a segmentation fault error midway through running:. ```hits: 122146249, hits per frag: 2.10747; processed 58500001 fragments; hits: 123209453, hits per frag: 2.11344; processed 59000000 fragments; hits: 124280773, hits per frag: 2.10932. /cm/local/apps/slurm/var/spool/job28571481/slurm_script: line 39: 1187 Segmentation fault salmon quant -i ${index_path} -o ${out_prefix} -l IU -1 ${mate1_reads} -2 ${mate2_reads}; ```. If it helps I'm running this on the following SRA data:; > SRR016679; > SRR016680; > SRR016681. This is running on a CentOS release 6.9 cluster. The script in which salmon is being called is being run through SLURM 17.11.7 workload management software. I tried installing a older version of salmon ( 0.9.1 ) through conda and ended up with the same error running that version. ; I've also tried downloading the source and compiling, but am running in to an error upon calling make:. ```libtool: compile: /usr/bin/cc -DHAVE_CONFIG_H -I. -I.. -I.. -MT libstaden_read_la-cram_io.lo -MD -MP -MF .deps/libstaden_read_la-cram_io.Tpo -c cram_io.c -o libstaden_read_la-cram_io.o; cram_io.c:66:18: error: lzma.h: No such file or directory; cram_io.c: In function 'lzma_mem_deflate':; cram_io.c:1389: error: 'LZMA_OK' undeclared (first use in this function); cram_io.c:1389: error: (Each undeclared identifier is reported only once; cram_io.c:1389: error: for each function it appears in.); cram_io.c:1389: error: 'LZMA_CHECK_CRC32' undeclared (first use in this function); cram_io.c: In function 'lzma_mem_inflate':; cram_io.c:1399: error: 'lzma_stream' undeclared (first use in this function); cram_io.c:1399: error: expected ';' before 'strm'; cram_io.c:1405: error: 'LZMA_OK' undecla",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/268:1136,install,installing,1136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/268,1,['install'],['installing']
Deployability,"dif; }. Determining if the function pthread_create exists in the pthreads failed with the following output:; Change Dir: /home/bli/src/salmon/CMakeFiles/CMakeTmp. Run Build Command:""/usr/bin/make"" ""cmTC_dd9f2/fast""; /usr/bin/make -f CMakeFiles/cmTC_dd9f2.dir/build.make CMakeFiles/cmTC_dd9f2.dir/build; make[1]: Entering directory '/home/bli/src/salmon/CMakeFiles/CMakeTmp'; Building C object CMakeFiles/cmTC_dd9f2.dir/CheckFunctionExists.c.o; /usr/bin/cc -DCHECK_FUNCTION_EXISTS=pthread_create -o CMakeFiles/cmTC_dd9f2.dir/CheckFunctionExists.c.o -c /usr/share/cmake-3.7/Modules/CheckFunctionExists.c; Linking C executable cmTC_dd9f2; /usr/bin/cmake -E cmake_link_script CMakeFiles/cmTC_dd9f2.dir/link.txt --verbose=1; /usr/bin/cc -DCHECK_FUNCTION_EXISTS=pthread_create CMakeFiles/cmTC_dd9f2.dir/CheckFunctionExists.c.o -o cmTC_dd9f2 -rdynamic -lpthreads ; /usr/bin/ld: cannot find -lpthreads; collect2: error: ld returned 1 exit status; CMakeFiles/cmTC_dd9f2.dir/build.make:97: recipe for target 'cmTC_dd9f2' failed; make[1]: *** [cmTC_dd9f2] Error 1; make[1]: Leaving directory '/home/bli/src/salmon/CMakeFiles/CMakeTmp'; Makefile:126: recipe for target 'cmTC_dd9f2/fast' failed; make: *** [cmTC_dd9f2/fast] Error 2. ```. Some search on the internet suggests me that sometimes `-lpthread` should be used instead of `-lpthreads`. And indeed, if I try to compile the following code:; ```; #include <pthread.h>. int main(int argc, char** argv); {; (void)argv;; #ifndef pthread_create; return ((int*)(&pthread_create))[argc];; #else; (void)argc;; return 0;; #endif; }; ```. I observe a failure with `-lpthreads`:; ```; $ cc -lpthreads /home/bli/src/salmon/CMakeFiles/CMakeTmp/CheckSymbolExists.c; /usr/bin/ld: cannot find -lpthreads; collect2: error: ld returned 1 exit status; ```. And a success with `-lpthread`:. ```; $ cc -lpthread /home/bli/src/salmon/CMakeFiles/CMakeTmp/CheckSymbolExists.c; $ ; ```. However, I'm unable to find where I can fix this in the whole configuration and build process.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/207:3572,configurat,configuration,3572,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/207,1,['configurat'],['configuration']
Deployability,different TPMs for different releases of ensembl fasta,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/653:29,release,releases,29,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/653,1,['release'],['releases']
Deployability,"e = 0.590918%. ```. and then this after processing the cells:; ```; [2018-07-24 10:56:23.180] [alevinLog] [info] Total 21135 UMI after deduplicating.; [2018-07-24 10:56:23.180] [alevinLog] [warning] Skipped 4 barcodes due to No mapped read; [2018-07-24 10:56:23.213] [alevinLog] [info] Clearing EqMap; Might take some time.; [2018-07-24 10:56:23.230] [alevinLog] [info] Starting Import of the gene count matrix.; [2018-07-24 10:56:23.743] [alevinLog] [info] Done Importing gene count matrix for dimension 290x57964; [2018-07-24 10:56:23.743] [alevinLog] [info] Starting dumping cell v gene counts in csv format; [2018-07-24 10:56:29.089] [alevinLog] [info] Finished dumping csv counts; [2018-07-24 10:56:29.089] [alevinLog] [info] Starting white listing; [2018-07-24 10:56:29.090] [alevinLog] [info] Done importing order of barcodes ""quants_mat_rows.txt"" file.; [2018-07-24 10:56:29.090] [alevinLog] [info] Total 290 barcodes found; [2018-07-24 10:56:29.090] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2018-07-24 10:56:29.090] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2018-07-24 10:56:29.090] [alevinLog] [info] Starting to make feature Matrix; [2018-07-24 10:56:29.354] [alevinLog] [info] Done making regular featues; [2018-07-24 10:56:29.354] [alevinLog] [info] Done making feature Matrix; [2018-07-24 10:56:29.359] [alevinLog] [info] Finished white listing; [2018-07-24 10:56:29.371] [alevinLog] [info] Finished optimizer; ```. Other info:; Salmon v0.11.0 - downloaded binary from Github; I used Gencode 28 for the transcriptome; read files: https://www.ncbi.nlm.nih.gov/sra/SRX2676721[accn]. OS: CentOS; version: 2.6.32-696.23.1.el6.centos.plus.x86_64; LSB Version:	:base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch; Distributor ID:	CentOS; Description:	CentOS release 6.9 (Final); Release:	6.9; Codename:	Final",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258:6411,release,release,6411,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258,2,"['Release', 'release']","['Release', 'release']"
Deployability,"e bash script we used to run `salmon` for a 422 sample dataset:. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=80G,h_vmem=90G,h_fsize=100G; #$ -N step6-txQuant-alzheimer.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/txQuant-alzheimer.$TASK_ID.txt; #$ -e ./logs/txQuant-alzheimer.$TASK_ID.txt; #$ -t 1-422; #$ -m a; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/${ID}. echo ""**** Job ends ****""; date; ```. The important part is that we are requesting 1 single core with 80 GB of free memory and setting the limit at 90 GB. We are also using the `-p 1` option. . Here is the log file for one of them (task 3):. ```; **** Job starts ****; Mon Mar 6 23:19:13 EST 2017; **** JHPCE info ****; User: lcollado; Job id: 9958683; Job name: step6-txQuant-alzheimer.gsk_phaseII; Hostname: compute-068; Task id: ; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases ; contains new features, improvements, and minor bug fixes; please upgrade at your; earliest convenience.; ###; ### salmo",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:1526,pipeline,pipeline,1526,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['pipeline'],['pipeline']
Deployability,"e instructions suggests that I should be in the ""build"" directory when I run cmake. However, if I do that it returns an error about CMakeLists.txt not being in that location. I noticed that is in the salmon directory so I ran cmake from there and it seemed to work fine. But, I'm not sure if that is leading to the problems I am having downstream. . The second issue is when I run make I get an error associated with configuring liblzma (error 77). I have pasted the console log below. I appreciate any suggestions and apologize if I missed something obvious. . This file contains any messages produced by compilers while; running configure, to aid debugging if configure makes a mistake. It was created by XZ Utils configure 5.2.2, which was; generated by GNU Autoconf 2.69. Invocation command line was. $ /Users/jeremybono/Downloads/salmon-1.10.1/external/xz-5.2.2/configure --prefix=/Users/jeremybono/Downloads/salmon-1.10.1/external/install CC=/Library/Developer/CommandLineTools/usr/bin/cc CXX=/Library/Developer/CommandLineTools/usr/bin/c++ CFLAGS= CPPFLAGS= LDFLAGS=. ## --------- ##; ## Platform. ##; ## --------- ##. hostname = Jeremys-Mac-Studio.local; uname -m = arm64; uname -r = 22.6.0; uname -s = Darwin; uname -v = Darwin Kernel Version 22.6.0: Wed Jul 5 22:21:53 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T6020. /usr/bin/uname -p = arm; /bin/uname -X = unknown. /bin/arch = unknown; /usr/bin/arch -k = unknown; /usr/convex/getsysinfo = unknown; /usr/bin/hostinfo = Mach kernel version:; 	 Darwin Kernel Version 22.6.0: Wed Jul 5 22:21:53 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T6020; Kernel configured for up to 12 processors.; 12 processors are physically available.; 12 processors are logically available.; Processor type: arm64e (ARM64E); Processors active: 0 1 2 3 4 5 6 7 8 9 10 11; Primary memory available: 64.00 gigabytes; Default processor set: 650 tasks, 3562 threads, 12 processors; Load average: 1.14, Mach factor: 10.84; /bin/machine = unknown; /usr/bin/osleve",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/912:1211,install,install,1211,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/912,1,['install'],['install']
Deployability,"e of intuition formally into the probabilistic model and (2) is it possible to incorporate this information efficiently?. This is definitely your domain of expertise (and I know it's a rhetorical question but I'd love to throw some ideas out here)... I can think of a few mostly heuristical approaches.... . 1) when apportioning reads to transcripts, after the mapping phase, incorporate a notion of ""evenness"" into the EM step... reads that decrease the variance in coverage are favored over reads that increase the variance (so, define read depth per 10 bp window or something and calculate the variance across all windows for the transcript, then try to assign reads such that they minimize read depth variance per isoform). The problem here is actual coverage biases may then masquerade as alternative transcript isoforms... 2) Use the information from the unique sequences between the transcripts... the read depth over unique regions updates the prior on the overall transcript abundance, and the otherwise non-unique reads get apportioned in accordance with the unique-region-derived prior... . But as I think about it... I realize I don't *really* know the underlying algorithmic details of the existing implements. But it would be **amazing** if you could incorporate this type of information into Salmon. I really hope some progress can be made here! . Thanks again for helping me out and showing interest in the motivating problem!. P.S.,; As a total aside, I've been working with this large yeast RNAseq dataset and eventually reached the same conclusions as the selective alignment paper and other recent ones; that is, the most important aspect for getting good transcript-level quantifications is not aligning to the genome vs. aligning to the transcriptome, but rather having an accurate transcriptome annotation to begin with. I saw **huge** gains from updating my transcriptome annotation to include UTRs, especially given differences in coverage bias between samples... for example,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851:3445,update,updates,3445,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851,1,['update'],['updates']
Deployability,"e salmon; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xec4): warning: the use of `tempnam' is dangerous, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1139,Install,Installing,1139,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installing']
Deployability,"e upgrade at your; earliest convenience.; ###; ### salmon (mapping-based) v0.7.2; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/R10003_D19KGACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/R10003_D19KGACXX/logs; [2017-03-08 11:37:32.888] [jointLog] [info] parsing read library format; [2017-03-08 11:37:32.893] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-051/job_scripts/9987275: line 31: 41232 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Softw; are/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.tr; anscripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/${ID}; **** Job ends ****; Wed Mar 8 11:37:36 EST 2017; ```. and the core dump file shows that the program was terminated:. ```bash; $ gdb core.41232; GNU gdb (GDB) Red Hat Enterprise Linux (7.2-60.el6_4.1); Copyright (C) 2010 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; For bug reporting instructions, please see:; <http://www.gnu.org/s",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:24037,pipeline,pipeline,24037,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['pipeline'],['pipeline']
Deployability,"e:3213: checking which decoders to build; configure:3305: result: lzma1 lzma2 delta x86 powerpc ia64 arm armthumb sparc; configure:3644: checking which match finders to build; configure:3695: result: hc3 hc4 bt2 bt3 bt4; configure:3713: checking which integrity checks to build; configure:3755: result: crc32 crc64 sha256; configure:3792: checking if assembler optimizations should be used; configure:3816: result: no; configure:3847: checking if small size is preferred over speed; configure:3865: result: no; configure:3881: checking if threading support is wanted; configure:3907: result: yes, posix; configure:3940: checking how much RAM to assume if the real amount is unknown; configure:3955: result: 128 MiB; configure:4085: checking if library symbol versioning should be used; configure:4108: result: no; configure:4126: checking for a shell that conforms to POSIX; configure:4167: result: /bin/sh; configure:4208: checking for a BSD-compatible install; configure:4276: result: /usr/bin/install -c; configure:4287: checking whether build environment is sane; configure:4342: result: yes; configure:4493: checking for a thread-safe mkdir -p; configure:4532: result: build-aux/install-sh -c -d; configure:4539: checking for gawk; configure:4569: result: no; configure:4539: checking for mawk; configure:4569: result: no; configure:4539: checking for nawk; configure:4569: result: no; configure:4539: checking for awk; configure:4555: found /usr/bin/awk; configure:4566: result: awk; configure:4577: checking whether make sets $(MAKE); configure:4599: result: yes; configure:4628: checking whether make supports nested variables; configure:4645: result: yes; configure:4771: checking whether ln -s works; configure:4775: result: yes; configure:4795: checking for style of include used by make; configure:4823: result: GNU; configure:4894: checking for gcc; configure:4921: result: /Library/Developer/CommandLineTools/usr/bin/cc; configure:5150: checking for C compiler version; configure:5159: ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/912:4315,install,install,4315,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/912,1,['install'],['install']
Deployability,eFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/SequenceBiasModel.cpp.o CMakeFiles/salmon.dir/StadenUtils.cpp.o CMakeFiles/salmon.dir/TranscriptGroup.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapFileSystem.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndexer.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndex.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAMapper.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapUtils.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/HitManager.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/bit_array.c.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_chrono.a /opt/boost/boost_1_57_0/lib/libboost_program_options.a /opt/boost/boost_1_57_0/lib/libboost_serialization.a ../../external/install/lib/libstaden-read.a -lz ../../external/install/lib/libdivsufsort.a ../../external/install/lib/libdivsufsort64.a ../../external/install/lib/libjellyfish-2.0.a ../../external/install/lib/libbwa.a -lm ../../externa,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:1796,install,install,1796,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,"eII; #$ -o ./logs/salmon_test11.$TASK_ID.txt; #$ -e ./logs/salmon_test11.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID} 2> logs/strace_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. This requests SGE 2 cores with a total free memory of 2 * 7 = 14 GB and a maximum memory of 16 GB. This is the `strace` output for task 1:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:3438,pipeline,pipeline,3438,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"eII; #$ -o ./logs/salmon_test12.$TASK_ID.txt; #$ -e ./logs/salmon_test12.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID} 2> logs/strace_test12_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. Again, here is the `strace` output for task 1 (411 lines):. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:78844,pipeline,pipeline,78844,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"eads unmapped: too many mismatches | 0.00%; % of reads unmapped: too short | 8.07%; % of reads unmapped: other | 0.12%; CHIMERIC READS:; Number of chimeric reads | 0; % of chimeric reads | 0.00%; ```. *yet, only `9,310,303` reads* were determined by STAR to project properly to annotated transcripts (slightly _less_ than are mapped to the transcriptome by salmon, at least without the decoy sequence included). So, there is a very high fraction of the reads that align to the genome, but a much smaller fraction ~45%-50% that align to the transcriptome. There are many reasons something like this could happen, but it suggests that there are a lot of reads being generated from outside of annotated transcripts. This could be a mix of novel transcripts in this sample (both at entirely novel loci, as well as novel transcripts within annotated loci), as well as of noisy transcription, unannotated transcribed pseudogenes etc. I took a look at the bigwig generated by this pipeline, and STAR seems to be mapping quite a lot of reads to chr21 as well as to the mitochondrial genome (chrM). However, as evidenced by the fact that neither salmon using selective-alignment (and mapping to the transcriptome) nor the STAR->salmon pipeline see these reads mapping to annotated transcripts they must be arising from outside of these regions. There are a few option in this case. You could manually investigate where these reads are coming from by aligning them with e.g. STAR and inspecting the BAM files. Alternatively, you could attempt to assemble novel transcripts (e.g. using StringTie or Scallop) and then add them to the transcriptome for quantification. However, it does seem that getting down to the bottom of the relatively low mapping rate to the annotated transcriptome, in light of the relatively high mapping rate to the whole genome, but outside of annotated transcripts, may require a bit more digging. I'm happy to answer any other specific questions that might arise if you dig into this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-745768992:2374,pipeline,pipeline,2374,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-745768992,2,['pipeline'],['pipeline']
Deployability,"eber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_lin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:7217,pipeline,pipeline,7217,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"ection, tells the Salmon model not to consider the effective length of each transcript for computing the conditional probabilities of originating a fragment from a transcript. So, for the RNA-seq data there is no reason to turn off this term of the model, and we highly recommend not to use that flag for the bulk RNA-seq abundance estimation with Salmon. Looking more carefully at the 2nd case you have posted as the failure case, it is interesting to see that there is a very nice visual evidence on the super transcript that the long transcript might not be expressed at all. I am referring to the zero coverage regions on the Super Transcript between the regions corresponding to the smaller transcripts, e. g., between POF1 and EMC1. So, we tried a solution that inspects the coverage profile of all transcripts and calculates the probability of observing a zero coverage region on each transcript. If this probability is too low, this would be counted as an evidence for a transcript not being expressed at all. This approach seems to be working fine on this example that you have shared here. however, one problem was that there were considerable number of reads in the sample that were uniquely mapping only to the Super Transcript and turning of the expression of that transcript would result in treating those reads as un-mapped. Furthermore, this problem was more evident when we tried that approach on other larger samples, it seemed that could effect the expression of a lot transcripts very significantly. Specially, on the real samples where the coverage are often not uniform and detecting a zero coverage region on a transcript is more common due to un-annotated transcripts in the samples and etc. Currently, we are actively looking for more thorough solutions for this problem to deal with the coverage profile of transcripts. I'll try to update you more as we make more progress about this. Thank you again for the detailed explanation, hope to get back at you soon. Best,; Mohsen",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-666512703:2553,update,update,2553,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-666512703,1,['update'],['update']
Deployability,"ed 268000000 positions. processed 269000000 positions. processed 270000000 positions. processed 271000000 positions. processed 272000000 positions. processed 273000000 positions. processed 274000000 positions. processed 275000000 positions. processed 276000000 positions. processed 277000000 positions. processed 278000000 positions. processed 279000000 positions. processed 280000000 positions. processed 281000000 positions. processed 282000000 positions. processed 283000000 positions. processed 284000000 positions. processed 285000000 positions. processed 286000000 positions. processed 287000000 positions. processed 288000000 positions. processed 289000000 positions; khash had 109134690 keys; saving hash to disk . . . done; Elapsed time: 7.61947s; [2018-08-16 19:47:14.359] [jLog] [info] done building index; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; ### salmon (mapping-based) v0.9.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { ./index }; ### [ libType ] => { U }; ### [ unmatedReads ] => { ./single.fastq }; ### [ output ] => { ./output }; ### [ allowOrphansFMD ] => { }; ### [ threads ] => { 16 }; ### [ incompatPrior ] => { 1e-20 }; ### [ biasSpeedSamp ] => { 1 }; ### [ fldMax ] => { 1000 }; ### [ fldMean ] => { 200 }; ### [ fldSD ] => { 80 }; ### [ forgettingFactor ] => { 0.65 }; ### [ maxOcc ] => { 200 }; ### [ maxReadOcc ] => { 100 }; ### [ numBiasSamples ] => { 2000000 }; ### [ numAuxModelSamples ] => { 5000000 }; ### [ numPreAuxModelSamples ] => { 1000000 }; ### [ numGibbsSamples ] => { 0 }; ### [ numBootstraps ] => { 0 }; ### [ vbPrior ] => { 0.001 }; Logs will be written to ./output/logs; [2018-08-16 19:47:14.418] [jointLog] [info] parsing read library format; [2018-08-16 19:47:14.418] [jointLog] [info] There is 1 library.; [",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271:22961,release,releases,22961,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271,2,"['release', 'upgrade']","['releases', 'upgrade']"
Deployability,"ed in the `aux_info/unmapped_names.txt` file with `d`, but all reads were marked as `u`. **Screenshots**; ```; $grep ""Number of fragments discarded because they are best-mapped to decoys"" */logs/*. ERX4307280_quant/logs/salmon_quant.log:[2022-02-02 15:51:25.854] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 948,850; SRX10245671_quant/logs/salmon_quant.log:[2022-02-02 15:57:10.321] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 961,758; SRX3847835_quant/logs/salmon_quant.log:[2022-02-02 15:33:54.185] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 220,351; ```. **Desktop (please complete the following information):**; - OS: Linux; - Version: ; ```; Linux farm.cse.ucdavis.edu 4.15.0-159-generic #167-Ubuntu SMP Tue Sep 21 08:55:05 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux; ```; ```; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 18.04.6 LTS; Release:	18.04; Codename:	bionic; ```; **Additional context**; I intentionally mapped all three libraries as SE, even though two are PE. Because of the presence of polycistronic transcripts in microbes, many paired-end reads would be discordant, which causes counts to look very...odd. See [this preprint](https://www.biorxiv.org/content/10.1101/2022.01.24.477642v1) for more details on that phenomenon. I'm trying to use the decoys as a first step in identifying reads that map to intergenic sequences, where reads might span two coding domain sequences, or land in the intergenic sequences between two coding domain sequenes. (#52). Decoy names: [s__Faecalibacterium_prausnitzii_C_clustered_intergenic_seq_names.txt.gz](https://github.com/COMBINE-lab/salmon/files/8005978/s__Faecalibacterium_prausnitzii_C_clustered_intergenic_seq_names.txt.gz); Transcriptome: [s__Faecalibacterium_prausnitzii_C.fa.gz](https://github.com/COMBINE-lab/salmon/files/8005980/s__Faecalibacterium_prausnitzii_C.fa.gz)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/748:5097,Release,Release,5097,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/748,1,['Release'],['Release']
Deployability,"ed more RAM? Or it is a bug.; ; More info as below:; [2018-10-24 11:14:15.505] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-10-24 11:14:15.505] [jointLog] [info] parsing read library format; [2018-10-24 11:14:15.505] [jointLog] [info] There is 1 library.; [2018-10-24 11:14:15.627] [jointLog] [info] Loading Quasi index; [2018-10-24 11:14:15.629] [jointLog] [info] Loading 32-bit quasi index; [2018-10-24 11:14:15.633] [stderrLog] [info] Loading Suffix Array; [2018-10-24 11:14:17.090] [stderrLog] [info] Loading Transcript Info; [2018-10-24 11:14:17.691] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-10-24 11:14:18.293] [stderrLog] [info] There were 309,566 set bits in the bit array; [2018-10-24 11:14:18.819] [stderrLog] [info] Computing transcript lengths; [2018-10-24 11:14:18.820] [stderrLog] [info] Waiting to finish loading hash; [2018-10-24 11:15:46.171] [jointLog] [info] done; [2018-10-24 11:15:46.171] [jointLog] [info] Index contained 309,566 targets; [2018-10-24 11:15:46.171] [stderrLog] [info] Done loading index. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used? 0.11.3; * How was salmon installed (compiled, downloaded executable, through bioconda)?. downloaded execitable. * Which reference (e.g. transcriptome) was used?; human; * Which read files were used?; * Which which program options were used?; All default. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Linux; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/304:1863,install,installed,1863,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/304,1,['install'],['installed']
Deployability,"eger width = 32; [2023-03-15 20:35:37.482] [puff::index::jointLog] [info] seqSize = 2,210,067,304; [2023-03-15 20:35:37.482] [puff::index::jointLog] [info] rankSize = 2,210,067,304; [2023-03-15 20:35:37.482] [puff::index::jointLog] [info] edgeVecSize = 0; [2023-03-15 20:35:37.482] [puff::index::jointLog] [info] num keys = 1,869,461,974; ^M[Building BooPHF] 0.194% elapsed: 0 min 0 sec remaining: 3 min 39 sec^M[Building BooPHF] 0.206% elapsed: 0 min 0 sec remaining: 3 min 33 sec^M[Building BooPHF] 0.394% elapsed: 0 min 1 sec remaining: 2 min 45 sec^M[Building BooPHF] 0.406% elapsed: 0 min 1 sec remaining: 2 min 44 sec^M[Building BooPHF] 0.594% elapsed: 0 min 1 sec remaining: 2 m; psed: 0 min 56 sec remaining: 1 min 16 sec^M[Building BooPHF] 42.4 % elapsed: 0 min 56 sec remaining: 1 min 16 sec^M[Building BooPHF] 42.6 % elapsed: 0 min 56 sec remaining: 1 min 15 sec^M[Building BooPHF] 42.6 % elapsed: 0 min 56 sec remaining: 1 min 15 sec^M[Building BooPHF] 42.8 % elapsed: 0 min 56 sec remaining: 1 min 15 sec^M[Building BooPHF] 42.; salmon index was invoked improperly.; For usage information, try salmon index --help; ````. **To Reproduce**; Steps and data to reproduce the behavior:. `salmon index -t input.fa -i input.index`. Specifically, please provide at least the following information:. * Which version of salmon was used? - 1.10.1; * How was salmon installed (compiled, downloaded executable, through bioconda)? - biconda; * Which reference (e.g. transcriptome) was used? - metagenome; * Which read files were used? ; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Linux- HPC; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. Thanks.; Ugur",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/837:6051,install,installed,6051,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/837,1,['install'],['installed']
Deployability,"elf, I ran 230 samples and 3 seg faulted. Specifically, please provide at least the following information:; * Which version of salmon was used?: 1.9.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?: quay.io docker container; * Which reference (e.g. transcriptome) was used?: A combination of the GRCh38.p13 transcripts and the repeatmasker annotation from UCSC, with the GRCh38.p13 primary assembly as decoys.; * Which read files were used?: Paired forward and reverse reads (trimmed by Trimmomatic); * Which which program options were used?:; - [--libType A, --validateMappings, --seqBias, --gcBias, --recoverOrphans, --writeUnmappedNames, -p 8, --rangeFactorizationBins 4]. **Expected behavior**; A clear and concise description of what you expected to happen. Salmon quant to produce quant.sf file. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-based) v1.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { references/salmon/sel.align.gencode.v39.ucsc.rmsk.salmon.v1.9.0.sidx/ }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR14506785_output_forward_paired.fq.gz }; ### [ mates2 ] => { SRR14506785_output_reverse_paired.fq.gz }; ### [ threads ] => { 8 }; ### [ validateMappings ] => { }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; ### [ recoverOrphans ] => { }; ### [ rangeFactorizationBins ] => { 4 }; ### [ output ] => { SRR14506785.salmon.rmsk.out }; ### [ writeUnmappedNames ] => { }",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/876:1165,UPGRADE,UPGRADE,1165,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/876,1,['UPGRADE'],['UPGRADE']
Deployability,"eline/Softw; are/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.tr; anscripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test2/${ID}; **** Job ends ****; Wed Mar 8 11:53:40 EST 2017; ```. as well as the `gdb` output for it's core dump file:. ```bash; $ gdb core.1629; GNU gdb (GDB) Red Hat Enterprise Linux (7.2-60.el6_4.1); Copyright (C) 2010 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>...; Missing separate debuginfo for the main executable file; Try: yum --disablerepo='*' --enablerepo='*-debug*' install /usr/lib/debug/.build-id/f2/3c99ed06abf17dd0ee1073eac092487ac62314; [New Thread 1629]; [New Thread 1707]; [New Thread 1708]; [New Thread 1709]; Core was generated by `/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/b'.; Program terminated with signal 6, Aborted.; #0 0x00000037e2032625 in ?? (); ""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/core.1629"" is a core file.; Please specify an executable to debug.; (gdb) q; ```. and the SGE info:. ```bash; $ qacct -j 9987283 -t 2; ==============================================================; qname shared.q; hostname compute-060.cm.cluster; group lieber_jaffe; owner lcollado; project NONE; department defaultdepartment; jobname step6-salmon_test2.gsk_phaseII; jobnumber 9987283; taskid 2; account sge; priority 0; qsub_time Wed Mar 8 11:53:12 2017; start_time Wed Mar 8 11:53:16 2017; end_time Wed Mar 8 11:53:40 2017; granted_pe local; slots 1; failed 0; exit_status ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:30818,install,install,30818,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['install'],['install']
Deployability,elp; Exiting.; ```. PBMC 3k shell log:; ```; ~/software/salmon/scripts/v1_10x/run.sh salmon alevin -lISR -b pbmc3k_fastqs/ --gemcode -i ../transcripts_index_salmon/ -p 8 -o alevin_output --tgMap ../hg_transcriptome/tx2gene.tsv. TEMPDIR is /tmp/tmp.WnzMm7GQBO; Running command [salmon alevin -lISR --gemcode -i ../transcripts_index_salmon/ -p 8 -o alevin_output --tgMap ../hg_transcriptome/tx2gene.tsv -1 /tmp/tmp.WnzMm7GQBO/p1.fa -2 /tmp/tmp.WnzMm7GQBO/p2.fa -r pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-002-chunk-000.fastq.gz; pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-002-chunk-000.fastq.gz; pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-002-chunk-000.fastq.gz; pbmc3k_fastqs/read-I1_si-TAAATCGT_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-TAAATCGT_lane-002-chunk-000.fastq.gz]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; Logs will be written to alevin_output/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ gemcode ] => { }; ### [ index ] => { ../transcripts_index_salmon/ }; ### [ threads ] => { 8 }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { ../hg_transcriptome/tx2gene.tsv }; ### [ mates1 ] => { /tmp/tmp.WnzMm7GQBO/p1.fa }; ### [ mates2 ] => { /tmp/tmp.WnzMm7GQBO/p2.fa }; ### [ unmatedReads ] => { pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-001-chunk-001.fastq.gz pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-002-chunk-000.fastq.gz pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-001-chunk-001.fastq.gz pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-002-chunk-000.fastq.gz pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-001-chunk-001.fastq.gz pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-002-chunk-000.fastq.gz pbmc3k_fastqs/read-I1_si-TA,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:9843,upgrade,upgrade,9843,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['upgrade'],['upgrade']
Deployability,"en attempting to build an index under Ubuntu 18.04 LTS; **To Reproduce**; Steps and data to reproduce the behavior:; ```; root@firefly:/usr/local/src/salmon# salmon-1.1.0_linux_x86_6/bin/salmon index -k 31 -i index -t sample_data/transcripts.fasta; Version Info: This is the most recent version of salmon.; [2020-04-07 21:11:41.237] [jLog] [info] building index; out : index; [2020-04-07 21:11:41.240] [puff::index::jointLog] [info] Running fixFasta. [Step 1 of 4] : counting k-mers; Illegal instruction (core dumped). root@firefly:/usr/local/src/salmon# salmon-0.14.1_linux_x86_64/bin/salmon index -k 31 -i index -t sample_data/transcripts.fasta; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with bug fixes is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ###; [2020-04-07 21:12:14.575] [jLog] [info] building index; [2020-04-07 21:12:14.580] [jointLog] [info] [Step 1 of 4] : counting k-mers; Elapsed time: 0.00677775s. [2020-04-07 21:12:14.596] [jointLog] [info] Replaced 0 non-ATCG nucleotides; [2020-04-07 21:12:14.596] [jointLog] [info] Clipped poly-A tails from 0 transcripts; [2020-04-07 21:12:14.599] [jointLog] [info] Building rank-select dictionary and saving to disk; [2020-04-07 21:12:14.599] [jointLog] [info] done; Elapsed time: 5.7764e-05s; [2020-04-07 21:12:14.606] [jointLog] [info] Writing sequence data to file . . . ; [2020-04-07 21:12:14.607] [jointLog] [info] done; Elapsed time: 0.000590993s; [2020-04-07 21:12:14.614] [jointLog] [info] Building 32-bit suffix array (length of generalized text is 28,577); [2020-04-07 21:12:14.616] [jointLog] [info] Building suffix array . . . ; success; saving to disk . . . done; Elapsed time: 0.000716831s; done; Elapsed t",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500:1229,update,updates,1229,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500,1,['update'],['updates']
Deployability,"ence to `libssh2_session_handshake'; /usr/bin/ld: (.text+0x58d): undefined reference to `libssh2_hostkey_hash'; /usr/bin/ld: (.text+0x6a0): undefined reference to `libssh2_hostkey_hash'; /usr/bin/ld: (.text+0x75d): undefined reference to `libssh2_knownhost_free'; ... So somehow this does not build - but I have the impression that the linker issues are caused by some missing CMAKE options (as well as using the build directory). Thus I used the cmake command line as its used in the Debian packaging:. $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt update; $ apt upgrade; $ apt build-dep salmon; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE; $ make; $ tar xaf sample_data.tgz; # src/salmon index -t sample_data/transcripts.fasta -i sample_salmon_quasi_index; Version Info: This is the most recent version of salmon.; index [""sample_salmon_quasi_index""] did not previously exist . . . creating it; [2023-03-10 11:56:01.434] [jLog] [warning] The salmon index is being built without any decoy sequences. It is recommended that decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be rovided during indexing. Further details can be found at https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indices-mapping-based-mode.; [2023-03-10 11:56:01.435] [jLog] [info] building index; out : sample_salmon_quasi_index; [2023-03-10 11:56:01.435] [puff::index::jointLog] [info] Running fixFasta. [Step 1 of 4] : counting k-mers. [2023-03-10 11:56:01.441] [puff::index::jo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855:3474,Release,Release,3474,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855,1,['Release'],['Release']
Deployability,"ent_ratio"": 1.0,; ""num_compatible_fragments"": 8925446,; ""num_assigned_fragments"": 8925446,; ""num_frags_with_concordant_consistent_mappings"": 2169449,; ""num_frags_with_inconsistent_or_orphan_mappings"": 10821303,; ""strand_mapping_bias"": 0.5001592570279366,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 1084379,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 1085070,; ""SF"": 5409839,; ""SR"": 5411464,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }. ```. Another log file in the folder of logs:; ```{shell}; $cat salmon_quant.log ; [2023-03-07 06:47:10.266] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-03-07 06:47:10.266] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2023-03-07 06:47:10.266] [jointLog] [info] parsing read library format; [2023-03-07 06:47:10.266] [jointLog] [info] There is 1 library.; [2023-03-07 06:47:10.412] [jointLog] [info] Loading Quasi index; [2023-03-07 06:47:10.412] [jointLog] [info] Loading 64-bit quasi index; [2023-03-07 06:51:59.707] [jointLog] [info] done; [2023-03-07 06:51:59.707] [jointLog] [info] Index contained 777288 targets; [2023-03-07 06:52:10.338] [jointLog] [info] Automatically detected most likely library type as IU; [2023-03-07 06:54:46.142] [fileLog] [info] ; At end of round 0; ==================; Observed 40535435 total fragments (40535435 in most recent round). [2023-03-07 06:54:46.141] [jointLog] [info] Computed 1249282 rich equivalence classes for further processing; [2023-03-07 06:54:46.141] [jointLog] [info] Counted 8925446 total reads in th",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/838:2066,release,release,2066,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/838,1,['release'],['release']
Deployability,"environment used to build the project. We hope that in most cases it will not require significant changes to achieve a successful analysis. Check [this page](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#editing-a-code-scanning-workflow) for detailed documentation on how to configure a CodeQL workflow. Questions? Check out the FAQ below!. ### FAQ; <details>; <summary>Click here to expand the FAQ section</summary>. #### How often will the code scanning analysis run?; By default, code scanning will trigger a scan with the CodeQL engine on the following events:; * On every pull request — to flag up potential security problems for you to investigate before merging a PR.; * On every push to your default branch and other protected branches — this keeps the analysis results on your repository’s *Security* tab up to date.; * Once a week at a fixed time — to make sure you benefit from the latest updated security analysis even when no code was committed or PRs were opened. #### What will this cost?; Nothing! The CodeQL engine will run inside GitHub Actions, making use of your [unlimited free compute minutes for public repositories](https://docs.github.com/en/actions/learn-github-actions/usage-limits-billing-and-administration#about-billing-for-github-actions). #### What types of problems does CodeQL find?; The CodeQL engine that powers GitHub code scanning is the exact same engine that powers LGTM.com. The exact set of rules has been tweaked slightly, but you should see almost exactly the same types of alerts as you were used to on LGTM.com: we’ve enabled the [`security-and-quality` query suite](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs) for you. #### How do I upgrade my CodeQL engine?; No need! New versions of the CodeQL analysis are constantly deploy",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/815:2284,update,updated,2284,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/815,1,['update'],['updated']
Deployability,er cannot create executables; See `config.log' for more details. ## ---------------- ##; ## Cache variables. ##; ## ---------------- ##. ac_cv_build=arm-apple-darwin22.6.0; ac_cv_env_CCASFLAGS_set=; ac_cv_env_CCASFLAGS_value=; ac_cv_env_CCAS_set=; ac_cv_env_CCAS_value=; ac_cv_env_CC_set=set; ac_cv_env_CC_value=/Library/Developer/CommandLineTools/usr/bin/cc; ac_cv_env_CFLAGS_set=set; ac_cv_env_CFLAGS_value=; ac_cv_env_CPPFLAGS_set=set; ac_cv_env_CPPFLAGS_value=; ac_cv_env_CPP_set=; ac_cv_env_CPP_value=; ac_cv_env_LDFLAGS_set=set; ac_cv_env_LDFLAGS_value=; ac_cv_env_LIBS_set=; ac_cv_env_LIBS_value=; ac_cv_env_LT_SYS_LIBRARY_PATH_set=; ac_cv_env_LT_SYS_LIBRARY_PATH_value=; ac_cv_env_build_alias_set=; ac_cv_env_build_alias_value=; ac_cv_env_host_alias_set=; ac_cv_env_host_alias_value=; ac_cv_env_target_alias_set=; ac_cv_env_target_alias_value=; ac_cv_host=arm-apple-darwin22.6.0; ac_cv_path_install='/usr/bin/install -c'; ac_cv_prog_AWK=awk; ac_cv_prog_ac_ct_CC=/Library/Developer/CommandLineTools/usr/bin/cc; ac_cv_prog_make_make_set=yes; am_cv_make_support_nested_variables=yes; gl_cv_posix_shell=/bin/sh. ## ----------------- ##; ## Output variables. ##; ## ----------------- ##. ACLOCAL='${SHELL} /Users/jeremybono/Downloads/salmon-1.10.1/external/xz-5.2.2/build-aux/missing aclocal-1.15'; AMDEPBACKSLASH='\'; AMDEP_FALSE='#'; AMDEP_TRUE=''; AMTAR='$${TAR-tar}'; AM_BACKSLASH='\'; AM_CFLAGS=''; AM_DEFAULT_V='$(AM_DEFAULT_VERBOSITY)'; AM_DEFAULT_VERBOSITY='1'; AM_V='$(V)'; AR=''; AS=''; AUTOCONF='${SHELL} /Users/jeremybono/Downloads/salmon-1.10.1/external/xz-5.2.2/build-aux/missing autoconf'; AUTOHEADER='${SHELL} /Users/jeremybono/Downloads/salmon-1.10.1/external/xz-5.2.2/build-aux/missing autoheader'; AUTOMAKE='${SHELL} /Users/jeremybono/Downloads/salmon-1.10.1/external/xz-5.2.2/build-aux/missing automake-1.15'; AWK='awk'; CC='/Library/Developer/CommandLineTools/usr/bin/cc'; CCAS=''; CCASDEPMODE=''; CCASFLAGS=''; CCDEPMODE=''; CFLAGS=''; CFLAG_VISIBILITY=''; COND_ASM_X86_64_FA,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/912:8820,install,install,8820,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/912,1,['install'],['install']
Deployability,"er, you are right that there is no notion of using the coverage profile in estimation (more on this below)!. > Also, my intuition for these transcripts is not really a coverage ""bias"" . My intuition agrees with yours here completely. First, this isn't really a coverage bias as we use the normal definition of the term. Second, the positional bias modeling in salmon is not on a per-transcript level (since that would be an astronomical number of different parameters to learn, and any procedure would almost certainly overfit). Instead, it groups transcripts into length bins, and learns a distinct coverage bias model per-bin. > It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. These are **great** points! A couple of thoughts. First, you are right that salmon, RSEM, etc. don't use coverage information in the way you describe here. One piece of software you might look into is [Salmon Anomaly Detection](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30381-3.pdf)). This is sort of akin to what you are suggesting, and post-processes salmon output by looking for anomalous coverage profiles. It can both flag ""suspicious"" transcripts, and can also sometimes move reads around to mitigate anomalous coverage. Another tool / metric you might consider is the junction coverage compatibility (paper [here](https://www.life-science-alliance.org/content/2/1/e201800175)). While both of these approaches get at some of the core intuitions you raise in your response, they are both rather ""heavyweight"", and nei",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:2001,pipeline,pipeline,2001,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,1,['pipeline'],['pipeline']
Deployability,"er/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/${ID}. echo ""**** Job ends ****""; date; ```. The log file for the same file (task 3) now shows that there was a problem:. ```; **** Job starts ****; Wed Mar 8 11:37:31 EST 2017; **** JHPCE info ****; User: lcollado; Job id: 9987275; Job name: step6-salmon_test.gsk_phaseII; Hostname: compute-051; Task id:; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and minor bug fixes; please upgrade at your; earliest convenience.; ###; ### salmon (mapping-based) v0.7.2; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/R10003_D19KGACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/R10003_D19KGACXX/logs; [2017-03-08 11:37:32.888] [jointLog] [info] parsing read library format; [2017-03-08 11:37:32.893] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-051/job_scripts/9987275: line 31: 41232 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Softw; are/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/R",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:23149,pipeline,pipeline,23149,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['pipeline'],['pipeline']
Deployability,"erge_files.cc (code 4); make[2]: *** [src/CMakeFiles/salmon_core.dir/merge_files.cc.o] Error 4; ```. This is weird, because the correct `include` directory is shown in the compiler command, and the file is there!. Here's my patch. Any idea what may be wrong with it, or which different approach I could try to get this to work?; I also tried using the `2.1.3.tar.gz` tarball from GitHub, but after adding `autoreconf -i` to the `CONFIGURE_COMMAND`, this leads to the same problem. ``` diff; --- salmon-0.4.2/CMakeLists.txt.orig 2015-06-15 02:31:09.000000000 +0200; +++ salmon-0.4.2/CMakeLists.txt 2015-08-18 21:13:29.684010359 +0200; @@ -357,14 +366,14 @@; message(""==================================================================""); ExternalProject_Add(libjellyfish; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; - URL ftp://ftp.genome.umd.edu/pub/jellyfish/jellyfish-2.1.3.tar.gz; - SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.1.3; + URL https://github.com/gmarcais/Jellyfish/releases/download/v2.2.3/jellyfish-2.2.3.tar.gz; + SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.2.3; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; - CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.1.3/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CXXFLAGS=${JELLYFISH_CXX_FLAGS}; + CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.2.3/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CXXFLAGS=${JELLYFISH_CXX_FLAGS}; BUILD_COMMAND ${MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CXXFLAGS=${JELLYFISH_CXX_FLAGS}; BUILD_IN_SOURCE 1; INSTALL_COMMAND make install && ; - cp config.h <INSTALL_DIR>/include/jellyfish-2.1.3/jellyfish/ &&; + cp config.h <INSTALL_DIR>/include/jellyfish-2.2.3/jellyfish/ &&; cp config.h <INSTALL_DIR>/include/; ). --- salmon-0.4.2/src/CMakeLists.txt.orig 2015-08-18 21:21:14.892734948 +0200; +++ salmon-0.4.2/src/CMakeLists.txt 2015-",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/11:1741,release,releases,1741,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/11,1,['release'],['releases']
Deployability,error Installing: CMake fail line 94; RapMap not found (with workaround),MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/42:6,Install,Installing,6,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/42,1,['Install'],['Installing']
Deployability,error in installation process,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/497:9,install,installation,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/497,1,['install'],['installation']
Deployability,error installing: CMake Error: Problem with archive_write_finish_entry(): Can't restore time,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10:6,install,installing,6,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10,1,['install'],['installing']
Deployability,"es. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossible to do. Our resident experts suspect there's a race condition occurring at the tail end of the job and that all of that extra memory is being allocated before the scheduler can kill it for exceeding the limit. Whatever the case, though, this throws into question some of those numbers that I've been grabbing from the accounting logs --- it's either being misreported, or the memory gobbling is happening so rapidly that it may not, in fact, be being properly recorded. I tested the index anyway. It *appears* to be working just fine. Nothing faulted or crashed when I attempted to quantify some reads against it. [index-qacct-17mer-16gigs.log](https://github.com/COMBINE-lab/salmon/files/4247214/index-qacct-17mer-16gigs.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:1796,UPDATE,UPDATE,1796,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,1,['UPDATE'],['UPDATE']
Deployability,"est/salmon_0.8.2_index_gencode.v25.transcripts/versionInfo.json"", O_RDONLY) = 4; read(4, ""{\n \""indexVersion\"": 2,\n \""ha""..., 8191) = 96; read(4, """", 8191) = 0; close(4) = 0; clock_gettime(CLOCK_REALTIME, {1491424830, 69887706}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/header.json"", O_RDONLY) = 4; read(4, ""{\n \""value0\"": {\n \""Index""..., 8191) = 357; read(4, """", 8191) = 0; close(4) = 0; clock_gettime(CLOCK_REALTIME, {1491424830, 139950818}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/header.json"", O_RDONLY) = 4; read(4, ""{\n \""value0\"": {\n \""Index""..., 8191) = 357; read(4, """", 8191) = 0; close(4) = 0; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffe7e5e8000; mprotect(0x7ffe7e5e8000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffebe5e7ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffebe5e89d0, tls=0x7ffebe5e8700, child_tidptr=0x7ffebe5e89d0) = 14677; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/sa.bin"", O_RDONLY) = 4; clock_gettime(CLOCK_REALTIME, {1491424830, 149197282}) = 0; read(4, ""l\n\221\21\0\0\0\0k\n\221\21\373\25\343\20\17\254\r\1\36\27\227\n\37\371\270\4\250\210\307\f""..., 8191) = 8191; mmap(NULL, 1342177280, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7ffe2e5e8000; munmap(0x7ffe2e5e8000, 1342177280) = 0; mmap(NULL, 1344270336, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7ffe2e3e9000; munmap(0x7ffe2e3e9000, 94208) = 0; munmap(0x7ffe7e400000, 1998848) = 0; [1m[2017-04-05 16:40:30.149] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-04-05 16:40:30.069] [jointLog] [info] Loading Quasi index; [00m[1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:166583,pipeline,pipeline,166583,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"esting. $ docker run -it debian:testing. $ apt-get update. $ apt-get install build-essential git libboost-all-dev liblzma-dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev. $ git clone https://github.com/COMBINE-lab/salmon.git; $ cd salmon; $ mkdir build && cd build; $ cmake -DNO_IPO=TRUE .. # GCC still doesn't handle LTO robustly; $ make -j8; $ make install; $ make test; ```. which leads to the output. ```; root@fd877e359439:/salmon/build# make install; [ 7%] Built target libcereal; [ 13%] Built target libtbb; [ 16%] Built target ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Ins",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1306,Install,Install,1306,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,4,"['Install', 'Release', 'configurat']","['Install', 'Installing', 'Release', 'configuration']"
Deployability,"et ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test tim",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1965,Install,Installing,1965,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Install'],['Installing']
Deployability,"eurat Object with information of sample tags obtained from R2 but I could not achieve this. ### **Background**; This is mice data comprised of 2 sequences: R1 contains CB (27bp divided in three sections of 9bp) and UMI, while R2 contains sample tag information and the transcript info as well. I need to differentiate not only the CB, but also the sampletags present in R2 since there are 5 different samples per cartridge. As stated in page 30 of the [BD Library Preparation Protocol](https://www.bdbiosciences.com/content/dam/bdb/marketing-documents/resources-pdf-folder/Protocol-EnhBead-+-Targeted+-AbSeq-+-ST-ruo.pdf), each sampletag is 70bp long (sampletag + abseq). . I have followed the [BD Single-Cell Multiomics Bioinformatics Handbook](https://scomix.bd.com/hc/article_attachments/9315606097549/23-21713_03__BD_Single-Cell_Multiomics_Bioinformatics_Handbook_EN.pdf), in which page 20 states: . > To account for every Sample Tag, each Sample Tag sequence in the kit is considered during pipeline analysis, whether the Sample Tags are used in the experiment or specified with a sample name.; The pipeline automatically adds the Sample Tag sequences to the FASTA reference file. Reads that align to a Sample Tag sequence and associate with a putative cell are used to identify the sample for that cell. ### **What I have tried so far**. 1. Added the sample tag sequences to the end of gentrome file; ```; [user@remote]$ tail -n 80 m.mus_gentrome.fa.gz; >JH584295.1 dna_sm:scaffold scaffold:GRCm39:JH584295.1:1:1976:1 REF; GGCTGAGCGGTGACATCATGGGCGGCGGGGTCCCAGACAGGAAGTGGGCGTGGCCTCCCA; CACTCACCCTGGCCCGCGGCGTCTGCCAGGTCGCTGTCCGAGATGCCGCCTGTggggggg; [...]; >sampletag11G; GTTGTCAAGATGCTACCGTTCAGAGGGTTGGCTCAGAGGCCCCAGGCTGCGGACGTCGTCGGACTCGCGT; >sampletag12G; GTTGTCAAGATGCTACCGTTCAGAGCTGGGTGCCTGGTCGGGTTACGTCGGCCCTCGGGTCGCGAAGGTC; ```. 2. Added the sample tag names to the end of decoy file; ```; [user@remote]$ tail -n 15 m.musculus_decoys.txt; GL456368.1; MU069434.1; JH584295.1; sampletag1G; sam",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/850:1146,pipeline,pipeline,1146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/850,1,['pipeline'],['pipeline']
Deployability,"evin-default-eduardo.zip). Specifically, please provide at least the following information:. * Which version of salmon was used? ; Salmon 0.10.2; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Installed with bioconda; * Which reference (e.g. transcriptome) was used? ; This transcriptome: https://drive.google.com/open?id=1XcsFUxJM6XaYEKh9BYdUoAyJSlWJLIiW. ; It's a mouse transcriptome with 3 additional transcripts at the end; * Which read files were used?; * Which which program options were used?; `salmon alevin -lISR -1 ./H2_S5_L003_R1_001.fastq.gz -2 H2_S5_L003_R2_001.fastq.gz --chromium -i salmon_index -p 8 -o alevin_output --tgMap txp2gene.tsv`. **Desktop (please complete the following information):**; - OS: CentOS; - Version:; Linux login1 3.10.0-514.2.2.el7.x86_64 #1 SMP Tue Dec 6 23:06:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux; LSB Version: :core-4.1-amd64:core-4.1-noarch; Distributor ID: CentOS; Description: CentOS Linux release 7.3.1611 (Core); Release: 7.3.1611; Codename: Core. **Additional context**; ```; Version Info: This is the most recent version of Salmon.; Logs will be written to alevin_output/logs; ### salmon (single-cell-based) v0.10.2; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { ./H2_S5_L003_R1_001.fastq.gz }; ### [ mates2 ] => { H2_S5_L003_R2_001.fastq.gz }; ### [ chromium ] => { }; ### [ index ] => { salmon_index }; ### [ threads ] => { 8 }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { txp2gene.tsv }. [2018-06-12 21:01:31.327] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-06-12 21:01:31.330] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 141 Million barcodes. [2018-06-12 21:08:38.126] [alevinLog] [info] Done barcode density calculation.; [2018-06-12 21:08:38.126] [alevinLog] [info] # Barcodes Used: 140111660 / 141062078.; [2018-06-12 21:08:42.014] [ale",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/237:1404,Release,Release,1404,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/237,1,['Release'],['Release']
Deployability,"experts tell me that you just need to be darned sure that conda-forge is a high priority channel, above bioconda, as [per instructions](https://bioconda.github.io/user/install.html#set-up-channels); that specifying multiple channels with `-c` explicitly is poor practice because it's so error prone; and that if I'm teaching people that, I'm a bad teacher. :). I'll look at the salmon documentation to make sure it's accurately represented there and then close this issue.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/480#issuecomment-579842099:168,install,install,168,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/480#issuecomment-579842099,1,['install'],['install']
Deployability,"f 2 sequences: R1 contains CB (27bp divided in three sections of 9bp) and UMI, while R2 contains sample tag information and the transcript info as well. I need to differentiate not only the CB, but also the sampletags present in R2 since there are 5 different samples per cartridge. As stated in page 30 of the [BD Library Preparation Protocol](https://www.bdbiosciences.com/content/dam/bdb/marketing-documents/resources-pdf-folder/Protocol-EnhBead-+-Targeted+-AbSeq-+-ST-ruo.pdf), each sampletag is 70bp long (sampletag + abseq). . I have followed the [BD Single-Cell Multiomics Bioinformatics Handbook](https://scomix.bd.com/hc/article_attachments/9315606097549/23-21713_03__BD_Single-Cell_Multiomics_Bioinformatics_Handbook_EN.pdf), in which page 20 states: . > To account for every Sample Tag, each Sample Tag sequence in the kit is considered during pipeline analysis, whether the Sample Tags are used in the experiment or specified with a sample name.; The pipeline automatically adds the Sample Tag sequences to the FASTA reference file. Reads that align to a Sample Tag sequence and associate with a putative cell are used to identify the sample for that cell. ### **What I have tried so far**. 1. Added the sample tag sequences to the end of gentrome file; ```; [user@remote]$ tail -n 80 m.mus_gentrome.fa.gz; >JH584295.1 dna_sm:scaffold scaffold:GRCm39:JH584295.1:1:1976:1 REF; GGCTGAGCGGTGACATCATGGGCGGCGGGGTCCCAGACAGGAAGTGGGCGTGGCCTCCCA; CACTCACCCTGGCCCGCGGCGTCTGCCAGGTCGCTGTCCGAGATGCCGCCTGTggggggg; [...]; >sampletag11G; GTTGTCAAGATGCTACCGTTCAGAGGGTTGGCTCAGAGGCCCCAGGCTGCGGACGTCGTCGGACTCGCGT; >sampletag12G; GTTGTCAAGATGCTACCGTTCAGAGCTGGGTGCCTGGTCGGGTTACGTCGGCCCTCGGGTCGCGAAGGTC; ```. 2. Added the sample tag names to the end of decoy file; ```; [user@remote]$ tail -n 15 m.musculus_decoys.txt; GL456368.1; MU069434.1; JH584295.1; sampletag1G; sampletag2G; [...]; sampletag12G; ```. 3. Created the index; ```; salmon index -t m.mus_gentrome.fa.gz -d m.musculus_decoys.txt -p 12 -i m.mus_s",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/850:1254,pipeline,pipeline,1254,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/850,1,['pipeline'],['pipeline']
Deployability,"f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../..",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:8469,pipeline,pipeline,8469,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,fail to update salmon1.4.0 by conda,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/604:8,update,update,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/604,1,['update'],['update']
Deployability,failed to upgrade salmon with conda,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/483:10,upgrade,upgrade,10,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/483,1,['upgrade'],['upgrade']
Deployability,"fe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOEN",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:9037,pipeline,pipeline,9037,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"fffbfb5e000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/librt.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0 \""\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=50288, ...}) = 0; mmap(NULL, 2132936, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf748000; mprotect(0x7fffbf74f000, 2097152, PROT_NONE) = 0; mmap(0x7fffbf94f000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x7000) = 0x7fffbf94f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libm.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0`>\0\0\0\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0644, st_size=611736, ...}) = 0; mmap(NULL, 2629816, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf4c5000; mprotect(0x7fffbf547000, 2093056, PROT_NONE) = 0; mmap(0x7fffbf746000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x81000) = 0x7fffbf746000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libgcc_s.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0P\36\0\0\0\0\0\0""..., 832) = 832; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbf4c4000; fstat(3, {st_mode=S_IFREG|0644, st_size=56072, ...}) = 0; mmap(NULL, 2151784, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf2b6000; mprotect(0x7fffbf2c3000, 2097152, PROT_NONE) = 0; mmap(0x7fffbf4c3000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0xd000) = 0x7fffbf4c3000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/lib",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:19535,pipeline,pipeline,19535,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory);",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:7855,pipeline,pipeline,7855,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"file as input corresponding to the stringtie gtf file.; **To Reproduce**; Steps and data to reproduce the behavior:; Trasncript fasta file corres[onding to the stringtie generated gtf file used for salmon indexing with the following command.; `salmon index -t stringtie.fasta -i annotation_merged_index -p 20 -k 31`; THe index output used for salmon quantification with the following command; `salmon quant -i matchedtranscript_index/ -l ISR -1 ../../12_1_trimmed_R1.fastq -2 ../../12_1_trimmed_R2.fastq --gcBias --seqBias --posBias --dumpEqWeights -o salmon_output_rerun --writeMappings=salmon_output_rerun/mapping.sam -p 20`. Actual transcript IDs; ```; transcript	gene; 1 MSTRG.1.1	MSTRG.1; 2 MSTRG.1.2	MSTRG.1; 3 MSTRG.1.3	MSTRG.1; 4	BGIOSGA002578-TA	MSTRG.1; 5 MSTRG.1.5	MSTRG.1; 6 MSTRG.1.6	MSTRG.1; ```; Output quant.sf file:; ```; transcript count TPM; 1 BGIOSGA002568-TA 5692.000 5.840431; 2 MSTRG.3 1165.181 0.825116; 3 MSTRG.3 15240.169 10.700565; 4 MSTRG.3 5233.400 3.656954; 5 MSTRG.3 34.780 0.027226; 6 MSTRG.3 5219.345 3.916051; 7 MSTRG.3 4.277 0.003473; ```; Rscript used to read the quant.sf file. ```; library(dplyr); tmp <- read.delim(""quant.sf"", header = TRUE, as.is = TRUE); idx <- grep(""^STRG\\.|^CHS\\."", tmp$Name, invert = TRUE); tmp$Name[idx] <- gsub(""\\.[0-9]+$"", """", tmp$Name[idx]); tmp %>% dplyr::rename(transcript = Name, count = NumReads) %>%; dplyr::select(transcript, count, TPM); ```. Specifically, please provide at least the following information:. * Which version of salmon was used?; v0.14.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; bioconda; * Which reference (e.g. transcriptome) was used?; transcriptome; * Which read files were used?; paired-end illumina read files. **Expected behavior**; A clear and concise description of what you expected to happen.; Expected to retrieve the full name of transcript IDs. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; Cluster with centOS",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/427:1755,install,installed,1755,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/427,1,['install'],['installed']
Deployability,"files were extracted from the SRA experiment with [fastq-dump](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=toolkit_doc&f=fastq-dump).; - Reads were aligned with STAR to the index and `unsorted` alignments to the transcriptome were returned (this keeps the paired-ends next to each other). I noticed that the cDNA FASTA files from ensembl include the transcript version, e.g. `ENSMUST00000178537.1` in the FASTA header. The GTF file specifies the transcript id and its version in different fields. Therefore, the STAR index does not include the version suffix. Instead, only the transcript ids are listed, e.g. `ENSMUST00000178537`. To provide a FASTA file with transcript identifiers that match those in STAR's BAM file, I pre-processed Ensembl's FASTA file with the following command:. ```; wget ftp://ftp.ensembl.org/pub/release-86/fasta/mus_musculus/cdna/Mus_musculus.GRCm38.cdna.all.fa.gz; gunzip Mus_musculus.GRCm38.cdna.all.fa.gz; cut -f1 -d ""."" Mus_musculus.GRCm38.cdna.all.fa > transcripts_unversioned.fa. head transcripts_unversioned.fa; >ENSMUST00000178537; GGGACAGGGGGC; >ENSMUST00000178862; GGGACTGGGGGGGC; >ENSMUST00000196221; ATGGCATAT; >ENSMUST00000179664; ATGGCATATCA; >ENSMUST00000177564; ATCGGAGGGATACGAG; [truncated]; ```. Then I try to run `salmon`:. ```; wget ftp://ftp.ensembl.org/pub/release-86/gtf/mus_musculus/Mus_musculus.GRCm38.86.gtf.gz; gunzip Mus_musculus.GRCm38.86.gtf.gz; salmon quant -t transcripts_unversioned.fa -g Mus_musculus.GRCm38.86.gtf -l IU -p 1 -o quantitation -a subsample.bam --seqBias --gcBias; ```. but get the segmentation fault. Omitting the `--seqBias --gcBias` options makes it work. Perhaps you can already spot where I am doing something wrong? If not, you can find the subsample.bam file [here](https://drive.google.com/open?id=0BzX9viKJksNtak0xako0VXptLW8). (The other files are publically available, as shown above.). Does that help? Please let me know if there is anything I can do to help you understand this better.; Best,; Thomas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261744459:2374,release,release-,2374,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261744459,1,['release'],['release-']
Deployability,"fo] Clipped poly-A tails from 0 transcripts; [2020-04-07 21:12:14.599] [jointLog] [info] Building rank-select dictionary and saving to disk; [2020-04-07 21:12:14.599] [jointLog] [info] done; Elapsed time: 5.7764e-05s; [2020-04-07 21:12:14.606] [jointLog] [info] Writing sequence data to file . . . ; [2020-04-07 21:12:14.607] [jointLog] [info] done; Elapsed time: 0.000590993s; [2020-04-07 21:12:14.614] [jointLog] [info] Building 32-bit suffix array (length of generalized text is 28,577); [2020-04-07 21:12:14.616] [jointLog] [info] Building suffix array . . . ; success; saving to disk . . . done; Elapsed time: 0.000716831s; done; Elapsed time: 0.0107059s; ```; Specifically, please provide at least the following information:. * Which version of salmon was used? 1.1.0, 1.0.0 and 0.14.1; * How was salmon installed (compiled, downloaded executable, through bioconda)? GitHub binary; * Which reference (e.g. transcriptome) was used? sample data from GitHub release; * Which read files were used? none; * Which which program options were used? -k 31 -i index -t sample_data/transcripts.fasta. **Expected behavior**; A clear and concise description of what you expected to happen.; I expected salmon 1.1.0 to run without a core-dump and produce similar results to 0.14.1. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Ubuntu 18.04.4 LTS; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; Linux firefly 5.3.0-40-generic #32~18.04.1-Ubuntu SMP Mon Feb 3 14:05:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. **Additional context**; Using ""bcbio-nextgen"", with ""salmon 1.1.0"" installed by Anaconda: Removed this version because of core-dumps and installed the binary releases of ""salmon"" 1.1.0 then 0.41.1 from GitHub in /usr/local. Did stand-alone tests with sample data from the GitHub bin",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500:2522,release,release,2522,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500,1,['release'],['release']
Deployability,"fo] writing output ; ```; And the quality control report by `fastp` ; [fastp_report.pdf](https://github.com/COMBINE-lab/salmon/files/10999908/fastp_report.pdf). The log of `bowtie2`:; ```{shell}; $cat bowtie2.log ; 40535435 reads; of these:; 40535435 (100.00%) were paired; of these:; 38666766 (95.39%) aligned concordantly 0 times; 313581 (0.77%) aligned concordantly exactly 1 time; 1555088 (3.84%) aligned concordantly >1 times; ----; 38666766 pairs aligned concordantly 0 times; of these:; 808295 (2.09%) aligned discordantly 1 time; ----; 37858471 pairs aligned 0 times concordantly or discordantly; of these:; 75716942 mates make up the pairs; of these:; 11008379 (14.54%) aligned 0 times; 9748641 (12.88%) aligned exactly 1 time; 54959922 (72.59%) aligned >1 times; 86.42% overall alignment rate; ```. The output of Single-End reads(just read1):; ```{shell}; salmon quant -i assembly_index -l A -r 9998_1.fastq.gz --meta -p 100 -o 9998.quant_se2; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with bug fixes is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ###; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { assembly_index }; ### [ libType ] => { A }; ### [ unmatedReads ] => { 9998_1.fastq.gz }; ### [ meta ] => { }; ### [ threads ] => { 100 }; ### [ output ] => { 9998.quant_se2 }; Logs will be written to 9998.quant_se2/logs; [2023-03-17 07:40:15.733] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-03-17 07:40:15.733] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/838:5909,UPGRADE,UPGRADE,5909,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/838,1,['UPGRADE'],['UPGRADE']
Deployability,forge instead of bzip.org; -----------------------------------------------------------; ERROR:; libtool: compile: /usr/bin/cc -DHAVE_CONFIG_H -I. -I.. -I.. -MT libstaden_read_la-compression.lo -MD -MP -MF .deps/libstaden_read_la-compression.Tpo -c compression.c -o libstaden_read_la-compression.o; compression.c:77:10: fatal error: zlib.h: No such file or directory; #include <zlib.h>; ^~~~~~~~; compilation terminated.; Makefile:663: recipe for target 'libstaden_read_la-compression.lo' failed; make[5]: *** [libstaden_read_la-compression.lo] Error 1; Makefile:734: recipe for target 'all-recursive' failed; make[4]: *** [all-recursive] Error 1; Makefile:478: recipe for target 'all' failed; make[3]: *** [all] Error 2; CMakeFiles/libstadenio.dir/build.make:111: recipe for target 'libstadenio-prefix/src/libstadenio-stamp/libstadenio-build' failed; make[2]: *** [libstadenio-prefix/src/libstadenio-stamp/libstadenio-build] Error 2; CMakeFiles/Makefile2:257: recipe for target 'CMakeFiles/libstadenio.dir/all' failed; make[1]: *** [CMakeFiles/libstadenio.dir/all] Error 2; Makefile:162: recipe for target 'all' failed; make: *** [all] Error 2; RESOLUTION:; sudo apt install zlib1g-dev; --------------------------------------------------------; ERROR:; libtool: compile: /usr/bin/cc -DHAVE_CONFIG_H -I. -I.. -I.. -MT libstaden_read_la-cram_io.lo -MD -MP -MF .deps/libstaden_read_la-cram_io.Tpo -c cram_io.c -o libstaden_read_la-cram_io.o; cram_io.c:63:10: fatal error: bzlib.h: No such file or directory; #include <bzlib.h>; ^~~~~~~~~; compilation terminated.; RESOLUTION:; sudo apt-get install libbz2-dev; ------------------------------------------------------------; ERROR:; libtool: compile: /usr/bin/cc -DHAVE_CONFIG_H -I. -I.. -I.. -MT libstaden_read_la-cram_io.lo -MD -MP -MF .deps/libstaden_read_la-cram_io.Tpo -c cram_io.c -o libstaden_read_la-cram_io.o; cram_io.c:66:10: fatal error: lzma.h: No such file or directory; #include <lzma.h>; RESOLUTION:; sudo apt-get install -y liblzma-dev; ```,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/383:5609,install,install,5609,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/383,3,['install'],['install']
Deployability,"gen3/Eigen/Core:420:0,; from /usr/local/salmon-0.10.2/include/eigen3/Eigen/Dense:1,; from /usr/local/salmon-0.10.2/include/SalmonUtils.hpp:21,; from /usr/local/salmon-0.10.2/include/ReadPair.hpp:7,; from /usr/local/salmon-0.10.2/include/AlignmentGroup.hpp:15,; from /usr/local/salmon-0.10.2/include/AlignmentLibrary.hpp:12,; from /usr/local/salmon-0.10.2/src/SalmonQuantifyAlignments.cpp:39:; /usr/local/salmon-0.10.2/include/eigen3/Eigen/src/Core/AssignEvaluator.h:90:50: warning: enum constant in boolean context [-Wint-in-bool-context]; MaySliceVectorize = bool(MightVectorize) && bool(DstHasDirectAccess); ^~~~~~~~~~~~~~~~~~~~~~~~; At global scope:; cc1plus: warning: unrecognized command line option ‘-Wno-unused-local-typedef’; cc1plus: warning: unrecognized command line option ‘-Wno-unused-local-typedef’; make[2]: *** [src/CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o] Error 1; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; make: *** [all] Error 2; ```. I also tried installing it through bioconda. Apparently, it installs it correctly, but when I try to use Trinity (I'm installing Salmon as a Trinity requirement) this is what happens: . ```; salmon: /opt/conda/conda-bld/salmon_1528409373758/work/salmon-0.10.2/include/eigen3/Eigen/src/Core/util/Memory.h:161: void* Eigen::internal::aligned_malloc(std::size_t): Assertion `(size<16 || (std::size_t(result)%16)==0) && ""System's malloc returned an unaligned pointer. Compile with EIGEN_MALLOC_ALREADY_ALIGNED=0 to fallback to handmade alignd memory allocator.""' failed.; Error, cmd:; salmon --no-version-check quant -i /home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa.out/Trinity.fasta.tmp.salmon.idx -l U -r /home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa.out/single.fa -o salmon_outdir -p 1 --minAssignedFrags 1; died with ret (6) at /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/../../Per",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403:1151,install,installing,1151,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403,1,['install'],['installing']
Deployability,"get 'src/CMakeFiles/salmon.dir/all' failed; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; Makefile:162: recipe for target 'all' failed; make: *** [all] Error 2. Specifically, please provide at least the following information:. * Which version of salmon was used? v1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? compiled; * Which reference (e.g. transcriptome) was used? Encountered compile error, so not to index/quant step yet; * Which read files were used? same as above; * Which which program options were used? same as above. **Expected behavior**; A clear and concise description of what you expected to happen.; I expect to finish ""make"" command without encountering compile error while using debug mode(""-DCMAKE_BUILD_TYPE=Debug"" ). **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; ![image](https://user-images.githubusercontent.com/24876498/103148237-98daa880-4798-11eb-9944-a104c41f75cf.png). **Desktop (please complete the following information):**; - OS: CentOS7; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; ""uname -a""; Linux 3.10.0-1062.18.1.el7.x86_64 #1 SMP Tue Mar 17 23:49:17 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. ""lsb_release -a""; LSB Version:	:core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch; Distributor ID:	CentOS; Description:	CentOS Linux release 7.7.1908 (Core); Release:	7.7.1908; Codename:	Core. **Additional context**; I want to trace the code while running ""salmon index ......"", ""salmon quant ......"" with gdb, but it seems that both the downloaded executable and the compiled ""Release"" mode do not contain debug symbol, so I'd like to compile the code with debug mode (which maybe will enable ""-g"" flag in g++); Thanks for your help in advance.; Best, ; kai2june",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/608:3845,release,release,3845,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/608,3,"['Release', 'release']","['Release', 'release']"
Deployability,"get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir : /usr/local/Caskroom/miniforge/base/etc/conda; conda av metadata url : None; channel URLs : https://conda.anaconda.org/conda-forge/osx-arm64; https://conda.anaconda.org/conda-forge/noarch; package cache : /usr/local/Caskroom/miniforge/base/pkg",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4923,install,install,4923,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['install'],['install']
Deployability,"gned concordantly 0 times; 313581 (0.77%) aligned concordantly exactly 1 time; 1555088 (3.84%) aligned concordantly >1 times; ----; 38666766 pairs aligned concordantly 0 times; of these:; 808295 (2.09%) aligned discordantly 1 time; ----; 37858471 pairs aligned 0 times concordantly or discordantly; of these:; 75716942 mates make up the pairs; of these:; 11008379 (14.54%) aligned 0 times; 9748641 (12.88%) aligned exactly 1 time; 54959922 (72.59%) aligned >1 times; 86.42% overall alignment rate; ```. The output of Single-End reads(just read1):; ```{shell}; salmon quant -i assembly_index -l A -r 9998_1.fastq.gz --meta -p 100 -o 9998.quant_se2; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with bug fixes is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ###; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { assembly_index }; ### [ libType ] => { A }; ### [ unmatedReads ] => { 9998_1.fastq.gz }; ### [ meta ] => { }; ### [ threads ] => { 100 }; ### [ output ] => { 9998.quant_se2 }; Logs will be written to 9998.quant_se2/logs; [2023-03-17 07:40:15.733] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-03-17 07:40:15.733] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/838:6261,update,updates,6261,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/838,1,['update'],['updates']
Deployability,"good suggestion. [https://sites.google.com/site/ummslogos/_/rsrc/1489610858836/home/apple-icon-76x76.png]. Javier E. Irazoqui, PhD; Associate Professor; Department of Microbiology and Physiological Systems; UMass Medical School. 368 Plantation Street; Albert Sherman Center; Room AS8.1053; Worcester, MA 01605. (774) 455-3797; Skype: javierirazoqui. Confidentiality Notice:; This e-mail message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential, proprietary and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender immediately and destroy or permanently delete all copies of the original message. On Feb 12, 2018, at 12:21 PM, Marcel Bargull <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @jirazoqui<https://github.com/jirazoqui> and @pdellorusso<https://github.com/pdellorusso>,; beware that if you install via a .tar.gz file, you make conda ignore all dependencies. It's somewhat equivalent to conda install --no-deps ... and thus I wouldn't recommend doing something like that.; Until we fix the dependencies in Bioconda, can you, if possible, use a separate Conda environment for salmon with conda create -c bioconda -c conda-forge --name salmon salmon. In this new environment you wouldn't have any dependency version conflict. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996006>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AiohHe_b7YX4kqzddLHJT7ZK6s1PhJgoks5tUHM1gaJpZM4SAonB>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996252:988,install,install,988,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996252,2,['install'],['install']
Deployability,"gs. [2021-04-16 16:57:15.493] [jointLog] [info] Mapping rate = 0.0417748%. [2021-04-16 16:57:15.493] [jointLog] [info] finished quantifyLibrary(); [2021-04-16 16:57:15.535] [jointLog] [info] Starting optimizer; [2021-04-16 16:57:15.564] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2021-04-16 16:57:15.568] [jointLog] [info] iteration = 0 | max rel diff. = 6.66952; [2021-04-16 16:57:16.080] [jointLog] [info] iteration = 100 | max rel diff. = 0.0161125; [2021-04-16 16:57:16.555] [jointLog] [info] iteration = 194 | max rel diff. = 0.000157223; [2021-04-16 16:57:16.558] [jointLog] [info] Finished optimizer; [2021-04-16 16:57:16.558] [jointLog] [info] writing output. [2021-04-16 16:57:16.681] [jointLog] [info] Computing gene-level abundance estimates; [2021-04-16 16:57:16.775] [jointLog] [info] There were 77689 transcripts mapping to 26673 genes; [2021-04-16 16:57:16.775] [jointLog] [info] NOTE: We recommend using tximport (https://bioconductor.org/packages/release/bioc/html/tximport.html) for aggregating transcript-level salmon abundance estimates to the gene level. It is more versatile, exposes more features, and allows considering multi-sample information during aggregation.; [2021-04-16 16:57:16.911] [jointLog] [info] Aggregating expressions to gene level; [2021-04-16 16:57:17.077] [jointLog] [info] done; [2021-04-16 16:57:17.088] [jointLog] [warning] NOTE: Read Lib [[ Trim/1-2-intestines-LDC4673.filtered.R1.fq.gz, Trim/1-2-intestines-LDC4673.filtered.R2.fq.gz]] :. Detected a *potential* strand bias > 1% in an unstranded protocol check the file: Salmon_out/1-2-intestines-LDC4673/lib_format_counts.json for details; ```. However，when I try old version (0.9.1) or latest version (1.4.0), I got a normal mapping rate (77.1074%):. ```; [2021-04-20 10:08:58.047] [jointLog] [info] setting maxHashResizeThreads to 10; [2021-04-20 10:08:58.048] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [20",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/652:3446,release,release,3446,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/652,1,['release'],['release']
Deployability,"gth less than equal to the k-mer length of 28 (perhaps after poly-A clipping). # [omissis]. [2021-12-24 17:32:57.019] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000178811.1], had length less than equal to the k-mer length of 28 (perhaps after poly-A clipping). [2021-12-24 17:32:57.126] [puff::index::jointLog] [warning] Removed 2279 transcripts that were sequence duplicates of indexed transcripts.; [2021-12-24 17:32:57.126] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2021-12-24 17:32:57.126] [puff::index::jointLog] [critical] The decoy file contained the names of 52 decoy sequences, but 0 were matched by sequences in the reference file provided. To prevent unintentional errors downstream, please ensure that the decoy file exactly matches with the fasta file that is being indexed.; [2021-12-24 17:32:57.224] [puff::index::jointLog] [error] The fixFasta phase failed with exit code 1; ```. **Expected behavior**; I followed the instructions, I don't think I should be getting this error?; I don't understand why I have only 52 decoys (basically the whole genome), and why zero were matched in the reference file provided. . If I look in `gentrome.fa` I do find the decoys; ```; zgrep ""chr8"" /no_backup/indexes/salmon/mm10/gentrome.fa ; >chr8; ```; I do not want to retain duplicated transcripts so the `--keepDuplicates` flag is something I would want to avoid. **Desktop (please complete the following information):**. ```; uname -a; Linux ant-login6.linux.crg.es 3.10.0-514.16.1.el7.x86_64 #1 SMP Wed Apr 12 07:10:20 CDT 2017 x86_64 x86_64 x86_64 GNU/Linux; ```; ```; lsb_release -a; LSB Version:	:core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch; Distributor ID:	Scientific; Description:	Scientific Linux release 7.2 (Nitrogen); Release:	7.2; Codename:	Nitrogen; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731:4857,release,release,4857,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731,2,"['Release', 'release']","['Release', 'release']"
Deployability,"gz; Already downloaded: /Users/Benjamin/Library/Caches/Homebrew/downloads/b27a343a5c5128c674be4986b6c0bb348bc77d521662866976898bd4768fd8bb--salmon-1.3.0.tar.gz; ==> Installing salmon from brewsci/bio; ==> cmake .; Last 15 lines from /Users/Benjamin/Library/Logs/Homebrew/salmon/01.cmake:; Build system will fetch and use JEMalloc; ==================================================================; CPACK_SOURCE_IGNORE_FILES = /src/PCA.cpp;/src/PCAUtils.cpp;/build/;/scripts/AggregateToGeneLevel.py;/scripts/ExpressionTools.py;/scripts/GenerateExpressionFiles.sh;/scripts/ParseSoftFile.py;/scripts/PlotCorrelation.py;/scripts/junk;/scripts/sfstrace.log;/scripts/SFPipeline.py;/bin/;/lib/;/sample_data/;PublishREADMEToWebsite.sh;/external/;/src/obsolete/;/include/obsolete/;WebsiteHeader.txt;/experimental_configs/;.git/; CC: /opt/homebrew/Library/Homebrew/shims/mac/super/clang; CC version: ; version: 1.0.0; Building basic pufferfish components for salmon; setting -DHAVE_NUMERIC_LIMITS128; -- Could NOT find PkgConfig (missing: PKG_CONFIG_EXECUTABLE) ; -- Could NOT find Jemalloc (missing: JEMALLOC_LIBRARY JEMALLOC_INCLUDE_DIR) ; NO_IPO = FALSE; TBB_LIBRARIES = /tmp/salmon-20220630-57321-j1f2iv/salmon-1.3.0/external/install/lib/libtbb.dylib;/tmp/salmon-20220630-57321-j1f2iv/salmon-1.3.0/external/install/lib/libtbbmalloc.dylib; -- Configuring incomplete, errors occurred!; See also ""/tmp/salmon-20220630-57321-j1f2iv/salmon-1.3.0/CMakeFiles/CMakeOutput.log"".; See also ""/tmp/salmon-20220630-57321-j1f2iv/salmon-1.3.0/CMakeFiles/CMakeError.log"". Do not report this issue to Homebrew/brew or Homebrew/core!. Benjamin@macbook-pro ~ % salmon ; zsh: exec format error: salmon; Benjamin@macbook-pro ~ % ; ```; I try via bioconda but I got a HTTPerror . and by building from source and I don't understand how to do it from the website . How can I do it on macOS Monterey M1 Max chip ? . thanks a lot for you help in advance . Since it's the v 1.3.0 is it possible to update the brew formula to 1.9.0 ?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/787:1479,install,install,1479,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/787,3,"['install', 'update']","['install', 'update']"
Deployability,"h version of salmon was used?. salmon v0.11.3 on MacBook Pro (15-inch, 2016) macOS Sierra 10.12.6. * How was salmon installed (compiled, downloaded executable, through bioconda)?. bioconda. * Which reference (e.g. transcriptome) was used?. To the best of my knowledge I followed the instructions in the tutorial at:; https://combine-lab.github.io/salmon/getting_started/. This describes where the data come from and how I invoked salmon. * Which read files were used?. See above. * Which which program options were used?. I used the bash script from ; https://combine-lab.github.io/salmon/getting_started/. **Expected behavior**. I expected an output indicating successful quantification. **Screenshots**. I couldn't figure out how to insert a picture, but here is the text from ""terminal"" window.; `(salmon) MacBook-Pro-2:salmon-tutorial brent$ bash quant_tut_samples.sh; Processing sample DRR016125; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.11.3; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { athal_index }; ### [ libType ] => { A }; ### [ mates1 ] => { data/DRR016125/DRR016125_1.fastq.gz }; ### [ mates2 ] => { data/DRR016125/DRR016125_2.fastq.gz }; ### [ threads ] => { 8 }; ### [ output ] => { quants/DRR016125_quant }; Logs will be written to quants/DRR016125_quant/logs; [2018-11-24 15:08:09.785] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-11-24 15:08:09.785] [jointLog] [info] parsing read library format; [2018-11-24 15:08:09.785] [jointLog] [info] There is 1 library.; [2018-11-24 15:08:09.877] [jointLog] [info] Loading Quasi index; [2018-11-24 15:08:09.877] [jointLog] [info] Loading 32-bit quasi index; [2018-11-24 15:08:09.877] [stderrLog] [info] Loading Suffix Array ; [2018-11-24 15:08:10.319] [stderrLog] [info] Loading Transcript Info ; [2018-11-24 15:",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/317:1248,upgrade,upgrades,1248,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/317,1,['upgrade'],['upgrades']
Deployability,"h':; (.text+0x3e1): undefined reference to `libssh2_session_abstract'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-libssh2.o): in function `ssh_statemach_act':; (.text+0x4b1): undefined reference to `libssh2_session_set_blocking'; /usr/bin/ld: (.text+0x4fb): undefined reference to `libssh2_session_handshake'; /usr/bin/ld: (.text+0x58d): undefined reference to `libssh2_hostkey_hash'; /usr/bin/ld: (.text+0x6a0): undefined reference to `libssh2_hostkey_hash'; /usr/bin/ld: (.text+0x75d): undefined reference to `libssh2_knownhost_free'; ... So somehow this does not build - but I have the impression that the linker issues are caused by some missing CMAKE options (as well as using the build directory). Thus I used the cmake command line as its used in the Debian packaging:. $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt update; $ apt upgrade; $ apt build-dep salmon; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE; $ make; $ tar xaf sample_data.tgz; # src/salmon index -t sample_data/transcripts.fasta -i sample_salmon_quasi_index; Version Info: This is the most recent version of salmon.; index [""sample_salmon_quasi_index""] did not previously exist . . . creating it; [2023-03-10 11:56:01.434] [jLog] [warning] The salmon index is being built without any decoy sequences. It is recommended that decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be rovided during indexing. Further details can be found at https://salmon.readthedocs.io/en/latest/salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855:3275,update,update,3275,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855,2,"['update', 'upgrade']","['update', 'upgrade']"
Deployability,"h_sd: 25.001769513739427. Sample: Gam_3h_RT_rep2_RL5404_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_3h_RT_rep3_RL5405_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_37C_rep1_RL5390_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_37C_rep2_RL5391_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_37C_rep3_RL5410_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_4C_rep1_RL5392_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_4C_rep2_RL5393_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_4C_rep3_RL5411_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_RT_rep1_RL5389_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_RT_rep2_RL5408_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_RT_rep3_RL5409_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427```. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; v1.10.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Binary; * Which reference (e.g. transcriptome) was used?; Moss (Physco) v6.1 that I had generated ; * Which read files were used?; ; * Which which program options were used?; `-l A -p 16 --validateMappings --numBootstraps 100 --seqBias --gcBias`. **Expected behavior**; A clear and concise description of what you expected to happen. **Desktop (please complete the following information):**; - OS: Linux server: Rocky Linux release 8.5 (Green Obsidian); - Version Rocky Linux release 8.5 (Green Obsidian)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/948:3023,install,installed,3023,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/948,3,"['install', 'release']","['installed', 'release']"
Deployability,"hared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356\1\3427\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=1926760, ...}) = 0; mmap(0x37e2000000, 3750152, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x37e2000000; mprotect(0x37e218a000, 2097152, PROT_NONE) = 0; mmap(0x37e238a000, 20480, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x18a000) = 0x37e238a000; mmap(0x37e238f000, 18696, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x37e238f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libdl.so.2"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\340\r\300\3417\0\0\0""..., 832) = 832; fstat(3, {st_mode=S",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:97560,pipeline,pipeline,97560,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"hared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356\201\r5\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=1926760, ...}) = 0; mmap(0x350d800000, 3750152, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x350d800000; mprotect(0x350d98a000, 2097152, PROT_NONE) = 0; mmap(0x350db8a000, 20480, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x18a000) = 0x350db8a000; mmap(0x350db8f000, 18696, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x350db8f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libdl.so.2"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\340\r@\r5\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFRE",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:22228,pipeline,pipeline,22228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"heimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID} 2> logs/strace_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. This requests SGE 2 cores with a total free memory of 2 * 7 = 14 GB and a maximum memory of 16 GB. This is the `strace` output for task 1:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory);",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:3886,pipeline,pipeline,3886,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"hello,; i am trying to run salmon on windows subsystem linux.; i installed using conda.; when i tried to run it, i got the following error:; ```; salmon index -t Homo_sapiens.GRCh38.dna.primary_assembly.fa -i hg38_index; salmon: /home/najib/miniconda3/envs/rnaseq_salmon/bin/../lib/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by salmon); salmon: /home/najib/miniconda3/envs/rnaseq_salmon/bin/../lib/libstdc++.so.6: version `GLIBCXX_3.4.22' not found (required by salmon); salmon: /home/najib/miniconda3/envs/rnaseq_salmon/bin/../lib/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /home/najib/miniconda3/envs/rnaseq_salmon/bin/../lib/libtbb.so.2); ```; what is the possible solution?; thank you for your help.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/864:65,install,installed,65,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/864,1,['install'],['installed']
Deployability,"hey @kikegoni ,. I'd strongly advise updating to latest salmon. 0.12.0 is a bit old (released 16 cycles back) there were some bugs which we fixed over time. It'd be great if you can verify the issue persists with the latest release ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/596#issuecomment-737335445:85,release,released,85,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/596#issuecomment-737335445,2,['release'],"['release', 'released']"
Deployability,"hey @pophipi , we have released `v0.11.1` with the fix.; Thanks for reporting this issue. Also, I tried running the `dropseq` mode for Alevin w/ the data you forwarded but it looks like the mapping rate is too low. I am not sure how to interpret the data, but just for sanity `Alevin` mapping rate is ~70% in the original Macosko et. al. paper. We will keep looking for the updates in DropSeq pipeline feel free to reopen this issue or create a new one regarding the low mapping rate if you find out the right location of UMI and CB in the dataset or trouble using #247 .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408565258:23,release,released,23,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408565258,3,"['pipeline', 'release', 'update']","['pipeline', 'released', 'updates']"
Deployability,"hey try the following command, I double checked on 1.5.1 and it seemed to give the 18 length CBs:; ```; sudo ~/salmon-1.5.1_linux_x86_64/bin/salmon alevin -l ISR -i ~/Data/salmon/cell_hash -1 R1.fq.gz -2 R2.fq.gz --read-geometry 2[1-15] --bc-geometry 1[3-8,24-29,45-50] --umi-geometry 1[51-56] -o /home/cndd3/Data/Multi_3/hash_1.5.1/ —keepCBFraction 1 --tgMap <might have to create a tsv file with feature name tab feature name>; ```. If the program is not exiting with error with the command you shared then probably there is some error on the update as it should throw error when you simultaneously provide with `citeseq` and `geometry` flags.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860927005:545,update,update,545,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860927005,1,['update'],['update']
Deployability,"hi @k3yavi,. Thanks for your help! I'm glad it's a quick fix. As for the dataset, I am not sure why the read length is 25bp. The [paper I pulled it from](https://www.ncbi.nlm.nih.gov/pubmed/29545397) stated that they used the standard DropSeq protocol and did not seem to mention and changes in CB and UMI length. In the case that they did change those lengths, what options can I use to set the pipeline?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408179330:396,pipeline,pipeline,396,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408179330,1,['pipeline'],['pipeline']
Deployability,"hi! ; while this has been discussed in detail in #379 , there have been many releases of Alevin since then.; So i am just a bit confused, if i want to generate a quant matrix of all CBs including those in the range of 1-10 reads for use with SoupX, how do i do this in the most streamlined way. As there has been a lot of discussion about this and many release of alevin since then. Will using FreqThreshold 0 --maxNumBarcodes 4294967295 do the trick? or do i also need to use --KeepCBFraction 1.0. or do i need to do as suggested by @alexvpickering in the issue above; ""Run alevin with standard options, then parse raw_cb_frequency.txt for a sample of 1-10UMI CBs and using them as input to --whitelist option for additional run of alevin with --freqThreshold 0 --maxNumBarcodes 4294967295"". Thanks,; Devika",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/538:77,release,releases,77,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/538,2,['release'],"['release', 'releases']"
Deployability,"his-libtype):; ```; grep ""^>"" GRCh38.primary_assembly.genome.fa | cut -d "" "" -f 1 > GRCh38.decoys.txt; sed -i 's/>//g' GRCh38.decoys.txt; cat gencode.v36.transcripts.fa GRCh38.primary_assembly.genome.fa | gzip > GRCh38.gentrome.fa.gz; salmon index -t GRCh38.gentrome.fa.gz -d GRCh38.decoys.txt -p 12 -i salmon_index --gencode; ```; 4. Run salmon ; ```; IDX=""/scratch/scratch/skgtjzw/workspace/middle_aged_microglia/salmon_quantification_SAF/salmon_index/""; for fn in /scratch/scratch/skgtjzw/workspace/middle_aged_microglia/salmon_quantification_SAF/SRR{2557119..2557121}; do; samp=`basename ${fn}`; echo ""Processing sample ${samp}""; salmon quant -i $IDX -l A -1 ${fn}_1.fastq.gz -2 ${fn}_2.fastq.gz -p 8 \; --validateMappings \; -o quants/${samp}_quant \; --gcBias; done; ```. Specifically, please provide at least the following information:. * Which version of salmon was used?; 1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; 1.3.0 salmon was installed by miniconda, then updated to 1.4.0 via miniconda ; * Which reference (e.g. transcriptome) was used?; Gencode_human/release_36/gencode.v36.transcripts.fa.gz; * Which read files were used?; fastq.gz file with 150 paired reads ; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; On a cluster with Ubuntu Linux. **Additional context**; I was running the default method of building index with only the gencode.v36.transcripts.fa.gz, and the mapping rate for my fastq files were 42-55%, which i think is quite low (based on what i read, it is expected to be around 70%). Then, I thought i might give a go with building decoy-aware transcriptome index, and this did not go well as i presented above. . I found an old post with the similar issue, which the conclusion was that t",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603:3485,install,installed,3485,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603,2,"['install', 'update']","['installed', 'updated']"
Deployability,"hmmmm I re-pasted the updated error twice but it still reverts back to original post?. Malformed key:value pair at line 44017: ""**@PG** ID:OSA IsCdna:True ReferenceLibraryID:Human.B37.3_RefGene20121217 VN:7.2""",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387498342:22,update,updated,22,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387498342,1,['update'],['updated']
Deployability,"hodologies for quantification and also help optimize salmon further for QuantSeq. I would still like you to check if you have used salmon quant command line correctly for QuantSeq data analysis. Your paper briefly alludes to QuantSeq Forward in the Introduction section of the paper. The QuantSeq Forward kit has an oligo (dT) primer which contains the Illumina-specific Read 2 linker ... but the Methods section of your paper does not specify if you have used QuantSeq FWD or REV. Page 14 of the PDF from the Lexogen Website data analysis pipeline for QuantSeq FWD<https://www.bluebee.com/wp-content/uploads/2018/11/015UG108V0201-QuantSeq-Data-Analysis-Pipeline_2018-10-18.pdf> recommends using the below htseq command line. htseq-count -m intersection-nonempty -s yes -f bam -r pos $bam; $resource_dir/annotation.gtf > $bam_dir/read_counts.txt. QuantSeq is a stranded protocol. For the QuantSeq FWD pipeline the argument -s yes indicates; stranded in the sense orientation. For the QuantSeq REV pipeline -s reverse is used. Similar to the above htseq command line arguments, I think if you are using QuantSeq FWD, the libType argument from salmon quant should have been SF. One way I checked these with my datasets was to run the salmon quant command 3 times - once with libType A, once with libType SF and once with libType SR -- with QuantSeq FWD the estimated counts will be almost same with libType A and libType SF. I echo what @rob-p<https://github.com/rob-p> says - Congratulations once again on the paper. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/449?email_source=notifications&email_token=AC4A5AGWBAOLTI4MOFLAJNDQYQN7FA5CNFSM4JOIEHZ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEG3S5HQ#issuecomment-565653150>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AC4A5AFB7EMLYHVLVSHVLBDQYQN7FANCNFSM4JOIEHZQ>. Sample S1. meta_info.json. ""salmon_version"":",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565684552:2077,pipeline,pipeline,2077,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565684552,1,['pipeline'],['pipeline']
Deployability,"https://github.com/COMBINE-lab/salmon/issues/602#issuecomment-748729130. Having read this and also wanting to use salmon to quantify transcript abundances from direct RNA data I have been using the pipeline here: https://github.com/nanoporetech/pipeline-transcriptome-de . In this case --noErrorModel is used but not --NoLengthCorrection. The pipeline uses NumReads as the counts in downstream analysis but I was wondering if this estimation of transcript counts also tries to normalize the length bias typical of short-read RNA seq workflows? If not, I think NumReads is OK but if it does this also seems not useable like the default TPM output.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/651:198,pipeline,pipeline,198,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/651,3,['pipeline'],"['pipeline', 'pipeline-transcriptome-de']"
Deployability,"i didn't try to fix the star index, it was created automatically by the; bcbio_nextgen pipeline i was using. i did add my story to the issue in the; star github repo mentioned in the biostars thread:; https://github.com/alexdobin/STAR/issues/1140. On Tue, Aug 2, 2022 at 11:27 AM HeedukOh ***@***.***> wrote:. > i ran into the same problem and apparently it's a STAR issue:; > https://www.biostars.org/p/486346/; >; > ""...it seems STAR is doing something during the indexing step which is; > causing a slight mismatch for 23 of the transcripts.""; >; > Hi,; > Thanks for the reply!; > I see that you used Salmon for indexing to get around this issue. Did you; > figure out a way to make STAR work after that, or did you stick with Salmon?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/785#issuecomment-1202823526>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABGJSQSM6CJ2GDKQF3UOZKLVXE47NANCNFSM5ZOT3OOQ>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/785#issuecomment-1205698238:87,pipeline,pipeline,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/785#issuecomment-1205698238,1,['pipeline'],['pipeline']
Deployability,"ibthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 8 }; ### [ output ] => { pbmc4k/alevin }; ### [ mates1 ] => { /dev/fd/63 }; ### [ mates2 ] => { /dev/fd/62 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ### [ tgMap ] => { tx2gene.txt }. [2018-06-08 13:37:41.409] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [New Thread 0x7ffd795e7700 (LWP 14279)]; [New Thread 0x7ffcf95e6700 (LWP 14280)]; [New Thread 0x7ffc795e5700 (LWP 14281)]; [2018-06-08 13:37:41.419] [alevinLog] [info] Processing barcodes files (if Present",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2943,release,releases,2943,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,2,"['release', 'upgrade']","['releases', 'upgrade']"
Deployability,"ich closely follow the options used in the alevin-fry tutorial. **Expected behavior**; A clear and concise description of what you expected to happen. I expected my reads to be mapped and a RAD file to be generated. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Linux (university cluster); - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; ; Output of `uname -a`:; ```; Linux amc-bodhi 3.10.0-514.21.1.el7.x86_64 #1 SMP Thu May 25 17:04:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux; ```. Output of `lsb_release -a`:; ```; LSB Version:	:core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch; Distributor ID:	CentOS; Description:	CentOS Linux release 7.4.1708 (Core) ; Release:	7.4.1708; Codename:	Core; ```. **Additional context**; Add any other context about the problem here. I have attached subsampled fastq files for one of my samples as an example:; [sub_R1.fastq.gz](https://github.com/COMBINE-lab/salmon/files/7331798/sub_R1.fastq.gz); [sub_R2.fastq.gz](https://github.com/COMBINE-lab/salmon/files/7331799/sub_R2.fastq.gz). This is the error log after attempting to run the map reads step, which indicates an issue with the index build:; [B13_MeOH_cells_Jurkat_Cas9_EGR1_1_stimulated.out.err.txt](https://github.com/COMBINE-lab/salmon/files/7331816/B13_MeOH_cells_Jurkat_Cas9_EGR1_1_stimulated.out.err.txt). This is the error log after building the index, which seems to have run successfully (though maybe I am missing something):; [build_idx.out.err.txt](https://github.com/COMBINE-lab/salmon/files/7331817/build_idx.out.err.txt). This is the versionInfo.json file that is successfully generated after building the index, but that can't be found when mapping",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:6212,Release,Release,6212,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,1,['Release'],['Release']
Deployability,"ich in theory should work unless `salmon` uses variable amounts of memory with the same data. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=10G,h_vmem=11G,h_fsize=100G; #$ -N step6-salmon_test.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test.$TASK_ID.txt; #$ -e ./logs/salmon_test.$TASK_ID.txt; #$ -m a; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/${ID}. echo ""**** Job ends ****""; date; ```. The log file for the same file (task 3) now shows that there was a problem:. ```; **** Job starts ****; Wed Mar 8 11:37:31 EST 2017; **** JHPCE info ****; User: lcollado; Job id: 9987275; Job name: step6-salmon_test.gsk_phaseII; Hostname: compute-051; Task id:; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and minor bug fixes; please upgrade at your; earliest convenience.; ###; ### salmon (mapping-based) v0.7.2; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-p",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:22154,pipeline,pipeline,22154,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['pipeline'],['pipeline']
Deployability,"ich leads to the output. ```; root@fd877e359439:/salmon/build# make install; [ 7%] Built target libcereal; [ 13%] Built target libtbb; [ 16%] Built target ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; S",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1719,Install,Installing,1719,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Install'],['Installing']
Deployability,"ieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipe",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:6901,pipeline,pipeline,6901,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"ieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/${ID}. echo ""**** Job ends ****""; date; ```. The important part is that we are requesting 1 single core with 80 GB of free memory and setting the limit at 90 GB. We are also using the `-p 1` option. . Here is the log file for one of them (task 3):. ```; **** Job starts ****; Mon Mar 6 23:19:13 EST 2017; **** JHPCE info ****; User: lcollado; Job id: 9958683; Job name: step6-txQuant-alzheimer.gsk_phaseII; Hostname: compute-068; Task id: ; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases ; contains new features, improvements, and minor bug fixes; please upgrade at your; earliest convenience.; ###; ### salmon (mapping-based) v0.7.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/R10003_D19KGACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/R10003_D19KGACXX/logs; [1m[2017-03-07 03:00:05.319] [jointLog] [info] parsing read library format; [00m[1m[2017-03-07 03:00:05.337] [jointLog] [info] There is 1 library.; [00m[1m[2017-03-07 03:00:41.948] [jointLog] [info] Loading Qua",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:2392,release,releases,2392,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,2,"['release', 'upgrade']","['releases', 'upgrade']"
Deployability,"ies are, where the include files are, and that boost was found was not sufficient. There must be some other set of symbols which need to be defined. `/opt/rh/devtoolset-4/root/usr/bin/c++ -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -rdynamic CMakeFiles/unitTests.dir/__/tests/UnitTests.cpp.o CMakeFiles/unitTests.dir/FragmentLengthDistribution.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/bit_array.c.o -o unitTests -L/home/mathog/src/salmon/lib -L/home/mathog/src/salmon/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" libsalmon_core.a libalevin_core.a -lgff -lpthread ../external/install/lib/libstaden-read.a -lz ../external/install/lib/libdivsufsort.a ../external/install/lib/libdivsufsort64.a ../external/install/lib/libbwa.a -lm -llzma -lbz2 -ltbb -lgomp -lrt ../external/install/lib/libjemalloc.a -lrt -ldl ../external/install/lib/libjemalloc.a -ldl`. Oh, I also had to update automake and autoconf because the 2 year old versions on this system were not new enough. Is there a static binary version of salmon available for download, Linux 64 bit? It looks like the default links are that way anyway, and that would save me what looks like at least another day of fighting with Cmake to force it to actually build a working make file",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:2790,install,install,2790,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['install'],['install']
Deployability,igure:4569: result: no; configure:4539: checking for mawk; configure:4569: result: no; configure:4539: checking for nawk; configure:4569: result: no; configure:4539: checking for awk; configure:4555: found /usr/bin/awk; configure:4566: result: awk; configure:4577: checking whether make sets $(MAKE); configure:4599: result: yes; configure:4628: checking whether make supports nested variables; configure:4645: result: yes; configure:4771: checking whether ln -s works; configure:4775: result: yes; configure:4795: checking for style of include used by make; configure:4823: result: GNU; configure:4894: checking for gcc; configure:4921: result: /Library/Developer/CommandLineTools/usr/bin/cc; configure:5150: checking for C compiler version; configure:5159: /Library/Developer/CommandLineTools/usr/bin/cc --version >&5; Apple clang version 15.0.0 (clang-1500.0.40.1); Target: arm64-apple-darwin22.6.0; Thread model: posix; InstalledDir: /Library/Developer/CommandLineTools/usr/bin; configure:5170: $? = 0; configure:5159: /Library/Developer/CommandLineTools/usr/bin/cc -v >&5; Apple clang version 15.0.0 (clang-1500.0.40.1); Target: arm64-apple-darwin22.6.0; Thread model: posix; InstalledDir: /Library/Developer/CommandLineTools/usr/bin; configure:5170: $? = 0; configure:5159: /Library/Developer/CommandLineTools/usr/bin/cc -V >&5; clang: error: argument to '-V' is missing (expected 1 value); clang: error: no input files; configure:5170: $? = 1; configure:5159: /Library/Developer/CommandLineTools/usr/bin/cc -qversion >&5; clang: error: unknown argument '-qversion'; did you mean '--version'?; clang: error: no input files; configure:5170: $? = 1; configure:5190: checking whether the C compiler works; configure:5212: /Library/Developer/CommandLineTools/usr/bin/cc conftest.c >&5; ld: library 'System' not found; clang: error: linker command failed with exit code 1 (use -v to see invocation); configure:5216: $? = 1; configure:5254: result: no; configure: failed program was:; | /* confdefs.h ,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/912:5484,Install,InstalledDir,5484,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/912,1,['Install'],['InstalledDir']
Deployability,"ild system will compile libgff; ==================================================================; ==================================================================; Build system will compile Staden IOLib; ==================================================================; Build system will fetch SPDLOG; ==================================================================; -- Found PkgConfig: /apps/gentoo/usr/bin/pkg-config (found version ""0.29.2""); -- Found Jemalloc: /apps/gentoo/usr/lib/libjemalloc.so (found version """"); Found Jemalloc library --- using this memory allocator; CPACK_SOURCE_IGNORE_FILES = /src/PCA.cpp;/src/PCAUtils.cpp;/build/;/scripts/AggregateToGeneLevel.py;/scripts/ExpressionTools.py;/scripts/GenerateExpressionFiles.sh;/scripts/ParseSoftFile.py;/scripts/PlotCorrelation.py;/scripts/junk;/scripts/sfstrace.log;/scripts/SFPipeline.py;/bin/;/lib/;/sample_data/;PublishREADMEToWebsite.sh;/external/;/src/obsolete/;/include/obsolete/;WebsiteHeader.txt;/experimental_configs/;.git/; TBB_LIBRARIES = /apps/gentoo/usr/lib/libtbbmalloc_proxy.so;/apps/gentoo/usr/lib/libtbbmalloc.so;/apps/gentoo/usr/lib/libtbb.so; -- Configuring done; CMake Error at src/CMakeLists.txt:158 (add_executable):; Cannot find source file:. $blah/salmon-0.10.2/external/install/src/rapmap/RapMapFileSystem.cpp. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. CMake Error at src/CMakeLists.txt:160 (add_executable):; Cannot find source file:. $blah/salmon-0.10.2/external/install/src/rapmap/rank9b.cpp. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. CMake Error at src/CMakeLists.txt:158 (add_executable):; No SOURCES given to target: salmon. CMake Error at src/CMakeLists.txt:160 (add_executable):; No SOURCES given to target: unitTests. -- Build files have been written to: $blah/salmon-0.10.2; $blah/salmon-0.10.2 $ make; make: *** No targets specified and no makefile found. Stop.; $blah/salmon-0.10.2 $; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387:5039,install,install,5039,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387,2,['install'],['install']
Deployability,"ile describes the option '-t transcripts.fa' for this purpose:. > ./bin/salmon quant -t transcripts.fa -l <LIBTYPE> -a aln.bam -o salmon_quant. Also the command-line help 'salmon quant --help-alignment' names the same options:. alignment input options:. -l [ --libType ] arg Format string describing the library ; type; -a [ --alignments ] arg input alignment (BAM) file(s).; -t [ --targets ] arg FASTA format file containing target ; transcripts. The 'salmon quant' command doesn't recognize either the short or long form of this option and stops execution immediately. There is no difference if the full set of options for a quantification run are provided or only this option. . **To Reproduce**; salmon quant -t Homo_sapiens.GRCh37.87.cdna.all.fa; salmon quant --targets Homo_sapiens.GRCh37.87.cdna.all.fa. Specifically, please provide at least the following information:. * Which version of salmon was used?; 0.12.0 and 0.11.3; * How was salmon installed (compiled, downloaded executable, through bioconda)?; downloaded executable (salmon-0.12.0_linux_x86_64.tar.gz, salmon-0.11.3-linux_x86_64.tar.gz); * Which reference (e.g. transcriptome) was used?; any, independant of transcriptome; * Which read files were used?; not applicable; * Which which program options were used?; other options than '-t/--targets' were irrelevant for provoking the error . **Expected behavior**; Salmon should run and process the alignment file in BAM format. **Screenshots**; --- Error messages ------------------; Exception : [unrecognised option '-t']. Exiting.; Exception : [unrecognised option '--targets']. Exiting.; --------------------------------------. **Desktop (please complete the following information):**; - OS: Ubuntu Linux; - Version:; Linux nnn 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 16.04.4 LTS; Release:	16.04; Codename:	xenial. **Additional context**; none",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/343:2260,Release,Release,2260,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/343,1,['Release'],['Release']
Deployability,"ile or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:8727,install,install,8727,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,8,"['install', 'pipeline']","['install', 'pipeline']"
Deployability,"ile_url':; open_trace_file.c:(.text+0xec4): warning: the use of `tempnam' is dangerous, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1249,Install,Installing,1249,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installing']
Deployability,"ime — to make sure you benefit from the latest updated security analysis even when no code was committed or PRs were opened. #### What will this cost?; Nothing! The CodeQL engine will run inside GitHub Actions, making use of your [unlimited free compute minutes for public repositories](https://docs.github.com/en/actions/learn-github-actions/usage-limits-billing-and-administration#about-billing-for-github-actions). #### What types of problems does CodeQL find?; The CodeQL engine that powers GitHub code scanning is the exact same engine that powers LGTM.com. The exact set of rules has been tweaked slightly, but you should see almost exactly the same types of alerts as you were used to on LGTM.com: we’ve enabled the [`security-and-quality` query suite](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs) for you. #### How do I upgrade my CodeQL engine?; No need! New versions of the CodeQL analysis are constantly deployed on GitHub.com; your repository will automatically benefit from the most recently released version. #### The analysis doesn’t seem to be working; If you get an error in GitHub Actions that indicates that CodeQL wasn’t able to analyze your code, please [follow the instructions here](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/troubleshooting-the-codeql-workflow) to debug the analysis. #### How do I disable LGTM.com?; If you have LGTM’s automatic pull request analysis enabled, then you can [follow these steps to disable the LGTM pull request analysis](https://lgtm.com/help/lgtm/managing-automated-code-review#disabling-pr-integration). You don’t actually need to remove your repository from LGTM.com; it will automatically be removed in the next few months as part of the deprecation of LGTM.com ([more info here](https://github.blog/2022-08-15-the-next-step-for-lgtm-com",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/815:3192,upgrade,upgrade,3192,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/815,2,"['deploy', 'upgrade']","['deployed', 'upgrade']"
Deployability,"initial_whitelist"": 28000,; ""low_conf_cbs"": 997,; ""num_features"": 5,; ""final_num_cbs"": 19134,; ""deduplicated_umis"": 127624221,; ""mean_umis_per_cell"": 6670,; ""mean_genes_per_cell"": 2229; }. ==> salmon_1.9_OG_2022-Oct-13_S3/aux_info/alevin_meta_info.json <==; {; ""total_reads"": 1657137137,; ""reads_with_N"": 59329,; ""noisy_cb_reads"": 447471964,; ""noisy_umi_reads"": 3629,; ""used_reads"": 1209602215,; ""mapping_rate"": 55.061293216313938,; ""reads_in_eqclasses"": 912441138,; ""total_cbs"": 33411349,; ""used_cbs"": 1567701,; ""initial_whitelist"": 28000,; ""low_conf_cbs"": 997,; ""num_features"": 5,; ""final_num_cbs"": 18395,; ""deduplicated_umis"": 125889439,; ""mean_umis_per_cell"": 6843,; ""mean_genes_per_cell"": 2248; }; ```. **To Reproduce**; Steps and data to reproduce the behavior:; 1. Run `salmon alevin` on more than 2^32 sequenced reads. Specifically, please provide at least the following information:. * Which version of salmon was used? v1.9.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? binary download from github; * Which reference (e.g. transcriptome) was used? Gencode Human v41 + CHM13 v2.0 assembly; * Which read files were used? BD Rhapsody + NovaSeq; * Which which program options were used?. ```; [cell barcodes were pre-corrected and merged using my own [custom script](https://gitlab.com/gringer/bioinfscripts/-/blob/master/synthSquish.pl)]; salmon alevin -l ISR \; -1 $(ls demultiplexed/squished_${machineID}*_R1_001.fastq.gz | sort) \; -2 $(ls demultiplexed/${machineID}*_R2_001.fastq.gz | sort) \; -i ${indexDir}/${indexName} --expectCells ${expectCellCount} \; -p 10 -o salmon_1.9_cbc_${projectID}_combined --tgMap ${indexDir}/txp2gene_${targetName}.txt \; --umi-geometry '1[28-35]' --bc-geometry '1[1-27]' --read-geometry '2[1-end]'; ```. **Expected behavior**; ```; {; ""total_reads"": 4579183639,; ""reads_with_N"": 165542,; ""noisy_cb_reads"": 1240522569,; ""noisy_umi_reads"": 6297,; ""used_reads"": 3338489231,; ""mapping_rate"": 52.32744469106451,; ""reads_in_eq",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/806:2615,install,installed,2615,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/806,1,['install'],['installed']
Deployability,"inting to prefixes in the suffix array (similar to the strategy used by STAR, but using much longer k-mers to improve lookup speed). We referred to this index as the quasi-index. As the software evolved and we continued to improve the mapping methodology, we eventually transitioned over to an index based on [our pufferfish data structure](https://github.com/COMBINE-lab/pufferfish). In addition to the new data structure, this coincided with our move over to selective-alignment as the mapping algorithm, and all of this happened at the 1.0.0 release (this is why, for example, indices built before 1.0.0 are not compatible with salmon > 1.0.0; a topic on which there have been a few GitHub issues). However, given the fact that the documentation and software are linked only through manual human intervention (we haven't leveled up to e.g. having salmon be a [literate program](https://en.wikipedia.org/wiki/Literate_programming) yet), these two sometimes get out of sync. This is an instance of that. We have maintained the functionality of the `--writeMappings` feature, and in fact, even augmented it. However, we have not replaced the antiquated `quasi-index` terminology in the documentation. The TLDR is that you can use `--writeMappings` with the index you built with the `salmon index` command, and it should work fine. If you are mapping against an index without decoy sequences, then the output format will be basically the same as older (pre 1.0.0) versions. If you have decoy sequences in your index, then there is an optional SAM flag with each record that tells you if the mapping is to a target or a decoy. Specifically, `XT:A:T` signifies that the mapping was to a non-decoy target and `XT:A:T` specifies that the mapping was to a sequence marked in the index as a decoy. I hope this diversion into historical leakage into the current documentation answers your question. Thanks for reporting this, and we'll try to address it upstream so it's fixed in the next release. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/727#issuecomment-996192524:2549,release,release,2549,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/727#issuecomment-996192524,1,['release'],['release']
Deployability,"ions.hpp:22,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/pthread/thread_data.hpp:10,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread_only.hpp:17,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread.hpp:12,; from /gpfs/projects/hpc_support/salmon/include/GenomicFeature.hpp:25,; from /gpfs/projects/hpc_support/salmon/src/GenomicFeature.cpp:22:; /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/pthread/thread_data.hpp:60:5: error: missing binary operator before token ""(""; 60 | #if PTHREAD_STACK_MIN > 0; | ^~~~~~~~~~~~~~~~~; In file included from /gpfs/projects/hpc_support/salmon/external/install/include/boost/functional/hash.hpp:6,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/detail/thread.hpp:41,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread_only.hpp:22:; /gpfs/projects/hpc_support/salmon/external/install/include/boost/container_hash/hash.hpp:130:33: warning: ‘template<class _Arg, class _Result> struct std::unary_function’ is deprecated [-Wdeprecated-declarations]; 130 | struct hash_base : std::unary_function<T, std::size_t> {};; | ^~~~~~~~~~~~~~; In file included from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/string:49,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/exceptions.hpp:20:; /gpfs/software/gcc/13.2.0/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here; 117 | struct unary_function; | ^~~~~~~~~~~~~~; make[2]: *** [src/CMakeFiles/salmon_core.dir/build.make:160: src/CMakeFiles/salmon_core.dir/GenomicFeature.cpp.o] Error 1; make[1]: *** [CMakeFiles/Makefile2:568: src/CMakeFiles/salmon_core.dir/all] Error 2; make: *** [Makefile:166: all] Error 2; ```. **To Reproduce**; ```; #!/usr/bin/env bash. module load cmake Bzip2/1.0.8 curl; module load oneTBB/gcc13.2/2021.13.0; module load boost/gcc13.2/1.86.0 . rm -rf CMake*. cma",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/953:2075,install,install,2075,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/953,1,['install'],['install']
Deployability,"iorxiv.org/content/10.1101/657874v2. Some questions on salmon index building with salmon/v1.0 (as I am confused following the documentation at https://salmon.readthedocs.io/en/latest/salmon.html) - let me know if my understanding is correct. 1. Is this how to create SAF indices - https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/ - with these steps, I assume I do not have to separately download mashmap and bedtools software. 2. If one has to use SA method, does one still use the generateDecoyTranscriptome.sh method as listed here - https://github.com/COMBINE-lab/SalmonTools/blob/master/scripts/generateDecoyTranscriptome.sh (and this requires the gff file, mashmap and bedtools software). 3. SA and SAF both require genome. Can I still use `salmon index` on the transcriptome file without using genome files? Based on the release notes quoted (copy/pasted) below, I am worried about the phrase `""mapping without selective alignment is disabled""`). . Salmon v1.0 release notes state: . > changes since v.014.1; > In this release of salmon, selective-alignment is enabled by default (and, in fact, mapping without selective-alignemnt is disabled). We may explore, in the future, ways to allow disabling selecive-alignment under the new mapping approach, but at this point, it is always enabled.; > ; ; 4. Page 18 of your preprint pdf states that you used ""salmon v0.15.0 for quasi-mapping"" - so I am assuming I have to keep 2 versions of salmon in my system if I have to do both quasi-mapping and SA/SAF?. 5. Page 19 of your preprint pdf states you used `--mimicBT2 and --useEM for SA and SAF` quantification methods. Is this the recommendation while using SA and SAF methods? ; From salmon v01.4.1 with SA method, I have all along used the default `VBEM `and `--validateMappings` based on info in [SalmonReadTheDocs](https://salmon.readthedocs.io/en/latest/salmon.html#validatemappings) . > Enables selective alignment of the sequencing reads when mapping them to the trans",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442:1107,release,release,1107,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442,1,['release'],['release']
Deployability,"ipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:8532,install,install,8532,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['install'],['install']
Deployability,"ir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedCellOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/Graph.cpp.o CMakeFiles/salmon.dir/DedupUMI.cpp.o CMakeFiles/salmon.dir/Alevin.cpp.o CMakeFiles/salmon.dir/AlevinHash.cpp.o CMakeFiles/salmon.dir/SalmonAlevin.cpp.o CMakeFiles/salmon.dir/WhiteList.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/SalmonQuantMerge.cpp.o CMakeFiles/salmon.dir/ProgramOptionsGenerator.cpp.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o CMakeFiles/salmon.dir/BAMUtils.cpp.o -o salmon -L/usr/common/src/salmon-1.2.1/lib -L/usr/common/src/salmon-1.2.1/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" ../external/pufferfish/src/libpuffer.a libsalmon_core.a ../external/pufferfish/external/twopaco/graphconstructor/libtwopaco.a ../external/pufferfish/external/twopaco/graphdump/libgraphdump.a ../external/pufferfish/external/ntcard/libntcard.a -lgff /usr/common/modules/el8/x86_64/software/io_lib/1.14.9-CentOS-vanilla/lib/libstaden-read.a /usr/lib64/libcurl.so /usr/lib64/libz.so -lm /usr/lib64/liblzma.so /usr/lib64/libbz2.so /usr/common/modules/el8/x86_64/software/libtbb/2020.5-CentOS-vanilla/lib/libtbbmalloc_proxy.so /usr/common/modules/el8/x86_64/software/libtbb/2020.5-CentOS-vanilla/lib/libtbbmalloc.so /usr/common/modules/el8/x86_64/software/libtbb/2020.5-CentOS-vanilla/lib/libtbb.so -lgomp /usr/lib64/libjemalloc.so -lrt ../external/pufferfish/src/libksw2pp.a libalevin_core.a -ldl -pthread ; /tmp/cc91ASWS.ltrans1.ltrans.o: In function `boost::iostreams::basic_gzip_compressor<std::allocator<cha",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162:1852,install,install,1852,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162,1,['install'],['install']
Deployability,ir/xxhash.c.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/SequenceBiasModel.cpp.o CMakeFiles/salmon.dir/StadenUtils.cpp.o CMakeFiles/salmon.dir/TranscriptGroup.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapFileSystem.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndexer.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndex.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAMapper.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapUtils.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/HitManager.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/bit_array.c.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_chrono.a /opt/boost/boost_1_57_0/lib/libboost_program_options.a /opt/boost/boost_1_57_0/lib/libboost_serialization.a ../../external/install/lib/libstaden-read.a -lz ../../external/install/lib/libdivsufsort.a ../../external/install/lib/libdivsufsort64.a ../../external/install/lib/libj,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:1730,install,install,1730,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,"irectory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Sal",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:7385,pipeline,pipeline,7385,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"it's not clear if the right fix is to pin the boost version [here](https://github.com/bioconda/bioconda-recipes/blob/master/recipes/salmon/meta.yaml), or just to go with the ""always use conda-forge on installs"" strategy in the documentation. I will consult with experts.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/480#issuecomment-579829090:201,install,installs,201,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/480#issuecomment-579829090,1,['install'],['installs']
Deployability,"itHub, but after adding `autoreconf -i` to the `CONFIGURE_COMMAND`, this leads to the same problem. ``` diff; --- salmon-0.4.2/CMakeLists.txt.orig 2015-06-15 02:31:09.000000000 +0200; +++ salmon-0.4.2/CMakeLists.txt 2015-08-18 21:13:29.684010359 +0200; @@ -357,14 +366,14 @@; message(""==================================================================""); ExternalProject_Add(libjellyfish; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; - URL ftp://ftp.genome.umd.edu/pub/jellyfish/jellyfish-2.1.3.tar.gz; - SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.1.3; + URL https://github.com/gmarcais/Jellyfish/releases/download/v2.2.3/jellyfish-2.2.3.tar.gz; + SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.2.3; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; - CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.1.3/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CXXFLAGS=${JELLYFISH_CXX_FLAGS}; + CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.2.3/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CXXFLAGS=${JELLYFISH_CXX_FLAGS}; BUILD_COMMAND ${MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CXXFLAGS=${JELLYFISH_CXX_FLAGS}; BUILD_IN_SOURCE 1; INSTALL_COMMAND make install && ; - cp config.h <INSTALL_DIR>/include/jellyfish-2.1.3/jellyfish/ &&; + cp config.h <INSTALL_DIR>/include/jellyfish-2.2.3/jellyfish/ &&; cp config.h <INSTALL_DIR>/include/; ). --- salmon-0.4.2/src/CMakeLists.txt.orig 2015-08-18 21:21:14.892734948 +0200; +++ salmon-0.4.2/src/CMakeLists.txt 2015-08-18 21:20:51.292295094 +0200; @@ -42,7 +42,7 @@; ${GAT_SOURCE_DIR}/external; ${GAT_SOURCE_DIR}/external/cereal/include; ${GAT_SOURCE_DIR}/external/install/include; -${GAT_SOURCE_DIR}/external/install/include/jellyfish-2.1.3; +${GAT_SOURCE_DIR}/external/install/include/jellyfish-2.2.3; ${GAT_SOURCE_DIR}/external/install/include/bwa; ${ZLIB_INCLUDE_DIR}; ${TBB_INCLUDE_DIRS}; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/11:2435,install,install,2435,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/11,5,['install'],['install']
Deployability,"k!. On Sun, Nov 01, 2015 at 08:48:45AM -0800, Rob Patro wrote:. > So, I've already updated the docs _here_ (i.e. the doc tag in the ReadMe should should point to the link I give above). I believe the right thing to do over in the Sailfish docs is to just remove any documentation about Salmon (since the projects are now maintained in separate repos each with their own docs).; > ; > ---; > ; > Reply to this email directly or view it on GitHub:; > ; > ## https://github.com/COMBINE-lab/salmon/issues/27#issuecomment-152843180; > ; > C. Titus Brown, ctbrown@ucdavis.edu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/27#issuecomment-152843296:83,update,updated,83,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/27#issuecomment-152843296,1,['update'],['updated']
Deployability,"keFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/Graph.cpp.o CMakeFiles/salmon.dir/DedupUMI.cpp.o CMakeFiles/salmon.dir/Alevin.cpp.o CMakeFiles/salmon.dir/AlevinHash.cpp.o CMakeFiles/salmon.dir/SalmonAlevin.cpp.o CMakeFiles/salmon.dir/WhiteList.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/SalmonQuantMerge.cpp.o CMakeFiles/salmon.dir/ProgramOptionsGenerator.cpp.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o CMakeFiles/salmon.dir/BAMUtils.cpp.o -o salmon -L/usr/common/src/salmon-1.2.1/lib -L/usr/common/src/salmon-1.2.1/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" ../external/pufferfish/src/libpuffer.a libsalmon_core.a ../external/pufferfish/external/twopaco/graphconstructor/libtwopaco.a ../external/pufferfish/external/twopaco/graphdump/libgraphdump.a ../external/pufferfish/external/ntcard/libntcard.a -lgff /usr/common/modules/el8/x86_64/software/io_lib/1.14.9-CentOS-vanilla/lib/libstaden-read.a /usr/lib64/libcurl.so /usr/lib64/libz.so -lm /usr/lib64/liblzma.so /usr/lib64/libbz2.so /usr/common/modules/el8/x86_64/software/libtbb/2020.5-CentOS-vanilla/lib/libtbbmalloc_proxy.so /usr/common/modules/el8/x86_64/software/libtbb/2020.5-CentOS-vanilla/lib/libtbbmalloc.so /usr/common/modules/el8/x86_64/software/libtbb/2020.5-CentOS-vanilla/lib/libtbb.so -lgomp /usr/lib64/libjemalloc.so -lrt ../external/pufferfish/src/libksw2pp.a libalevin_core.a -ldl -pthread ; /tmp/cc91ASWS.ltrans1.ltrans.o: In function `boost::iostreams::basic_gzip_compressor<std::allocator<char> >::basic_gzip_compressor(boost::iostreams::gzip_params const&, long) [clone .con",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162:1945,install,install,1945,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162,1,['install'],['install']
Deployability,"l_la-url.o): In function `fix_hostname.isra.7':; (.text.unlikely+0x2e4): undefined reference to `idn2_check_version'; (.text.unlikely+0x301): undefined reference to `idn2_lookup_ul'; (.text.unlikely+0x34b): undefined reference to `idn2_strerror'; /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_la-cookie.o): In function `Curl_cookie_add':; (.text+0xbb1): undefined reference to `psl_builtin'; (.text+0xbca): undefined reference to `psl_is_cookie_domain_acceptable'; /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_la-version.o): In function `curl_version':; (.text+0xd6): undefined reference to `idn2_check_version'; (.text+0xe2): undefined reference to `idn2_check_version'; (.text+0x106): undefined reference to `psl_get_version'; /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_la-version.o): In function `curl_version_info':; (.text+0x1e9): undefined reference to `idn2_check_version'; /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_la-socks_gssapi.o): In function `check_gss_err.part.0':; (.text+0x57): undefined reference to `gss_release_buffer'; (.text+0x77): undefined reference to `gss_display_status'; (.text+0x9b): undefined reference to `gss_release_buffer'; (.text+0xcf): undefined reference to `gss_release_buffer'; (.text+0xef): undefined reference to `gss_display_status'; (.text+0x10e): undefined reference to `gss_release_buffer'; (.text+0x18e): undefined reference to `gss_release_buffer'; /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_la-socks_gssapi.o): In function `Curl_SOCKS5_gssapi_negotiate':; (.text+0x2ef): undefined reference to `gss_import_name'; (.text+0x302): undefined reference to `gss_release_buffer'; (.text+0x42c): undefined reference to `gss_release_buffer'; (.text+0x437): undefined reference to `gss_release_buffer'; (.text+0x532): undefined reference to `gss_release_buffer'; (.text+0x56c): undefined reference to `gss_release_name'; ```. and hundreds more, all related to libcurl. System is Linux Mint 19.2 (Ubuntu 18.04), idn2 and all other related libraries are installed.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/425:2701,install,installed,2701,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/425,1,['install'],['installed']
Deployability,"le | Time = 6.1119 s; -----------------------------------------; size = 25107960; -----------------------------------------; | Loading contig offsets | Time = 29.509 ms; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 163.13 us; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 358.06 ms; -----------------------------------------; size = 3025374818; Number of ones: 25107959; Number of ones per inventory item: 512; Inventory entries filled: 49039; -----------------------------------------; | Loading contig boundaries | Time = 3.1166 s; -----------------------------------------; size = 3025374818; -----------------------------------------; | Loading sequence | Time = 237.3 ms; -----------------------------------------; size = 2272136048; -----------------------------------------; | Loading positions | Time = 2.8327 s; -----------------------------------------; size = 2977516968; -----------------------------------------; | Loading reference sequence | Time = 228.26 ms; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 320.51 us; -----------------------------------------; [2024-05-03 15:10:04.136] [jointLog] [info] done; [2024-05-03 15:10:04.170] [jointLog] [info] Index contained 147554 targets. [2024-05-03 15:10:05.131] [jointLog] [info] Number of decoys : 61 ; processed 21000000 fragmentsointLog] [info] First decoy index : 147456; hits: 25885546, hits per frag: 1.2683(base) [**no further output**]; ```. **Desktop (please complete the following information):**; - OS: Ubuntu linux. ```; $ uname -a; Linux big-bird 5.15.0-102-generic #112-Ubuntu SMP Tue Mar 5 16:50:32 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux; $ lsb_release -a; No LSB modules are available.; Distributor ID: Ubuntu; Description: Ubuntu 22.04.4 LTS; Release: 22.04; Codename: jammy; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/929:7907,Release,Release,7907,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/929,1,['Release'],['Release']
Deployability,"les/salmon.dir/__/external/install/src/rapmap/bit_array.c.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_chrono.a /opt/boost/boost_1_57_0/lib/libboost_program_options.a /opt/boost/boost_1_57_0/lib/libboost_serialization.a ../../external/install/lib/libstaden-read.a -lz ../../external/install/lib/libdivsufsort.a ../../external/install/lib/libdivsufsort64.a ../../external/install/lib/libjellyfish-2.0.a ../../external/install/lib/libbwa.a -lm ../../external/install/lib/liblzma.a -lbz2 -ltbb -ltbbmalloc -lgomp -lrt ../../external/install/lib/libjemalloc.a -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib""; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xd26): warning: the use of `tempnam' is dangerous, better use `mkstemp'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `tbb::strict_ppl::internal::concurrent_queue_base_v3<UnpairedRead*>::internal_push(void const*, void (*)(UnpairedRead**, void const*)) [clone .constprop.1465]':; SalmonQuantifyAlignments.cpp:(.text+0x136d): undefined reference to `tbb::internal::throw_exception_v4(tbb::internal::exception_id)'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `tbb::strict_ppl::internal::concurrent_queue_base_v3<ReadPair*>::internal_push(void const*, void (*)(ReadPair**, void const*)) [clon",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:2765,install,install,2765,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,libc++abi: terminating ; zsh: abort. I got this on Terminal while trying to run Salmon program.; I installed Salmon via conda so I have the 10.3,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/939:99,install,installed,99,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/939,1,['install'],['installed']
Deployability,"lmon quant --threads 1 --libType=U -i index -r SRR493367.fastq.gz -o SRR493367; ```. I get the following error(s) even though the same version of kallisto was used for the indexing & quantifiation:; ```; Encountered exception [JSON Parsing failed - provided NVP (SeqHash512) not found] when loading index.; The index was likely build with an older (and incompatible) version of RapMap. Please re-build the index with a compatible version.; ```. ## To Reproduce; - Install docker ; - Download transcriptome:; ```; wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/gencode.v27.transcripts.fa.gz; ```; - Run docker container (warning 2GB):; ```; docker run -v $PWD -w $PWD:$PWD -it lifebitai/rnaseq-nf-dseq2 bash; ```; - Download reads (warning reads are 2.3GB:; ```; fastq-dump SRR493367; ```; - Index transcriptome:; ```; salmon index --threads 1 -t gencode.v27.transcripts.fa.gz -i index; ```; - Run quantification cmd above. <br />; Specifically, please provide at least the following information:. * Which version of salmon was used? v0.12.0; * How was salmon installed? Download precompliied binary and made Dockerfile with the following:; ```Dockerfile; COPY ./salmon-0.12.0_linux_x86_64/bin /usr/local/bin; COPY ./salmon-0.12.0_linux_x86_64/lib /usr/local/lib. RUN chmod -R u+x /usr/local/bin. ENV PATH=""$PATH:/usr/local/bin""; ```; * Which reference (e.g. transcriptome) was used? gencode.v27.transcripts.fa.gz; * Which read files were used? SRR493367.fastq.gz; * Which which program options were used? See above. I encountered this error when running this [Nextflow pipeline](https://github.com/PhilPalmer/RNASeq-nf-dseq2). More details can be found [here](https://deploit.lifebit.ai/public/jobs/5c6eca93758e8300a8740a59) . Any ideas what the problem may be? I am not sure if it is a problem with my installation of Salmon, the [data](https://www.ncbi.nlm.nih.gov/sra/?term=SRR493367), the command or something else. Any help would be much appreciated. ; Thanks in advance",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/345:1147,install,installed,1147,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/345,3,"['install', 'pipeline']","['installation', 'installed', 'pipeline']"
Deployability,lmon.dir/QSufSort.c.o CMakeFiles/salmon.dir/is.c.o CMakeFiles/salmon.dir/bwt_gen.c.o CMakeFiles/salmon.dir/bwtindex.c.o CMakeFiles/salmon.dir/xxhash.c.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/SequenceBiasModel.cpp.o CMakeFiles/salmon.dir/StadenUtils.cpp.o CMakeFiles/salmon.dir/TranscriptGroup.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapFileSystem.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndexer.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndex.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAMapper.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapUtils.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/HitManager.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/bit_array.c.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_chrono.a /opt/boost/boost_1_57_0/lib/libboost_program_options.a /opt/boost/boost_1_57_0/lib/libboost_serialization.a ../../external/install/lib/li,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:1589,install,install,1589,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,"lmon.dir/__/external/install/src/rapmap/HitManager.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/bit_array.c.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_chrono.a /opt/boost/boost_1_57_0/lib/libboost_program_options.a /opt/boost/boost_1_57_0/lib/libboost_serialization.a ../../external/install/lib/libstaden-read.a -lz ../../external/install/lib/libdivsufsort.a ../../external/install/lib/libdivsufsort64.a ../../external/install/lib/libjellyfish-2.0.a ../../external/install/lib/libbwa.a -lm ../../external/install/lib/liblzma.a -lbz2 -ltbb -ltbbmalloc -lgomp -lrt ../../external/install/lib/libjemalloc.a -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib""; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xd26): warning: the use of `tempnam' is dangerous, better use `mkstemp'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `tbb::strict_ppl::internal::concurrent_queue_base_v3<UnpairedRead*>::internal_push(void const*, void (*)(UnpairedRead**, void const*)) [clone .constprop.1465]':; SalmonQuantifyAlignments.cpp:(.text+0x136d): undefined reference to `tbb::internal::throw_exception_v4(tbb::internal::exception_id)'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:2631,install,install,2631,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,"lmonIndex::build(this=<unavailable>, indexDir=(m_pathname = ""athal_index""), idxOpt=<unavailable>) at SalmonIndex.hpp:76; frame #17: 0x00000000009839c3 salmon`salmonIndex(argc=<unavailable>, argv=<unavailable>, (null)=<unavailable>) at BuildSalmonIndex.cpp:236; frame #18: 0x000000000097a673 salmon`main [inlined] std::__1::__function::__value_func<int (int, char const**, std::__1::unique_ptr<SalmonIndex, std::__1::default_delete<SalmonIndex> >&)>::operator(this=<unavailable>, __args=<unavailable>, __args=<unavailable>, __args=<unavailable>)(int&&, char const**&&, std::__1::unique_ptr<SalmonIndex, std::__1::default_delete<SalmonIndex> >&) const at functional:1884:16 ; frame #19: 0x000000000097a648 salmon`main [inlined] std::__1::function<int (int, char const**, std::__1::unique_ptr<SalmonIndex, std::__1::default_delete<SalmonIndex> >&)>::operator(this=<unavailable>, __arg=<unavailable>, __arg=<unavailable>, __arg=<unavailable>)(int, char const**, std::__1::unique_ptr<SalmonIndex, std::__1::default_delete<SalmonIndex> >&) const at functional:2556; frame #20: 0x000000000097a648 salmon`main(argc=<unavailable>, argv=<unavailable>) at Salmon.cpp:274; frame #21: 0x000000000046bbf0 salmon`_start(ap=<unavailable>, cleanup=<unavailable>) at crt1_c.c:75:7; ```; Given that the crash is happening in a stream.Put() call, I presume that the stream must not be open and this should have been caught earlier. ```; template <typename StreamType>; class BasicOStreamWrapper {; public:; typedef typename StreamType::char_type Ch;; BasicOStreamWrapper(StreamType& stream) : stream_(stream) {}. void Put(Ch c) {; stream_.put(c);; }; ```; If you can provide any clues as to where in this lengthy backtrace the problem actually begins, it would be appreciated.; I used minimal changes to the raw dist to get this working.; Separately installed dependencies:. cereal 1.3.0.10; libgff 2.0.0; tbb 2020.3; boost-libs 1.72.0. Pufferfish 1.6.0 and staden-io_lib 1.14.8.1 are embedded in the build. Best,. Jason",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/725:7314,install,installed,7314,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/725,1,['install'],['installed']
Deployability,"lt still segfaults. It still needed an edit of the CMakeLists.txt file. Still, for future reference:. ```; pversion=1.2.1; package=salmon; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; wget https://github.com/COMBINE-lab/salmon/archive/v1.2.1.tar.gz; gunzip -c v1.2.1.tar.gz | tar -xf -; /bin/rm v1.2.1.tar.gz; cd ${package}-${pversion}; mv CMakeLists.txt CMakeLists.txt.dist; cat >mypatch <<'EOD'; --- CMakeLists.txt.dist	2020-04-21 22:31:07.000000000 -0700; +++ CMakeLists.txt	2020-06-09 14:55:02.733885772 -0700; @@ -419,6 +419,10 @@; find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); +message(""Forcing Boost_FOUND to TRUE""); +set(Boost_FOUND TRUE); +set(Boost_LIBRARY_DIRS ""/usr/lib64/boost169""); +set(Boost_LIBRARIES -lboost_iostreams -lboost_filesystem -lboost_system -lboost_timer -lboost_chrono -lboost_program_options); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; EOD; patch -p0 <mypatch; module load cmake; module load io_lib; module load libgff; module load libtbb; mkdir build; cd build; export CFLAGS=""-g -O0""; export CXXFLAGS=""-g -O0""; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_09.log; make -j 4 2>&1 | tee build_2020_06_09.log. ```. Since it was compiled ""-g -O0"" this time it was easier to step through it. Well, somewhat. In Salmon.cpp line 195 is the last place a break point works. If one is set for 197 it segfaults before reaching it. Line 195 is:. `	 po::store(parsed, vm);; `; I tried briefly to trace inward from there but couldn't make heads or tails of the path it was taking through an endless series of headers.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641612831:1122,patch,patch,1122,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641612831,1,['patch'],['patch']
Deployability,"ly/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/R10003_D19KGACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/R10003_D19KGACXX/logs; [2017-03-08 11:37:32.888] [jointLog] [info] parsing read library format; [2017-03-08 11:37:32.893] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-051/job_scripts/9987275: line 31: 41232 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Softw; are/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.tr; anscripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/${ID}; **** Job ends ****; Wed Mar 8 11:37:36 EST 2017; ```. and the core dump file shows that the program was terminated:. ```bash; $ gdb core.41232; GNU gdb (GDB) Red Hat Enterprise Linux (7.2-60.el6_4.1); Copyright (C) 2010 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>...; Missing separate debuginfo for the main executable file; Try: yum --disablerepo='*' --enablerepo='*-debug*' install /usr/lib/debug/.build-id/f2/3c99ed06abf",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:24137,pipeline,pipeline,24137,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['pipeline'],['pipeline']
Deployability,"m github. **Describe the bug**; A clear and concise description of what the bug is. core dumped crash on building index process. **To Reproduce**; Steps and data to reproduce the behavior:. wget http://ftp.ensembl.org/pub/current_fasta/mus_musculus/cdna/Mus_musculus.GRCm39.cdna.all.fa.gz ; wget http://ftp.ensembl.org/pub/current_fasta/mus_musculus/dna/Mus_musculus.GRCm39.dna.primary_assembly.fa.gz; wget https://github.com/COMBINE-lab/salmon/releases/download/v1.8.0/salmon-1.8.0_linux_x86_64.tar.gz; grep ""^>"" <(gunzip -c Mus_musculus.GRCm39.dna.primary_assembly.fa.gz) | cut -d "" "" -f 1 > decoys.txt; sed -i.bak -e 's/>//g' decoys.txt; cat Mus_musculus.GRCm39.cdna.all.fa.gz Mus_musculus.GRCm39.dna.primary_assembly.fa.gz > gentrome.fa.gz; salmon index -t gentrome.fa.gz -d decoys.txt -p 60 -i Mus_musculus.GRCm39_v1.8.0_decoy.index. Specifically, please provide at least the following information:. * Which version of salmon was used?; 1.8.0. * How was salmon installed (compiled, downloaded executable, through bioconda)?; downloaded executable. * Which reference (e.g. transcriptome) was used?; downloaded executable; . **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. salmon-1.8.0_linux_x86_64/bin/salmon index -t gentrome.fa.gz -d decoys.txt -p 60 -i Mus_musculus.GRCm39_v1.8.0_decoy.index; Version Info: This is the most recent version of salmon.; index [""Mus_musculus.GRCm39_v1.8.0_decoy.index""] did not previously exist . . . creating it; [2022-06-01 18:13:38.986] [jLog] [info] building index; out : Mus_musculus.GRCm39_v1.8.0_decoy.index; [2022-06-01 18:13:38.986] [puff::index::jointLog] [info] Running fixFasta. [Step 1 of 4] : counting k-mers; [2022-06-01 18:13:38.994] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000178537.2], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2022-06-01 18:13:38.994] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000178862.2], ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/783:1096,install,installed,1096,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/783,1,['install'],['installed']
Deployability,"m_free=80G,h_vmem=90G,h_fsize=100G; #$ -N step6-txQuant-alzheimer.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/txQuant-alzheimer.$TASK_ID.txt; #$ -e ./logs/txQuant-alzheimer.$TASK_ID.txt; #$ -t 1-422; #$ -m a; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/${ID}. echo ""**** Job ends ****""; date; ```. The important part is that we are requesting 1 single core with 80 GB of free memory and setting the limit at 90 GB. We are also using the `-p 1` option. . Here is the log file for one of them (task 3):. ```; **** Job starts ****; Mon Mar 6 23:19:13 EST 2017; **** JHPCE info ****; User: lcollado; Job id: 9958683; Job name: step6-txQuant-alzheimer.gsk_phaseII; Hostname: compute-068; Task id: ; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases ; contains new features, improvements, and minor bug fixes; please upgrade at your; earliest convenience.; ###; ### salmon (mapping-based) v0.7.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl0",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:1625,pipeline,pipeline,1625,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['pipeline'],['pipeline']
Deployability,"mage. For more detail, here are the steps performed (perhaps taking a look at the installed packages will highlight a difference, as I did this from a clean testing Docker image, so my environment had nothing else in it). ### Attempt to reproduce segfault on Debian:testing. ```{bash}; $ docker pull debian:testing. $ docker run -it debian:testing. $ apt-get update. $ apt-get install build-essential git libboost-all-dev liblzma-dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev. $ git clone https://github.com/COMBINE-lab/salmon.git; $ cd salmon; $ mkdir build && cd build; $ cmake -DNO_IPO=TRUE .. # GCC still doesn't handle LTO robustly; $ make -j8; $ make install; $ make test; ```. which leads to the output. ```; root@fd877e359439:/salmon/build# make install; [ 7%] Built target libcereal; [ 13%] Built target libtbb; [ 16%] Built target ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:808,install,install,808,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,"['Install', 'install']","['Install', 'install']"
Deployability,may be try creating a new environment and/or specify the version of salmon you wan't to install ? it can happen sometimes based on the dependency structure already installed in your environment. You can also the pre build binaries from https://github.com/COMBINE-lab/salmon/releases. It's more of an issue with conda than salmon itself. Closing this one but let us know if you still face any issue.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/461#issuecomment-565296541:88,install,install,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/461#issuecomment-565296541,3,"['install', 'release']","['install', 'installed', 'releases']"
Deployability,"ments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; warning: Loadable section "".note.gnu.property"" outside of ELF segments; [New Thread 0x7ffff0987700 (LWP 17537)]. Thread 2 ""salmon"" received signal SIGSEGV, Segmentation fault.; [Switching to Thread 0x7ffff0987700 (LWP 17537)]; 0x00007ffff68202ab in je_tcache_bin_flush_small () from /lib64/libjemalloc.so.2; Missing separate debuginfos, use: yum debuginfo-install boost169-filesystem-1.69.0-4.el8.x86_64 boost169-iostreams-1.69.0-4.el8.x86_64 boost169-program-options-1.69.0-4.el8.x86_64 boost169-system-1.69.0-4.el8.x86_64 brotli-1.0.6-1.el8.x86_64 bzip2-libs-1.0.6-26.el8.x86_64 cyrus-sasl-lib-2.1.27-1.el8.x86_64 jemalloc-5.2.1-2.el8.x86_64 keyutils-libs-1.5.10-6.el8.x86_64 krb5-libs-1.17-9.el8.x86_64 libcom_err-1.44.6-3.el8.x86_64 libcurl-7.61.1-11.el8.x86_64 libgcc-8.3.1-4.5.el8.x86_64 libgomp-8.3.1-4.5.el8.x86_64 libidn2-2.2.0-1.el8.x86_64 libnghttp2-1.33.0-1.el8_0.1.x86_64 libpsl-0.20.2-5.el8.x86_64 libselinux-2.9-2.1.el8.x86_64 libssh-0.9.0-4.el8.x86_64 libstdc++-8.3.1-4.5.el8.x86_64 libunistring-0.9.9-3.el8.x86_64 libxcrypt-4.1.1-4.el8.x86_64 openldap-2.4.46-11.el8_1.x86_64 pcre2-10.32-1.el8.x86_64 tbb-devel-2018.2-9.el8.x86_64 xz-libs-5.2.4-3.el8.x86_64 zlib-1.2.11-10.el8.x86_64; (gdb) bt; #0 0x00007ffff68202ab in je_tcache_bin_flush_small () from /lib64/libjemalloc.so.2; #1 0x00007ffff68221ee in tcache_flush_cache () from",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410:5137,install,install,5137,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641594410,1,['install'],['install']
Deployability,"mily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/liebe",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:5414,pipeline,pipeline,5414,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"mmand not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.441] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.441] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.441] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.441] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ m",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:3262,release,release,3262,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['release'],['release']
Deployability,"mmand not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.532] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.532] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.532] [jointLog] [info] parsing read library format; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon[2019-07-24 13:33:29.532] [jointLog] [info] There is 1 library.; quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ ma",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:4873,release,release,4873,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['release'],['release']
Deployability,"mmand not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.626] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.626] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.626] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.626] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ m",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:6483,release,release,6483,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['release'],['release']
Deployability,"mmand not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.720] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.720] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.720] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.720] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ m",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:8094,release,release,8094,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['release'],['release']
Deployability,"mmand not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.808] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.808] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.808] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.808] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ m",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:9705,release,release,9705,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['release'],['release']
Deployability,"mmand not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.899] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.899] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.899] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.899] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ m",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:11316,release,release,11316,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['release'],['release']
Deployability,"mmand not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.990] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.990] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.990] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.990] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ m",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:12927,release,release,12927,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['release'],['release']
Deployability,"mmand not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:30.175] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:30.175] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:30.175] [jointLog] [info] parsing read library format; [2019-07-24 13:33:30.175] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ m",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:16149,release,release,16149,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['release'],['release']
Deployability,"mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti""..., 45terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:24:37.940] [joint""..., 136) = 136; tgkill(32681, 32681, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```; and for task 2:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/li",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:41262,pipeline,pipeline,41262,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti""..., 45terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:40:15.587] [joint""..., 136) = 136; tgkill(51996, 51996, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```. and for task 2:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/li",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:122225,pipeline,pipeline,122225,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"my bad about that, just upgraded the alias to change salmon's path (from 0.7.2 to 1.3.0), but changes have not been affected. I'm so sorry about that",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/563#issuecomment-680255521:24,upgrade,upgraded,24,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/563#issuecomment-680255521,1,['upgrade'],['upgraded']
Deployability,"n is a concern to me, because sequencing is expensive, and it'd be good to have an idea of whether we need to further improve our library prep (which would certainly be the case for 9X duplication, but less important with 3-5X duplication). Is anyone able to explain how the UMI deduplication is applied in Salmon Alevin, or why it might be different from other analysis platforms?. * Which version of salmon was used? v1.9.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? Binary download from github; * Which reference (e.g. transcriptome) was used? Gencode Human v42; * Which read files were used? NovaSeq 6000 S2; * Which program options were used?. ```; salmon alevin -l ISR \; -1 $(ls demultiplexed/squished_${machineID}*_R1_001.fastq.gz | sort) \; -2 $(ls demultiplexed/${machineID}*_R2_001.fastq.gz | sort) \; --mrna ${indexDir}/mt_genes.txt --rrna ${indexDir}/rRNA_genes.txt \; -i ${indexDir}/${indexName} --expectCells ${expectCellCount} --whitelist goodSampleTagCells.txt \; -p 10 -o salmon_1.9_cbc_whitelist_${projectID}_combined --tgMap ${indexDir}/txp2gene_${targetName}.txt \; --umi-geometry '1[28-35]' --bc-geometry '1[1-27]' --read-geometry '2[1-end]'; ```. **Expected behavior**. I would expect the Salmon Alevin PCR duplication estimate to be similar to that of SevenBridges, or my semi-manual attempt (e.g. 3-5X). **Desktop OS/Version:**. `Linux musculus 5.18.0-4-amd64 #1 SMP PREEMPT_DYNAMIC Debian 5.18.16-1 (2022-08-10) x86_64 GNU/Linux`. ```; No LSB modules are available.; Distributor ID: Debian; Description: Debian GNU/Linux bookworm/sid; Release: unstable; Codename: sid; ```. **Additional Information**; The SevenBridges Rhapsody pipeline uses STAR v2.5.2b for annotating R2 reads, which are combined with R1 reads using custom python scripts (possibly involving calling HTSeq and Picard), then collapsed down to molecules using custom python scripts (apparently ""apply rsec and dbec correction to the (sorted) valid annotation dataset"").",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/808:3858,Release,Release,3858,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/808,2,"['Release', 'pipeline']","['Release', 'pipeline']"
Deployability,"n.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_chrono.a /opt/boost/boost_1_57_0/lib/libboost_program_options.a /opt/boost/boost_1_57_0/lib/libboost_serialization.a ../../external/install/lib/libstaden-read.a -lz ../../external/install/lib/libdivsufsort.a ../../external/install/lib/libdivsufsort64.a ../../external/install/lib/libjellyfish-2.0.a ../../external/install/lib/libbwa.a -lm ../../external/install/lib/liblzma.a -lbz2 -ltbb -ltbbmalloc -lgomp -lrt ../../external/install/lib/libjemalloc.a -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib""; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xd26): warning: the use of `tempnam' is dangerous, better use `mkstemp'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `tbb::strict_ppl::internal::concurrent_queue_base_v3<UnpairedRead*>::internal_push(void const*, void (*)(UnpairedRead**, void const*)) [clone .constprop.1465]':; SalmonQuantifyAlignments.cpp:(.text+0x136d): undefined reference to `tbb::internal::throw_exception_v4(tbb::internal::exception_id)'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `tbb::strict_ppl::internal::concurrent_queue_base_v3<ReadPair*>::internal_push(void const*, void (*)(ReadPair**, void const*)) [clone .constprop.1477]':; SalmonQuantifyAlignments.cpp:(.text+0x161d): undefined reference to `tbb::internal::throw_exc",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:2878,install,install,2878,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,"n/bash; #$ -cwd; #$ -l mem_free=14G,h_vmem=15G,h_fsize=100G; #$ -N step6-salmon_test2.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test2.$TASK_ID.txt; #$ -e ./logs/salmon_test2.$TASK_ID.txt; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test2/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test2/${ID}. echo ""**** Job ends ****""; date; ```. and the log file for task 2:. ```bash; $ more logs/salmon_test2.2.txt; **** Job starts ****; Wed Mar 8 11:53:17 EST 2017; **** JHPCE info ****; User: lcollado; Job id: 9987283; Job name: step6-salmon_test2.gsk_phaseII; Hostname: compute-060; Task id:; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and minor bug fixes; please upgrade at your; earliest convenience.; ###; ### salmon (mapping-based) v0.7.2; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts }; ### [ threads ] => { 1 ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:27996,pipeline,pipeline,27996,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['pipeline'],['pipeline']
Deployability,"nd failed at ; [ 86%] Building CXX object src/CMakeFiles/salmon.dir/EMUtils.cpp.o; c++: error: -pg and -fomit-frame-pointer are incompatible; src/CMakeFiles/salmon.dir/build.make:62: recipe for target 'src/CMakeFiles/salmon.dir/EMUtils.cpp.o' failed; make[2]: *** [src/CMakeFiles/salmon.dir/EMUtils.cpp.o] Error 1; CMakeFiles/Makefile2:790: recipe for target 'src/CMakeFiles/salmon.dir/all' failed; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; Makefile:162: recipe for target 'all' failed; make: *** [all] Error 2. **To Reproduce**; Steps and data to reproduce the behavior:; 1. run a docker container using ubuntu:18.04 as image. 2. (packages I installed); apt-get install -y gcc g++ make wget git curl libtbb2-dbg libtbb-dev unzip zlib1g-dev libcurl4-openssl-dev liblzma-dev libbz2-dev libcereal-dev libgff-dev libpkgconfig-perl libjemalloc-dev; /*; gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0; g++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0; GNU Make 4.1; */; wget https://github.com/Kitware/CMake/releases/download/v3.13.4/cmake-3.13.4-Linux-x86_64.sh /*cmake version 3.13.4*/. 3. git clone https://github.com/COMBINE-lab/salmon.git; I'm at the top commit: commit 0813a0a287c2bd80071511830befe5d786a59ad1 (HEAD -> master, tag: v1.4.0, origin/master, origin/HEAD). 4. In directory salmon/build, I type; cmake -DFETCH_BOOST=TRUE -DTBB_INSTALL_DIR=/usr/include -DCMAKE_BUILD_TYPE=Debug -DCMAKE_INSTALL_PREFIX=../stage .. =============At last, getting these:; -- Configuring done; -- Generating done; -- Build files have been written to: /root/salmon/build. 5. In directory salmon/build, I type; make. ===========Then crashed here; [ 86%] Built target unitTests; Scanning dependencies of target salmon; [ 86%] Building CXX object src/CMakeFiles/salmon.dir/EMUtils.cpp.o; c++: error: -pg and -fomit-frame-pointer are incompatible; src/CMakeFiles/salmon.dir/build.make:62: recipe for target 'src/CMakeFiles/salmon.dir/EMUtils.cpp.o' failed; make[2]: *** [src/CMakeFiles/salmon.dir/EMUtils.cpp.o] Error 1; ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/608:1233,release,releases,1233,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/608,1,['release'],['releases']
Deployability,"nda; * Which reference (e.g. transcriptome) was used?; * human hg38 [gencode v43 comprehensive](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_43/gencode.v43.primary_assembly.annotation.gtf.gz) produces the error; * human hg38 [gencode v43 basic](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_43/gencode.v43.basic.annotation.gtf.gz) works fine.; * Which read files were used?; * The issue is reproducible with multiple independent read files. Logs attached are from reads subsampled from [GSM7099349](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM7099349); * Which which program options were used?; * --skipQuant -l A. **Expected behavior**; A clear and concise description of what you expected to happen.; salmon quant finishes without seg fault with `--skipQuant`; **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; Terminal output when `--skipQuant` is on:; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-based) v1.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /share/genomes/human/hg38/gencode_v43/primary_comprehensive/SalmonIndex }; ### [ skipQuant ] => { }; ### [ libType ] => { A }; ### [ mates1 ] => { GSM7099349.R1.fastq }; ### [ mates2 ] => { GSM7099349.R2.fastq }; ### [ output ] => { salmon_out }; ### [ threads ] => { 1 }; Logs will be written to salmon_out/logs; [2023-11-30 09:40:21.543] [jointLog] [info] setting maxHashResizeThreads to 1; [2023-11-30 09:40:21.543] [jointLog] [info] Fragment incompatibility pri",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/902:1540,UPGRADE,UPGRADE,1540,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/902,1,['UPGRADE'],['UPGRADE']
Deployability,"nda; salmon 0.6.0 1 bioconda; salmon 0.6.0 boost1.60_1 bioconda; salmon 0.6.0 boost1.60_2 bioconda; salmon 0.7.2 boost1.60_2 bioconda; salmon 0.7.2 boost1.60_3 bioconda; salmon 0.7.2 boost1.61_3 bioconda; salmon 0.8.0 boost1.60_0 bioconda; salmon 0.8.0 boost1.61_0 bioconda; salmon 0.8.1 0 bioconda; salmon 0.8.2 0 bioconda; salmon 0.8.2 1 bioconda; salmon 0.9.0 0 bioconda; salmon 0.9.1 0 bioconda; salmon 0.9.1 1 bioconda; salmon 0.10.0 1 bioconda; salmon 0.10.1 1 bioconda; salmon 0.10.2 1 bioconda; salmon 0.11.0 h445c947_0 bioconda; salmon 0.11.1 h445c947_0 bioconda; salmon 0.11.2 h445c947_0 bioconda; salmon 0.11.3 h86b0361_1 bioconda; salmon 0.11.3 h86b0361_2 bioconda; ```. When I try to install, I get `PackageNotFoundError`.; ```; $ conda create -n salmon salmon=0.11.3; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - salmon=0.11.3; - jemalloc[version='>=5.1.0']; - salmon=0.11.3; - libcxx. Current channels:. - https://conda.anaconda.org/bioconda/linux-64; - https://conda.anaconda.org/bioconda/noarch; - https://repo.anaconda.com/pkgs/main/linux-64; - https://repo.anaconda.com/pkgs/main/noarch; - https://repo.anaconda.com/pkgs/free/linux-64; - https://repo.anaconda.com/pkgs/free/noarch; - https://repo.anaconda.com/pkgs/r/linux-64; - https://repo.anaconda.com/pkgs/r/noarch; - https://repo.anaconda.com/pkgs/pro/linux-64; - https://repo.anaconda.com/pkgs/pro/noarch. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org. and use the search bar at the top of the page.; ```. It is weird because I am installing on `linux64`.; ```; $ lsb_release -a; LSB Version:	:base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch; Distributor ID:	CentOS; Description:	CentOS release 6.5 (Final); Release:	6.5; Codename:	Final; ```; Any help would be greatly appreciated.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/308:1826,install,installing,1826,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/308,3,"['Release', 'install', 'release']","['Release', 'installing', 'release']"
Deployability,"ne-lab.github.io/alevin-tutorial/2019/selective-alignment/), a segmentation fault occurs. (gdb backtrack is provided below.). **To Reproduce**; Steps and data to reproduce the behavior:. 1. run a docker container using ubuntu:18.04 as image. 2. (packages I installed); apt-get install -y gcc g++ make wget git curl libtbb2-dbg libtbb-dev unzip zlib1g-dev libcurl4-openssl-dev liblzma-dev libbz2-dev libcereal-dev libgff-dev libpkgconfig-perl libjemalloc-dev; /*; gcc (Ubuntu 7.5.0-3ubuntu118.04) 7.5.0; g++ (Ubuntu 7.5.0-3ubuntu118.04) 7.5.0; GNU Make 4.1; */; wget https://github.com/Kitware/CMake/releases/download/v3.13.4/cmake-3.13.4-Linux-x86_64.sh /cmake version 3.13.4/. 3. git clone https://github.com/COMBINE-lab/salmon.git; I'm at the top commit: commit 0813a0a (HEAD -> master, tag: v1.4.0, origin/master, origin/HEAD). 4. In directory salmon/build, I type; > cmake -DFETCH_BOOST=TRUE -DTBB_INSTALL_DIR=/usr/include -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=../stage ..; > make; > make install. 5. following your tutorial https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/; > wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M23/gencode.vM23.transcripts.fa.gz; > wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M23/GRCm38.primary_assembly.genome.fa.gz; > grep ""^>"" <(gunzip -c GRCm38.primary_assembly.genome.fa.gz) | cut -d "" "" -f 1 > decoys.txt; > sed -i.bak -e 's/>//g' decoys.txt; > cat gencode.vM23.transcripts.fa.gz GRCm38.primary_assembly.genome.fa.gz > gentrome.fa.gz; > salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon_index --gencode. ===========Then I get segmentation fault; ![image](https://user-images.githubusercontent.com/24876498/103153659-191b0100-47cd-11eb-942e-fcd99b3cf2e2.png). 6. gdb salmon <corefile>; It seemed to crash at these functions: fixFasta(), fixFastaMain() ; ![image](https://user-images.githubusercontent.com/24876498/103153694-554e6180-47cd-11eb-9e4e-dc4bfdf7f731.png). Sp",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/609:1408,install,install,1408,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/609,1,['install'],['install']
Deployability,"ng 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:56:54.826] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:56:54.883] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:56:54.908] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:56:54.908] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:57:09.336] [stderrLog] [info] Done loading index; [2019-01-29 09:57:09.336] [jointLog] [info] done; [2019-01-29 09:57:09.336] [jointLog] [info] Index contained 80,511 targets. processed 2 Million fragments; hits: 812181, hits per frag: 0.326777. [2019-01-29 09:57:36.647] [alevinLog] [info] Starting optimizer; [2019-01-29 09:57:36.587] [jointLog] [info] Computed 12,933 rich equivalence classes for further processing; [2019-01-29 09:57:36.587] [jointLog] [info] Counted 242,520 total reads in the equivalence classes ; [2019-01-29 09:57:36.601] [jointLog] [warning] Only 242520 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2019-01-29 09:57:36.601] [jointLog] [info] Mapping rate = 8.94141%. [2019-01-29 09:57:36.601] [jointLog] [info] finished quantifyLibrary(). Analyzed 293 cells (100% of all).; [2019-01-29 09:57:40.090] [alevinLog] [info] Total 206902 UMI after deduplicating.; [2019-01-29 09:57:40.091] [alevinLog] [warning] Skipped 71 barcodes due to No mapped read; [2019-01-29 09:57:40.110] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-01-29 09:57:40.176] [alevinLog] [info] Starting Import of the gene count matrix.; [2019-01-29 09:57:41.168] [alevinLog] [info] Done Importing gene count matrix for dimension 222x19879; [2019-01-29 09:57:41.168] [alevinLog] [info] Starting dumping cell v gene counts in csv format; Segmentation fault (core dumped); ```. I then installed through conda salmon=0.12.0. Both times it failed with core dump.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:10273,install,installed,10273,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['install'],['installed']
Deployability,"ng] Only 268744 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2023-11-30 09:38:33.436] [jointLog] [info] Mapping rate = 53.7596%. [2023-11-30 09:38:33.436] [jointLog] [info] finished quantifyLibrary(); [2023-11-30 09:38:33.440] [jointLog] [info] Starting optimizer; [2023-11-30 09:38:33.498] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2023-11-30 09:38:33.511] [jointLog] [info] iteration = 0 | max rel diff. = 101.852; [2023-11-30 09:38:34.853] [jointLog] [info] iteration = 100 | max rel diff. = 0.263537; [2023-11-30 09:38:36.144] [jointLog] [info] iteration = 200 | max rel diff. = 0.0414157; [2023-11-30 09:38:37.438] [jointLog] [info] iteration = 300 | max rel diff. = 1.17048; [2023-11-30 09:38:38.135] [jointLog] [info] iteration = 355 | max rel diff. = 0.00351135; [2023-11-30 09:38:38.148] [jointLog] [info] Finished optimizer; [2023-11-30 09:38:38.148] [jointLog] [info] writing output ; ```. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Linux; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; - Linux r640c10 4.18.0-372.16.1.el8_6.x86_64 #1 SMP Tue Jun 28 03:02:21 EDT 2022 x86_64 GNU/Linux. **Additional context**; Add any other context about the problem here.; The issue is definitely not insufficient memory (>300 GB available). ; Interestingly, the same salmon index was working perfectly until now. I re-created the index to make sure the files were not corrupted somehow but it resulted in the same error. I doubt that this is due to an update in salmon itself, because we have been using the same singularity container for this process for a while, so the same salmon version, same index now producing the error. . For my use case, not using the `--skipQuant` doesn't really cause any problem. I just wanted to report the bug.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/902:10621,update,update,10621,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/902,1,['update'],['update']
Deployability,"ning: the use of `tempnam' is dangerous, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salm",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1296,Install,Installing,1296,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installing']
Deployability,"nk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-004-chunk-002.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-001-chunk-001.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-002-chunk-000.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [2018-12-05 15:10:07.252] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 14, 5) is being used. Updating UMI k-mer length accordingly.; Logs will be written to ./fastq/test/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ gemcode ] => { }; ### [ index ] => { ../transcripts_index_salmon/ }; ### [ threads ] => { 8 }; ### [ output ] => { ./fastq/test/ }; ### [ tgMap ] => { ../hg_transcriptome/tx2tx.tsv }; ### [ end ] => { 5 }; ### [ umiLength ] => { 5 }; ### [ barcodeLength ] => { 14 }; ### [ dumpCsvCounts ] => { }; ### [ dumpFeatures ] => { }; ### [ mates1 ] => { /tmp/tmp.lLLibfwH4G/p1.fa }; ### [ mates2 ] => { /tmp/tmp.lLLibfwH4G/p2.fa }; ### [ unmatedReads ] => { ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz ./fastqs/flowcell1/read-I1_si-A",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:3504,upgrade,upgrades,3504,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['upgrade'],['upgrades']
Deployability,"nloaded executable, through bioconda)?: quay.io docker container; * Which reference (e.g. transcriptome) was used?: A combination of the GRCh38.p13 transcripts and the repeatmasker annotation from UCSC, with the GRCh38.p13 primary assembly as decoys.; * Which read files were used?: Paired forward and reverse reads (trimmed by Trimmomatic); * Which which program options were used?:; - [--libType A, --validateMappings, --seqBias, --gcBias, --recoverOrphans, --writeUnmappedNames, -p 8, --rangeFactorizationBins 4]. **Expected behavior**; A clear and concise description of what you expected to happen. Salmon quant to produce quant.sf file. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-based) v1.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { references/salmon/sel.align.gencode.v39.ucsc.rmsk.salmon.v1.9.0.sidx/ }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR14506785_output_forward_paired.fq.gz }; ### [ mates2 ] => { SRR14506785_output_reverse_paired.fq.gz }; ### [ threads ] => { 8 }; ### [ validateMappings ] => { }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; ### [ recoverOrphans ] => { }; ### [ rangeFactorizationBins ] => { 4 }; ### [ output ] => { SRR14506785.salmon.rmsk.out }; ### [ writeUnmappedNames ] => { }; Logs will be written to SRR14506785.salmon.rmsk.out/logs; [2023-09-28 04:51:02.450] [jointLog] [info] setting maxHashResizeThreads to 8; [2023-09-28 04:51:02.450] [jointLog] [info] Fragment i",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/876:1353,release,releases,1353,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/876,2,"['release', 'upgrade']","['releases', 'upgrade']"
Deployability,"nst&) const'; SalmonUtils.cpp:(.text+0x39b7): undefined reference to `boost::program_options::abstract_variables_map::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'; libsalmon_core.a(SalmonUtils.cpp.o): In function `salmon::utils::validateOptionsMapping_(SalmonOpts&, boost::program_options::variables_map&)':; SalmonUtils.cpp:(.text+0xec56): undefined reference to `boost::program_options::abstract_variables_map::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'; libsalmon_core.a(SalmonUtils.cpp.o):SalmonUtils.cpp:(.text+0xec92): more undefined references to `boost::program_options::abstract_variables_map::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const' follow; collect2: error: ld returned 1 exit status; make[2]: *** [src/unitTests] Error 1; make[1]: *** [src/CMakeFiles/unitTests.dir/all] Error 2; make: *** [all] Error 2. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. **Describe the bug**; A clear and concise description of what the bug is. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * Which reference (e.g. transcriptome) was used?; * Which read files were used?; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/551:2596,install,installed,2596,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/551,1,['install'],['installed']
Deployability,"nstallation. I decided to get the cmake `-DFETCH_BOOST=TRUE` option, in spite of having installed Boost. ; I get this error (here is the full log):. `cmake -DFETCH_BOOST=TRUE`. > Salmon requires g++ 5.2 or greater. https://pastebin.com/UmVJw0Ae. This is particularly odd.; I have installed a recent GCC version and even rebuilt Boost after it... As you can see, if I type . > gcc --version; > g++ --version. By root and user, I always get... > gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36); Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. and . > g++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36); Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. On another tutorial, I found that I should open a bash instead while installing gcc/g++, with the instruction:. `scl enable devtoolset-7 bash`. When I run . > gcc --version; > g++ --version. By root and user, this time the proper version is recognised!. > gcc (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5); Copyright (C) 2017 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. and. > g++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5); Copyright (C) 2017 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. As you can see, this time the latest version is recognised. I'm quite sure the bash was open even when I rebuilt Boost... But even though I re-open the bash before cmaking Salmon, it will always complain about an outdated version, having it opened or not won't make any difference. I'm also attaching",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/388:1148,install,installing,1148,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/388,1,['install'],['installing']
Deployability,"nt; ReadExperimentT = ReadExperiment<EquivalenceClassBuilder<TGValue> >; size_t = long unsigned int]::__lambda33}) (fastx_parser::FastxParser<fastx_parser::ReadSeq>*&)’; get_deleter()(__p);; ^; /opt/build/salmon/src/SalmonQuantify.cpp:1964:39: note: candidate is:; auto parserPtrDeleter = [&salmonOpts](auto* p) -> void {; ^; /opt/build/salmon/src/SalmonQuantify.cpp:1964:53: note: processReadLibrary(ReadExperimentT&, ReadLibrary&, SalmonIndex*, std::vector<Transcript>&, ClusterForest&, std::atomic<long unsigned int>&, std::atomic<long unsigned int>&, std::atomic<long unsigned int>&, bool, std::atomic<bool>&, ForgettingMassCalculator&, FragmentLengthDistribution&, SalmonOpts&, double, bool, std::mutex&, size_t, std::vector<std::vector<AlignmentGroup<AlnT> > >&, volatile bool&) [with AlnT = rapmap::utils::QuasiAlignment; ReadExperimentT = ReadExperiment<EquivalenceClassBuilder<TGValue> >; size_t = long unsigned int]::__lambda33; auto parserPtrDeleter = [&salmonOpts](auto* p) -> void {; ^; /opt/build/salmon/src/SalmonQuantify.cpp:1964:53: note: candidate expects 0 arguments, 1 provided; make[2]: *** [src/CMakeFiles/salmon.dir/SalmonQuantify.cpp.o] Error 1; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; make: *** [all] Error 2`. * Which version of salmon was used?; Salmon 0.3.2; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Cloned from git as latest source and attempted to cmake + make && make install . **Expected behavior**; A clear and concise description of what you expected to happen.; Expecting the makefile to use c++14 correctly to process the ""auto p"" variable the way it is intended within the template functions. See SalmonQuantify.cpp:1964 with errors regarding ""p was not declared in this scope"". . **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; Centos 7 ; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; 7.4",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/296:49777,install,installed,49777,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/296,2,['install'],"['install', 'installed']"
Deployability,"o Reproduce. Which version of salmon was used?; salmon v0.11.3 on MacBook Pro (15-inch, 2016) macOS Sierra 10.12.6. How was salmon installed (compiled, downloaded executable, through bioconda)?; bioconda. Which reference (e.g. transcriptome) was used?; To the best of my knowledge I followed the instructions in the tutorial at:; https://combine-lab.github.io/salmon/getting_started/. This describes where the data come from and how I invoked salmon. Which read files were used?; See above. Which which program options were used?; I used the bash script from; https://combine-lab.github.io/salmon/getting_started/. Expected behavior. I expected an output indicating successful quantification. Screenshots. I couldn't figure out how to insert a picture, but here is the text from ""terminal"" window.; `(salmon) MacBook-Pro-2:salmon-tutorial brent$ bash quant_tut_samples.sh; Processing sample DRR016125; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon. salmon (mapping-based) v0.11.3; [ program ] => salmon; [ command ] => quant; [ index ] => { athal_index }; [ libType ] => { A }; [ mates1 ] => { data/DRR016125/DRR016125_1.fastq.gz }; [ mates2 ] => { data/DRR016125/DRR016125_2.fastq.gz }; [ threads ] => { 8 }; [ output ] => { quants/DRR016125_quant }; Logs will be written to quants/DRR016125_quant/logs; [2018-11-24 15:08:09.785] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-11-24 15:08:09.785] [jointLog] [info] parsing read library format; [2018-11-24 15:08:09.785] [jointLog] [info] There is 1 library.; [2018-11-24 15:08:09.877] [jointLog] [info] Loading Quasi index; [2018-11-24 15:08:09.877] [jointLog] [info] Loading 32-bit quasi index; [2018-11-24 15:08:09.877] [stderrLog] [info] Loading Suffix Array; [2018-11-24 15:08:10.319] [stderrLog] [info] Loading Transcript Info; [2018-11-24 15:08:10.423] [stderrLog] [info] Loading Ra",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/318:1292,upgrade,upgrades,1292,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/318,1,['upgrade'],['upgrades']
Deployability,"o such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../external/install/lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeli",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:7704,pipeline,pipeline,7704,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"o-stamp/libstadenio-build] Error 2; CMakeFiles/Makefile2:257: recipe for target 'CMakeFiles/libstadenio.dir/all' failed; make[1]: *** [CMakeFiles/libstadenio.dir/all] Error 2; Makefile:162: recipe for target 'all' failed; make: *** [all] Error 2; ```. The internet tells me it's probably an issue with the order that the libraries are specified to gcc in or that gcc needs a `-lz` flag. However I don't even know where that gcc command is coming from. **To Reproduce**. This is difficult, because I would assume that the errors I'm seeing are specific to my machine. However I can say that I ran; ```; ./cmake-3.14.5-Linux-x86_64/bin/cmake -DFETCH_BOOST=TRUE; ```. and then. ```; make; ```. **Expected behavior**; I expected the project to build and produce a binary I could use to test my changes. **Desktop (please complete the following information):**; - OS: Ubuntu 18.04; - Version:. ```; lsb_release -a; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 18.04.2 LTS; Release:	18.04; Codename:	bionic; kurt@kurtputer:~/Development/refinebio-collab$ uname -a; Linux kurtputer 4.15.0-51-generic #55-Ubuntu SMP Wed May 15 14:27:21 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux; ```. **Additional context**; I was able to fix the following errors with these resolutions:; ```; ERROR:; CMake Error: The following variables are used in this project, but they are set to NOTFOUND.; Please set them or make sure they are set and tested correctly in the CMake files:; CURL_LIBRARY; linked by target ""salmon"" in directory /home/kurt/Development/salmon/src; linked by target ""unitTests"" in directory /home/kurt/Development/salmon/src; RESOLUTION:; sudo apt-get install libcurl4-openssl-dev; ----------------------------------; ERROR:; Performing download step for 'libbz2'; % Total % Received % Xferd Average Speed Time Time Time Current; Dload Upload Total Spent Left Speed; 100 227 100 227 0 0 1013 0 --:--:-- --:--:-- --:--:-- 1013; 100 16207 0 16207 0 0 34336 0 --:--:-- --:--:-- --:-",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/383:2848,Release,Release,2848,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/383,1,['Release'],['Release']
Deployability,o-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -static-libstdc++ -Wno-deprecated-register -Wno-unused-local-typedefs -L/opt/rh/devtoolset-2/root/usr/lib64 -L/opt/rh/devtoolset-2/root/usr/lib CMakeFiles/salmon.dir/QSufSort.c.o CMakeFiles/salmon.dir/is.c.o CMakeFiles/salmon.dir/bwt_gen.c.o CMakeFiles/salmon.dir/bwtindex.c.o CMakeFiles/salmon.dir/xxhash.c.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/SequenceBiasModel.cpp.o CMakeFiles/salmon.dir/StadenUtils.cpp.o CMakeFiles/salmon.dir/TranscriptGroup.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapFileSystem.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndexer.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndex.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAMapper.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapUtils.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/HitManager.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/bit_array.c.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boo,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:1367,install,install,1367,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,"oading positions | Time = 171.81 s; -----------------------------------------; size = 3221360466; -----------------------------------------; | Loading reference sequence | Time = 7.9564 s; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 35.741 ms; -----------------------------------------; Index requested greater than vector's size: 6442720932>6442720932; Index requested greater than vector's size: 6442720996>6442720932; Index requested greater than vector's size: 6442721060>6442720932; Index requested greater than vector's size: 6442721124>6442720932; Index requested greater than vector's size: 6442721188>6442720932; Index requested greater than vector's size: 6442721252>6442720932; Index requested greater than vector's size: 6442721316>6442720932; Index requested greater than vector's size: 6442721380>6442720932; Index requested greater than vector's size: 6442721444>6442720932; ...; ```. The index does not finish loading, and so salmon does not enter read quantification routines. **To Reproduce**. * Which version of salmon was used? 1.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? ; Github release tarball; * Which reference (e.g. transcriptome) was used?; Gencode v32, with additional elements representing genic introns and intergenic spaces.; * Which read files were used?; NCBI SRA run accession GSM2392582; * Which which program options were used?; --no-version-check --libType ISR --threads 4 --seqBias --gcBias --useVBOpt. **Expected behavior**; I expected index loading to complete successfully.; **Desktop (please complete the following information):**; - OS: CentOS6. **Additional context**; I've uploaded the index file archive [here](https://www.icloud.com/iclouddrive/00DWWhkSucg2BTWLuFswSHwvQ#rapmap_issue_8_index) and the transcripts fasta file [here](https://www.icloud.com/iclouddrive/0oCdFG64TJe0IlvkYyIUZRfSQ#rapmap_issue_8_transcripts).",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/463:2727,install,installed,2727,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/463,2,"['install', 'release']","['installed', 'release']"
Deployability,"observe the coverage bias in them. I'd suggest can you please try subsampling randomly across the full `Fastq` if you haven't tried that already.; * `re: subsampling coefficient:` If you are looking for per-CB level mapping rate for your sample that would be very easy to calculate, although getting one number for the full sample might be little tricky since the mapping rate might have large variance across the sample, but it would be an interesting plot to generate, do let us know how it looks in your case.; If you run Alevin with `--dumpFeatures` flag, alevin will generate a file `featureDump.txt`, whose first column will be the per CB level mapping rate i.e. `#mapped reads/#raw reads`. If you wan't absolute values for per-CB reads and mapped reads, it should be in the file `filtered_cb_frequency.txt` and `mappedUMI.txt` respectively.; * `re: cellranger subsampling:` Correct me if I am wrong, when you say cellranger subsampling, do you mean the `cellranger aggregate` pipeline? It's possible you are talking about some other step which I am not aware of but if it's `aggregate` then I think it happens downstream of all the quantification. Indeed coverage bias correction is an important part of the aggregation step but in general it's not the only one and that's why we recommend using the `Seurat` package downstream of the Alevin quantified matrices. We will be more than happy to write a tutorial on, ""how to perform batch correction downstream of Alevin"" but in summary the following steps would be the gist of the process.; - Use Alevin w/o any modification to the `fastq` on both of your sample to generate the gene count matrices. (We have made a major upgrade to the Alevin. We'd recommend using [v0.12.0-alpha](https://github.com/COMBINE-lab/salmon/tree/v0.12.0-alpha) for now, we are planning to make an official release before the end of this week, currently you can use pre-release. Unfortunately, not available on conda yet).; - Import Alevin count matrices into R using ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433169468:1501,pipeline,pipeline,1501,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433169468,1,['pipeline'],['pipeline']
Deployability,"ode. ===========Then I get segmentation fault; ![image](https://user-images.githubusercontent.com/24876498/103153659-191b0100-47cd-11eb-942e-fcd99b3cf2e2.png). 6. gdb salmon <corefile>; It seemed to crash at these functions: fixFasta(), fixFastaMain() ; ![image](https://user-images.githubusercontent.com/24876498/103153694-554e6180-47cd-11eb-9e4e-dc4bfdf7f731.png). Specifically, please provide at least the following information:. * Which version of salmon was used? v1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? compiled; * Which reference (e.g. transcriptome) was used? gencode.vM23.transcripts.fa.gz GRCm38.primary_assembly.genome.fa.gz; * Which read files were used? not quantifying yet, I'm at the indexing step.; * Which which program options were used? salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon_index --gencode. **Expected behavior**; A clear and concise description of what you expected to happen.; Producing directory that contains indexed files to be applied to ""salmon quant"" command. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; 2 pictures: a segmentation fault screenshot and a gdb backtrack screenshot in ""**To Reproduce**"" section. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] : CentOS7; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; - ""uname -a""; Linux 3.10.0-1062.18.1.el7.x86_64 #1 SMP Tue Mar 17 23:49:17 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux; - ""lsb_release -a""; LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch; Distributor ID: CentOS; Description: CentOS Linux release 7.7.1908 (Core); Release: 7.7.1908; Codename: Core; ; **Additional context**; Thanks for your help in advance.; Best,; kai2june",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/609:3900,release,release,3900,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/609,2,"['Release', 'release']","['Release', 'release']"
Deployability,"ode.hpp:17,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/system/system_error.hpp:11,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/exceptions.hpp:22,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/pthread/thread_data.hpp:10,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread_only.hpp:17,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread.hpp:12,; from /gpfs/projects/hpc_support/salmon/include/GenomicFeature.hpp:25,; from /gpfs/projects/hpc_support/salmon/src/GenomicFeature.cpp:22:; /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/pthread/thread_data.hpp:60:5: error: missing binary operator before token ""(""; 60 | #if PTHREAD_STACK_MIN > 0; | ^~~~~~~~~~~~~~~~~; In file included from /gpfs/projects/hpc_support/salmon/external/install/include/boost/functional/hash.hpp:6,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/detail/thread.hpp:41,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread_only.hpp:22:; /gpfs/projects/hpc_support/salmon/external/install/include/boost/container_hash/hash.hpp:130:33: warning: ‘template<class _Arg, class _Result> struct std::unary_function’ is deprecated [-Wdeprecated-declarations]; 130 | struct hash_base : std::unary_function<T, std::size_t> {};; | ^~~~~~~~~~~~~~; In file included from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/string:49,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/exceptions.hpp:20:; /gpfs/software/gcc/13.2.0/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here; 117 | struct unary_function; | ^~~~~~~~~~~~~~; make[2]: *** [src/CMakeFiles/salmon_core.dir/build.make:160: src/CMakeFiles/salmon_core.dir/GenomicFeature.cpp.o] Error 1; make[1]: *** [CMakeFiles/Makefile2:568: src/CMakeFiles/salmon_core.dir/all] Error 2; make: *** [Makefile:1",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/953:1882,install,install,1882,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/953,1,['install'],['install']
Deployability,"ode.v43.basic.annotation.gtf.gz) works fine.; * Which read files were used?; * The issue is reproducible with multiple independent read files. Logs attached are from reads subsampled from [GSM7099349](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM7099349); * Which which program options were used?; * --skipQuant -l A. **Expected behavior**; A clear and concise description of what you expected to happen.; salmon quant finishes without seg fault with `--skipQuant`; **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; Terminal output when `--skipQuant` is on:; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-based) v1.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /share/genomes/human/hg38/gencode_v43/primary_comprehensive/SalmonIndex }; ### [ skipQuant ] => { }; ### [ libType ] => { A }; ### [ mates1 ] => { GSM7099349.R1.fastq }; ### [ mates2 ] => { GSM7099349.R2.fastq }; ### [ output ] => { salmon_out }; ### [ threads ] => { 1 }; Logs will be written to salmon_out/logs; [2023-11-30 09:40:21.543] [jointLog] [info] setting maxHashResizeThreads to 1; [2023-11-30 09:40:21.543] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-11-30 09:40:21.543] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2023-11-30 09:40:21.543] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2023-11-",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/902:1919,update,updates,1919,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/902,1,['update'],['updates']
Deployability,"oduce**; First, I put the UMI in front of the barcode.; `zcat R2.fastq.gz | paste - - - - | awk '{print $1"" ""$2""\n""substr($3,9,8)substr($3,1,8)substr($3,17)""\n""$4""\n""$5}' | pigz -p8 > R2_Alevin.fq.gz`. then, I run Alevin with:; `salmon alevin -lA -i ref_genome/index/ --barcodeLength 8 --umiLength 8 --end 5 -1 fq/R2_Alevin.fq.gz -2 fq/R1.fastq.gz -p 8 --tgMap ref_genome/gencode.vM20.tx2gene.tsv -o alevin_out --dumpUmiGraph --dumpFeatures --dumpCsvCounts --whitelist BC.whitelist`. This seems to work: the library is 47M and the _filtered_cb_frequency.txt_ contains 43M assigned barcodes in total. The _MappedUmi.txt_ contains 18.5M UMIs, fitting perfectly with the reported alignment rate of ~40% (which is relatively low, but OK for this library). Also if I use the `--dumpfq` option, the barcodes and UMIs are nicely attached to the sequencing reads. Strangely, if I sum the entries in the CSV or binary quant matrix, I get ~3.75M reads. ; ; I was able to run the 10x PBMC4k example and there, the sum of the count matrix entries indeed fitted the reported UMI counts and mapping rate. . Specifically, please provide at least the following information:. * Which version of salmon was used?; salmon 0.13.1. * How was salmon installed (compiled, downloaded executable, through bioconda)?; downloaded executable and bioconda give the same result. * Which reference (e.g. transcriptome) was used?; mouse gencode vM20 (mm10). * Which read files were used?; adapted celseq2 protocol. * Which program options were used?; See above. **Expected behavior**; I expected a total of 18.5M counts in the quant matrix, where the sums per barcode fit those reported in the _MappedUmi.txt_ Is my assumption that the quant matrix should only contain integers correct?. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; Ubuntu 18.04.1 LTS. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361:1688,install,installed,1688,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361,1,['install'],['installed']
Deployability,"oduces the error; * human hg38 [gencode v43 basic](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_43/gencode.v43.basic.annotation.gtf.gz) works fine.; * Which read files were used?; * The issue is reproducible with multiple independent read files. Logs attached are from reads subsampled from [GSM7099349](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM7099349); * Which which program options were used?; * --skipQuant -l A. **Expected behavior**; A clear and concise description of what you expected to happen.; salmon quant finishes without seg fault with `--skipQuant`; **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; Terminal output when `--skipQuant` is on:; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-based) v1.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /share/genomes/human/hg38/gencode_v43/primary_comprehensive/SalmonIndex }; ### [ skipQuant ] => { }; ### [ libType ] => { A }; ### [ mates1 ] => { GSM7099349.R1.fastq }; ### [ mates2 ] => { GSM7099349.R2.fastq }; ### [ output ] => { salmon_out }; ### [ threads ] => { 1 }; Logs will be written to salmon_out/logs; [2023-11-30 09:40:21.543] [jointLog] [info] setting maxHashResizeThreads to 1; [2023-11-30 09:40:21.543] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-11-30 09:40:21.543] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set t",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/902:1728,release,releases,1728,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/902,2,"['release', 'upgrade']","['releases', 'upgrade']"
Deployability,"og] [info] contig count for validation: 0; [2020-07-04 15:34:24.274] [puff::index::jointLog] [info] Total # of Contigs : 0; [2020-07-04 15:34:24.274] [puff::index::jointLog] [info] Total # of numerical Contigs : 0; [2020-07-04 15:34:24.274] [puff::index::jointLog] [info]; Total # of segments we have position for : 0; [2020-07-04 15:34:24.277] [puff::index::jointLog] [info] total contig vec entries 0; [2020-07-04 15:34:24.277] [puff::index::jointLog] [info] bits per offset entry 0; [2020-07-04 15:34:24.277] [puff::index::jointLog] [info] there were 0 equivalence classes; [2020-07-04 15:34:24.278] [puff::index::jointLog] [info] # segments = 0; [2020-07-04 15:34:24.278] [puff::index::jointLog] [info] total length = 0; /var/spool/torque/mom_priv/jobs/9244742.blue101.SC: line 23: 23870 Segmentation fault /home/jl2e19/.conda/envs/SALMON/bin/salmon index -t ./gentrome.fa.gz -d ./decoys.txt -p 12 -i /scratch/jl2e19/salmon_index; mkdir: cannot create directory `/scratch/jl2e19/analysed/2020_06_09/salmon/A2_NB_2249': File exists; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v1.1.0; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /scratch/jl2e19/salmon_index }; ### [ libType ] => { A }; ### [ mates1 ] => { /scratch/jl2e19/rnaseq/rawdata/A2_NB_2249_1.fq }; ### [ mates2 ] => { /scratch/jl2e19/rnaseq/rawdata/A2_NB_2249_2.fq }; ### [ validateMappings ] => { }; ### [ output ] => { /scratch/jl2e19/analysed/2020_06_09/salmon/A2_NB_2249/ }; Logs will be written to /scratch/jl2e19/analysed/2020_06_09/salmon/A2_NB_2249/logs; [2020-07-04 15:51:46.138] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-07-04 15:51:46.138] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-07-04 15:51:46.138] ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/543:17809,upgrade,upgrade,17809,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/543,1,['upgrade'],['upgrade']
Deployability,"oject...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```;",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2259,Install,Installing,2259,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,['Install'],['Installing']
Deployability,"ok, this is not really a bug but I think it needs attention. i am using anaconda environment for many tools and keep it updated as much as possible with the `conda update --all` command. but the bottleneck is salmon, which has very old dependencies, and it's a dilemma either to update salmon from 0.8.1 (pretty old buggy version) to the latest one (0.11.3) and downgrade a bunch of other important packages, or vice versa. **Describe the bug**; a bug is a species of animal kingdom, a small insect (just kidding). **To Reproduce**; Steps and data to reproduce the behavior:; ```; $ conda update salmon; Solving environment: done. ## Package Plan ##. environment location: /home/software/anaconda2. added / updated specs: ; - salmon. The following packages will be downloaded:. package | build; ---------------------------|-----------------; salmon-0.11.3 | h86b0361_2 2.9 MB bioconda; blas-1.0 | mkl 6 KB; numpy-1.14.3 | py27h28100ab_1 41 KB; ------------------------------------------------------------; Total: 3.0 MB. The following packages will be UPDATED:. jemalloc: 4.5.0-0 bioconda --> 5.1.0-hfc679d8_0 conda-forge; libgcc-ng: 7.2.0-hdf63c60_3 conda-forge --> 8.2.0-hdf63c60_1 ; libstdcxx-ng: 7.2.0-hdf63c60_3 conda-forge --> 8.2.0-hdf63c60_1 ; salmon: 0.8.1-0 bioconda --> 0.11.3-h86b0361_2 bioconda . The following packages will be DOWNGRADED:. blas: 1.1-openblas conda-forge --> 1.0-mkl ; fastqc: 0.11.7-5 bioconda --> 0.11.6-2 bioconda ; gsl: 2.4-blas_openblash47a8a8e_1 conda-forge [blas_openblas] --> 2.1-2 conda-forge; numpy: 1.15.1-py27_blas_openblashd3ea46f_1 conda-forge [blas_openblas] --> 1.14.3-py27h28100ab_1 ; openjdk: 8.0.144-zulu8.23.0.3_2 conda-forge --> 8.0.121-1 ; scikit-learn: 0.19.2-py27_blas_openblasha84fab4_201 conda-forge [blas_openblas] --> 0.19.1-py27hedc7406_0 ; scipy: 1.1.0-py27_blas_openblash7943236_201 conda-forge [blas_openblas] --> 1.1.0-py27hd20e5f9_0; ```. **Expected behavior**; salmon should be updated to the latest version without the requirement of d",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/286:120,update,updated,120,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/286,5,['update'],"['update', 'updated']"
Deployability,"okies, I think I see the issue. So look at the following lines in the log:; ```; [2019-06-17 21:21:44.518] [alevinLog] [info] Total 824863; [2019-06-17 21:22:47.680] [alevinLog] [info] Total Unique barcodes found: 3474567; ```; What it means is alevin found total: `3,474,567` unique CB in the whole sample and keeps `824,863` CB for further processing which is ~23% of the CB. So all the `keepCBFraction` values above 0.23 would have no effect. If you wan't to generate the `whitelist.txt`, alevin has to have some low confidence CB to learn from, so I am guessing in your case any value from 0.15-0.20 should ideally work. Having said that, I am still exploring why even setting `freqThreshold` to 0, alevin not considers all `3M` CB for processing, I guess there is some kind of filter which is coming into the picture but I might need a bit more time to explore that. I will update here once I figure it out. Thanks again for raising the issue and investing your time in improving alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503344686:879,update,update,879,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503344686,1,['update'],['update']
Deployability,olset-2/root/usr/lib64 -L/opt/rh/devtoolset-2/root/usr/lib CMakeFiles/salmon.dir/QSufSort.c.o CMakeFiles/salmon.dir/is.c.o CMakeFiles/salmon.dir/bwt_gen.c.o CMakeFiles/salmon.dir/bwtindex.c.o CMakeFiles/salmon.dir/xxhash.c.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/SequenceBiasModel.cpp.o CMakeFiles/salmon.dir/StadenUtils.cpp.o CMakeFiles/salmon.dir/TranscriptGroup.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapFileSystem.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndexer.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndex.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAMapper.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapUtils.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/HitManager.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/bit_array.c.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_chrono.a /opt/boost/boost_1_57_0/lib/libboost_program_options.a /opt/boos,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:1515,install,install,1515,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,"on ""5.2.3""); Found liblzma library: /apps/gentoo/usr/lib/liblzma.a; ===========================================; -- Found BZip2: /apps/gentoo/usr/lib/libbz2.a (found version ""1.0.6""); -- Looking for BZ2_bzCompressInit; -- Looking for BZ2_bzCompressInit - found; Found libbz2 library: /apps/gentoo/usr/lib/libbz2.a; ===========================================; -- Looking for pthread.h; -- Looking for pthread.h - found; -- Looking for pthread_create; -- Looking for pthread_create - not found; -- Looking for pthread_create in pthreads; -- Looking for pthread_create in pthreads - not found; -- Looking for pthread_create in pthread; -- Looking for pthread_create in pthread - found; -- Found Threads: TRUE; -- Could NOT find Boost; BOOST_INCLUDEDIR =; BOOST_LIBRARYDIR =; Boost_FOUND = 0; Build system will fetch and build Boost; ==================================================================; Setting Temporary Boost paths; BOOST INCLUDE DIR = $blah/salmon-0.10.2/external/install/include; BOOST INCLUDE DIRS = $blah/salmon-0.10.2/external/install/include; BOOST LIB DIR = $blah/salmon-0.10.2/external/install/lib; BOOST LIBRARIES =; Build system will build libdivsufsort; ==================================================================; Build system will fetch and build the Cereal serialization library; ==================================================================; Build system will fetch and build BWA (for Salmon); ==================================================================; -- Found TBB: /apps/gentoo/usr/include (found suitable version ""2018.0"", minimum required is ""2018.0"") found components: tbb tbbmalloc tbbmalloc_proxy; TBB_LIBRARIES = /apps/gentoo/usr/lib/libtbbmalloc_proxy.so;/apps/gentoo/usr/lib/libtbbmalloc.so;/apps/gentoo/usr/lib/libtbb.so; Build system will compile libgff; ==================================================================; ==================================================================; Build system will compile Staden IOLib; =======",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387:2965,install,install,2965,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387,1,['install'],['install']
Deployability,"on for the problems you are facing in alevin. >Your first question was related to alevin quantifying very less number of reads. To answer that,; if you look at the log, at the first few lines, alevin warns about ~91% of the reads being thrown away because; of the noisy CBs. The problem is alevin’s first “knee"" estimation is overshooting in predicting the first boundary. You will find https://github.com/COMBINE-lab/salmon/issues/362 issue to be; very useful in understanding that. As a summary if you look at the plot I attached it has bi-modalities,; which is generally not the case and alevin is greedily finding the threshold at the first ~100 cells. If this; happens the general direction is to help alevin by proving a upper bound, in case of your data; would be ~14000 cells. You can tell alevin with `—expectCells 14000` and alevin start to work; normally and logs ~12% of the data is noisy. >You second question was a little complicated to answer. Seemingly, your salmon index has transcript with; same exact name `ENST00000399966.9`, occurring twice with different sequences. Just by looking at the index,; I am unsure it’s actually present in the reference or its salmon indexing messing up. If I Assume it was actually; present two times in the reference, alevin should report it instead of exiting abruptly in the middle of quantification.; Although, alevin does warns:; ```; [2019-07-04 14:12:32.519] [alevinLog] [warning] Found 1 transcripts with duplicate names; ```; >However, the bug i.e. not being able to distinguish duplicate names of the transcript, has been ; fixed and pushed in the develop branch of salmon. Alevin was reporting the error at the stage of quantification too, ; if you dump the logs in a file, but it was invisible in the console as it was over written my complex progress bar. . >Once I process it through the modified pipeline, alevin finished normally and I am attaching the quants generated; by alevin. >Thanks again for forwarding the data.; Best,; —Avi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845:2078,pipeline,pipeline,2078,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845,1,['pipeline'],['pipeline']
Deployability,"on the second one and on another one I tested with a segfault but no other information to why that we can see:; ```; salmon quant -i ../data/references/salmon-1.4.0-ncbi-GRCm39_AND_egfp_Annot109 -l ISF \; -1 trimmomatic/AAV_204M_TCCTGGTA_L001_R1_001.fastq.qualtrim.paired.fastq \; -2 trimmomatic/AAV_204M_TCCTGGTA_L001_R2_001.fastq.qualtrim.paired.fastq \; --numBootstraps=30 \; --validateMappings --recoverOrphans \; -o salmon/AAV_204M_TCCTGGTA_L001 \; --seqBias --gcBias --writeUnmappedNames -p 8. #it ran for a while and then did:; processed 3,000,000 fragmentsintLog] [info] First decoy index : 129,698; hits: 760,262, hits per frag: 0.254757Segmentation fault; ```. I tried running just the R1 fastq file and it finished fine without a segfault. Mapping rates were ~15%. **To Reproduce**; Specific to particular fastq files . Specifically, please provide at least the following information:. * Which version of salmon was used?; 1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; compiled using CMake with gcc version 8.2.0 (not by me); easybuild config file is at https://github.com/IGBIllinois/easybuild/blob/master/easyconfigs/s/Salmon/Salmon-1.4.0-IGB-gcc-8.2.0.eb. * Which reference (e.g. transcriptome) was used?; Custom reference of NCBI GRCm39 + egfp protein, although same segfault occurs when using plain GRCm39 that has worked for many other SE and PE projects; * Which read files were used?; Owned by PI; I may or may not be able to send a pair to you; * Which which program options were used?; See above example. **Expected behavior**; Finishing without segfault like the first sample did. I can send you the salmon_quant.log or any other file that would be useful. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; OS CentOS 7.8; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux t",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/668:1307,install,installed,1307,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/668,1,['install'],['installed']
Deployability,"one building index; for info, total work write each : 2.331 total work inram from level 3 : 4.322 total work raw : 25.000 ; Bitarray 528992256 bits (100.00 %) (array + ranks ); final hash 0 bits (0.00 %) (nb in final hash 0). My script to build the above index:. ~/salmon/bin/salmon index \; -t mouse_cDNA_ref/mus_cdna.fa.gz \; -i indexs/alt_long_index \; -k 31. My HPCC run on CentOS. . My script to run salmon quant:. ~/salmon/bin/salmon quant -i mnt/home/oconn341/salmon/indexs/alt_long_index -l A -1 preprocs_fastq/ERAP1_EAE_2270_S4/ERAP1_EAE_2270_S4_R1_001.fastq.gz -2 preprocs_fastq/ERAP1_EAE_2270_S4/ERAP1_EAE_2270_S4_R2_001.fastq.gz -o preprocs_fastq/ERAP1_EAE_2270_S4 --validateMappings --rangeFactorizationBins 4 --gcBias --seqBias. ; **To Reproduce**; Steps and data to reproduce the behavior:. Reproduces every time . Specifically, please provide at least the following information:. * Which version of salmon was used? V1.5.2; * How was salmon installed (compiled, downloaded executable, through bioconda)? Pre-compiled binary ; * Which reference (e.g. transcriptome) was used? Mus_musculus.GRCm39.cdna.all.fa.gz; * Which read files were used? see above; * Which which program options were used? see above. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] CentOS ; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here. I am thinking this is an issue w/ building the index. If there is a pre-made index w/ or w/o decoys for mouse that you can direct me to I would appreciate it. Following the link posted in the salmon documentation about pre-made index's is not helpful and I am not sure how to download them from there. A ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/696:7846,install,installed,7846,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/696,1,['install'],['installed']
Deployability,"onfused following the documentation at https://salmon.readthedocs.io/en/latest/salmon.html) - let me know if my understanding is correct. 1. Is this how to create SAF indices - https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/ - with these steps, I assume I do not have to separately download mashmap and bedtools software. 2. If one has to use SA method, does one still use the generateDecoyTranscriptome.sh method as listed here - https://github.com/COMBINE-lab/SalmonTools/blob/master/scripts/generateDecoyTranscriptome.sh (and this requires the gff file, mashmap and bedtools software). 3. SA and SAF both require genome. Can I still use `salmon index` on the transcriptome file without using genome files? Based on the release notes quoted (copy/pasted) below, I am worried about the phrase `""mapping without selective alignment is disabled""`). . Salmon v1.0 release notes state: . > changes since v.014.1; > In this release of salmon, selective-alignment is enabled by default (and, in fact, mapping without selective-alignemnt is disabled). We may explore, in the future, ways to allow disabling selecive-alignment under the new mapping approach, but at this point, it is always enabled.; > ; ; 4. Page 18 of your preprint pdf states that you used ""salmon v0.15.0 for quasi-mapping"" - so I am assuming I have to keep 2 versions of salmon in my system if I have to do both quasi-mapping and SA/SAF?. 5. Page 19 of your preprint pdf states you used `--mimicBT2 and --useEM for SA and SAF` quantification methods. Is this the recommendation while using SA and SAF methods? ; From salmon v01.4.1 with SA method, I have all along used the default `VBEM `and `--validateMappings` based on info in [SalmonReadTheDocs](https://salmon.readthedocs.io/en/latest/salmon.html#validatemappings) . > Enables selective alignment of the sequencing reads when mapping them to the transcriptome. This can improve both the sensitivity and specificity of mapping and, as a result, can improve",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442:1165,release,release,1165,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442,1,['release'],['release']
Deployability,"or PRs were opened. #### What will this cost?; Nothing! The CodeQL engine will run inside GitHub Actions, making use of your [unlimited free compute minutes for public repositories](https://docs.github.com/en/actions/learn-github-actions/usage-limits-billing-and-administration#about-billing-for-github-actions). #### What types of problems does CodeQL find?; The CodeQL engine that powers GitHub code scanning is the exact same engine that powers LGTM.com. The exact set of rules has been tweaked slightly, but you should see almost exactly the same types of alerts as you were used to on LGTM.com: we’ve enabled the [`security-and-quality` query suite](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs) for you. #### How do I upgrade my CodeQL engine?; No need! New versions of the CodeQL analysis are constantly deployed on GitHub.com; your repository will automatically benefit from the most recently released version. #### The analysis doesn’t seem to be working; If you get an error in GitHub Actions that indicates that CodeQL wasn’t able to analyze your code, please [follow the instructions here](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/troubleshooting-the-codeql-workflow) to debug the analysis. #### How do I disable LGTM.com?; If you have LGTM’s automatic pull request analysis enabled, then you can [follow these steps to disable the LGTM pull request analysis](https://lgtm.com/help/lgtm/managing-automated-code-review#disabling-pr-integration). You don’t actually need to remove your repository from LGTM.com; it will automatically be removed in the next few months as part of the deprecation of LGTM.com ([more info here](https://github.blog/2022-08-15-the-next-step-for-lgtm-com-github-code-scanning/)). #### Which source code hosting platforms does code scanning support?; GitHub c",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/815:3369,release,released,3369,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/815,1,['release'],['released']
Deployability,"or**; I expected the project to build and produce a binary I could use to test my changes. **Desktop (please complete the following information):**; - OS: Ubuntu 18.04; - Version:. ```; lsb_release -a; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 18.04.2 LTS; Release:	18.04; Codename:	bionic; kurt@kurtputer:~/Development/refinebio-collab$ uname -a; Linux kurtputer 4.15.0-51-generic #55-Ubuntu SMP Wed May 15 14:27:21 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux; ```. **Additional context**; I was able to fix the following errors with these resolutions:; ```; ERROR:; CMake Error: The following variables are used in this project, but they are set to NOTFOUND.; Please set them or make sure they are set and tested correctly in the CMake files:; CURL_LIBRARY; linked by target ""salmon"" in directory /home/kurt/Development/salmon/src; linked by target ""unitTests"" in directory /home/kurt/Development/salmon/src; RESOLUTION:; sudo apt-get install libcurl4-openssl-dev; ----------------------------------; ERROR:; Performing download step for 'libbz2'; % Total % Received % Xferd Average Speed Time Time Time Current; Dload Upload Total Spent Left Speed; 100 227 100 227 0 0 1013 0 --:--:-- --:--:-- --:--:-- 1013; 100 16207 0 16207 0 0 34336 0 --:--:-- --:--:-- --:--:-- 166k; bzip2-1.0.6.tar.gz: FAILED; sha256sum: WARNING: 1 computed checksum did NOT match; bzip2-1.0.6.tar.gz did not match expected SHA256! Exiting.; CMakeFiles/libbz2.dir/build.make:89: recipe for target 'libbz2-prefix/src/libbz2-stamp/libbz2-download' failed; make[2]: *** [libbz2-prefix/src/libbz2-stamp/libbz2-download] Error 1; CMakeFiles/Makefile2:183: recipe for target 'CMakeFiles/libbz2.dir/all' failed; make[1]: *** [CMakeFiles/libbz2.dir/all] Error 2; Makefile:162: recipe for target 'all' failed; make: *** [all] Error 2; RESOLUTION:; modifying build.make to pull from sourceforge instead of bzip.org; -----------------------------------------------------------; ERROR:; libtool: compile: /us",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/383:3524,install,install,3524,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/383,1,['install'],['install']
Deployability,"ory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib"", {st_mode=S_IFDIR|0775, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/aja",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:6402,pipeline,pipeline,6402,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"ose that explicitly tag me, but somehow I missed this one) should go to SPAM. So, I've been missing some of the newer issues here. The short answer is that the documentation needs to be updated. When salmon was originally published, we made use of [RapMap](https://github.com/COMBINE-lab/RapMap) as the underlying mapper, which performed quasi-mapping against an index that consisted of a suffix array and a hash over k-mers pointing to prefixes in the suffix array (similar to the strategy used by STAR, but using much longer k-mers to improve lookup speed). We referred to this index as the quasi-index. As the software evolved and we continued to improve the mapping methodology, we eventually transitioned over to an index based on [our pufferfish data structure](https://github.com/COMBINE-lab/pufferfish). In addition to the new data structure, this coincided with our move over to selective-alignment as the mapping algorithm, and all of this happened at the 1.0.0 release (this is why, for example, indices built before 1.0.0 are not compatible with salmon > 1.0.0; a topic on which there have been a few GitHub issues). However, given the fact that the documentation and software are linked only through manual human intervention (we haven't leveled up to e.g. having salmon be a [literate program](https://en.wikipedia.org/wiki/Literate_programming) yet), these two sometimes get out of sync. This is an instance of that. We have maintained the functionality of the `--writeMappings` feature, and in fact, even augmented it. However, we have not replaced the antiquated `quasi-index` terminology in the documentation. The TLDR is that you can use `--writeMappings` with the index you built with the `salmon index` command, and it should work fine. If you are mapping against an index without decoy sequences, then the output format will be basically the same as older (pre 1.0.0) versions. If you have decoy sequences in your index, then there is an optional SAM flag with each record that ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/727#issuecomment-996192524:1113,release,release,1113,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/727#issuecomment-996192524,1,['release'],['release']
Deployability,"ot:. You might have heard that we’ve integrated LGTM’s underlying CodeQL analysis engine natively into GitHub. The result is [**GitHub code scanning**](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/about-code-scanning)!. With LGTM fully integrated into code scanning, we are focused on improving CodeQL within the native GitHub code scanning experience. In order to take advantage of current and future improvements to our analysis capabilities, we suggest you enable code scanning on your repository. Please take a look at our [blog post for more information](https://github.blog/2022-08-15-the-next-step-for-lgtm-com-github-code-scanning/). This pull request enables code scanning by adding an auto-generated [`codeql.yml` workflow file for GitHub Actions](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/setting-up-code-scanning-for-a-repository#setting-up-code-scanning-manually) to your repository — take a look! Whilst we've attempted to make use of the existing configuration that you had on LGTM.com, there may be some differences in environment used to build the project. We hope that in most cases it will not require significant changes to achieve a successful analysis. Check [this page](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#editing-a-code-scanning-workflow) for detailed documentation on how to configure a CodeQL workflow. Questions? Check out the FAQ below!. ### FAQ; <details>; <summary>Click here to expand the FAQ section</summary>. #### How often will the code scanning analysis run?; By default, code scanning will trigger a scan with the CodeQL engine on the following events:; * On every pull request — to flag up potential security problems for you to investigate before merging a PR.; * On every push to your default branch ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/815:1212,configurat,configuration,1212,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/815,1,['configurat'],['configuration']
Deployability,"otation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/${ID}. echo ""**** Job ends ****""; date; ```. The important part is that we are requesting 1 single core with 80 GB of free memory and setting the limit at 90 GB. We are also using the `-p 1` option. . Here is the log file for one of them (task 3):. ```; **** Job starts ****; Mon Mar 6 23:19:13 EST 2017; **** JHPCE info ****; User: lcollado; Job id: 9958683; Job name: step6-txQuant-alzheimer.gsk_phaseII; Hostname: compute-068; Task id: ; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases ; contains new features, improvements, and minor bug fixes; please upgrade at your; earliest convenience.; ###; ### salmon (mapping-based) v0.7.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/R10003_D19KGACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/R10003_D19KGACXX/logs; [1m[2017-03-07 03:00:05.319] [jointLog] [info] parsing read library format; [00m[1m[2017-03-07 03:00:05.337] [jointLog] [info] There is 1 library.; [00m[1m[2017-03-07 03:00:41.948] [jointLog] [info] Loading Quasi index; [00m[1m[2017-03-07 03:00:41.972] [jointLog] [info] Loading 32-bit quasi index; [00m[1m[2017-03-07 03:42:43.689] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-03-07 04:54:34.7",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:2656,pipeline,pipeline,2656,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['pipeline'],['pipeline']
Deployability,"output/salmon }; # [ mates1 ] => { reads_1.fastq }; # [ mates2 ] => { reads_2.fastq }; Logs will be written to output/salmon/logs; there is 1 lib; [2015-08-23 21:58:57.438] [jointLog] [info] parsing read library format; [bns_restore_core] Parse error reading index/hs_ens_ercc.sidx/bwaidx.amb; ```. I've provided a reproducible and self-contained Snakefile that only depends on the binaries being dumped in `~/software` and the reads_*fastq below. Let me know if there is anything I can do to help. Thanks a bunch!. Harold. ---. ``` python; ercc_fa = 'index/ERCC.fa'; ens_fa = 'index/Homo_sapiens.GRCh38.cdna.all.fa'; ens_ercc_fa = 'index/hs_ens_ercc.fa'; ens_ercc_sidx = 'index/hs_ens_ercc.sidx'. SALMON_PRE = '~/software/SalmonBeta-0.4.2_DebianSqueeze'; SALMON = 'LD_LIBRARY_PATH={0}/lib; {0}/bin/salmon'.format(SALMON_PRE). rule all:; input:; ens_ercc_fa,; ens_ercc_sidx,; 'output/salmon/quant.sf'. rule download_ens:; output:; ens_fa; params:; dl = 'ftp://ftp.ensembl.org/pub/release-81/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz'; threads: 1; shell:; 'curl {params.dl} | zcat > {output}'. rule download_ercc:; output:; ercc_fa; params:; dl = 'http://bio.math.berkeley.edu/kallisto/transcriptomes/ERCC.fa.gz'; threads: 1; shell:; 'curl {params.dl} | zcat > {output}'. rule merge_ercc:; input:; ens_fa,; ercc_fa; output:; ens_ercc_fa; shell:; 'cat {input[0]} {input[1]} > {output}'. rule sal_ens_ercc:; input:; ens_ercc_fa; output:; ens_ercc_sidx; threads: 20; shell:; '{SALMON} index -i {output} -p {threads} -t {input}'. rule salmon:; input:; 'reads_1.fastq',; 'reads_2.fastq',; ens_ercc_sidx; output:; 'output/salmon',; 'output/salmon/quant.sf'; shell:; '{SALMON} quant '; '-i {ens_ercc_sidx} '; '--libType IU '; '--output {output[0]} '; '-1 {input[0]} -2 {input[1]}'; ```. Finally, here are the reads:. `reads_1.fastq`:. ```; @SRR896663.1 FCC0AYTACXX:1:1101:1460:1869 length=100; NAAGTGCTTCATTGTCATCCAACTTCAACTCGTTGACTTTATCTATCAGTCCTTCAATGTCGCCCATACCAAGAAGTTTGCTAATAAAAGGCTGTGT",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/12:1682,release,release-,1682,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/12,1,['release'],['release-']
Deployability,"p:256:32: error: ‘class RapMapSAIndex<long int, spp::sparse_hash_map<long unsigned int, rapmap::utils::SAInterval<long int>, rapmap::utils::KmerKeyHasher, std::equal_to<long unsigned int>, spp::libc_allocator<std::pair<const long unsigned int, rapmap::utils::SAInterval<long int> > > > >’ has no member named ‘isDecoy’; decoy = quasiIndex64_->isDecoy(tid);; .../salmon/include/SalmonIndex.hpp:260:43: error: ‘class RapMapSAIndex<int, FrugalBooMap<long unsigned int, rapmap::utils::SAInterval<int> > >’ has no member named ‘isDecoy’; decoy = quasiIndexPerfectHash32_->isDecoy(tid);; .../salmon/include/SalmonIndex.hpp:262:32: error: ‘class RapMapSAIndex<int, spp::sparse_hash_map<long unsigned int, rapmap::utils::SAInterval<int>, rapmap::utils::KmerKeyHasher, std::equal_to<long unsigned int>, spp::libc_allocator<std::pair<const long unsigned int, rapmap::utils::SAInterval<int> > > > >’ has no member named ‘isDecoy’; decoy = quasiIndex32_->isDecoy(tid);; ```. In investigating this further, it appears that the version of RapMap being downloaded and compiled (release salmon-v0.14.1, according to scripts/fetchRapMap.sh) is missing the commit that introduced the isDecoy() function for the RapMapSAIndex class (what appears to be commit COMBINE-lab/RapMap@152ed9026005f4a823988c4893386079aa663a53, with changes in COMBINE-lab/RapMap@55ef430ec8c3b130666c8f3855073a79c6236fb4 on the develop-salmon branch). (Also, was it intentional that two releases of RapMap were made on the same commit? Both salmon-v0.14.0 and salmon-v0.14.1 releases appear to have been made on commit COMBINE-lab/RapMap@89dbe45481dac12ac8cffd6d5d924699c5ad7e04.). Adjusting the fetchRapMap.sh script to use the SVER and EXPECTED_SHA256SUM variables back to their values in commit COMBINE-lab/salmon@cf07385f2164698eda5b9869dd4865fec747840d, then re-running the script, and recompiling produces no errors, and the tests all run. Hope that helps, and thanks for all your work in developing Salmon!. Best regards,; Patrick Reilly",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/418:1458,release,release,1458,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/418,3,['release'],"['release', 'releases']"
Deployability,"parameters. The EffectiveLength though is 250 for all genes across all samples. I've used all four different versions of Salmon as listed below but I'm still getting the same similar mapping rate and the parameters at quant.sf though the values differ a bit from each Salmon version. **To Reproduce**; ### Steps and data to reproduce the behavior: for version 0.8. **First I took the genome fasta file and the gff3 file and made a transcriptome fasta file using Salmon:**; module load Cufflinks/2.2.1; gffread all.gff3 -g all.chrs.fasta -w MSU7_transcript.fasta. **I then indexed the transcript fasta file.**; #!/bin/bash; #SBATCH -N 1; #SBATCH -c 8; #SBATCH --mem=50G; #SBATCH --mail-use=tarun2@illinois.edu; #SBATCH -J index_Salmon. module load Salmon/0.8.2-IGB-gcc-4.9.4-Python-2.7.13. salmon index -t ~/data/genome/MSU7_transcript.fasta -i ~/data/genome/MSU7_transcript.index --type quasi -k 31. **I then run transcript abundance estimate pipeline for the raw-reads and the trimmed reads as follows:**; #!/bin/bash; #SBATCH -N 1; #SBATCH -c 8; #SBATCH --mem=10G; #SBATCH --mail-use=tarun2@illinois.edu; #SBATCH -J Salmon; #SBATCH -a 1-24. module load Salmon/0.8.2-IGB-gcc-4.9.4-Python-2.7.13. line=$(sed -n -e ""$SLURM_ARRAY_TASK_ID p"" ~/source/BLBnew.txt). salmon quant -i ~/data/genome/MSU7_transcript.index -l A \; -1 ~/data/raw-data/BLB/${line}1.fastq.gz \; -2 ~/data/raw-data/BLB/${line}2.fastq.gz --numBootstraps=30 \; -p 12 -o ~/results/salmon_quant_Sheng_old/${line} --seqBias --gcBias. #!/bin/bash; #SBATCH -N 1; #SBATCH -c 8; #SBATCH --mem=10G; #SBATCH --mail-use=tarun2@illinois.edu; #SBATCH -J Salmon; #SBATCH -a 1-24. module load Salmon/0.8.2-IGB-gcc-4.9.4-Python-2.7.13. line=$(sed -n -e ""$SLURM_ARRAY_TASK_ID p"" ~/source/BLBnew.txt). salmon quant -i ~/data/genome/MSU7_transcript.index -l A \; -1 ~/results/trimmingSheng/${line}1.paired.fastq \; -2 ~/results/trimmingSheng/${line}2.paired.fastq --numBootstraps=30 \; -p 12 -o ~/results/salmon_quant_Sheng_new/${line} --seqBias --gcBi",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346:1593,pipeline,pipeline,1593,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346,1,['pipeline'],['pipeline']
Deployability,"pdate this later). > Why am I seeing much higher values for this gene with FeatureCounts?. I have now run FeatureCounts several times with different overlaps (minOverlap =25, minOverlap =50, minOverlap =75min Overlap =100) and indeed the counts have decreased (again the psbI example: 8685 , 6011, 4237, 1805 accordingly). Again, this is a good argument for the hypothesis put forward. >Why does running Salmon outside nf-core lead to much higher values?. Hopefully, after I run Decoy mode, this problem is solved. I also tried mapping mode with the --softclipOverhangs option. That increased the counts (psbI : 4696 counts); playing around with the --minScoreFraction flag in addition to the --softclipOverhangs flag also increased the numbers ( minScoreFraction= 0 ->psbI = 8496; minScoreFraction= 0.5 ->psbI = 5633; minScoreFraction= 0.7 ->psbI =3627 ). . So, in summary, your explanation seems to be completely correct. ; In the case that decoy mode resolves the difference between the pipeline and the run outside the pipeline, I would not give this to the nf-core people. But I will if there are still large discrepancies after the run. I'm still not sure what the best parameters are for my analysis, but the --softclipOverhangs flag seems to be the best option for me now.; So thanks again!. @drpatelh. Thank you very much for your quick reply as well. ; I was a bit inaccurate when I said I used the FeatureCounts from the pipeline. I actually wasn't able to use the resulting .txt files. Instead, I used the resulting bam file from the pipeline to perform a FeatureCounts analysis on R. I hope this information answers the question of how I can compare the two results?; My genome and gtf file are from [EnsemblPlants](https://plants.ensembl.org/Arabidopsis_thaliana/Info/Index), so they should be fine. In the MultiQC file, the vast majority of reads align to protein coding regions according to FeatureCounts, so I hope my primary files are fine. . Thanks again for your help and time!. A",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1238043213:1923,pipeline,pipeline,1923,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1238043213,2,['pipeline'],['pipeline']
Deployability,"piled with Bioconda. I am now trying to get the latest version through Bioconda and with the same ""salmon quant"" command (See below) that works on the old version, I get a ""segmentation fault 11"" error and it never actually quantifies any reads. Do you know why this would happen?. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; 0.11.3; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Bioconda; * Which reference (e.g. transcriptome) was used?; gencode.v27.transcripts.fa; * Which read files were used?; fastq; * Which which program options were used?; -l A, single end . **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. ```; salmon quant -i ~/Reference_indexes/humangencodev27_transcripts_index_20181023 -l A -r ~/Downloads/ENCFF600FYP.fastq.gz -o ./salmon_test/ENCFF600FYP_quant; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.11.3; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { ~/Reference_indexes/humangencodev27_transcripts_index_20181023 }; ### [ libType ] => { A }; ### [ unmatedReads ] => { ~/Downloads/ENCFF600FYP.fastq.gz }; ### [ output ] => { ./salmon_test/ENCFF600FYP_quant }; Logs will be written to ./salmon_test/ENCFF600FYP_quant/logs; [2018-10-23 20:11:13.424] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-10-23 20:11:13.425] [jointLog] [info] parsing read library format; [2018-10-23 20:11:13.425] [jointLog] [info] There is 1 library.; [2018-10-23 20:11:13.513] [stderrLog] [info] Loading Suffix Array ; [2018-10-23 20:11:13.513] [jointLog] [info] Loading Quasi index; [2018-10-23 20:11:13.513] [jointLog] [info] Loading 32-bit quasi index; [2018-10-23 20:11:14",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/303:1259,upgrade,upgrade,1259,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/303,1,['upgrade'],['upgrade']
Deployability,"pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/sa.bin"", O_RDONLY) = 4; clock_gettime(CLOCK_REALTIME, {1491424830, 149197282}) = 0; read(4, ""l\n\221\21\0\0\0\0k\n\221\21\373\25\343\20\17\254\r\1\36\27\227\n\37\371\270\4\250\210\307\f""..., 8191) = 8191; mmap(NULL, 1342177280, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7ffe2e5e8000; munmap(0x7ffe2e5e8000, 1342177280) = 0; mmap(NULL, 1344270336, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7ffe2e3e9000; munmap(0x7ffe2e3e9000, 94208) = 0; munmap(0x7ffe7e400000, 1998848) = 0; [1m[2017-04-05 16:40:30.149] [stderrLog] [info] Loading Suffix Array ; [00m[1m[2017-04-05 16:40:30.069] [jointLog] [info] Loading Quasi index; [00m[1m[2017-04-05 16:40:30.139] [jointLog] [info] Loading 32-bit quasi index; [00mread(4, ""\16'w=\r\320m\306\0\35\26\306\0\224\23\270\10\205]D\0|\3!\4c_-\7\310O\2""..., 1178864057) = 1178864057; close(4) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts/txpInfo.bin"", O_RDONLY) = 4; clock_gettime(CLOCK_REALTIME, {1491424833, 297142816}) = 0; read(4, ""\315\5\3\0\0\0\0\0|\0\0\0\0\0\0\0ENST00000456328.""..., 8191) = 8191; read(4, ""RP4-669L17.8-001|RP4-669L17.8|12""..., 8191) = 8191; read(4, "".2|LINC01128-004|LINC01128|874|l""..., 8191) = 8191; read(4, ""THUMT00000097991.1|AGRN-002|AGRN""..., 8191) = 8191; read(4, ""HUMG00000001412.6|OTTHUMT0000000""..., 8191) = 8191; read(4, ""F3L-007|CPSF3L|1868|protein_codi""..., 8191) = 8191; read(4, ""01413.3|OTTHUMT00000004082.2|AUR""..., 8191) = 8191; read(4, ""UMT00000001363.3|ATAD3A-001|ATAD""..., 8191) = 8191; read(4, ""DK11B-202|CDK11B|2490|protein_co""..., 8191) = 8191; read(4, ""00002763.1|GNB1-002|GNB1|1512|re""..., 8191) = 8191; read(4, ""20-006|FAAP20|569|protein_coding""..., 8191) = 8191; read(4, ""212.1|ENSG00000157881.13|OTTHUMG""..., 8191) = 8191; read(4, ""0563.3|OTTHUMT00000099318.1|LINC""..., 8191) = 8191; rea",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:167601,pipeline,pipeline,167601,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"pmap/bit_array.c.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_chrono.a /opt/boost/boost_1_57_0/lib/libboost_program_options.a /opt/boost/boost_1_57_0/lib/libboost_serialization.a ../../external/install/lib/libstaden-read.a -lz ../../external/install/lib/libdivsufsort.a ../../external/install/lib/libdivsufsort64.a ../../external/install/lib/libjellyfish-2.0.a ../../external/install/lib/libbwa.a -lm ../../external/install/lib/liblzma.a -lbz2 -ltbb -ltbbmalloc -lgomp -lrt ../../external/install/lib/libjemalloc.a -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib""; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xd26): warning: the use of `tempnam' is dangerous, better use `mkstemp'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `tbb::strict_ppl::internal::concurrent_queue_base_v3<UnpairedRead*>::internal_push(void const*, void (*)(UnpairedRead**, void const*)) [clone .constprop.1465]':; SalmonQuantifyAlignments.cpp:(.text+0x136d): undefined reference to `tbb::internal::throw_exception_v4(tbb::internal::exception_id)'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `tbb::strict_ppl::internal::concurrent_queue_base_v3<ReadPair*>::internal_push(void const*, void (*)(ReadPair**, void const*)) [clone .constprop.1477]':; SalmonQuantifyAlig",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:2805,install,install,2805,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,"poly-A tails from 0 transcripts; [2020-04-07 21:12:14.599] [jointLog] [info] Building rank-select dictionary and saving to disk; [2020-04-07 21:12:14.599] [jointLog] [info] done; Elapsed time: 5.7764e-05s; [2020-04-07 21:12:14.606] [jointLog] [info] Writing sequence data to file . . . ; [2020-04-07 21:12:14.607] [jointLog] [info] done; Elapsed time: 0.000590993s; [2020-04-07 21:12:14.614] [jointLog] [info] Building 32-bit suffix array (length of generalized text is 28,577); [2020-04-07 21:12:14.616] [jointLog] [info] Building suffix array . . . ; success; saving to disk . . . done; Elapsed time: 0.000716831s; done; Elapsed time: 0.0107059s; ```; Specifically, please provide at least the following information:. * Which version of salmon was used? 1.1.0, 1.0.0 and 0.14.1; * How was salmon installed (compiled, downloaded executable, through bioconda)? GitHub binary; * Which reference (e.g. transcriptome) was used? sample data from GitHub release; * Which read files were used? none; * Which which program options were used? -k 31 -i index -t sample_data/transcripts.fasta. **Expected behavior**; A clear and concise description of what you expected to happen.; I expected salmon 1.1.0 to run without a core-dump and produce similar results to 0.14.1. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Ubuntu 18.04.4 LTS; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; Linux firefly 5.3.0-40-generic #32~18.04.1-Ubuntu SMP Mon Feb 3 14:05:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. **Additional context**; Using ""bcbio-nextgen"", with ""salmon 1.1.0"" installed by Anaconda: Removed this version because of core-dumps and installed the binary releases of ""salmon"" 1.1.0 then 0.41.1 from GitHub in /usr/local. Did stand-alone tests with sample data from the GitHub binary release.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500:3346,install,installed,3346,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500,4,"['install', 'release']","['installed', 'release', 'releases']"
Deployability,"possible with the `conda update --all` command. but the bottleneck is salmon, which has very old dependencies, and it's a dilemma either to update salmon from 0.8.1 (pretty old buggy version) to the latest one (0.11.3) and downgrade a bunch of other important packages, or vice versa. **Describe the bug**; a bug is a species of animal kingdom, a small insect (just kidding). **To Reproduce**; Steps and data to reproduce the behavior:; ```; $ conda update salmon; Solving environment: done. ## Package Plan ##. environment location: /home/software/anaconda2. added / updated specs: ; - salmon. The following packages will be downloaded:. package | build; ---------------------------|-----------------; salmon-0.11.3 | h86b0361_2 2.9 MB bioconda; blas-1.0 | mkl 6 KB; numpy-1.14.3 | py27h28100ab_1 41 KB; ------------------------------------------------------------; Total: 3.0 MB. The following packages will be UPDATED:. jemalloc: 4.5.0-0 bioconda --> 5.1.0-hfc679d8_0 conda-forge; libgcc-ng: 7.2.0-hdf63c60_3 conda-forge --> 8.2.0-hdf63c60_1 ; libstdcxx-ng: 7.2.0-hdf63c60_3 conda-forge --> 8.2.0-hdf63c60_1 ; salmon: 0.8.1-0 bioconda --> 0.11.3-h86b0361_2 bioconda . The following packages will be DOWNGRADED:. blas: 1.1-openblas conda-forge --> 1.0-mkl ; fastqc: 0.11.7-5 bioconda --> 0.11.6-2 bioconda ; gsl: 2.4-blas_openblash47a8a8e_1 conda-forge [blas_openblas] --> 2.1-2 conda-forge; numpy: 1.15.1-py27_blas_openblashd3ea46f_1 conda-forge [blas_openblas] --> 1.14.3-py27h28100ab_1 ; openjdk: 8.0.144-zulu8.23.0.3_2 conda-forge --> 8.0.121-1 ; scikit-learn: 0.19.2-py27_blas_openblasha84fab4_201 conda-forge [blas_openblas] --> 0.19.1-py27hedc7406_0 ; scipy: 1.1.0-py27_blas_openblash7943236_201 conda-forge [blas_openblas] --> 1.1.0-py27hd20e5f9_0; ```. **Expected behavior**; salmon should be updated to the latest version without the requirement of downgrading of its dependencies. Linux nscc04 2.6.32-696.30.1.el6.x86_64 #1 SMP Fri May 18 11:50:44 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/286:1943,update,updated,1943,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/286,1,['update'],['updated']
Deployability,"probably unrelated, but also unexpected. Make test on my linux and osx box looks like:. ```; $ make test; Running tests...; Test project /Users/rob/salmon/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.13 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 0.87 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 0.39 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 1.41 sec; ```. It looks the same on the continuous integration server : . ```; Running tests...; /usr/local/cmake-3.9.2/bin/ctest --force-new-ctest-process ; Test project /home/travis/build/COMBINE-lab/salmon/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.13 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 2.55 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.72 sec; 100% tests passed, 0 tests failed out of 3; Total Test time (real) = 4.41 sec; ```. Also, you can look, in the build directory, in the subdirectory `Testing/Temporary/LastTestsFailed.log` which will give details of which specific test failed.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393676260:551,continuous,continuous,551,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393676260,2,"['continuous', 'integrat']","['continuous', 'integration']"
Deployability,problem in installing salmon,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453:11,install,installing,11,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453,1,['install'],['installing']
Deployability,"pt/rh/devtoolset-4/root/usr/bin/c++ -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -rdynamic CMakeFiles/unitTests.dir/__/tests/UnitTests.cpp.o CMakeFiles/unitTests.dir/FragmentLengthDistribution.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/bit_array.c.o -o unitTests -L/home/mathog/src/salmon/lib -L/home/mathog/src/salmon/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" libsalmon_core.a libalevin_core.a -lgff -lpthread ../external/install/lib/libstaden-read.a -lz ../external/install/lib/libdivsufsort.a ../external/install/lib/libdivsufsort64.a ../external/install/lib/libbwa.a -lm -llzma -lbz2 -ltbb -lgomp -lrt ../external/install/lib/libjemalloc.a -lrt -ldl ../external/install/lib/libjemalloc.a -ldl`. Oh, I also had to update automake and autoconf because the 2 year old versions on this system were not new enough. Is there a static binary version of salmon available for download, Linux 64 bit? It looks like the default links are that way anyway, and that would save me what looks like at least another day of fighting with Cmake to force it to actually build a working make file. . You are developing on something like a recent Fedora or Ubuntu? In my experience packages which use boost and cmake inevitably cause a great great d",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:2970,install,install,2970,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['install'],['install']
Deployability,"pts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/${ID}; **** Job ends ****; Wed Mar 8 11:37:36 EST 2017; ```. and the core dump file shows that the program was terminated:. ```bash; $ gdb core.41232; GNU gdb (GDB) Red Hat Enterprise Linux (7.2-60.el6_4.1); Copyright (C) 2010 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>...; Missing separate debuginfo for the main executable file; Try: yum --disablerepo='*' --enablerepo='*-debug*' install /usr/lib/debug/.build-id/f2/3c99ed06abf17dd0ee1073eac092487ac62314; [New Thread 41232]; [New Thread 41236]; [New Thread 41235]; [New Thread 41234]; Core was generated by `/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/b'.; Program terminated with signal 6, Aborted.; #0 0x0000003612832625 in ?? (); ""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/core.41232"" is a core file.; Please specify an executable to debug.; (gdb) q; ```. The SGE information shows that it basically reached 10.7 GB of RAM:. ```bash; $ qacct -j 9987275 -t 3; ==============================================================; qname shared.q; hostname compute-051.cm.cluster; group lieber_jaffe; owner lcollado; project NONE; department defaultdepartment; jobname step6-salmon_test.gsk_phaseII; jobnumber 9987275; taskid 3; account sge; priority 0; qsub_time Wed Mar 8 11:37:17 2017; start_time Wed Mar 8 11:37:31 2017; end_time Wed Mar 8 11:37:36 2017; granted_pe local; slots 1; failed 0; exit_status 0; ru_wallclock 5; ru_utime 0.368; ru_stime 3.680; ru_maxrss 537668; ru_ixrss 0; ru_ismrss 0; ru_idrss 0; ru_isrss 0; ru_",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:25305,pipeline,pipeline,25305,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['pipeline'],['pipeline']
Deployability,"quences. It is recommended that decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be provided during index ing. Further details can be found at https://salmon.readthedocs.io/en/latest/sal mon.html#preparing-transcriptome-indices-mapping-based-mode.; [2022-08-22 15:07:03.860] [jLog] [info] building index; out : transcripts_index; [2022-08-22 15:07:03.860] [puff::index::jointLog] [info] Running fixFasta. [Step 1 of 4] : counting k-mers. [2022-08-22 15:07:03.865] [puff::index::jointLog] [info] Replaced 0 non-ATCG nuc leotides; [2022-08-22 15:07:03.865] [puff::index::jointLog] [info] Clipped poly-A tails fr om 0 transcripts; wrote 0 cleaned references; [2022-08-22 15:07:03.865] [puff::index::jointLog] [info] Filter size not provide d; estimating from number of distinct k-mers; [2022-08-22 15:07:03.866] [puff::index::jointLog] [info] ntHll estimated 47270 d istinct k-mers, setting filter size to 2^20; Threads = 2; Vertex length = 31; Hash functions = 5; Filter size = 1048576; Capacity = 2; Files:; transcripts_index/ref_k31_fixed.fa; --------------------------------------------------------------------------------; Round 0, 0:1048576; Pass Filling Filtering; terminate called without an active exception; Aborted (core dumped). **To Reproduce**; Steps and data to reproduce the behavior:; salmon index -t contigs_for_salmon -i transcripts_index -k 31; my reads are paired end RNA-reads (rRNA REMOVED); My transcriptome is a 90 contigs resulted from reads assembly; Specifically, please provide at least the following information:. * Which version of salmon was used?; * ; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * Which reference (e.g. transcriptome) was used?; * Which read files were used?; * Which which program options were used?; 1.9.0 (latest). **Expected behavior**; use salmon index for Preparing transcriptome indices. **Desktop (please complete the following information):**; - OS: ubuntu 20.04.4 LTS",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/795:1959,install,installed,1959,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/795,1,['install'],['installed']
Deployability,question about the transcriptome for salmon pipeline,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/773:44,pipeline,pipeline,44,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/773,1,['pipeline'],['pipeline']
Deployability,"r -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message):; Could NOT find Iconv (missing: Iconv_LIBRARY); Call Stack (most recent call first):; /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE); /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindIconv.cmake:120 (find_package_handle_standard_args); CMakeLists.txt:362 (find_package). -- Configuring incomplete, errors occurred!; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeOutput.log"".; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeError.log"".; ```; I'm also attaching the full CMake logs. This is right at the edge of my knowledge, so I'm not 100% sure I got libiconv installed correctly. Compilation completed without error, and I added the bin, include, and lib directories to PATH, CPATH, and LD_LIBRARY_PATH, respectively. [CMakeError.log](https://github.com/COMBINE-lab/salmon/files/6665942/CMakeError.log); [CMakeOutput.log](https://github.com/COMBINE-lab/salmon/files/6665943/CMakeOutput.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:2814,install,installed,2814,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,1,['install'],['installed']
Deployability,"r barcode and UMI tags in the alevin generated BAM/SAM (with the `--writeMappings` flag). We have been testing this out, and have been able to access all this information by parsing through the SAM file. However in the end our plan to use this with [Vireo](https://vireosnp.readthedocs.io/en/latest/index.html) and [cellSNP](https://github.com/single-cell-genetics/cellSNP) for genetic demultiplexing of samples didn't really work out, mainly because `alevin` generates a transcriptomic BAM, and `cellSNP` expects a genomic BAM and VCF. I tried a few different options for getting this to work, including (i) attempting to convert to a genomic BAM using [sam-xlate](https://github.com/mozack/ubu/wiki) (which didn't seem to work because `sam-xlate` is designed to convert in the other direction), and (ii) converting the VCF to transcriptomic coordinates, as suggested [here](https://github.com/single-cell-genetics/cellSNP/issues/14) by the `Vireo`/`cellSNP` authors (the VCF conversion seemed to work, but `cellSNP` still didn't match it to the BAM properly). For now, I think we are going to go back to using `Cell Ranger` in our pipeline, since this did work with `Vireo`/`cellSNP`, although was of course much slower than `alevin` and has issues with multi-mapping reads. If you have any other ideas please let me know too. However I also wanted to suggest that if there is any interest on your end in developing some sort of conversion tool (transcriptomic BAM -> genomic BAM) for `alevin` outputs, then I think this would be super useful for people, especially if these genetic demultiplexing tools become more widely used. (We have been getting very good demultiplexing performance with `Cell Ranger` + `Vireo`/`cellSNP`, and are planning to release some of our code as a small `Snakemake` pipeline for others to use, so if it were somehow possible to update this to use `alevin` in the future we would be very interested in this.). Thanks again for your help and previous responses on Slack.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/550:1302,pipeline,pipeline,1302,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/550,4,"['pipeline', 'release', 'update']","['pipeline', 'release', 'update']"
Deployability,"r command, and the file is there!. Here's my patch. Any idea what may be wrong with it, or which different approach I could try to get this to work?; I also tried using the `2.1.3.tar.gz` tarball from GitHub, but after adding `autoreconf -i` to the `CONFIGURE_COMMAND`, this leads to the same problem. ``` diff; --- salmon-0.4.2/CMakeLists.txt.orig 2015-06-15 02:31:09.000000000 +0200; +++ salmon-0.4.2/CMakeLists.txt 2015-08-18 21:13:29.684010359 +0200; @@ -357,14 +366,14 @@; message(""==================================================================""); ExternalProject_Add(libjellyfish; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; - URL ftp://ftp.genome.umd.edu/pub/jellyfish/jellyfish-2.1.3.tar.gz; - SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.1.3; + URL https://github.com/gmarcais/Jellyfish/releases/download/v2.2.3/jellyfish-2.2.3.tar.gz; + SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.2.3; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; - CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.1.3/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CXXFLAGS=${JELLYFISH_CXX_FLAGS}; + CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.2.3/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CXXFLAGS=${JELLYFISH_CXX_FLAGS}; BUILD_COMMAND ${MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CXXFLAGS=${JELLYFISH_CXX_FLAGS}; BUILD_IN_SOURCE 1; INSTALL_COMMAND make install && ; - cp config.h <INSTALL_DIR>/include/jellyfish-2.1.3/jellyfish/ &&; + cp config.h <INSTALL_DIR>/include/jellyfish-2.2.3/jellyfish/ &&; cp config.h <INSTALL_DIR>/include/; ). --- salmon-0.4.2/src/CMakeLists.txt.orig 2015-08-18 21:21:14.892734948 +0200; +++ salmon-0.4.2/src/CMakeLists.txt 2015-08-18 21:20:51.292295094 +0200; @@ -42,7 +42,7 @@; ${GAT_SOURCE_DIR}/external; ${GAT_SOURCE_DIR}/external/cereal/include; ${GAT_SOURCE_DIR}/external/install/include; -${GAT_SOURCE",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/11:1906,install,install,1906,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/11,1,['install'],['install']
Deployability,"r message:. ```; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.347] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.347] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.347] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.347] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ m",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:1651,release,release,1651,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['release'],['release']
Deployability,r/bwt_gen.c.o CMakeFiles/salmon.dir/bwtindex.c.o CMakeFiles/salmon.dir/xxhash.c.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/SequenceBiasModel.cpp.o CMakeFiles/salmon.dir/StadenUtils.cpp.o CMakeFiles/salmon.dir/TranscriptGroup.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapFileSystem.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndexer.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndex.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAMapper.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapUtils.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/HitManager.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/bit_array.c.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_chrono.a /opt/boost/boost_1_57_0/lib/libboost_program_options.a /opt/boost/boost_1_57_0/lib/libboost_serialization.a ../../external/install/lib/libstaden-read.a -lz ../../external/install/lib/libdivsufsort.a ../../ex,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:1660,install,install,1660,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,"r/local/salmon-0.10.2/include/SalmonUtils.hpp:21,; from /usr/local/salmon-0.10.2/include/ReadPair.hpp:7,; from /usr/local/salmon-0.10.2/include/AlignmentGroup.hpp:15,; from /usr/local/salmon-0.10.2/include/AlignmentLibrary.hpp:12,; from /usr/local/salmon-0.10.2/src/SalmonQuantifyAlignments.cpp:39:; /usr/local/salmon-0.10.2/include/eigen3/Eigen/src/Core/AssignEvaluator.h:90:50: warning: enum constant in boolean context [-Wint-in-bool-context]; MaySliceVectorize = bool(MightVectorize) && bool(DstHasDirectAccess); ^~~~~~~~~~~~~~~~~~~~~~~~; At global scope:; cc1plus: warning: unrecognized command line option ‘-Wno-unused-local-typedef’; cc1plus: warning: unrecognized command line option ‘-Wno-unused-local-typedef’; make[2]: *** [src/CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o] Error 1; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; make: *** [all] Error 2; ```. I also tried installing it through bioconda. Apparently, it installs it correctly, but when I try to use Trinity (I'm installing Salmon as a Trinity requirement) this is what happens: . ```; salmon: /opt/conda/conda-bld/salmon_1528409373758/work/salmon-0.10.2/include/eigen3/Eigen/src/Core/util/Memory.h:161: void* Eigen::internal::aligned_malloc(std::size_t): Assertion `(size<16 || (std::size_t(result)%16)==0) && ""System's malloc returned an unaligned pointer. Compile with EIGEN_MALLOC_ALREADY_ALIGNED=0 to fallback to handmade alignd memory allocator.""' failed.; Error, cmd:; salmon --no-version-check quant -i /home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa.out/Trinity.fasta.tmp.salmon.idx -l U -r /home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa.out/single.fa -o salmon_outdir -p 1 --minAssignedFrags 1; died with ret (6) at /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/../../PerlLib/Process_cmd.pm line 19.; Process_cmd::process_cmd(""salmon --no-version-check quant -i /h",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403:1198,install,installs,1198,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403,2,['install'],"['installing', 'installs']"
Deployability,"r/rlang_error>; Error in `[[<-`:; ! Cannot add new cells with [[<-; ---; Backtrace:; ▆; 1. ├─methods (local) `[[<-`(`*tmp*`, ""slice"", value = `<VisiumV2[,600]>`); 2. └─SeuratObject (local) `[[<-`(`*tmp*`, ""slice"", value = `<VisiumV2[,600]>`); Run rlang::last_trace(drop = FALSE) to see 1 hidden frame.; ```. I checked that Seurat has not changed the `sobj[[""ASSAYNAME""]] <- MYASSAYOBJECT` syntax in the same R session by following [this tutorial](https://satijalab.org/seurat/articles/multimodal_vignette) up to the line where the `adt` assay is added and confirmed that the resulting object had two assays present. I think this may be a versioning issue related to what types of objects can be added into layers (aka slots) in a Seurat object. For reference, here are some details of the objects involved:; ```; > class(brain); [1] ""Seurat""; attr(,""package""); [1] ""SeuratObject""; > class(image.data); [1] ""VisiumV2""; attr(,""package""); [1] ""Seurat""; ```. It is worth noting that I installed Salmon using the docker image found [here](https://hub.docker.com/r/combinelab/salmon) approximately three months ago. The version number I see is `1.10.3`. Below is my sessionInfo output as well. My best guess is that I have to adjust the object type for `image.data` here to something that can be coerced into a slot in the `brain` Seurat object, but I am not sure what object that should be. Let me know if I am making a simple mistake here too, I am quite rusty with the nuances of R. Thank you for your consideration and I hope to hear from the team soon!. ```; > sessionInfo(); R version 4.3.3 (2024-02-29); Platform: x86_64-conda-linux-gnu (64-bit); Running under: Ubuntu 22.04.4 LTS. Matrix products: default; BLAS/LAPACK: /home/chris/anaconda3/envs/r_and_python/lib/libopenblasp-r0.3.27.so; LAPACK version 3.12.0. locale:; [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ; [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ; [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ; [7] LC_PAPER=en_US.UTF-8 LC_NAME=C",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/942:1514,install,installed,1514,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/942,1,['install'],['installed']
Deployability,"ranscript (as it should).; The problem is that (at least for some transcripts) we're getting abundance estimates for the copy of a transcript that's on a contig, but not estimates for the copy on the regular chromosome.; In short, it's picking the wrong duplicate. What we're after is a way to get it to prioritize the copies on chromosomes over the copies on contigs. **To Reproduce**. * Salmon version 0.10.2; * Salmon installed through bioconda.; * Reference grch38. All cdnas and ncrnas.; * Reads were single-end; * Program options: salmon quant -p 48 --seqBias --gcBias --biasSpeedSamp 5 -l A . **Expected behavior**; That the selected duplicate reference transcript would be the one on the chromosome, rather than the contig.; In particular, the LTA gene is of interest to us. In grch38, the two ids are [ENSG00000226979](https://useast.ensembl.org/Homo_sapiens/Gene/Summary?g=ENSG00000226979;r=6:31572054-31574324) (on chr6) and [ENSG00000231408](https://useast.ensembl.org/Homo_sapiens/Gene/Summary?g=ENSG00000231408;r=CHR_HSCHR6_MHC_MANN_CTG1:31611502-31613772) (on CHR_HSCHR6_MHC_MANN_CTG1). Each of the transcripts of these two genes has an identical copy in the other gene. The transcripts for both genes appear in the duplicate_clusters.tsv file in the salmon index directory. ; When we quant, only transcripts of ENSG00000231408 appear in the output. We would rather that ENSG00000226979 be the one to appear. What is the best way forward to accomplish this? Should we just remove the contig transcripts from the reference?. **Desktop:**; - OS: Centos Linux; - `uname -a`: 3.10.0-862.2.3.el7.x86_64 #1 SMP Wed May 9 18:05:47 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux; - `lsb_release -a`: LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch; Distributor ID: CentOS; Description: CentOS Linux release 7.5.1804 (Core); Release: 7.5.1804; Codename: Core",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/249:2244,release,release,2244,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/249,2,"['Release', 'release']","['Release', 'release']"
Deployability,"rded fragments. The difference is that every fragment can have many potential mappings. The number you are looking at is the total number of attempted alignments that failed to achieve the threshold score. Luckily, salmon reports both numbers. The number of fragments for which all alignments failed to reach the score threshold is 4,196,417; given in aux_info.json by ""num_fragments_filtered_vm"": 4196417. One point to note is that these are all fragments for which mapping is attempted (they had at least one k-mer match the reference), but no alignment was valid up to the threshold. You could try running the quantification again with --softclip to allow softclipping of the reads and see if any considerable fraction of these 4196417 failed to align because they overhang the annotated transcripts or contain adapters etc. Nonetheless, even if all of these mapped, the rate would still be ~72%. The remainder of the reads didn't even have a matching k-mer in common with the reference transcriptome, which means they are exceedingly unlikely to have come from the transcripts that were indexed. Further explanation of what these metadata numbers mean would be very helpful to me. Also useful would be a statistic (or more than one statistic) that fully categorises the read alignments or non-alignments. **Desktop (please complete the following information):**; - OS: Debian; - `uname-a`: Linux musculus 6.7.9-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.7.9-2 (2024-03-13) x86_64 GNU/Linux; - `lsb_release -a`; ```; No LSB modules are available.; Distributor ID: Debian; Description: Debian GNU/Linux trixie/sid; Release: n/a; Codename: trixie; ```. **Additional context**. I'm not really after an explanation of why read mapping rates are low in my specific case, I'm after an explanation *in the documentation* of why read mapping rates from Salmon are generally low. Update: I've just confirmed that trimming doesn't have any substantial impact on the results for our first sample [AG1232_001_MR1].",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/925:9539,Release,Release,9539,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/925,2,"['Release', 'Update']","['Release', 'Update']"
Deployability,"rder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -rdynamic CMakeFiles/unitTests.dir/__/tests/UnitTests.cpp.o CMakeFiles/unitTests.dir/FragmentLengthDistribution.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/bit_array.c.o -o unitTests -L/home/mathog/src/salmon/lib -L/home/mathog/src/salmon/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" libsalmon_core.a libalevin_core.a -lgff -lpthread ../external/install/lib/libstaden-read.a -lz ../external/install/lib/libdivsufsort.a ../external/install/lib/libdivsufsort64.a ../external/install/lib/libbwa.a -lm -llzma -lbz2 -ltbb -lgomp -lrt ../external/install/lib/libjemalloc.a -lrt -ldl ../external/install/lib/libjemalloc.a -ldl`. Oh, I also had to update automake and autoconf because the 2 year old versions on this system were not new enough. Is there a static binary version of salmon available for download, Linux 64 bit? It looks like the default links are that way anyway, and that would save me what looks like at least another day of fighting with Cmake to force it to actually build a working make file. . You are developing on something like a recent Fedora or Ubuntu? In my experience packages which use boost and cmake inevitably cause a great great deal of pain when they are built on platforms like Centos or RHEL where long term support is one of the goals. They work fine on platforms which are cutting edge, but backwards compatibility extends ba",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:3138,install,install,3138,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['install'],['install']
Deployability,"rge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir : /usr/local/Caskroom/miniforge/base/etc/conda; conda av metadata url : None; channel URLs : https://conda.anaconda.org/conda-forge/osx-arm64; https://conda.anaconda.org/conda-forge/noarch; package cache : /usr/local/Caskroom/miniforge/base/pkgs; /Users/Benjamin/.conda/pkgs; envs directories : /usr/local/Caskroom/miniforge/base/envs; /Users/Benjamin/.conda/envs; platform : osx-arm64; user-agent : conda/4.12.0 requests/2.27.1 CPython/3.9.13 Darwin/21.5.0 OSX/12.4; UID:GID : 501:20; netrc file : None; offline mode : False. An unexpected error has occurred. Conda has prepared the above report. If submitted, this report will be used by core maintainers to improve; future releases of conda.; Would you like conda to send this report to the core maintainers?. [y/N]: y; Upload did not complete. Thank you for helping to improve conda.; Opt-in to always sending reports (and not see this message again); by running. $ conda config --set report_errors true; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:6351,release,releases,6351,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['release'],['releases']
Deployability,"rgets. processed 185 Million fragments; hits: 690426925, hits per frag: 3.72226. [2018-12-05 16:57:31.421] [jointLog] [info] Computed 215,739 rich equivalence classes for further processing; [2018-12-05 16:57:31.421] [jointLog] [info] Counted 131,957,987 total reads in the equivalence classes ; [2018-12-05 16:57:31.421] [jointLog] [warning] 0.000112378% of fragments were shorter than the k used to build the index (31).; If this fraction is too large, consider re-building the index with a smaller k.; The minimum read size found was 24. [2018-12-05 16:57:31.421] [jointLog] [warning] Found 539897 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-12-05 16:57:31.421] [jointLog] [info] Mapping rate = 70.9532%. [2018-12-05 16:57:31.421] [jointLog] [info] finished quantifyLibrary(); [2018-12-05 16:57:35.529] [alevinLog] [info] Starting optimizer. Analyzed 3856 cells (100% of all).; [2018-12-05 17:04:51.878] [alevinLog] [info] Total 47125847 UMI after deduplicating.; [2018-12-05 17:04:51.928] [alevinLog] [info] Clearing EqMap; Might take some time.; [2018-12-05 17:05:04.064] [alevinLog] [info] Starting Import of the gene count matrix.; Exception : [std::bad_alloc]; alevin was invoked improperly.; For usage information, try alevin --help; Exiting.; ```. **Desktop (please complete the following information):**; Ubuntu 14.04 LTS; 3.13.0-143-generic #192-Ubuntu SMP Tue Feb 27 10:45:36 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux; Distributor ID:	Ubuntu; Description:	Ubuntu 14.04.5 LTS; Release:	14.04; Codename:	trusty. **Additional context**; If I include only a subset of the fastq files, the command completes with no error. I have succeeded in running up to 3 of the files (3 *I1*, 3 *I2* and 3 *RA* files), but got the above-mentioned error when running it on 4 or more fastq files. I read that std::bad_alloc was usually caused by memory issues. The system I am using has 128Gb of RAM available. Thank you for your help",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:14851,Release,Release,14851,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['Release'],['Release']
Deployability,"riments consist of multiple samples. In other samples, the same transcript fractions could give rise to a slightly different set of observed fragments that induce exactly the same type of variation under uncertainty; and since that uncertainty is baked into the sample, it cannot and should not be removed. Having exact replication of a sample at a numerical threshold below the inferential uncertainty for a transcript conveys false confidence in the precision of the estimate. This is why, for transcript-level analysis, we highly recommend having salmon produce posterior gibbs samples (with the `--numGibbsSamples` flag). This will draw samples from the posterior distribution over the abundance estimates and allow determination of what inferences can be made robustly and what cannot. We have spent a good deal of time thinking about how to properly perform statistical inference on these uncertain quantities, and so I'd point you at [swish](https://bioconductor.org/packages/release/bioc/vignettes/fishpond/inst/doc/swish.html), which is a tool for differential analysis at the transcript level that makes uses of a non-parametric test over the inferential replicates (Gibbs samples) to incorporate uncertainty into the differential analysis. We also developed a tool [terminus](https://academic.oup.com/bioinformatics/article/36/Supplement_1/i102/5870485) that makes use of the Gibbs samples and point estimates of salmon to group together transcripts whose individual abundances cannot be reliably inferred given the fragments in the sample. While the best way to properly assess, propagate and handle uncertainty in transcript-level inference is still, in my opinion, an active area of research in the field, these are some solutions we've come up with to address this challenge so far. And while, as a computer scientist myself, I _certainly_ appreciate the desire to be able to have e.g. exactly the same numerical output for a particular sample, we feel that doing so might convey a fal",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:3758,release,release,3758,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,1,['release'],['release']
Deployability,ripts/v1_10x/run.sh salmon alevin -lISR -b pbmc3k_fastqs/ --gemcode -i ../transcripts_index_salmon/ -p 8 -o alevin_output --tgMap ../hg_transcriptome/tx2gene.tsv. TEMPDIR is /tmp/tmp.WnzMm7GQBO; Running command [salmon alevin -lISR --gemcode -i ../transcripts_index_salmon/ -p 8 -o alevin_output --tgMap ../hg_transcriptome/tx2gene.tsv -1 /tmp/tmp.WnzMm7GQBO/p1.fa -2 /tmp/tmp.WnzMm7GQBO/p2.fa -r pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-002-chunk-000.fastq.gz; pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-002-chunk-000.fastq.gz; pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-002-chunk-000.fastq.gz; pbmc3k_fastqs/read-I1_si-TAAATCGT_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-TAAATCGT_lane-002-chunk-000.fastq.gz]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; Logs will be written to alevin_output/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ gemcode ] => { }; ### [ index ] => { ../transcripts_index_salmon/ }; ### [ threads ] => { 8 }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { ../hg_transcriptome/tx2gene.tsv }; ### [ mates1 ] => { /tmp/tmp.WnzMm7GQBO/p1.fa }; ### [ mates2 ] => { /tmp/tmp.WnzMm7GQBO/p2.fa }; ### [ unmatedReads ] => { pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-001-chunk-001.fastq.gz pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-002-chunk-000.fastq.gz pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-001-chunk-001.fastq.gz pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-002-chunk-000.fastq.gz pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-001-chunk-001.fastq.gz pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-002-chunk-000.fastq.gz pbmc3k_fastqs/read-I1_si-TAAATCGT_lane-001-chunk-001.fastq.gz pbmc3k_fastqs/read-I1_si-TAAAT,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:9895,upgrade,upgrades,9895,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['upgrade'],['upgrades']
Deployability,"rity-and-quality` query suite](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs) for you. #### How do I upgrade my CodeQL engine?; No need! New versions of the CodeQL analysis are constantly deployed on GitHub.com; your repository will automatically benefit from the most recently released version. #### The analysis doesn’t seem to be working; If you get an error in GitHub Actions that indicates that CodeQL wasn’t able to analyze your code, please [follow the instructions here](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/troubleshooting-the-codeql-workflow) to debug the analysis. #### How do I disable LGTM.com?; If you have LGTM’s automatic pull request analysis enabled, then you can [follow these steps to disable the LGTM pull request analysis](https://lgtm.com/help/lgtm/managing-automated-code-review#disabling-pr-integration). You don’t actually need to remove your repository from LGTM.com; it will automatically be removed in the next few months as part of the deprecation of LGTM.com ([more info here](https://github.blog/2022-08-15-the-next-step-for-lgtm-com-github-code-scanning/)). #### Which source code hosting platforms does code scanning support?; GitHub code scanning is deeply integrated within GitHub itself. If you’d like to scan source code that is hosted elsewhere, we suggest that you create a mirror of that code on GitHub. #### How do I know this PR is legitimate?; This PR is filed by the official LGTM.com GitHub App, in line with the [deprecation timeline that was announced on the official GitHub Blog](https://github.blog/2022-08-15-the-next-step-for-lgtm-com-github-code-scanning/). The proposed GitHub Action workflow uses the [official open source GitHub CodeQL Action](https://github.com/github/codeql-action/). If you have any other questions or concerns, please",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/815:3989,integrat,integration,3989,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/815,1,['integrat'],['integration']
Deployability,"rized equivalence relation group fragments not only by the transcripts to which they map, but also with respect to the conditional probabilities of having generated that fragment & alignment score given each transcript. Practically, what happens is that the space of conditional probabilities is quantized, and an equivalence relation is defined based on both the transcript set and the vector of conditional probability bins into which the mapping falls with respect to each transcript in the equivalence class. This means that range-factorized equivalence classes can have multiple classes of fragments that map to the same set of transcripts, but with different conditional probabilities. Additionally, for each bin, the average conditional probability of fragments arising from that bin is maintained. What you are seeing printed out are the transcript sets, followed by the conditional bin indexes. Starting in the next release (and currently in the develop branch), we've cleaned up the interaction of the range-factorized equivalence classes with the `--dumpEq` and `--dumpEqWeights` flags. If you run with the `--dumpEqWeights` flags, salmon will dump the transcript sets, followed by the conditional probability vector, followed by the fragment count. If you run with the `--dumpEq` flag, it will collapse all of the range-factorized equivalence classes into ""simple"" equivalence classes by combining classes with the same transcript set (but different conditional probability vectors) and summing the corresponding fragment counts. This, of course, is a lossy transformation, and the equivalence classes will no longer represent the relevant conditional probabilities used during inference. Also, since the range-factorized equivalence classes allow for (but probabilistically down-weight) non-optimal mappings of fragments to transcripts, these collapsed equivalence classes will tend to have bigger labels (i.e. more transcripts) which might be difficult to properly interpret without the",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/402#issuecomment-517041654:1462,release,release,1462,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/402#issuecomment-517041654,1,['release'],['release']
Deployability,"rliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ###; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { assembly_index }; ### [ libType ] => { A }; ### [ unmatedReads ] => { 9998_1.fastq.gz }; ### [ meta ] => { }; ### [ threads ] => { 100 }; ### [ output ] => { 9998.quant_se2 }; Logs will be written to 9998.quant_se2/logs; [2023-03-17 07:40:15.733] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-03-17 07:40:15.733] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2023-03-17 07:40:15.733] [jointLog] [info] parsing read library format; [2023-03-17 07:40:15.733] [jointLog] [info] There is 1 library.; [2023-03-17 07:40:15.882] [jointLog] [info] Loading Quasi index; [2023-03-17 07:40:15.882] [jointLog] [info] Loading 64-bit quasi index; [2023-03-17 07:40:15.882] [stderrLog] [info] Loading Suffix Array ; [2023-03-17 07:42:06.971] [stderrLog] [info] Loading Transcript Info ; [2023-03-17 07:42:17.580] [stderrLog] [info] Loading Rank-Select Bit Array; [2023-03-17 07:42:20.101] [stderrLog] [info] There were 777288 set bits in the bit array; [2023-03-17 07:42:20.887] [stderrLog] [info] Computing transcript lengths; [2023-03-17 07:42:20.892] [stderrLog] [info] Waiting to finish loading hash; [2023-03-17 07:44:44.131] [stderrLog] [info] Done loading index; [2023-03-17 07:44:44.131] [jointLog] [inf",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/838:7167,release,release,7167,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/838,1,['release'],['release']
Deployability,"rna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [info] Starting to make feature Matrix; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making regular featues; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making feature Matrix; [2019-01-29 09:55:59.123] [alevinLog] [info] Finished white listing; [2019-01-29 09:55:59.126] [alevinLog] [info] Finished optimizer; ``` . Concat fastq:; ```; salmon alevin -l ISR -1 big.fastq.1.gz -2 big.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index/ -o salmon.dir/ --tgMap transcript2geneMap.tsv --dumpCsvCounts; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of Salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to salmon.dir/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { big.fastq.1.gz }; ### [ mates2 ] => { big.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:56:37.731] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:56:37.749] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 2 Million barcodes. [2019-01-29 09:56:43.029] [alevinLog] [info] Done barcode density calculation.; [2019-01-29 09:56:43.029] [alevinLog] [info] # Barcodes Used: 2695632 / 2712324.; [2019-01-29 09:56:52.900] [alevinLog] [info] Knee found left b",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:6237,release,releases,6237,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,2,"['release', 'upgrade']","['releases', 'upgrade']"
Deployability,"ror.hpp:11,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/exceptions.hpp:22,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/pthread/thread_data.hpp:10,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread_only.hpp:17,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread.hpp:12,; from /gpfs/projects/hpc_support/salmon/include/GenomicFeature.hpp:25,; from /gpfs/projects/hpc_support/salmon/src/GenomicFeature.cpp:22:; /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/pthread/thread_data.hpp:60:5: error: missing binary operator before token ""(""; 60 | #if PTHREAD_STACK_MIN > 0; | ^~~~~~~~~~~~~~~~~; In file included from /gpfs/projects/hpc_support/salmon/external/install/include/boost/functional/hash.hpp:6,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/detail/thread.hpp:41,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread_only.hpp:22:; /gpfs/projects/hpc_support/salmon/external/install/include/boost/container_hash/hash.hpp:130:33: warning: ‘template<class _Arg, class _Result> struct std::unary_function’ is deprecated [-Wdeprecated-declarations]; 130 | struct hash_base : std::unary_function<T, std::size_t> {};; | ^~~~~~~~~~~~~~; In file included from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/string:49,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/exceptions.hpp:20:; /gpfs/software/gcc/13.2.0/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here; 117 | struct unary_function; | ^~~~~~~~~~~~~~; make[2]: *** [src/CMakeFiles/salmon_core.dir/build.make:160: src/CMakeFiles/salmon_core.dir/GenomicFeature.cpp.o] Error 1; make[1]: *** [CMakeFiles/Makefile2:568: src/CMakeFiles/salmon_core.dir/all] Error 2; make: *** [Makefile:166: all] Error 2; ```. **To Reproduce**; ```; #!/usr/bin/env bash. module load cmake Bzip2/1.0.8 c",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/953:1982,install,install,1982,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/953,1,['install'],['install']
Deployability,"rray + ranks ); final hash 0 bits (0.00 %) (nb in final hash 0). My script to build the above index:. ~/salmon/bin/salmon index \; -t mouse_cDNA_ref/mus_cdna.fa.gz \; -i indexs/alt_long_index \; -k 31. My HPCC run on CentOS. . My script to run salmon quant:. ~/salmon/bin/salmon quant -i mnt/home/oconn341/salmon/indexs/alt_long_index -l A -1 preprocs_fastq/ERAP1_EAE_2270_S4/ERAP1_EAE_2270_S4_R1_001.fastq.gz -2 preprocs_fastq/ERAP1_EAE_2270_S4/ERAP1_EAE_2270_S4_R2_001.fastq.gz -o preprocs_fastq/ERAP1_EAE_2270_S4 --validateMappings --rangeFactorizationBins 4 --gcBias --seqBias. ; **To Reproduce**; Steps and data to reproduce the behavior:. Reproduces every time . Specifically, please provide at least the following information:. * Which version of salmon was used? V1.5.2; * How was salmon installed (compiled, downloaded executable, through bioconda)? Pre-compiled binary ; * Which reference (e.g. transcriptome) was used? Mus_musculus.GRCm39.cdna.all.fa.gz; * Which read files were used? see above; * Which which program options were used? see above. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] CentOS ; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here. I am thinking this is an issue w/ building the index. If there is a pre-made index w/ or w/o decoys for mouse that you can direct me to I would appreciate it. Following the link posted in the salmon documentation about pre-made index's is not helpful and I am not sure how to download them from there. A simpler option would be appreciated. . Thanks!. UPDATE: This was solved by using an index generated by a friend So apparently the issue is w/ building the index.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/696:8937,UPDATE,UPDATE,8937,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/696,1,['UPDATE'],['UPDATE']
Deployability,"rrespond to multiple sequences. **To Reproduce**; Steps and data to reproduce the behavior:; 1. Merging quantifications with Salmon:; salmon quantmerge \; --quants temp/salmon/L1EHI0900465--Q_S1_N6.quant \; -o result/salmon/gene_L1EHI0900465--Q_S1_N6.TPM; 2. Searching for a specific gene ID in the quantification file:; grep ""k141_1346622_1"" temp/salmon/L1EHI0900465--Q_S1_N6.quant/quant.sf; # Multiple lines are found for this gene ID; 3. Searching for the same gene ID in the resulting TPM file:; grep ""k141_1346622_1"" result/salmon/gene_L1EHI0900465--Q_S1_N6.TPM; #No results are found, which is unexpected. <img width=""1166"" alt=""截屏2024-01-30 21 56 23"" src=""https://github.com/COMBINE-lab/salmon/assets/19604271/b77e5aa4-aadc-4a17-bdde-b998ce14d72c"">; <img width=""1056"" alt=""截屏2024-01-30 21 55 28"" src=""https://github.com/COMBINE-lab/salmon/assets/19604271/877cfa9b-0484-4937-87b2-e987679e09e3"">. Specifically, please provide at least the following information:. * Which version of salmon was used? salmon 1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? conda install salmon -y; * Which reference (e.g. transcriptome) was used? metagenome data; * Which read files were used? L1EHI0900465--Q_S1_N6.quant/; * Which which program options were used?; salmon quantmerge \; --quants temp/salmon/L1EHI0900465--Q_S1_N6.quant \; -o result/salmon/gene_L1EHI0900465--Q_S1_N6.TPM. **Expected behavior**; A clear and concise description of what you expected to happen.; I hope to keep all the gene IDs and for those who contains more than one line, take average values for each gene ID. . **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/910:1344,install,installed,1344,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/910,2,['install'],"['install', 'installed']"
Deployability,"ruct std::unary_function’ is deprecated [-Wdeprecated-declarations]; 130 | struct hash_base : std::unary_function<T, std::size_t> {};; | ^~~~~~~~~~~~~~; In file included from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/string:49,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/exceptions.hpp:20:; /gpfs/software/gcc/13.2.0/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here; 117 | struct unary_function; | ^~~~~~~~~~~~~~; make[2]: *** [src/CMakeFiles/salmon_core.dir/build.make:160: src/CMakeFiles/salmon_core.dir/GenomicFeature.cpp.o] Error 1; make[1]: *** [CMakeFiles/Makefile2:568: src/CMakeFiles/salmon_core.dir/all] Error 2; make: *** [Makefile:166: all] Error 2; ```. **To Reproduce**; ```; #!/usr/bin/env bash. module load cmake Bzip2/1.0.8 curl; module load oneTBB/gcc13.2/2021.13.0; module load boost/gcc13.2/1.86.0 . rm -rf CMake*. cmake .. \; -DCMAKE_C_COMPILER=gcc \; -DBOOST_ROOT=/gpfs/software/boost/xeonmax/gcc13.2/1.86.0/ \; -DTBB_INSTALL_DIR=/gpfs/software/oneTBB/xeonmax/gcc13.2.0/2021.13.0 \; -DTBB_ROOT=/gpfs/software/oneTBB/xeonmax/gcc13.2.0/2021.13.0 \; -DCMAKE_CXX_COMPILER=g++ \; -DCMAKE_C_FLAGS=""-O3 -march=sapphirerapids -mtune=sapphirerapids"" \; -DCMAKE_CXX_FLAGS=""-O3 -march=sapphirerapids -mtune=sapphirerapids"" \; -DCMAKE_INSTALL_PREFIX:PATH=/gpfs/software/salmon/xeonmax/gcc13.2.0/1.10.3. make clean; make -j 25; ```. Specifically, please provide at least the following information:. * Which version of salmon was used? **1.10.3**; * How was salmon installed (compiled, downloaded executable, through bioconda)? **compiled**. **Expected behavior**; A successful build. **Desktop (please complete the following information):**; - OS: **Rocky Linux 9.4**; - Version: **Linux xm013 5.14.0-427.26.1.el9_4.x86_64 #1 SMP PREEMPT_DYNAMIC Tue Jul 23 16:00:21 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux**. **Additional context**; std err file attached.; [build.err.gz](https://github.com/user-attachments/files/16677963/build.err.gz)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/953:3705,install,installed,3705,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/953,1,['install'],['installed']
Deployability,"ry(tximport); library(devtools); library(ggplot2); library(patchwork); # Just install Seurat like normal. Tutorial's allusion to a ""spatial"" branch appears to be outdated.; library(Seurat); }). # navigate to data directory; wkdir <- ""path/to/alevin_data/""; setwd(wkdir). # load in alevin output; files <- file.path(""alevin_out/alevin/quants_mat.gz""); file.exists(files). # set prefix for output files; prefix = ""alevin"". # tximport loads the alevin data into R; txi <- tximport(files = files, type = ""alevin""). # Creating a Seurat object with spatial assay; assay <- ""Spatial""; brain <- CreateSeuratObject(counts = txi$counts, project = ""SPATIAL"", assay = assay); brain. # loading the 10x image data; seqdir <- ""path/to/10x_imaging_data/""; image.data <- Read10X_Image(paste0(seqdir,""spatial/"")). # Since the names of alevin cb is different from 10x; # we rename the cells and filter the image data; # to have the metadata for only quantified cells; image.data@boundaries$centroids@cells <- gsub(""-1"", """", image.data@boundaries$centroids@cells); common.cells <- intersect(Cells(x = brain), image.data@boundaries$centroids@cells). # Subset the centroids object; centroids <- image.data@boundaries$centroids. # Find indices of common cells; common_indices <- which(centroids@cells %in% common.cells). # Subset the cells and coords slots; centroids@cells <- centroids@cells[common_indices]; centroids@coords <- centroids@coords[common_indices, ]. # Update the image.data object with the subsetted centroids; image.data@boundaries$centroids <- centroids. # Update the brain object accordingly; brain <- subset(brain, cells = common.cells). # adding image data to Seurat object; DefaultAssay(object = image.data) <- ""Spatial""; brain@images[['slice']] <- image.data; ```; The rest of the tutorial (plotting and clustering) is fairly standard and should work just fine. Of course, if your setup differs substantially from mine, it is certainly possible you will encounter different behavior so stay vigilent!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/942#issuecomment-2204802696:1675,Update,Update,1675,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/942#issuecomment-2204802696,2,['Update'],['Update']
Deployability,"s (i checked in the duplicate_clusters.tsv file and in total there are 5 transcript in that cluster), am I right? does salmon work like this?; Does it explain the little differences I see in the transcript quantification?; Correct me if I'm wrong, salmon tries to assign the reads as equally as possible to every duplicate transcript, but of course if we have for example 21 reads and 4 transcript, they will have respectively 5,5,5 and 6 reads, which can explain the small differences I see. ; Is it correct?; (anyway, in this way i can explain the first two genes which have respectively a read count of 3639 and 3631, but for the last two genes a difference of 32 reads sounds too big to me) . This can be a problem for me, since I belive that the issue of the duplicate transcripts derives from haplotypic genes, such as RPS18 which has more than one ENSG ID (i.e. ENSG00000226225 and ENSG00000231500). ENSG00000231500 is absent in the pipeline without the flag, while in the pipeline with the flag the expression level is ""splitted"" between the two genes (which are actually only one gene). both the results I obtain don't represent the ""reality"".; I'm afraid I will have to remove all the ""ambigous"" genes from the reference, keeping only the ones with the ""canonical"" ENSG ID; since I'm doing a ""pan-genes"" analysis, and the number of duplicate transcript is ~11,000, this can be painful...; Has anyone ever encountered a problem like this? Is someone using a reference transcriptome that is already ""clean"" from haplotypic genes? also, do the 11k duplicate genes derive only from haplytipic genes, or there are other strange biological things that I am not considering?. Last question (which is not about duplicate transcript but about tximport...tell me if it is off topic and i will ask elsewhere); For the gene ENSG00000231500.6, tximport reports an expression of 164.677488, while the sum of the TPM of the transcript of that gene is 163.659568 (a very small difference, but still a differ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/310:2677,pipeline,pipeline,2677,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/310,2,['pipeline'],['pipeline']
Deployability,"s the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon (buik mode). **Describe the bug**; A clear and concise description of what the bug is.; I compiled the code (salmon v1.4.0) and produced the executable. Then when I try to ""salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon_index --gencode"" (transcriptome and genome from your tutorial: https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/), a segmentation fault occurs. (gdb backtrack is provided below.). **To Reproduce**; Steps and data to reproduce the behavior:. 1. run a docker container using ubuntu:18.04 as image. 2. (packages I installed); apt-get install -y gcc g++ make wget git curl libtbb2-dbg libtbb-dev unzip zlib1g-dev libcurl4-openssl-dev liblzma-dev libbz2-dev libcereal-dev libgff-dev libpkgconfig-perl libjemalloc-dev; /*; gcc (Ubuntu 7.5.0-3ubuntu118.04) 7.5.0; g++ (Ubuntu 7.5.0-3ubuntu118.04) 7.5.0; GNU Make 4.1; */; wget https://github.com/Kitware/CMake/releases/download/v3.13.4/cmake-3.13.4-Linux-x86_64.sh /cmake version 3.13.4/. 3. git clone https://github.com/COMBINE-lab/salmon.git; I'm at the top commit: commit 0813a0a (HEAD -> master, tag: v1.4.0, origin/master, origin/HEAD). 4. In directory salmon/build, I type; > cmake -DFETCH_BOOST=TRUE -DTBB_INSTALL_DIR=/usr/include -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=../stage ..; > make; > make install. 5. following your tutorial https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/; > wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M23/gencode.vM23.transcripts.fa.gz; > wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M23/GRCm38.primary_assembly.genome.fa.gz; > grep ""^>"" <(gunzip -c GRCm38.primary_assembly.genome.fa.gz) | cut -d "" "" -f 1 > decoys.txt; > sed -i.bak -e 's/>//g' decoys.txt; > cat gencode.vM23.transcripts.fa.gz GRCm38.primary_assembly.genome.fa.gz > gentrome.fa.gz; > salmon index -t gentrome.fa.gz -d decoys.t",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/609:1002,release,releases,1002,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/609,1,['release'],['releases']
Deployability,"s, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB V",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1341,Install,Installing,1341,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installing']
Deployability,"sModel.cpp.o CMakeFiles/salmon.dir/StadenUtils.cpp.o CMakeFiles/salmon.dir/TranscriptGroup.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapFileSystem.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndexer.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndex.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAMapper.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapUtils.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/HitManager.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/bit_array.c.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_chrono.a /opt/boost/boost_1_57_0/lib/libboost_program_options.a /opt/boost/boost_1_57_0/lib/libboost_serialization.a ../../external/install/lib/libstaden-read.a -lz ../../external/install/lib/libdivsufsort.a ../../external/install/lib/libdivsufsort64.a ../../external/install/lib/libjellyfish-2.0.a ../../external/install/lib/libbwa.a -lm ../../external/install/lib/liblzma.a -lbz2 -ltbb -ltbbmalloc -lgomp -lrt ../../external/install/lib/libjemalloc.a -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib""; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:2093,install,install,2093,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,salmon 0.14.1. Maybe that is the problem... I am going to update now and try again.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623868804:58,update,update,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623868804,1,['update'],['update']
Deployability,salmon 1.8.0: binary release does not come with proper file permissions,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/761:21,release,release,21,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/761,1,['release'],['release']
Deployability,salmon v1.4.0 executable compiled using release mode(-DCMAKE_BUILD_TYPE=Release) produce segmentation fault,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/609:40,release,release,40,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/609,2,"['Release', 'release']","['Release', 'release']"
Deployability,"salmon; $ ldd `which salmon`; linux-vdso.so.1 => (0x00007ffd8d9c0000); libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f20010a9000); libtbb.so.2 => /usr/lib/x86_64-linux-gnu/libtbb.so.2 (0x00007f2000e6b000); libgomp.so.1 => /usr/lib/x86_64-linux-gnu/libgomp.so.1 (0x00007f2000c49000); librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f2000a41000); libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f2000737000); libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f2000521000); libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f2000158000); /lib64/ld-linux-x86-64.so.2 (0x000055aeef1e1000); libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f1ffff53000); libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f1fffbd1000); $ ldd ~/src/salmon/build/src/salmon; linux-vdso.so.1 => (0x00007fffdc2d7000); libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f990745d000); libtbb.so.2 => /home/ryan/src/salmon/build/src/../../external/install/lib/libtbb.so.2 (0x00007f990722f000); libgomp.so.1 => /usr/lib/x86_64-linux-gnu/libgomp.so.1 (0x00007f990700d000); librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f9906e05000); libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f9906afb000); libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f99068e5000); libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f990651c000); /lib64/ld-linux-x86-64.so.2 (0x0000564b94030000); libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f9906317000); libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f9905f95000); $ md5sum `which salmon` ~/src/salmon/build/src/salmon; 90831f998ff897969da448043c590f61 /home/ryan/bin/salmon; 90831f998ff897969da448043c590f61 /home/ryan/src/salmon/build/src/salmon; ```. I don't know enough about how dynamic linking works to explain this. Anyway, I did `export LD_LIBRARY_PATH=/home/ryan/src/salmon/external/install/lib` and now I'm running `while true; do salmon ...; done` again.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267493389:1224,install,install,1224,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267493389,2,['install'],['install']
Deployability,same thing happened to me using the conda install,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364822189:42,install,install,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364822189,1,['install'],['install']
Deployability,"script set and the vector of conditional probability bins into which the mapping falls with respect to each transcript in the equivalence class. This means that range-factorized equivalence classes can have multiple classes of fragments that map to the same set of transcripts, but with different conditional probabilities. Additionally, for each bin, the average conditional probability of fragments arising from that bin is maintained. What you are seeing printed out are the transcript sets, followed by the conditional bin indexes. Starting in the next release (and currently in the develop branch), we've cleaned up the interaction of the range-factorized equivalence classes with the `--dumpEq` and `--dumpEqWeights` flags. If you run with the `--dumpEqWeights` flags, salmon will dump the transcript sets, followed by the conditional probability vector, followed by the fragment count. If you run with the `--dumpEq` flag, it will collapse all of the range-factorized equivalence classes into ""simple"" equivalence classes by combining classes with the same transcript set (but different conditional probability vectors) and summing the corresponding fragment counts. This, of course, is a lossy transformation, and the equivalence classes will no longer represent the relevant conditional probabilities used during inference. Also, since the range-factorized equivalence classes allow for (but probabilistically down-weight) non-optimal mappings of fragments to transcripts, these collapsed equivalence classes will tend to have bigger labels (i.e. more transcripts) which might be difficult to properly interpret without the relevant conditional probabilities. The `--hardFilter` flag will filter out transcripts that have non-best alignment scores (a big component of the conditional fragment probability), but that can have a negative effect on the modeling and inference. We'll update the documentation accordingly when we cut the next release to make all of these interactions more clear.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/402#issuecomment-517041654:2794,update,update,2794,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/402#issuecomment-517041654,2,"['release', 'update']","['release', 'update']"
Deployability,"se/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir : /usr/local/Caskroom/miniforge/base/etc/conda; conda av metadata url : None; channel URLs : https://conda.anaconda.org/conda-forge/osx-arm64; https://conda.anaconda.org/conda-forge/noarch; package cache : /usr/local/Caskroom/miniforge/base/pkgs; /Users/Benjamin/.conda/pkgs; envs directories : /usr/local/Caskroom/miniforge/base/envs; /Users/Benjamin/.conda/envs; platform : osx-arm64; user-agent : conda/4.12.0 requests/2.27.1 CPython/3.9.13 Darwin/21.5.0 OSX/12.4; UID:GID : 501:20; netrc file : None; offline mode : False. An unexpected error has occurred. Conda has prepared the above report. If submitted, this report will be used by core maintainers to improve; future releases of conda.; Would you like conda to send this report to the core maintainers?. [y/N]: y; Upload did not complete. Thank you ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:5482,install,installed,5482,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['install'],['installed']
Deployability,"se4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` c",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2009,Install,Installing,2009,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Install'],['Installing']
Deployability,sed time: 0.20793s; [2019-07-01 12:33:02.252] [jointLog] [info] Writing sequence data to file . . . ; [2019-07-01 12:33:04.501] [jointLog] [info] done; Elapsed time: 2.24861s; [2019-07-01 12:33:04.572] [jointLog] [info] Building 32-bit suffix array (length of generalized text is 469043886); [2019-07-01 12:33:08.681] [jointLog] [info] Building suffix array . . . ; success; saving to disk . . . done; Elapsed time: 61.4932s; done; Elapsed time: 171.743s; processed 12000000 positionsKilled. I can send log files if required. The problem I have is that I cannot seem to run quant without the quant function. salmon quant --validateMappings ; -i /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index -l IU ; -1 /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz ; -2 /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz ; -o /home/RnaSeq/salmon_output_files/out/DM4h; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index }; ### [ libType ] => { IU }; ### [ mates1 ] => { /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz }; ### [ mates2 ] => { /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { /home/RnaSeq/salmon_output_files/out/DM4h }; Logs will be written to /home/RnaSeq/salmon_output_files/out/DM4h/logs; [2019-07-01 12:51:42.856] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-01 12:51:42.856] [jointLog] [info] Usage of --validateMappings implies use of minScoreFra,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562:2269,upgrade,upgrade,2269,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562,1,['upgrade'],['upgrade']
Deployability,"shared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356A\316;\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=1926760, ...}) = 0; mmap(0x3bce400000, 3750152, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x3bce400000; mprotect(0x3bce58a000, 2097152, PROT_NONE) = 0; mmap(0x3bce78a000, 20480, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x18a000) = 0x3bce78a000; mmap(0x3bce78f000, 18696, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x3bce78f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libdl.so.2"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\340\r\300\316;\0\0\0""..., 832) = 832; fstat(3, {st_mode=S",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:59099,pipeline,pipeline,59099,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['pipeline'],['pipeline']
Deployability,"so I followed some tutorial to (1) update my Ubuntu, and (2) install the newest GBLIC library, but the problem still persist. . However, if I use the exact same code on a HPCC, it actually works. **To Reproduce**; Steps and data to reproduce the behavior:; Totally following your index preparation tutorial like this:. grep ""^>"" <(gunzip -c TAIR10_chr_all.fas.gz) | cut -d "" "" -f 1 > decoys.txt; sed -i.bak -e 's/>//g' decoys.txt; cat Araport11_cdna_20240409.gz TAIR10_chr_all.fas.gz > gentrome.fasta.gz; salmon index -t gentrome.fasta.gz -d decoys.txt -p 12 -i salmon_index --gencode. Then the error pops:; salmon: /lib/x86_64-linux-gnu/libpthread.so.0: version `GLIBC_PRIVATE' not found (required by /home/plyric/anaconda3/share/salmon-0.8.1-0/bin/../lib/librt.so.1). If I manage to get the index using an HPCC and run local quant like this:; salmon quant -i Arabidopsis_index -l A -1 filtered_a234-f1_S10_L002_R1_001.fastq.gz -2 filtered_a234-f1_S10_L002_R2_001.fastq.gz --validateMappings -o test_transcripts_quant; Then same error pops. Specifically, please provide at least the following information:. * Which version of salmon was used?; It is very strange. I am supposed to get v1.10.3 by bioconda default, but -v order get the same error. So I don't know how to get my version. The conda list says ""0.8.1"" ; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Bioconda, official install order code; * Which reference (e.g. transcriptome) was used?; Arabidopsis (not important for the issue); * Which read files were used?; Arabidopsis (not important for the issue); * Which which program options were used?; Default. **Expected behavior**; I just want it work. **Screenshots**; <img width=""868"" alt=""image"" src=""https://github.com/COMBINE-lab/salmon/assets/83922432/3913fbea-a0a7-4fb4-8aa1-4efef8b0990b"">. **Desktop (please complete the following information):**; - OS: Windows 11 => WSL => Ubuntu 22.04.4 LTS (GNU/Linux 5.10.16.3-microsoft-standard-WSL2 x86_64)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/927:1968,install,installed,1968,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/927,2,['install'],"['install', 'installed']"
Deployability,"so.6 (0x00007f859979f000); ```. The linux version and g++ version are listed below:; ```; cat /proc/version; Linux version 4.9.0-0.bpo.6-amd64 (debian-kernel@lists.debian.org) (gcc version 4.9.2 (Debian 4.9.2-10+deb8u1) ) #1 SMP Debian 4.9.82-1+deb9u3~bpo8+1 (2018-03-22). ~/data/PCSI/PC10X/paper/pbmc$ g++ -v; Using built-in specs.; COLLECT_GCC=g++; COLLECT_LTO_WRAPPER=/u/user/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper; Target: x86_64-unknown-linux-gnu; Configured with: ./configure --prefix=/u/user/local; Thread model: posix; gcc version 5.4.0 (GCC); ```. ```; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] =",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:2370,configurat,configuration,2370,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,1,['configurat'],['configuration']
Deployability,"specially appreciated!. I was wondering what the reason for setting an upper limit on the barcode length in alevin is - would longer barcodes affect the computation in some manner? We are working with barcodes of length 27, which are incompatible with the hardcoded upper barcode length limit [here](https://github.com/COMBINE-lab/salmon/blob/2ebc89c3fa744b8fc8794c9ab538ae50e41c1adc/src/AlevinUtils.cpp#L578). I manually raised the limit on a modified alevin version, and the final output looks as expected, so if there is no risk that I am unaware of, would you consider raising or removing the barcode length limit altogether?. Thank you for you help!. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; alevin. **Describe the bug**; Using the manual barcode and UMI specification with `--end`, `--barcodeLength`, and `--umiLength` fails for barcodes longer than 20 with the error message:; ```; Barcode length (27) was not in the required length range [1, 20].; ```; The barcode length upper limit is hardcoded [here](https://github.com/COMBINE-lab/salmon/blob/2ebc89c3fa744b8fc8794c9ab538ae50e41c1adc/src/AlevinUtils.cpp#L578). **To Reproduce**; In Salmon 1.0.0, run `salmon alevin [...] --end 5 --barcodeLength 27 --umiLength 8` (or any `barcodeLength` value above 20). * Which version of salmon was used? 1.0.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? bioconda; * Which reference (e.g. transcriptome) was used? not relevant; * Which read files were used? not relevant; * Which which program options were used? `--end 5 --barcodeLength 27 --umiLength 8`. **Expected behavior**; Ideally, barcode longer than 20 would be processed as normal. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Mac OS X; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`] 10.14.6 (18G103). **Additional context**; See top of post",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/445:1462,install,installed,1462,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/445,1,['install'],['installed']
Deployability,"st they differ dramatically (e.g. psbI or ATCG00080: Salmon: 24; FeatureCounts: 9277). Looking at the mapping, I would say that FeatureCounts is definitely closer to reality here. ; When I dig deeper, it seems that the genes with the biggest difference between the two analyses are very small genes (e.g. psbI is only 111bp) or tRNAs (which should be removed by the prep method; these would be excluded from the analysis anyway). ; I have now tried several things: I used the nf-core/rnaseq pipeline, skipping the alignment part (--skip_alignment) and using Salmon as a pseudo-aligner (--pseudo_aligner: salmon), which gave results for the chloroplast reads that are quite close to the alignment-based determination by Salmon (e.g. psbI: 372).; I also tried using the pseudo-alignment without the pipeline (indexing: salmon index -t input.fa -r transcripts_index -k 31 pseudomapping: salmon quant -i transcripts_index -l A -1 sequencingdata_R1.fastq.gz -2 sequencingdata_R2.fastq.gz --validate mapping - o transcripts.quant). The result was that the chloroplast numbers were now roughly between the salmon counts from the pipeline and the counts from the pipeline with FeatureCounts. I skipped the trimming part here, so differences are to be expected, but they still seem very high (e.g. psbI 2677).; First, I have no idea where the difference between counts with and without pipelines comes from. I tried to find out what parameters the pipeline uses for Salmon, but I didn't find anything special there.; And secondly, I wonder if Salmon has somehow problems with the chloroplast genome (super small, polycistronic and monocistronic units, partially small genes, high expression levels)? I know there are publications where Salmon has been used for chloroplast read counts, but I haven't found any information about their parameters. I would be super happy if you guys could help me here. I could also just work with FeatureCounts, but I would like to understand my problems. All the best; Florian",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798:1683,pipeline,pipeline,1683,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798,4,['pipeline'],"['pipeline', 'pipelines']"
Deployability,"st.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/SalmonQuantMerge.cpp.o CMakeFiles/salmon.dir/ProgramOptionsGenerator.cpp.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/ONTAlignmentModel.cpp.o CMakeFiles/salmon.dir/AlignmentCommon.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o CMakeFiles/salmon.dir/BAMUtils.cpp.o -o salmon -L/vol/mgx-sw/src/tools/salmon/lib -L/vol/mgx-sw/lib -L/vol/mgx-sw/src/tools/salmon/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" ../external/pufferfish/src/libpuffer.a libsalmon_core.a ../external/pufferfish/external/twopaco/graphconstructor/libtwopaco.a ../external/pufferfish/external/twopaco/graphdump/libgraphdump.a ../external/pufferfish/external/ntcard/libntcard.a -lgff /usr/lib/x86_64-linux-gnu/libboost_iostreams.a /usr/lib/x86_64-linux-gnu/libboost_filesystem.a /usr/lib/x86_64-linux-gnu/libboost_system.a /usr/lib/x86_64-linux-gnu/libboost_timer.a /usr/lib/x86_64-linux-gnu/libboost_chrono.a /usr/lib/x86_64-linux-gnu/libboost_program_options.a /usr/lib/x86_64-linux-gnu/libboost_locale.a ../../external/install/lib/libstaden-read.a /usr/lib/x86_64-linux-gnu/libcurl.a /usr/lib/x86_64-linux-gnu/libz.a -lm /usr/lib/x86_64-linux-gnu/liblzma.a /usr/lib/x86_64-linux-gnu/libbz2.a -lgomp ../external/pufferfish/src/libksw2pp.a libalevin_core.a ../../external/install/lib/libjemalloc.a -ltbbmalloc_proxy -ltbbmalloc -ltbb -lrt -ldl /usr/lib/x86_64-linux-gnu/libboost_system.a /usr/lib/x86_64-linux-gnu/libboost_chrono.a /usr/lib/x86_64-linux-gnu/libboost_thread.a -pthread /usr/lib/x86_64-linux-gnu/libboost_atomic.a ; ```. I also tried compiling without `-DFETCH_BOOST=TRUE`, i.e. boost packages installed via apt-get, but the same error occurs.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/664:3254,install,install,3254,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/664,3,['install'],"['install', 'installed']"
Deployability,"staden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xec4): warning: the use of `tempnam' is dangerous, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 10",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1196,Install,Installing,1196,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installing']
Deployability,"stall/src/rapmap/RapMapUtils.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/HitManager.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/bit_array.c.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_chrono.a /opt/boost/boost_1_57_0/lib/libboost_program_options.a /opt/boost/boost_1_57_0/lib/libboost_serialization.a ../../external/install/lib/libstaden-read.a -lz ../../external/install/lib/libdivsufsort.a ../../external/install/lib/libdivsufsort64.a ../../external/install/lib/libjellyfish-2.0.a ../../external/install/lib/libbwa.a -lm ../../external/install/lib/liblzma.a -lbz2 -ltbb -ltbbmalloc -lgomp -lrt ../../external/install/lib/libjemalloc.a -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib""; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xd26): warning: the use of `tempnam' is dangerous, better use `mkstemp'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `tbb::strict_ppl::internal::concurrent_queue_base_v3<UnpairedRead*>::internal_push(void const*, void (*)(UnpairedRead**, void const*)) [clone .constprop.1465]':; SalmonQuantifyAlignments.cpp:(.text+0x136d): undefined reference to `tbb::internal::throw_exception_v4(tbb::internal::exception_id)'; CMakeFiles/salmon.di",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:2583,install,install,2583,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,stdc++ -Wno-deprecated-register -Wno-unused-local-typedefs -L/opt/rh/devtoolset-2/root/usr/lib64 -L/opt/rh/devtoolset-2/root/usr/lib CMakeFiles/salmon.dir/QSufSort.c.o CMakeFiles/salmon.dir/is.c.o CMakeFiles/salmon.dir/bwt_gen.c.o CMakeFiles/salmon.dir/bwtindex.c.o CMakeFiles/salmon.dir/xxhash.c.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/SequenceBiasModel.cpp.o CMakeFiles/salmon.dir/StadenUtils.cpp.o CMakeFiles/salmon.dir/TranscriptGroup.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapFileSystem.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndexer.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAIndex.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapSAMapper.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/RapMapUtils.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/HitManager.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/salmon.dir/__/external/install/src/rapmap/bit_array.c.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/ErrorModel.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:1442,install,install,1442,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,1,['install'],['install']
Deployability,"t even then there were segfaults observed intermittently. - The current Galaxy Tool wrapper for Salmon runs `salmon index ... && salmon quant ...` for every input fastq by default, but I've also generated and pointed `salmon quant` to a common index and have observed the same segfault behavior. I've also tried out the `--perfectHash` flag in both of these scenarios to no avail. - I have the ability to specify/wrap another version of Salmon to be compatible with Galaxy if the thought is that a more recent release could help. - I'm happy to provide any context past this that could help solve the issue!. - Also, I lack any biological insight so I'll ping my colleague @gmnelson for backup in that space. **Terminal Output**; <details>; <summary>Example Output</summary>; <br>. ```; Fatal error: Exit code 139 (); Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [2018-08-16 19:42:27.806] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; [2018-08-16 19:42:27.811] [jointLog] [warning] Entry with header [ENST00000434970.2], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-08-16 19:42:27.811] [jointLog] [warning] Entry with header [ENST00000448914.1], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-08-16 19:42:27.811] [jointLog] [warning] Entry with header [ENST00000415118.1], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-08-16 19:42:27.811] [jointLog] [warning] Entry with header [ENST00000632684.1], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-08-16 19:42:27.811] [jointLog] [warning] Entry with header [ENST00000631435.1], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-08",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271:3259,release,releases,3259,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271,2,"['release', 'upgrade']","['releases', 'upgrade']"
Deployability,"t libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: U",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1491,Install,Installation,1491,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installation']
Deployability,"t ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:1881,Install,Installing,1881,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Install'],['Installing']
Deployability,"t results similar to if you had aligned to the target transcriptome using Bowtie2. In this case, you perform indexing by simply not providing any `--decoy` flag to the `index` command. In that case, all of the records in the target fasta will be treated as valid and quantifiable targets. Of course, for reasons detailed in the pre-print --- the high _sensitivity_ of both Bowtie2 and selective-alignment --- we recommend including either mashmap-derived decoys or the organism's genome as a decoy whenever possible. . 4) Related to @k3yavi's response and my elaboration above: we have dropped quasi-mapping from 1.0.0 (though something akin to it may return in the future if there is sufficient demand and if the shortcomings described in the manuscript can be overcome). However, as I mention in part 3 above, this doesn't mean it's not possible to use v1.0.0 without an explicit decoy sequence. The `--decoy` flag of the indexing command is optional, not required. We will update this in the documentation making it more explicit. However, as @k3yavi points out, it is true that if you wish to use quasi-mapping and selective-alignment against the full genome on the same machine, you will need both versions, as quasi-mapping is supported only in the [RapMap](https://github.com/COMBINE-lab/RapMap/tree/develop-salmon), while indexing something on the scale of the genome when not using the [pufferfish-based](https://github.com/COMBINE-lab/pufferfish/tree/develop) index has tremendous memory requirements (as is not recommended ). 5 & 6) To re-iterate @k3yavi's answer --- the extra flags used in the pre-print were only for the purpose of holding as many variables fixed as possible when comparing different approaches. It continues to be recommended to use the VBEM over the EM; it seems to perform better with respect to the ways in which we can measure and such improvements have also been documented in [other work](https://www.ncbi.nlm.nih.gov/pubmed/23821651). The _main_ effect of `--mi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390:1916,update,update,1916,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390,1,['update'],['update']
Deployability,"t_mapped"": 55.82249021745959,; mapped/salmon_MS0.33_AG1232_015_FI3/aux_info/meta_info.json: ""percent_mapped"": 55.80153947588767,; mapped/salmon_MS0.33_AG1232_016_FG1/aux_info/meta_info.json: ""percent_mapped"": 49.49543448190936,; mapped/salmon_MS0.33_AG1232_017_FG2/aux_info/meta_info.json: ""percent_mapped"": 55.19039678416574,; mapped/salmon_MS0.33_AG1232_018_FG3/aux_info/meta_info.json: ""percent_mapped"": 50.730150343757518,; ```. The [readthedocs](https://salmon.readthedocs.io/en/latest/file_formats.html#meta-information) link for Salmon suggests, ""Most of the information recorded in this file should be self-descriptive"", but this is not the case for me. **To Reproduce**; Steps and data to reproduce the behavior:. 1. Map reads; 2. Observe consistent mapping rates below 80%. Specifically, please provide at least the following information:. * Which version of salmon was used? **salmon (selective-alignment-based) v1.10.2**; * How was salmon installed (compiled, downloaded executable, through bioconda)? **package installation via Debian**; * Which reference (e.g. transcriptome) was used? **transcriptome**; * Which read files were used? **NovaSeq X Plus; read length 150bp x 2; untrimmed **; * Which which program options were used?. ```; for sampleName in $(ls -d ag1232/AG* | perl -pe 's/^ag1232.//'); do; salmon quant -p 12 --index reference/salmon_index -l ISR -1 ag1232/${sampleName}/*_1.fq.gz -2 ag1232/${sampleName}/*_2.fq.gz \; --validateMappings --seqBias --gcBias --posBias --numBootstraps 10 --writeUnmappedNames -o mapped/salmon_${sampleName};; done; ```. Making Salmon less stringent:; ```; for sampleName in $(ls -d ag1232/AG* | perl -pe 's/^ag1232.//'); do; salmon quant -p 12 --index reference/salmon_index -l ISR -1 ag1232/${sampleName}/*_1.fq.gz -2 ag1232/${sampleName}/*_2.fq.gz \; --validateMappings --seqBias --gcBias --posBias --softclip --allowDovetail --minScoreFraction 0.33 --recoverOrphans \; --numBootstraps 10 --writeUnmappedNames -o mapped/salmon_MS0.33_${sam",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/925:4918,install,installed,4918,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/925,2,['install'],"['installation', 'installed']"
Deployability,"table, through bioconda)?; wget https://github.com/COMBINE-lab/salmon/releases/download/v1.3.0/salmon-1.3.0_linux_x86_64.tar.gz; tar xzvf salmon-1.3.0_linux_x86_64.tar.gz; Directory was relabeled as salmon. * Which reference (e.g. transcriptome) was used?; Mouse Gencode vM25; wget http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.transcripts.fa.gz; wget http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/GRCm38.primary_assembly.genome.fa.gz. * Which read files were used?; Files used for salmon quant are attached (*fq.gz). * Which which program options were used?; None specifically was invoked to run salmon.; I am running salmon on a cluster (Linux 3.10.0-957.el7.x86_64 x86_64). **Expected behavior**; A clear and concise description of what you expected to happen. I expect the salmon quant to align and quantify the reads. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; 1) Attaching the screenshot in the zipped folder.; 2) Attaching the screenshot of the contents in the folder containing the indexed file. The versionInfo.json file is present in that folder. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; Linux 3.10.0-957.el7.x86_64 x86_64; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; Linux compute-106.cm.cluster 3.10.0-957.el7.x86_64 #1 SMP Thu Nov 8 23:39:32 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux. lsb-release:. LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch; Distributor ID: CentOS; Description: CentOS Linux release 7.6.1810 (Core); Release: 7.6.1810; Codename: Core. **Additional context**; Add any other context about the problem here.; [Files.zip](https://github.com/COMBINE-lab/salmon/files/5079070/Files.zip)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561:3202,release,release,3202,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561,3,"['Release', 'release']","['Release', 'release']"
Deployability,"talling: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```; ...; [2023-03-10 05:51:33.748] [puff::index::jointLog",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2336,Install,Installation,2336,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Install'],['Installation']
Deployability,"ted to ""word""...; Reading symbols from /u/user/local/bin/salmon...done.; (gdb) run alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; Starting program: /u/user/local/bin/salmon alevin -l ISR --chromium -p 4 -o BM_1/alevin -1 ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz -2 ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz --maxHashResizeThreads 2 -i /u/user/ref/cellranger/salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] =",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:1939,configurat,configuration,1939,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,1,['configurat'],['configuration']
Deployability,"tem system timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); +message(""Forcing Boost_FOUND to TRUE""); +set(Boost_FOUND TRUE); +set(Boost_LIBRARY_DIRS ""/usr/lib64/boost169""); +set(Boost_LIBRARIES -lboost_iostreams -lboost_filesystem -lboost_system -lboost_timer -lboost_chrono -lboost_program_options); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; EOD; patch -p0 <mypatch; module load cmake; module load io_lib; module load libgff; module load libtbb; # module load pufferfish #ignored even if set; mkdir build; cd build; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_23.log; make -j 4 2>&1 | tee build_2020_06_23.log; make test # both passed; make install 2>&1 | tee install_2020_06_23.log; cd ..; cp sample_data.tgz $TOPDIR; module_generate_from_directory.sh \; $package \; $pversion \; CentOS/vanilla \; $TOPDIR \; ""Fast highly-accurate, transcript-level quantification estimates from RNA-seq data."" \; ""https://github.com/COMBINE-lab/salmon""; ```. When the following commands are run in an XFCE4 terminal or an uxterm (black text, white background) using the sample data provided in the distribution:. ```; gunzip -c sample_data.tgz | (cd /tmp; tar -xf -); module load salmon; cd /tmp/sample_data; salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type puff; salmon quant -i sample_salmon_fmd_index \; -l IU \; -1 reads_1.fastq -2 reads_2.fastq \; -o sample_salmon_fmd_quant. ```; the output line:. ```; [2020-06-23 13:58:50.657] [jointLog] [warning] Only 10000 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings.; ```. is emitted in ye",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/541:1680,install,install,1680,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/541,1,['install'],['install']
Deployability,"terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:24:37.940] [joint""..., 136) = 136; tgkill(32681, 32681, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```; and for task 2:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:41447,pipeline,pipeline,41447,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:40:15.587] [joint""..., 136) = 136; tgkill(51996, 51996, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```. and for task 2:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:122410,pipeline,pipeline,122410,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"th and trying to run “salmon –version” I get the following error:. dyld: lazy symbol binding failed: Symbol not found: _os_unfair_lock_lock. Referenced from: /Users/douglasbarrows/Tools/salmon_0.11.4-pre_OSX/bin/./salmon (which was built for Mac OS X 10.13). Expected in: /usr/lib/libSystem.B.dylib. dyld: Symbol not found: _os_unfair_lock_lock. Referenced from: /Users/douglasbarrows/Tools/salmon_0.11.4-pre_OSX/bin/./salmon (which was built for Mac OS X 10.13). Expected in: /usr/lib/libSystem.B.dylib. Trace/BPT trap: 5. Is that something you have seen before?. From: Rob Patro <notifications@github.com>; Reply-To: COMBINE-lab/salmon <reply@reply.github.com>; Date: Tuesday, October 23, 2018 at 8:25 PM; To: COMBINE-lab/salmon <salmon@noreply.github.com>; Cc: dougbarrows <dbarrows@mail.rockefeller.edu>, Author <author@noreply.github.com>; Subject: Re: [COMBINE-lab/salmon] Segmentation fault 11 with bioconda build (#303). Thanks for reporting this. It seems there is an osx bioconda issue (likely related to their massive backend upgrade). Hopefully we can fix this upstream in the next release. I. The meantime, can you see if this<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_files_2383948_salmon-5F0.11.4-2Dpre-5FOSX.tar.gz&d=DwMFaQ&c=JeTkUgVztGMmhKYjxsy2rfoWYibK1YmxXez1G3oNStg&r=AcsC5BcigO3PFsA0uPOPf6vTyS2zaocuu4GaWSrIemY&m=wLNfpc7aJ_B1oE6XAqYsYKk5m7_TsLrkikeQql9eerg&s=40WTo4E4Odm5ZPLtYzGnDNBOb05l6L5woT7ke2vQ1L4&e=> OSX binary works for you?. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_303-23issuecomment-2D432468434&d=DwMFaQ&c=JeTkUgVztGMmhKYjxsy2rfoWYibK1YmxXez1G3oNStg&r=AcsC5BcigO3PFsA0uPOPf6vTyS2zaocuu4GaWSrIemY&m=wLNfpc7aJ_B1oE6XAqYsYKk5m7_TsLrkikeQql9eerg&s=2d8a8eiQ0LuIlgyxoiTnsiwesaQ16X9sju0l7tT1WAw&e=>, or mute the thread<https://urldefense.proofpoint.com/v2/url?u=https-3A__gi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/303#issuecomment-432469726:1084,upgrade,upgrade,1084,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/303#issuecomment-432469726,1,['upgrade'],['upgrade']
Deployability,"thank you @alpapan, your post in this open issue had the information that helped me build the latest version of salmon (1.10.0 at this time) on Ubuntu 20 and 22. The documentation at https://salmon.readthedocs.io/en/latest/building.html#requirements-for-building-from-source was not helping with the build errors reported here, which is what I encountered too. . In my case the problem was that I had a custom build of libstaden installed (that I did not want to remove) that cmake was picking up, but which triggered those many libcurl linking errors (misleadingly I would say, since it seems to be related to the way libstaden is installed, not directly libcurl related, which is fine on my system). Here it is the build recipe that worked for me on Ubuntu 20/22:; ```; sudo apt install libboost-iostreams-dev libboost-chrono-dev libboost-filesystem-dev \; libboost-timer-dev libboost-program-options-dev ; PREFIX=$HOME/sw # or wherever you want it; mkdir build && cd build; cmake -DNO_IPO=TRUE -DFETCH_STADEN=TRUE -DCMAKE_INSTALL_PREFIX=${PREFIX} ..; make -j6; make install; ```; Note that the installation message states:; `Please add $PREFIX/lib to your LD_LIBRARY_PATH` ; .. but that does not seem to be needed, the linker seems to resolve those libraries properly in the installation directory.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/425#issuecomment-1445139922:429,install,installed,429,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/425#issuecomment-1445139922,6,['install'],"['install', 'installation', 'installed']"
Deployability,"thanks. From: Rob Patro ***@***.***>; Reply-To: COMBINE-lab/salmon ***@***.***>; Date: Thursday, May 6, 2021 at 1:53 PM; To: COMBINE-lab/salmon ***@***.***>; Cc: ""andrew e. davidson"" ***@***.***>, Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] salmon --writeUnmappedNames produced undocumented result (#657). Hi @aedavids<https://github.com/aedavids>,. Thanks for catching that this is undocumented! This means that the mapping type was determined as mapping to a decoy sequence. When we added this output into the code, the documentation wasn't updated accordingly. We'll update the documentation. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833857753>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AN3VWAQ35L6PU3DKXYIM4ODTML6TPANCNFSM44HLOFXQ>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833861332:555,update,updated,555,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833861332,2,['update'],"['update', 'updated']"
Deployability,the installation of salmon index cannot be completed,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/755:4,install,installation,4,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/755,1,['install'],['installation']
Deployability,"the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 16 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:56:39.675] [jointLog] [info] parsing read library format; [00m[1m[2017-03-29 14:56:39.733] [jointLog] [info] There is 1 library.; [00mterminate called without an active exception; /cm/local/apps/sge/var/spool/compute-067/job_scripts/110316: line 31: 64339 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 16 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}; **** Job ends ****; Wed Mar 29 14:58:05 EDT 2017. ```. ### SGE email example info. ```; Job-array task 110316.1 (step6-salmon_test4.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-067.cm.cluster; Host = compute-067.cm.cluster; Start Time = 03/29/2017 14:53:42; End Time = 03/29/2017 14:58:05; User Time = 00:00:00; System Time = 00:05:39; Wallclock Time = 00:04:23; CPU = 00:05:39; Max vmem = 24.202G; Exit Status = 0; ```. Note that in this case, it didn't read the maximum memory requested (16 * 3 = 48 GB). ## Large memory, p 1. ### Bash. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=80G,h_vmem=90G,h_fsize=100G; #$",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:6475,pipeline,pipeline,6475,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['pipeline'],['pipeline']
Deployability,"the selective alignment algorithm Salmon employs is not well-suited for long reads (#602), and therefore the software needs to be run in alignment mode for accurate counting. My main question then concerns the optimal parameters for the upstream alignment step. The ONT community seems to have settled on using minimap2 for this, but beyond that the guidance gets a bit murky... The [minimap2](https://github.com/lh3/minimap2/#map-long-splice) documentation suggests the following command for mapping long RNA reads:. `minimap2 -ax splice:hq -uf ref.fa reads.fq > aln.sam`. This approach seems to employ a splicing aware algorithm against a genomic reference, using canonical splicing signals to help map the transcripts. However, this method doesn't seem to be applicable to Salmon given the requirement that the reads are aligned directly to the transcriptome (hence the need to account for splicing with '_-ac splice_' is lost). An alternative approach I've seen (i.e., the one used in ONT's own DGE [pipeline](https://github.com/nanoporetech/pipeline-transcriptome-de)) is to use minimap2 to align to the transcriptome reference but to retain a large number of secondary mappings (-N 100 in minimap2):. `minimap2 -ax map-ont -N 100 transcriptome.fa reads.fq`. This makes more sense in terms of the _-ax_ preset used, but I guess I'm just wondering then what the optimal input for Salmon would be in order to get the most accurate count data? I know secondary mappings are important for the algorithm to calculate uncertainty / maximum likelihood, but is there an recommend number of these to retain? The logic behind allowing for a high number of secondary alignments when using a transcriptome reference is to account for the high similarity among isoforms. From a high-level view I could see how this might be problematic though, depending on how Salmon actually uses the alternate mappings (i.e., is it just for the statistics or does it affect the counts as well?). . I've also seen groups to",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/790:1161,pipeline,pipeline,1161,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/790,1,['pipeline'],['pipeline']
Deployability,"the suggestion, I've now been investigating the potential of an index-related issue. Firstly, I downloaded the pre-built salmon index from refgenie using `refgenie pull hg38/salmon_sa_index`. I then ran `salmon quant` using this index and the singularity image of salmon v1.9.0. What, would you know: it worked in about 11 minutes. ```; <truncated>; [2023-02-23 14:46:31.892] [jointLog] [info] Aggregating expressions to gene level; [2023-02-23 14:46:32.452] [jointLog] [info] done; ```. This pre-built index does appear to be decoy-aware:. ```; [2023-02-23 14:38:21.709] [jointLog] [info] Number of decoys : 195; [2023-02-23 14:38:21.709] [jointLog] [info] First decoy index : 177412 ; ```. Secondly, I created a new transcriptome-only salmon index (`singularity run -B /data $SALMON_SIMG salmon index -t genome.transcripts.fa -i salmon_index -k 31`), then ran `salmon quant` again (as above) but using the new transcriptome-only index. Note: 'genome.transcripts.fa' is the transcripts file created during the `nf-core/rnaseq` pipeline. Again, this analysis completed properly in a reasonable time. Seems like there is something very wrong with the 'gentrome.fa' file that's being created by `nf-core/rnaseq`! It's just so odd that _some_ samples would work and others wouldn't. 2. It's definitely worth noting that I originally opted against using `star_salmon` with the following command:. ```; nextflow run nf-core/rnaseq --max_memory 55.GB --fasta /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz --gtf /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.106.gtf.gz --skip_alignment --pseudo_aligner salmon --seq_center 'Ramaciotti Centre for Genomics' --input samplesheet.csv --outdir nf-core_results --save_merged_fastq true --skip_markduplicates true --extra_salmon_quant_args '--seqBias --gcBias --posBias' -profile singularity; ```. I'll re-run (a) using the refgenie salmon index specified; (b) with the `star_salmon` pathway to see if the decoy-aware index c",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948:1426,pipeline,pipeline,1426,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948,1,['pipeline'],['pipeline']
Deployability,"ting the index. It ensures that the index (and hence the resulting quantifications) contain the shortened names for gencode transcripts. In alignment-based mode, the behavior of the flag would have to be slightly different. It would have to re-normalize not only the names of the reference sequences in the fasta file, but it would also have to re-normalize the names in the BAM header so that they match. Specifically, the requirement is that the names of the sequences in the input fasta file are a 1-1 match with the names in the BAM header so that transcripts can be matched up properly with their sequences for training and applying the error model. However, if your BAM file already contains the stripped transcript names (i.e. if the BAM file header has the names without everything past the initial `|`), then I believe you can use the following command to have salmon do the same to the fasta file on the fly, so that the names match. ```{bash}; salmon-1.5.1_linux_x86_64/bin/salmon quant --ont -p 4 -t <(awk '{ if ($0 ~ ""^>"") { split($0,a,""|""); print a[1] } else { print $0 } }' Genome_files/gencode.vM24.transcripts.fa) -l U -a Documents/Day2_03_DRS_pass.bam -o Documents/counts/Day2_03_DRS_pass; ```. If the BAM file contains the ""full"" transcript name however, I think the current options are either to let salmon use the full transcript name from the fasta file, or to modify the GTF when running with minimap2, so that the BAM file itself contains the shortened names. Finally, I'd like to mention that the way you _intended_ to use the `--gencode` flag in alignment mode actually makes _a lot_ of sense, and I think it would be a very nice feature. Basically, the idea would be to apply stripping everything after the first `|` from *both* the fasta header and the BAM header, and using the reduced names for `quant.sf` outputs. We'll certainly. look into adding this functionality in a future release. Apologies for confusion caused by the ambiguous documentation of this flag. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/671#issuecomment-860792782:2101,release,release,2101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/671#issuecomment-860792782,1,['release'],['release']
Deployability,"tory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356\1\3427\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=1926760, ...}) = 0; mmap(0x37e2000000, 3750152, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x37e2000000; mprotect(0x37e218a000, 2097152, PROT_NONE) = 0; mmap(0x37e238a000, 20480, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x18a000) = 0x37e238a000; mmap(0x37e238f000, 18696, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x37e238f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:97239,pipeline,pipeline,97239,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"tory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356\201\r5\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755, st_size=1926760, ...}) = 0; mmap(0x350d800000, 3750152, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x350d800000; mprotect(0x350d98a000, 2097152, PROT_NONE) = 0; mmap(0x350db8a000, 20480, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x18a000) = 0x350db8a000; mmap(0x350db8f000, 18696, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x350db8f000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libdl.so.2"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:21907,pipeline,pipeline,21907,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"tory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/d",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:5739,pipeline,pipeline,5739,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"transcripts, whose estimated number of reads simply have _tremendous_ inferential uncertainty — and small perturbations in the initial conditions of the optimization will lead to different estimated values for their abundances. For those transcripts where you observe such fluctuations between runs, this is simply evidence that the precision that can be confidently placed on those estimates is below the degree of variation you observe. Treating these transcripts in downstream analysis as more certain can easily lead to spurious inferences regarding things like differential transcript expression or usage. . One can make an argument for trying to provide a way to enforce removal of this variation (which, granted, would be a challenge). However, the reason we decided against even attempting this is because it doesn't properly address any issue with respect to an actual biological analysis. That is, even if you could fix, precisely, the update order and initialization conditions for a specific sample to eliminate any variation between runs, almost all experiments consist of multiple samples. In other samples, the same transcript fractions could give rise to a slightly different set of observed fragments that induce exactly the same type of variation under uncertainty; and since that uncertainty is baked into the sample, it cannot and should not be removed. Having exact replication of a sample at a numerical threshold below the inferential uncertainty for a transcript conveys false confidence in the precision of the estimate. This is why, for transcript-level analysis, we highly recommend having salmon produce posterior gibbs samples (with the `--numGibbsSamples` flag). This will draw samples from the posterior distribution over the abundance estimates and allow determination of what inferences can be made robustly and what cannot. We have spent a good deal of time thinking about how to properly perform statistical inference on these uncertain quantities, and so I'd point ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:2654,update,update,2654,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,1,['update'],['update']
Deployability,"tting the reads 50/50 or, with the default settings, giving nearly all the reads to the longer transcript. I realized that, as a human, the reason the short transcript is obviously the dominant one is how the reads pileup in the alignment. There are hundreds of reads mapping to both transcripts, but NO reads map to the 5' of the long transcript. As I understand the selective alignment, the alignment scores are passed to the quantification step, but the *position* of the reads is not used downstream. In order to pass my human intuition along here, the software would need to pay attention to the coverage bias of the reads mapping to the transcripts and assign a penalty when two otherwise identical transcripts have a different coverage variance across the transcript. This sounds like what the --posBias flag should incorporate into the effective lengths, but it doesn't have much effect on these transcripts for me (FYI, I am getting a segfault when I run only --posBias in the current salmon version, but if I run all the models together like --gcBias --seqBias --posBias, it completes fine). . Also, my intuition for these transcripts is not really a coverage ""bias"" as much as the read depth absolutely plummeting at the 5' end of the long transcript. It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. So, for now my workaround is to just modify the transcripts so they are non-overlapping in the transcriptome fasta or to manually count reads after looking at the alignments, but I'd love to hear any more thoughts you have on this problem. Thanks,; Jason",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651:2158,pipeline,pipeline,2158,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651,1,['pipeline'],['pipeline']
Deployability,"turn debug off . if [[ ! -f ""$outputDir""/quant.sf ]]; then. 	mkdir -p ""$outputDir"". # printf ""##############\n"" ; # printf ""warning --minAssignedFrags is set to $minNumFrags to enable test data set\n"" ; # minNumFrags=1 ; # --minAssignedFrags=$minNumFrags \ ; # printf ""##############\n"" . #if [[ -f ""$inputDir""/output_single_end.fq.gz ]]; then . numThr=12; salmon quant \; -i $salmonIndexDir \; --libType A \; -1 ""${rightReads}"" \; -2 ""${leftReads}"" \; -p $numThr \; --recoverOrphans \; --validateMappings \; --gcBias \; --seqBias \; --rangeFactorizationBins 4 \; --writeUnmappedNames \; --output ${outputDir}. salmonRet=$?; if [ $salmonRet -ne 0 ]; then; echo ERROR salmon ""$rightReads"" returned exit status ""$exitStatus""; continue; fi. #fi ; else; echo ""[INFO] skipping ${outputDir}/quant.sf it already exists""; fi; }; ```. Specifically, please provide at least the following information:. * Which version of salmon was used?; * salmon 1.4.0 . * How was salmon installed (compiled, downloaded executable, through bioconda)?; * compiled locally salmon-1.4.0_linux_x86_64.tar.gz; * ; * Which reference (e.g. transcriptome) was used?; * we have custom human ref with additional annotations; * ; * Which read files were used?; paired reads. * Which which program options were used?; * see above. **Expected behavior**; A clear and concise description of what you expected to happen. I think this is a potential documentation issue?. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; - $ lsb_release -a; bash: lsb_release: command not found...; (base) [aedavids@mustard bin]$ uname -a ; Linux mustard 3.10.0-862.6.3.el7.x86_64 #1 SMP Tue Jun 26 16:32:21 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux. **Additional context**; Add any other context a",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/677:2197,install,installed,2197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/677,1,['install'],['installed']
Deployability,"tw; are/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.tr; anscripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/${ID}; **** Job ends ****; Wed Mar 8 11:37:36 EST 2017; ```. and the core dump file shows that the program was terminated:. ```bash; $ gdb core.41232; GNU gdb (GDB) Red Hat Enterprise Linux (7.2-60.el6_4.1); Copyright (C) 2010 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>...; Missing separate debuginfo for the main executable file; Try: yum --disablerepo='*' --enablerepo='*-debug*' install /usr/lib/debug/.build-id/f2/3c99ed06abf17dd0ee1073eac092487ac62314; [New Thread 41232]; [New Thread 41236]; [New Thread 41235]; [New Thread 41234]; Core was generated by `/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/b'.; Program terminated with signal 6, Aborted.; #0 0x0000003612832625 in ?? (); ""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/core.41232"" is a core file.; Please specify an executable to debug.; (gdb) q; ```. The SGE information shows that it basically reached 10.7 GB of RAM:. ```bash; $ qacct -j 9987275 -t 3; ==============================================================; qname shared.q; hostname compute-051.cm.cluster; group lieber_jaffe; owner lcollado; project NONE; department defaultdepartment; jobname step6-salmon_test.gsk_phaseII; jobnumber 9987275; taskid 3; account sge; priority 0; qsub_time Wed Mar 8 11:37:17 2017; start_time Wed Mar 8 11:37:31 2017; end_time Wed Mar 8 11:37:36 2",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:25092,install,install,25092,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['install'],['install']
Deployability,"ude/pthread.h:33,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/x86_64-pc-linux-gnu/bits/gthr-default.h:35,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/x86_64-pc-linux-gnu/bits/gthr.h:148,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/ext/atomicity.h:35,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/bits/ios_base.h:39,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/ios:44,; from /gpfs/software/gcc/13.2.0/include/c++/13.2.0/ostream:40,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/system/error_code.hpp:17,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/system/system_error.hpp:11,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/exceptions.hpp:22,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/pthread/thread_data.hpp:10,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread_only.hpp:17,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread.hpp:12,; from /gpfs/projects/hpc_support/salmon/include/GenomicFeature.hpp:25,; from /gpfs/projects/hpc_support/salmon/src/GenomicFeature.cpp:22:; /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/pthread/thread_data.hpp:60:5: error: missing binary operator before token ""(""; 60 | #if PTHREAD_STACK_MIN > 0; | ^~~~~~~~~~~~~~~~~; In file included from /gpfs/projects/hpc_support/salmon/external/install/include/boost/functional/hash.hpp:6,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/detail/thread.hpp:41,; from /gpfs/projects/hpc_support/salmon/external/install/include/boost/thread/thread_only.hpp:22:; /gpfs/projects/hpc_support/salmon/external/install/include/boost/container_hash/hash.hpp:130:33: warning: ‘template<class _Arg, class _Result> struct std::unary_function’ is deprecated [-Wdeprecated-declarations]; 130 | struct hash_base : std::unary_function<T, std::size_t> {};; | ^~~~~~~~~~~~",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/953:1336,install,install,1336,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/953,1,['install'],['install']
Deployability,"ug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon; **Describe the bug**; A clear and concise description of what the bug is.; The cDNA fasta file contains 176241 ENSTs,but the result file only contains 166667 ENSTs.; **To Reproduce**; Steps and data to reproduce the behavior:; The steps and data are as follows. ; Specifically, please provide at least the following information:. * Which version of salmon was used? v0.9.1; * How was salmon installed (compiled, downloaded executable, through bioconda)?; downloaded executable; * Which reference (e.g. transcriptome) was used? ; Homo_sapiens.GRCh38.cdna.all.fa obtained from Ensembl release 83; * Which read files were used? ; GSE41009; * Which which program options were used? ; Building index: salmon index -t filepath/Homo_sapiens.GRCh38.cdna.all.fa -i V83-homo_index --type quasi -k 31; Quantification: salmon quant -p 50 -i filepath/V83-homo_index -l IU -1 ESC-SRR574820_1.fastq ESC-SRR574821_1.fastq -2 ESC-SRR574820_2.fastq ESC-SRR574821_2.fastq -o ESC-quantification. **Expected behavior**; A clear and concise description of what you expected to happen.; The result file should contain all the ENSTs existed in cDNA fasta file.; **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; uname -a; Linux mn1 2.6.32-431.29.2.2.ky3.1.x86_64 #1 SMP Thu Sep 25 10:15:09 CST 2014 x86_64 x86_64 x86_64 GNU/Linux. lsb_release -a; LSB Version:	:base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch; Distributor ID:	NeoKylin; Description:	NeoKylin release 3.2 (Carambola); Release:	3.2; Codename:	Carambola; **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/255:1881,release,release,1881,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/255,2,"['Release', 'release']","['Release', 'release']"
Deployability,"ugh bioconda (defined in conda environment).; * Which reference (e.g. transcriptome) was used? BY4742 transcriptome generated using gffread (command used: ""gffread -g BY4742.fa -o wt-syn-transcriptome.gff -w wt-syn-transcriptome.fa -v -C BY4742.gff"").; * Which read files were used? Paired end fastq files (trimmed by fastp).; * Which which program options were used? ""--validateMappings --threads 1 --libType A --index transcriptome-index --mates1 sample1_R1_001.trimmed.fastq.gz --mates2 sample1_R2_001.trimmed.fastq.gz --output sample1"". **Expected behavior**; A clear and concise description of what you expected to happen.; Salmon quant to generate quant.sf file. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with bug fixes is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ###; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ validateMappings ] => { }; ### [ threads ] => { 1 }; ### [ libType ] => { A }; ### [ index ] => { transcriptome-index }; ### [ mates1 ] => { sample1_R1_001.trimmed.fastq.gz }; ### [ mates2 ] => { sample1_R2_001.trimmed.fastq.gz }; ### [ output ] => { sample1 }; Logs will be written to sample1/logs; [2023-10-11 16:03:44.489] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-10-11 16:03:44.490] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2023-10-11 16:03:44.490] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies us",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/881:1574,release,releases,1574,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/881,2,"['release', 'upgrade']","['releases', 'upgrade']"
Deployability,update single-cell protocol documentation,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/723:0,update,update,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/723,1,['update'],['update']
Deployability,update stadenio and htscodecs,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/916:0,update,update,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/916,1,['update'],['update']
Deployability,upgrade CMakeLists.txt to use external copies of dependencies & no downloading,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19:0,upgrade,upgrade,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19,1,['upgrade'],['upgrade']
Deployability,"vin (single-cell mode)?**; Alevin; **Describe the bug**; A clear and concise description of what the bug is.; Reanalyzing published Drop-Seq data the alevin analysis results in drastically fewer barcodes accepted than the published dataset. Published dataset contains 3000 CBs for the specific sample (authors report that 70% of [these] putative cells from WT mice met QC criteria), alevin result contains 459 CBs.; A similar highly abbreviated CB result was obtained with reanalysis of SRR8889412. **To Reproduce**; Steps and data to reproduce the behavior:. Data used from Sample: https://www.ebi.ac.uk/ena/browser/view/SRR8889411; Publication: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6925218/#; Specific Sample: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3720936. Alevin was run using no special parameters with the --dropseq flags. The only significant protocol deviation was in index construction (see below). Specifically, please provide at least the following information:. * Which version of salmon was used?; v1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Salmon was run in stock docker container; * Which reference (e.g. transcriptome) was used?; Full decoy Index generated on Gencode M25 per Alevin Velocity tutorial with a k=17 (dataset has 50bp R2 Reads); Introns were extracted with 49bp flanking sequence. ; ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz. * Which read files were used?; Data used from Sample: https://www.ebi.ac.uk/ena/browser/view/SRR8889411; * Which which program options were used?; --dropseq -l ISR. **Expected behavior**; A clear and concise description of what you expected to happen.; Cell calls should be ballpark similar to published result (3000 original vs. 459 alevin). **Tar of Alevin Output directory**; [WT01_P7_WT_Cerebellum_alevin.output.tar.gz](https://github.com/COMBINE-lab/salmon/files/5953855/WT01_P7_WT_Cerebellum_alevin.output.tar.gz)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/625:1118,install,installed,1118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/625,1,['install'],['installed']
Deployability,"vin-tutorial/2018/output-format/](url) . It's the ""Reading Alevin’s bfh (big freaking hash) file"" section, where there are just 2 lines I should run. The problem is on the second line, ""parser.read_bfh()"" function. It throws me a `pandas.errors.ParserError: Error tokenizing data. C error: Expected 1 fields in line 110446, saw 20` . I tried diagnosing the problem and looked into the input bfh.txt file. The problem wasn't just line 110447, but many other lines that had more than 1 field. So the real question breaks down into: should the bfh.txt file have only 1 field per row (line)? If this is the case, then the input bfh.txt file is problematic. If not, then the parser function is problematic, as it should account for more than 1 field. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; * 1.4.0; ; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * conda create -n salmon -c conda-forge -c bioconda salmon; conda activate salmon. * Which reference (e.g. transcriptome) was used?; * generated index via ""Protein-coding transcript sequences"" here : https://www.gencodegenes.org/human/ ; * generated the txp2gene.tsv file via ""Comprehensive Gene Annotation, Region: PRI"" here: ; https://www.gencodegenes.org/human/release_37lift37.html. * Which read files were used?; * 5k_pbmc FASTQ file from 10x: https://support.10xgenomics.com/single-cell-gene-expression/datasets/3.0.2/5k_pbmc_v3; ; * Which program options were used?; `salmon alevin -l ISR -1 5k_pbmc_v3_S1_L001_R1_001.fastq.gz 5k_pbmc_v3_S1_L002_R1_001.fastq.gz 5k_pbmc_v3_S1_L002_R1_001.fastq.gz -2 5k_pbmc_v3_S1_L001_R2_001.fastq.gz 5k_pbmc_v3_S1_L002_R2_001.fastq.gz 5k_pbmc_v3_S1_L003_R2_001.fastq.gz --chromiumV3 -i index -p 10 -o alevin_output --tgMap txp2gene.tsv --dumpBfh --noDedup --dumpBarcodeEq; `. **Expected behavior**; The bfh.txt file should be parsed. In other words, the li",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/650:1157,install,installed,1157,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/650,1,['install'],['installed']
Deployability,"vin/alevin.log"",; ""{out_data}/{sample}/map/aux_info/meta_info.json"",; ""{out_data}/{sample}/map/cmd_info.json"",; ""{out_data}/{sample}/map/libParams"",; ""{out_data}/{sample}/map/logs/salmon_quant.log"",; ""{out_data}/{sample}/map/map.rad"",; ""{out_data}/{sample}/map/unmapped_bc_count.bin"",; params:; job_name = ""map_reads"",; memory = ""select[mem>64] rusage[mem=64]"",; library_type = ""ISR"",; end = 5,; barcodeLength = 16,; umiLength = 8,; out_dir = ""{out_data}/{sample}/map""; log:; ""logs/map_reads/{sample}.out""; threads:; 16; shell:; """"""; salmon alevin \; -l {params.library_type} \; -1 {input.R1} \; -2 {input.R2} \; -i {input.idx} \; -p {threads} \; -o {params.out_dir} \; --tgMap {input.tgmap} \; --end {params.end} \; --barcodeLength {params.barcodeLength} \; --umiLength {params.umiLength} \; --keepCBFraction 1 \; --sketch; """"""; ```. Specifically, please provide at least the following information:. * Which version of salmon was used? v1.5.2; * How was salmon installed (compiled, downloaded executable, through bioconda)? Downloaded [this](https://github.com/COMBINE-lab/salmon/releases/tag/v1.5.2) binary; * Which reference (e.g. transcriptome) was used? Human reference (GRCh38) (from the alevin-fry tutorial [here](https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz)); * Which read files were used? See attached subsampled sub_R1.fastq.gz and sub_R2.fastq.gz from one sample as representative reads.; * Which which program options were used? See above snakemake rule code for program options, which closely follow the options used in the alevin-fry tutorial. **Expected behavior**; A clear and concise description of what you expected to happen. I expected my reads to be mapped and a RAD file to be generated. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Linux (university cluster); - Version [ If you are on OSX, the output of `",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:4648,install,installed,4648,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,1,['install'],['installed']
Deployability,"warnings in the form of '[warning] len : *, but txp.RefLenght : *' appeared in the running log.; How did this occurred? Will this affect the quantification?; salmon version : v1.0.0; reference genome: ensembl GRCh38 release 96; ****gentrome and decoy generating command:****; grep ""^>"" $home/Ensembl_human_v96/Homo_sapiens.GRCh38.dna.primary_assembly.fa | cut -d "" "" -f 1 > decoys_new.txt; sed -i.bak -e 's/>//g' decoys_new.txt; cat $home/Ensembl_human_v96/Homo_sapiens.GRCh38_v96.cdna.all.fa $home/Ensembl_human_v96/Homo_sapiens.GRCh38.dna.primary_assembly.fa > $home/Ensembl_human_v96/gentrome.fa.gz; ; ****salmon index command:****; salmon index -t $home/Ensembl_human_v96/gentrome.fa.gz -d ; $home/Ensembl_human_v96/decoys.txt -p 12 -i ${home}/NGS/salmon_index_human_v96. ****salmon quant command:****; 	salmon quant -i ${home_path}/NGS/salmon_index_human_v96 -l A \; 	-1 ${fastq1} -2 ${fastq2} --validateMappings -p 12 --gcBias \; 	-o $count_path/${sample_name} ; ![image](https://user-images.githubusercontent.com/51859749/69779623-8f70bc80-11e3-11ea-9c94-6be4b9819d28.png)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/457:216,release,release,216,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/457,1,['release'],['release']
Deployability,"was not able to reproduce this yet. Here is my current output:. ```; [100%] Linking CXX executable salmon; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xec4): warning: the use of `tempnam' is dangerous, better use `mkstemp'; [100%] Built target salmon; root@e08cc9670e4a:/salmon-0.10.2/build# make install; [ 6%] Built target libdivsufsort; [ 12%] Built target libbz2; [ 17%] Built target liblzma; [ 24%] Built target libcereal; [ 31%] Built target libgff; [ 36%] Built target libbwa; [ 42%] Built target libstadenio; [ 48%] Built target libspdlog; [ 50%] Built target ksw2pp_sse4; [ 52%] Built target alevin_core; [ 55%] Built target ksw2pp_sse2; [ 60%] Built target ksw2pp_basic; [ 60%] Built target ksw2pp; [ 73%] Built target salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1043,Install,Installing,1043,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Install'],['Installing']
Deployability,"when I run cmake I get: . Cannot find source file:; [...]salmon-0.9.1/external/install/src/rapmap/RapMapFileSystem.cpp; Tried extensions .c .C .c++ .cc .cpp .cxx .m .M .mm .h .hh .h++ .hm .hpp .hxx .in .txx; CMake Error at src/CMakeLists.txt:120 (add_executable):; Cannot find source file:; [...]/salmon-0.9.1/external/install/src/rapmap/rank9b.cpp; Tried extensions .c .C .c++ .cc .cpp .cxx .m .M .mm .h .hh .h++ .hm .hpp .hxx .in .txx. Apart from that the build tries to download libgff, although libgf-dev is installed - it fails because it requires curl, which is not installed - i.e. that should also be tested for. System: Debian GNU/Linux (unstable), amd64 . Best, ; Gert",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181:79,install,install,79,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181,4,['install'],"['install', 'installed']"
Deployability,"whole pipeline runs without problems and the mapping looks good. When I compare the number of reads between Salmon and FeatureCounts, the results are pretty much the same for the nucleus, but for the chloroplast they differ dramatically (e.g. psbI or ATCG00080: Salmon: 24; FeatureCounts: 9277). Looking at the mapping, I would say that FeatureCounts is definitely closer to reality here. ; When I dig deeper, it seems that the genes with the biggest difference between the two analyses are very small genes (e.g. psbI is only 111bp) or tRNAs (which should be removed by the prep method; these would be excluded from the analysis anyway). ; I have now tried several things: I used the nf-core/rnaseq pipeline, skipping the alignment part (--skip_alignment) and using Salmon as a pseudo-aligner (--pseudo_aligner: salmon), which gave results for the chloroplast reads that are quite close to the alignment-based determination by Salmon (e.g. psbI: 372).; I also tried using the pseudo-alignment without the pipeline (indexing: salmon index -t input.fa -r transcripts_index -k 31 pseudomapping: salmon quant -i transcripts_index -l A -1 sequencingdata_R1.fastq.gz -2 sequencingdata_R2.fastq.gz --validate mapping - o transcripts.quant). The result was that the chloroplast numbers were now roughly between the salmon counts from the pipeline and the counts from the pipeline with FeatureCounts. I skipped the trimming part here, so differences are to be expected, but they still seem very high (e.g. psbI 2677).; First, I have no idea where the difference between counts with and without pipelines comes from. I tried to find out what parameters the pipeline uses for Salmon, but I didn't find anything special there.; And secondly, I wonder if Salmon has somehow problems with the chloroplast genome (super small, polycistronic and monocistronic units, partially small genes, high expression levels)? I know there are publications where Salmon has been used for chloroplast read counts, but I haven't ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798:1358,pipeline,pipeline,1358,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798,1,['pipeline'],['pipeline']
Deployability,"x81000) = 0x7fffbf746000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libgcc_s.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0P\36\0\0\0\0\0\0""..., 832) = 832; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbf4c4000; fstat(3, {st_mode=S_IFREG|0644, st_size=56072, ...}) = 0; mmap(NULL, 2151784, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf2b6000; mprotect(0x7fffbf2c3000, 2097152, PROT_NONE) = 0; mmap(0x7fffbf4c3000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0xd000) = 0x7fffbf4c3000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356A\316;\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:57361,pipeline,pipeline,57361,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['pipeline'],['pipeline']
Deployability,"x81000) = 0x7fffbf746000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libgcc_s.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0P\36\0\0\0\0\0\0""..., 832) = 832; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbf4c4000; fstat(3, {st_mode=S_IFREG|0644, st_size=56072, ...}) = 0; mmap(NULL, 2151784, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf2b6000; mprotect(0x7fffbf2c3000, 2097152, PROT_NONE) = 0; mmap(0x7fffbf4c3000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0xd000) = 0x7fffbf4c3000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356\1\3427\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:95821,pipeline,pipeline,95821,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"x81000) = 0x7fffbf746000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libgcc_s.so.1"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0P\36\0\0\0\0\0\0""..., 832) = 832; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbf4c4000; fstat(3, {st_mode=S_IFREG|0644, st_size=56072, ...}) = 0; mmap(NULL, 2151784, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fffbf2b6000; mprotect(0x7fffbf2c3000, 2097152, PROT_NONE) = 0; mmap(0x7fffbf4c3000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0xd000) = 0x7fffbf4c3000; close(3) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/pcre/8.36/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/jags/4.2.0/lib64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/compiler/gcc/4.4.7/netcdf/4.3.2/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/jhpce/shared/community/core/curl/7.43.0/lib/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/2011.11p1/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/cm/shared/apps/sge/current/lib/linux-x64/libc.so.6"", O_RDONLY) = -1 ENOENT (No such file or directory); open(""/lib64/libc.so.6"", O_RDONLY) = 3; read(3, ""\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0p\356\201\r5\0\0\0""..., 832) = 832; fstat(3, {st_mode=S_IFREG|0755",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:20489,pipeline,pipeline,20489,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"x86 powerpc ia64 arm armthumb sparc; configure:3644: checking which match finders to build; configure:3695: result: hc3 hc4 bt2 bt3 bt4; configure:3713: checking which integrity checks to build; configure:3755: result: crc32 crc64 sha256; configure:3792: checking if assembler optimizations should be used; configure:3816: result: no; configure:3847: checking if small size is preferred over speed; configure:3865: result: no; configure:3881: checking if threading support is wanted; configure:3907: result: yes, posix; configure:3940: checking how much RAM to assume if the real amount is unknown; configure:3955: result: 128 MiB; configure:4085: checking if library symbol versioning should be used; configure:4108: result: no; configure:4126: checking for a shell that conforms to POSIX; configure:4167: result: /bin/sh; configure:4208: checking for a BSD-compatible install; configure:4276: result: /usr/bin/install -c; configure:4287: checking whether build environment is sane; configure:4342: result: yes; configure:4493: checking for a thread-safe mkdir -p; configure:4532: result: build-aux/install-sh -c -d; configure:4539: checking for gawk; configure:4569: result: no; configure:4539: checking for mawk; configure:4569: result: no; configure:4539: checking for nawk; configure:4569: result: no; configure:4539: checking for awk; configure:4555: found /usr/bin/awk; configure:4566: result: awk; configure:4577: checking whether make sets $(MAKE); configure:4599: result: yes; configure:4628: checking whether make supports nested variables; configure:4645: result: yes; configure:4771: checking whether ln -s works; configure:4775: result: yes; configure:4795: checking for style of include used by make; configure:4823: result: GNU; configure:4894: checking for gcc; configure:4921: result: /Library/Developer/CommandLineTools/usr/bin/cc; configure:5150: checking for C compiler version; configure:5159: /Library/Developer/CommandLineTools/usr/bin/cc --version >&5; Apple clang version 15.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/912:4503,install,install-sh,4503,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/912,1,['install'],['install-sh']
Deployability,"x_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID} 2> logs/strace_test12_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. Again, here is the `strace` output for task 1 (411 lines):. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:79910,pipeline,pipeline,79910,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"xt -p 12 -i salmon_index --gencode"" (transcriptome and genome from your tutorial: https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/), a segmentation fault occurs. (gdb backtrack is provided below.). **To Reproduce**; Steps and data to reproduce the behavior:. 1. run a docker container using ubuntu:18.04 as image. 2. (packages I installed); apt-get install -y gcc g++ make wget git curl libtbb2-dbg libtbb-dev unzip zlib1g-dev libcurl4-openssl-dev liblzma-dev libbz2-dev libcereal-dev libgff-dev libpkgconfig-perl libjemalloc-dev; /*; gcc (Ubuntu 7.5.0-3ubuntu118.04) 7.5.0; g++ (Ubuntu 7.5.0-3ubuntu118.04) 7.5.0; GNU Make 4.1; */; wget https://github.com/Kitware/CMake/releases/download/v3.13.4/cmake-3.13.4-Linux-x86_64.sh /cmake version 3.13.4/. 3. git clone https://github.com/COMBINE-lab/salmon.git; I'm at the top commit: commit 0813a0a (HEAD -> master, tag: v1.4.0, origin/master, origin/HEAD). 4. In directory salmon/build, I type; > cmake -DFETCH_BOOST=TRUE -DTBB_INSTALL_DIR=/usr/include -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=../stage ..; > make; > make install. 5. following your tutorial https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/; > wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M23/gencode.vM23.transcripts.fa.gz; > wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M23/GRCm38.primary_assembly.genome.fa.gz; > grep ""^>"" <(gunzip -c GRCm38.primary_assembly.genome.fa.gz) | cut -d "" "" -f 1 > decoys.txt; > sed -i.bak -e 's/>//g' decoys.txt; > cat gencode.vM23.transcripts.fa.gz GRCm38.primary_assembly.genome.fa.gz > gentrome.fa.gz; > salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon_index --gencode. ===========Then I get segmentation fault; ![image](https://user-images.githubusercontent.com/24876498/103153659-191b0100-47cd-11eb-942e-fcd99b3cf2e2.png). 6. gdb salmon <corefile>; It seemed to crash at these functions: fixFasta(), fixFastaMain() ; ![image](https://use",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/609:1349,Release,Release,1349,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/609,1,['Release'],['Release']
Deployability,"xz-5.2.0 is no longer available on tukaani.org. More generally, this is the source of future issues (next one with the next release of xz, since no archiving of previous releases on tukaani.org)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/23:124,release,release,124,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/23,2,['release'],"['release', 'releases']"
Deployability,"y precisely what you mean by reproducible? Do you mean that the values in the .sf file are not identical? If so, this is expected behavior. It exists for a number of reasons. The big one is that the initial phase of salmon uses an online inference algorithm so that specific details of the solution are dependent on the order in which the reads are processed (which is random given that multiple threads parse reads and update estimates asynchronously). However, the more important point here is that the inference estimates returned by Salmon (and, for that matter, every other transcript-level expression tool) are the result of a statistical optimization procedure that cannot guarantee a unique global optimal solution (and, in fact, even if a global optimum could be guaranteed, there may be multiple different optima). Thus, there is uncertainty inherent in the statistical problem being solved. Of course, if one ordered updates in the same way and set up the initial conditions precisely the same, there would be convergence to the same result, but any sense of confidence there is illusory. However, Salmon does provide a way to quantify, statistically, confidence in the result. The `--numBootstraps` option will do bootstrap sampling, or the `--numGibbsSamples` option will perform posterior Gibbs sampling. Both of these techniques will provide samples from the posterior distribution, and the variance of these samples will give you some information about the variance in the results that are due purely to the inherent statistical uncertainty in the problem. In the `scripts` folder there is a python script `ConvertBootstrapsToTSV.py` that will convert either the bootstrap or gibbs samples to a easily readable tsv format. These samples represent the estimated number of reads coming from each transcript when sampling from the posterior. These can be used to empirically estimate that statistical uncertainty in the abundance estimates of the different transcripts. Finally, I'll not",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248:955,update,updates,955,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248,1,['update'],['updates']
Deployability,"y related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon. **Describe the bug**; The alignments to two partially overlapping transcripts suggest that only one of the transcripts is expressed, but salmon is assigning the majority of these reads to the other transcript. Even ignoring coverage differences that suggest that transcript ENST00000364953.1 is the source of these reads, this transcript is the only one of the two with unambiguous alignments, and so I would expect salmon to count the rest of the reads for this transcript. I tried quantifying this same bam with eXpress, and it produces the expected result of counting all the reads for transcript ENST00000364953.1. The alignments were generated with STAR, aligning to the GRCh38 genome and using STAR's transcriptome bam output (using gencode v35 main annotations). I'm happy to provide the small bam containing these alignments in transcriptome space, but I don't seem to be able to upload this here. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used? 1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? bioconda; * Which reference (e.g. transcriptome) was used? GRCh38/gencode v35; * Which read files were used?; * Which which program options were used? -l 'U'. **Expected behavior**; salmon counting all the reads for transcript ENST00000364953.1. **Screenshots**; <img width=""998"" alt=""salmon_unexpected_counts"" src=""https://user-images.githubusercontent.com/17803131/102898647-cf7e8f00-4437-11eb-90bb-37b8498ba333.png"">. **Desktop (please complete the following information):**; - OS: Ubuntu 18.04; - Version ; Linux 4.15.0-88-generic #88-Ubuntu SMP Tue Feb 11 20:11:34 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux; Distributor ID:	Ubuntu; Description:	Ubuntu 18.04.5 LTS; Release:	18.04; Codename:	bionic. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/605:1187,install,installed,1187,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/605,2,"['Release', 'install']","['Release', 'installed']"
Deployability,"y); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib"", {st_mode=S_IFDIR|0755, st_size=33280, ...}) = 0; open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:5575,pipeline,pipeline,5575,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,4,['pipeline'],['pipeline']
Deployability,"y/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test2/R10002_C29P7ACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test2/R10002_C29P7ACXX/logs; [2017-03-08 11:53:36.762] [jointLog] [info] parsing read library format; [2017-03-08 11:53:36.763] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-060/job_scripts/9987283: line 31: 1629 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Softw; are/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.tr; anscripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test2/${ID}; **** Job ends ****; Wed Mar 8 11:53:40 EST 2017; ```. as well as the `gdb` output for it's core dump file:. ```bash; $ gdb core.1629; GNU gdb (GDB) Red Hat Enterprise Linux (7.2-60.el6_4.1); Copyright (C) 2010 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>; This is free software: you are free to change and redistribute it.; There is NO WARRANTY, to the extent permitted by law. Type ""show copying""; and ""show warranty"" for details.; This GDB was configured as ""x86_64-redhat-linux-gnu"".; For bug reporting instructions, please see:; <http://www.gnu.org/software/gdb/bugs/>...; Missing separate debuginfo for the main executable file; Try: yum --disablerepo='*' --enablerepo='*-debug*' install /usr/lib/debug/.build-id/f2/3c99ed06abf17dd0ee10",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:29872,pipeline,pipeline,29872,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['pipeline'],['pipeline']
Deployability,"yAlignments.cpp.o -o salmon -L/root/soft/salmon/salmon-0.6.0/lib -L/root/soft/salmon/salmon-0.6.0/external/install/lib -L/opt/boost/boost_1_57_0/lib -rdynamic libsalmon_core.a -lgff -lpthread /opt/boost/boost_1_57_0/lib/libboost_iostreams.a /opt/boost/boost_1_57_0/lib/libboost_filesystem.a /opt/boost/boost_1_57_0/lib/libboost_system.a /opt/boost/boost_1_57_0/lib/libboost_thread.a /opt/boost/boost_1_57_0/lib/libboost_timer.a /opt/boost/boost_1_57_0/lib/libboost_chrono.a /opt/boost/boost_1_57_0/lib/libboost_program_options.a /opt/boost/boost_1_57_0/lib/libboost_serialization.a ../../external/install/lib/libstaden-read.a -lz ../../external/install/lib/libdivsufsort.a ../../external/install/lib/libdivsufsort64.a ../../external/install/lib/libjellyfish-2.0.a ../../external/install/lib/libbwa.a -lm ../../external/install/lib/liblzma.a -lbz2 -ltbb -ltbbmalloc -lgomp -lrt ../../external/install/lib/libjemalloc.a -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib""; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xd26): warning: the use of `tempnam' is dangerous, better use `mkstemp'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `tbb::strict_ppl::internal::concurrent_queue_base_v3<UnpairedRead*>::internal_push(void const*, void (*)(UnpairedRead**, void const*)) [clone .constprop.1465]':; SalmonQuantifyAlignments.cpp:(.text+0x136d): undefined reference to `tbb::internal::throw_exception_v4(tbb::internal::exception_id)'; CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o: In function `tbb::strict_ppl::internal::concurrent_queue_base_v3<ReadPair*>::internal_push(void const*, void (*)(ReadPair**, void const*)) [clone .constprop.1477]':; SalmonQuantifyAlignments.cpp:(.text+0x161d): undefined reference to `tbb::internal::throw_exception_v4(tbb::internal::exception_id)'; ```. I'm using ; gcc 4.8.2; boost 1.5.7; icc 15.0.0 20140723",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/43:2985,install,install,2985,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/43,2,['install'],['install']
Deployability,"yes `--no-version-check` does the trick, but among all the users of the cluster I'm pretty sure some of them will forgot ;-). on our local installation I disabled the getVersionMessage even if salmon handle the no network cleanly. (I tested using `unshare -n salmon whatever you want`); NB debian maintainer also disabled the phone home call in their packages. sorry if it it may sound harsh",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617310271:139,install,installation,139,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617310271,1,['install'],['installation']
Deployability,"ze = 2665509853; -----------------------------------------; | Loading positions | Time = 4.3613 s; -----------------------------------------; size = 3516045923; -----------------------------------------; | Loading reference sequence | Time = 360.88 ms; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 985.04 us; -----------------------------------------; [2023-02-23 09:40:13.935] [jointLog] [info] done; ```; (taken from the terminal as the logfile is empty, and the current time is 12:54 pm = >3 hr run time so far). **To Reproduce**; I ran the following command:. ```; salmon quant \; --geneMap Homo_sapiens.GRCh38.106.gtf \; --threads 6 \; --libType=ISR \; --index salmon_index \; -1 ACV_REP2_1_val_1.fq.gz -2 CV_REP2_2_val_2.fq.gz \; --seqBias --gcBias --posBias \; -o ACV_REP2; ```; * Which version of salmon was used? v1.9.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? `nf-core/rnaseq`: via singularity; while running manually to troubleshoot: conda.; * Which reference (e.g. transcriptome) was used? Homo_sapiens.GRCh38 transcriptome + genome as a 'gentrome'; * Which read files were used? newly sequenced bulk RNAseq reads. **Expected behavior**; All samples with similar numbers of reads using the same index to finish in roughly the same amount of time. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: Pop!_OS 22.04 LTS x86_64 [Linux]; - Version: ; ``` ; $ uname -a; Linux pop-os 6.0.2-76060002-generic #202210150739~1666289067~22.04~fe0ce53 SMP PREEMPT_DYNAMIC Thu O x86_64 x86_64 x86_64 GNU/Linux. $lsb_release -a; No LSB modules are available.; Distributor ID:	Pop; Description:	Pop!_OS 22.04 LTS; Release:	22.04; Codename:	jammy; ```. **Additional context**; - I can't share these reads publicly but might be able to share personally (but I'd have",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/830:11177,install,installed,11177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/830,1,['install'],['installed']
Deployability,"} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID} 2> logs/strace_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. This requests SGE 2 cores with a total free memory of 2 * 7 = 14 GB and a maximum memory of 16 GB. This is the `strace` output for task 1:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64/libpthread.so.0"", O_RDONLY) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/x86_64"", 0x7fffffffb4f0) = -1 ENOENT (No such file or directory); open(""/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:4577,pipeline,pipeline,4577,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['pipeline'],['pipeline']
Deployability,"} ;"" > ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_1_66_0/tools/build/src/user-config.jam. /path/to/b2 .. toolset=${CC} ...; ```; ; There are still challenges to fix it. 1. The `make test` was finished with timeout. When setting `travis_wait 30 make test`, still failed with the timeout. Maybe we need to change the unit test logic to output something (log or progress bar) regularly to `stdout` during the test process or change the test logic itself. It is freezing at the below point. ```; /usr/local/cmake-3.9.2/bin/ctest --force-new-ctest-process ; Test project /home/travis/build/junaruga/salmon/build; Start 1: unit_tests; ```. 2. The `b2` parameter string `toolset=gcc-7 cxxflags=-std=c++14` is duplicated like this. Maybe we can change the logic in `CMakeLists.txt`. ```; CC=/usr/bin/gcc-7 CXX=/usr/bin/g++-7 /home/travis/build/junaruga/salmon/external/boost_1_66_0/b2 -d0 -j2 --with-iostreams --with-atomic --with-chrono --with-container --with-date_time --with-exception --with-filesystem --with-graph --with-graph_parallel --with-math --with-program_options --with-system --with-locale --with-timer toolset=gcc-7 toolset=gcc-7 cxxflags=-std=c++14 ""cxxflags= -std=c++14 -I/home/travis/build/junaruga/salmon/external/install/include -L/home/travis/build/junaruga/salmon/external/install/lib"" link=static install; ```. 3. `CMakeLists.txt` and `cmake/*.cmake` have a mixture of the different code formatting style. Aligning for formatting those make us read the files easier. I found the useful information for that. [1][2][3][4].; * 2 or 4 space indent?; * ""Tab"" indent is unintentionally used maybe.; * `set(...)` or `set (...)`.; * `set or SET`. [1] the KDE cmake coding style: https://community.kde.org/Policies/CMake_Coding_Style; [2] Asking the cmake code formatter: https://stackoverflow.com/questions/41446408/is-there-any-utility-that-can-reformat-a-cmake-file; [3] cmake code formatter: https://github.com/cheshirekow/cmake_format; [4] cmake lint: https://github.com/richq/cmake-lint",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/276:1499,install,install,1499,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/276,3,['install'],['install']
Energy Efficiency," ### FAQ; <details>; <summary>Click here to expand the FAQ section</summary>. #### How often will the code scanning analysis run?; By default, code scanning will trigger a scan with the CodeQL engine on the following events:; * On every pull request — to flag up potential security problems for you to investigate before merging a PR.; * On every push to your default branch and other protected branches — this keeps the analysis results on your repository’s *Security* tab up to date.; * Once a week at a fixed time — to make sure you benefit from the latest updated security analysis even when no code was committed or PRs were opened. #### What will this cost?; Nothing! The CodeQL engine will run inside GitHub Actions, making use of your [unlimited free compute minutes for public repositories](https://docs.github.com/en/actions/learn-github-actions/usage-limits-billing-and-administration#about-billing-for-github-actions). #### What types of problems does CodeQL find?; The CodeQL engine that powers GitHub code scanning is the exact same engine that powers LGTM.com. The exact set of rules has been tweaked slightly, but you should see almost exactly the same types of alerts as you were used to on LGTM.com: we’ve enabled the [`security-and-quality` query suite](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs) for you. #### How do I upgrade my CodeQL engine?; No need! New versions of the CodeQL analysis are constantly deployed on GitHub.com; your repository will automatically benefit from the most recently released version. #### The analysis doesn’t seem to be working; If you get an error in GitHub Actions that indicates that CodeQL wasn’t able to analyze your code, please [follow the instructions here](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/troubleshooting-the-codeql-workflow)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/815:2725,power,powers,2725,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/815,2,['power'],['powers']
Energy Efficiency," --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximport). I got a colSum for all my samples and then checked the numbers for the transcripts and the decoys - this lead me to post my original question on this thread.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1177,Adapt,Adapter,1177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapt'],['Adapter']
Energy Efficiency," described in the Bowtie2 manual)](http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-dovetail) are considered discordant. This is the same default behavior imposed by Bowtie2. If you look in the `meta_info.json` file for some of these samples (which is in the `aux_info` subdirectory of the quantification directory for a sample), you can see how many mappings are being discarded by virtue of being dovetail mappings. It is possible to allow such alignments (consider them as concordant) by passing the `--allowDovetail` flag. It is not the case that such alignments are always ""bad"", its simply that one would not expect many fragments to align in such a way, and if these constitute the overwhelming majority of the mappings, one might be suspicious about the underlying data. * Selective alignment actually _aligns_ the reads to the transcriptome. For this purpose, it performs end-to-end alignment. This means that if you suspect that the sample may contain adapters or very low-quality read ends, the reads should be trimmed prior to quantification. It is, therefore, worth checking how the mapping rate changes for some of these samples if the reads are trimmed first. * Selective alignment is more robust than quasi-mapping to the chosen value of `-k`, the minimum match length used when searching for alignments. I noticed that some of the samples contain relatively short reads, so you might see if the mapping rate changes if you adopt a smaller value of `-k` in the index (e.g. we use `23` in the [pre-print](https://www.biorxiv.org/content/10.1101/657874v2.full.pdf)). * You mention that this index doesn't contain any decoy sequence. This of course, should not affect the mapping rate. However, I'd be quite curious to see if you index the reference using the _whole genome_ as decoy (i.e. the SAF method from the pre-print), how many reads are discarded because they map better to a decoy sequence (this information can also be obtained from `meta_info.json`). Thi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798:2780,adapt,adapters,2780,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798,1,['adapt'],['adapters']
Energy Efficiency," it to some degree and matches the corresponding location on the genome. Again, you can test this by changing the required overlap fraction of FeatureCounts. * Why does running salmon outside of nf-core produce much higher counts?. * Since you are indexing *just* the transcriptome, and not including the genome as decoy sequence (as is done in nf-core), then the only thing that will prevent reads from being assigned to the gene in question is if so much of the read overhangs off the end of the annotated transcript that no mapping matches the minimum required alignment score. This is likely to be a much more liberal threshold than what STAR allows, so it also explains why you see higher counts than when alignment mode is used. * Other thoughts / suggestions?. * So, there are several things that you might consider doing if you believe the correct behavior in your case is to assign these reads to such genes. First, when run in mapping mode, salmon has a `--softclipOverhangs` flag that will further reduce the penalty for reads overhanging the annotated end of a transcript. This will allow more reads to map to the transcript even if they can't obtain a good alignment score. Likewise, you can combine this with further reducing the required minimum score using the `--minScoreFraction` [parameter](https://salmon.readthedocs.io/en/latest/salmon.html#minscorefraction). Finally, looking forward, we have developed and been testing even more comprehensive solutions to cases when one wants to allow large amounts of soft-clipping (see e.g. [this tutorial](https://combine-lab.github.io/salmon-tutorials/2021/softclip/)). While those features have not yet been migrated into the main salmon branch, you may find the tutorial instructive and the corresponding feature branch useful. If you believe that the annotations themselves are incomplete/incorrect and that may be leading to some of this behavior, you might consider augmenting or updating those annotations. Finally, I'd be reticent to",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883:3548,reduce,reduce,3548,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883,1,['reduce'],['reduce']
Energy Efficiency," low, but now there's somewhat of an explanation, the average read is shorter than a single k-mer. So, the next thing I tried was indexing with a smaller k; a _really_ small one in this case,`k=15`. Then, I re-ran on the _trimmed_ reads (the fact that the trimming took us from 51-21bp suggests that the reads had a lot of low quality bases, adapter contamination, or both). Under this setting, I still get a very low mapping rate, but it was _much_ higher — `16.766993524863488%`. The final thing I tried was seeing how the mapping rate changed as I altered `--minScoreFraction`, which is the salmon parameter that determines the alignment score that a read must achieve in order to be mapped validly. The default is 0.65. This means that the read cannot have a score < 0.65 * the maximum achievable score for the read given it's length. In the case of a 21bp read, the best score would be a score of 42, so a read must obtain a score >= 27 in order to be mapped. This is already a pretty poor mapping, but I reduced it even more to 0.3 (so any read with a score > 12 would pass). This led to a mapping rate of `~46%`. However, at this point, I'm not sure I would be confident in such mappings. For example, the situation here would be a 21bp read with multiple mismatches and, much of the time, one or more indels. So, my conclusion, at least on this sample, is that the main issue is data quality. Trimming the reads and indexing with a smaller k can lead to a mapping rate `~16%`, and then allowing _really bad_ alignments can take it up to `~45%` (and even more — when I set `--minScoreFraction` to 0.1, I get a mapping rate of `57%`). But the level of confidence that one might derive from poorly-aligned 21bp reads is (and probably should be) quite low. I can't say, of course, that this is the situation with the other samples, as I've not looked at them. However, for this sample, and likely for some or all of the others, there is likely a data quality issue. So, perhaps the first order of",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668:2120,reduce,reduced,2120,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668,1,['reduce'],['reduced']
Energy Efficiency," selective-alignment default of 0.35.; [2021-05-19 18:46:25.303] [jointLog] [info] parsing read library format; [2021-05-19 18:46:25.303] [jointLog] [info] There is 1 library.; [2021-05-19 18:46:25.429] [jointLog] [info] Loading pufferfish index; [2021-05-19 18:46:25.429] [jointLog] [info] Loading dense pufferfish index.; [2021-05-19 18:46:27.087] [jointLog] [info] done; [2021-05-19 18:46:27.087] [jointLog] [info] Index contained 141,069 targets; [2021-05-19 18:46:32.618] [jointLog] [info] Number of decoys : 0; [2021-05-19 18:46:33.428] [jointLog] [info] Automatically detected most likely library type as IU. [2021-05-19 18:49:27.444] [jointLog] [error] . [2021-05-19 18:49:27.506] [jointLog] [error] Processing reads : Error reading from the FASTA/Q stream. Minimum return code for left and right read was (-2). Make sure the file is valid. ```; For rabbitQC's log; ```; Detecting adapter sequence for read1...; CCCAGCCATAACACAGTATCAAACTCCACTATTTGTCTGATCCGTACTTATTACAGCCGT. Detecting adapter sequence for read2...; CCAACTTGGTCTACAAGACGCCACATCCCCTATTATAGAAGAGCTAATAAATTTCCATGA. Read1 before filtering:; total reads: 44178187; total bases: 2140649565; Q20 bases: 1899503304(88.7349%); Q30 bases: 1839878933(85.9496%). Read1 after filtering:; total reads: 34172299; total bases: 1775386278; Q20 bases: 1762557969(99.2774%); Q30 bases: 1737891531(97.8881%). Read2 before filtering:; total reads: 44178187; total bases: 2233386484; Q20 bases: 2180294210(97.6228%); Q30 bases: 2141791820(95.8988%). Read2 aftering filtering:; total reads: 34172299; total bases: 1749324083; Q20 bases: 1731172028(98.9623%); Q30 bases: 1700577336(97.2134%). Filtering result:; reads passed filter: 68344598; reads failed due to low quality: 11353966; reads failed due to too many N: 40048; reads failed due to too short: 8617762; reads with adapter trimmed: 382600; bases trimmed due to adapters: 6698794; reads corrected by overlap analysis: 123572; bases corrected by overlap analysis: 125602. Duplication rate: 1.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/660:2610,adapt,adapter,2610,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/660,1,['adapt'],['adapter']
Energy Efficiency," transcript by salmon) as well as to the genome. It is quite common that the mapping rate to the genome is higher than that to the transcriptome. This is much more a result of what you are aligning _to_ than the aligner. If you were to take the transcriptome, and align to it using Hisat2 with `--no-spliced-alignment` and `--end-to-end` (since there won't be splice junctions when you align to the transcriptome), I'd expect you to get a similar mapping rate as you see in salmon. > I also noticed a high number of mappings discarded because of alignment score. I also wonder why the number of mappings discarded can be larger than num of processed (57113760, the reads number in 1_1.fq.gz). . Good question. The number you are looking at is the number of discarded _mappings_, not the number of discarded _fragments_. The difference is that every fragment can have many potential mappings. The number you are looking at is the total number of attempted _alignments_ that failed to achieve the threshold score. Luckily, salmon reports both numbers. The number of fragments for which _all_ alignments failed to reach the score threshold is `4,196,417`; given in `aux_info.json` by ` ""num_fragments_filtered_vm"": 4196417`. One point to note is that these are all fragments for which mapping is attempted (they had at least one k-mer match the reference), but no alignment was valid up to the threshold. You could try running the quantification again with `--softclip` to allow softclipping of the reads and see if any considerable fraction of these `4196417` failed to align because they overhang the annotated transcripts or contain adapters etc. Nonetheless, even if all of these mapped, the rate would still be ~72%. The remainder of the reads didn't even have a matching k-mer in common with the reference transcriptome, which means they are exceedingly unlikely to have come from the transcripts that were indexed. > Thanks. You're welcome! Please let me know if you have any follow-up questions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-697125235:2029,adapt,adapters,2029,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-697125235,1,['adapt'],['adapters']
Energy Efficiency," v0.8 and 1.2.1. The one that seems most relevant here is the introduction of selective-alignment to replace the quasi-mapping procedure that was originally used in salmon. Selective-alignment actually scores the mappings found to the transcriptome, and rejects alignments whose quality is below a (user-specified) threshold. Here, you can see that, in 1.2.1. * 39 fragments are mapped within the score threshold; * 216 fragments are discarded because no mapping location has an alignment score above the threshold. all together, this means that the total number of ""mapped"" fragments in 1.2.1 is very similar to 0.8 (1.2.1 maps 39+216 = 255, while 0.8 maps 254). However, 1.2.1 discards 216 of the fragments because no mapping is sufficiently good. The default for ""sufficiently good"", by the way, is to have an alignment score of at least 65% of the maximum possible for a read of the given length. For typical RNA-seq data, this is actually quite liberal / generous, and is similar to the type of noise in alignment that Bowtie2 allows with the sensitive flag. In general, the heuristics used in 1.2.1 (selective-alignment) tend to be more sensitive than those used in 0.8 (quasi-mapping), since the mappings are then validated using alignment scoring. However, this does mean that the quality of the alignment along the whole read matters. Thus, it is more important to do quality / adapter trimming in the newer version compared to the older one. There is also a flag in 1.2.1 (`--softclip`) that will allow mismatches / gaps at the ends of reads to not detract from the alignment score. So, these are the main differences. However, looking at the output logs you provided, a couple of basic questions did come to mind. Why are there so few reads to begin with? Even in 0.8, only 254 reads mapped, which is obviously a very small number of reads. Is there something non-typical about this sample? Is it a full RNA-seq sample? Are these reads something atypical (like long reads — ONT or PacBio)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/542#issuecomment-651332239:1497,adapt,adapter,1497,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/542#issuecomment-651332239,1,['adapt'],['adapter']
Energy Efficiency," you linked (see attached logs). This certainly helped, although I'm still nowhere near a time-frame of ~30min. Here are my results:. The 31-mer running took a bit over an hour and consumed ~17GB of memory. This is about half the running time as the previous version, but approx. the same amount of memory requirement (more on that below). The 17-mer running, took 4.5hrs to complete and consumed ~64GB of memory. This particular running is again, about twice as fast, although the time really depends on the memory limitations I gave it. Since it appears that this version no longer crashes when given less than about 250GB of memory, I also tested with 32G and 16GB of memory, just to see what impact this would have on the times. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossib",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:1098,power,powers,1098,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,1,['power'],['powers']
Energy Efficiency,""",; ""{out_data}/ref/idx/ref_indexing.log"",; ""{out_data}/ref/idx/reflengths.bin"",; ""{out_data}/ref/idx/refseq.bin"",; ""{out_data}/ref/idx/seq.bin"",; ""{out_data}/ref/idx/versionInfo.json""; params:; job_name = ""build_idx"",; memory = ""select[mem>64] rusage[mem=64]"",; out_dir = ""{out_data}/ref/idx""; log:; ""logs/build_idx.out""; threads:; 16; shell:; """"""; salmon index \; -t {input.fasta} \; -i {params.out_dir} \; -p {threads}; """"""; ```. Running this rule does generate all the expected output files, including `versionInfo.json`. My pipeline crashes during the next step, where I am attempting to map reads. Again, I followed the code as outlined by the alevin-fry tutorial (tweaked slightly) and my snakemake rule is as follows (apologies that I am still using the deprecated --end, --barcodeLength and --umiLength options; my intention was to update those once I had my pipeline working, but I've gotten stuck on the index build):. ```; rule map_reads: ; # map reads and generate a RAD (Reduced Alignment Data) file; input:; R1 = ""{out_data}/preprocessed_fastqs/{sample}_R1.fastq.gz"",; R2 = ""{out_data}/preprocessed_fastqs/{sample}_R2.fastq.gz"",; idx = rules.build_idx.output,; tgmap = ""{out_data}/ref/transcriptome/transcriptome_splici_fl86_t2g.tsv""; output:; ""{out_data}/{sample}/map/alevin/alevin.log"",; ""{out_data}/{sample}/map/aux_info/meta_info.json"",; ""{out_data}/{sample}/map/cmd_info.json"",; ""{out_data}/{sample}/map/libParams"",; ""{out_data}/{sample}/map/logs/salmon_quant.log"",; ""{out_data}/{sample}/map/map.rad"",; ""{out_data}/{sample}/map/unmapped_bc_count.bin"",; params:; job_name = ""map_reads"",; memory = ""select[mem>64] rusage[mem=64]"",; library_type = ""ISR"",; end = 5,; barcodeLength = 16,; umiLength = 8,; out_dir = ""{out_data}/{sample}/map""; log:; ""logs/map_reads/{sample}.out""; threads:; 16; shell:; """"""; salmon alevin \; -l {params.library_type} \; -1 {input.R1} \; -2 {input.R2} \; -i {input.idx} \; -p {threads} \; -o {params.out_dir} \; --tgMap {input.tgmap} \; --end {params.end} ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:3384,Reduce,Reduced,3384,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,1,['Reduce'],['Reduced']
Energy Efficiency,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; Bulk mode. **Describe the bug**; We uses salmon with ver 0.8 in the beginning, later on we found that it could updated to the latest version. Then after we updated it through conda, the quantify amount was reduced from 200+ to 39. **To Reproduce**; `salmon index -t test.transcripts.fa -i test_index --type puff -k 31 ; salmon quant -l A -i test_index -g annotation.gtf -r test.ccs.fq.gz -z -o test > test.sam`. Specifically, please provide at least the following information:. * Which version of salmon was used?; 0.8.1 to 1.2.1; * How was salmon installed (compiled, downloaded executable, through bioconda)?; through bioconda ; * Which reference (e.g. transcriptome) was used?; transcriptome. **Expected behavior**; what is the different between these two versions? We expected that the result would not have such different like this. And we don't know which one is more accurate. . **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; ![image](https://user-images.githubusercontent.com/47863838/85987901-de542e00-ba20-11ea-916a-fe90ca18586f.png). ![image](https://user-images.githubusercontent.com/47863838/85986442-d4c9c680-ba1e-11ea-9b98-140559ee0149.png). **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; Ubuntu Linux.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/542:292,reduce,reduced,292,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/542,1,['reduce'],['reduced']
Energy Efficiency,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; It is a question related to both salmon and alevin. **Describe the bug**; Hey,. First, thanks a lot for creating and maintaining Salmon!! It is super useful!!. I have run alevin with some scRNA-seq data from 10x (so R1 is the BC +UMI and R2 is the RNA sequence) and by evaluating the logs and the lib_format_counts.json file I can see that there are ~360M of mapped fragments. However, if I run salmon quant in the R2 fastq.gz file I see that ~450M of fragments are now mapping. I do not understand from where are these differences coming.... I can still find differences (reduced though) when using the selective alignment as indicated here: https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/. **To Reproduce**; Steps and data to reproduce the behavior:. For the classic pseudoalignment - Salmon alevin. ```console; cat cmd_info.json; {; ""salmon_version"": ""1.4.0"",; ""libType"": ""ISR"",; ""mates1"": ""Parent_NGSC3_DI_PBMC_R1_alldata.fastq.gz"",; ""mates2"": ""Parent_NGSC3_DI_PBMC_R2_alldata.fastq.gz"",; ""chromiumV3"": [],; ""index"": ""/home/egonie/dato-activo/reference.genomes_kike/GRCh38/gencode/transcriptome_pseudoalignment_salmon"",; ""threads"": ""8"",; ""output"": ""alevin_pseudoalignment_output"",; ""tgMap"": ""/home/egonie/dato-activo/reference.genomes_kike/GRCh38/gencode/tr2g.tsv"",; ""auxDir"": ""aux_info""; }; cat lib_format_counts.json ; {; ""read_files"": ""[ Parent_NGSC3_DI_PBMC_R1_alldata.fastq.gz, Parent_NGSC3_DI_PBMC_R2_alldata.fastq.gz]"",; ""expected_format"": ""ISR"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 360423666,; ""num_assigned_fragments"": 360423666,; ""num_frags_with_concordant_consistent_mappings"": 0,; ""num_frags_with_inconsistent_or_orphan_mappings"": 1760256573,; ""strand_mapping_bias"": 0.0,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 0,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 0,; ""SF"": 0,; ""SR"": 0,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ``` . For the classic pseudoalignment - Salmon ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/702:659,reduce,reduced,659,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/702,1,['reduce'],['reduced']
Energy Efficiency,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; Salmon. **Describe the bug**; Only `u` (unmapped) reads are labelled in the `aux_info/unmapped.txt` file, even when the log file indicates that many fragments were discarded because they are best-mapped to decoys. . **To Reproduce**. This GitHub repository details the motivation and full workflow of my pipeline: https://github.com/greenelab/2022-microberna/. To get the read files, I ran:; ```; rule rnaseq_sample_download:; output:; reads=""outputs/rnaseq_fastp/{sra}.fq.gz"",; json = ""outputs/rnaseq_fastp/{sra}.fastp.json"",; html = ""outputs/rnaseq_fastp/{sra}.fastp.html""; params: tmp_base = lambda wildcards: ""inputs/tmp_raw/"" + wildcards.sra; threads: 1; resources:; mem_mb=8000; run:; row = m.loc[m['experiment_accession'] == wildcards.sra]; fastqs = row['fastq_ftp'].values[0]; fastqs = fastqs.split("";""); if len(fastqs) == 1:; # single end data; download and stream directly to fastp for trimming.; fastq = fastqs[0]; shell(""mkdir -p inputs/tmp_raw""); if not os.path.exists(params.tmp_base + "".fastq.gz""):; shell(""wget -O {params.tmp_base}.fastq.gz ftp://{fastq}""). shell(""fastp -i {params.tmp_base}.fastq.gz --json {output.json} --html {output.html} -R {wildcards.sra} --stdout | gzip > {output.reads}""). # check that the file exists, and if it does, remove raw fastq files; if os.path.exists(output.reads):; os.remove(params.tmp_base + "".fastq.gz""). else:; # paired end data; download both files, interleave, and then remove files; fastq_1 = fastqs[0]; fastq_2 = fastqs[1]; shell(""mkdir -p inputs/tmp_raw""); if not os.path.exists(params.tmp_base + ""_1.fastq.gz""):; shell(""wget -O {params.tmp_base}_1.fastq.gz ftp://{fastq_1}""). if not os.path.exists(params.tmp_base + ""_2.fastq.gz""):; shell(""wget -O {params.tmp_base}_2.fastq.gz ftp://{fastq_2}""). shell(""fastp -i {params.tmp_base}_1.fastq.gz -I {params.tmp_base}_2.fastq.gz --json {output.json} --html {output.html} -R {wildcards.sra} --stdout | gzip > {",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/748:419,green,greenelab,419,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/748,1,['green'],['greenelab']
Energy Efficiency,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; alevin. **Describe the bug**; We have an adapted Celseq2 protocol, where read1 (42bp) is used as the sequencing read and read2 (also 42bp) contains (5' -> 3') the barcode (8bp), UMI (8bp), 26 remaining nt's. Alevin seems to run fine, but the quant matrix has a very low UMI count, which does not fit with the _MappedUMI.txt_ file or the reported alignment rate.; ; **To Reproduce**; First, I put the UMI in front of the barcode.; `zcat R2.fastq.gz | paste - - - - | awk '{print $1"" ""$2""\n""substr($3,9,8)substr($3,1,8)substr($3,17)""\n""$4""\n""$5}' | pigz -p8 > R2_Alevin.fq.gz`. then, I run Alevin with:; `salmon alevin -lA -i ref_genome/index/ --barcodeLength 8 --umiLength 8 --end 5 -1 fq/R2_Alevin.fq.gz -2 fq/R1.fastq.gz -p 8 --tgMap ref_genome/gencode.vM20.tx2gene.tsv -o alevin_out --dumpUmiGraph --dumpFeatures --dumpCsvCounts --whitelist BC.whitelist`. This seems to work: the library is 47M and the _filtered_cb_frequency.txt_ contains 43M assigned barcodes in total. The _MappedUmi.txt_ contains 18.5M UMIs, fitting perfectly with the reported alignment rate of ~40% (which is relatively low, but OK for this library). Also if I use the `--dumpfq` option, the barcodes and UMIs are nicely attached to the sequencing reads. Strangely, if I sum the entries in the CSV or binary quant matrix, I get ~3.75M reads. ; ; I was able to run the 10x PBMC4k example and there, the sum of the count matrix entries indeed fitted the reported UMI counts and mapping rate. . Specifically, please provide at least the following information:. * Which version of salmon was used?; salmon 0.13.1. * How was salmon installed (compiled, downloaded executable, through bioconda)?; downloaded executable and bioconda give the same result. * Which reference (e.g. transcriptome) was used?; mouse gencode vM20 (mm10). * Which read files were used?; adapted celseq2 protocol. * Which program options were used?; See above. **Expected ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361:127,adapt,adapted,127,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361,1,['adapt'],['adapted']
Energy Efficiency,"**_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1401,adapt,adapter,1401,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapt'],['adapter']
Energy Efficiency,", and the System Monitor seems to be working fine (salmon is an active process using 12% CPU, 6.9 GiB memory, 13.5 GiB Disk read total, N/A Disk write total, Disk read 1.2 MiB/s (sometimes 1.1 or 1.3), Disk write N/A, Priority normal); and the Resources Tab shows that ; * out of 8 available CPUs, one is working at 100% (the others 5% at max) and ; * Memory 99.3% (which is only 7.7 GiB); * swap 9.5% (which is only 2 GiB of 21.4 GiB available). So here are (finally) my questions:. 1. How can I get Salmon to use the swap (I set swappiness to 100, and it still doesn't seem to care about the swap); 2. Is it normal that there is nothing ""visible"" happening during Round0?; 3. How can I see or check if it is still working (and it might be worthwhile to wait longer)? ; 4. Is what I'm doing correct to create an index file for running Salmon on human RNA-seq data that is supposed to ""end up"" in sleuth?; 5. Is there another way to create an index file that I can use as an index file to create input data for sleuth from RNA-seq data using Salmon (that might need less computational power)?. The last lines of the output are:. [2021-04-02 08:46:48.282] [puff::index::jointLog] [warning] Entry with header [ENST00000634174.1|ENSG00000282732.1|OTTHUMG00000191398.1|OTTHUMT00000487783.1|AC073539.7-201|AC073539.7|28|unprocessed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping). [2021-04-02 08:48:32.206] [puff::index::jointLog] [warning] Removed 833 transcripts that were sequence duplicates of indexed transcripts.; [2021-04-02 08:48:32.207] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2021-04-02 08:48:33.535] [puff::index::jointLog] [info] Replaced 151,122,967 non-ATCG nucleotides; [2021-04-02 08:48:33.536] [puff::index::jointLog] [info] Clipped poly-A tails from 1,833 transcripts; wrote 233807 cleaned references; [2021-04-02 08:50:46.347] [puff::index::jointLog] [info",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/643:4913,power,power,4913,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/643,1,['power'],['power']
Energy Efficiency,", sampleRoundNonCollapsedMultithreaded_(std::vector<std::pair<TranscriptGroup const, TGValue>, std::allocator<std::pair<TranscriptGroup const, TGValue> > >&, std::vector<bool, std::allocator<bool> >&, std::vector<unsigned long, std::allocator<unsigned long> >&, std::vector<double, std::allocator<double> >&, std::vector<double, std::allocator<double> >&, Eigen::Matrix<double, -1, 1, 0, -1, 1>&, std::vector<double, std::allocator<double> > const&, std::vector<double, std::allocator<double> >&, std::vector<unsigned int, std::allocator<unsigned int> >&)::{lambda(tbb::blocked_range<unsigned long> const&)#2}, tbb::auto_partitioner const>::execute() (); #3 0x00007f20171ca492 in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f1fd8dc0c00, parent=..., child=<optimized out>); at ../../src/tbb/custom_scheduler.h:469; #4 0x00007f20171c85a0 in tbb::internal::generic_scheduler::local_spawn_root_and_wait (this=0x7f1fd8dc0c00, first=..., next=@0x7f1fd8db7d38: 0x7f1fd8db7340); at ../../src/tbb/scheduler.cpp:649; #5 0x0000000000632eba in sampleRoundNonCollapsedMultithreaded_(std::vector<std::pair<TranscriptGroup const, TGValue>, std::allocator<std::pair<TranscriptGroup const, TGValue> > >&, std::vector<bool, std::allocator<bool> >&, std::vector<unsigned long, std::allocator<unsigned long> >&, std::vector<double, std::allocator<double> >&, std::vector<double, std::allocator<double> >&, Eigen::Matrix<double, -1, 1, 0, -1, 1>&, std::vector<double, std::allocator<double> > const&, std::vector<double, std::allocator<double> >&, std::vector<unsigned int, std::allocator<unsigned int> >&) (); #6 0x000000000063936f in bool CollapsedGibbsSampler::sample<ReadExperiment>(ReadExperiment&, SalmonOpts&, std::function<bool (std::vector<double, std::allocator<double> > const&)>&, unsigned int) (); #7 0x000000000065d783 in salmonQuantify(int, char**) (); #8 0x000000000057dbcf in main (); Detaching from program: /home/ryan/bin/salmon, process 29153; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267534520:3099,schedul,scheduler,3099,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267534520,1,['schedul'],['scheduler']
Energy Efficiency,"--noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximport). I got a colSum for all my samples and then checked the numbers for the transcripts and the decoys - this lead me to post my original question on this thread.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1273,Adapt,Adapter,1273,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapt'],['Adapter']
Energy Efficiency,"-cell RNA-seq experiment because map to introns. <img width=""400"" alt=""image"" src=""https://user-images.githubusercontent.com/5101911/69015737-65272f80-0997-11ea-87ab-9237e105622a.png"">. ### Loss of reads by using exonic references. Both Alevin and Cell ranger count only reads aligned to exons by default, thus losing some 35% of the reads. Large intronic proportions are a general feature of single-cell RNA-seq, for example the 10X PBMCs has ~20-25%, and nuclear data sets have 46% intronic reads in [[source](https://kb.10xgenomics.com/hc/en-us/articles/360000087552-Why-do-I-have-a-high-percentage-of-reads-mapping-to-intronic-regions-)]. . **So the best way to increase library 'quality' / counting statistics (which is my prime concern) seem to be including reads mapped to introns – leading to hopefully a large increase in UMIs.**. ### Considerations: separate, additive signals. Since exons and introns contain different biological signal, ideally I would like to count as:. 1. Exon only 		(current)* ; 2. Intron only 		(as control / comparison to 1.) ; 3. Exon + intron 	(finally, for boosting statistics) . Where 2 would be a complementary set to 1, so that no read is counted as both intron and exon, and thus 1+2 =~ 3. . \* _I am not sure what happens to a read that maps to an exon/intron junction using the default Alevin and 10x Cell Ranger pipelines, but I assume both count it as exonic._. ### Solution by counting programs. - There is a way to build a ""pre-mRNA"" reference for 10X Cell ranger as described [here](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/advanced/references#premrna). . - I wondered if Alevin can be adapted to this aim? I guess besides all complete transcript models, you need to add one more: the pre-mRNA. (While some complexity can theoretically arise by the serial nature of splicing, I would ignore it at first). Would that be a good idea, or the advantage of Alevin would evaporate if we include introns?. Thanks!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/450:1827,adapt,adapted,1827,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/450,1,['adapt'],['adapted']
Energy Efficiency,"-zero). Thus, if the only mapping for a read disagrees with the expected type, it will still be used. There is a way to modify this behavior, but since stranded library prep is imperfect, the default behavior is the most reasonable for most situations. The reason that you'll see consistency in most cases, regardless of the library type, is as follows. Imagine that I have a read that maps to transcript 1 in the forward orientation and transcript 2 in the reverse orientation. Further, imagine I have a stranded library, and I expect all reads to map in the reverse orientation. If the mapping to transcript 1 is ""spurious"", there are unlikely to be many othe reads mapping to that transcript in this manner, while we would expect other reads to map to transcript 2 in the prescribed manner. Since Salmon considers all of the reads in its probabilistic model when deciding how each read should be allocated, the fact that many reads map to transcript 2 will increase its abundance and, likewise, increase the probability that we assign this read to transcript 2 --- that is, the other mappings will help us make the right choice, regardless of the fact that we neglected to assign a stranded library type. That said, there are situations where the library type makes a difference. This is most often for a few transcripts that are very sequence similar (e.g. Paralogs that happen to be on opposite strands). In this case, most of the reads that map to one transcript will map to the other as well. In this case, the much larger conditional probability of agreeing with the prescribed library type will cause these reads to be allocated to the transcript to which they map in the expected orientation. However, the fraction of such transcripts is usually a small proportion of all expressed transcripts in an experiment, which is why, even if you do have a stranded library and some strand-specific expression, you'd expect the overall concordance to be very high between runs with different provide",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-238090033:1479,allocate,allocated,1479,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-238090033,1,['allocate'],['allocated']
Energy Efficiency,"/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1583,adapt,adapter,1583,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapt'],['adapter']
Energy Efficiency,"/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4522,adapt,adapters,4522,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['adapt'],['adapters']
Energy Efficiency,"022-06-01 18:14:47.999] [puff::index::jointLog] [info] Replaced 73,600,668 non-ATCG nucleotides; [2022-06-01 18:14:47.999] [puff::index::jointLog] [info] Clipped poly-A tails from 647 transcripts; wrote 116780 cleaned references; [2022-06-01 18:14:53.762] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers; [2022-06-01 18:15:29.014] [puff::index::jointLog] [info] ntHll estimated 2268760823 distinct k-mers, setting filter size to 2^36; Threads = 60; Vertex length = 31; Hash functions = 5; Filter size = 68719476736; Capacity = 2; Files: ; Mus_musculus.GRCm39_v1.8.0_decoy.index/ref_k31_fixed.fa. Round 0, 0:68719476736; Pass	Filling	Filtering; 1	104	79	; 2	75	5; True junctions count = 14895414; False junctions count = 1201318; Hash table size = 16096732; Candidate marks count = 337141231. Reallocating bifurcations time: 8; True marks count: 335754103; Edges construction time: 117. Distinct junctions = 14895414. TwoPaCo::buildGraphMain:: allocated with scalable_malloc; freeing.; TwoPaCo::buildGraphMain:: Calling scalable_allocation_command(TBBMALLOC_CLEAN_ALL_BUFFERS, 0);; allowedIn: 21; Max Junction ID: 14896947; seen.size():119175585 kmerInfo.size():14896948; approximateContigTotalLength: 1087128541; counters for complex kmers:; (prec>1 & succ>1)=3126880 | (succ>1 & isStart)=773 | (prec>1 & isEnd)=671 | (isStart & isEnd)=30; contig count: 24974474 element count: 3020582944 complex nodes: 3128354; # of ones in rank vector: 24974473; [2022-06-01 18:28:09.708] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.; [2022-06-01 18:28:09.708] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory Mus_musculus.GRCm39_v1.8.0_decoy.index; size = 3020582944. | Loading contigs | Time = 469.49 ms. size = 3020582944. | Loading contig boundaries | Time = 242.8 ms. Number of ones: 24974473; Number of ones per inventory item: 512; Inventory entries filled: 48779; 24974473; [2022-06-01",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/783:11768,allocate,allocated,11768,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/783,1,['allocate'],['allocated']
Energy Efficiency,"16:02:11.267] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:single end, relative orientation:none, strandedness:unstranded }; [2023-01-29 16:02:11.308] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam"", fasta = ""/rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas"" . . .done. processed 0 reads in current round[2023-01-29 16:02:12.216] [jointLog] [info] replaced 186,207 non-ACGT nucleotides with random nucleotides; [2023-01-29 16:02:12.668] [jointLog] [info] Automatically detected most likely library type as U. processed 2000000 reads in current round[2023-01-29 16:02:13.116] [jointLog] [info] . The alignment group queue pool has been exhausted. 1842 extra fragments were allocated on the heap to saturate the pool. No new fragments will be allocated. processed 13423395 reads in current round; killing thread 3 . . . done. Freeing memory used by read queue . . . 00000; Joined parsing thread . . . ""leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam"" ; Closed all files . . . ; Emptied frag queue. . . ; Emptied Alignment Group Pool. . ; Emptied Alignment Group Queue. . . done; [2023-01-29 16:02:59.265] [jointLog] [info] . Completed first pass through the alignment file.; Total # of mapped reads : 13423395; # of uniquely mapped reads : 13423394; # ambiguously mapped reads : 1. [2023-01-29 16:02:59.271] [jointLog] [info] Computed 169 rich equivalence classes for further processing; [2023-01-29 16:02:59.272] [jointLog] [info] Counted 13,423,395 total reads in the equivalence classes ; [2023-01-29 16:02:59.272] [jointLog] [info] starting optimizer; [2023-01-29 16:02:59.274] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2023-01-29 16:02:59.274] [jointLog] [info] iteration = 0 | max rel diff. = 237.557; [",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/825:2894,allocate,allocated,2894,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/825,1,['allocate'],['allocated']
Energy Efficiency,"16:06:31.513] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:single end, relative orientation:none, strandedness:unstranded }; [2023-01-29 16:06:31.580] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""apex_infe_t1_rep1_S29_R1_001Aligned.out.bam"", fasta = ""/rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas"" . . .done. processed 0 reads in current round[2023-01-29 16:06:34.583] [jointLog] [info] replaced 186,207 non-ACGT nucleotides with random nucleotides; processed 2000000 reads in current round[2023-01-29 16:06:35.068] [jointLog] [info] Automatically detected most likely library type as U. [2023-01-29 16:06:35.443] [jointLog] [info] . The alignment group queue pool has been exhausted. 1955 extra fragments were allocated on the heap to saturate the pool. No new fragments will be allocated. processed 26000000 reads in current roundSegmentation fault (core dumped); ```. Output for failure case - four files. ```; salmon quant -t /rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas -l A -a leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam leaf_mock_t6_rep1_S40_R1_001Aligned.out.bam leaf_mock_t5_rep3_S63_R1_001Aligned.out.bam leaf_mock_t5_rep1_S39_R1_001Aligned.out.bam -p 8 -o ../SalmonQuantFiles; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.9.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { /rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas }; # [ libType ] => { A }; # [ alignments ] => { leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam leaf_mock_t6_rep1_S40_R1_001Aligned.out.bam leaf_mock_t5_rep3_S63_R1_001Aligned.out.bam leaf_mock_t5_rep1_S39_R1_001Aligned.out.bam }; # [ threads ] => { 8 }; # [ output ] => { ../SalmonQuantFiles }; Logs will be written to ../Sa",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/825:7867,allocate,allocated,7867,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/825,1,['allocate'],['allocated']
Energy Efficiency,"303] [jointLog] [info] There is 1 library.; [2021-05-19 18:46:25.429] [jointLog] [info] Loading pufferfish index; [2021-05-19 18:46:25.429] [jointLog] [info] Loading dense pufferfish index.; [2021-05-19 18:46:27.087] [jointLog] [info] done; [2021-05-19 18:46:27.087] [jointLog] [info] Index contained 141,069 targets; [2021-05-19 18:46:32.618] [jointLog] [info] Number of decoys : 0; [2021-05-19 18:46:33.428] [jointLog] [info] Automatically detected most likely library type as IU. [2021-05-19 18:49:27.444] [jointLog] [error] . [2021-05-19 18:49:27.506] [jointLog] [error] Processing reads : Error reading from the FASTA/Q stream. Minimum return code for left and right read was (-2). Make sure the file is valid. ```; For rabbitQC's log; ```; Detecting adapter sequence for read1...; CCCAGCCATAACACAGTATCAAACTCCACTATTTGTCTGATCCGTACTTATTACAGCCGT. Detecting adapter sequence for read2...; CCAACTTGGTCTACAAGACGCCACATCCCCTATTATAGAAGAGCTAATAAATTTCCATGA. Read1 before filtering:; total reads: 44178187; total bases: 2140649565; Q20 bases: 1899503304(88.7349%); Q30 bases: 1839878933(85.9496%). Read1 after filtering:; total reads: 34172299; total bases: 1775386278; Q20 bases: 1762557969(99.2774%); Q30 bases: 1737891531(97.8881%). Read2 before filtering:; total reads: 44178187; total bases: 2233386484; Q20 bases: 2180294210(97.6228%); Q30 bases: 2141791820(95.8988%). Read2 aftering filtering:; total reads: 34172299; total bases: 1749324083; Q20 bases: 1731172028(98.9623%); Q30 bases: 1700577336(97.2134%). Filtering result:; reads passed filter: 68344598; reads failed due to low quality: 11353966; reads failed due to too many N: 40048; reads failed due to too short: 8617762; reads with adapter trimmed: 382600; bases trimmed due to adapters: 6698794; reads corrected by overlap analysis: 123572; bases corrected by overlap analysis: 125602. Duplication rate: 1.23916%. Insert size peak (evaluated by paired-end reads): 1. JSON report: RabbitQC.json; HTML report: SRR1852518.html; ```; Best,; Ci",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/660:3443,adapt,adapter,3443,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/660,2,['adapt'],"['adapter', 'adapters']"
Energy Efficiency,"6 -i salmon_index --gencode. This seemed to be working fine and got to Round 0 without any problems.; It created the ""twopaco_tmp"" directory about 5 minutes after starting and created a ""bifurcations.bin"" inside this directory. However, 4 hours have passed, and neither the file nor the directory have any new modifications (and the file is still a staggering 0 bytes large). I also read that this will take quite a lot of memory, but there should be some TB left on the hard drive. I created a 21 GiB swap partition which works fine (I've already seen it at 60%, so it is active and recognized and everything despite being on another physical hard drive ; (the 1. hard drive has a dual installation of win 10 and ubuntu 20.4 and the swap from the installation (2 GiB, because I thought that would be enough at the time and tried to save some space ^^) and the 2. hard drive has a swap partition of 20 GiB (with the highest priority of all swaps), which results in a total of 21.4 GiB in the System Monitor Resources Tab). . The system is still responding, and the System Monitor seems to be working fine (salmon is an active process using 12% CPU, 6.9 GiB memory, 13.5 GiB Disk read total, N/A Disk write total, Disk read 1.2 MiB/s (sometimes 1.1 or 1.3), Disk write N/A, Priority normal); and the Resources Tab shows that ; * out of 8 available CPUs, one is working at 100% (the others 5% at max) and ; * Memory 99.3% (which is only 7.7 GiB); * swap 9.5% (which is only 2 GiB of 21.4 GiB available). So here are (finally) my questions:. 1. How can I get Salmon to use the swap (I set swappiness to 100, and it still doesn't seem to care about the swap); 2. Is it normal that there is nothing ""visible"" happening during Round0?; 3. How can I see or check if it is still working (and it might be worthwhile to wait longer)? ; 4. Is what I'm doing correct to create an index file for running Salmon on human RNA-seq data that is supposed to ""end up"" in sleuth?; 5. Is there another way to create an ind",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/643:3772,Monitor,Monitor,3772,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/643,1,['Monitor'],['Monitor']
Energy Efficiency,"; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffbbe5dd000; mprotect(0x7ffbbe5dd000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffbfe5dced0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffbfe5dd9d0, tls=0x7ffbfe5dd700, child_tidptr=0x7ffbfe5dd9d0) = 10754; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti""..., 45terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:24:38.504] [joint""..., 136) = 136; tgkill(10693, 10693, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```. (371 lines for task 1, 368 for task 2). Basically, both fail at a point where `mmap()` cannot allocate memory. So it definitely looks like a memory issue and I don't know if these information gives you any hints. . ## Bumping memory. Bumping the memory request to 28/30GB. This is a scenario where task 2 seems to work ok but tasks 1 and 3 fail. ```bash; #!/bin/bash; #$ -cwd; #$ -pe local 2; #$ -l mem_free=14G,h_vmem=15G,h_fsize=100G; #$ -N step6-salmon_test12.gsk_phaseII; #$ -o ./logs/salmon_test12.$TASK_ID.txt; #$ -e ./logs/salmon_test12.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:77455,allocate,allocate,77455,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['allocate'],['allocate']
Energy Efficiency,"> Alevin adopts efficient algorithms for cellular-barcode whitelist generation, cellular-barcode correction, lightweight per-cell UMI deduplication and quantification. Is it possible to use Salmon as a standalone tool to extract and correct the barcodes from 10x Genomics Chromium linked reads and add a `BX:Z` tag to the FASTQ header? That is to say, can Salmon be used as a drop-in replacement for `longranger basic`?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/233:16,efficient,efficient,16,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/233,1,['efficient'],['efficient']
Energy Efficiency,"@GWW,. First, thanks for trying this out and for filing the report. We're eager to reproduce this, figure out what's going on, and fix it. It's theoretically possible to use something like [cgroups](http://man7.org/linux/man-pages/man7/cgroups.7.html) to limit the number of threads that the process could even allocate. However, it really should not be allocating more threads than are being given (+1 for the asynchronous logger thread). Can you please provide some details about the specific OS and version you're running on where you are seeing this behavior?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395826503:311,allocate,allocate,311,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395826503,1,['allocate'],['allocate']
Energy Efficiency,"@ctb — One thing that would be required for this (apart from some engineering of the command-line parsing / validation code) is a trustworthy, efficient, _multithreaded_ `FAST(A/Q)` parser for interleaved format reads. Right now, Salmon (& Sailfish, &RapMap, & most of the other HTS-centric methods we're developing) use the Jellyfish 2 read parser. I've made this choice since it's fairly simple to use, yet provides nice parallel performance and, most importantly, is fairly well-tested and trust-worthy. Can you suggest a reliable, well-tested, concurrency-enabled library for parsing reads in interleaved format?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152827801:143,efficient,efficient,143,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152827801,1,['efficient'],['efficient']
Energy Efficiency,"@k3yavi It seems like indexing both mature and un-spliced transcripts in one index, quantifying them jointly, and then post processing (re-normalizing) the two feature types could be a bit more efficient. Is there any obvious advantage to explicitly specifying which features are decoys vs. mapping and quantifying everything in one go?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/450#issuecomment-555288890:194,efficient,efficient,194,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/450#issuecomment-555288890,1,['efficient'],['efficient']
Energy Efficiency,"@rob-p I would request that you try out bbduk and bbmap for quality/adapter trimming and contaminant removal.; > Thank you for verifying @zhangchipku, For the time being, I can recommend `fastp` as a fairly efficient / fast trimmer that. It might even be able to work in a streaming fashion so that you could pipe the trimmed reads directly to salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-592995074:68,adapt,adapter,68,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-592995074,2,"['adapt', 'efficient']","['adapter', 'efficient']"
Energy Efficiency,"@rob-p thanks for merging! I wish the Travis CI's lint task helps to fix the warnings, and keep the consistent format of `cmake` files!; Eventually we will see the green color passing the lint check on the Travis CI page :)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/293#issuecomment-424512831:164,green,green,164,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/293#issuecomment-424512831,1,['green'],['green']
Energy Efficiency,"@zhangchipku,. Yes, it seems that the biggest culprit here is `num_fragments_filtered_vm`. That is the number of fragments filtered because the best alignment failed to reach the threshold for a ""valid"" alignment. Here, `47,470,013` fragments are discarded entirely because they didn't have an alignment meeting the required quality. If these fragments (which do have matching MEMs, because alignment was carried out for them) were mapped, then the overall mapping rate would go up to `50,729,814 + 47,470,013 = 98,199,827 / 107,275,750 = ~91.5%`. Now, I wouldn't expect _all_ of these to be mappable, and some alignments might not be feasible at any reasonable quality whatsoever. My recommendation would be as follows. First, have you trimmed these reads (using e.g. `fastp` or `TrimGalore` or some such)? Very low quality read ends or (more likely) adapter contamination could cause the reads that have matching MEMs to fail to align within the required score threshold. My first recommendation would be to trim the reads and see how the mapping rate changes. Second, the required alignment score is a user-alterable parameter. By changing `--minScoreFraction` to be lower, you can allow reads with even lower alignment scores to be counted for quantification. The default value is `0.65`, so you could explore what happens if you lower this number. The number represents the fraction of the maximum achievable alignment score that a read must obtain to be considered a valid alignment. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586473052:852,adapt,adapter,852,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586473052,1,['adapt'],['adapter']
Energy Efficiency,"A follow up on this (with a lot of help from @raungar; thanks!) led to the conclusion that the problem was that insufficient memory was allocated to the cluster job during indexing (indexing this transcriptome takes ~4.3G). Allocating more memory to the job resolves the issue. The strange thing is that the cluster manager seemed to kill the job rather than refuse to allocate the memory (which would have resulted in a `bad_alloc` exception that would have made the problem clear). So, if you're indexing with salmon on a cluster and see this behavior, be aware of the memory allocation and that the cluster software may surreptitiously kill the process rather than simply fail to allocate the memory!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467720836:136,allocate,allocated,136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467720836,3,['allocate'],"['allocate', 'allocated']"
Energy Efficiency,"Actually that's a very nice idea! Thanks for sharing it. If we can modularize it into multiple independent components that would reduce the overall complexity and might help differentiate the use cases. I'll definitely raise this in our next alevin meeting. Although, it might take some time to get back regarding this but I will poke back here once we have some progress. Thanks again !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503646040:129,reduce,reduce,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503646040,1,['reduce'],['reduce']
Energy Efficiency,"Actually, ; I was wondering if I could use this method to help me quantify my Nanopore library with barcode sequence?; I have already demultiplexed the ONT library to each individual barcode by using some other tools and generated a meta table with matched barcode and readID.; It would be great if you guys have any ideas on how can I generate a barcode-gene count matrix from it.; My current workflow is aligning via minimap2 and subset the bam file to each barcode by matching the readID, and use Salmon or other tools to quantify the counts, and compile the matrix together. But it took a very long time and memory.; Maybe there's another more efficient way.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/920#issuecomment-2014070596:648,efficient,efficient,648,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/920#issuecomment-2014070596,1,['efficient'],['efficient']
Energy Efficiency,"Add [sci-rna-seq3 protocol](https://www.nature.com/articles/s41586-019-0969-x) to salmon alevin. To use this protocol pass the `--sciseq3` flag. The details of library preparation can be seen [here](https://teichlab.github.io/scg_lib_structs/methods_html/sci-RNA-seq3.html). Briefly, the reads have 9-10 bp hairpin adaptor index, and 10bp reverse transcription index which together make the cell barcode of 19-20 bp in length; an 8 bp UMI which follows a 6bp anchor sequence CAGAGC. . Summary of changes:; 1. `--sciseq3` flag added to process sci-rna-seq3 reads; 2. a local copy of single cell protocol is created before barcodes and UMI are extracted to allow share the position of anchor sequence and avoid searching twice; 3. In case the barcode is 19bp, `A` is added as the last nucleotide to make the cell barcodes length 20 bp for all barcodes. It was tested on data from the [Nature paper](https://www.nature.com/articles/s41586-019-0969-x). Correlation b/w the counts from the GEO submission [GSE119945](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE119945) and sum of spliced, unspliced reads with and without ambiguous counts using `usa` mode in alevin-fry gave reasonable looking correlations. ; Results for one of the fastq files:; ![image](https://user-images.githubusercontent.com/12998572/128923136-eefa8738-f87e-4f67-bba6-5cc1648ce194.png). ```; Min. 1st Qu. Median Mean 3rd Qu. Max. ; 0.4594 0.7805 0.8295 0.8253 0.8736 0.9943 ; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/695:315,adapt,adaptor,315,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/695,1,['adapt'],['adaptor']
Energy Efficiency,"B_INCLUDE_DIRS-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_LIBRARY; TBB_LIBRARY-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_LIBRARY_DEBUG; TBB_LIBRARY_DEBUG-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_LIBRARY_DIRS; TBB_LIBRARY_DIRS-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_MALLOC_LIBRARY; TBB_MALLOC_LIBRARY-ADVANCED:INTERNAL=1; //ADVANCED property for variable: TBB_MALLOC_LIBRARY_DEBUG; TBB_MALLOC_LIBRARY_DEBUG-ADVANCED:INTERNAL=1; ```. Also, here's the output of every hardware/OS reporting command I can think of:. ```; $ cat /proc/cpuinfo; processor : 0; vendor_id : GenuineIntel; cpu family : 6; model : 63; model name : Intel(R) Xeon(R) CPU E5-2623 v3 @ 3.00GHz; stepping : 2; microcode : 0x36; cpu MHz : 3300.000; cache size : 10240 KB; physical id : 0; siblings : 8; core id : 0; cpu cores : 4; apicid : 0; initial apicid : 0; fpu : yes; fpu_exception : yes; cpuid level : 15; wp : yes; flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36; clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc; arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqd; q dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4; _2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb tpr_sh; adow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm x; saveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts; bugs :; bogomips : 5985.57; clflush size : 64; cache_alignment : 64; address sizes : 46 bits physical, 48 bits virtual; power management:; ...; [And 7 more cores]; $ uname -a; Linux salomon24 4.4.0-51-generic #72-Ubuntu SMP Thu Nov 24 18:29:54 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux; $ lsb_release -d; Description: Ubuntu 16.04.1 LTS; ```. lshw output: [salomon24-lshw.txt](https://github.com/COMBINE-lab/salmon/files/650904/salomon24-lshw.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266953657:2266,monitor,monitor,2266,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266953657,2,"['monitor', 'power']","['monitor', 'power']"
Energy Efficiency,"E_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ff97e5d39d0, tls=0x7ff97e5d3700, child_tidptr=0x7ff97e5d39d0) = 52022; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ff8fe5d2000; mprotect(0x7ff8fe5d2000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ff93e5d1ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ff93e5d29d0, tls=0x7ff93e5d2700, child_tidptr=0x7ff93e5d29d0) = 52023; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ff8be5d1000; mprotect(0x7ff8be5d1000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ff8fe5d0ed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ff8fe5d19d0, tls=0x7ff8fe5d1700, child_tidptr=0x7ff8fe5d19d0) = 52024; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ff87e5d0000; mprotect(0x7ff87e5d0000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ff8be5cfed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ff8be5d09d0, tls=0x7ff8be5d0700, child_tidptr=0x7ff8be5d09d0) = 52025; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ff83e5cf000; mprotect(0x7ff83e5cf000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ff87e5ceed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ff87e5cf9d0, tls=0x7ff87e5cf700, child_tidptr=0x7ff87e5cf9d0) = 52026; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti"".",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:121248,allocate,allocate,121248,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['allocate'],['allocate']
Energy Efficiency,"E_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffcfe5e19d0, tls=0x7ffcfe5e1700, child_tidptr=0x7ffcfe5e19d0) = 10750; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffc7e5e0000; mprotect(0x7ffc7e5e0000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffcbe5dfed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffcbe5e09d0, tls=0x7ffcbe5e0700, child_tidptr=0x7ffcbe5e09d0) = 10751; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffc3e5df000; mprotect(0x7ffc3e5df000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffc7e5deed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffc7e5df9d0, tls=0x7ffc7e5df700, child_tidptr=0x7ffc7e5df9d0) = 10752; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffbfe5de000; mprotect(0x7ffbfe5de000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffc3e5dded0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffc3e5de9d0, tls=0x7ffc3e5de700, child_tidptr=0x7ffc3e5de9d0) = 10753; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffbbe5dd000; mprotect(0x7ffbbe5dd000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffbfe5dced0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffbfe5dd9d0, tls=0x7ffbfe5dd700, child_tidptr=0x7ffbfe5dd9d0) = 10754; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti"".",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:76954,allocate,allocate,76954,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['allocate'],['allocate']
Energy Efficiency,"E_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffcfe5e19d0, tls=0x7ffcfe5e1700, child_tidptr=0x7ffcfe5e19d0) = 32693; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffc7e5e0000; mprotect(0x7ffc7e5e0000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffcbe5dfed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffcbe5e09d0, tls=0x7ffcbe5e0700, child_tidptr=0x7ffcbe5e09d0) = 32694; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffc3e5df000; mprotect(0x7ffc3e5df000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffc7e5deed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffc7e5df9d0, tls=0x7ffc7e5df700, child_tidptr=0x7ffc7e5df9d0) = 32695; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffbfe5de000; mprotect(0x7ffbfe5de000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffc3e5dded0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffc3e5de9d0, tls=0x7ffc3e5de700, child_tidptr=0x7ffc3e5de9d0) = 32696; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffbbe5dd000; mprotect(0x7ffbbe5dd000, 4096, PROT_NONE) = 0; clone(child_stack=0x7ffbfe5dced0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7ffbfe5dd9d0, tls=0x7ffbfe5dd700, child_tidptr=0x7ffbfe5dd9d0) = 32697; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti"".",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:40285,allocate,allocate,40285,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['allocate'],['allocate']
Energy Efficiency,"Good evening,; I have been trying to do some alignments using salmon but I get this error after a few; hours. error: commlib error: got read error (closing ""compute-0-19.local/shepherd_ijs/1""). Your ""qlogin"" request could not be scheduled, try again later. Here is one example of the codes I used that didn't work, some others worked fine. for this I built a decoy-aware transcriptome file. salmon quant --libType A -1 L395_gfp_plus_Track_3446_3455_R1.fastq -2; L395_gfp_plus_Track-3446-3455_R2.fastq -i desalttama_salmon_index31 -p 12; --writeUnmappedNames --writeMappings -o desalttama_salmon_index31_quant_L395. I used This qlogin; qlogin -q all.q -l h_rt=48:00:00 -l mem_free=10G -R yes -now n -pe smp 1. How can I solve this issue?; Thank you; Beatriz",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/580:229,schedul,scheduled,229,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/580,1,['schedul'],['scheduled']
Energy Efficiency,"Good morning,. I'm a *nix developer with a lot of experience porting software to various platforms. My preferred method for deployment is build-from-source package managers such as FreeBSD ports, Gentoo Portage, MacPorts, pkgsrc (which I use extensively on CentOS), etc. Package managers in-general minimize problems for end users (and hence reduce PRs for you guys). Build-from-source package managers also allow customizing build options (e.g. adding -march=native), which can sometimes offer significantly better performance than you can get from a generic binary package that has to support older CPUs. Currently, developing such packages for salmon is a challenge due to the way the build system works. I've been looking through the build system and the main barrier to packaging is the unconditional bundling of some dependencies, such as seqlib and htslib. If you were to update the cmake systems so that they first look for *all* dependencies installed externally, as they already do for jemalloc and tbb, then it would be easier for developers to package salmon. Best,. Jason",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/502:342,reduce,reduce,342,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/502,1,['reduce'],['reduce']
Energy Efficiency,Hello! . I absolutely love Salmon and use it whenever I get the chance. I've also found that the automatic inference of library type is an extremely powerful feature for other contexts outside of salmon mapping -- but virtually no other tools offer this capability and certainly not with the same speed as salmon. Would it be possible to make a small function Salmon or a standalone package that can be used to infer library type independent of salmon mapping?. Thanks!; Henry,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/534:149,power,powerful,149,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/534,1,['power'],['powerful']
Energy Efficiency,"Hello,. I have a 10x scRNA-seq dataset I would like to run Alevin on, with bootstrapping. I am working on a cluster and submitting my script (I'll paste it below) with a Slurm scheduler. My issue is that the job runs for a couple of seconds, then gives me this massive “core” output - that is encrypted someway and I can’t read - and then an empty log and an empty alevin.log, so I don’t even have anything to use for troubleshooting. ```; (salmon) [amonaco_m@med0113 1_bootstrappedAlevin]$ ls -al; total 47106; drwxrwxr-x 3 amonaco_m hpc-ag-zinzen 4096 Mar 3 11:00 .; drwxrwxr-x 4 amonaco_m hpc-ag-zinzen 4096 Mar 2 11:47 ..; drwxrwxr-x 2 amonaco_m hpc-ag-zinzen 4096 Mar 3 11:00 alevin; -rw------- 1 amonaco_m hpc-ag-zinzen 36540416 Mar 3 11:00 core.39485; -rw-rw-r-- 1 amonaco_m hpc-ag-zinzen 0 Mar 3 11:00 logs; (salmon) [amonaco_m@med0113 1_bootstrappedAlevin]$ ls -al alevin; total 1; drwxrwxr-x 2 amonaco_m hpc-ag-zinzen 4096 Mar 3 11:00 .; drwxrwxr-x 3 amonaco_m hpc-ag-zinzen 4096 Mar 3 11:00 ..; -rw-rw-r-- 1 amonaco_m hpc-ag-zinzen 0 Mar 3 11:00 alevin.log; ```. I have used Salmon Alevin before on this dataset - without the bootstrap option - while providing the Cell Ranger whitelisted barcodes, and everything has gone smoothly (same script as below, commented out line). I have tried increasing the allotted memory and thread number as well, but with no change in outcome. Have you ever encountered something like this or could address me to where the issue may be (I'm assuming something to do with the bootstrap)?. *****Script I submit:*****; ```; #!/bin/bash; # expected run time ; #SBATCH --time=24:00:00 ; # Combine stderr and stdout log files into the stdout log file.; #SBATCH -o without -e; # Keep current environment variables.; #SBATCH --export=variables; # number of cores; #SBATCH -n 30; # expected memory to be used; #SBATCH —mem=50000; # Specify queue via expected length of job. ; #SBATCH --partition=medium; # Set the log directory.; #SBATCH -o logs. ####declarations; ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/636:176,schedul,scheduler,176,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/636,1,['schedul'],['scheduler']
Energy Efficiency,"Hello,. I'm trying to create an index file with salmon (version 1.4.0) according to this tutorial here: https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/ (because I would like to find isoforms using isoformSwitchAnalyseR and the salmon files I already have didn't seem to work, and this tutorial was recommended in the documentation (https://salmon.readthedocs.io/en/latest/salmon.html ) for preparing transcriptome indices (mapping-based mode) ). Since my samples are from humans, I replaced the mouse-files with the (still) current Gencode files for human (v37), and everything seemed to work well until the last step:. salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon_index --gencode. I left my machine alone for almost 8 h (no other programs, nothing to disturb it). When I finally had a look at it, the terminal was still in Round0, the system monitor still showed some action, and the system was still responsive (no freeze or anything). When I had a look at the index directory, there were no changes in any files after the sub-directory ""twopaco_tmp"" was created, and this directory only contains a file called bifurcations.bin, which was 0 byes (after 8h of computing time). Therefore, I rebooted my system (if there went anything wrong that I couldn't see) and tried changing the parameters. . 1. I changed the number of threads to -p 6 since my machine is rather old, and maybe -p 12 was too much. 2. Since someone seemed to have a similar problem and would have tried changing the filter size next, I tried to change the filter size by adding --filterSize 2^39 (at the same time, I also added --keepDuplicates because I want to use the data to find differentially expressed isoforms later on). salmon index -t gentrome.fa.gz -d decoys.txt -p 6 --keepDuplicates --filterSize 2^39 -i salmon_index --gencode. However, this didn't work and got killed. . I thought it might be due to the --filterSize argument and changed it to 39 (because maybe the 2^ is assu",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/643:883,monitor,monitor,883,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/643,1,['monitor'],['monitor']
Energy Efficiency,"Hello,. I've actually been thinking of a different method that would require very stringent mapping. By providing transcripts of only exon 1 & 2, exon 2 & 3, and exon 1 & 3 I could get a better idea of the number of reads that skip exon 2 all together. Also, by averaging the read counts that map to the junctions of exon 1 & 2 and exon 2 & 3, I can help eliminate polyA tail bias that is heavily positioned towards exon 1 and would also allow me to get a more accurate prediction of the two gene versions since 1 read mapped to exon 1 & 2 and 1 read mapped to exon 2 & 3 would essentially tell me twice that the gene is there while a read mapped to exon 1 & 3 would only tell me once that the gene is there. However, doing so would force me to bring ```AuxSampleNumber``` down to very low numbers such as 10 - 100 as using stringent coverage parameters drastically reduces my reads mapped. . I do wonder though how these low AUX numbers might affect your model development and algorithm. Any input into the aspect of low AUX numbers?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/401#issuecomment-512905804:866,reduce,reduces,866,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/401#issuecomment-512905804,1,['reduce'],['reduces']
Energy Efficiency,"Hello,. Thanks for creating this efficient and rapid tool. I have earlier used Salmon in alignment based-mode and now trying the mapping based mode. I get a ""Version Server Response:Not found"" message on quantification of fast read. I suspect the problem is with my index but I am not entirely sure what exactly. I installed salmon version 1.10.1 from Bioconda, and built the index, which appeared to have executed successfully. Below is the trail of commands:. (salmonenv) nanaaffoh@kenneths-mbp-2 salmon % conda install -c bioconda salmon. Building decoy aware index; (salmonenv) nanaaffoh@kenneths-mbp-2 salmon % grep ""^>"" ../rna_seq_trial/GRCh38.primary_assembly.genome.fa | cut -d "" "" -f -1 > decoys.txt; (salmonenv) nanaaffoh@kenneths-mbp-2 salmon % less decoys.txt; (salmonenv) nanaaffoh@kenneths-mbp-2 salmon % sed -i.bak -e 's/>//g' decoys.txt; (salmonenv) nanaaffoh@kenneths-mbp-2 salmon % cat ../rna_seq_trial/gencode.v43.transcripts.fa ../rna_seq_trial/GRCh38.primary_assembly.genome.fa > gentrome.fa; (salmonenv) nanaaffoh@kenneths-mbp-2 salmon % salmon index -t gentrome.fa -d decoys.txt -p 12 -i salmon_index --gencode. This results in successful building of the index. Then when I attempt a mapping based quantification for a paired end reads FW and RV, as below, I get therefor mentioned. salmon -i salmon_index -l A -1 $FW -2 $RV --validateMappings -o /Volumes/Ultra_Touch/malaria/Salmon/$FILEBASE/. The info.json file from the index folder has these contents:. {; ""index_version"": 4,; ""reference_gfa"": [; ""salmon_index""; ],; ""sampling_type"": ""dense"",; ""k"": 31,; ""num_kmers"": 2662886061,; ""num_contigs"": 37302977,; ""seq_length"": 3781975371,; ""have_ref_seq"": true,; ""have_edge_vec"": false,; ""SeqHash"": ""39d9ea9f308ee7e18cdb034c1d064c3a9722df115147533a2ec237fb7cecfca9"",; ""NameHash"": ""29a75bc06784c090e5e015d4a5a7e895b7b3d91c9855a10528ee0130377edf3d"",; ""SeqHash512"": ""4e84aa54ec0cb1dad420c66197d8a9485e913b0a60805f2d7e44ce71ad0521b8103cf94dad72e1530b05dc0d08f39e5d4b9225345d8e7ffc60cb5",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/851:33,efficient,efficient,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/851,1,['efficient'],['efficient']
Energy Efficiency,"Hi ; I am running an analysis using FLAIR (https://github.com/BrooksLabUCSC/flair) that uses the desired salmon version at the back end. Since it is trying to construct a de-novo transcriptome it pools the samples resulting in a sam file that is 266GB. When I run this analysis on the HPC, the salmon analysis ends without quant.sf file being written. The start and end of the STDERR written by salmon are shown below. . ```; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.6.0; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { ../data/FLAIR_2021-12-26/collapse_2021-12-26.firstpass.fa }; # [ output ] => { tmp99xm2qn8_2 }; # [ threads ] => { 8 }; # [ ont ] => { }; # [ libType ] => { U }; # [ alignments ] => { tmp99xm2qn8.firstpass.sam }; ---------------------------------------------; Completed first pass through the alignment file.; Total # of mapped reads : 74567310; # of uniquely mapped reads : 8113553; # ambiguously mapped reads : 66453757. Freeing memory used by read queue . . .; Joined parsing thread . . . ""tmp99xm2qn8.firstpass.sam""; Closed all files . . .; Emptied frag queue. . .; Emptied Alignment Group Pool. .; Emptied Alignment Group Queue. . . done; ============; Exception : [std::bad_alloc]; ============; ```; /home/ys/work_lies/Tools/salmon-1.6.0_linux_x86_64/bin/salmon alignment-quant was invoked improperly.; For usage information, try /home/ys/work_lies/Tools/salmon-1.6.0_linux_x86_64/bin/salmon quant --help-alignments. I have tried increasing the memory allocated to the analysis. It seems to complete but without the quantification files. . I also do not understand if it runs to the this point how this statement ""alignment-quant was invoked improperly."" could be true. . Any help would be greatly appreciated.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/732:1546,allocate,allocated,1546,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/732,1,['allocate'],['allocated']
Energy Efficiency,"Hi @AndrewSkelton,. There is currently no easy way to keep the index in RAM as STAR/Bowtie2 do. This is a feature we've been interested in for a _long_ time, but it's a feature that is very hard to justify spending a PhD student's time on since it's not going to contribute directly to any paper. But, this is a feature we'd like to add and maybe we can swing it with some of the CZI round-3 funding we just got. Nonetheless, the capability currently doesn't exist. Salmon can take multiple fastq files as input, but then it assumes they all derive from the same library, so you get one ""aggregate"" quant.sf, which isn't what you want here. So, I think the only approach currently would be to schedule a number of small jobs. I get why this isn't ideal. One small saving grace is that recent versions of salmon (>= 1.0.0) adopt the pufferfish index which is _much_ smaller than the previous RapMap index. Thus, the index loading time is quite small for a typical transcriptome. Also, this often allows operating system cache to keep the index around, even if it's not explicitly stored in shared memory. Thanks for both of the suggestions, and I'll be sure to keep you in the loop if we acquire either of the capabilities you mention above!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/589#issuecomment-733215735:693,schedul,schedule,693,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/589#issuecomment-733215735,1,['schedul'],['schedule']
Energy Efficiency,"Hi @AnnaAMonaco ,. Thanks for reaching out and I agree it'd be super useful to have alevin working for both scRNA-seq and scATAC-seq multiome datasets. In short I'd say the framework is not ready yet and there are multiple challenges which we are still working-on to find the right solution. The Central issue is that the technologies to profile open-chromatin regions expects the read to align majorly to non-coding regions and salmon/alevin framework is designed to work (generally) with transcriptomic data. Having said that, one can potentially index the full genome using salmon indexing but we have not yet extensively validated the genomic alignment generated from alevin framework. Once settled, we can certainly figure out ways to run alevin without UMI, that's the easier part. What do I do now ? Basically since the scRNA-seq and scATAC-seq are two different library preps (along with the fastq), I'd still recommend using alevin for scRNA-seq, however, one might have to run other tools (like bwa-mem) to align scATAC-seq data. The are multiple reasons to recommend that, the significant power of alevin comes in with (1) multi-mapping reads but we generally expect low number of such reads with ATAC-seq data (2) UMI deduplication which is absent in the ATAC-seq data and the deduplication happens based on the aligned position. Again, I agree it's great to have a uniform workflow for the multiome data but we are thinking about the challenges in designing such workflow and how solve them. We'd let you know once we have a vignette / tutorial. -- Avi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/611#issuecomment-758028858:1100,power,power,1100,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/611#issuecomment-758028858,1,['power'],['power']
Energy Efficiency,"Hi @Ci-TJ,. This suggests that the FASTQ files were ""desynchronized"" during / after trimming somehow. Salmon requires that the FASTQ files are synchronized. So, if the trimmer decides to discard a read from the first read file, it must also discard the corresponding read from the second read file. I'm not specifically familiar with RabbitQC, but most quality / adapter trimmers have an option to separate out any reads that become orphaned during trimming so that the output paired FASTQ files remain synchronized. You should make sure that any such options are passed during QC. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/660#issuecomment-846252372:363,adapt,adapter,363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/660#issuecomment-846252372,1,['adapt'],['adapter']
Energy Efficiency,"Hi @GWW ,. Ok, we figured out where the threads are coming from. Deep inside the concurrent hash map we are using, there is a [function that grows the hash map](https://github.com/COMBINE-lab/salmon/blob/master/include/cuckoohash_map.hh#L1558). This function uses a function called [`parallel_exec`](https://github.com/COMBINE-lab/salmon/blob/master/include/cuckoohash_map.hh#L1751) to move the items from the old table to the new one. Here, they greedily use as many threads as available for that process. We can't see this behavior on our end by monitoring top/htop, because the hash table doubling happens so fast it's below the monitoring resolution. There are a couple ways to address this, one of which is hacking inside the hashmap library to modify this behavior. However, it would be nice if there was a way to do this without modifying the code (e.g. by limiting the number of threads the process was allowed to spawn concurrently from outside of the process itself). We are looking to see if this is doable using e.g. cgroups or some such.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395890018:548,monitor,monitoring,548,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395890018,2,['monitor'],['monitoring']
Energy Efficiency,"Hi @Ray6283,. It seems you are asking about the EM/VBEM algorithm in general. I would say your description is _almost_ right, except this part:. > Then using p_ij s , we put f_j to transcripts with highest probability , say t_jm , we do this for all fragments, so for each fragment we have assigned unique transcript. So we can have new eta, call it eta_1 ( because we have abundance). Specifically, the EM algorithm does _not_ do ""hard"" assignment. That is, at no point during the algorithm, is a fragment fully assigned to a specific transcript (unless it was uniquely mapped there). Rather, the EM algorithm performs ""soft"" assignment. So, consider we have a fragment $f_j$ that maps to two transcripts $t_{j1}$ and $t_{j2}$. The EM algorithm will ""partially"" allocate this fragment to each of the transcripts. Specifically, it will allocate them proportional to $P(f_j \in t_{j1}) \propto P(t_{j1} \mid \eta) P(f_j \mid t_{j1})$ and $P(f_j \in t_{j2}) \propto P(t_{j2} \mid \eta) P(f_j \mid t_{j2})$ respectively. Then, in the ""M"" phase of the EM algorithm, one calculates the total mass arising from a transcript $t_i$ as $\sum_{f_j \text{ such that } f_j \text{ maps to } t_i} P(f_j \in t_i)$ (one sum). Computing these abundances for all $t_i$ gives us our next estimate of $\eta$, and then we can go back and re-compute the probabilities $P(f_j \in t_{j1})$ etc. This is done until convergence. _Originally posted by @rob-p in https://github.com/COMBINE-lab/salmon/discussions/889#discussioncomment-7304773_",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/890:763,allocate,allocate,763,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/890,2,['allocate'],['allocate']
Energy Efficiency,"Hi @Ray6283,. The `bootstraps.gz` file is not designed to be read as plain text. The file encodes information in binary. If you are interested in extract the information encoded in those files, the easiest thing to do is likely to read them in using the [`fishpond`](https://bioconductor.org/packages/release/bioc/html/fishpond.html) package. Looking at the code there will also show you exactly how those files are packed. The same is true for the bias files. The format for those is documented [here](https://salmon.readthedocs.io/en/latest/file_formats.html#sequence-specific-bias-files) and [here](https://salmon.readthedocs.io/en/latest/file_formats.html#fragment-gc-bias-files), those these are binary encoded files and not designed for human consumption. For the bias files, even if you did read them in, the information is not trivially interpretable (e.g. the parameters of the variable length Markov model, etc.). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/47#issuecomment-1792970641:749,consumption,consumption,749,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/47#issuecomment-1792970641,1,['consumption'],['consumption']
Energy Efficiency,"Hi @annajbott ,. Thanks for your question.; It's an expected behavior. The idea is to dump some low confidence CB as well for certain kind of downstream processing. You'd see a file `whitelist.txt` as well in the output alevin folder which should contain whitelisted CB names (4340 in your case). You might have to filter those matrix out after loading the full matrix to get cells only passes the whitelisting filter. Please checkout [tximport](https://github.com/mikelove/tximport) to import the matrix in R, it's very efficient to load. In case you need some stats regarding the resource usage check [EDS](https://github.com/COMBINE-lab/EDS).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/428#issuecomment-530430735:521,efficient,efficient,521,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/428#issuecomment-530430735,1,['efficient'],['efficient']
Energy Efficiency,"Hi @diyang1354,. It is recommended to do adapter trimming prior to mapping and quantification (standard practices actually involve adapter and _light_ quality trimming of reads). Adapter contamination could affect the mapping rate, especially if selective-alignment, which is recommended, is being used.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/398#issuecomment-511428337:41,adapt,adapter,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/398#issuecomment-511428337,3,"['Adapt', 'adapt']","['Adapter', 'adapter']"
Energy Efficiency,"Hi @diyang1354,. To answer your questions as directly as possible:. 1.) Yes, you cannot align to a transcript of less than the k-mer length.; 2.) If you are processing bulk RNA-seq data, and therefore using `selective-alignment`, using a smaller `k` is unlikely to reduce your alignment accuracy, but it *can* increase the runtime of mapping if you make it too small. If you are processing single-cell RNA-seq data and using `--sketch` mode, then a reduction in the value of `k` can negatively impact accuracy. Finally, I'll mention that RNA-seq, in general, isn't a great assay for measuring very small molecules, so you probably want to be somewhat suspicious of the quantification results for *very short* transcripts anyway. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/754#issuecomment-1050469681:265,reduce,reduce,265,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/754#issuecomment-1050469681,1,['reduce'],['reduce']
Energy Efficiency,"Hi @euduca,. This is a good idea. Currently, there is no easy way to do this apart from hacking the CMake file. If salmon doesnt find jellyfish in a standard location, it just ferches its own copy. Fortunately, in the newest release (scheduled to drop this coming week), we've dropped the dependency on libjellyfish. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/225#issuecomment-392336913:234,schedul,scheduled,234,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/225#issuecomment-392336913,1,['schedul'],['scheduled']
Energy Efficiency,"Hi @gnaisha,. Thank you for providing the file to reproduce the issue. So, the difference here is all in the default fragment length mean and standard deviation that salmon and eXpress use. This really only matters in single-end libraries like this, since in paired-end libraries both tools will estimate the fragment length distribution from the data itself. Nonetheless, if not given specific parameters to override the default, salmon assumes μ = 250 and σ = 25, while eXpress assumes μ = 200 and σ = 80. If you run salmon like:. ```; salmon quant -lU -t transcriptome.fa -a sample_nested_transcripts_ENST00000364953-1_ENST00000375633-5.bam --fldMean 200 --fldSD 80 -o quant_directory; ```. Then you will see the following behavior for these transcripts:. ```; ENST00000364953.1 64 23.127 1000000.000000 49.000; ENST00000375633.5 586 384.567 0.000000 0.000; ```. So that the all of the reads are, indeed, allocated to the former. The effect of the transcript length on the assignment probabilities is a direct result of the probabilistic model (and due to the length effect that actually exists in the full-length RNA-seq assay). It's unfortunate that there's not a good way to estimate the fragment length distribution in single-end data, and so we are left with having to set some defaults. Depending on the actual library, different defaults will match better or worse. On the plus side, it's easy to change these values if you have better knowledge of the parameters or reason to believe that one value will work better than another.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-749739255:908,allocate,allocated,908,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-749739255,1,['allocate'],['allocated']
Energy Efficiency,"Hi @jan-g1,. The length of a feature is used during inference to determine the likelihood that multimapping reads should be allocated to different targets. You're describing what is essentially a simplified model where P(f | t) (i.e., the probability of a fragment given a transcript) is independent of length(t). There's currently no option to disable length normalization completely in Salmon, and you can't ""de-normalize"" by simply multiplying by a factor because those weights are considered during each and every round of the EM (or VBEM) algorithm. However, supporting this should actually be very straight-forward. We simply assign a uniform and identical length to all transcripts for the purpose of inference. I can add such a flag in the next release, though it will initially have to be incompatible with bias correction (since it's not clear right now how the biases for which we account interact with this type of sequencing). Also, it would be possible to run salmon with `--dumpEq`, and then to have a little script / tool that simply re-runs the EM, but without different length factors, using the equivalence class file. I might be able to hack something like that together on short notice if you'd be interested in testing it out. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264659889:124,allocate,allocated,124,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264659889,1,['allocate'],['allocated']
Energy Efficiency,"Hi @jeremymsimon — @Gaura is going to take a look at unfiltered permit listing and will share those results here later. Regarding frameshift errors, I think that's certainly out of scope for the alevin -> fry phase, but that type of thing *could* be in scope for `splitp`. Basically, my logic / reasoning is this: I'd like to avoid further complicating the already immense salmon/alevin codebase with special implementations handling problems outside of their core function (e.g. mapping reads to the reference efficiently and quantifying UMIs/barcode). Since most protocols (and the most common) have quite simple barcode geometry, it makes sense for this code to live there. I'm fully supportive of enabling support for more complex barcode geometries and preprocessing requirements if there are folks whom it would help, but it feels like that essential complexity belongs upstream of alevin / fry, so that by the time the reads get to alevin, it can assume a straightforward geometry. So TLDR : I think we'd be willing to investigate what is required to address potential frameshift errors, and how much of a difference that makes, but I think that analysis and eventual implementation (if we decide it's worth it), belongs in `splitp`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837:511,efficient,efficiently,511,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837,1,['efficient'],['efficiently']
Energy Efficiency,"Hi @jeremymsimon, . Somehow, the notification for this in my e-mail got classified as SPAM. Anyway, thank you for the detailed description! I'm going to ping @Gaura here. @Gaura — this is the alternative protocol I was discussing with you yesterday. As you can see, the main issue here is the ""noisy"" barcodes. Let me know what you think would be necessary to add support for this, and I'm happy to schedule a technical discussion if you want to discuss some options.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-921879305:399,schedul,schedule,399,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-921879305,1,['schedul'],['schedule']
Energy Efficiency,"Hi @k3yavi, ; I just re-read this post and I believe that in the CEL-Seq2 protocol, read_1 has first the UMI and then the CB and then polyT... because the sequencing starts with the Illumina adapter (see image below from paper). . Thanks!; ![13059_2016_938_fig1_html](https://user-images.githubusercontent.com/39304679/49376447-edbda900-f70f-11e8-85d7-b86b15c477d5.gif)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-443709804:191,adapt,adapter,191,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-443709804,1,['adapt'],['adapter']
Energy Efficiency,"Hi @k3yavi,. Thanks for the reply!. Let's take the PBMC 4K as example. Looking at the summary sheet from 10x: ; http://cf.10xgenomics.com/samples/cell-exp/2.1.0/pbmc4k/pbmc4k_web_summary.html. They detected 4,340 cells with a median UMI count of 3,866 per cell. That means ~17M UMIs in the count matrix, which is in the same order what I find with Alevin. I am not sure if/where Alevin reports the number of mapped reads (maybe it is the number of hits?), but this is not of much importance. Indeed, the total UMI count is **much** lower than the number of sequenced/mapped/barcoded reads (~190M), which is expected. However, using the `--dumpUmiGraph` option provides a file ""MappedUMI.txt"" which I assume are the number of deduplicated UMIs mapped per cell/barcode (summed over all genes). The sum of over all the barcodes = 17M in this case and the sum per barcode = the sum in the quant_mat. This does not hold for the adapted cel-seq2 protocol. sum mapped UMI != summed quant_mat.gz. I am making a mistake, or is there something wrong?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490098177:923,adapt,adapted,923,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490098177,1,['adapt'],['adapted']
Energy Efficiency,"Hi @kvittingseerup,. Basic adapter and quality trimming should be done. There's some [nice work by Matt MacManes](https://www.frontiersin.org/articles/10.3389/fgene.2014.00013/full) showing that you should be careful about aggressive quality trimming, but light quality trimming is usually beneficial. This is particularly important if the underlying aligner isn't doing local alignment (e.g. STAR will likely just softclip bad bases).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/390#issuecomment-506744431:27,adapt,adapter,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/390#issuecomment-506744431,1,['adapt'],['adapter']
Energy Efficiency,"Hi @kvittingseerup,. No need to apologize, I think it was I who was not clear. What I am saying is that this is *already* the way that Salmon handles such a case. That is, if you have a paired-end read, and one of the reads maps but the other doesn't (due to e.g., adapter contamination or just very low quality), then Salmon will consider the remaining (mapping) end of the read as representative of an entire fragment, and will resolve the fragment origin accordingly during optimization. Generally, not having both ends of a paired-end read leads to increased ambiguity, but this isn't a particularly big problem if it only happens to a generally small fraction of the reads. Further, since you cannot reliably infer the implied fragment length on a transcript from only a single-end read, such mappings will not contribute to the bias model. Again, however, as long as this doesn't happen to the vast majority of fragments, it should have only a negligible effect on quantification and bias correction. Please let me know if this description makes sense. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997:265,adapt,adapter,265,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997,1,['adapt'],['adapter']
Energy Efficiency,"Hi @kzkedzierska,. I'm not sure why the virtual memory usage here is so high, and am also not aware of a great way to predict it. One thing I might ask is if you could test this executable on your system ( [salmon-1.2.0-beta](https://drive.google.com/open?id=1QHYCT3Vs9bRD7UmJY6JJKjlzmmUE4wRl)). This is the near-final beta version of 1.2.0 whose release is imminent. One of the big changes in this version is a considerably more memory-efficient construction. We have been measuring this in terms of resident memory, but it may also apply to virtual memory. Would you mind giving it a try if you have a chance?. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-605106040:437,efficient,efficient,437,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-605106040,1,['efficient'],['efficient']
Energy Efficiency,"Hi @lauraht,. So I decided to explore just one of these to see if I could figure out what might be going on. The below is with respect to `SRR9007475`. So first, even though I processed the data with the latest version of the develop branch (which will become 1.2.0), I got basically identical results to what you reported. Simply aligning the data against an index built on a human Gencode v26 transcriptome (with no decoys) gives me a mapping rate of `0.00378202832148367%`. The first thing I did was to quality and adapter trim the data (using `fastp -i SRR9007475.fastq.gz -o SRR9007475_trimmed.fastq.gz -q 10 -w 8`) and ... whoa. This is the fastp html report [fastp.html.zip](https://github.com/COMBINE-lab/salmon/files/4176345/fastp.html.zip). So the first astounding statistic, the mean read length before trimming is 51bp (these are relatively short single-end reads). The mean read length after trimming is 21bp! So, the average read length is, in fact, less than the k-mer length used for indexing (default is k=31). On the trimmed data, the mapping rate goes up to `2.3545475882931305%`, still very low, but now there's somewhat of an explanation, the average read is shorter than a single k-mer. So, the next thing I tried was indexing with a smaller k; a _really_ small one in this case,`k=15`. Then, I re-ran on the _trimmed_ reads (the fact that the trimming took us from 51-21bp suggests that the reads had a lot of low quality bases, adapter contamination, or both). Under this setting, I still get a very low mapping rate, but it was _much_ higher — `16.766993524863488%`. The final thing I tried was seeing how the mapping rate changed as I altered `--minScoreFraction`, which is the salmon parameter that determines the alignment score that a read must achieve in order to be mapped validly. The default is 0.65. This means that the read cannot have a score < 0.65 * the maximum achievable score for the read given it's length. In the case of a 21bp read, the best score would be ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668:518,adapt,adapter,518,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668,1,['adapt'],['adapter']
Energy Efficiency,"Hi @lcolladotor,. That's really strange. It *is* the case that it's possible for Salmon to use more than one thread if you set `-p 1` --- it will use up to 2 threads in this case (1 is always dedicated for parsing). However, none of this would explain the memory usage you see. Adding more threads should not substantially change the memory burden in any way, as the main memory usage is in memory shared between threads and the amount of thread local memory is very small (a few MB at most). I would recommend updating to the latest version of Salmon (v0.8.2), as it does reduce the memory usage even more. I commonly quantify on the human transcriptome, and this uses 3-4G on my machine (with 16 threads). If you're still seeing this behavior with the newest version, we can try and debug further --- though I'm not sure exactly where to look next.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-289310854:573,reduce,reduce,573,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-289310854,1,['reduce'],['reduce']
Energy Efficiency,"Hi @lubios,. This suggests that the machine was not able to allocate enough memory to perform the requested operation. I would try the following things in order to see if they fix the issue. First, try quantifying without the decoy-aware index. This doesn't provide the benefits of the decoy sequence, but it will ensure that this is, in fact, the problem you are having. If that works, try building the decoy-aware index with the `--sparse` parameter. This will build the sparse index instead of the dense index, which is a bit smaller and may therefore fit in RAM on the machine where you are doing quantification. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-962058307:60,allocate,allocate,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-962058307,1,['allocate'],['allocate']
Energy Efficiency,"Hi @matthew-valentine,. In general, extra non-primary alignments are OK. This can, of course, slow down quantification somewhat because many more alignments are being evaluated. However, salmon (with the `--ont` flag) is designed to consider the provided alignments and allocate the corresponding read proportionally according to all of the relevant probabilities (including alignment quality). If, under this aligner setting, there are many *highly* sub-optimal alignments being reported, you may consider filtering them out, but that shouldn't be strictly necessary. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/796#issuecomment-1235769651:270,allocate,allocate,270,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/796#issuecomment-1235769651,1,['allocate'],['allocate']
Energy Efficiency,"Hi @mdshw5,. Thanks for sharing the file. I was able to build the transcriptome. The final index on this is ~15G. Here are the stats from the run on our machine:. ```; ~/salmon/build/issue432$ du -h big_idx/; 15G big_idx/; ~/salmon/build/issue432$ cat indexing_time.txt; 9737.34user 339.95system 21:11.51elapsed 792%CPU (0avgtext+0avgdata 14894700maxresident)k; 1232inputs+150622584outputs (0major+99352946minor)pagefaults 0swaps; ```. so the peak construction memory was about the same and the build took 21m with 16 threads. If you have a place, I can share the built index. What were the stats of the machine on which you were building? Was there sufficient RAM allocated?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538602738:665,allocate,allocated,665,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538602738,1,['allocate'],['allocated']
Energy Efficiency,"Hi @rhlampe,. Currently, there is no way to prevent the salmon indexer from using more memory if it is needed ot build the index. However, if there is a limit placed by the cluster, it will likely just result in a `bad_alloc` exception from the indexer. The number of sequences alone can tell you a bit about scaling, but the total number of nuclotides being indexed is actually a better predictor of resource usage. How many nucleotides, total, are the references you're considering? While we are working on ways to make the indexing scheme highly scalable, it's worth noting that, to achieve some of it's speed, salmon pre-computes a lot of information it its index (so that the index can become fairly large). One thing I might suggest, if you want to attempt to index and quantify on a very large reference, is to use the `--perfectHash` index in the newest development version of Salmon (pre-release tarball attached below). The latest version (for which the official version should appear soon) represents a number of improvements to index construction. The default indexer has reduced memory usage by ~40%, and the new `--perfectHash` indexer, while somewhat slower, reduces the memory usage even more (by an additional 40-50%). With a fixed memory budget, then, it should allow you to index ever larger references. --Rob. [Salmon-v0.7.3-pre_linux_x86_64.tar.gz](https://github.com/COMBINE-lab/salmon/files/512019/Salmon-v0.7.3-pre_linux_x86_64.tar.gz)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/97#issuecomment-251759242:1084,reduce,reduced,1084,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/97#issuecomment-251759242,2,['reduce'],"['reduced', 'reduces']"
Energy Efficiency,"Hi @rob-p . Before I answer your question and layout my logic, I want to mention that I am **_not_** suggesting fastp is not doing its job, **_neither am I stating that fastp is working incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Not",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:266,adapt,adapter,266,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,5,['adapt'],"['adapter', 'adapter-trimming', 'adapters']"
Energy Efficiency,Hi @rob-p . Thanks for the elaborate answer - makes a lot of sense. The problem is that adapter contamination typically occures because the fragments were smaller than the sequence length we sequence into the adapters - and it can occur for a larger fraction of the reads (I've seen up to 50% of reads affected in the 3'end) making it non-negligible. That is why I suggested the extension in the first place. I think it makes a lot of sense to trim adapters away - both because they reduce the number of compatible reads - mostly because the failure to do so will result in an overestimation of the fragment length. . Now that I think about it I don't think we should trim reads based on quality as that will lead to an underestimation of the read length - or what do you think?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355909325:88,adapt,adapter,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355909325,4,"['adapt', 'reduce']","['adapter', 'adapters', 'reduce']"
Energy Efficiency,"Hi @rob-p . Thanks for the quick reply. Indeed my salmon index does not include lncRNAs, but my sequencing does. For indexing, I only used UCSC RefSeq transcripts (which I believe contains only protein coding transcripts that exclude most of lncRNAs). But this does not seem to suffice to explain the low mapping rate as Wikipedia says ""[Quantitatively, lncRNAs demonstrate ~10-fold lower abundance than mRNAs in a population of cells.](https://en.wikipedia.org/wiki/Long_non-coding_RNA#Abundance)"". To answer your questions:; 1. I used `htseq-count`, and here are the overall statistics (out of 149347870 record pairs processed):; ```; stat	""-s yes""	""-s reverse""; __no_feature	135258158	44917653; __ambiguous	39301	594958; __too_low_aQual	0	0; __not_aligned	0	0; __alignment_not_unique	7430169	7430169; ```. 2. I haven't done quality/adapter trimming as the data really looks clean and of high quality according to FastQC report. 3. Unfortunately I can't share the raw data yet but I will try your suggestion to quantify with STAR at the transcript level.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-847091597:835,adapt,adapter,835,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-847091597,1,['adapt'],['adapter']
Energy Efficiency,"Hi @rob-p . Totally understood (even more severe current limitations here) - survey completed. I think there'll ""always"" be Illumina-level coding (we use it to multiplex samples or cells), but I suspect most (all?) wild-west method will be some form of using the one read for barcoding. So as long as I can stipulate which bases in the read are which kind of barcode (cell/molecular) that'd be a good start. Of course having more mature methods than the current [drop-seq protocol](http://mccarrolllab.com/wp-content/uploads/2016/03/Drop-seqAlignmentCookbookv1.2Jan2016.pdf) to error correct, remove poly-A, remove adaptor sequences etc. always very welcome. (I suspect @vals is onto something... I still struggle to be entirely convinced that UMIs, as currently used, have the long-term legs that some people think.)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-282741659:615,adapt,adaptor,615,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-282741659,1,['adapt'],['adaptor']
Energy Efficiency,"Hi @rob-p and all,. Thank you for the wonderful tool.; I've been using Salmon for some time now, and have encountered a question.; How is Salmon affected by different read lengths and adapters?. I have a dataset with 5%-15% adapters at 3' of read. How will salmon output be affected if:; 1) I don't remove them; 2) I trim all reads down; 3) use an adapter trimming program - resulting in reads with different length. . Thank you",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/634:184,adapt,adapters,184,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/634,3,['adapt'],"['adapter', 'adapters']"
Energy Efficiency,"Hi @rob-p,. thank you for your quick answer. As mentioned already, I started with the full set of options (at least I thought so) and then reduced them to the minimal case to reproduce the error for reporting the problem.; I was mislead by the term 'unrecognized option' and didn't expect the program to ""forget"" options from other modes. But now that you stated that this is the case, I realized that the '-a' in front of the BAM file name was missing, which I overlooked before. After adding it the program at least started to run. (Although it ran into another crirical error, appearantly misinterpreting chromosome and supercontig names from the BAM file header generated by STAR as transcript names.). Maybe it would be a good idea to distinguish in the error messages between 'unrecognised' and 'inappropriate' options to provide a better clue to the user what went wrong.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/343#issuecomment-462761900:139,reduce,reduced,139,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/343#issuecomment-462761900,1,['reduce'],['reduced']
Energy Efficiency,"Hi @rob-p,. would it be possible to add a feature similar to `salmon quant` like `--read-geometry 1[1-end]` (as in Alevin) to define which part of both R1 (and R2) should be used for the quantification? That would omit the need for trimming in case of adapters and make salmon workflows even more lightweight. best,; -Alex",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/743:252,adapt,adapters,252,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/743,1,['adapt'],['adapters']
Energy Efficiency,"Hi @rob-p. I'm using a SGE-based cluster. The disk I'm writing to is a networked disk that is mounted via NFS on the machines the cluster runs on. I've attached the output of running `qconf -sconf`, which provides details on how the cluster has been configured (I've edited out some lines about the admin e-mails, etc.). I'm not sure how useful much of this information is. A lot of it has to do with scheduling of jobs -- how many jobs/resources users can attempt to claim, that kind of thing. Let me know if there's something else that would be more useful in this context. I've also attached the log that was generated by the indexing run itself (just for the 17mer index), just in case. I can say one thing from having inspected the logs of these things failing a number of times before I finally caved and started giving it insane amounts of memory: by far the longest time and (most likely) the biggest resource hog is between the first and second pass. Even with only 16GB, it manages to complete the first pass (it still takes quite a while, though):. ```; Pass	Filling	Filtering; 1	718	3236	; 2	1839	237; ```. [qconf-sconf.txt](https://github.com/COMBINE-lab/salmon/files/4172585/qconf-sconf.txt); [index_GRCm38_GENCODE_M23_PRI_17mer.log.txt](https://github.com/COMBINE-lab/salmon/files/4172594/index_GRCm38_GENCODE_M23_PRI_17mer.log.txt). EDIT: Oh, I should also probably say, that I'm only seeing this slowdown on index creation. I'm sure that was implied, but I just wanted to be clear that at the moment, I'm happy enough to let the index build for a few hours every once in a while. I'm still saving huge amounts of mapping time, relative to ""full"" aligners.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583567362:401,schedul,scheduling,401,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583567362,1,['schedul'],['scheduling']
Energy Efficiency,"Hi @roryk,. Salmon doesn't currently have the ability to output a pseudobam, but that is definitely possible (and not too difficult). We have a related feature planned; perhaps you could tell me if it suits your use case. However, first, I should mention that if you'd simply like a pseudobam for _all_ the mapping locations of the reads, you can use [RapMap](https://github.com/COMBINE-lab/RapMap). RapMap implements the quasi-mapping algorithm upon which Salmon and Sailfish are based (and RapMap is used as a library in the Salmon and Sailfish codebases). Given an index and set of reads, RapMap will report all of the multi-mapping locations that Salmon and Sailfish would consider during quantification. The other feature we have in the works is to have Salmon optionally output a `.bam` file (with actual alignments) post-quantification. It turns out that, given the quasi-mapping information and the quantification results, taking the extra step from quasi-mapping to an actual _alignment_ can be done fairly efficiently. In this mode, Salmon would make one more pass over the reads and, considering the estimated abundances, sample a single alignment for each multi-mapping read proportional to the relative abundance of the different multi-mapping targets (i.e. it would perform a sampling over the multi-mapping locations that would, in expectation, give the same abundances as the _soft_ assignments computed by the optimization algorithm). This feature will be very useful for [transrate](https://github.com/Blahah/transrate). However, given that your goal is to use outside information to perform the filtering yourself, this option may not be ideal for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-175092553:1016,efficient,efficiently,1016,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-175092553,1,['efficient'],['efficiently']
Energy Efficiency,"Hi @tamuanand ,. Thanks for pointing this out. You are right, we missed to update the salmon doc with this details. You can find the latest preprint [here](https://www.biorxiv.org/content/10.1101/657874v2). The new version don't require the GTF because now we don't generate the decoys explicitly i.e. you don't have to run mashmap. With the latest version salmon, it can consume the full genome and transcriptome without the explicit need of annotation. It's much more efficient and takes significantly less memory to align/quantify compared to other genome based method. Please checkout the preprint for more details and [this](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/) tutorial for how to index the gentrome (genome + transcriptome) index. We will update the salmon docs too, to reflect the same.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/384#issuecomment-549183799:470,efficient,efficient,470,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/384#issuecomment-549183799,1,['efficient'],['efficient']
Energy Efficiency,"Hi @tamuanand,. Sure; is there anything specific about bbduk and bbmap for quality / adapter trimming that you think would be provided beyond or in addition to what fastp provides? Also, we have a beta implementation of soft-clipping and are looking for a wide net of testing data. Any suggestions to that end would be welcome!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597344801:85,adapt,adapter,85,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597344801,1,['adapt'],['adapter']
Energy Efficiency,"Hi @tamuanand,. Thanks for the suggestion. You're right, of course, and we should change the wording in that readme. The cause of the sequence similarity is not always known, and frankly, not important for our particular application. We adopted this term as shorthand given it's common use and also because the version of MashMap used to compute these sequence-similar regions was introduced in the paper [A fast adaptive algorithm for computing whole-genome homology maps](https://academic.oup.com/bioinformatics/article/34/17/i748/5093242). In the preprint itself, we're generally careful to simply refer to these as sequence-similar regions ;).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499476462:413,adapt,adaptive,413,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499476462,1,['adapt'],['adaptive']
Energy Efficiency,"Hi @vd4mmind,. Indeed, @mdshw5 is spot on. The issue you're seeing is a result of the hash table doubling failing to allocate sufficient memory when attempting to build a hash table for all 31-mers in the mouse genome. In addition to the memory requirements of building a quasi-index on the genome (which we're actually working to mitigate b/c we think it could be useful in another context), this won't be particularly useful for quantification. Salmon treats each entry in the multifasta file as a distinct transcriptional target. Thus, here, even if the index did build successfully, you'd be quantifying the abundance of different chromosomes & contigs, rather than the transcripts. What you should do (as pointed out by @mdshw5 above), is to grab a file that contains the mouse transcripts (or take your mm9 genome and an appropriate gtf file and use a tool like `gffread` to extract the transcript sequences).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197873003:117,allocate,allocate,117,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197873003,1,['allocate'],['allocate']
Energy Efficiency,"Hi @xinbindai,. What you are seeing in both Salmon and RSEM is the expected behavior. This is because, to a large extent, the entire purpose of these tools is to appropriately allocate mulit-mapping reads. In your case, it is likely the case that one of the two very similar transcripts could account for all of the reads, while the other could not. For example, image I have a simple scenario where I have two transcripts:. ```; ACACACTGTGTGTG; ACACACGGTGTGTG; ```. Now, imagine I observe the ""reads"":. ```; ACAC; ACAC; CACA; CACA; ACTG; CTGT; GTGT; TGTG; TGTG; ```. The majority of these reads could have come from either transcript (and are equally likely to have come from both). However, the fact that we observe `ACGT` and `CTGT` is rather strong evidence that we could explain all of the reads via the first transcript while positing 0 (or close to 0) abundance for the second. On a much larger scale, this is what Salmon and RSEM are doing --- they are finding the most likely abundances of the transcripts given the observed data (the reads). When there is unique evidence of one of the two variants, and no unique evidence of the other, the maximum likelihood estimate for the variant with no unique evidence is very small. I'm not sure how many reads you are mapping, but you likely got a somewhat different estimate from eXpress since it tends to regularize it's abundance estimates a bit more strongly than Salmon or RSEM. That being said, this is the intended behavior of these tools, they are meant to probabilistically allocate multi-mapping fragments to similar transcripts in a manner that maximizes a global likelihood, so I don't think that what you are seeing is un-expected. In fact, it is consistent with the probabilistic model that underlies all three tools.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263408444:176,allocate,allocate,176,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263408444,2,['allocate'],['allocate']
Energy Efficiency,"Hi @yeodynasty,. There are two different ways to tackle this question. The first relies on the fact that the correction employed by salmon for GC bias is done via the adjustment of transcript effective lengths. Here, you could compare the effective length in the quant.sf file to the effective length you would get ignoring GC-fragment (or other bias). Granted, the latter is not written down in the file here, but it is straightforward to calculate since salmon also writes out the fragment length distribution. ; The effective length discarding bias estimates is simply the transcript length, minus the mean of the conditional fragment length distribution (the fragment length distribution from 0 up to the transcript length, re-normalized to be an appropriate probability distribution). If you look at the differences between these values, you can infer how much bias correction was applied. Specifically, when the bias-corrected length is longer than the non bias-corrected length, then these transcripts are over-represented in sequencing and the bias correction aims to reduce their estimated abundance. On the other hand, when the bias-corrected length is shorter than the non bias-corrected length, then these transcripts are under-represented in sequencing and the bias correction aims to increase their estimated abundance.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/578#issuecomment-717267531:1076,reduce,reduce,1076,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/578#issuecomment-717267531,1,['reduce'],['reduce']
Energy Efficiency,"Hi Avi,. Yes I just asked and the guide sequences were reverse complemented. I was looking through the results and comparing it with the output of another alignment software. I noticed that there are substantially fewer UMI per guide (in cell) throughout ( see figures for comparison). . ![image](https://user-images.githubusercontent.com/9895004/83803410-7eb16f80-a67a-11ea-832d-562c88dafef3.png) ; ![image](https://user-images.githubusercontent.com/9895004/83803427-8709aa80-a67a-11ea-9ea4-f66ca447a65c.png). Also, the number of UMIs per cell barcode is consistently lower and there is around 796 barcodes that are not found in the 10X whitelist, the majority of which tend to have 1 UMI count only. Here is tally, where the TRUE column indicates the barcode is found in the whitelist. The row names indicate the total number of UMIs; ; ![image](https://user-images.githubusercontent.com/9895004/83803984-7279e200-a67b-11ea-8578-fc863f94f714.png). It would be great if you can implement the index hopping correction in Alevin. The software we have works fine if the number of samples is not too large. If had known how to code in C++, I would have implemented part of the code more efficiently using Rcpp. Please let me know if you ever decide to add this feature to Salmon. I am more than happy to help. Rick,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639088909:1184,efficient,efficiently,1184,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639088909,1,['efficient'],['efficiently']
Energy Efficiency,"Hi Mohsen and Rob,. So sorry if you've already been troubleshooting the example data I gave you. I realized that that is not a good example of the problem. In this example, there are snR40 and snR40_genomic transcripts, representing processed and pre-processed isoforms. However, it just so happens that there is residual adapter on some of the reads I provided and the first nucleotide of the adapter sequence actually matches the first nucleotide of the longer, genomic version of this transcript, therefore, the genomic variant gets a slightly better alignment score, as it should. After hard trimming any residual adapter the results for this transcript were a lot better (although still not quite the ratio I would expect). I have quite a few examples like this and I'm fairly sure they are not *all* explained by alignment of adapter sequences. However, I just wanted to let you know in case you were already troubleshooting my example data. I'm aggregating a handful more general examples of the same problem, but ones without a trivial solution like the one I provided. The files are too large to attach on github directly, though, do you have a preferred way to share the files? Maybe a google drive?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-642954815:322,adapt,adapter,322,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-642954815,4,['adapt'],['adapter']
Energy Efficiency,"Hi Rob & Team, . First and foremost, my thanks for developing such a great and versatile tool, very grateful for your work. . I'm hoping for some words of wisdom. We've got some data from Lexogen CORALL libraries (parired end + UMI). One of the main benefits in using this kit, is the lack of fragmentation step, instead there is Displacement Stop Primers (DSP) which are theoretically randomly distributed. . One approach we've taken is to trim adapters, and collapse UMIs (from STAR alignment). Following these steps, we've got theoretically clean data, so using `samtools fastq` to make a Salmon-friendly input. We observed a very unusual fragment length distribution with this, it looks largely poisson. I've rationalised this as the fragments being particularly short after UMI + Adaptor trimming, and given the random nature of DSPs, this could make some sense. One thing that stuck out in my mind was ordering of the reads (which were coord sorted), thus they'd be coming into salmon that way, breaking an assumption of the streaming EM algorithm. . We're currently name sorting the reads prior to Salmon quantification, but I wonder if you could explain if this unusual FLD could be a consequence of position sorted fastq, or any other thoughts you have around this situation? The good news is that ultimately, the same high level biology comes out of the quantifications whichever way do it. . Thanks for any insight. Andrew",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/765:446,adapt,adapters,446,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/765,2,"['Adapt', 'adapt']","['Adaptor', 'adapters']"
Energy Efficiency,"Hi Rob,. Thanks for the clarity regarding the effect of insert size distribution on quantification. That does resolve this issue, and gives me a path going forward using Salmon for this data. However, I am trying to use Salmon for small RNA-Seq data, where the insert size is equal to read length for most reads after adapter trimming. Would it be possible to add a flag to use read length as a proxy for insert size, potentially with a fallback to fldMean/fldSD in the case of full-length, untrimmed reads? This is something I would be willing to contribute myself, if it sounds appropriate. Thanks,; Gautam",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-752064194:318,adapt,adapter,318,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-752064194,1,['adapt'],['adapter']
Energy Efficiency,"Hi Ryan,. The difficulty is, indeed, exactly as you specify. Given a single-end read, one does not know the length of the _fragment_ from which it originates. In this case the ""right"" thing to do (the best thing we can do) is to consider the read as starting / ending a fragment of every possible length allowed by the user-provided fragment length distribution (with the contribution of each possible fragment weighted by the probability of observing a fragment of that length). In order to make this computationally feasible, one would have to do some clever pre-computation and thing a bit more about how to efficiently update the observed GC model (right now, each mapping contributes a single weight to the model, but under the naive implementation in the single-end case, each mapping would contribute different weights to each bin of the observed GC-bias curve, which would slow things down considerably). Also, as you point out, the quality of the correction would depend somewhat on the user providing appropriate parameters for the fragment length distribution mean and standard deviation — but this seems reasonable in the single-end case. That being said, I'm sure there's a way to handle this efficiently, I'd just have to think about it a bit. Regarding your second question; Salmon learns the fragment length distribution in paired-end data, but not with single-end data. Single-end data can provide a little bit of information (e.g. there is in upper bound on fragment lengths that one can infer based on single-end reads based on how far they map from the end of the transcript), but not enough information to reliably infer a fragment length distribution. cc @mikelove in case he has any thoughts on this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243833424:611,efficient,efficiently,611,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243833424,2,['efficient'],['efficiently']
Energy Efficiency,"Hi, ; I've been trying to run alevin for single cell data. I've been using test data and the salmon alevin command seems to work right until the end, and then the core is dumped just as counts are in the csv format. I've also tried running it without --dumpCsvCounts and this also results in a segmentation fault. . What I was running:; salmon alevin -l ISR -1 ./hgmm_100_S1_L002_001.fastq.1.gz -2 ./hgmm_100_S1_L002_001.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index -p 10 -o salmon.dir/hgmm_100_S1_L002_001 --tgMap transcript2geneMap.tsv --dumpCsvCounts. Final part of output:; Analyzed 287 cells (100% of all).; [2019-01-25 11:14:44.509] [alevinLog] [info] Total 46729.00 UMI after deduplicating.; [2019-01-25 11:14:44.509] [alevinLog] [warning] Skipped 63 barcodes due to No mapped read; [2019-01-25 11:14:44.529] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-01-25 11:14:44.561] [alevinLog] [info] Starting Import of the gene count matrix of size 224x19879.; [2019-01-25 11:14:44.576] [alevinLog] [info] Done initializing the empty matrix.; [2019-01-25 11:14:45.067] [alevinLog] [info] Done Importing gene count matrix for dimension 224x19879; [2019-01-25 11:14:45.770] [alevinLog] [info] Starting dumping cell v gene counts in csv format; Segmentation fault (core dumped) . I am running version 0.12.0 of salmon, installed via bioconda. I have also allocated 30GB of memory for the job, so this isn't a memory issue.; I have seen other users having similar issues using salmon quant having installed salmon through conda and the suggestions have been to install from binaries. This is not an option as salmon needs to be run easily using a conda environment. ; Has any headway been made into fixing the bioconda build?. Thanks,; Anna",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337:1397,allocate,allocated,1397,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337,1,['allocate'],['allocated']
Energy Efficiency,"Hi, I am running salmon-1.9.0, but in quant bulk mode for rat from *.bam files it stops with this error `Segmentation fault (core dumped)`. --threads 10 and 10 cpu (each core is 5.3 GB) are allocated for this job. Thanks for your solution(s) in advance!. Hi again, I found this issue is related to multiple bam input files which I've done by -a parameter with a (space-separated) list of these files. It is fixed now if just run salmon per file individually.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-1239714634:190,allocate,allocated,190,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-1239714634,1,['allocate'],['allocated']
Energy Efficiency,"Hi,. I am testing Alevin, and would like to compare against Cell Ranger on my data set. While primary mapping statistics indicate more reads mapped, I would like to compare the results in the final analysis, in Seurat. Many steps rely on HGNC Gene symbols as opposed to Ensemble IDs. ### What is the best way to convert ensembl IDs to gene symbol in Alevin?. Alevin (aligned as in this [gist](https://gist.github.com/k3yavi/c501705ed2d29b12b0d10cf78b3ed001#file-alevin-default-ipynb), imported to R in this [tutorial](https://combine-lab.github.io/alevin-tutorial/2018/running-alevin/)) returns ensembl IDs in format like ""ENSG00000215910.7"". ```R; require(""fishpond""); require(""tximport""); ; files <- file.path(""[...]/alevin/quants_mat.gz""); file.exists(files); txi <- tximport(files, type=""alevin"");; rownames( txi$counts); ``` . I am currently converting these using biomart with suboptimal adaptations:. ```R; BiocManager::install(""biomaRt""); require('biomaRt'); mart <- useDataset(""hsapiens_gene_ensembl"", useMart(""ensembl"")); genes <- rownames(txi$counts); df$id <- NA; meta.genes <- getBM(attributes = c(""ensembl_gene_id"",""external_gene_name"", ""description""), ; values = genes, mart = mart ); ```; Manual adaptations:. 1. I trim IDs after dot (""ENSG00000215910.7"" → ""ENSG00000215910”); 2. I remove NA values (not all trimmed gene IDs are found in biomaRt); 3. I add up counts of genes (per ENS.ID) with the same gene symbol, e.g. “Y_RNA” or “HSPA14”. ```R; g.LookUp = meta.genes[,2]; names(g.LookUp) = meta.genes[,1]; ; # 1. Trim; ensembl_ID.simple =str_split_fixed(genes,pattern = '\\.', n=2)[,1]; ; genes.converted = g.LookUp[ensembl_ID.simple]; any.duplicated(genes.converted); ; # ...etc; ```. Is there a better way to convert IDs, possibly implemented in Alevin / Salmon?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/448:894,adapt,adaptations,894,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/448,2,['adapt'],['adaptations']
Energy Efficiency,"Hi,. I am using Salmon v 1.10.1 do perform selective alignment on paired end RNAseq samples and I have trouble to interpret the output statistics (i.e succesfully mapped pairs ....); Here is my command line on a sample containing 34,462,097 pairs (After cleaning, adapter removal, rRNA trimming). **salmon quant -i $IndexDir -l A -1 $forward -2 $reverse -p 8 --seqBias --gcBias –useVBOpt --discardOrphansQuasi –consensusSlack 0.35 --minScoreFraction 0.8 --decoyThreshold 1 -o $OutputDir/$pairname_Output**. Here is the the output statistics of the alignment; [Salmon_quant_output.txt](https://github.com/COMBINE-lab/salmon/files/11768911/Salmon_quant_output.txt). So I have few questions : . 1- Where is idicated the numer of processed pairs, i.e. the number of pairs in the sample ?. 2- Does the mapping rate correspond to the reads that will be used for the quantification (i.e. succesfully mapped and that were above every filtering thresholds) or this % also takes into account the discarded mapping ? This is of great importance to tell if the mapping step is good or not. 3- Counted 20,588,460 total reads in the equivalence classes What does this mean ? Is it the numner of pairs that mapped (discarded and not discarded or only the ones that are kept for quentification). 4- What is the difference between mapping discarded and fragment discarded ? To count the number if pairs that did not map to my reference should I sum Number of mappings discarded because of alignment score + Number of fragments entirely discarded because of alignment score + Number of fragments discarded because they are best-mapped to decoys + Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets. Thanks in advance for your time and answers,,. Florian Rocher",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/852:264,adapt,adapter,264,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/852,1,['adapt'],['adapter']
Energy Efficiency,"Hi,. I have been trying to run the installed salmon version on our HPC cluster on minimap aligned ONT reads and got the following error:. `processed 0 reads in current round/var/lib/slurm/slurmd/job10333001/slurm_script: line 25: 2153273 Bus error (core dumped)`. My script was as follows:. ```; module load salmon/1.9.0-gcc-10.3.0; cd /scratch/prj/ppn_microglia_mod/targeted/transcriptome/clean/transcriptome. for bc in {01..54}; do. salmon quant --ont -t /scratch/users/k19022845/refgenome/gencode.v44.transcripts.fa -l A -a ""combined_BC""$bc""_aligned.bam"" -o ""BC""$bc""_transcripts_quant"". done; ```; Salmon version was `1.9.0`; Transcriptome ref: Homo Sapiens Gencode v.44. The directories were generated for the barcodes and contain `aux info`, `cmd_info.json`, `libParams` and `logs` but the directories/files are empty. The command was run through `slurm` scheduler on HPC cluster. The output log looks like (repeated for `for` loop):; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; # salmon (alignment-based) v1.9.0; # [ program ] => salmon ; # [ command ] => quant ; # [ ont ] => { }; # [ targets ] => { /scratch/users/k19022845/refgenome/gencode.v44.transcripts.fa }; # [ libType ] => { A }; # [ alignments ] => { combined_BC01_aligned.bam }; # [ output ] => { BC01_trascripts_quant }; Logs will be written to BC01_trascripts_quant/logs; [2023-11-04 16:49:44.093] [jointLog] [info] setting maxHashResizeThreads to 8; [2023-11-04 16:49:44.093] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:single end",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/898:860,schedul,scheduler,860,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/898,1,['schedul'],['scheduler']
Energy Efficiency,"Hi,. If I don't trim the adaptors and still use --ont will I still get correct quantification? Is adaptor trimming very essential? Is there a way I can use salmon without adaptor trimming?. Also, can you please clarify about the secondary alignmenmts if these are included in Salmon or not?. Thanks,; Harsha; ________________________________; From: Feng Yan ***@***.***>; Sent: 08 January 2024 23:30; To: COMBINE-lab/salmon ***@***.***>; Cc: Harshangda Karan Puri ***@***.***>; Author ***@***.***>; Subject: Re: [COMBINE-lab/salmon] Quantification in Alignment mode for Nanopore Data (Issue #903). also interested to know how Salmon uses secondary alignment. Because I found this tutorial https://combine-lab.github.io/salmon-tutorials/2021/ont-long-read-quantification/ [combine-lab.github.io]<https://urldefense.com/v3/__https://combine-lab.github.io/salmon-tutorials/2021/ont-long-read-quantification/__;!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTnGob8fw$> actually includes secondary alignments.; And based on my experience, secondary alignments are used by Salmon, because when I give a BAM before and after removing secondary (-F 256 flag in samtools), the results are different. —; Reply to this email directly, view it on GitHub [github.com]<https://urldefense.com/v3/__https://github.com/COMBINE-lab/salmon/issues/903*issuecomment-1881982972__;Iw!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTEiG0xQE$>, or unsubscribe [github.com]<https://urldefense.com/v3/__https://github.com/notifications/unsubscribe-auth/A3SZAPCLOZYB72ZEIEEXH43YNR6S7AVCNFSM6AAAAABANBCPNSVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTQOBRHE4DEOJXGI__;!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTntkMlxE$>.; You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/903#issuecomment-1884769339:25,adapt,adaptors,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/903#issuecomment-1884769339,3,['adapt'],"['adaptor', 'adaptors']"
Energy Efficiency,"Hi,. Might be something trivial that takes no effort to figure out. I have mouse `RNA-seq` data (`single-end` `stranded` - `reverse strand`) which I `STAR` mapped against `mm10` with `gencode.vM12.primary_assembly.annotation` `GTF`, where I ran `STAR` in a mode that also generates a bam file of the reads mapping to the `transcriptome`. For my purpose I'd like to retain only reads that map to transcripts annotated as `protein_coding` in the `GTF`, which would be my total, meaning `TPM`s will be calculated based on that slice of the pie rather than based on all reads. What I did is `samtools` `sort` and `index` the transcriptomic `bam`, and then subset that `bam` with a `bed` file which only includes the transcripts that are annotated as `protein_coding`. This reduces the number of mapped reads from 11,653,865 to 3,483,962. When I use `Salmon` to quantify expression of that subsetted `bam`, Salmon crashes, but it doesn't if I give it the un-subsetted `bam`. Any idea why it's crashing?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/213:769,reduce,reduces,769,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/213,1,['reduce'],['reduces']
Energy Efficiency,"Hi,; I was skimming through some of the code and other open issues on support for other library (cell barcode/umi) designs. It looks like there is code for supporting inDrop libraries, but I wasn't sure which parameters I'd need to set. I have inDrop v2 libraries that I'd like to process and am just trying to figure out if we'll need to write our own extensions or if there is already code in place that we can test. Related to some of the comments about the best model for UMI correction in #269 ; The inDrop (at least the v2 protocol) is based on the CEL-Seq like chemistry -- which uses (in vitro transcription) IVT for the initial amplification rather than PCR. From what I've seen so far, the 2 main flavors of single cell RNA-Seq library construction chemistry are; 1. CelSeq/inDrop; polyA capture -> Reverse transcription (RT) for 1st strand cDNA synthesis -> 2nd strand synthesis -> IVT (linear) amplification -> fragmentation -> RT again to convert back to cDNA -> final PCR to amplify library and add Illumina adapters. 2. DropSeq/10X; polyA capture -> RT with template switching -> PCR amplification of cDNA -> fragmentation followed by variable library construction (either transposon/Nextera based or more traditional --frag, end repair, a-tail and adapter ligation) -> final PCR to amplify library and add Illumina adapters. Thanks so much!; Julie",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/339:1022,adapt,adapters,1022,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/339,3,['adapt'],"['adapter', 'adapters']"
Energy Efficiency,"Hi,; When I use the default k-mer length of 31 to generate index, it throws warnings like 'ENSTxxxxx had length less than equal to the k-mer length of 31'. I checked these transcripts, and most of them are immunoglobulin and T cell receptor genes. ; My question is:; 1. Transcripts with a length below specified k-mer length will be discarded during alignment, right? ; 2. If I reduced the k-mer length to a smaller odd value, say 15, will this affect accuracy? My read length is 150. ; Thanks",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/754:378,reduce,reduced,378,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/754,1,['reduce'],['reduced']
Energy Efficiency,Holy cloud-computing charges! I'm sorry to hear about this. We can certainly rate-limit this message. I'll work on fixing this upstream. Sorry for the trouble.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-328981463:21,charge,charges,21,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-328981463,1,['charge'],['charges']
Energy Efficiency,"How big is the index directory? The fact that it hasn't used up all of the memory doesn't mean that the allocator should be able to allocate more. If the next chunk it needs to allocate is large (e.g. the position table), and it needs that memory in contiguous space, the allocation might fail. I'd recommend either trying this on a larger memory machine, or trying a smaller index (e.g. the selective alignment index with custom decoys rather than the whole genome) on this machine. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-629842095:132,allocate,allocate,132,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-629842095,2,['allocate'],['allocate']
Energy Efficiency,"I also have had to submit indexing jobs with much larger resources and times since the switch to the new indexing method with whole genome decoys. Prior to this I could built and index asking for only 16GB of ram in minutes. Now, I have to request ~256GB of memory and it runs for 7-10 hours. These are just ""standard"" mouse transcriptomes (GENCODE M23). I should note that using 17-mers as my kmer length dramatically increased these requirements. I re-ran using 31-mers, and the time reduces to a couple of hours and only used ~20GB of memory. I've attached two files that have summaries of the resources used in the jobs I ran in the above. Everything about these jobs is the same, except for the k-mer lengths. I requested the same amount of resources for each, but you can see that the one labeled 31mer has drastically less ""ru_maxrss"", which is the maximum amount of memory used by the process (it's in KB, although it's not labeled in the log). I also noted that there weren't any hard page faults for either of the jobs (""ru_majflt""). The longer job did have more soft page faults/page reclaims (""ru_minflt""). I don't know if that's useful information or not. [qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4172209/qacct-17mer.log); [qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4172210/qacct-31mer.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583526416:486,reduce,reduces,486,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583526416,1,['reduce'],['reduces']
Energy Efficiency,"I gave it another try, as I wasn't monitoring resources before. It's trying to make a liar of me! It is working fine now after wasting my entire day. :/ It took under a minute. I had tried to run it a dozen times by the time I gave up and posted. Oh well, thanks for the help! I'll go hide in shame somewhere now and convince myself I didn't imagine the whole thing :D",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/100#issuecomment-258491545:35,monitor,monitoring,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/100#issuecomment-258491545,1,['monitor'],['monitoring']
Energy Efficiency,"I see, we might have to tweak a bit based on the use case for `longranger basic`.; In `v0.10`, alevin should still be able to do CB correction, and attach the corrected CBs to the header of the second file, although the remaining template sequence (128 bases) from the first file might get loss, since `cellranger` was using template sequencing in only one file. Like @rob-p was saying we can work on making this step more generalized, once we confirm that the error-correction model for `cellranger` and `longranger` can be used interchangeably. In theory we can still concatenate the remaining 128 bases into an interleaved format since alevin has hidden options to provide the lengths explicitly but we have not tested this feature extensively. We will keep this at the top of our feature-request list and would inform you as soon as we have a stable version with this feature. Thanks again for the interest !!. re: *interleaved format* -- indeed an interleave format does makes sense and should be the default dumping format, but I believe since the default mode of 10x's `mkfastq` is to dump separate `FASTQ`, we should not use resources to create an interim interleaved format and then consume it downstream (since`FASTQ` itself is not very efficient), instead, in alevin we just consume the two separate `FASTQ` into our own interim data-structure to perform the downstream analysis.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395195411:1247,efficient,efficient,1247,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395195411,1,['efficient'],['efficient']
Energy Efficiency,"I was running some quantification on Google Compute Engine and a particular study repeatedly printed ""couldn't dequeue read chunk"" for 2.5 days. By the time I discovered it, over 300GB of Egress traffic (sending the message to my local computer) had accumulated. Cost me close to $100 between Google's egress charges and my ISPs bandwidth overage charges. It would be nice if the message didn't print so much. I'm now running Salmon commands with `timeout 1h` prefix to prevent this but might run into an issue with 1 hour not being long enough for all quantification runs.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152:309,charge,charges,309,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152,2,['charge'],['charges']
Energy Efficiency,"I was trying to troubleshoot the contemplation period of salmon with monitoring utilities and just stumbled upon this issue upon submitting my own. The failed version check gets buried by the spew of warnings for too short/long transcripts for hg38 mrna.fna in my case. The current behaviour is particularly irritating as I assumed, that `salmon index -h` just runs into a loop accidentally. The check takes multiple minutes to timeout. I am behind a proxy. Please remove the version check by default, as this is not common behaviour of command line tools or anticipated by the user. Or at least please add a verbose message before checking ""Checking for upgrades online..."".",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/277#issuecomment-474388032:69,monitor,monitoring,69,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/277#issuecomment-474388032,1,['monitor'],['monitoring']
Energy Efficiency,"I'm looking at using Salmon on metatranscriptomes (environmental de novo assemblies). Our assemblies are typically very large, i.e. many millions of sequences. When scheduling jobs on my university's cluster (LSF), I'm required to set a memory limit. When salmon exceeds this limit, the job is killed, and I must restart the process. Is there a recommendation for predicting how much memory salmon will use to index/quant based on the size of the transcriptome? Could it be possible to set a memory limit for salmon so that it doesn't attempt to call more than is allocated?. Thank you!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/97:165,schedul,scheduling,165,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/97,2,"['allocate', 'schedul']","['allocated', 'scheduling']"
Energy Efficiency,"I've got some SMART-seq2 data that's been demultiplexed, so hundreds of small Fastq files. So, I was wondering: . - Does Salmon have a way to take multiple samples / libraries on a single run and perform quantification in an optimised serial way? ; - Does Salmon have a way to keep the index in memory similar to STAR? . I guess the obvious alternative is to schedule lots of runs, but just wondered if there were alternative options. Thanks!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/589:359,schedul,schedule,359,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/589,1,['schedul'],['schedule']
Energy Efficiency,"If an adapter is not trimmed, will it affect the mapping rate?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/398:6,adapt,adapter,6,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/398,1,['adapt'],['adapter']
Energy Efficiency,Is it necessary to trim adapters before using salmon?,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/398:24,adapt,adapters,24,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/398,1,['adapt'],['adapters']
Energy Efficiency,"Is there a way to compile Salmon to a 32-bit architecture by any chance? I ask because I'd like to have single-cell tutorials on sandbox.bio v2 that use Salmon. But to power the platform, I'm running a 32-bit/i686 Debian OS in the browser 😬. When I try to compile it in a [i386/debian:bookworm-20230904-slim](https://hub.docker.com/r/i386/debian/) Docker container, this is the error I get:. ```; 1075.0 -- Build files have been written to: /root/build/salmon/external/oneTBB-2021.5.0; 1075.2 [ 14%] Performing build step for 'libtbb'; 1075.7 [ 2%] Building CXX object src/tbb/CMakeFiles/tbb.dir/address_waiter.cpp.o; 1079.6 [ 5%] Building CXX object src/tbb/CMakeFiles/tbb.dir/allocator.cpp.o; 1083.2 [ 7%] Building CXX object src/tbb/CMakeFiles/tbb.dir/arena.cpp.o; 1087.7 In file included from /usr/lib/gcc/i686-linux-gnu/12/include/x86gprintrin.h:89,; 1087.7 from /usr/lib/gcc/i686-linux-gnu/12/include/immintrin.h:27,; 1087.7 from /root/build/salmon/external/oneTBB-2021.5.0/src/tbb/../../include/oneapi/tbb/detail/_machine.h:42,; 1087.7 from /root/build/salmon/external/oneTBB-2021.5.0/src/tbb/../../include/oneapi/tbb/detail/_utils.h:26,; 1087.7 from /root/build/salmon/external/oneTBB-2021.5.0/src/tbb/task_dispatcher.h:20,; 1087.7 from /root/build/salmon/external/oneTBB-2021.5.0/src/tbb/arena.cpp:17:; 1087.7 /usr/lib/gcc/i686-linux-gnu/12/include/waitpkgintrin.h: In function 'tbb::detail::r1::prolonged_pause()':; 1087.7 /usr/lib/gcc/i686-linux-gnu/12/include/waitpkgintrin.h:53:1: error: inlining failed in call to 'always_inline' '_tpause(unsigned int, unsigned long long)': target specific option mismatch; 1087.7 53 | _tpause (unsigned int __A, unsigned long long __B); 1087.7 | ^~~~~~~; 1087.7 compilation terminated due to -Wfatal-errors.; 1087.8 make[5]: *** [src/tbb/CMakeFiles/tbb.dir/build.make:104: src/tbb/CMakeFiles/tbb.dir/arena.cpp.o] Error 1; 1087.8 make[4]: *** [CMakeFiles/Makefile2:170: src/tbb/CMakeFiles/tbb.dir/all] Error 2; 1087.8 make[3]: *** [Makefile:156: all] Er",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/872:168,power,power,168,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/872,1,['power'],['power']
Energy Efficiency,"No problem! We're actually working now on an optional use of a perfect hash in the quasi-index. It increases index construction times, but provides the same speed of lookup as the current hash. Also, it reduces the memory usage by a factor of ~2. We just have to figure out how to implement this cleanly in the code base.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-187748517:203,reduce,reduces,203,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-187748517,1,['reduce'],['reduces']
Energy Efficiency,No worries - and that is exactly what I thought could be possible :-). Just out of curiosity - how would Salmon currently handle if half of a read could be quasi-mapped to a transcript but the second half did not fit anywhere (due to it being very low quality or sequencing adapter contamination)?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353287536:274,adapt,adapter,274,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353287536,1,['adapt'],['adapter']
Energy Efficiency,NumThreads (Consumer Threads) should be reduced too?,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/178:40,reduce,reduced,40,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/178,1,['reduce'],['reduced']
Energy Efficiency,"Oh, I should've pushed my PR sooner!; Thanks!; I'll take a look how it compares to what I did. ; One thing to note is that it'd be useful to be able to specify the length of the CB - we use 8 bp in our slightly-adapted CEL-Seq2 protocol.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418579796:211,adapt,adapted,211,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418579796,1,['adapt'],['adapted']
Energy Efficiency,"Ok, salmon V1.0.0 finished in 5H 15 min, so about 5 times faster, the exact same library and parameters, and achieved almost the same mapping rate (85.1058% with V1.2.0 vs 84.6341% with V1.0.0) attaching log. I must add I did not trim this library for adapters nor quality, nor did anything to it. Just mapped as is. But fastQC showed excellent levels of quality even at the ends and no or minimal adapter content. ; Also no changes have been done one my OS other than regular updates, but still Ubuntu 18.04. I don't remember any specific changes I've done to it. ; Pearson's correlation in transcript abundance (isoform lelvel) is 0.9984013. Spearman's is 0.9899048. ; Also, I did checked that salmon was actually using 4 threads in both cases, and it was fully using those.; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4707443/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127:252,adapt,adapters,252,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127,2,['adapt'],"['adapter', 'adapters']"
Energy Efficiency,"Ok, thank you very much.; The problem I had was RAM availability. I enlarged it for 48 and it works.; However, to quantify I had another problem.; I use this command line and I increase to 56 RAM. srun ./salmon-1.5.2_linux_x86_64/bin/salmon quant -i salmon_index \; -l A \; -1 ERR3537668_1.fastq.gz \; -2 ERR3537668_2.fastq.gz \; -o transcripts_DecoyQuant \; --validateMappings \; --numBootstraps 100 \; --gcBias \; --seqBias\; -p 12. And I got this error message:; [2021-11-08 14:35:28.348] [jointLog] [info] Finished Bootstrapping; ERROR: Could not create the directory [""transcripts_quant""]. Please check; that. But actually, it was created.; I really don't understand the message error. Best wishes,; Luciana. On Fri, Nov 5, 2021 at 5:56 PM Rob Patro ***@***.***> wrote:. > Hi @lubios <https://github.com/lubios>,; >; > This suggests that the machine was not able to allocate enough memory to; > perform the requested operation. I would try the following things in order; > to see if they fix the issue. First, try quantifying without the; > decoy-aware index. This doesn't provide the benefits of the decoy sequence,; > but it will ensure that this is, in fact, the problem you are having. If; > that works, try building the decoy-aware index with the --sparse; > parameter. This will build the sparse index instead of the dense index,; > which is a bit smaller and may therefore fit in RAM on the machine where; > you are doing quantification.; >; > Best,; > Rob; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-962058307>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ADRT5CUYGXBSY3UOX24RTYDUKQLETANCNFSM5HOIMSQQ>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-963995631:871,allocate,allocate,871,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-963995631,1,['allocate'],['allocate']
Energy Efficiency,Quantification matrix with adapted Celseq2 protocol,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361:27,adapt,adapted,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361,1,['adapt'],['adapted']
Energy Efficiency,"Thank you for verifying @zhangchipku, and thank you very much for the kind words! We appreciate the feedback and input from our users like yourself. We'll prioritize the soft-clipping functionality for upcoming releases (maybe even the next if we can make that work in time). For the time being, I can recommend `fastp` as a fairly efficient / fast trimmer that. It might even be able to work in a streaming fashion so that you could pipe the trimmed reads directly to salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586548443:332,efficient,efficient,332,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586548443,1,['efficient'],['efficient']
Energy Efficiency,"Thanks for the recommendation. I'll definitely take a look at it. It is true that we typically suggest that you drop singletons if they are created during e.g. adapter / quality trimming etc.. However, it is also the case that one really may only want to consider very ""light"" quality trimming for RNA-seq data [as suggested by Matt MacManes](https://www.frontiersin.org/articles/10.3389/fgene.2014.00013/full). . If the trimming leads to the loss of a large number of reads, my initial reaction would be to try an understand why. One could always ""re-synchronize"" the singletons by providing them with fake mates, which would cause them to be mapped and treated as orphans during quantification. However, again, it's probably worth understanding why an experiment ends up with a lot of singletons before going through the trouble of accounting for them.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-400061755:160,adapt,adapter,160,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-400061755,1,['adapt'],['adapter']
Energy Efficiency,"Thanks, I usually do not trim reads. I am surprised to see such a difference from version 0.8.3. Do you have a recommendation for --minScoreFraction if I do not trim reads? Or maybe I should go back to NOT using --validateMappings?; For testing purposes, I will try trimming the reads for this sample. Will report back.; Oh, and this sample was prepared by ultra-low RNA input protocol, so the issues of adapter contamination could be present.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673:404,adapt,adapter,404,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673,1,['adapt'],['adapter']
Energy Efficiency,"Thanks, both, for your thoughts here. . As I understand it, current UMI quantification approaches take a BAM file with read alignments and then (hopefully in some smart way) count unique UMIs from reads aligned to (overlapping?) genomic features of interest. In the first instance, can Salmon produce output compatible with those sorts of approaches? (I seem to recall it's possible to output (pseudo)BAMs, but I have not yet had a need for this.). @vals: your suggestion of just ignoring UMIs is interesting - hadn't thought about that. It would be cool to figure out if that actually works as you suggest it might. I don't have any brilliant brainwaves to offer at the moment, but to you first point, Rob, I _definitely_ think the desire is/will be there. The sheer number of cells being sequenced demands very computationally efficient quantification, and since Salmon is at least as accurate as competitors while being extremely fast, in my mind Salmon is the leading contender for very wide use. Apparently 10X is about to drop a dataset of 1.3M cells, so yeah...fast methods needed. D.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-255853373:829,efficient,efficient,829,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-255853373,1,['efficient'],['efficient']
Energy Efficiency,That sounds like a very good way of doing it :-). I'm sorry I was not clear enough - my question was acutally meant for a single sequence - let me try again:; Lets say we have a read pair where one mate maps fine - but the other mate have a problem - half of it is an adapter (or low quality sequence with to many errors). How would Salmon currently handle this situation where the first half of a sequence (e.g. nt 1-50) could be quasi-mapped to a transcript but the second half (nt 51-100) did not match anywhere? Would the the second half cause the whole sequence to be discarded or would it be enough that the first half matched for it to be considered/counted?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-354955072:268,adapt,adapter,268,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-354955072,1,['adapt'],['adapter']
Energy Efficiency,"That works!. I wrote something very similar yesterday but using a here document generated from a Makefile in to job scheduler, and I couldn't get it to work. I'll file that under overcomplicating things...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168620775:116,schedul,scheduler,116,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168620775,1,['schedul'],['scheduler']
Energy Efficiency,"The virtual memory should also be greatly reduced in 1.2.0 (which I am working on finalizing the release of at the moment). There will be detailed release notes describing the improvements. However, getting the pre-built index is probably worth it if it's the right organism and annotation.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/503#issuecomment-612193221:42,reduce,reduced,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/503#issuecomment-612193221,1,['reduce'],['reduced']
Energy Efficiency,"This is a different issue. This means that your BAM-file is ill-formed for consumption by salmon. Basically, the BAM input requirements for salmon are the same as those for RSEM. Specifically,. * All alignments for a given read must appear contiguously in the BAM file.; * If you have paired-end data, then the alignments must be of the form:; ```; alignment_1 for left read; alignment_1 for right read; alignment_2 for left read; alignment_2 for right read; ...; alignment_k for left read; alignment_k for right read; ```. * You cannot mix alignments for paired-end and single-end reads in the same BAM file. These requirements must be satisfied or the BAM file cannot be properly parsed / interpreted. Typically, this is done by passing the proper arguments to the aligner used upstream of salmon (for which we recommend Bowtie2 if you are aligning to a _de novo_ transcriptome or STAR if you are doing reference-based quantification against a genome assembly and annotation).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/822#issuecomment-1376659692:75,consumption,consumption,75,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/822#issuecomment-1376659692,1,['consumption'],['consumption']
Energy Efficiency,Using the --reduceGCMemory flag fixed it.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/708#issuecomment-923452593:12,reduce,reduceGCMemory,12,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/708#issuecomment-923452593,1,['reduce'],['reduceGCMemory']
Energy Efficiency,"Very interesting @gmarcais. I wonder if/how allocations have an effect here. Are all methods using pre-allocated space to store their captures? Also, is xpressive drunk?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1024188974:103,allocate,allocated,103,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1024188974,1,['allocate'],['allocated']
Energy Efficiency,"We are using Salmon to help allocate multimapped reads in dual RNA-seq data. What this means is we combine a host and pathogen genome (bacterial genome + host transcriptome) and also use a combined annotation file as well.; Basically, we can then find out which reads uniquely map to each gene/transcript from both organisms. . The issue we are having is when using Salmon in alignment-based mode (using STAR), we are observing quite substantial variations in how ambiguous (multimapping) reads are being assigned. We use the same quant command/params and the same input files - and we run the same data twice in different output locations.; The correlations between quant files are generally really good ~ 99.9x (spearman). . However, the number of allocated reads to a small proportion of transcripts varies quite a lot. For example:; ```; ENST00000383869.1 goes from 7699.89 reads to 4871.19 between runs; ENST00000374675.7 goes from 1326.02 reads to 0 between runs; ```. We initially noticed this when examining differentially expressed genes downstream, which were a bit unusual. These two transcripts in particular have a high number of ambiguous counts (generally >1000) when examining the `ambig_info.tsv` file (the number of ambig reads does remain the same though). I tried additional params and runs including:; Accounting for biases: `--seqBias --gcBias --posBias`; Including bootstrap information: `--numBootstraps 100 --bootstrapReproject`. Both params reduced the variation between runs slightly, but not enough to reduce the disparity. We don't see this difference when running in selective alignment mode. We are using `v.1.3.0` and `single end` reads. ```; STAR --runThreadN 30 --runMode genomeGenerate --genomeDir index/ --genomeFastaFiles $fasta --sjdbGTFfile $gff --sjdbGTFfeatureExon exon --sjdbGTFtagExonParentTranscript Parent --sjdbOverhang $sjdbOverhang. STAR --runThreadN 30 --genomeDir . --sjdbGTFfile $gff $readFilesCommand --readFilesIn $reads --outSAMtype BAM Unsorted -",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600:28,allocate,allocate,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600,2,['allocate'],"['allocate', 'allocated']"
Energy Efficiency,"Well, one can certainly use a tool (like gffread or rsem-prepare-reference) to take a genome and a (possibly custom/augmented) GTF to extract a set of target transcripts. Above, it looks like you were only processing between 90 and 100k transcripts. Given the overall size of the overall reference — ~2.4 billion nucleotides — my guess would be that some of these transcripts may be exceedingly long (and perhaps extracted incorrectly from the underlying tool). I should note that an index can be built on large references (which is why we support 64-bit index construction), but it's a very rare use-case as most transcriptomes (even large _de novo_ transcriptomes) rarely cross the 2^31 barrier, and I would expect it to consume quite a bit of memory. The default `quasi` indexer of Salmon is optimized to be very fast for typical sized transcriptomes (usually a few hundred mega-bases) at the cost of using more memory. The alternative `fmd` index can be made more memory efficient, by setting a larger sampling factor, but the resulting mapping will be slower (though still much faster than standard alignment). I would first check to see if the transcripts.fa file contains what you were expecting (i.e. the normal transcriptome + the auxiliary transcripts you were interested in quantifying), and that you actually have close to 2.4Gb of non-redundant transcriptome sequence that you want to quantify. If this is the case, the options are to try and build the quasi-index on a large memory machine (building the index requires more memory than mapping with the constructed index), or using the fmd-index with a large sampling factor. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/39#issuecomment-176802594:975,efficient,efficient,975,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/39#issuecomment-176802594,1,['efficient'],['efficient']
Energy Efficiency,"What's wrong with actually running salmon, monitoring stderr for what you need, and then killing the process?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/189#issuecomment-361717344:43,monitor,monitoring,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/189#issuecomment-361717344,1,['monitor'],['monitoring']
Energy Efficiency,Will a smaller k-mer length reduce alignment accuracy?,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/754:28,reduce,reduce,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/754,1,['reduce'],['reduce']
Energy Efficiency,"Yep that should work too, although a couple of minor things, you might wanna use 10 reads since that's the lower bound. Secondly, those reads should be mapped too, I guess copy the 98 length sequence from the transposons's region. Lastly the UMI, if the UMI sequence overlap w/ already present UMI sequence then it can potentially effect the deduplication of cell having more than 10 counts, you might wanna chose a disjoint UMI sequence *not* in your dataset and reduce the count by 1 in the count matrix since if all newly added UMI are same and get mapped to same gene then it will be deduplicated to 1.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406664115:464,reduce,reduce,464,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406664115,1,['reduce'],['reduce']
Energy Efficiency,"You are right on the spot. ; After trimming, every problem went away:; ""num_processed"": 102482661,; ""num_mapped"": 85812375,; ""num_decoy_fragments"": 760387,; ""num_dovetail_fragments"": 1265734,; ""num_fragments_filtered_vm"": 7722295,; ""num_alignments_below_threshold_for_mapped_fragments_vm"": 293676436,; ""percent_mapped"": 83.7335546937057,. I would really like to have the soft clipping feature though. With salmon being so fast, trimming step basically takes more time than the salmon quantification step. A lot of us are now turning to cloud platforms and are charged by the the computing time. Some other questions unrelated to this topic:; For snRNA-seq like 10X platform, do you recommend just trimming read2?; From what I read out of documentation, decoy enhanced index would only work with --validateMapping. Would Alevin only work with non-decoy index then?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586530740:560,charge,charged,560,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586530740,1,['charge'],['charged']
Energy Efficiency,"You're very welcome! Sorry for the console spam in the first place; I wasn't anticipating usage scenarios with that type of imbalance between producers and consumers. My guess is that the newest version of Salmon will also consume slightly less user-time as well, since now the parsing thread will backoff rather than busy wait when it wants to produce more reads for consumption.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-349406690:368,consumption,consumption,368,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-349406690,1,['consumption'],['consumption']
Energy Efficiency,"_mono_S58_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam.salmon_quant }; Logs will be written to 4010760_5_mono_S58_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam.salmon_quant/logs; [2021-03-05 18:20:21.015] [jointLog] [info] setting maxHashResizeThreads to 10; [2021-03-05 18:20:21.015] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; parseThreads = 5; [2021-03-05 18:20:21.314] [jointLog] [info] numQuantThreads = 5; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""/groups/inah/test_Salmon/4010760_5_mono_S58_L001_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam"", fasta = ""a; ll_transcripts.fa"" . . .done; [2021-03-05 18:20:24.846] [jointLog] [info] replaced 1216 non-ACGT nucleotides with random nucleotides; processed 0 reads in current round[2021-03-05 18:20:25.180] [jointLog] [info] Automatically detected most likely library type as ISR; processed 3000000 reads in current round[2021-03-05 18:20:39.705] [jointLog] [info]; The alignment group queue pool has been exhausted. 7187672 extra fragments were allocated on the heap to saturate the pool. No new fragments will be allocated; processed 12000000 reads in current round; processed 21000000 reads in current round; processed 29000000 reads in current round; processed 38000000 reads in current round; processed 47000000 reads in current round; processed 56000000 reads in current round; processed 57000000 reads in current round/var/spool/slurmd/job599153/slurm_script: line 102: 17542 Segmentation fault singularity exec --bind $TMPDIR:/tmp,/groups:/groups,/work:/work /groups/arcsingularity/salmon_1.4.0.sif salmon quant -t all_transcripts.fa -l A -p 10 -a $in_FILES -o $outdir.salmon_quant. Salmon does not quantify transcript expression. I would appreciate any suggestions.; Thanks, Ina",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/638:2545,allocate,allocated,2545,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/638,2,['allocate'],['allocated']
Energy Efficiency,"```. Secondly, I created a new transcriptome-only salmon index (`singularity run -B /data $SALMON_SIMG salmon index -t genome.transcripts.fa -i salmon_index -k 31`), then ran `salmon quant` again (as above) but using the new transcriptome-only index. Note: 'genome.transcripts.fa' is the transcripts file created during the `nf-core/rnaseq` pipeline. Again, this analysis completed properly in a reasonable time. Seems like there is something very wrong with the 'gentrome.fa' file that's being created by `nf-core/rnaseq`! It's just so odd that _some_ samples would work and others wouldn't. 2. It's definitely worth noting that I originally opted against using `star_salmon` with the following command:. ```; nextflow run nf-core/rnaseq --max_memory 55.GB --fasta /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz --gtf /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.106.gtf.gz --skip_alignment --pseudo_aligner salmon --seq_center 'Ramaciotti Centre for Genomics' --input samplesheet.csv --outdir nf-core_results --save_merged_fastq true --skip_markduplicates true --extra_salmon_quant_args '--seqBias --gcBias --posBias' -profile singularity; ```. I'll re-run (a) using the refgenie salmon index specified; (b) with the `star_salmon` pathway to see if the decoy-aware index created that way is appropriate. 3. Other; I've installed `piscem` and can give it a go, although it does seem more like a salmon index issue with `nf-core/rnaseq` from the debugging above. Do you agree? If so, I'll raise an issue there. Considering this, would it still be useful to have access to the reads? I've got the green light to share them if need be. If so, what's a good contact address to share a OneDrive link?. Thanks!; Charles. p.s. something else odd that I can dig into further later if need be is that the singularity version of salmon created an index in about 5 minutes, yet the conda version has been creating the index for nearly 20 minutes so far with no change...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948:2721,green,green,2721,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948,1,['green'],['green']
Energy Efficiency,"and poly-T was used to select mRNAs during the library construction...; 3. Not using pre-mature transcripts so reads mapping to introns are discarded: I am not sure if this is a valid point since we usually quantify mature mRNAs, not pre-mature ones.; 4. Library type: my library was constructed in a stranded way. The program detected my libtype as ISR:; ```; {; ""read_files"": ""[ DS_1_HW_FM_1P.fq.gz, DS_1_HW_FM_2P.fq.gz]"",; ""expected_format"": ""ISR"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 18651686,; ""num_assigned_fragments"": 18651686,; ""num_frags_with_concordant_consistent_mappings"": 17799536,; ""num_frags_with_inconsistent_or_orphan_mappings"": 864409,; ""strand_mapping_bias"": 0.0001987858838992702,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 3539,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 17799536,; ""SF"": 419781,; ""SR"": 441089,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```; When I change the libtype to a broader category, such as IU, the mapping rates slightly increased from ~55% to 65%, also I got more counts in each transcript, but this introduced higher strand mapping bias (Appeared as a warning message). ; 5. many short reads: No... in my case, the majority of the reads are ~150bp. And I used k=31 (default).; 6. Read trimming: I trimmed the adaptors and low-quality bases from the ends. One thing I noticed in my FastQC report is that I have warnings for 'Per Base Sequence Content'. I can see a fluctuation of nucleotides in around the first 12bp of each run due to a biased selection of random primers. This is so common in RNA-seq data so I did not trim the first several bases...Not sure if this can cause the low mapping rate.; One of my fastQC reports:. [DS_1_HW_FM_1P_fastqc.html.zip](https://github.com/COMBINE-lab/salmon/files/4730665/DS_1_HW_FM_1P_fastqc.html.zip). So...Is there a way I can increase the mapping rates? Or do I need to? My trimmed reads are all of very high quality so I do expect a mapping rate of >70%. I would appreciate it if this could be clarified.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/533:2777,adapt,adaptors,2777,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/533,1,['adapt'],['adaptors']
Energy Efficiency,"any problems.; It created the ""twopaco_tmp"" directory about 5 minutes after starting and created a ""bifurcations.bin"" inside this directory. However, 4 hours have passed, and neither the file nor the directory have any new modifications (and the file is still a staggering 0 bytes large). I also read that this will take quite a lot of memory, but there should be some TB left on the hard drive. I created a 21 GiB swap partition which works fine (I've already seen it at 60%, so it is active and recognized and everything despite being on another physical hard drive ; (the 1. hard drive has a dual installation of win 10 and ubuntu 20.4 and the swap from the installation (2 GiB, because I thought that would be enough at the time and tried to save some space ^^) and the 2. hard drive has a swap partition of 20 GiB (with the highest priority of all swaps), which results in a total of 21.4 GiB in the System Monitor Resources Tab). . The system is still responding, and the System Monitor seems to be working fine (salmon is an active process using 12% CPU, 6.9 GiB memory, 13.5 GiB Disk read total, N/A Disk write total, Disk read 1.2 MiB/s (sometimes 1.1 or 1.3), Disk write N/A, Priority normal); and the Resources Tab shows that ; * out of 8 available CPUs, one is working at 100% (the others 5% at max) and ; * Memory 99.3% (which is only 7.7 GiB); * swap 9.5% (which is only 2 GiB of 21.4 GiB available). So here are (finally) my questions:. 1. How can I get Salmon to use the swap (I set swappiness to 100, and it still doesn't seem to care about the swap); 2. Is it normal that there is nothing ""visible"" happening during Round0?; 3. How can I see or check if it is still working (and it might be worthwhile to wait longer)? ; 4. Is what I'm doing correct to create an index file for running Salmon on human RNA-seq data that is supposed to ""end up"" in sleuth?; 5. Is there another way to create an index file that I can use as an index file to create input data for sleuth from RNA-seq da",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/643:3845,Monitor,Monitor,3845,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/643,1,['Monitor'],['Monitor']
Energy Efficiency,"d references; [2023-03-15 20:12:12.984] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers; [2023-03-15 20:12:29.921] [puff::index::jointLog] [info] ntHll estimated 1872745301 distinct k-mers, setting filter size to 2^35; Threads = 2; Vertex length = 31; Hash functions = 5; Filter size = 34359738368; Capacity = 2; Files:; illerney.index/ref_k31_fixed.fa; --------------------------------------------------------------------------------; Round 0, 0:34359738368; Pass Filling Filtering; 1 297 695; 2 55 3; True junctions count = 5239944; False junctions count = 16749742; Hash table size = 21989686; Candidate marks count = 29916168; --------------------------------------------------------------------------------; Reallocating bifurcations time: 2; True marks count: 20234145; Edges construction time: 59; --------------------------------------------------------------------------------; Distinct junctions = 5239944. TwoPaCo::buildGraphMain:: allocated with scalable_malloc; freeing.; TwoPaCo::buildGraphMain:: Calling scalable_allocation_command(TBBMALLOC_CLEAN_ALL_BUFFERS, 0);; allowedIn: 139; Max Junction ID: 12729038; seen.size():101832313 kmerInfo.size():12729039; approximateContigTotalLength: 1607258836; counters for complex kmers:; (prec>1 & succ>1)=133010 | (succ>1 & isStart)=7442 | (prec>1 & isEnd)=7516 | (isStart & isEnd)=2442; contig count: 11353512 element count: 2210067304 complex nodes: 150410; # of ones in rank vector: 11353511; [2023-03-15 20:35:10.185] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.; [2023-03-15 20:35:10.185] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory illerney.index; size = 2210067304; -----------------------------------------; | Loading contigs | Time = 451.61 ms; -----------------------------------------; size = 2210067304; -----------------------------------------; | Loading contig boundaries | Time = 180.73 ms; -----------",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/837:2516,allocate,allocated,2516,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/837,1,['allocate'],['allocated']
Energy Efficiency,"e *full* decoy index is substantially larger than the index on just the transcriptome (after all, it is indexing the entire human genome in addition to the transcriptome). One thing you might try to test this hypothesis, other than requesting to build on a node with more RAM, is to compute a hash (e.g. md5 or sha256 sum) on all of the files in the index, and also record their sizes. Then we can build the index on the same version of the files on our end and compare. Second — and perhaps more importantly for your end goal — the main purpose of the decoy-aware index is to improve specificity rather than sensitivity. That is, the decoys are designed to help avoid _spurious_ mapping of reads to an annotated transcript when a better explanation for the read exists elsewhere in the genome. However, the reads that are mapped to decoys are not otherwise used for quantification. Thus, using the decoy aware transcriptome index is unlikely to improve your mapping rate. I agree that your mapping rate does seem rather low. There are a few potential culprits here, and some diagnostics we can look at to see what might be going wrong. First, you can take a look at the file `aux_info/meta_info.json` in the salmon quantification directories to get a few more details about why reads were not mapped. If you share one of those files here I can describe the relevant fields. Also, I have two more rather common things to consider that might affect the mapping rate. One is to add the sequence for the ribosomal RNAs to your transcriptome before indexing and then quantifying. If your mapping rate increases considerably, this is evidence of rather inefficient depletion prior to sequencing. The other thing to consider is to do basic adapter / quality trimming on the reads to see if that affects your mapping rate at all. I hope these two different responses are useful, and I'll keep this issue open so feel free to reply here with any further questions or discoveries you make regarding the above.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850:2071,adapt,adapter,2071,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850,1,['adapt'],['adapter']
Energy Efficiency,"e I answer your question and layout my logic, I want to mention that I am **_not_** suggesting fastp is not doing its job, **_neither am I stating that fastp is working incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:997,adapt,adapter-trimming,997,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['adapt'],['adapter-trimming']
Energy Efficiency,"e correct command line `salmon quant` options for Lexogen/QuantSeq _(this will be referred to as QS in the rest of the message(s))_ ?. `salmon quant --threads 16 --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximpo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1016,Adapt,Adapter,1016,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapt'],['Adapter']
Energy Efficiency,"ed. There is a way to modify this behavior, but since stranded library prep is imperfect, the default behavior is the most reasonable for most situations. The reason that you'll see consistency in most cases, regardless of the library type, is as follows. Imagine that I have a read that maps to transcript 1 in the forward orientation and transcript 2 in the reverse orientation. Further, imagine I have a stranded library, and I expect all reads to map in the reverse orientation. If the mapping to transcript 1 is ""spurious"", there are unlikely to be many othe reads mapping to that transcript in this manner, while we would expect other reads to map to transcript 2 in the prescribed manner. Since Salmon considers all of the reads in its probabilistic model when deciding how each read should be allocated, the fact that many reads map to transcript 2 will increase its abundance and, likewise, increase the probability that we assign this read to transcript 2 --- that is, the other mappings will help us make the right choice, regardless of the fact that we neglected to assign a stranded library type. That said, there are situations where the library type makes a difference. This is most often for a few transcripts that are very sequence similar (e.g. Paralogs that happen to be on opposite strands). In this case, most of the reads that map to one transcript will map to the other as well. In this case, the much larger conditional probability of agreeing with the prescribed library type will cause these reads to be allocated to the transcript to which they map in the expected orientation. However, the fraction of such transcripts is usually a small proportion of all expressed transcripts in an experiment, which is why, even if you do have a stranded library and some strand-specific expression, you'd expect the overall concordance to be very high between runs with different provided library types. Let me know if this answers your question, and if you have any others. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-238090033:2208,allocate,allocated,2208,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-238090033,1,['allocate'],['allocated']
Energy Efficiency,"es. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossible to do. Our resident experts suspect there's a race condition occurring at the tail end of the job and that all of that extra memory is being allocated before the scheduler can kill it for exceeding the limit. Whatever the case, though, this throws into question some of those numbers that I've been grabbing from the accounting logs --- it's either being misreported, or the memory gobbling is happening so rapidly that it may not, in fact, be being properly recorded. I tested the index anyway. It *appears* to be working just fine. Nothing faulted or crashed when I attempted to quantify some reads against it. [index-qacct-17mer-16gigs.log](https://github.com/COMBINE-lab/salmon/files/4247214/index-qacct-17mer-16gigs.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:2225,allocate,allocated,2225,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,2,"['allocate', 'schedul']","['allocated', 'scheduler']"
Energy Efficiency,"h_sd: 25.001769513739427. Sample: Gam_3h_RT_rep2_RL5404_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_3h_RT_rep3_RL5405_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_37C_rep1_RL5390_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_37C_rep2_RL5391_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_37C_rep3_RL5410_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_4C_rep1_RL5392_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_4C_rep2_RL5393_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_4C_rep3_RL5411_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_RT_rep1_RL5389_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_RT_rep2_RL5408_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_RT_rep3_RL5409_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427```. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; v1.10.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Binary; * Which reference (e.g. transcriptome) was used?; Moss (Physco) v6.1 that I had generated ; * Which read files were used?; ; * Which which program options were used?; `-l A -p 16 --validateMappings --numBootstraps 100 --seqBias --gcBias`. **Expected behavior**; A clear and concise description of what you expected to happen. **Desktop (please complete the following information):**; - OS: Linux server: Rocky Linux release 8.5 (Green Obsidian); - Version Rocky Linux release 8.5 (Green Obsidian)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/948:3524,Green,Green,3524,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/948,2,['Green'],['Green']
Energy Efficiency,"hello! have you by any chance figured it out? I have quite similiar problem. . I am running salmon v.1.1.0 on my ubuntu machine with 128GB of RAM. I set the limit for vitrual memory at ~75GB to not overload the system:. ```bash; ○ → ulimit -a; core file size (blocks, -c) 0; data seg size (kbytes, -d) unlimited; scheduling priority (-e) 0; file size (blocks, -f) unlimited; pending signals (-i) 514510; max locked memory (kbytes, -l) 65536; max memory size (kbytes, -m) unlimited; open files (-n) 1024; pipe size (512 bytes, -p) 8; POSIX message queues (bytes, -q) 819200; real-time priority (-r) 0; stack size (kbytes, -s) 8192; cpu time (seconds, -t) unlimited; max user processes (-u) 514510; virtual memory (kbytes, -v) 75331648; file locks (-x) unlimited; ```. I am building the index with the following command:. ```bash; salmon index \; -t /mnt/rescomp/ref/hg38/gentrome.fa.gz \; -i /mnt/rescomp/ref/hg38/salmon_index -k 31 \; --decoys /mnt/rescomp/ref/hg38/decoys.txt \; --threads 16 \; --gencode |& tee logs/salmon_index.log; ```. gentrome is created based on the gencode transcriptome (v33) and genome primary algnment sequence (GRCh38.p13). [salmon_index.log](https://github.com/COMBINE-lab/salmon/files/4392725/salmon_index.log). The output directory:; ```; ○ → ll /mnt/rescomp/ref/hg38/salmon_index; total 7.9G; drwxr-sr-x 1 37304 723 4.0K Mar 27 01:36 ./; drwxr-sr-x 1 37304 723 4.0K Mar 26 22:13 ../; -rw-r--r-- 1 37304 723 888K Mar 27 00:32 complete_ref_lens.bin; -rw-r--r-- 1 37304 723 31K Mar 27 00:27 duplicate_clusters.tsv; -rw-r--r-- 1 37304 723 674M Mar 27 01:46 path.bin; -rw-r--r-- 1 37304 723 55 Mar 27 01:46 pre_indexing.log; -rw-r--r-- 1 37304 723 40K Mar 27 01:46 ref_indexing.log; -rw-r--r-- 1 37304 723 3.3G Mar 27 00:32 ref_k31_fixed.fa; -rw-r--r-- 1 37304 723 703 Mar 27 00:32 ref_sigs.json; -rw-r--r-- 1 37304 723 4.1G Mar 27 01:36 tmp_dbg.bin; ```; I know for a fact that the memory usage did not go over 16GB. Any hints how to proceed?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-604919589:313,schedul,scheduling,313,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-604919589,1,['schedul'],['scheduling']
Energy Efficiency,"info] setting maxHashResizeThreads to 8; [2023-01-29 16:02:11.267] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:single end, relative orientation:none, strandedness:unstranded }; [2023-01-29 16:02:11.308] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam"", fasta = ""/rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas"" . . .done. processed 0 reads in current round[2023-01-29 16:02:12.216] [jointLog] [info] replaced 186,207 non-ACGT nucleotides with random nucleotides; [2023-01-29 16:02:12.668] [jointLog] [info] Automatically detected most likely library type as U. processed 2000000 reads in current round[2023-01-29 16:02:13.116] [jointLog] [info] . The alignment group queue pool has been exhausted. 1842 extra fragments were allocated on the heap to saturate the pool. No new fragments will be allocated. processed 13423395 reads in current round; killing thread 3 . . . done. Freeing memory used by read queue . . . 00000; Joined parsing thread . . . ""leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam"" ; Closed all files . . . ; Emptied frag queue. . . ; Emptied Alignment Group Pool. . ; Emptied Alignment Group Queue. . . done; [2023-01-29 16:02:59.265] [jointLog] [info] . Completed first pass through the alignment file.; Total # of mapped reads : 13423395; # of uniquely mapped reads : 13423394; # ambiguously mapped reads : 1. [2023-01-29 16:02:59.271] [jointLog] [info] Computed 169 rich equivalence classes for further processing; [2023-01-29 16:02:59.272] [jointLog] [info] Counted 13,423,395 total reads in the equivalence classes ; [2023-01-29 16:02:59.272] [jointLog] [info] starting optimizer; [2023-01-29 16:02:59.274] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2023-01-29 16:02:59.274] [jointL",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/825:2825,allocate,allocated,2825,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/825,1,['allocate'],['allocated']
Energy Efficiency,"info] setting maxHashResizeThreads to 8; [2023-01-29 16:06:31.513] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:single end, relative orientation:none, strandedness:unstranded }; [2023-01-29 16:06:31.580] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""apex_infe_t1_rep1_S29_R1_001Aligned.out.bam"", fasta = ""/rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas"" . . .done. processed 0 reads in current round[2023-01-29 16:06:34.583] [jointLog] [info] replaced 186,207 non-ACGT nucleotides with random nucleotides; processed 2000000 reads in current round[2023-01-29 16:06:35.068] [jointLog] [info] Automatically detected most likely library type as U. [2023-01-29 16:06:35.443] [jointLog] [info] . The alignment group queue pool has been exhausted. 1955 extra fragments were allocated on the heap to saturate the pool. No new fragments will be allocated. processed 26000000 reads in current roundSegmentation fault (core dumped); ```. Output for failure case - four files. ```; salmon quant -t /rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas -l A -a leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam leaf_mock_t6_rep1_S40_R1_001Aligned.out.bam leaf_mock_t5_rep3_S63_R1_001Aligned.out.bam leaf_mock_t5_rep1_S39_R1_001Aligned.out.bam -p 8 -o ../SalmonQuantFiles; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.9.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { /rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas }; # [ libType ] => { A }; # [ alignments ] => { leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam leaf_mock_t6_rep1_S40_R1_001Aligned.out.bam leaf_mock_t5_rep3_S63_R1_001Aligned.out.bam leaf_mock_t5_rep1_S39_R1_001Aligned.out.bam }; # [ threads ] => { 8 }; # [ output ] => {",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/825:7798,allocate,allocated,7798,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/825,1,['allocate'],['allocated']
Energy Efficiency,"ing incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondri",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1161,adapt,adapter,1161,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['adapt'],['adapter']
Energy Efficiency,"inly does seem very low. To answer your specific questions first:; 1) I'm not sure --- let's try tor find out; 2) I don't think so (if they are part of your index, they should be aligned against); 3) If there are many transcripts / targets you expect to be sequenced but which aren't present in this set, that can affect the mapping rate, but not likely to take it down to 6%. Here are the things I'd investigate --- roughly in order: . 1) In addition to the fraction of reads STAR mapped (which you report above), what fraction of the reads are assigned to features by featureCounts? In some cases, when there is a failure of rRNA depletion of polyA selection, you can end up with an experiment where most of the sequenced RNA comes from rRNA not present in the reference transcriptome. In this case, STAR will be able to align the reads to the genome, but you won't see these reads mapping to annotated features (and you also won't see them showing up in your transcript level quantifications). So, it may be worth to take a look at the count of reads assigned to the feature set of genes by featureCounts. 2) Above, it looks like a considerable number of fragments were discarded due to no alignment reaching the required alignment score (`11,448,458` fragments discarded because of this). Have you tried to adapter / quality trim the data? Does this have any effect on the mapping rate?. 3) If the above don't reveal any clues, I'd be happy to try to take a look at the data if you can share it. I'd be quite surprised if STAR is aligning a lot of reads *to transcriptome features* that are being missed by salmon. Nonetheless, if you pass the proper flags to STAR (including `--quantMode TranscriptomeSAM`), then you can use the SAM/BAM file generated by STAR to perform quantification with salmon (i.e. use STAR's alignments to do _transcript-level_ quantification). I'd be happy to help dig further on any of these, so please feel free to reach out if you find anything interesting. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-846251054:1381,adapt,adapter,1381,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-846251054,1,['adapt'],['adapter']
Energy Efficiency,"input gentrome file, replace ambiguous characters (e.g. `N`) with pseudo-random nucleotides. It will also report any transcripts smaller than the chosen k-mer size, and it will detect and remove (unless `--keepDuplicates` is passed) any identical / duplicate sequences. After all of this, it will begin constructing the index in earnest. This is done by running a modified version of [TwoPaCo](https://github.com/medvedevgroup/TwoPaCo) to construct the compacted colored de Bruijn graph on the gentrome, which is then indexed using our [pufferfish index](https://github.com/COMBINE-lab/pufferfish). The TwoPaCo algorithm that generates the compacted colored de Bruijn graph from the input sequence is based on a very elegant algorithm that couples a Bloom filter with an exact hash table, and makes two (or more) passes over the input to identify all of the junctions in the reference (which directly implies all unitigs). To make the algorithm work efficiently, one needs to have an estimate for the number of distinct k-mers that will be encountered in the reference sequence. If the estimate is too big, one wastes memory. If the estimate is too small, the Bloom filter is not big enough, it doesn't filter efficiently, and the algorithm ends up putting way too much data in the exact hash table. In order to determine how to set the Bloom filter size appropriately, we take the following approach. If the Bloom filter size isn't provided directly (_note_: this is _not_ the same as the k-mer size, this is an estimate of the total number of distinct k-mers in the entire input data), then we make a call to a function defined in the [ntCard](https://github.com/bcgsc/ntCard) library. This is a program designed specifically for cardinality estimation of k-mers in sequencing data. Based on the estimated number of distinct k-mers, we use the standard equations (derived from the theory behind Bloom filters) to set the Bloom filter to be of the smallest possible size that still achieves a relati",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186:1318,efficient,efficiently,1318,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186,1,['efficient'],['efficiently']
Energy Efficiency,"ion](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30381-3.pdf)). This is sort of akin to what you are suggesting, and post-processes salmon output by looking for anomalous coverage profiles. It can both flag ""suspicious"" transcripts, and can also sometimes move reads around to mitigate anomalous coverage. Another tool / metric you might consider is the junction coverage compatibility (paper [here](https://www.life-science-alliance.org/content/2/1/e201800175)). While both of these approaches get at some of the core intuitions you raise in your response, they are both rather ""heavyweight"", and neither, of course, is built into salmon. So, I **completely agree** that a lightweight version of something like SAD would be great to have built _into_ salmon. Specifically, it makes a lot of sense to have some component of the likelihood account for the coverage profile of transcripts. While I don't know of any widely-used and actively maintained quantification tools that do this, the idea for this was proposed in the [iReckon paper](https://www.ncbi.nlm.nih.gov/pubmed/23204306) and a coverage-based heuristic was introduced. However, the coverage was not directly incorporated into the likelihood. Rather, a variant of the normal likelihood function was used and then coverage was used to select between different potential solutions that were otherwise of similar likelihood. Given issues like the one you see here, and the ones that we observed in the JCC paper and that Cong and Carl observed in the SAD paper, it seems clear that it would be a big win for a quantification tool to include some sort of built-in lightweight model for things like this. The big questions are (1) how do you fold this type of intuition formally into the probabilistic model and (2) is it possible to incorporate this information efficiently? I'm _very_ interested in pursuing something like this if it can be made to work efficiently. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:4212,efficient,efficiently,4212,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['efficient'],['efficiently']
Energy Efficiency,"isabling range-factorized equivalence classes. ; [2021-05-19 18:46:25.303] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-05-19 18:46:25.303] [jointLog] [info] parsing read library format; [2021-05-19 18:46:25.303] [jointLog] [info] There is 1 library.; [2021-05-19 18:46:25.429] [jointLog] [info] Loading pufferfish index; [2021-05-19 18:46:25.429] [jointLog] [info] Loading dense pufferfish index.; [2021-05-19 18:46:27.087] [jointLog] [info] done; [2021-05-19 18:46:27.087] [jointLog] [info] Index contained 141,069 targets; [2021-05-19 18:46:32.618] [jointLog] [info] Number of decoys : 0; [2021-05-19 18:46:33.428] [jointLog] [info] Automatically detected most likely library type as IU. [2021-05-19 18:49:27.444] [jointLog] [error] . [2021-05-19 18:49:27.506] [jointLog] [error] Processing reads : Error reading from the FASTA/Q stream. Minimum return code for left and right read was (-2). Make sure the file is valid. ```; For rabbitQC's log; ```; Detecting adapter sequence for read1...; CCCAGCCATAACACAGTATCAAACTCCACTATTTGTCTGATCCGTACTTATTACAGCCGT. Detecting adapter sequence for read2...; CCAACTTGGTCTACAAGACGCCACATCCCCTATTATAGAAGAGCTAATAAATTTCCATGA. Read1 before filtering:; total reads: 44178187; total bases: 2140649565; Q20 bases: 1899503304(88.7349%); Q30 bases: 1839878933(85.9496%). Read1 after filtering:; total reads: 34172299; total bases: 1775386278; Q20 bases: 1762557969(99.2774%); Q30 bases: 1737891531(97.8881%). Read2 before filtering:; total reads: 44178187; total bases: 2233386484; Q20 bases: 2180294210(97.6228%); Q30 bases: 2141791820(95.8988%). Read2 aftering filtering:; total reads: 34172299; total bases: 1749324083; Q20 bases: 1731172028(98.9623%); Q30 bases: 1700577336(97.2134%). Filtering result:; reads passed filter: 68344598; reads failed due to low quality: 11353966; reads failed due to too many N: 40048; reads failed due to too short: 8617762; reads with adapter trimmed: 382600; bases trimmed due to adapters: 6",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/660:2507,adapt,adapter,2507,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/660,1,['adapt'],['adapter']
Energy Efficiency,"l have neighboring genomic DNA). I wanted to see how this ratio changes between samples (for example, in a snoRNA processing-defective mutant strain), but quickly realized this is not easily done in salmon or any other quant tools because the processed transcript is entirely a subset of the sequence of the pre-processed transcript. The only way to accurately quantify it is to use the coverage information, which as you agreed is not really taken into account downstream. If Salmon could incorporate the coverage information to solve this class of problem, that would indeed be a **huge win**. I think the ncRNA example would be both a great biologically-interesting motivating problem, as well as a good technical benchmark for implementing any new methods. It could even be used as a secondary RNA velocity measure in scRNA seq data, provided the method used can detect these (non-polyadenylated) transcripts. > The big questions are (1) how do you fold this type of intuition formally into the probabilistic model and (2) is it possible to incorporate this information efficiently?. This is definitely your domain of expertise (and I know it's a rhetorical question but I'd love to throw some ideas out here)... I can think of a few mostly heuristical approaches.... . 1) when apportioning reads to transcripts, after the mapping phase, incorporate a notion of ""evenness"" into the EM step... reads that decrease the variance in coverage are favored over reads that increase the variance (so, define read depth per 10 bp window or something and calculate the variance across all windows for the transcript, then try to assign reads such that they minimize read depth variance per isoform). The problem here is actual coverage biases may then masquerade as alternative transcript isoforms... 2) Use the information from the unique sequences between the transcripts... the read depth over unique regions updates the prior on the overall transcript abundance, and the otherwise non-unique reads get ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851:2613,efficient,efficiently,2613,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851,1,['efficient'],['efficiently']
Energy Efficiency,"mber of splices: GC/AG |	39101; Number of splices: AT/AC |	13983; Number of splices: Non-canonical |	478779; Mismatch rate per base, % |	0.56%; Deletion rate per base |	0.03%; Deletion average length |	4.89; Insertion rate per base |	0.03%; Insertion average length |	4.88; MULTI-MAPPING READS:; Number of reads mapped to multiple loci |	1029261; % of reads mapped to multiple loci |	1.20%; Number of reads mapped to too many loci |	565; % of reads mapped to too many loci |	0.00%; UNMAPPED READS:; Number of reads unmapped: too many mismatches |	0; % of reads unmapped: too many mismatches |	0.00%; Number of reads unmapped: too short |	47533174; % of reads unmapped: too short |	55.56%; Number of reads unmapped: other |	4006; % of reads unmapped: other |	0.00%; CHIMERIC READS:; Number of chimeric reads |	0; % of chimeric reads |	0.00%. ```. I filtered it by samtools -f 2 -F 3840 . and Salmon gave me this result which is still very weak: 24323638 counts. So I decided to reduce the parameters as indicated in this link: https://github.com/alexdobin/STAR/issues/169; Because I trimmed my sequence and some can have a size between 100pb -150pb. ` ""STAR --runThreadN {threads} --runMode alignReads --genomeDir {input.ref} --readFilesIn {input.fq1} {input.fq2} --readFilesCommand zcat --outSAMtype BAM Unsorted SortedByCoordinate --outFilterScoreMinOverLread 0 --outFilterMatchNminOverLread 0 --quantMode TranscriptomeSAM GeneCounts --outFileNamePrefix {output} --outStd Log {log} ""`. I got this final.out:; ```; Started job on |	Jul 05 14:25:19; Started mapping on |	Jul 05 14:25:23; Finished on |	Jul 05 16:37:44; Mapping speed, Million of reads per hour |	38.78. Number of input reads |	85547657; Average input read length |	298; UNIQUE READS:; Uniquely mapped reads number |	70090369; Uniquely mapped reads % |	81.93%; Average mapped length |	191.51; Number of splices: Total |	1068826; Number of splices: Annotated (sjdb) |	0; Number of splices: GT/AG |	470490; Number of splices: GC/AG |	43525",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664:1867,reduce,reduce,1867,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664,1,['reduce'],['reduce']
Energy Efficiency,"mming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1324,adapt,adapters,1324,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapt'],['adapters']
Energy Efficiency,"ng assigned. We use the same quant command/params and the same input files - and we run the same data twice in different output locations.; The correlations between quant files are generally really good ~ 99.9x (spearman). . However, the number of allocated reads to a small proportion of transcripts varies quite a lot. For example:; ```; ENST00000383869.1 goes from 7699.89 reads to 4871.19 between runs; ENST00000374675.7 goes from 1326.02 reads to 0 between runs; ```. We initially noticed this when examining differentially expressed genes downstream, which were a bit unusual. These two transcripts in particular have a high number of ambiguous counts (generally >1000) when examining the `ambig_info.tsv` file (the number of ambig reads does remain the same though). I tried additional params and runs including:; Accounting for biases: `--seqBias --gcBias --posBias`; Including bootstrap information: `--numBootstraps 100 --bootstrapReproject`. Both params reduced the variation between runs slightly, but not enough to reduce the disparity. We don't see this difference when running in selective alignment mode. We are using `v.1.3.0` and `single end` reads. ```; STAR --runThreadN 30 --runMode genomeGenerate --genomeDir index/ --genomeFastaFiles $fasta --sjdbGTFfile $gff --sjdbGTFfeatureExon exon --sjdbGTFtagExonParentTranscript Parent --sjdbOverhang $sjdbOverhang. STAR --runThreadN 30 --genomeDir . --sjdbGTFfile $gff $readFilesCommand --readFilesIn $reads --outSAMtype BAM Unsorted --outSAMunmapped ""Within"" --outSAMattributes ""Standard"" --outFileNamePrefix $sample_name/$sample_name --sjdbGTFfeatureExon quant --sjdbGTFtagExonParentTranscript parent --quantMode TranscriptomeSAM --quantTranscriptomeBan ""Singleend"" --outFilterMultimapNmax 999 --outFilterType ""BySJout"" --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --outFilterMismatchNmax 999 --outFilterMismatchNoverReadLmax 1 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --winAnchorMultimapNmax 999; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600:1467,reduce,reduced,1467,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600,2,['reduce'],"['reduce', 'reduced']"
Energy Efficiency,"nt-697125235) in other mapping issue reports, it's possible that there could be multiple fragments in those numbers that contribute to a single read, meaning the unaccounted number is probably higher:. > The number you are looking at is the number of discarded mappings, not the number of discarded fragments. The difference is that every fragment can have many potential mappings. The number you are looking at is the total number of attempted alignments that failed to achieve the threshold score. Luckily, salmon reports both numbers. The number of fragments for which all alignments failed to reach the score threshold is 4,196,417; given in aux_info.json by ""num_fragments_filtered_vm"": 4196417. One point to note is that these are all fragments for which mapping is attempted (they had at least one k-mer match the reference), but no alignment was valid up to the threshold. You could try running the quantification again with --softclip to allow softclipping of the reads and see if any considerable fraction of these 4196417 failed to align because they overhang the annotated transcripts or contain adapters etc. Nonetheless, even if all of these mapped, the rate would still be ~72%. The remainder of the reads didn't even have a matching k-mer in common with the reference transcriptome, which means they are exceedingly unlikely to have come from the transcripts that were indexed. Further explanation of what these metadata numbers mean would be very helpful to me. Also useful would be a statistic (or more than one statistic) that fully categorises the read alignments or non-alignments. **Desktop (please complete the following information):**; - OS: Debian; - `uname-a`: Linux musculus 6.7.9-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.7.9-2 (2024-03-13) x86_64 GNU/Linux; - `lsb_release -a`; ```; No LSB modules are available.; Distributor ID: Debian; Description: Debian GNU/Linux trixie/sid; Release: n/a; Codename: trixie; ```. **Additional context**. I'm not really after an explanatio",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/925:8741,adapt,adapters,8741,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/925,1,['adapt'],['adapters']
Energy Efficiency,"oduce**; First, I put the UMI in front of the barcode.; `zcat R2.fastq.gz | paste - - - - | awk '{print $1"" ""$2""\n""substr($3,9,8)substr($3,1,8)substr($3,17)""\n""$4""\n""$5}' | pigz -p8 > R2_Alevin.fq.gz`. then, I run Alevin with:; `salmon alevin -lA -i ref_genome/index/ --barcodeLength 8 --umiLength 8 --end 5 -1 fq/R2_Alevin.fq.gz -2 fq/R1.fastq.gz -p 8 --tgMap ref_genome/gencode.vM20.tx2gene.tsv -o alevin_out --dumpUmiGraph --dumpFeatures --dumpCsvCounts --whitelist BC.whitelist`. This seems to work: the library is 47M and the _filtered_cb_frequency.txt_ contains 43M assigned barcodes in total. The _MappedUmi.txt_ contains 18.5M UMIs, fitting perfectly with the reported alignment rate of ~40% (which is relatively low, but OK for this library). Also if I use the `--dumpfq` option, the barcodes and UMIs are nicely attached to the sequencing reads. Strangely, if I sum the entries in the CSV or binary quant matrix, I get ~3.75M reads. ; ; I was able to run the 10x PBMC4k example and there, the sum of the count matrix entries indeed fitted the reported UMI counts and mapping rate. . Specifically, please provide at least the following information:. * Which version of salmon was used?; salmon 0.13.1. * How was salmon installed (compiled, downloaded executable, through bioconda)?; downloaded executable and bioconda give the same result. * Which reference (e.g. transcriptome) was used?; mouse gencode vM20 (mm10). * Which read files were used?; adapted celseq2 protocol. * Which program options were used?; See above. **Expected behavior**; I expected a total of 18.5M counts in the quant matrix, where the sums per barcode fit those reported in the _MappedUmi.txt_ Is my assumption that the quant matrix should only contain integers correct?. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; Ubuntu 18.04.1 LTS. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361:1917,adapt,adapted,1917,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361,1,['adapt'],['adapted']
Energy Efficiency,"omatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, [@vals has an excellent series of blog posts on investigating and addressing low mapping rates](http://www.nxn.se/valent/2017/9/18/low-mapping-rate-5-human-dna-contamination); - bbmap Command ([based of this biostars post](https://www.biostars.org/p/143019/#210890)):; `bbmap.sh in=read_1.fq.gz ref=rRNA_Chlor_Mito.fa maxindel=1 minid=0.95 outu=clean_read_1.fq.gz nodisk`; - Strategy:; `use the rRNA+Mito+Chloroplast file and map the reads using bbmap, then collect the unmapped reads (clean_read_1.fq.gz) for my downstream analysis`. 2. **_STEP 2 - run bbduk.sh on the outu files from bbmap step -- the outu stands for output unmapped - as stated in the logic above, anything that is unmapped to the rRNA_Chlor_Mito.fa is a clean read for downstream analysis_**. I use bbduk with adapter trimming and quality trimming in same command line - also, the adapters.fa file that ships with BBTools can be used in all runs. Hope that helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:3423,adapt,adapter,3423,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['adapt'],"['adapter', 'adapters']"
Energy Efficiency,"path/to/logs/%x_%j.out; #SBATCH --ntasks=6; #SBATCH --time=02:00:00; #SBATCH --cpus-per-task=2; #SBATCH --mem-per-cpu=30G; module load parallel # parallel/20150822-GCC-4.9.2; module load Anaconda3/2022.05; conda activate Salmon. parallel --jobs 6 --header : --colsep ',' \; 'salmon quant -I /path/to/index/folder/ \; -l A\; -1 /path/to/""{fastq_1}"" \; -2 /path/to/""{fastq_2}""\; --writeUnmappedNames \; --validateMappings \; --recoverOrphans\; --gcBias \; --seqBias \; --recoverOrphans\; -o /path/to/output/{Samples} \; --threads 2' :::: /path/to/sheet_with_sample_and_fastq_names.csv; ```; Specifically, please provide at least the following information:. * Which version of salmon was used?; Both 1.10.2 and 1.10.3 were tested. ; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Used bioconda; * Which reference (e.g. transcriptome) was used?; GRCh38 ; * Which read files were used?; Illumina NovaSeq. Merged fastq based on direction (fastq split across lanes and had to add top off data) with zcat, used cutadapt for adapter trimming. . * Which which program options were used?; Ribodetector was used to get rid of rRNA contamination. Used output of non rRNA files with Salmon quant. **Expected behavior**; A clear and concise description of what you expected to happen.; Salmon Quant outputting of .sf files. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; From SLURM generated error file. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; HPCS: Red Hat Server 7.9. **Additional context**; Add any other context about the problem here.; Removal of --recoverOrphans leads to jobs finishing to completion. . Oddly enough, with --recoverOrphans dropped, I start seeing output into .err files I set in SLURM rather than in the .log file with each folder. .",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/961:1832,adapt,adapter,1832,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/961,1,['adapt'],['adapter']
Energy Efficiency,"plicates` is passed) any identical / duplicate sequences. After all of this, it will begin constructing the index in earnest. This is done by running a modified version of [TwoPaCo](https://github.com/medvedevgroup/TwoPaCo) to construct the compacted colored de Bruijn graph on the gentrome, which is then indexed using our [pufferfish index](https://github.com/COMBINE-lab/pufferfish). The TwoPaCo algorithm that generates the compacted colored de Bruijn graph from the input sequence is based on a very elegant algorithm that couples a Bloom filter with an exact hash table, and makes two (or more) passes over the input to identify all of the junctions in the reference (which directly implies all unitigs). To make the algorithm work efficiently, one needs to have an estimate for the number of distinct k-mers that will be encountered in the reference sequence. If the estimate is too big, one wastes memory. If the estimate is too small, the Bloom filter is not big enough, it doesn't filter efficiently, and the algorithm ends up putting way too much data in the exact hash table. In order to determine how to set the Bloom filter size appropriately, we take the following approach. If the Bloom filter size isn't provided directly (_note_: this is _not_ the same as the k-mer size, this is an estimate of the total number of distinct k-mers in the entire input data), then we make a call to a function defined in the [ntCard](https://github.com/bcgsc/ntCard) library. This is a program designed specifically for cardinality estimation of k-mers in sequencing data. Based on the estimated number of distinct k-mers, we use the standard equations (derived from the theory behind Bloom filters) to set the Bloom filter to be of the smallest possible size that still achieves a relatively low, pre-specified, false positive rate. The message you are seeing is that the estimates suggest the Bloom filter should be of size 2^28 *bits*, which is ~ 33.55MB — pretty small, actually. This is because ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186:1578,efficient,efficiently,1578,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-616713186,1,['efficient'],['efficiently']
Energy Efficiency,"quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, [@vals has an excellent series of blog posts on investigating and addressing low mapping rates](http://www.nxn.se/valent/2017/9/18/low-mappin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1805,adapt,adapter,1805,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapt'],['adapter']
Energy Efficiency,"r resulting from the same sample using selective alignment, we could compare and contrast the two. At that point, there are a few options depending on how deeply you want to dive. You could try to see how STAR and selective alignment are mapping differently to these transcripts. One potential difference is that STAR is _a lot_ more happy to softclip reads, which selective alignment won't do by default (you can test the effect with the `--softclipOverhangs` to allow selective alignment to softclip reads that hang off the transcript end or `--softclip` to allow softclips anywhere). Note that selective alignment may _still_ be a bit more conservative than STAR about softclips simply because of the nature of the scoring function it uses. This might give you a sense if one of these alignment methodologies is more consistent with your expectations in this case. Another option is to consider doing a grouping with `terminus`. This will reduce the set of ""genes"" that you can call as DE, because it will be happy to group together transcripts from different genes. However, it should help considerably in eliminating DE from highly-uncertain point estimates. Finally, you might consider performing DE with swish (cc @mikelove as he might have some input here) rather than DESeq2 (though we've typically been using swish at the transcript level rather than the gene level). Unlike DESeq2, swish will explicitly take into account the inferential uncertainty in the abundance estimates, using the Gibbs samples produced by salmon. This will allow it to avoid spurious DE calls that might otherwise occur when you have highly uncertain transcripts that, by chance, end up being assigned very different abundances in different samples / over different runs. Sorry for the information dump, but I wanted to lay out what might be going on, how to assess it, and what some potential solutions might be. If you dive in to start investigating this, feel free to reach out in this issue along the way if yo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:4127,reduce,reduce,4127,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,1,['reduce'],['reduce']
Energy Efficiency,"r_data.py"", line 145, in query; self.load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Cas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4411,adapt,adapter,4411,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['adapt'],['adapter']
Energy Efficiency,"ranscriptome (with no decoys) gives me a mapping rate of `0.00378202832148367%`. The first thing I did was to quality and adapter trim the data (using `fastp -i SRR9007475.fastq.gz -o SRR9007475_trimmed.fastq.gz -q 10 -w 8`) and ... whoa. This is the fastp html report [fastp.html.zip](https://github.com/COMBINE-lab/salmon/files/4176345/fastp.html.zip). So the first astounding statistic, the mean read length before trimming is 51bp (these are relatively short single-end reads). The mean read length after trimming is 21bp! So, the average read length is, in fact, less than the k-mer length used for indexing (default is k=31). On the trimmed data, the mapping rate goes up to `2.3545475882931305%`, still very low, but now there's somewhat of an explanation, the average read is shorter than a single k-mer. So, the next thing I tried was indexing with a smaller k; a _really_ small one in this case,`k=15`. Then, I re-ran on the _trimmed_ reads (the fact that the trimming took us from 51-21bp suggests that the reads had a lot of low quality bases, adapter contamination, or both). Under this setting, I still get a very low mapping rate, but it was _much_ higher — `16.766993524863488%`. The final thing I tried was seeing how the mapping rate changed as I altered `--minScoreFraction`, which is the salmon parameter that determines the alignment score that a read must achieve in order to be mapped validly. The default is 0.65. This means that the read cannot have a score < 0.65 * the maximum achievable score for the read given it's length. In the case of a 21bp read, the best score would be a score of 42, so a read must obtain a score >= 27 in order to be mapped. This is already a pretty poor mapping, but I reduced it even more to 0.3 (so any read with a score > 12 would pass). This led to a mapping rate of `~46%`. However, at this point, I'm not sure I would be confident in such mappings. For example, the situation here would be a 21bp read with multiple mismatches and, much of",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668:1452,adapt,adapter,1452,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668,1,['adapt'],['adapter']
Energy Efficiency,"referred to as QS in the rest of the message(s))_ ?. `salmon quant --threads 16 --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximport). I got a colSum for all my samples and then checked the numbers for the transc",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1101,Adapt,Adapter,1101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapt'],['Adapter']
Energy Efficiency,"s/TAIR10_chr_all.fas -l A -a leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam leaf_mock_t6_rep1_S40_R1_001Aligned.out.bam leaf_mock_t5_rep3_S63_R1_001Aligned.out.bam leaf_mock_t5_rep1_S39_R1_001Aligned.out.bam -p 8 -o ../SalmonQuantFiles; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.9.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { /rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas }; # [ libType ] => { A }; # [ alignments ] => { leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam leaf_mock_t6_rep1_S40_R1_001Aligned.out.bam leaf_mock_t5_rep3_S63_R1_001Aligned.out.bam leaf_mock_t5_rep1_S39_R1_001Aligned.out.bam }; # [ threads ] => { 8 }; # [ output ] => { ../SalmonQuantFiles }; Logs will be written to ../SalmonQuantFiles/logs; [2023-01-29 16:52:41.666] [jointLog] [info] setting maxHashResizeThreads to 8; [2023-01-29 16:52:41.666] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:single end, relative orientation:none, strandedness:unstranded }; [2023-01-29 16:52:41.668] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam"", fasta = ""/rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas"" . . .done. processed 0 reads in current round[2023-01-29 16:52:42.565] [jointLog] [info] replaced 186,207 non-ACGT nucleotides with random nucleotides; processed 2000000 reads in current round[2023-01-29 16:52:43.137] [jointLog] [info] Automatically detected most likely library type as U. [2023-01-29 16:52:43.276] [jointLog] [info] . The alignment group queue pool has been exhausted. 1759 extra fragments were allocated on the heap to saturate the pool. No new fragments will be allocated. processed 25000000 reads in current roundSegmentation fault (core dumped). ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/825:9910,allocate,allocated,9910,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/825,2,['allocate'],['allocated']
Energy Efficiency,"ting the index. It ensures that the index (and hence the resulting quantifications) contain the shortened names for gencode transcripts. In alignment-based mode, the behavior of the flag would have to be slightly different. It would have to re-normalize not only the names of the reference sequences in the fasta file, but it would also have to re-normalize the names in the BAM header so that they match. Specifically, the requirement is that the names of the sequences in the input fasta file are a 1-1 match with the names in the BAM header so that transcripts can be matched up properly with their sequences for training and applying the error model. However, if your BAM file already contains the stripped transcript names (i.e. if the BAM file header has the names without everything past the initial `|`), then I believe you can use the following command to have salmon do the same to the fasta file on the fly, so that the names match. ```{bash}; salmon-1.5.1_linux_x86_64/bin/salmon quant --ont -p 4 -t <(awk '{ if ($0 ~ ""^>"") { split($0,a,""|""); print a[1] } else { print $0 } }' Genome_files/gencode.vM24.transcripts.fa) -l U -a Documents/Day2_03_DRS_pass.bam -o Documents/counts/Day2_03_DRS_pass; ```. If the BAM file contains the ""full"" transcript name however, I think the current options are either to let salmon use the full transcript name from the fasta file, or to modify the GTF when running with minimap2, so that the BAM file itself contains the shortened names. Finally, I'd like to mention that the way you _intended_ to use the `--gencode` flag in alignment mode actually makes _a lot_ of sense, and I think it would be a very nice feature. Basically, the idea would be to apply stripping everything after the first `|` from *both* the fasta header and the BAM header, and using the reduced names for `quant.sf` outputs. We'll certainly. look into adding this functionality in a future release. Apologies for confusion caused by the ambiguous documentation of this flag. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/671#issuecomment-860792782:1998,reduce,reduced,1998,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/671#issuecomment-860792782,1,['reduce'],['reduced']
Energy Efficiency,"ubdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.13.final.0; virtual packages : __osx=12.4=0; __unix=0=0; __archspec=1=arm64; base environment : /usr/local/Caskroom/miniforge/base (writable); conda av data dir ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4683,adapt,adapters,4683,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['adapt'],['adapters']
Energy Efficiency,"umGibbsSamples 100`) and to dump the range-factorized equivalence classes used for offline quantification (`-d`). The Gibbs sampling files will contain the traces for the transcripts in question over the various iterations of the sampling procedure. Transcripts where there is a tremendous amount of ambiguity will tend to have highly anti-correlated posterior samples, and similarly, if you were to consider the abundance output of these transcripts as a *group*, there would be a large reduction in inferential relative variance. In fact, we [wrote a whole paper on this topic](https://academic.oup.com/bioinformatics/article/36/Supplement_1/i102/5870485). Consider this example from that paper:. ![image](https://user-images.githubusercontent.com/361470/101438021-706d3600-38df-11eb-9ada-a54ea9092d2d.png). The x-axis is samples from the Gibbs chains, and the y-values denote the estimated number of reads assigned to both transcripts in each sample. The green line at the top is what you get if you sum the abundances of these two transcripts. The main point is that the inferential relative variance (adjusted ratio of the variance over the mean) is _much_ smaller for the sum of these transcripts than for either individually. This is strong evidence that they are _inherently_ uncertain given the read evidence and alignments used for quantification. The tool described in that paper, called [`terminus`](https://github.com/COMBINE-lab/terminus), is a tool for automatically finding such groups of transcripts. Anyway, once you have the Gibbs samples in hand, we can walk you though how to do some assessment of these transcripts (tagging @hiraksarkar here since he's most likely to have access to scripts that will let us look at the posterior samples from individual transcripts). Similarly, if you can provide the quantification directory, we can help examine this too. If this is the case, that the posterior distributions are highly anti-correlated, it is likely that the ambiguity you ar",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:2032,green,green,2032,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,1,['green'],['green']
Integrability," --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximport). I got a colSum for all my samples and then checked the numbers for the transcripts and the decoys - this lead me to post my original question on this thread.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1177,Adapter,Adapter,1177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapter'],['Adapter']
Integrability," 16:48:51 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux; Distributor ID:	Ubuntu; Description:	Ubuntu 14.04.5 LTS; Release:	14.04; Codename:	trusty; ```. **Additional context**; - This SLURM cluster is managed by [Galaxy Cloudman](https://galaxyproject.org/cloudman/), and my installation of Salmon is currently constrained to a conda install. . - I've fiddled with many different CPU/Memory requirements for each of these `salmon` jobs I've run and have only had successful runs while using a single thread on a single node (`--ntasks=1 --nodes=1`), but even then there were segfaults observed intermittently. - The current Galaxy Tool wrapper for Salmon runs `salmon index ... && salmon quant ...` for every input fastq by default, but I've also generated and pointed `salmon quant` to a common index and have observed the same segfault behavior. I've also tried out the `--perfectHash` flag in both of these scenarios to no avail. - I have the ability to specify/wrap another version of Salmon to be compatible with Galaxy if the thought is that a more recent release could help. - I'm happy to provide any context past this that could help solve the issue!. - Also, I lack any biological insight so I'll ping my colleague @gmnelson for backup in that space. **Terminal Output**; <details>; <summary>Example Output</summary>; <br>. ```; Fatal error: Exit code 139 (); Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [2018-08-16 19:42:27.806] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; [2018-08-16 19:42:27.811] [jointLog] [warning] Entry with header [ENST00000434970.2], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-08-16 19:42:27.811] [jointLog] [warning] Entry with header [ENST00000448914.1], had length less than the k-me",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271:2714,wrap,wrap,2714,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271,1,['wrap'],['wrap']
Integrability," ; fails to compile salmon due to an internal compiler error.; The problem occurs for both the 1.4.0 release as well as the current; git master branch during the final linking of the salmon executable:. ```; git clone https://github.com/COMBINE-lab/salmon.git; mkdir salmon/build; cd salmon/build ; cmake -DFETCH_BOOST=TRUE -DCMAKE_INSTALL_PREFIX=${PREFIX} ..; make; ```. ```; [100%] Linking CXX executable salmon; /usr/bin/ld: ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): in function `find_file_url':; open_trace_file.c:(.text+0xf4e): warning: the use of `tempnam' is dangerous, better use `mkstemp'; during IPA pass: icf; lto1: internal compiler error: Segmentation fault; Please submit a full bug report,; with preprocessed source if appropriate.; See <file:///usr/share/doc/gcc-9/README.Bugs> for instructions.; lto-wrapper: fatal error: /usr/bin/c++ returned 1 exit status; compilation terminated.; /usr/bin/ld: error: lto-wrapper failed; collect2: error: ld returned 1 exit status; make[2]: *** [src/CMakeFiles/salmon.dir/build.make:456: src/salmon] Error 1; make[1]: *** [CMakeFiles/Makefile2:689: src/CMakeFiles/salmon.dir/all] Error 2; make: *** [Makefile:163: all] Error 2; ```. With VERBOSE=1, this is the final command that fails:; ```; /usr/bin/c++ -O3 -DNDEBUG -flto -fno-fat-lto-objects CMakeFiles/salmon.dir/EMUtils.cpp.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedCellOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/Graph.cpp.o CMakeFiles/salmon.dir/DedupUMI.cpp.o CMakeFiles/salmon.dir/Alevin.cpp.o CMakeFiles/salmon.dir/AlevinHash.cpp.o CMakeFiles/salmon.dir/SalmonAlevin.cpp.o CMakeFiles/salmon.dir/WhiteList.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/664:1036,wrap,wrapper,1036,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/664,1,['wrap'],['wrapper']
Integrability," ; libboost-all-dev ; liblzma-dev ; libbz2-dev ; cmake ; zlib1g-dev ; curl ; unzip ; wget ; libcurl4-openssl-dev ; libtbb-dev ; libtbb12 ; liblzma-dev ; libjemalloc2 ; pkg-config ; libgff-dev; ```. One thing I noticed during build is that, while I included `libjemalloc2` here, the salmon build procedure still downloaded and built `jemalloc`. However, I don't _think_ jemalloc is the thing causing the segfault. Regarding dependencies that can't be used — the current `libstaden` is behind the upstream release. The upstream release contains an important bug fix for a bug (and suggested fix that we proposed to the developer) upon which we rely. More importantly, afaik there is no relevant `libpufferfish-dev` package (we certainly have not made one), and so there is not even e.g. a check in the `CMakeLists.txt` file. Salmon's build always tries to run `fetchPufferfish.sh` to download the relevant `pufferfish` source files needed to build `salmon`. Critically, the relevant `pufferfish` dependencies and `salmon` releases move in lockstep. Each new `salmon` release it accompanied by a new tag in the `pufferfish` repo (so that the specific source used to build a given `salmon` release is fixed and easily trackable). So, I think the easiest way to move forward is to:. * do a diff of my list of packages above with what is pulled in by `apt build-dep salmon`. * figure out why, even when `libjemalloc2` is installed, the build system tries to build `jemalloc` itself (maybe we need the dev package?). * determine what folks want to do upstream about the lockstep pufferfish dependency. Right now, the `fetchPufferfish.sh` script pulls a tagged tarball from github and checks that the sha matches, and moves the relevant source files into place. This is true both when we build our own releases as well as when `salmon` is built for other distribution channels like `conda`. While I am happy to have someone figure out how to package that up as a package that can be put into the repo and depe",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464538233:1182,depend,dependencies,1182,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464538233,1,['depend'],['dependencies']
Integrability, [info] Index contained 182608 targets. processed 19000000 fragments; hits: 65897209; hits per frag: 3.47349. [2016-12-13 22:40:22.572] [jointLog] [info] Computed 137534 rich equivalence classes for further processing; [2016-12-13 22:40:22.572] [jointLog] [info] Counted 16265961 total reads in the equivalence classes; [2016-12-13 22:40:22.618] [jointLog] [info] Mapping rate = 83.509%. [2016-12-13 22:40:22.618] [jointLog] [info] finished quantifyLibrary(); [2016-12-13 22:40:22.619] [jointLog] [info] Starting optimizer; [2016-12-13 22:40:22.904] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-12-13 22:40:22.911] [jointLog] [info] iteration = 0 | max rel diff. = 299.976; [2016-12-13 22:40:23.620] [jointLog] [info] iteration = 100 | max rel diff. = 0.121769; [2016-12-13 22:40:24.367] [jointLog] [info] iteration = 200 | max rel diff. = 0.103587; [2016-12-13 22:40:25.102] [jointLog] [info] iteration = 300 | max rel diff. = 0.144748; [2016-12-13 22:40:25.815] [jointLog] [info] iteration = 400 | max rel diff. = 0.231057; [2016-12-13 22:40:26.505] [jointLog] [info] iteration = 500 | max rel diff. = 0.0156154; [2016-12-13 22:40:27.020] [jointLog] [info] iteration = 570 | max rel diff. = 0.00955966; [2016-12-13 22:40:27.052] [jointLog] [info] Finished optimizer; [2016-12-13 22:40:27.052] [jointLog] [info] writing output. [2016-12-13 22:40:27.523] [jointLog] [info] Starting Gibbs Sampler 1 week; 100% [=====================================================] in 44s; [2016-12-13 22:41:12.189] [jointLog] [info] Finished Gibbs Sampler; [2016-12-13 22:41:12.190] [jointLog] [warning] NOTE: Read Lib [SRR2454059.fq.gz] :. Detected a *potential* strand bias > 1% in an unstranded protocol check the file: test_quant/lib_format_counts.json for details; ```. edit: One note is that I was using my build of the same commit number. I'm running the executable you compiled now (since I had to put the appropriate libraries in the `LD_LIBRARY_PATH` to get it to be happy).,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:3787,protocol,protocol,3787,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,1,['protocol'],['protocol']
Integrability," [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.649] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.649] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-based) v1.5.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 5 }; ### [ index ] => { ref//salmon.index.human.122116 }; ### [ libType ] => { U }; ### [ unmatedReads ] => { subset_SRR2173892_trimmed.fq }; ### [ output ] => { salmonRes_SRR2173892 }; Logs will be written to salmonRes_SRR2173892/logs; [2021-07-16 11:47:01.807] [jointLog] [info] setting maxHashResizeThreads to 5; [2021-07-16 11:47:01.807] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-07-16 11:47:01.807] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.807] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.807] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.807] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; ./salmonRes_SRR1501367/quant.sf ; Error in file(file, ""rt"") : cannot open the connection; In addition: Warning message:; In file(file, ""rt"") :; cannot open file './salmonRes_SRR1501367/quant.sf': No such file or directory",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/685:11794,message,message,11794,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/685,1,['message'],['message']
Integrability," annotation and assembly available here : https://data.jgi.doe.gov/refine-download/phytozome?q=Chlamydomonas+reinhardtii+CC-4532; Reads available here : https://www.ncbi.nlm.nih.gov/sra/SRR10737773. Gentrome and Transcriptome indexes where generate as follows : ; ```; grep ""^>"" <(gunzip -c CreinhardtiiCC_4532_707_v6.0.hardmasked.fa.gz) | cut -d "" "" -f 1 > decoys.txt; sed -i.bak -e 's/>//g' decoys.txt. cat CreinhardtiiCC_4532_707_v6.1.transcript_primaryTranscriptOnly.fa.gz CreinhardtiiCC_4532_707_v6.0.hardmasked.fa.gz > gentrome.fa.gz. salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i index_gentrome; salmon index -t CreinhardtiiCC_4532_707_v6.1.transcript_primaryTranscriptOnly.fa.gz -p 12 -i index_transcriptome; ```; Salmon quant was run as follows:; ```; salmon quant -i index_gentrome -l A -1 SRR10737773_1.fastq -2 SRR10737773_2.fastq -p 12 -o quant_gentrome; salmon quant -i index_transcriptome -l A -1 SRR10737773_1.fastq -2 SRR10737773_2.fastq -p 12 -o quant_transcriptome; ```; I get this error when quantifying on gentrome and not transcriptome (full log : [salmon.log](https://github.com/user-attachments/files/17371227/salmon.log)). ```; /usr/include/c++/14.1.1/bits/stl_vector.h:1130: std::vector<_Tp, _Alloc>::reference std::vector<_Tp, _Alloc>::operator[](size_type) [with _Tp = Transcript; _Alloc = std::allocator<Transcript>; reference = Transcript&; size_type = long unsigned int]: Assertion '__n < this->size()' failed.; salmon.sh: line 3: 54621 Aborted (core dumped) salmon quant -i index_gentrome -l A -1 SRR10737773_1.fastq -2 SRR10737773_2.fastq -p 12 -o quant_gentrome; ```. **Detail**; OS : Arch Linux x86_64; Kernel : 6.9.7-arch1-1; gcc: 14.1.1 20240522; Salmon version : 1.10.3; Salmon was installed through **Arch AUR** (https://aur.archlinux.org/packages/salmon) because conda triggers another bug.; I suspect that this is the cause of the bug. I tried to clean up my dependencies/packages but could not fix the bug. . Thank you for this great program! Cheers!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/965:2125,depend,dependencies,2125,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/965,1,['depend'],['dependencies']
Integrability," dependencies that can't be used — the current `libstaden` is behind the upstream release. The upstream release contains an important bug fix for a bug (and suggested fix that we proposed to the developer) upon which we rely. More importantly, afaik there is no relevant `libpufferfish-dev` package (we certainly have not made one), and so there is not even e.g. a check in the `CMakeLists.txt` file. Salmon's build always tries to run `fetchPufferfish.sh` to download the relevant `pufferfish` source files needed to build `salmon`. Critically, the relevant `pufferfish` dependencies and `salmon` releases move in lockstep. Each new `salmon` release it accompanied by a new tag in the `pufferfish` repo (so that the specific source used to build a given `salmon` release is fixed and easily trackable). So, I think the easiest way to move forward is to:. * do a diff of my list of packages above with what is pulled in by `apt build-dep salmon`. * figure out why, even when `libjemalloc2` is installed, the build system tries to build `jemalloc` itself (maybe we need the dev package?). * determine what folks want to do upstream about the lockstep pufferfish dependency. Right now, the `fetchPufferfish.sh` script pulls a tagged tarball from github and checks that the sha matches, and moves the relevant source files into place. This is true both when we build our own releases as well as when `salmon` is built for other distribution channels like `conda`. While I am happy to have someone figure out how to package that up as a package that can be put into the repo and depended upon, we currently don't have the capacity to tackle that ourselves and don't have a suitable mechanism to replace the current approach to obtaining the dependent pufferfish files. However, this question is very important as e.g. a segfault exactly like the one you are encountering was actually a bug in the pufferfish source used in the 1.9.0 release of `salmon` that was _fixed_ for the 1.10.0 release. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464538233:1771,depend,dependency,1771,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464538233,3,['depend'],"['depended', 'dependency', 'dependent']"
Integrability," described in the Bowtie2 manual)](http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-dovetail) are considered discordant. This is the same default behavior imposed by Bowtie2. If you look in the `meta_info.json` file for some of these samples (which is in the `aux_info` subdirectory of the quantification directory for a sample), you can see how many mappings are being discarded by virtue of being dovetail mappings. It is possible to allow such alignments (consider them as concordant) by passing the `--allowDovetail` flag. It is not the case that such alignments are always ""bad"", its simply that one would not expect many fragments to align in such a way, and if these constitute the overwhelming majority of the mappings, one might be suspicious about the underlying data. * Selective alignment actually _aligns_ the reads to the transcriptome. For this purpose, it performs end-to-end alignment. This means that if you suspect that the sample may contain adapters or very low-quality read ends, the reads should be trimmed prior to quantification. It is, therefore, worth checking how the mapping rate changes for some of these samples if the reads are trimmed first. * Selective alignment is more robust than quasi-mapping to the chosen value of `-k`, the minimum match length used when searching for alignments. I noticed that some of the samples contain relatively short reads, so you might see if the mapping rate changes if you adopt a smaller value of `-k` in the index (e.g. we use `23` in the [pre-print](https://www.biorxiv.org/content/10.1101/657874v2.full.pdf)). * You mention that this index doesn't contain any decoy sequence. This of course, should not affect the mapping rate. However, I'd be quite curious to see if you index the reference using the _whole genome_ as decoy (i.e. the SAF method from the pre-print), how many reads are discarded because they map better to a decoy sequence (this information can also be obtained from `meta_info.json`). Thi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798:2780,adapter,adapters,2780,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798,1,['adapter'],['adapters']
Integrability," install -y gcc g++ make wget git curl libtbb2-dbg libtbb-dev unzip zlib1g-dev libcurl4-openssl-dev liblzma-dev libbz2-dev libcereal-dev libgff-dev libpkgconfig-perl libjemalloc-dev; /*; gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0; g++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0; GNU Make 4.1; */; wget https://github.com/Kitware/CMake/releases/download/v3.13.4/cmake-3.13.4-Linux-x86_64.sh /*cmake version 3.13.4*/. 3. git clone https://github.com/COMBINE-lab/salmon.git; I'm at the top commit: commit 0813a0a287c2bd80071511830befe5d786a59ad1 (HEAD -> master, tag: v1.4.0, origin/master, origin/HEAD). 4. In directory salmon/build, I type; cmake -DFETCH_BOOST=TRUE -DTBB_INSTALL_DIR=/usr/include -DCMAKE_BUILD_TYPE=Debug -DCMAKE_INSTALL_PREFIX=../stage .. =============At last, getting these:; -- Configuring done; -- Generating done; -- Build files have been written to: /root/salmon/build. 5. In directory salmon/build, I type; make. ===========Then crashed here; [ 86%] Built target unitTests; Scanning dependencies of target salmon; [ 86%] Building CXX object src/CMakeFiles/salmon.dir/EMUtils.cpp.o; c++: error: -pg and -fomit-frame-pointer are incompatible; src/CMakeFiles/salmon.dir/build.make:62: recipe for target 'src/CMakeFiles/salmon.dir/EMUtils.cpp.o' failed; make[2]: *** [src/CMakeFiles/salmon.dir/EMUtils.cpp.o] Error 1; CMakeFiles/Makefile2:790: recipe for target 'src/CMakeFiles/salmon.dir/all' failed; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; Makefile:162: recipe for target 'all' failed; make: *** [all] Error 2. Specifically, please provide at least the following information:. * Which version of salmon was used? v1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? compiled; * Which reference (e.g. transcriptome) was used? Encountered compile error, so not to index/quant step yet; * Which read files were used? same as above; * Which which program options were used? same as above. **Expected behavior**; A clear and concise description o",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/608:1904,depend,dependencies,1904,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/608,1,['depend'],['dependencies']
Integrability," library type. When I change the ""A"" to ""ISR"" or ""IU"", the % mapped changes a lot. That does seem strange, but I honestly don't know much about `Evigene` or what it's doing in combining these assemblies. When you specify ""IU"", the mappings will generally be _more_ lenient (i.e. you'd expect to get more mappings) than when you specify ""ISR"". The ""A"" flag just looks at how the first 10,000 reads map and guesses the library type based on that. On thing to make sure of is that your reads aren't ""ordered"" in any way, such that you'd expect the first 10,000 to deviate in any meaningful way from the statistics of the reads of the reads. > Is it better to build assemblies with strand-aware flags? If so, does it usually make a large difference to quantification results, or a minor one? I don't know what protocol the sequencing facility used, but I am sure I could ask them. I gather from my recent reading that the extra information gained by using a stranded protocol is worthwhile, so I would expect that the sequencing facility used one, but why doesn't Trinity or MEGAHIT detect the sequecing protocol that was used? . So there are really 2 questions here. *If* the data are stranded, then yes, it's worthwhile to use stranded flags in both assembly and quantification. This is because stranded protocols will allow you to better disambiguate (a) overlapping genes and (b) reads that are ambiguous between sequence-similar genes that happen to reside on different strands. The *second* question is why Trinity or MEGAHIT wouldn't detect this. The main reason for this is that these are assembly tools. Without access to a reference genome, there is no principled way for these tools to know what the orientation of a read is _a priori_, so they generally rely on the user to specify if the reads are stranded or unstranded. > Or, if you have to specify it, why do none of the example Trinity commands I've come across include this option? It doesn't strike me as a commonly used specification i",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427:1147,protocol,protocol,1147,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427,2,['protocol'],['protocol']
Integrability," main purpose of this is to avoid spurious mapping to transcriptomic sequences that may be similar to other unannotated sequences in the genome that are nonetheless a better match for the read (e.g. an unannotated possibly transcribed pseudogene). The way this works in practice is that both the transcript sequences themselves *and the full genome* are indexed. Any read that aligns _strictly better_ to the genome than the transcriptome is considered to map to a decoy, and is not used for the purposes of quantification. Consistent with the behavior I hypothesized above for STAR, if you have many softclipped bases at the end of the read that nonetheless match what is in the genome downstream of the end of the annotated transcript, you'll likely see these reads assigned as decoys. To check this, you can look at salmon's `meta_info.json` output file to see how many reads were mapped best to decoys. * Why do I see much higher counts for this gene with FeatureCounts?. * It depends on the specific behavior you invoke. However, my guess is that FeatureCounts is being run with flags such that reads that only somewhat overlap a feature are nonetheless assigned to it. This suggests that while no good alignment may actually exist to the annotated transcript, FeatureCounts is still assigning the read to that feature because it overlaps it to some degree and matches the corresponding location on the genome. Again, you can test this by changing the required overlap fraction of FeatureCounts. * Why does running salmon outside of nf-core produce much higher counts?. * Since you are indexing *just* the transcriptome, and not including the genome as decoy sequence (as is done in nf-core), then the only thing that will prevent reads from being assigned to the gene in question is if so much of the read overhangs off the end of the annotated transcript that no mapping matches the minimum required alignment score. This is likely to be a much more liberal threshold than what STAR allows, so",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883:2177,depend,depends,2177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883,1,['depend'],['depends']
Integrability," message(""Boost_FOUND = ${Boost_FOUND}""); @@ -571,7 +574,22 @@; endif(); ; ## Try and find TBB first; -find_package(TBB 2018.0 COMPONENTS tbb tbbmalloc tbbmalloc_proxy); +if(DEFINED ENV{ROOT_LIBTBB}); + message(""ROOT_LIBTBB in env""); + set(ROOT_LIBTBB ); + set(TBB_DIR $ENV{ROOT_LIBTBB}); + set(TBB_INCLUDE_DIRS ${TBB_DIR}/include); + set(TBB_INCLUDE_DIR ${TBB_DIR}/include); + set(TBB_LIBRARY_DIRS ${TBB_DIR}/lib); + set(TBB_LIBRARY ${TBB_DIR}/lib); + set(TBB_LIB_DIR ${TBB_DIR}/lib); + set(TBB_VERSION ""2019.6""); + set(TBB_FOUND TRUE); +else(); + message(""ROOT_LIBTBB NOT in env""); + find_package(TBB 2018.0 COMPONENTS tbb tbbmalloc tbbmalloc_proxy); +endif(); +; ; if (${TBB_FOUND}); if (${TBB_VERSION} VERSION_GREATER_EQUAL 2018.0); @@ -696,7 +714,19 @@; #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""); ; -find_package(libgff); +if(DEFINED ENV{ROOT_LIBGFF}); + message(""ROOT_LIBGFF in env""); + set(LIBGFF_DIR $ENV{ROOT_LIBGFF}); + set(LIBGFF_INCLUDE_DIRS ${LIBGFF_DIR}/include); + set(LIBGFF_INCLUDE_DIR ${LIBGFF_DIR}/include); + set(LIBGFF_LIBRARY_DIRS ${LIBGFF_DIR}/lib); + set(LIBGFF_LIBRARY ${LIBGFF_DIR}/lib); + set(LIBGFF_LIB_DIR ${LIBGFF_DIR}/lib); + set(LIBGFF_FOUND TRUE); +else(); + message(""ROOT_LIBGFF NOT in env""); + find_package(libgff); +endif(); if(NOT LIBGFF_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); @@ -739,7 +769,14 @@; endif(); ; find_package(CURL); -find_package(libstadenio); +if(DEFINED ENV{ROOT_IO_LIB}); + set(ROOT_IO_LIB $ENV{ROOT_IO_LIB}); + set(STADEN_INC ""-I${ROOT_IO_LIB}/include""); + set(STADEN_LIB ""-L${ROOT_IO_LIB}/lib""); + set(LIBSTADENIO_FOUND TRUE); +else(); + find_package(libstadenio); +endif(); if (NOT LIBSTADENIO_FOUND); message(""Build system will compile Staden IOLib""); message(""==================================================================""). ```. In the meantime the binary distribution was loaded. . Thanks.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460:4284,message,message,4284,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460,8,['message'],['message']
Integrability," parse reads and update estimates asynchronously). However, the more important point here is that the inference estimates returned by Salmon (and, for that matter, every other transcript-level expression tool) are the result of a statistical optimization procedure that cannot guarantee a unique global optimal solution (and, in fact, even if a global optimum could be guaranteed, there may be multiple different optima). Thus, there is uncertainty inherent in the statistical problem being solved. Of course, if one ordered updates in the same way and set up the initial conditions precisely the same, there would be convergence to the same result, but any sense of confidence there is illusory. However, Salmon does provide a way to quantify, statistically, confidence in the result. The `--numBootstraps` option will do bootstrap sampling, or the `--numGibbsSamples` option will perform posterior Gibbs sampling. Both of these techniques will provide samples from the posterior distribution, and the variance of these samples will give you some information about the variance in the results that are due purely to the inherent statistical uncertainty in the problem. In the `scripts` folder there is a python script `ConvertBootstrapsToTSV.py` that will convert either the bootstrap or gibbs samples to a easily readable tsv format. These samples represent the estimated number of reads coming from each transcript when sampling from the posterior. These can be used to empirically estimate that statistical uncertainty in the abundance estimates of the different transcripts. Finally, I'll note that while, for the reasons described above, the output is not purely deterministic. The difference between subsequent runs of salmon (with differences changing depending on the order in which reads are parsed and processed) is typically small (and much smaller than the statistical uncertainty in the abundance estimates of the transcripts). I'd be happy to answer any other questions you have. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248:2190,depend,depending,2190,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248,1,['depend'],['depending']
Integrability," protocols, it is usually the case that we get 1 read -> 1 transcript, even if we don't read the whole thing. We have tested the effect of this in ONT data with spike ins, and have verified that using `--noLengthCorrection` does generally lead to improved accuracy with respect to quantification estimates. We have informed ONT of this, and I would guess they may optimize the flags that are used soon (we have also developed an error model that works correctly for these long reads, and that should make it into the next release of salmon). Regarding the effect this has on the `NumReads` values reported by salmon, it's not as simple as with the `TPM` estimates. The length affects the assigned reads through the probabilistic model on which inference is done. With the length effect we have that P(f | t_i) ∝ P( position | f, t_i ) * P( alignment | f, t_i) --- forgetting the alignment term for the time being, we have that with length correction P( position | f, t_i ) ∝ 1 / l_i and without length correction the l_i term goes away. In other words, the probability of allocating reads has a term that depends on the effective length when the `--noLengthCorrection` flag is not passed, but that term goes away when it is passed. This is not quite as drastic as with TPM where the normalization includes the length directly in the normalization (note, however, that when the `--noLengthCorrection` flag is passed, this adjusts the TPM as well). Further, the `NumReads` is still better than TPM in this regard because it still encodes the effect size (i.e. `NumReads` will sum to the total number of aligned reads). Anyway TLDR: Passing the `--noLengthCorrection` flag *is* better for ONT data, though results without this flag are sub-optimal, they are not unusable. We have let ONT know about this, and I would suspect they will address it (perhaps they'll even accept a PR?). Finally, a long read error model has been created and will _hopefully_ make it to the next version of salmon. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147:1444,depend,depends,1444,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147,1,['depend'],['depends']
Integrability," selective-alignment default of 0.35.; [2021-05-19 18:46:25.303] [jointLog] [info] parsing read library format; [2021-05-19 18:46:25.303] [jointLog] [info] There is 1 library.; [2021-05-19 18:46:25.429] [jointLog] [info] Loading pufferfish index; [2021-05-19 18:46:25.429] [jointLog] [info] Loading dense pufferfish index.; [2021-05-19 18:46:27.087] [jointLog] [info] done; [2021-05-19 18:46:27.087] [jointLog] [info] Index contained 141,069 targets; [2021-05-19 18:46:32.618] [jointLog] [info] Number of decoys : 0; [2021-05-19 18:46:33.428] [jointLog] [info] Automatically detected most likely library type as IU. [2021-05-19 18:49:27.444] [jointLog] [error] . [2021-05-19 18:49:27.506] [jointLog] [error] Processing reads : Error reading from the FASTA/Q stream. Minimum return code for left and right read was (-2). Make sure the file is valid. ```; For rabbitQC's log; ```; Detecting adapter sequence for read1...; CCCAGCCATAACACAGTATCAAACTCCACTATTTGTCTGATCCGTACTTATTACAGCCGT. Detecting adapter sequence for read2...; CCAACTTGGTCTACAAGACGCCACATCCCCTATTATAGAAGAGCTAATAAATTTCCATGA. Read1 before filtering:; total reads: 44178187; total bases: 2140649565; Q20 bases: 1899503304(88.7349%); Q30 bases: 1839878933(85.9496%). Read1 after filtering:; total reads: 34172299; total bases: 1775386278; Q20 bases: 1762557969(99.2774%); Q30 bases: 1737891531(97.8881%). Read2 before filtering:; total reads: 44178187; total bases: 2233386484; Q20 bases: 2180294210(97.6228%); Q30 bases: 2141791820(95.8988%). Read2 aftering filtering:; total reads: 34172299; total bases: 1749324083; Q20 bases: 1731172028(98.9623%); Q30 bases: 1700577336(97.2134%). Filtering result:; reads passed filter: 68344598; reads failed due to low quality: 11353966; reads failed due to too many N: 40048; reads failed due to too short: 8617762; reads with adapter trimmed: 382600; bases trimmed due to adapters: 6698794; reads corrected by overlap analysis: 123572; bases corrected by overlap analysis: 125602. Duplication rate: 1.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/660:2610,adapter,adapter,2610,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/660,1,['adapter'],['adapter']
Integrability," std::char_traits<char>, std::allocator<char> > const, unsigned int> >, 4ul>::cuckoo_status cuckoohash_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, unsigned int, BarcodeGroupStringHasher, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned int> >, 4ul>::cuckoo_expand_simple<std::integral_constant<bool, false>, std::integral_constant<bool, false> >(unsigned long)::{lambda(unsigned long, unsigned long, std::__exception_ptr::exception_ptr&)#1}) (); #7 0x00000000007af2a3 in bool cuckoohash_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, unsigned int, BarcodeGroupStringHasher, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned int> >, 4ul>::cuckoo_reserve<std::integral_constant<bool, false> >(unsigned long) [clone .constprop.984] (); #8 0x00000000007d3e29 in void initiatePipeline<alevin::protocols::Chromium, boost::program_options::basic_parsed_options<char> >(AlevinOpts<alevin::protocols::Chromium>&, SalmonOpts&, boost::program_options::basic_parsed_options<char>&, boost::program_options::variables_map&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >) (); #9 0x00000000007b0935 in salmonBarcoding(int, char**) (); #10 0x000000000065d57c in main (); (gdb); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:8698,protocol,protocols,8698,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,2,['protocol'],['protocols']
Integrability," subsetting from Biostrings, but in the premature case the strand information is used. Of course, this problem is out of the scope of this forum so it will be okay to close this issue. I will reach out to the developers of GenomicRanges and Biostrings to point out this potential problem and seek their guidance. Thank you again for all your help. Rached. ```; # setwd('wd'). options(scipen = 9999). libraries <- lapply(; X = c('data.table', 'magrittr', 'rtracklayer', 'Biostrings', 'reshape2', 'ggplot2'),; FUN = library, character.only = TRUE; ). ### Inputs ####; anot.gtf <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.101.gtf.gz' # Ensembl GTF; genome.fasta <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz' # Genome fasta from Ensembl; gencode.tx.fasta <- '../../shared_data/annotations/Gencode/gencode.v35.transcripts.fa.gz' # Gencode transcript FASTA. dotPlot.fname <- '../ouput/dotPlots.pdf'. ### Read exon annotations ####; message('Loading Ensembl exon annotation (1-22, X, Y, MT)...'). chromosomes <- c(1:22, 'X', 'Y', 'MT'). anot <- import(anot.gtf, feature = 'exon') %>% sort; anot <- anot[seqnames(anot) %in% chromosomes, ]. # append gene and transcript version numbers to IDs; anot$gene_id <- paste(anot$gene_id, anot$gene_version, sep = '.'); anot$transcript_id <- paste(anot$transcript_id, anot$transcript_version, sep = '.'). ### Create premature transcript annotations ####; message('Creating premature transcript annotation...'). anot.pre <- split(anot, anot$transcript_id); anot.pre <- anot.pre[lengths(anot.pre) > 1] %>% range %>% unlist %>% sort # only consider transcripts with > 1 exon. anot.pre$transcript_range <- as.character(anot.pre); anot.pre$gene_id <- anot[match(names(anot.pre), anot$transcript_id), ]$gene_id. # collapse replicate pre-mature transcripts per gene...; names(anot.pre) <- anot.pre$premature_group <- sapply(; split(; names(anot.pre),; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_');",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:4276,message,message,4276,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['message'],['message']
Integrability," the right end of the transcript which is inconsistent with the coverage profile and, as hoped, salmon did not assign any reads to that variant. So, in these two scenarios the default options produce nice results in line with our human intuition. 2. **Failure scenario with default options:** ; ![PDI1_example](https://user-images.githubusercontent.com/10292386/86509895-3df36600-bda0-11ea-8f0b-df0de4fefa31.png); <img width=""383"" alt=""PDI1_table"" src=""https://user-images.githubusercontent.com/10292386/86509897-40ee5680-bda0-11ea-9566-9f2bdab464f0.png"">. In this example there are four genes (oriented in the same direction) with wildly different expression levels. I added a ""PDI1_SuperTranscript"" which stretches from the 5' end of PDI1 to the 3' end of POF1 (so, all reads from all 4 genes would multimap to the super transcript). This is a contrived example to illustrate the technical details, but you could imagine similar biological scenarios, especially regarding splicing isoforms. With the default options, you get the counterintuitive result that all of the reads from just MGR1 and POF1 (the two lowest abundance transcripts) are assigned to the super transcript. EMC1 loses ~50% of its reads to the super transcript, and PDI1 only loses ~10%. I'm not showing it, but if you remove the default PDI1 transcript from the index (so it's just the super transcript + the 3 genes MGR1/EMC1/POF1), all three of them lose all of their reads to the super transcript... meaning that whether or not EMC1 gets assigned any reads depends entirely on the presence of a non-overlapping gene, PDI1, in the salmon index. This is definitely at odds with our intuition from looking at the coverage plots, but makes sense when you break all the transcripts down to a simple reads per kb equation. As before, if you turn off length modeling then all of the reads get assigned to the super transcript. I hope this was insightful and cleared up the issue a bit. Feel free to e-mail or reply here. Best,; Jason",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847:6417,depend,depends,6417,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847,1,['depend'],['depends']
Integrability," transcript by salmon) as well as to the genome. It is quite common that the mapping rate to the genome is higher than that to the transcriptome. This is much more a result of what you are aligning _to_ than the aligner. If you were to take the transcriptome, and align to it using Hisat2 with `--no-spliced-alignment` and `--end-to-end` (since there won't be splice junctions when you align to the transcriptome), I'd expect you to get a similar mapping rate as you see in salmon. > I also noticed a high number of mappings discarded because of alignment score. I also wonder why the number of mappings discarded can be larger than num of processed (57113760, the reads number in 1_1.fq.gz). . Good question. The number you are looking at is the number of discarded _mappings_, not the number of discarded _fragments_. The difference is that every fragment can have many potential mappings. The number you are looking at is the total number of attempted _alignments_ that failed to achieve the threshold score. Luckily, salmon reports both numbers. The number of fragments for which _all_ alignments failed to reach the score threshold is `4,196,417`; given in `aux_info.json` by ` ""num_fragments_filtered_vm"": 4196417`. One point to note is that these are all fragments for which mapping is attempted (they had at least one k-mer match the reference), but no alignment was valid up to the threshold. You could try running the quantification again with `--softclip` to allow softclipping of the reads and see if any considerable fraction of these `4196417` failed to align because they overhang the annotated transcripts or contain adapters etc. Nonetheless, even if all of these mapped, the rate would still be ~72%. The remainder of the reads didn't even have a matching k-mer in common with the reference transcriptome, which means they are exceedingly unlikely to have come from the transcripts that were indexed. > Thanks. You're welcome! Please let me know if you have any follow-up questions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-697125235:2029,adapter,adapters,2029,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-697125235,1,['adapter'],['adapters']
Integrability," v0.8 and 1.2.1. The one that seems most relevant here is the introduction of selective-alignment to replace the quasi-mapping procedure that was originally used in salmon. Selective-alignment actually scores the mappings found to the transcriptome, and rejects alignments whose quality is below a (user-specified) threshold. Here, you can see that, in 1.2.1. * 39 fragments are mapped within the score threshold; * 216 fragments are discarded because no mapping location has an alignment score above the threshold. all together, this means that the total number of ""mapped"" fragments in 1.2.1 is very similar to 0.8 (1.2.1 maps 39+216 = 255, while 0.8 maps 254). However, 1.2.1 discards 216 of the fragments because no mapping is sufficiently good. The default for ""sufficiently good"", by the way, is to have an alignment score of at least 65% of the maximum possible for a read of the given length. For typical RNA-seq data, this is actually quite liberal / generous, and is similar to the type of noise in alignment that Bowtie2 allows with the sensitive flag. In general, the heuristics used in 1.2.1 (selective-alignment) tend to be more sensitive than those used in 0.8 (quasi-mapping), since the mappings are then validated using alignment scoring. However, this does mean that the quality of the alignment along the whole read matters. Thus, it is more important to do quality / adapter trimming in the newer version compared to the older one. There is also a flag in 1.2.1 (`--softclip`) that will allow mismatches / gaps at the ends of reads to not detract from the alignment score. So, these are the main differences. However, looking at the output logs you provided, a couple of basic questions did come to mind. Why are there so few reads to begin with? Even in 0.8, only 254 reads mapped, which is obviously a very small number of reads. Is there something non-typical about this sample? Is it a full RNA-seq sample? Are these reads something atypical (like long reads — ONT or PacBio)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/542#issuecomment-651332239:1497,adapter,adapter,1497,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/542#issuecomment-651332239,1,['adapter'],['adapter']
Integrability,"!grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnes <- c(chosenOnesP, chosenOnesM). # subset chosed ones; anot.ori <- anot; anot.pre.ori <- anot.pre. anot <- anot[anot$transcript_id %in% chosenOnes, ]; anot.pre <- anot.pre[anot.pre$premature_group %in% chosenOnes, ]. # sanity check (make sure strand information is the same for pre and mature RNA counterparts); all(; sort(paste(strand(anot), anot$transcript_id) %>% unique) ==; sort(paste(strand(anot.pre), anot.pre$premature_group) %>% unique); ) %>% print. ### Mature transcript sequences ####; message('Creating mature transcript sequences...'). # subset pos sorted exons, split by tx ID, concatenate exon seq per transcript using unlist; mature.tx <- lapply(; X = split(dna[anot], anot$transcript_id),; FUN = unlist; ) %>% DNAStringSet. message('... now getting reverse complements of mature transcripts on the minus strand...'). mature.tx[names(mature.tx) %in% anot[strand(anot) == '-', ]$transcript_id] <- reverseComplement(; mature.tx[names(mature.tx) %in% anot[strand(anot) == '-', ]$transcript_id]; ). ### Premature transcript sequences ####; message('Creating premature transcript sequences...'). premature.tx <- dna[anot.pre]. message('... now getting reverse complements of premature transcripts on the minus strand...'). premature.tx[names(premature.tx) %in% anot.pre[strand(anot.pre) == '-', ]$premature_group] <- reverseComplement(; premature.tx[names(premature.tx) %in% anot.pre[strand(anot.pre) == '-', ]$premature_group]; ). names(premature.tx) <- anot.pre$premature_group # paste0(anot.pre$premature_group, '_premature') # premature rna indicator. ### Dot plots ####; smoothDot <- function(s1, s2, w = 10) {. s1a <- sapply(; X = 1:(length(s1) - w + 1),; function(z) paste(s1[ z:(z + w - 1) ], collapse = ''); ). s2a <- sapply(;",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:7632,message,message,7632,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['message'],['message']
Integrability,"""Wrong whitelist provided"" Error Message",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682:33,Message,Message,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682,1,['Message'],['Message']
Integrability,"# Create premature transcript annotations ####; message('Creating premature transcript annotation...'). anot.pre <- split(anot, anot$transcript_id); anot.pre <- anot.pre[lengths(anot.pre) > 1] %>% range %>% unlist %>% sort # only consider transcripts with > 1 exon. anot.pre$transcript_range <- as.character(anot.pre); anot.pre$gene_id <- anot[match(names(anot.pre), anot$transcript_id), ]$gene_id. # collapse replicate pre-mature transcripts per gene...; names(anot.pre) <- anot.pre$premature_group <- sapply(; split(; names(anot.pre),; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ),; paste, collapse = ';'; )[; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ]. # ... need to convert GR to data.table before unique because unique method for GR class ignores metadata and rownames; anot.pre <- as.data.table(anot.pre) %>% unique %>% makeGRangesFromDataFrame(., keep.extra.columns = T); names(anot.pre) <- anot.pre$premature_group. ### Read human genome sequence ####; message('Loading genome sequence...'). dna <- readDNAStringSet(filepath = genome.fasta). # simplify chromosome names; names(dna) <- sapply(strsplit(names(dna), ' '), '[', 1). dna <- dna[chromosomes] # subset chrom 1-22, X, Y, MT. ### Read Gencode transcript sequences ####; gencode <- readDNAStringSet(gencode.tx.fasta); names(gencode) <- gsub(; pattern = '\\|.*', replacement = '',; x = names(gencode); ). ### Sample transcripts on + and - strand (and avoid premature transcripts with multiple mature counterparts for simplicity); anot.pre <- anot.pre[order(width(anot.pre), decreasing = F), ]. chosenOnesP <- anot.pre[; strand(anot.pre) == '+' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnesM <- anot.pre[; strand(anot.pre) == '-' & !grepl(';', anot.pre$premature_group) & anot.pre$prema",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:5692,message,message,5692,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['message'],['message']
Integrability,"## Description of bug and how to reproduce. Short version: the error message telling users that -l has to go before -1 and -2 doesn’t always seem to work. I think I found an issue with the error messages from Salmon (in particular, I think a certain error message isn’t always reported when it should be). Long version of the story: I ran salmon (v1.6.0, installed with conda on linux, run on bulk data, mm10 data, both my own reference and a precomputed one) with the command:. ```; salmon quant -i $index -1 $read1 -2 $read2 –o res -l A --posBias –-validateMapping; ```. Where $index is the index, $read1 and $read2 are the reads. And it crashed without throwing an error, outputting:. ```; Logs will be written to Salmon_out/res/logs; [2022-01-20 13:56:19.915] [jointLog] [info] setting maxHashResizeThreads to 52; [2022-01-20 13:56:19.915] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2022-01-20 13:56:19.915] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2022-01-20 13:56:19.915] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2022-01-20 13:56:19.915] [jointLog] [info] parsing read library format; ```. But no errors/no other outputs after that. I reran many times with slightly different settings, including different set of reads and a different reference with the same results, but only got an error when I ran: . ```; salmon quant -p 1 -i $index -1 $read1 -2 $read2 –o res_new -l OSR; ```. Which returned the error:. ```; [2022-01-20 14:39:44.578] [jointLog] [error] Failed to successfully parse any complete read libraries. Please make sure you provided arguments properly to -1, -2 (for paired-end libraries) or -r (for single-end libraries), and that the library format option (-l) *comes before* the read libraries.; ```. This error allowed me to fix the original command (running now, yay!) but I",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/736:69,message,message,69,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/736,3,['message'],"['message', 'messages']"
Integrability,"#449). Hi @s1corley<https://github.com/s1corley>. As @rob-p<https://github.com/rob-p> mentions, your paper could help assess different methodologies for quantification and also help optimize salmon further for QuantSeq. I would still like you to check if you have used salmon quant command line correctly for QuantSeq data analysis. Your paper briefly alludes to QuantSeq Forward in the Introduction section of the paper. The QuantSeq Forward kit has an oligo (dT) primer which contains the Illumina-specific Read 2 linker ... but the Methods section of your paper does not specify if you have used QuantSeq FWD or REV. Page 14 of the PDF from the Lexogen Website data analysis pipeline for QuantSeq FWD<https://www.bluebee.com/wp-content/uploads/2018/11/015UG108V0201-QuantSeq-Data-Analysis-Pipeline_2018-10-18.pdf> recommends using the below htseq command line. htseq-count -m intersection-nonempty -s yes -f bam -r pos $bam; $resource_dir/annotation.gtf > $bam_dir/read_counts.txt. QuantSeq is a stranded protocol. For the QuantSeq FWD pipeline the argument -s yes indicates; stranded in the sense orientation. For the QuantSeq REV pipeline -s reverse is used. Similar to the above htseq command line arguments, I think if you are using QuantSeq FWD, the libType argument from salmon quant should have been SF. One way I checked these with my datasets was to run the salmon quant command 3 times - once with libType A, once with libType SF and once with libType SR -- with QuantSeq FWD the estimated counts will be almost same with libType A and libType SF. I echo what @rob-p<https://github.com/rob-p> says - Congratulations once again on the paper. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/449?email_source=notifications&email_token=AC4A5AGWBAOLTI4MOFLAJNDQYQN7FA5CNFSM4JOIEHZ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEG3S5HQ#issuecomment-565653150>, or unsubscribe<http",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565684552:1950,protocol,protocol,1950,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565684552,1,['protocol'],['protocol']
Integrability,"&& ...) [with K = std::__cxx11::basic_string<char>&; F = densityCalculator(single_parser*, AlevinOpts<ProtocolT>&, std::mutex&, CFreqMapT&, std::atomic<long unsigned int>&, std::atomic<long unsigned int>&) [with ProtocolT = alevin::protocols::Chromium; single_parser = fastx_parser::FastxParser<fastx_parser::ReadSeq>; CFreqMapT = cuckoohash_map<std::__cxx11::basic_string<char>, unsigned int, BarcodeGroupStringHasher>]::<lambda(uint32_t&)>; Args = {int}; Key = std::__cxx11::basic_string<char>; T = unsigned int; Hash = BarcodeGroupStringHasher; KeyEqual = std::equal_to<std::__cxx11::basic_string<char> >; Allocator = std::allocator<std::pair<const std::__cxx11::basic_string<char>, unsigned int> >; long unsigned int SLOT_PER_BUCKET = 4ul]::<lambda(cuckoohash_map<std::__cxx11::basic_string<char>, unsigned int, BarcodeGroupStringHasher>::mapped_type&)>, int> (fn=..., key=..., this=<optimized out>); at /u/user/tmp/salmon/include/cuckoohash_map.hh:529; #15 upsert<std::__cxx11::basic_string<char>&, densityCalculator(single_parser*, AlevinOpts<ProtocolT>&, std::mutex&, CFreqMapT&, std::atomic<long unsigned int>&, std::atomic<long unsigned int>&) [with ProtocolT = alevin::protocols::Chromium; single_parser = fastx_parser::FastxParser<fastx_parser::ReadSeq>; CFreqMapT = cuckoohash_map<std::__cxx11::basic_string<char>, unsigned int, BarcodeGroupStringHasher>]::<lambda(uint32_t&)>, int> (fn=..., key=..., this=<optimized out>); at /u/user/tmp/salmon/include/cuckoohash_map.hh:554; #16 densityCalculator<alevin::protocols::Chromium> (parser=<optimized out>, aopt=..., ioMutex=..., freqCounter=...,; usedNumBarcodes=..., totNumBarcodes=...) at /u/user/tmp/salmon/src/Alevin.cpp:137; #17 0x0000000000ba4970 in std::execute_native_thread_routine (__p=<optimized out>); at ../../../.././libstdc++-v3/src/c++11/thread.cc:84; #18 0x00007fff7fbc7064 in start_thread (arg=0x7ffcf97e7700) at pthread_create.c:309; #19 0x00007fff7e95b62d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234:18271,Protocol,ProtocolT,18271,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234,4,"['Protocol', 'protocol']","['ProtocolT', 'protocols']"
Integrability,"**Describe the bug**; Build problem. . Centos 6.9's boost is too old for salmon. There are RPMs for 1.5.7 installed. The library files are in /usr/lib64 and the include files are in /usr/include/boost157. These all work and are employed by numerous other packages without issues. Using devtoolset-4 (for a recent enough compiler) and a freshly built cmake 3.1.3 this command:. `scl enable devtoolset-4 '~/bin/cmake -DBOOST_ROOT=/usr/lib64 ../CMakeLists.txt'; `; fails with . ```; -- Could NOT find Boost; BOOST_INCLUDEDIR = ; BOOST_LIBRARYDIR = ; Boost_FOUND = 0; CMake Error at CMakeLists.txt:346 (message):; Salmon cannot be compiled without Boost. ```; This:; `scl enable devtoolset-4 '~/bin/cmake -DBOOST_LIBRARYDIR=/usr/lib64 -DBOOST_INCLUDEDIR=/usr/include/boost157 ../CMakeLists.txt; `; fails with:. ```; BOOST_INCLUDEDIR = /usr/include/boost157; BOOST_LIBRARYDIR = /usr/lib64; Boost_FOUND = 0; CMake Error at CMakeLists.txt:346 (message):; Salmon cannot be compiled without Boost. ```; This::; `scl enable devtoolset-4 '~/bin/cmake -DBoost_NO_BOOST_CMAKE=BOOL:ON -DBOOST_LIBRARYDIR=/usr/lib64 -DBOOST_INCLUDEDIR=/usr/include/boost157 ../CMakeLists.txt'; `; fails the exact same way. Examined the CMakeLists.txt file, found the list of acceptable versions starts with 1.59.0. Crud. ; Tried modifying one line to:; ` find_package(Boost 1.57.0 COMPONENTS iostreams filesystem system thread timer chrono program_options); `; but it still failed. I am out of tricks. Is it really the case that Salmon cannot use 1.57.0?. Thanks.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236:599,message,message,599,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236,2,['message'],['message']
Integrability,"**Describe the bug**; I am trying to quantify long reads mapped using minimap2 and I am getting a large number of the following messages:. ```; [2018-09-10 12:42:32.972] [jointLog] [warning] CIGAR = 106c16M1D7M1D8M1D26M1D55M3D8M1D32M2I14M1I8M1I52M1D14M1I2M1I19M1I1M1I7M11D28M1D5M3I40M1D5M1I5M1I6M1I13M147c; [2018-09-10 12:42:32.972] [jointLog] [warning] (in update()) CIGAR string for read [e6b69e2f-1bf2-4fd5-bace-d4d213164026] seems inconsistent. It refers to non-existant positions in the read!. ```. **To Reproduce**; * Which version of salmon was used?; salmon version: salmon 0.11.3, minimap2 version: 2.9-r720; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Installed through bioconda.; * Which reference (e.g. transcriptome) was used?; Ensembl [cDNA collection](http://ftp.ensembl.org/pub/release-93/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz).; * Which read files were used?; Nanopore reads.; * Which which program options were used?; salmon quant -p {threads} -t {input.trs} -l SF -a {input.bam} -o {output.tsv_dir}. **Desktop (please complete the following information):**; Ubuntu 14.04.5 LTS. **Additional context**; I am wondering whether the issue is caused by the fact that minimap2 does not include sequences in the secondary alignments. The errors disappear if I filter for primary alignments only.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/289:128,message,messages,128,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/289,1,['message'],['messages']
Integrability,"**Describe the bug**; I followed every step of this tutorial to generate the index.; https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/; Instead of using the mouse genomic data, I used the human data (https://www.gencodegenes.org/human/release_33lift37.html).; I invoked the indexing with the following command: ; **salmon index -t gentrome.fa.gz -d decoys.txt -p 8 -i salmon_index --gencode**; In the beginning everything seems to run smoothly, but a couple minutes in different error messages appear:; **error: Cant write to a temporary file**; **error: Cant read the input file**; followed by **Segmentation fault** and then the algorithm exits. ; Nonetheless a directory with different files regarding the indexing is beeing created.; However when I run; **salmon quant -i salmon_index/ -l A -1 ../../patients/patient001/fastq/S0012_1.fastq.gz -2 ../../patients/patient001/fastq/S0012_2.fastq.gz --validateMappings -o transcripts_quant**. it tells me that **The index version file salmon_index/versionInfo.json doesn't seem to exist**. **To Reproduce**; I installed salmon via bioconda, version 1.1.0. **Desktop (please complete the following information):**; Its running on CentOS 7",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/503:507,message,messages,507,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/503,1,['message'],['messages']
Integrability,"**Describe the bug**; I tried to compile salmon following instructions. I downloaded the latest release (v1.10.1), and I also cloned the master branch at commit 1c3f6c014ce77ec593d5b37ee2bb0cf9feddf123 with the same result. In the newly created ""build"" folder, I run ""cmake .."" either with or without the flag specifying the location of the boost library (-DBOOST_ROOT=/usr/lib/x86_64-linux-gnu, as that's where I see several libboost_<something>.so files). I didn't use any other flag. In all cases, cmake ends without complaining. Then, I run ""make"", which proceeds for several minutes until it ends up printing the following final lines:. [ 99%] Building CXX object src/CMakeFiles/salmon.dir/BAMUtils.cpp.o; [100%] Linking CXX executable salmon; /usr/bin/ld: ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): in function `find_file_url':; open_trace_file.c:(.text+0xfef): warning: the use of `tempnam' is dangerous, better use `mkstemp'; during IPA pass: icf; lto1: internal compiler error: Segmentation fault; 0x7f0fa367051f ???; 	./signal/../sysdeps/unix/sysv/linux/x86_64/libc_sigaction.c:0; 0x7f0fa3657d8f __libc_start_call_main; 	../sysdeps/nptl/libc_start_call_main.h:58; 0x7f0fa3657e3f __libc_start_main_impl; 	../csu/libc-start.c:392; Please submit a full bug report,; with preprocessed source if appropriate.; Please include the complete backtrace with any bug report.; See <file:///usr/share/doc/gcc-11/README.Bugs> for instructions.; lto-wrapper: fatal error: /usr/bin/c++ returned 1 exit status; compilation terminated.; /usr/bin/ld: error: lto-wrapper failed; collect2: error: ld returned 1 exit status; make[2]: *** [src/CMakeFiles/salmon.dir/build.make:487: src/salmon] Error 1; make[1]: *** [CMakeFiles/Makefile2:603: src/CMakeFiles/salmon.dir/all] Error 2; make: *** [Makefile:166: all] Error 2. **To Reproduce**; That happened in an Ubuntu 22.04.2 LTS, with cmake version 3.22.1, GNU make 4.3, gcc 11.3.0, etc.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/860:1484,wrap,wrapper,1484,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/860,2,['wrap'],['wrapper']
Integrability,"**Hi all,; Just an update:; I also got same warning message (as @rbenel talk about it here) when creating index along with decoy sequences I took @kvittingseerup's advice and made a transcripts.fa file by gffread command. Here is my input files and commend:; All gtf and genome references were downloaded from GENCODE: GRCh38.primary_assembly.genome.fa.gz, gencode.v36.annotation.gtf (CHR) and gencode.v36.transcripts.fa.gz.; commends:; grep ""^>"" <(gunzip -c GRCh38.primary_assembly.genome.fa.gz) | cut -d "" "" -f 1 > decoys.txt; sed -i.bak -e 's/>//g' decoys.txt; cat salmon_transcripts.fa.gz GRCh38.primary_assembly.genome.fa.gz > gentrome.fa.gz; salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon-decoy-sa-index --gencode; warnings:**. [Step 1 of 4] : counting k-mers; [2020-12-26 10:47:50.823] [puff::index::jointLog] [warning] Entry with header [ENST00000473810.1|ENSG00000239255.1|OTTHUMG00000157482|OTTHUMT00000348942.1|AC007620.1-201|AC007620.1|25|processed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:50.973] [puff::index::jointLog] [warning] Entry with header [ENST00000603775.1|ENSG00000271544.1|OTTHUMG00000184300|OTTHUMT00000468575.1|AC006499.8-201|AC006499.8|23|processed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:52.758] [puff::index::jointLog] [warning] Entry with header [ENST00000632684.1|ENSG00000282431.1|OTTHUMG00000190602|OTTHUMT00000485301.1|TRBD1-201|TRBD1|12|TR_D_gene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:54.950] [puff::index::jointLog] [warning] Entry with header [ENST00000543745.1|ENSG00000255972.1|OTTHUMG00000168883|OTTHUMT00000401485.1|AC026333.1-201|AC026333.1|28|processed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:55.202] [puff::index::jointLog] [warning] Entry",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354991:52,message,message,52,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354991,1,['message'],['message']
Integrability,"**Hi all,; Just an update:; I also got same warning message (as @rbenel talk about it here) when creating index along with decoy sequences I took @kvittingseerup's suggestion and made a transcripts.fa file by gffread command. Here is my input files and commend:; All gtf and genome references were downloaded from GENCODE: GRCh38.primary_assembly.genome.fa.gz, gencode.v36.annotation.gtf (CHR), gencode.v36.transcripts.fa.gz.; commends:; grep ""^>"" <(gunzip -c GRCh38.primary_assembly.genome.fa.gz) | cut -d "" "" -f 1 > decoys.txt; sed -i.bak -e 's/>//g' decoys.txt; cat salmon_transcripts.fa.gz GRCh38.primary_assembly.genome.fa.gz > gentrome.fa.gz; salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon-decoy-sa-index --gencode; warnings:**; [Step 1 of 4] : counting k-mers; [2020-12-26 10:47:50.823] [puff::index::jointLog] [warning] Entry with header [ENST00000473810.1|ENSG00000239255.1|OTTHUMG00000157482|OTTHUMT00000348942.1|AC007620.1-201|AC007620.1|25|processed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:50.973] [puff::index::jointLog] [warning] Entry with header [ENST00000603775.1|ENSG00000271544.1|OTTHUMG00000184300|OTTHUMT00000468575.1|AC006499.8-201|AC006499.8|23|processed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:52.758] [puff::index::jointLog] [warning] Entry with header [ENST00000632684.1|ENSG00000282431.1|OTTHUMG00000190602|OTTHUMT00000485301.1|TRBD1-201|TRBD1|12|TR_D_gene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:54.950] [puff::index::jointLog] [warning] Entry with header [ENST00000543745.1|ENSG00000255972.1|OTTHUMG00000168883|OTTHUMT00000401485.1|AC026333.1-201|AC026333.1|28|processed_pseudogene|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 10:47:55.202] [puff::index::jointLog] [warning] Entr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354493:52,message,message,52,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354493,1,['message'],['message']
Integrability,"**Hi there,**. **So I'm trying to install Salmon-0.8.2 but I'm having a few issues. I should note upfront that I'm working on a cluster and therefore I do not have root privileges.** . **Anyway, when going through the build process I wasn't able to install boost using salmons flags, so I installed it independently. I was then able to make it to the 'make' stage, but the got to this point:**. [ 7%] Built target liblzma; [ 14%] Built target libbz2; [ 21%] Built target libdivsufsort; [ 29%] Built target liberal; [ 37%] Built target libgff; [ 38%] Performing build step for 'libbwa'; utils.c:33:18: fatal error: zlib.h: No such file or directory; #include <zlib.h>; ^; compilation terminated.; make[3]: *** [utils.o] Error 1; make[2]: *** [libbwa-prefix/src/libbwa-stamp/libbwa-build] Error 2; make[1]: *** [CMakeFiles/libbwa.dir/all] Error 2; make: *** [all] Error 2. **I resolved this by making a custom script which told make where to look for zlib:**. export C_INCLUDE_PATH=/users/work/jake/bin/zlib-1.2.11/; export CPLUS_INCLUDE_PATH=/users/work/jake/bin/zlib-1.2.11/; make. **Executing that script allowed me to progress a little but I'm now receiving the following error message:**. [ 7%] Built target liblzma; [ 14%] Built target libbz2; [ 21%] Built target libdivsufsort; [ 29%] Built target libcereal; [ 37%] Built target libgff; [ 38%] Performing build step for 'libbwa'; /bin/ld: cannot find -lz; collect2: error: ld returned 1 exit status; make[3]: *** [bwa] Error 1; make[2]: *** [libbwa-prefix/src/libbwa-stamp/libbwa-build] Error 2; make[1]: *** [CMakeFiles/libbwa.dir/all] Error 2; make: *** [all] Error 2. **I'm not the best command line user so my 'fixes' might not be the best approach. Still I'm not really sure how to approach this new error message. Google doesn't turn up much so any advice you could give it would be greatly appreciated.**",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141:1180,message,message,1180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141,2,['message'],['message']
Integrability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. **Describe the bug**; I installed latest version of salmon through git clone for trinityrnaseq. When i run trinity using a command ""perl Trinity --seqType fq --left reads_1.fq --right reads_2.fq --CPU 6 --max_memory 20G' I am getting a message to install salmon. kindly give me a solution for this. **To Reproduce**; Trinity Trinity-v2.8.5 requires salmon to be installed. Get it here: https://combine-lab.github.io/salmon/ at Trinity line 3870. Specifically, please provide at least the following information:. * Which version of salmon was used?; * How was salmon installed (compiled, downloaded executable, through bioconda)?; **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; iipr@iipr-ubuntu:~/trinityrnaseq-Trinity-v2.8.5$ perl Trinity --seqType fq --left reads_1.fq --right reads_2.fq --CPU 6 --max_memory 20G. ______ ____ ____ ____ ____ ______ __ __; | || \ | || \ | || || | |; | || D ) | | | _ | | | | || | |; |_| |_|| / | | | | | | | |_| |_|| ~ |; | | | \ | | | | | | | | | |___, |; | | | . \ | | | | | | | | | | |; |__| |__|\_||____||__|__||____| |__| |____/. Trinity-v2.8.5. Left read files: $VAR1 = [; 'reads_1.fq'; ];; Right read files: $VAR1 = [; 'reads_2.fq'; ];; Trinity version: Trinity-v2.8.5; ** NOTE: Latest version of Trinity is v2.8.6, and can be obtained at:; 	https://github.com/trinityrnaseq/trinityrnaseq/releases. Trinity Trinity-v2.8.5 requires salmon to be installed. Get it here: https://combine-lab.github.io/salmon/ at Trinity line 3870.; iipr@iipr-ubuntu:~/trinityrnaseq-Trinity-v2.8.5$ ^C. **Desktop (please complete the following information):**; - OS: Ubuntu; - Version18.04. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/452:322,message,message,322,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/452,1,['message'],['message']
Integrability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. The bug is primarily related to salmon, but I am using salmon to build an index for use with alevin-fry per the [alevin-fry tutorial](https://combine-lab.github.io/alevin-fry-tutorials/2021/improving-txome-specificity/). . **Describe the bug**; A clear and concise description of what the bug is. I have previously followed the steps outlined in the alevin-fry tutorial for a single sample and everything worked as expected. Now I am following the same steps but wrapped in a snakemake pipeline to process several samples and am running into issues building the index. Specifically, I am receiving the following error when my pipeline moves on the mapping reads step:. ```; Exception : [Error: The index version file /beevol/home/winklerc/projects/scifi_pipeline/scifi/ref/idx/complete_ref_lens.bin/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; alevin (sc-align) was invoked improperly.; ```. I have tried re-building the index, and have also tried reusing the index that I had previously built for the single sample run that previously worked. However, neither of those approaches fixed the above error. When I build the index I am able to generate all of the expected files and the file sizes match those of my previous (successful) index build, so I am not sure why I am getting an error that the `versionInfo.json` file is missing. **To Reproduce**; Steps and data to reproduce the behavior:. I followed the alevin-fry tutorial to generate a splici transcriptome, using the same [Human reference (GRCh38) dataset](https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz) provided by the tutorial. My snakemake rule to build the index uses the same commands outlined in the alevin-fry tutorial, and looks like this:. ```; rule build_idx: ; # build a splici (spliced + intron) index for alevin-fry; input:; fasta = ""{out_data}/ref/transcriptome/transcriptome",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:549,wrap,wrapped,549,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,1,['wrap'],['wrapped']
Integrability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. salmon. **Describe the bug**; A clear and concise description of what the bug is. Running `salmon index` on a HPC cluster (called from a trinity perl script). After a while salmon is only idling. In the stderr I see:. ```; Encountered FastxParser destructor while parser was still marked active (or while parsing threads were still active). Be sure to call stop() before letting FastxParser leave scope!; ```. The problem seems to be the available memory. On HPC systems one usually needs to specify a max amount of memory which is enforced (e.g. with ulimit). . If I give more memory to the job salmon finishes. . **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * Which reference (e.g. transcriptome) was used?; * Which read files were used?; * Which which program options were used?. Salmon 1.1 installed through conda. I guess any data will do to reproduce as long as the memory limitations ar small enough. **Expected behavior**; A clear and concise description of what you expected to happen. Would be good if salmon would exit with a better error message and a non-zero exit code in such a case. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. CentOS 7. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/484:1336,message,message,1336,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/484,1,['message'],['message']
Integrability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; Alevin; **Describe the bug**; A clear and concise description of what the bug is.; Reanalyzing published Drop-Seq data the alevin analysis results in drastically fewer barcodes accepted than the published dataset. Published dataset contains 3000 CBs for the specific sample (authors report that 70% of [these] putative cells from WT mice met QC criteria), alevin result contains 459 CBs.; A similar highly abbreviated CB result was obtained with reanalysis of SRR8889412. **To Reproduce**; Steps and data to reproduce the behavior:. Data used from Sample: https://www.ebi.ac.uk/ena/browser/view/SRR8889411; Publication: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6925218/#; Specific Sample: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3720936. Alevin was run using no special parameters with the --dropseq flags. The only significant protocol deviation was in index construction (see below). Specifically, please provide at least the following information:. * Which version of salmon was used?; v1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Salmon was run in stock docker container; * Which reference (e.g. transcriptome) was used?; Full decoy Index generated on Gencode M25 per Alevin Velocity tutorial with a k=17 (dataset has 50bp R2 Reads); Introns were extracted with 49bp flanking sequence. ; ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz. * Which read files were used?; Data used from Sample: https://www.ebi.ac.uk/ena/browser/view/SRR8889411; * Which which program options were used?; --dropseq -l ISR. **Expected behavior**; A clear and concise description of what you expected to happen.; Cell calls should be ballpark similar to published result (3000 original vs. 459 alevin). **Tar of Alevin Output directory**; [WT01_P7_WT_Cerebellum_alevin.output.tar.gz](https://github.com/COMBINE-lab/salmon",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/625:932,protocol,protocol,932,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/625,1,['protocol'],['protocol']
Integrability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; No; **Describe the bug**; Running salmon 0.11.3, quasi mode, with 192M of ram.; Salmon quasi mode aborted with following message:; processed 14,000,000 fragmentsntLog] [info] Automatically detected most likely library type as SR; hits: 108,161,934; hits per frag: 8.53594terminate called after throwing an instance of 'std::bad_alloc'; what(): std::bad_alloc; This happens when using a gffread-created transcripts.fa. Salmon built the index that have 309,566 targets. Do I just need more RAM? Or it is a bug.; ; More info as below:; [2018-10-24 11:14:15.505] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-10-24 11:14:15.505] [jointLog] [info] parsing read library format; [2018-10-24 11:14:15.505] [jointLog] [info] There is 1 library.; [2018-10-24 11:14:15.627] [jointLog] [info] Loading Quasi index; [2018-10-24 11:14:15.629] [jointLog] [info] Loading 32-bit quasi index; [2018-10-24 11:14:15.633] [stderrLog] [info] Loading Suffix Array; [2018-10-24 11:14:17.090] [stderrLog] [info] Loading Transcript Info; [2018-10-24 11:14:17.691] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-10-24 11:14:18.293] [stderrLog] [info] There were 309,566 set bits in the bit array; [2018-10-24 11:14:18.819] [stderrLog] [info] Computing transcript lengths; [2018-10-24 11:14:18.820] [stderrLog] [info] Waiting to finish loading hash; [2018-10-24 11:15:46.171] [jointLog] [info] done; [2018-10-24 11:15:46.171] [jointLog] [info] Index contained 309,566 targets; [2018-10-24 11:15:46.171] [stderrLog] [info] Done loading index. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used? 0.11.3; * How was salmon installed (compiled, downloaded executable, through bioconda)?. downloaded execitable. * Which reference (e.g. transcriptome) was used?; h",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/304:207,message,message,207,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/304,1,['message'],['message']
Integrability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; Salmon. **Describe the bug**; Unit test failure during `make test`. **To Reproduce**; Building this Dockerfile is enough to reproduce the error; ```; # Use Ubuntu as the base image; FROM ubuntu:latest. WORKDIR /pipeline. RUN apt-get update && \; apt-get install -y --no-install-recommends \; git ca-certificates make cmake libboost-all-dev build-essential \; libcurl4-openssl-dev libbz2-dev liblzma-dev unzip curl && \; git clone --branch v1.10.1 https://github.com/COMBINE-lab/salmon.git && \; cd salmon && mkdir build && cd build && \; cmake -DNO_IPO=TRUE -DBOOST_ROOT=/usr -DTBB_INSTALL_DIR=/usr \; -DCMAKE_INSTALL_PREFIX=/usr/local .. && \; make && make install && \; make test || true; ```. Specifically, please provide at least the following information:. * Which version of salmon was used? v0.10.1; * How was salmon installed (compiled, downloaded executable, through bioconda)? compiled; * Which reference (e.g. transcriptome) was used? none; * Which read files were used? none; * Which which program options were used? It was the unit test. **Expected behavior**; I expect the tests to pass. This seems like it might be related to #229 but maybe not.; I did try `./src/unitTests` and that passes. . **Desktop (please complete the following information):**; - I built the Dockerfile on MacOS. **Additional context**; The error log file says; ```; -- For unit tests, will set working directory to /pipeline/salmon/tests; ./unitTests: error while loading shared libraries: libtbb.so.12: cannot open shared object file: No such file or directory; CMake Error at /pipeline/salmon/cmake/UnitTests.cmake:8 (message):; Error running 127; ```; This is strange because the other tests (which pass) must need this `libtbb.so.12` too right?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/845:1696,message,message,1696,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/845,1,['message'],['message']
Integrability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; This bug is generated from Salmon. **Describe the bug**; To use Salmon, I installed windows subsystem for Linux (WLS), then newest Ubuntu, Anaconda, bioconda, and finally Salmon (via Bioconda) on my PC. However, when I run any order (making index or do quant), I get this error message:. salmon: /lib/x86_64-linux-gnu/libpthread.so.0: version `GLIBC_PRIVATE' not found (required by /home/plyric/anaconda3/share/salmon-0.8.1-0/bin/../lib/librt.so.1). I checked what this means and thought this is because this Ubuntu may not have GLIBC C++ library, so I followed some tutorial to (1) update my Ubuntu, and (2) install the newest GBLIC library, but the problem still persist. . However, if I use the exact same code on a HPCC, it actually works. **To Reproduce**; Steps and data to reproduce the behavior:; Totally following your index preparation tutorial like this:. grep ""^>"" <(gunzip -c TAIR10_chr_all.fas.gz) | cut -d "" "" -f 1 > decoys.txt; sed -i.bak -e 's/>//g' decoys.txt; cat Araport11_cdna_20240409.gz TAIR10_chr_all.fas.gz > gentrome.fasta.gz; salmon index -t gentrome.fasta.gz -d decoys.txt -p 12 -i salmon_index --gencode. Then the error pops:; salmon: /lib/x86_64-linux-gnu/libpthread.so.0: version `GLIBC_PRIVATE' not found (required by /home/plyric/anaconda3/share/salmon-0.8.1-0/bin/../lib/librt.so.1). If I manage to get the index using an HPCC and run local quant like this:; salmon quant -i Arabidopsis_index -l A -1 filtered_a234-f1_S10_L002_R1_001.fastq.gz -2 filtered_a234-f1_S10_L002_R2_001.fastq.gz --validateMappings -o test_transcripts_quant; Then same error pops. Specifically, please provide at least the following information:. * Which version of salmon was used?; It is very strange. I am supposed to get v1.10.3 by bioconda default, but -v order get the same error. So I don't know how to get my version. The conda list says ""0.8.1"" ; * How was salmon installed (compiled, downloaded e",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/927:364,message,message,364,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/927,1,['message'],['message']
Integrability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; alevin. **Describe the bug**; I am trying to use Alevin to quantify a single cell RNA-Seq 10x Genomics CHROMIUM dataset. I am using Salmon 0.10.2, and it does not produce the count matrix. The output folder contains nothing but the log files. Specifically, I get the following error:; `[2018-07-19 16:27:46.916] [alevinLog] [error] Barcode not found in frequency table`; The full messages are bellow. **To Reproduce**; Steps and data to reproduce the behavior:; I explain how to download the data and reproduce the issue in the following. Specifically, please provide at least the following information:; * Which version of salmon was used?; 0.10.2. * How was salmon installed (compiled, downloaded executable, through bioconda)?; conda config --append channels conda-forge; conda config --append channels bioconda; conda install salmon=0.10.2. * Which reference (e.g. transcriptome) was used?; I am interested only in the transposons. Therefore, I am using the ""canonical DNA sequences of the transposable elements from species in the genus Drosophila"", which are available from the [Bergman](https://github.com/bergmanlab/transposons) Lab. Specifically, I use [this](https://github.com/bergmanlab/transposons/blob/master/current/transposon_sequence_set.fa) fasta file. The first 3 lines are:; >FBte0000104; GTGACATATCCATAAGTCCCTAAGACTTAAGCATATGCCTACATACTAATACACTTACAA; CACATACACCCCAATACAACATACACTACTCCGGATGTACCCAACAGATACCAGATAAGA; In another study, I have successfully used Salmon to quantify transposon expression from bulk RNA-Seq data with a mapping rate of 2%, which is enough for the kind of analysis that I am interested in. * Which read files were used?; The [SRR6327122](https://trace.ncbi.nlm.nih.gov/Traces/sra/?run=SRR6327122) run. The fastq files can be downloaded in a couple of hours using the SRA Toolkit, e.g.,; `fastq-dump --split-files --gzip --outdir ./ SRR6327122`; The first few lines of the ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253:466,message,messages,466,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253,1,['message'],['messages']
Integrability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; alevin. **Describe the bug**; We have an adapted Celseq2 protocol, where read1 (42bp) is used as the sequencing read and read2 (also 42bp) contains (5' -> 3') the barcode (8bp), UMI (8bp), 26 remaining nt's. Alevin seems to run fine, but the quant matrix has a very low UMI count, which does not fit with the _MappedUMI.txt_ file or the reported alignment rate.; ; **To Reproduce**; First, I put the UMI in front of the barcode.; `zcat R2.fastq.gz | paste - - - - | awk '{print $1"" ""$2""\n""substr($3,9,8)substr($3,1,8)substr($3,17)""\n""$4""\n""$5}' | pigz -p8 > R2_Alevin.fq.gz`. then, I run Alevin with:; `salmon alevin -lA -i ref_genome/index/ --barcodeLength 8 --umiLength 8 --end 5 -1 fq/R2_Alevin.fq.gz -2 fq/R1.fastq.gz -p 8 --tgMap ref_genome/gencode.vM20.tx2gene.tsv -o alevin_out --dumpUmiGraph --dumpFeatures --dumpCsvCounts --whitelist BC.whitelist`. This seems to work: the library is 47M and the _filtered_cb_frequency.txt_ contains 43M assigned barcodes in total. The _MappedUmi.txt_ contains 18.5M UMIs, fitting perfectly with the reported alignment rate of ~40% (which is relatively low, but OK for this library). Also if I use the `--dumpfq` option, the barcodes and UMIs are nicely attached to the sequencing reads. Strangely, if I sum the entries in the CSV or binary quant matrix, I get ~3.75M reads. ; ; I was able to run the 10x PBMC4k example and there, the sum of the count matrix entries indeed fitted the reported UMI counts and mapping rate. . Specifically, please provide at least the following information:. * Which version of salmon was used?; salmon 0.13.1. * How was salmon installed (compiled, downloaded executable, through bioconda)?; downloaded executable and bioconda give the same result. * Which reference (e.g. transcriptome) was used?; mouse gencode vM20 (mm10). * Which read files were used?; adapted celseq2 protocol. * Which program options were used?; See above. **Expected ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361:143,protocol,protocol,143,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361,1,['protocol'],['protocol']
Integrability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; in Salmon bulk mode, while using the following commands to create an index:; A. Ingredients preparation:; grep ""^>"" genome.fa | cut -d "" "" -f 1 > ./decoys.txt; sed -i.bak -e 's/>//g' decoys.txt; cat Gencode_transcripts.fa genome.fa > ./gentrome.fa; B. index building:; salmon index -t gentrome.fa -d decoys.txt -p 12 -i salmon_index --gencode; **Describe the bug**; I got the following bug/error message:; Version Info: This is the most recent version of salmon.; salmon.sh: line 23: 37339 Illegal instruction (core dumped) salmon index -t gentrome.fa -d decoys.txt -p 12 -i salmon_index --gencode. Specifically, I was using the following version and files/options:. * Salmon 1.0.0; * through bioconda?; conda update salmon; * gencode.v27.transcripts.fa; * default. Any help to fix this bug would be appreciated!. Kind regards,; Jamal.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/458:482,message,message,482,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/458,1,['message'],['message']
Integrability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon; **Describe the bug**; A clear and concise description of what the bug is.; salmon quant is leading to segmentation fault when `--skipQuant` flag is set. The behavior may be annotation dependent.; **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used? :; * v1.9.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? ; * bioconda; * Which reference (e.g. transcriptome) was used?; * human hg38 [gencode v43 comprehensive](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_43/gencode.v43.primary_assembly.annotation.gtf.gz) produces the error; * human hg38 [gencode v43 basic](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_43/gencode.v43.basic.annotation.gtf.gz) works fine.; * Which read files were used?; * The issue is reproducible with multiple independent read files. Logs attached are from reads subsampled from [GSM7099349](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM7099349); * Which which program options were used?; * --skipQuant -l A. **Expected behavior**; A clear and concise description of what you expected to happen.; salmon quant finishes without seg fault with `--skipQuant`; **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; Terminal output when `--skipQuant` is on:; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/902:278,depend,dependent,278,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/902,1,['depend'],['dependent']
Integrability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon; **Describe the bug**; I used the default parameters to run salmon on mouse sample. But I got the warning:. `Detected a *potential* strand bias > 1% in an unstranded protocol check the file:`. **To Reproduce**; `""expected_format"": ""IU"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 10869138,; ""num_assigned_fragments"": 10869138,; ""num_frags_with_concordant_consistent_mappings"": 10212463,; ""num_frags_with_inconsistent_or_orphan_mappings"": 1088473,; ""strand_mapping_bias"": 0.5258466052704426,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 4842274,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 5370189,; ""SF"": 593930,; ""SR"": 494543,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0`. Specifically, please provide at least the following information:. * Which version of salmon was used? ; ""salmon_version"": ""0.14.1"". * How was salmon installed (compiled, downloaded executable, through bioconda)? bioconda. * Which reference (e.g. transcriptome) was used?; gencode mouse VM22. * Which read files were used?. Downloaded from sra（Just ordinary Illumina reads). * Which which program options were used?. ```; salmon quant -i $mm10_whole_index -l A \; -1 $fastq1 \; -2 $fastq2 \; -p 20 --validateMappings -o $output_whole; ```. **Expected behavior**; Why Strand bias is very high?. **Desktop (please complete the following information):**; Linux localhost.localdomain 3.10.0-957.el7.x86_64 #1 SMP Thu Nov 8 23:39:32 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/422:259,protocol,protocol,259,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/422,1,['protocol'],['protocol']
Integrability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; yes; **Describe the bug**; A clear and concise description of what the bug is.; I was going though the tutorial https://combine-lab.github.io/alevin-tutorial/2020/alevin-velocity/; using Alevin and scVelo. The filtering with ; scv.pp.filter_genes(adata, min_shared_counts = 30). gives the error bellow. Any advice?; **Error**; R[write to console]: Error in (function (object, connection, ascii = FALSE, xdr = TRUE, version = NULL, : ; unimplemented type 'char' in 'eval'. R[write to console]: In addition: ; R[write to console]: Warning message:. R[write to console]: call dbDisconnect() when finished working with a connection . ---------------------------------------------------------------------------; RRuntimeError Traceback (most recent call last); /primary/projects/mnp/tools/anaconda3/envs/alevin_env/lib/python3.7/copy.py in deepcopy(x, memo, _nil); 168 if reductor:; --> 169 rv = reductor(4); 170 else:. /primary/projects/mnp/tools/anaconda3/envs/alevin_env/lib/python3.7/site-packages/rpy2/rinterface_lib/sexp.py in __getstate__(self); 123 self.__sexp__._cdata,; --> 124 globalenv.__sexp__._cdata); 125 ). /primary/projects/mnp/tools/anaconda3/envs/alevin_env/lib/python3.7/site-packages/rpy2/rinterface_lib/_rinterface_capi.py in serialize(cdata, cdata_env); 412 if error_occured[0]:; --> 413 raise embedded.RRuntimeError(_geterrmessage()); 414 return res. RRuntimeError: Error in (function (object, connection, ascii = FALSE, xdr = TRUE, version = NULL, : ; unimplemented type 'char' in 'eval'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last); /primary/projects/mnp/tools/anaconda3/envs/alevin_env/lib/python3.7/copy.py in deepcopy(x, memo, _nil); 140 ; --> 141 d = id(x); 142 y = memo.get(d, _nil). SystemError: <built-in function id> returned a result with an error set. The above exception was the direct cause of the following ex",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/526:623,message,message,623,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/526,1,['message'],['message']
Integrability,"**_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1401,adapter,adapter,1401,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapter'],['adapter']
Integrability,"**tl;dr**: 3-tag sequencing methods for bulk RNA samples contain known sample indices and UMIs and thus resembles sc-RNA-seq read formats. Do you have a recommendation on how to use Salmon and / or Alevin to quantify gene expression for this data type?. Congratulations on the recent [alevin preprint](https://www.biorxiv.org/content/early/2018/10/24/335000)! The new algorithm to deduplicate UMIs looks awesome. I am wondering if you had a recommendation on how to leverage it for 3' tag sequencing of bulk samples. There are a number of protocols that focus on the 3' ends of transcripts to allow for cheap quantification of gene expression, e.g. - [BRB-seq](https://www.biorxiv.org/content/early/2018/01/30/256594); - [Drug-seq](https://www.nature.com/articles/s41467-018-06500-x); - [Quant-seq](https://www.lexogen.com/quantseq-3mrna-sequencing/). These methods combine conventional (known) sample-indices to label samples (or wells) with unique molecular identifiers (UMIs). (I found [one question on this topic](https://github.com/COMBINE-lab/salmon/issues/108) in the salmon issue tracker from back in 2016). Here is the Drug-seq approach, for example:. ![Drug-seq](https://media.springernature.com/lw900/springer-static/image/art%3A10.1038%2Fs41467-018-06500-x/MediaObjects/41467_2018_6500_Fig1_HTML.png). The resulting read data resembles that of single-cell approaches and requires deduplication of UMIs and quantification based on reads with a strong 3' bias. It seems analysis of this data could benefit a lot from the algorithms implemented in Alevin. Can this data be analyzed with Salmon and / or Alevin? Are there any pitfalls that I should be aware off?. Many thanks for any feedback - and thanks again for making these great tools available to the community.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/306:539,protocol,protocols,539,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/306,1,['protocol'],['protocols']
Integrability,"--noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in my final summarized table (after tximport). I got a colSum for all my samples and then checked the numbers for the transcripts and the decoys - this lead me to post my original question on this thread.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:1273,Adapter,Adapter,1273,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,1,['Adapter'],['Adapter']
Integrability,--splitseqV1 protocol barcode and umi is extra from R1?,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/774:13,protocol,protocol,13,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/774,1,['protocol'],['protocol']
Integrability,"-16 16:57:16.558] [jointLog] [info] Finished optimizer; [2021-04-16 16:57:16.558] [jointLog] [info] writing output. [2021-04-16 16:57:16.681] [jointLog] [info] Computing gene-level abundance estimates; [2021-04-16 16:57:16.775] [jointLog] [info] There were 77689 transcripts mapping to 26673 genes; [2021-04-16 16:57:16.775] [jointLog] [info] NOTE: We recommend using tximport (https://bioconductor.org/packages/release/bioc/html/tximport.html) for aggregating transcript-level salmon abundance estimates to the gene level. It is more versatile, exposes more features, and allows considering multi-sample information during aggregation.; [2021-04-16 16:57:16.911] [jointLog] [info] Aggregating expressions to gene level; [2021-04-16 16:57:17.077] [jointLog] [info] done; [2021-04-16 16:57:17.088] [jointLog] [warning] NOTE: Read Lib [[ Trim/1-2-intestines-LDC4673.filtered.R1.fq.gz, Trim/1-2-intestines-LDC4673.filtered.R2.fq.gz]] :. Detected a *potential* strand bias > 1% in an unstranded protocol check the file: Salmon_out/1-2-intestines-LDC4673/lib_format_counts.json for details; ```. However，when I try old version (0.9.1) or latest version (1.4.0), I got a normal mapping rate (77.1074%):. ```; [2021-04-20 10:08:58.047] [jointLog] [info] setting maxHashResizeThreads to 10; [2021-04-20 10:08:58.048] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-04-20 10:08:58.048] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-04-20 10:08:58.048] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-04-20 10:08:58.048] [jointLog] [info] parsing read library format; [2021-04-20 10:08:58.048] [jointLog] [info] There is 1 library.; [2021-04-20 10:08:58.145] [jointLog] [info] Loading pufferfish index; [2021-04-20 10:08:58.146] [jointLog] [info] Loading dense pufferfish index.; [2021-04-20 10:09:05.198] [joi",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/652:4025,protocol,protocol,4025,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/652,1,['protocol'],['protocol']
Integrability,"-4}"" --incompatPrior 1e-20 --biasSpeedSamp 1 --fldMax 1000 --fldMean 200 --fldSD 80 --forgettingFactor 0.65 --maxReadOcc 100 --numBiasSamples 2000000 --numAuxModelSamples 5000000 --numPreAuxModelSamples 1000000 --numGibbsSamples 0 --numBootstraps 0 --consensusSlack 0 --vbPrior 0.001 --sigDigits 3; ```. - `syslog`; ```; Aug 27 20:14:23 ip-172-31-16-139 kernel: [ 2134.447133] traps: salmon[7495] general protection ip:7ff9ce320dca sp:7ffd6e497020 error:0 in libtbb.so.2[7ff9ce2fe000+37000]; ```. **`salmon 0.11.2 run with: NativeSpecification --ntasks=1 --nodes=1 --mem-per-cpu=100000`**; - `scontrol show job 99`; ```; JobId=99 Name=g995_salmon_refinery_stemcellcommons_org; UserId=galaxy(1001) GroupId=users(100); Priority=4294901662 Account=(null) QOS=(null); JobState=COMPLETED Reason=None Dependency=(null); Requeue=1 Restarts=0 BatchFlag=1 ExitCode=0:0; RunTime=00:07:36 TimeLimit=UNLIMITED TimeMin=N/A; SubmitTime=2018-08-27T20:20:26 EligibleTime=2018-08-27T20:20:26; StartTime=2018-08-27T20:20:26 EndTime=2018-08-27T20:28:02; PreemptTime=None SuspendTime=None SecsPreSuspend=0; Partition=main AllocNode:Sid=ip-172-31-24-127:7975; ReqNodeList=(null) ExcNodeList=(null); NodeList=w21; BatchHost=w21; NumNodes=1 NumCPUs=1 CPUs/Task=1 ReqS:C:T=*:*:*; MinCPUsNode=1 MinMemoryNode=100000M MinTmpDiskNode=0; Features=(null) Gres=(null) Reservation=(null); Shared=OK Contiguous=0 Licenses=(null) Network=(null); Command=(null); WorkDir=/mnt/galaxy/tmp/job_working_directory/000/995; ```. - `Galaxy stderr`; ```; Fatal error: Exit code 139 (); ...; /mnt/galaxy/tmp/job_working_directory/000/995/tool_script.sh: line 50: 9700 Segmentation fault (core dumped) salmon quant --index ./index --libType U --unmatedReads ./single.fastq --output ./output --allowOrphans --ma 2 --mp 4 --go 5 --ge 3 --minScoreFraction 0.65 --threads ""${GALAXY_SLOTS:-4}"" --incompatPrior 1e-20 --biasSpeedSamp 1 --fldMax 1000 --fldMean 200 --fldSD 80 --forgettingFactor 0.65 --maxReadOcc 100 --numBiasSamples 2000000 --numAuxMo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416364238:4204,Depend,Dependency,4204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416364238,1,['Depend'],['Dependency']
Integrability,"-p modfiles/$PACKAGE_NAME. cd source/$PACKAGE_NAME/$VERSION; wget $LATEST_RELEASE -O - | tar -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message):; Could NOT find Iconv (missing: Iconv_LIBRARY); Call Stack (most recent call first):; /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE); /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindIconv.cmake:120 (find_package_handle_standard_args); CMakeLists.txt:362 (find_package). -- Configuring incomplete, errors occurred!; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeOutput.log"".; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeError.log"".; ```; I'm also attaching the full CMake logs. This is right at the edge of my knowledge, so I'm not 100% sure I got libiconv installed correctly. Compilation completed without error, and I added the bin, include, and lib directories to PATH, CPATH, and LD_LIBRARY_PATH, respectively. [CMakeError.log](https://github.com/COMBINE-lab/salmon/files/6665942/CMakeError.l",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:1994,message,message,1994,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,1,['message'],['message']
Integrability,".806405; [2021-05-20 11:35:04.117] [jointLog] [info] iteration = 400 | max rel diff. = 0.143529; [2021-05-20 11:35:04.611] [jointLog] [info] iteration = 500 | max rel diff. = 0.131881; [2021-05-20 11:35:05.124] [jointLog] [info] iteration = 600 | max rel diff. = 1.67827; [2021-05-20 11:35:05.631] [jointLog] [info] iteration = 700 | max rel diff. = 0.0151842; [2021-05-20 11:35:06.145] [jointLog] [info] iteration = 800 | max rel diff. = 0.135721; [2021-05-20 11:35:06.657] [jointLog] [info] iteration = 900 | max rel diff. = 0.0942774; [2021-05-20 11:35:06.882] [jointLog] [info] iteration = 945 | max rel diff. = 0.00880347; [2021-05-20 11:35:06.894] [jointLog] [info] Finished optimizer; [2021-05-20 11:35:06.894] [jointLog] [info] writing output . [2021-05-20 11:35:06.972] [jointLog] [warning] NOTE: Read Lib [[ /upload/uploads/files/public/1/Mice_A_batch2_1.fq.gz, /upload/uploads/files/public/1/Mice_A_batch2_2.fq.gz]] :. Detected a *potential* strand bias > 1% in an unstranded protocol check the file: /results/RNA-Seq/Mice_A_batch2/salmon_out/lib_format_counts.json for details. ```. I also run `STAR` alignment and `htseq-count` on the same sample to quantify expression at the gene level, where the alignment rate is high and quantification is ok:. ```; RNA Alignment Statistics for Mice_A_batch2. Started job on |	May 20 06:25:05; Started mapping on |	May 20 06:25:42; Finished on |	May 20 10:46:09; Mapping speed, Million of reads per hour |	37.44. Number of input reads |	162499486; Average input read length |	300; UNIQUE READS:; Uniquely mapped reads number |	141917701; Uniquely mapped reads % |	87.33%; Average mapped length |	298.28; Number of splices: Total |	128444547; Number of splices: Annotated (sjdb) |	127401836; Number of splices: GT/AG |	127633760; Number of splices: GC/AG |	629527; Number of splices: AT/AC |	35900; Number of splices: Non-canonical |	145360; Mismatch rate per base, % |	0.28%; Deletion rate per base |	0.01%; Deletion average length |	2.29; Insertion ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/661:7128,protocol,protocol,7128,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/661,1,['protocol'],['protocol']
Integrability,"/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:1583,adapter,adapter,1583,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,1,['adapter'],['adapter']
Integrability,"/build/CMakeFiles/progress.marks; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/Makefile2 all; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libcereal.dir/build.make CMakeFiles/libcereal.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libcereal.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libcereal.dir/build.make CMakeFiles/libcereal.dir/build; make[2]: Nothing to be done for `CMakeFiles/libcereal.dir/build'.; [ 8%] Built target libcereal; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib && ./configure --enable-shared=no --without-libcurl --prefix=/Users/gabriel/Projects/salmon-0.13.1/external/install LDFLAGS= CFLAGS= CC=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc CXX=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++; checking for a BSD-compatible install... /usr/local/bin/g",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:1410,depend,depend,1410,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,1,['depend'],['depend']
Integrability,"/conda/core/subdir_data.py"", line 210, in load; _internal_state = self._load(); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 375, in _load; raw_repodata_str = fetch_repodata_remote_request(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/subdir_data.py"", line 701, in fetch_repodata_remote_request; resp = session.get(join_url(url, filename), headers=headers, proxies=session.proxies,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 542, in get; return self.request('GET', url, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 529, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/sessions.py"", line 645, in send; r = adapter.send(request, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 413, in send; conn = self.get_connection(request.url, proxies); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/requests/adapters.py"", line 308, in get_connection; raise InvalidProxyURL(""Please check proxy URL. It is malformed""; requests.exceptions.InvalidProxyURL: Please check proxy URL. It is malformed and could be missing the host. `$ /usr/local/bin/conda install salmon`. environment variables:; CIO_TEST=<not set>; CONDA_ROOT=/usr/local/Caskroom/miniforge/base; CURL_CA_BUNDLE=<not set>; INFOPATH=/opt/homebrew/share/info:; MANPATH=/opt/homebrew/share/man::; PATH=/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr; /sbin:/sbin; REQUESTS_CA_BUNDLE=<not set>; SSL_CERT_FILE=<not set>; all_proxy=<set>. active environment : None; user config file : /Users/Benjamin/.condarc; populated config files : /usr/local/Caskroom/miniforge/base/.condarc; conda version : 4.12.0; conda-build version : not installed; python version : 3.9.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:4522,adapter,adapters,4522,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['adapter'],['adapters']
Integrability,"0"",; ""numPreAuxModelSamples"": ""1000000"",; ""numGibbsSamples"": ""0"",; ""numBootstraps"": ""0"",; ""vbPrior"": ""0.001"",; ""auxDir"": ""aux_info""; }; ``` . **Expected behavior**; For `salmon quant` to run to completion. **Desktop (please complete the following information):**; ```; Ubuntu Linux; Linux ip-172-31-24-127.ec2.internal 3.13.0-100-generic #147-Ubuntu SMP Tue Oct 18 16:48:51 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux; Distributor ID:	Ubuntu; Description:	Ubuntu 14.04.5 LTS; Release:	14.04; Codename:	trusty; ```. **Additional context**; - This SLURM cluster is managed by [Galaxy Cloudman](https://galaxyproject.org/cloudman/), and my installation of Salmon is currently constrained to a conda install. . - I've fiddled with many different CPU/Memory requirements for each of these `salmon` jobs I've run and have only had successful runs while using a single thread on a single node (`--ntasks=1 --nodes=1`), but even then there were segfaults observed intermittently. - The current Galaxy Tool wrapper for Salmon runs `salmon index ... && salmon quant ...` for every input fastq by default, but I've also generated and pointed `salmon quant` to a common index and have observed the same segfault behavior. I've also tried out the `--perfectHash` flag in both of these scenarios to no avail. - I have the ability to specify/wrap another version of Salmon to be compatible with Galaxy if the thought is that a more recent release could help. - I'm happy to provide any context past this that could help solve the issue!. - Also, I lack any biological insight so I'll ping my colleague @gmnelson for backup in that space. **Terminal Output**; <details>; <summary>Example Output</summary>; <br>. ```; Fatal error: Exit code 139 (); Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [2018-08-16 19:42:",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271:2385,wrap,wrapper,2385,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271,1,['wrap'],['wrapper']
Integrability,"0.4.2/src/merge_files.cc(17):; /tmp/Salmon/0.4.2/intel-2015a/salmon-0.4.2/include/merge_files.hpp(21): catastrophic error: cannot open source file ""jellyfish/err.hpp""; #include <jellyfish/err.hpp>; ^. compilation aborted for /tmp/Salmon/0.4.2/intel-2015a/salmon-0.4.2/src/merge_files.cc (code 4); make[2]: *** [src/CMakeFiles/salmon_core.dir/merge_files.cc.o] Error 4; ```. This is weird, because the correct `include` directory is shown in the compiler command, and the file is there!. Here's my patch. Any idea what may be wrong with it, or which different approach I could try to get this to work?; I also tried using the `2.1.3.tar.gz` tarball from GitHub, but after adding `autoreconf -i` to the `CONFIGURE_COMMAND`, this leads to the same problem. ``` diff; --- salmon-0.4.2/CMakeLists.txt.orig 2015-06-15 02:31:09.000000000 +0200; +++ salmon-0.4.2/CMakeLists.txt 2015-08-18 21:13:29.684010359 +0200; @@ -357,14 +366,14 @@; message(""==================================================================""); ExternalProject_Add(libjellyfish; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; - URL ftp://ftp.genome.umd.edu/pub/jellyfish/jellyfish-2.1.3.tar.gz; - SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.1.3; + URL https://github.com/gmarcais/Jellyfish/releases/download/v2.2.3/jellyfish-2.2.3.tar.gz; + SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.2.3; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; - CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.1.3/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CXXFLAGS=${JELLYFISH_CXX_FLAGS}; + CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/jellyfish-2.2.3/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CXXFLAGS=${JELLYFISH_CXX_FLAGS}; BUILD_COMMAND ${MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CXXFLAGS=${JELLYFISH_CXX_FLAGS}; BUILD_IN_SOURCE 1; INSTALL_COMMAND make install && ; - cp config.h <INST",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/11:1397,message,message,1397,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/11,1,['message'],['message']
Integrability,"022-05-13 03:02:19.507] [jointLog] [info] iteration = 400 | max rel diff. = 5.00889; [2022-05-13 03:02:20.812] [jointLog] [info] iteration = 500 | max rel diff. = 10.9087; [2022-05-13 03:02:22.073] [jointLog] [info] iteration = 600 | max rel diff. = 0.162723; [2022-05-13 03:02:23.316] [jointLog] [info] iteration = 700 | max rel diff. = 0.125884; [2022-05-13 03:02:24.647] [jointLog] [info] iteration = 800 | max rel diff. = 0.611449; [2022-05-13 03:02:26.020] [jointLog] [info] iteration = 900 | max rel diff. = 0.0687607; [2022-05-13 03:02:27.302] [jointLog] [info] iteration = 1,000 | max rel diff. = 0.144642; [2022-05-13 03:02:28.620] [jointLog] [info] iteration = 1,100 | max rel diff. = 0.0139885; [2022-05-13 03:02:29.874] [jointLog] [info] iteration = 1,200 | max rel diff. = 0.053712; [2022-05-13 03:02:31.161] [jointLog] [info] iteration = 1,300 | max rel diff. = 0.0312546; [2022-05-13 03:02:32.489] [jointLog] [info] iteration = 1,400 | max rel diff. = 0.107944; [2022-05-13 03:02:32.656] [jointLog] [info] iteration = 1,414 | max rel diff. = 0.00665317; [2022-05-13 03:02:32.664] [jointLog] [info] Finished optimizer; [2022-05-13 03:02:32.665] [jointLog] [info] writing output . [2022-05-13 03:02:32.905] [jointLog] [warning] NOTE: Read Lib [[ /fastp_6BE_1.fq.gz, /fastp_6BE_2.fq.gz]] :. Detected a *potential* strand bias > 1% in an unstranded protocol check the file: sample6BE.salmon/lib_format_counts.json for details. This is the lib_format_counts.json details . ""read_files"": ""[ /fastp_6BE_1.fq.gz, /fastp_6BE_2.fq.gz]"",; ""expected_format"": ""IU"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 27069942,; ""num_assigned_fragments"": 27069942,; ""num_frags_with_concordant_consistent_mappings"": 25715904,; ""num_frags_with_inconsistent_or_orphan_mappings"": 1666158,; ""strand_mapping_bias"": 0.0481568915485141,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 1238398,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 24477506,; ""SF"": 981192,; ""SR"": 684966,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }. Thanks",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775:3456,protocol,protocol,3456,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775,1,['protocol'],['protocol']
Integrability,"1) So `--celseq2` isn't there, I had initially checked here, to make sure that there wasn't something wrong with my command.. ; ```; alevin; ==========; salmon-based processing of single-cell RNA-seq data. alevin options:. mapping input options:; -l [ --libType ] arg Format string describing the library ; type; -i [ --index ] arg salmon index; -r [ --unmatedReads ] arg List of files containing unmated reads ; of (e.g. single-end reads); -1 [ --mates1 ] arg File containing the #1 mates; -2 [ --mates2 ] arg File containing the #2 mates. alevin-specific Options:; --noDedup Stops the pipeline after CB sequence ; correction and quasi-mapping reads.; --dropseq Use DropSeq Single Cell protocol for ; the library; --chromium Use 10x chromium v2 Single Cell ; protocol for the library.; --gemcode Use 10x gemcode v1 Single Cell protocol; for the library.; --whitelist arg File containing white-list barcodes; --noQuant Don't run downstream barcode-salmon ; model.; --naive Run Gene level naive deduplication; --noSoftMap Don't use soft-assignment for quant ; instead do hard-assignment.; --mrna arg path to a file containing mito-RNA ; gene, one per line; --rrna arg path to a file containing ribosomal ; RNA, one per line; --useCorrelation Use pair-wise pearson correlation with ; True barcodes as a feature for ; white-list creation.; --dumpfq Dump barcode modified fastq file for ; downstream analysis by using coin toss ; for multi-mapping.; --debug Enabling this mode mode will try to ; ignore segfaults based on no whitelist ; mapping or no whitelist deduplicated ; count; --dumpBfh dump the big hash with all the barcodes; and the UMI sequence.; --dumpFeatures Dump features for whitelist and ; downstream analysis.; --dumpCsvCounts Dump cell v transcripts count matrix in; csv format.; --lowRegionMinNumBarcodes arg (=200) Minimum Number of CB to use for ; learning Low confidence region ; (Default: 200).; --maxNumBarcodes arg (=100000) Maximum allowable limit to process the ; cell barcodes.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443517536:687,protocol,protocol,687,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443517536,3,['protocol'],['protocol']
Integrability,"1.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0""); if (NOT BOOST_RECONFIGURE); -find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); +set(BOOST_INCLUDEDIR ""/usr/include/boost169""); +set(BOOST_LIBRARYDIR ""/usr/lib64/boost169""); +set(Boost_FOUND 1); +; message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); @@ -571,7 +574,22 @@; endif(); ; ## Try and find TBB first; -find_package(TBB 2018.0 COMPONENTS tbb tbbmalloc tbbmalloc_proxy); +if(DEFINED ENV{ROOT_LIBTBB}); + message(""ROOT_LIBTBB in env""); + set(ROOT_LIBTBB ); + set(TBB_DIR $ENV{ROOT_LIBTBB}); + set(TBB_INCLUDE_DIRS ${TBB_DIR}/include); + set(TBB_INCLUDE_DIR ${TBB_DIR}/include); + set(TBB_LIBRARY_DIRS ${TBB_DIR}/lib); + set(TBB_LIBRARY ${TBB_DIR}/lib); + set(TBB_LIB_DIR ${TBB_DIR}/lib); + set(TBB_VERSION ""2019.6""); + set(TBB_FOUND TRUE); +else(); + message(""ROOT_LIBTBB NOT in env""); + find_package(TBB 2018.0 COMPONENTS tbb tbbmalloc tbbmalloc_proxy); +endif(); +; ; if (${TBB_FOUND}); if (${TBB_VERSION} VERSION_GREATER_EQUAL 2018.0); @@ -696,7 +714,19 @@; #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""); ; -find_package(libgff); +if(DEFINED ENV{ROOT_LIBGFF}); + message(""ROOT_LIBGFF in env""); + set(LIBGFF_DIR $ENV{ROOT_LIBGFF}); + set(LIBGFF_INCLUDE_DIRS ${LIBGFF_DIR}/include); + set(LIBGFF_INCLUDE_DIR ${LIBGFF_DIR}/include); + set(LIBGFF_LIBRARY_DIRS ${LIBGFF_DIR}/lib); + set(LIBGFF_LIBRARY ${LIBGFF_DIR}/lib); + set(LIBGFF_LIB_DIR ${LIBGFF_DIR}/lib); + set(LIBGFF_FOUND TRUE); +else(); + message(""ROOT_LIBGFF NOT in env""); + find_package(libgff); +endif(); if(NOT LIBGFF_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); @@ -739,7 +769,14 @@; endif(); ; find_package(CURL); -find_package(libstadenio); +if(DEFINED ENV{ROO",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460:4073,message,message,4073,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460,1,['message'],['message']
Integrability,"1.0/cd14_monocytes](url), with the 10x v1 wrapper, the initialization seems to go smoothly then Alevin produces the following:. ```; [2018-09-13 11:41:47.586] [jointLog] [info] Computed 0 rich equivalence classes for further processing; [2018-09-13 11:41:47.586] [jointLog] [info] Counted 0 total reads in the equivalence classes ; [2018-09-13 11:41:47.593] [jointLog] [warning] Only 0 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2018-09-13 11:41:47.593] [jointLog] [warning] Something seems to be wrong with the calculation of the mapping rate. The recorded ratio is likely wrong. Please file this as a bug report. [2018-09-13 11:41:47.593] [jointLog] [info] Mapping rate = 0%; ```. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:; A downloaded binary Salmon v0.11.2 was executed using the v1 wrapper script compiled locally in a Salmon specific Conda environment. The GRCh38.p12 reference was used. Dataset is linked above in bug description. . Full command used:; `~/bin/salmon/scripts/v1_10x/run.sh salmon alevin -l ISR -1 read-I1_*.fastq.gz -2 read-RA_*.fastq.gz -r read-I1_*.fastq.gz --gemcode -i ../../../index_15_pc -p 10 -o ../../alevin_15_pc --tgMap ../../../txp2gene.tsv --dumpCsvCounts --dumpFeatures --end 5 --umiLength 5 --barcodeLength 14; `; Full terminal output:. ```; (Salmonenv) @compute-1-16: ~/Documents/PBMCStem/cd14/fastqs/flowcell1 $ ~/bin/salmon/scripts/v1_10x/run.sh salmon alevin -l ISR -1 read-I1_*.fastq.gz -2 read-RA_*.fastq.gz -r read-I1_*.fastq.gz --gemcode -i ../../../index_15_pc -p 10 -o ../../alevin_15_pc --tgMap ../../../txp2gene.tsv --dumpCsvCounts --dumpFeatures --end 5 --umiLength 5 --barcodeLength 14; TEMPDIR is /tmp/tmp.fyLlOm2tjU; Running command [salmon alevin -l ISR -1 read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz re",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/294:1132,wrap,wrapper,1132,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/294,1,['wrap'],['wrapper']
Integrability,"10; ```; It takes a bit to finish and once done I can do:. List the fasta headers of the decoy sequences; ```; head decoys.txt ; GL456210.1; chrX; chrY; GL456221.1; JH584304.1; ```. While this shows the the new hybrid (genome + transcriptome) fasta file which contains the decoy sequences from the genome, concatenated with the transcriptome (`gentrome.fa`) for a total of 119414 sequences.; ```; zcat gentrome.fa | grep ""^>"" | wc -l; gzip: gentrome.fa: decompression OK, trailing garbage ignored; 119414; ```. To create a salmon index do the following:; ```; salmon index \; -t /no_backup/indexes/salmon/mm10/gentrome.fa \; -i /no_backup/indexes/salmon/mm10 \; -d /no_backup/indexes/salmon/mm10/decoys.txt \; -k 28 --threads 6; ```; The author of `salmon` find that a *k* of 31 seems to work well for reads of 75bp or longer, but recommend considering a smaller *k* if you plan to deal with shorter reads. So I picked `28` cause I have 50bp SE. After the job starts I get this error message:; ```; Version Info: This is the most recent version of salmon.; [2021-12-24 17:32:49.324] [jLog] [info] building index; out : /no_backup/indexes/salmon/mm10; [2021-12-24 17:32:49.326] [puff::index::jointLog] [info] Running fixFasta. [Step 1 of 4] : counting k-mers; [2021-12-24 17:32:49.337] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000177564.1], had length less than equal to the k-mer length of 28 (perhaps after poly-A clipping); [2021-12-24 17:32:49.337] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000196221.1], had length less than equal to the k-mer length of 28 (perhaps after poly-A clipping). # [omissis]. [2021-12-24 17:32:57.019] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000178811.1], had length less than equal to the k-mer length of 28 (perhaps after poly-A clipping). [2021-12-24 17:32:57.126] [puff::index::jointLog] [warning] Removed 2279 transcripts that were sequence duplicates of indexed transcripts.; [2021-12-24 17:32:57.126",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731:2346,message,message,2346,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731,1,['message'],['message']
Integrability,"12; approximateContigTotalLength: 132160289; counters for complex kmers:; (prec>1 & succ>1)=181344 | (succ>1 & isStart)=714 | (prec>1 & isEnd)=800 | (isStart & isEnd)=42; contig count: 2077595 element count: 297242564 complex nodes: 182900; # of ones in rank vector: 2077594; [2021-12-31 11:28:32.554] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.; [2021-12-31 11:28:32.554] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory /no_backup/indexes/salmon/mm10_gencode; size = 297242564; -----------------------------------------; | Loading contigs | Time = 135.18 ms; -----------------------------------------; size = 297242564; -----------------------------------------; | Loading contig boundaries | Time = 61.18 ms; -----------------------------------------; Number of ones: 2077594; Number of ones per inventory item: 512; Inventory entries filled: 4058; 2077594; [2021-12-31 11:28:33.532] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2021-12-31 11:28:33.566] [puff::index::jointLog] [info] contig count for validation: 2,077,594; [2021-12-31 11:28:34.693] [puff::index::jointLog] [info] Total # of Contigs : 2,077,594; [2021-12-31 11:28:34.693] [puff::index::jointLog] [info] Total # of numerical Contigs : 2,077,594; [2021-12-31 11:28:34.787] [puff::index::jointLog] [info] Total # of contig vec entries: 13,003,859; [2021-12-31 11:28:34.787] [puff::index::jointLog] [info] bits per offset entry 24; [2021-12-31 11:28:35.409] [puff::index::jointLog] [info] Done constructing the contig vector. 2077595; [2021-12-31 11:28:36.870] [puff::index::jointLog] [info] # segments = 2,077,594; [2021-12-31 11:28:36.870] [puff::index::jointLog] [info] total length = 297,242,564; [2021-12-31 11:28:36.999] [puff::index::jointLog] [info] Reading the reference files ...; [2021-12-31 11:28:38.719] [puff::index::jointLog] [info] positional integer width = 29; [2021-12-31 11:28:38.719] [puff::inde",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883:2840,wrap,wrapping,2840,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883,1,['wrap'],['wrapping']
Integrability,"1:HH577BCX2:1:1101:1900:1954; GAGACTTTCTAGTCGATCTACTGCCC; +; GGGGGIIIIIGGGGIGIIIIIIIIII; ```. example of r2.fq:. ```; @D00323:881:HH577BCX2:1:1101:1815:1951; AGGTTGCAGTGAGCTGAGATCGTGCCACTGCACTCTAGCCACCACACCTGGCTAATTTTTGTATTTTTAAGTAGAGACAGAGTTTCGCTATGTTGGCCAG; +; AAA<GGGGA<G.GAGAGA.GGAGAGG.G.GGAAGGG.<.<GGGGGGIIGGGGAGGAGGAGGIIA.AAGAGGIGGAG.<AG.AGGGGAAGGGGGIIGGAG.; @D00323:881:HH577BCX2:1:1101:1963:1952; TAATACCGCTTTAGCTACATCTCAGATCTGGGTAAGTCATGTCTGCATTTTCAATAATTTCATTTTTTAAACTTCTACCTTAATTCTGATGTTTACTCAT; +; GAGGAGGGGAGGIGGGGGGGGIIGGGGGIIGIIGGGGGGGGGGGGGGGGIIIIGIIGGIIGGAGIIIIIGGGGIGGAGAGIIIGGGGGGGIIIIGGGIII; @D00323:881:HH577BCX2:1:1101:1900:1954; GCTTCATATAGTCTTACCTTTCTGAGGACCAATTTGGCTGAATTCTCTGCTTTCTAATCTGACTCCTTATGGGGGATCCCTGCTATAGAGATGTAGACCA; +; GGAGAGGGGAGGIIIGGGIGIIIIIIGIGIIGGGIIIIIIIGGGGGGGIGGGGGGGGGGGGGGIIGIGGGGIGGGAGGIGIGIGGGGGGIGGGIIGGIGG; ```. example of `known_cb.txt`:. ```; GGATAGGGTCATAGCT; GGATAGGGTTAGAGAT; GGATAGGGTTGCCTGG; GGATAGGGTACGCAAG; GGATAGGGTAACGGAC; GGATAGGGTCAACAGG; GGATAGGGTAACGGCA; GGATAGGGTTTGTCTT; GGATAGGGTGCTAGTT; GGATAGGGTACGACCC; ```. According to the documentation, `dumpfq` will output the reads to `stdout`, and here is the content of `alevin_out/corrected_r2.fq`:. ```; Version Info: This is the most recent version of Salmon.; Sequence-Size 17greater than specified 16.; Please report the issue on Github.; ```. In addition, we have some protocol under development, where CBs/UMIs are not in the read1.fq and read2.fq. They are rather in the index reads from illumina (i5 and i7). After calling `bcl2fastq`, we normally get 4 fastqs for each sample:. ```; R1.fastq; R2.fastq; I1.fastq; I2.fastq; ```. Both `R1.fastq` and `R2.fastq` contain important gene/genome information, it is the combination of the sequence in `I1.fastq` and `I2.fastq` that define cells. Is this something that `alevin` might support in future. In this case, if I know exact the sequence of I1 and I2, what the `whitelist.txt` file should look like?. Thank you!. Regards,; Xi",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/291:2124,protocol,protocol,2124,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/291,1,['protocol'],['protocol']
Integrability,"1bf67b581cb6d3d83ae1b8d7885c868b7ab634bbf86448889fcc246b9e65374b79270f6d11d5a71ac6335910fcda2b1b9e86bcafe1ae3ae89f; [2020-07-04 15:10:22.800] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers; [2020-07-04 15:11:07.094] [puff::index::jointLog] [info] ntHll estimated 2630714644 distinct k-mers, setting filter size to 2^36; error: Can't open a temporary file; error: Can't read the input file; [2020-07-04 15:34:24.273] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory /scratch/jl2e19/salmon_index; size = 0; -----------------------------------------; | Loading contigs | Time = 84.402 us; -----------------------------------------; size = 0; -----------------------------------------; | Loading contig boundaries | Time = 30.909 us; -----------------------------------------; Number of ones: 0; Number of ones per inventory item: 512; Inventory entries filled: 1; [2020-07-04 15:34:24.273] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2020-07-04 15:34:24.273] [puff::index::jointLog] [info] contig count for validation: 0; [2020-07-04 15:34:24.274] [puff::index::jointLog] [info] Total # of Contigs : 0; [2020-07-04 15:34:24.274] [puff::index::jointLog] [info] Total # of numerical Contigs : 0; [2020-07-04 15:34:24.274] [puff::index::jointLog] [info]; Total # of segments we have position for : 0; [2020-07-04 15:34:24.277] [puff::index::jointLog] [info] total contig vec entries 0; [2020-07-04 15:34:24.277] [puff::index::jointLog] [info] bits per offset entry 0; [2020-07-04 15:34:24.277] [puff::index::jointLog] [info] there were 0 equivalence classes; [2020-07-04 15:34:24.278] [puff::index::jointLog] [info] # segments = 0; [2020-07-04 15:34:24.278] [puff::index::jointLog] [info] total length = 0; /var/spool/torque/mom_priv/jobs/9244742.blue101.SC: line 23: 23870 Segmentation fault /home/jl2e19/.conda/envs/SALMON/bin/salmon index -t ./gentrome.fa.gz -d ./decoys.txt -p 12 -i /",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/543:16642,wrap,wrapping,16642,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/543,1,['wrap'],['wrapping']
Integrability,"303] [jointLog] [info] There is 1 library.; [2021-05-19 18:46:25.429] [jointLog] [info] Loading pufferfish index; [2021-05-19 18:46:25.429] [jointLog] [info] Loading dense pufferfish index.; [2021-05-19 18:46:27.087] [jointLog] [info] done; [2021-05-19 18:46:27.087] [jointLog] [info] Index contained 141,069 targets; [2021-05-19 18:46:32.618] [jointLog] [info] Number of decoys : 0; [2021-05-19 18:46:33.428] [jointLog] [info] Automatically detected most likely library type as IU. [2021-05-19 18:49:27.444] [jointLog] [error] . [2021-05-19 18:49:27.506] [jointLog] [error] Processing reads : Error reading from the FASTA/Q stream. Minimum return code for left and right read was (-2). Make sure the file is valid. ```; For rabbitQC's log; ```; Detecting adapter sequence for read1...; CCCAGCCATAACACAGTATCAAACTCCACTATTTGTCTGATCCGTACTTATTACAGCCGT. Detecting adapter sequence for read2...; CCAACTTGGTCTACAAGACGCCACATCCCCTATTATAGAAGAGCTAATAAATTTCCATGA. Read1 before filtering:; total reads: 44178187; total bases: 2140649565; Q20 bases: 1899503304(88.7349%); Q30 bases: 1839878933(85.9496%). Read1 after filtering:; total reads: 34172299; total bases: 1775386278; Q20 bases: 1762557969(99.2774%); Q30 bases: 1737891531(97.8881%). Read2 before filtering:; total reads: 44178187; total bases: 2233386484; Q20 bases: 2180294210(97.6228%); Q30 bases: 2141791820(95.8988%). Read2 aftering filtering:; total reads: 34172299; total bases: 1749324083; Q20 bases: 1731172028(98.9623%); Q30 bases: 1700577336(97.2134%). Filtering result:; reads passed filter: 68344598; reads failed due to low quality: 11353966; reads failed due to too many N: 40048; reads failed due to too short: 8617762; reads with adapter trimmed: 382600; bases trimmed due to adapters: 6698794; reads corrected by overlap analysis: 123572; bases corrected by overlap analysis: 125602. Duplication rate: 1.23916%. Insert size peak (evaluated by paired-end reads): 1. JSON report: RabbitQC.json; HTML report: SRR1852518.html; ```; Best,; Ci",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/660:3443,adapter,adapter,3443,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/660,2,['adapter'],"['adapter', 'adapters']"
Integrability,"49 kmerInfo.size():563056; approximateContigTotalLength: 72618120; counters for complex kmers:; (prec>1 & succ>1)=21819 | (succ>1 & isStart)=419 | (prec>1 & isEnd)=421 | (isStart & isEnd)=30; contig count: 717834 element count: 122492815 complex nodes: 22689; # of ones in rank vector: 717833; [2021-08-20 18:05:53.542] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.; [2021-08-20 18:05:53.542] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory indexs/alt_long_index; size = 122492815; -----------------------------------------; | Loading contigs | Time = 11.032 ms; -----------------------------------------; size = 122492815; -----------------------------------------; | Loading contig boundaries | Time = 5.8509 ms; -----------------------------------------; Number of ones: 717833; Number of ones per inventory item: 512; Inventory entries filled: 1403; 717833; [2021-08-20 18:05:53.775] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2021-08-20 18:05:53.780] [puff::index::jointLog] [info] contig count for validation: 717,833; [2021-08-20 18:05:53.943] [puff::index::jointLog] [info] Total # of Contigs : 717,833; [2021-08-20 18:05:53.944] [puff::index::jointLog] [info] Total # of numerical Contigs : 717,833; [2021-08-20 18:05:53.963] [puff::index::jointLog] [info] Total # of contig vec entries: 3,341,414; [2021-08-20 18:05:53.964] [puff::index::jointLog] [info] bits per offset entry 22; [2021-08-20 18:05:54.037] [puff::index::jointLog] [info] Done constructing the contig vector. 717834; [2021-08-20 18:05:54.564] [puff::index::jointLog] [info] # segments = 717,833; [2021-08-20 18:05:54.564] [puff::index::jointLog] [info] total length = 122,492,815; [2021-08-20 18:05:54.582] [puff::index::jointLog] [info] Reading the reference files ...; [2021-08-20 18:05:55.151] [puff::index::jointLog] [info] positional integer width = 27; [2021-08-20 18:05:55.151] [puff::index::jointLo",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/696:4894,wrap,wrapping,4894,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/696,1,['wrap'],['wrapping']
Integrability,"65 --threads ""${GALAXY_SLOTS:-4}"" --incompatPrior 1e-20 --biasSpeedSamp 1 --fldMax 1000 --fldMean 200 --fldSD 80 --forgettingFactor 0.65 --maxReadOcc 100 --numBiasSamples 2000000 --numAuxModelSamples 5000000 --numPreAuxModelSamples 1000000 --numGibbsSamples 0 --numBootstraps 0 --consensusSlack 0 --vbPrior 0.001 --sigDigits 3; ```. - `syslog`; ```; ip-172-31-30-93 kernel: [ 681.083866] salmon[4167]: segfault at 2641a ip 00007fe2fcdc2dca sp 00007fff27128b90 error 4 in libtbb.so.2[7fe2fcda0000+37000]; ```. **`salmon 0.11.2 run with: NativeSpecification --ntasks=1 --nodes=1 --mem=100000`**; - `scontrol show job 98`; ```; JobId=98 Name=g994_salmon_refinery_stemcellcommons_org; UserId=galaxy(1001) GroupId=users(100); Priority=4294901663 Account=(null) QOS=(null); JobState=RUNNING Reason=None Dependency=(null); Requeue=1 Restarts=0 BatchFlag=1 ExitCode=0:0; RunTime=00:08:19 TimeLimit=UNLIMITED TimeMin=N/A; SubmitTime=2018-08-27T20:06:23 EligibleTime=2018-08-27T20:06:23; StartTime=2018-08-27T20:06:23 EndTime=Unknown; PreemptTime=None SuspendTime=None SecsPreSuspend=0; Partition=main AllocNode:Sid=ip-172-31-24-127:2236; ReqNodeList=(null) ExcNodeList=(null); NodeList=w21; BatchHost=w21; NumNodes=1 NumCPUs=1 CPUs/Task=1 ReqS:C:T=*:*:*; MinCPUsNode=1 MinMemoryCPU=100000M MinTmpDiskNode=0; Features=(null) Gres=(null) Reservation=(null); Shared=OK Contiguous=0 Licenses=(null) Network=(null); Command=(null); WorkDir=/mnt/galaxy/tmp/job_working_directory/000/994; ```. - `Galaxy stderr`; ```; Fatal error: Exit code 139 (); ...; /mnt/galaxy/tmp/job_working_directory/000/994/tool_script.sh: line 50: 7495 Segmentation fault (core dumped) salmon quant --index ./index --libType U --unmatedReads ./single.fastq --output ./output --allowOrphans --ma 2 --mp 4 --go 5 --ge 3 --minScoreFraction 0.65 --threads ""${GALAXY_SLOTS:-4}"" --incompatPrior 1e-20 --biasSpeedSamp 1 --fldMax 1000 --fldMean 200 --fldSD 80 --forgettingFactor 0.65 --maxReadOcc 100 --numBiasSamples 2000000 --numAuxModelSamples 5",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416364238:2377,Depend,Dependency,2377,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416364238,1,['Depend'],['Dependency']
Integrability,": +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 11:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). Hi @adamfreedman<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_adamfreedman&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=kxY9gCLGWZJp-dp7l31S6M5u2RuUTeWXVrKmaydpo5o&e=>,. I think this is just conda being very very very slow (and potentially broken). The following works fine for me (and finishes in ~1 minute):. mamba create -n salmon -c conda-forge -c bioconda salmon=1.10.2. Can you use the mamba resolver in your environment? Conda has become hardly usable over the years, but mamba works quite well as a fast replacement. I'll also note that I swapped the order of conda-forge and bioconda as the docs specify that bioconda should preferably come last in the list of channels. --Rob. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784137337&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=GNiCXqUbJLM16QBJ5PNAqv-rsgDdpCpcvezPXO_riWk&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ADBMMUCOMVRRPOAZQL2EIITYBZVT5AVCNFSM6AAAAAA6UYYPGOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTOOBUGEZTOMZTG4&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=54-iPwwQkGRgqbmGQptKb39rCEfDF7oE_8NSR2kN4Xs&e=>.; You are receiving this because you were mentioned.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835:2454,Message,Message,2454,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835,1,['Message'],['Message']
Integrability,":1458040 approximateContigTotalLength: 96596288 ; counters for complex kmers: ; (prec>1 & succ>1)=163493 | (succ>1 & isStart)=1600 | (prec>1 & isEnd)=1705 | (isStart & isEnd)=136 contig count: 2046804 element count: 189087548 complex nodes: 166934 ; number of ones in rank vector: 2046803 ; [2022-04-16 11:19:37.060] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file. [2022-04-16 11:19:37.060] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory salmon_index_23 ; size = 189087548 ; ----------------------------------------- ; | Loading contigs | Time = 43.37 ms ----------------------------------------- ; size = 189087548 ; ----------------------------------------- ; | Loading contig boundaries | Time = 19.565 ms ----------------------------------------- ; Number of ones: 2046803 ; Number of ones per inventory item: 512 ; Inventory entries filled: 3998 ; 2046803 ; [2022-04-16 11:19:37.638] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure. [2022-04-16 11:19:37.687] [puff::index::jointLog] [info] contig count for validation: 2,046,803 ; [2022-04-16 11:19:38.556] [puff::index::jointLog] [info] Total # of Contigs : 2,046,803 ; [2022-04-16 11:19:38.556] [puff::index::jointLog] [info] Total # of numerical Contigs : 2,046,803 ; [2022-04-16 11:19:38.774] [puff::index::jointLog] [info] Total # of contig vec entries: 15,036,896 ; [2022-04-16 11:19:38.774] [puff::index::jointLog] [info] bits per offset entry 24 ; [2022-04-16 11:19:39.637] [puff::index::jointLog] [info] Done constructing the contig vector. 2046804 [2022-04-16 11:19:40.720] [puff::index::jointLog] [info] # segments = 2,046,803 ; [2022-04-16 11:19:40.720] [puff::index::jointLog] [info] total length = 189,087,548 ; [2022-04-16 11:19:40.878] [puff::index::jointLog] [info] Reading the reference files ... ; [2022-04-16 11:19:42.562] [puff::index::jointLog] [info] positional integer width = 28 ; [2022-04-16 11:19:42.562] [puf",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:12073,wrap,wrapping,12073,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['wrap'],['wrapping']
Integrability,":49:06.436] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2020-12-26 10:49:06.448] [puff::index::jointLog] [info] Replaced 151,122,967 non-ATCG nucleotides; [2020-12-26 10:49:06.448] [puff::index::jointLog] [info] Clipped poly-A tails from 1,829 transcripts; wrote 231443 cleaned references; [2020-12-26 10:49:09.969] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers; [2020-12-26 10:49:40.159] [puff::index::jointLog] [info] ntHll estimated 2628436199 distinct k-mers, setting filter size to 2^36; Threads = 12; Vertex length = 31; Hash functions = 5; Filter size = 68719476736; Capacity = 2; Files:; salmon-decoy-sa-index/ref_k31_fixed.fa. **So using gffread I created a transcripts.fa file:; gffread -w salmon_transcripts.fa -g GRCh38.primary_assembly.genome.fa gencode.v36.annotation.gtf. using this new transcripts.fa I run again the above mentioned salmon index with decoy command, but the warning message was shown up again:**. [Step 1 of 4] : counting k-mers; [2020-12-26 11:30:08.799] [puff::index::jointLog] [warning] Entry with header [ENST00000473810.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:08.951] [puff::index::jointLog] [warning] Entry with header [ENST00000603775.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:10.751] [puff::index::jointLog] [warning] Entry with header [ENST00000632684.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:12.936] [puff::index::jointLog] [warning] Entry with header [ENST00000543745.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:13.188] [puff::index::jointLog] [warning] Entry with header [ENST00000415118.1], had length less than equal to the k-mer length of 31 (perhaps after po",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354991:14924,message,message,14924,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354991,1,['message'],['message']
Integrability,"; diff -au CMakeLists.txt.dist CMakeLists.txt; --- CMakeLists.txt.dist 2019-12-06 10:40:58.430641796 -0800; +++ CMakeLists.txt 2019-12-06 13:14:57.292041895 -0800; @@ -387,7 +387,10 @@; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0""); if (NOT BOOST_RECONFIGURE); -find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); +set(BOOST_INCLUDEDIR ""/usr/include/boost169""); +set(BOOST_LIBRARYDIR ""/usr/lib64/boost169""); +set(Boost_FOUND 1); +; message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); @@ -571,7 +574,22 @@; endif(); ; ## Try and find TBB first; -find_package(TBB 2018.0 COMPONENTS tbb tbbmalloc tbbmalloc_proxy); +if(DEFINED ENV{ROOT_LIBTBB}); + message(""ROOT_LIBTBB in env""); + set(ROOT_LIBTBB ); + set(TBB_DIR $ENV{ROOT_LIBTBB}); + set(TBB_INCLUDE_DIRS ${TBB_DIR}/include); + set(TBB_INCLUDE_DIR ${TBB_DIR}/include); + set(TBB_LIBRARY_DIRS ${TBB_DIR}/lib); + set(TBB_LIBRARY ${TBB_DIR}/lib); + set(TBB_LIB_DIR ${TBB_DIR}/lib); + set(TBB_VERSION ""2019.6""); + set(TBB_FOUND TRUE); +else(); + message(""ROOT_LIBTBB NOT in env""); + find_package(TBB 2018.0 COMPONENTS tbb tbbmalloc tbbmalloc_proxy); +endif(); +; ; if (${TBB_FOUND}); if (${TBB_VERSION} VERSION_GREATER_EQUAL 2018.0); @@ -696,7 +714,19 @@; #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""); ; -find_package(libgff); +if(DEFINED ENV{ROOT_LIBGFF}); + message(""ROOT_LIBGFF in env""); + set(LIBGFF_DIR $ENV{ROOT_LIBGFF}); + set(LIBGFF_INCLUDE_DIRS ${LIBGFF_DIR}/include); + set(LIBGFF_INCLUDE_DIR ${LIBGFF_DIR}/include); + set(LIBGFF_LIBRARY_DIRS ${LIBGFF_DIR}/lib); + set(LIBGFF_LIBRARY ${LIBGFF_DIR}/lib); + set(LIBGFF_LIB_DIR ${LIBGFF_DIR}/lib); + set(LIBGFF_FOUND TRUE); +else(); + message(""ROOT_LIBGFF NOT in env""); + find_package(libgff); +endif(); if(NO",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460:3727,message,message,3727,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460,1,['message'],['message']
Integrability,"; drwxrwxr-x. 3 modules modules 4096 Sep 6 15:58 share; ls -al $ROOT_LIBGFF; total 20; drwxrwxr-x. 5 modules modules 4096 Dec 6 11:10 .; drwxrwxr-x. 3 modules modules 4096 Dec 6 11:07 ..; drwxrwxr-x. 2 modules modules 4096 Dec 6 11:07 bin; drwxrwxr-x. 2 modules modules 4096 Dec 6 10:59 include; lrwxrwxrwx. 1 modules modules 5 Dec 6 11:10 lib -> lib64; drwxrwxr-x. 2 modules modules 4096 Dec 6 11:07 lib64; ls -al $ROOT_LIBTBB; total 16; drwxrwxr-x. 4 modules modules 4096 Dec 6 11:48 .; drwxrwxr-x. 3 modules modules 4096 Dec 6 11:40 ..; drwxrwxr-x. 3 modules modules 4096 Dec 6 11:40 include; lrwxrwxrwx. 1 modules modules 5 Dec 6 11:48 lib -> lib64; drwxrwxr-x. 2 modules modules 4096 Dec 6 11:40 lib64. ```. Even after I had hacked up the CMakeLists.txt file to set some of these it still wouldn't build. For instance in that file:; ```; ## Try and find TBB first; if(DEFINED ENV{ROOT_LIBTBB}); message(""ROOT_LIBTBB in env""); set(ROOT_LIBTBB ); set(TBB_DIR $ENV{ROOT_LIBTBB}); set(TBB_INCLUDE_DIRS ${TBB_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_DIR}/lib); set(TBB_LIBRARY ${TBB_DIR}/lib); set(TBB_LIB_DIR ${TBB_DIR}/lib); set(TBB_VERSION ""2019.6""); set(TBB_FOUND TRUE); else(); message(""ROOT_LIBTBB NOT in env""); find_package(TBB 2018.0 COMPONENTS tbb tbbmalloc tbbmalloc_proxy); endif(). if (${TBB_FOUND}); ```. But apparently that wasn't enough, because:. ```; cmake \; -DCMAKE_INSTALL_PREFIX:PATH=$TOPDIR \; .. ...; TBB_LIBRARIES = ; -- Configuring done; CMake Error at external/pufferfish/external/twopaco/CMakeLists.txt:11 (add_dependencies):; The dependency target ""tbb"" of target ""graphdump"" does not exist.; ```. This doesn't work obviously, but here are the mods to CMakeLists.txt that I tried:. ```; diff -au CMakeLists.txt.dist CMakeLists.txt; --- CMakeLists.txt.dist 2019-12-06 10:40:58.430641796 -0800; +++ CMakeLists.txt 2019-12-06 13:14:57.292041895 -0800; @@ -387,7 +387,10 @@; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460:1986,message,message,1986,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460,1,['message'],['message']
Integrability,"> And for us, who have blocked download on a computational cluster `cmake` silently continues even when `scripts/fetchRapMap.sh` failed (see error code `403` below). Dists downloading their own dependencies is also forbidden in package managers such as FreeBSD ports and pkgsrc (which is cross-platform and I personally use on Mac, NetBSD, and RHEL). Trusting upstream scripts to pull stuff off the Internet is a security risk, so the package managers perform and validate (via checksum) all downloads in a separate stage. It would be nice not to have to hack out the download code from a build system in order to create and maintain a package.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-989326040:194,depend,dependencies,194,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-989326040,1,['depend'],['dependencies']
Integrability,"> Can you try doing:; > ; > ```; > export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:/Users/maysonlin/Downloads/salmon-1.2.1-h2072146_0 2/lib; > ```; > ; > before running salmon? The problem is that the executable is looking for `libtbb` and `libtbb_proxy`, but they are not in the library path. Hi, Rob, thank you for replying, do you mean type those code in ""Terminal""? ; I tried it, and I got this message:. -bash: export: `2/lib': not a valid identifier",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/517#issuecomment-623073440:395,message,message,395,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/517#issuecomment-623073440,1,['message'],['message']
Integrability,"> Hello, Thank you for your message. However, I am working with fission yeast transcriptome and since I am not expecting a lot of splicing junctions with this organism, I read that people recommended using -ax map-ont in this case?. Ye, it is. If there are not many splicing junctions, then it is like runging with genomic reads. But still, I do not see any recommantion of doing it. . For your first questions, is `7ff17d41-0678-447f - acd0-57b53d35ba32` an ID of a read from your `fastq` file? For me, It does not look like a gene name. If it is an ID, how do you get this?. After I ran the quantificaton, what I get is like this：; gens, length and so on.; ![image](https://user-images.githubusercontent.com/14146871/179023113-d06ee0a3-4efd-406e-8736-895345cafae5.png). I import Genomes and bam file inoto IGV to check `ATMG01170.1`:; ![image](https://user-images.githubusercontent.com/14146871/179024217-63f8920f-0ab3-4c42-b4cf-24dbd9de1134.png). I am not familiar with IGV so I did not know how to import the .gtf file to see what you showed. ![image](https://user-images.githubusercontent.com/14146871/179024687-9aed6cfd-e203-415f-9f9f-c6501a915c27.png)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/786#issuecomment-1184610671:28,message,message,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/786#issuecomment-1184610671,1,['message'],['message']
Integrability,"> Hi @tamuanand ,; > ; > I am not well versed in Lexongen Quantseq but the following paper is worth checking.; > https://www.nature.com/articles/s41598-019-55434-x , let us know if you have any thoughts. @k3yavi You mention that you are not well-versed in Lexogen Quantseq. Just to clarify, Lexogen is the company, Quantseq is the technology. . It is the same Quantseq that is mentioned in the salmon quant help text . ```; salmon quant --help-reads; ................................; --noLengthCorrection [experimental] : Entirely disables; length correction when estimating the; abundance of transcripts. This option; can be used with protocols where one; expects that fragments derive from; their underlying targets without regard; to that target's length (e.g. QuantSeq); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565245678:637,protocol,protocols,637,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565245678,1,['protocol'],['protocols']
Integrability,"> In STAR there is an option to use stranded alignment (--readStrand, which can take ""Unstranded"", ""Forward"", or ""Reverse""). For the pipeline I'm building it would be ideal if I didn't have to specify the strandedness of the library as I'm not the one preparing the samples and it's not always easy to get that information from the scientist in the lab. As such, it would be great if I can use the default strandedness argument to STAR (""Unstranded"") and let salmon ""do the right thing"" by letting it choose the libType for me. With that in mind, if I let salmon choose for me (-l A) am I risking throwing out any data?. Right, so in this case, STAR should produce all highest-scoring valid alignments regardless of orientation. Then, when running salmon with `-l A` it will detect the strandedness and only discard alignments compatible with the appropriate strand type (which may be unstranded if that is the protocol). Salmon is pretty conservative about reporting when there is any ambiguity. By default, if the strand bias is stronger than a few percent. In a stranded protocol, it will report and if it infers more than a few percent of fragments no having a valid alignment. So you can always double-check samples where the strandedness is at all ambiguous. > In addition, if a transcript was aligned in a unstranded manner and ended up aligning to the wrong location due to ambiguity between the positive orientation of one transcript and the negative orientation of another, can salmon correct this by reassigning it to the right transcript based on the joint probability of all the other alignments (if you can't tell I'm at the edge of my BS zone)?. If there is not an alignment to the correct location _in addition to_ the wrong location, then no. If you run salmon in alignment mode, it will assign each fragment probabilistically to the set of transcripts to which it aligns. There is, by definition, a probability of 0 for a fragment being assigned to a location where it doesn't align.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/590#issuecomment-733417813:911,protocol,protocol,911,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/590#issuecomment-733417813,1,['protocol'],['protocol']
Integrability,"> Is this read set & reference txome available to try and reproduce this?. Unfortunately no, it's a generated fasta file (it used to work with 0.9.1 without ""validateMappings"" though). [info] Building 32-bit suffix array (length of generalized text is 462349554); processed 462000000 positions; khash had 208056876 keys. > Also, would it be possible to check if this occurs using the bioconda-packaged release?. Still a seg fault but I now have the following message:; WARNING: Could not associate known library type with read!; WARNING: PE compatibility function called with SE read!; expected: Library format { type:paired end, relative orientation:inward, strandedness:unstranded }, observed: Library format { type:, relative orientation:, strandedness: }; Segmentation fault: 11",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393236903:459,message,message,459,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393236903,1,['message'],['message']
Integrability,"> Ok, when I attempt the build the way you say above, I get the following error during CMake:; > ; > ```; > -- fetch PUFFERFISH exit code 127; > CMake Error at CMakeLists.txt:317 (message):; > Could not fetch pufferfish source [fetchPufferfish.sh returned exit code; > 127]. Did you do the. ```; apt build-dep salmon; ```. step? I can't imagine that you get this problem if you follow my log step by step. Debian is usually using dynamic linking. By having all Build-Dependencies (which is ensured in the step above) the existence of the libraries is granted and the options for cmake I specified are ensuring that the libs are found. Kind regards, Andreas.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464176548:180,message,message,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464176548,2,"['Depend', 'message']","['Dependencies', 'message']"
Integrability,"> The same with version 1.2.0.; > ; > Is there a way to disable version check by default, completely? I install Salmon as a module and I wouldn't let it update itself automatically, anyway. ```; --- Salmon.cpp.ori 2020-04-21 15:12:29.916219870 +0000; +++ Salmon.cpp 2020-04-21 15:16:48.488926415 +0000; @@ -53,7 +53,7 @@; ""Usage: salmon -h|--help or \n""; "" salmon -v|--version or \n""; "" salmon -c|--cite or \n""; - "" salmon [--no-version-check] <COMMAND> [-h | options]\n\n"");; + "" salmon <COMMAND> [-h | options]\n\n"");; helpMsg.write(""Commands:\n"");; helpMsg.write("" index Create a salmon index\n"");; helpMsg.write("" quant Quantify a sample\n"");; @@ -171,8 +171,6 @@; // https://gist.github.com/randomphrase/10801888; po::options_description sfopts(""Allowed Options"");; sfopts.add_options()(""version,v"", ""print version string"")(; - ""no-version-check"",; - ""don't check with the server to see if this is the latest version"")(; ""cite,c"", ""show citation information"")(; ""help,h"", ""produce help message"")(""command"", po::value<string>(),; ""command to run {index, quant, sf}"")(; @@ -209,11 +207,6 @@; std::exit(0);; }. - if (!vm.count(""no-version-check"")) {; - std::string versionMessage = getVersionMessage();; - std::cerr << versionMessage;; - }; -; // po::notify(vm);. std::string cmd = vm[""command""].as<std::string>();; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617250297:991,message,message,991,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617250297,1,['message'],['message']
Integrability,> but I suspect the issue is also related to this log message. I wondered about that too but other samples gave me 2 and 3 degenerate classes and still passed...,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393579057:54,message,message,54,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393579057,1,['message'],['message']
Integrability,"@Gaura So with the changes implemented, custom geometry is ~19% slower here than the hand-coded sci-seq3 protocol (improved from ~1/3 slower); is that correct? That's a nice improvement. @gmarcais — do you think it's worth testing out PCRE2? Most of these regexes are *very* short — and if boost is ~20% slower than PCRE2 and we are ~20% slower than the custom parsing code .... maybe that's the whole gap? Any idea how difficult this would be to try?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023346183:105,protocol,protocol,105,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023346183,1,['protocol'],['protocol']
Integrability,"@HenrikBengtsson,. Good catch. We had to update the continuous integration image used because we bumped some libraries (and the compiler version). Apparently the permissions are not set up in the same way by default. Can you share what you think the permissions should be for the relevant files / folders?. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/761#issuecomment-1067239060:63,integrat,integration,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/761#issuecomment-1067239060,1,['integrat'],['integration']
Integrability,"@Miserlou : it's also worth noting that the error message preceding the segfault in #323 is coming from the library (libstaden) that we use to parse SAM/BAM files. So, it's something where I think we will need a BAM that exhibits whatever triggers that behavior.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/320#issuecomment-444994980:50,message,message,50,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/320#issuecomment-444994980,1,['message'],['message']
Integrability,"@PeteHaitch Thanks for making the pull request and correcting the barcode length for the celseq2 protocol. We'll review it soon and merge it to the develop (which will be merged to master in next release). @rob-p I think we already have that capability of specifying the CB and UMI length, it's just CelSeq2 was little difference in the *order* of them. Basically the flags like `--chromium` or any other protocols are wrapper around using the standard CB and UMI lengths. If one wants a customization we can always use `--umiLength` and `--barcodeLength`. I am thinking of tweaking the `--end` part of the `struct` to select the order of the CB and UMI which incase of CelSeq2 is reverse.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418772038:97,protocol,protocol,97,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418772038,3,"['protocol', 'wrap']","['protocol', 'protocols', 'wrapper']"
Integrability,"@bgruening So I've tried some runs today with higher memory configurations and can still reproduce the segfault. I'm going to continue on and try to write up a reproducer for @dpryan79 [here](https://github.com/bioconda/bioconda-recipes/issues/10662#issuecomment-415967622). **`salmon 0.11.2 run with: NativeSpecification --ntasks=1 --nodes=1 --mem=25000`**; - `scontrol show job 94`; ```; JobId=94 Name=g990_salmon_refinery_stemcellcommons_org; UserId=galaxy(1001) GroupId=users(100); Priority=4294901667 Account=(null) QOS=(null); JobState=COMPLETED Reason=None Dependency=(null); Requeue=1 Restarts=0 BatchFlag=1 ExitCode=0:0; RunTime=00:07:32 TimeLimit=UNLIMITED TimeMin=N/A; SubmitTime=2018-08-27T15:36:41 EligibleTime=2018-08-27T15:36:41; StartTime=2018-08-27T15:36:41 EndTime=2018-08-27T15:44:13; PreemptTime=None SuspendTime=None SecsPreSuspend=0; Partition=main AllocNode:Sid=ip-172-31-24-127:21595; ReqNodeList=(null) ExcNodeList=(null); NodeList=w19; BatchHost=w19; NumNodes=1 NumCPUs=1 CPUs/Task=1 ReqS:C:T=*:*:*; MinCPUsNode=1 MinMemoryNode=25000M MinTmpDiskNode=0; Features=(null) Gres=(null) Reservation=(null); Shared=OK Contiguous=0 Licenses=(null) Network=(null); Command=(null); WorkDir=/mnt/galaxy/tmp/job_working_directory/000/990; ```. - `Galaxy stderr`; ```; Fatal error: Exit code 139 (); ...; /mnt/galaxy/tmp/job_working_directory/000/990/tool_script.sh: line 50: 5713 Segmentation fault (core dumped) salmon quant --index ./index --libType U --unmatedReads ./single.fastq --output ./output --allowOrphans --ma 2 --mp 4 --go 5 --ge 3 --minScoreFraction 0.65 --threads ""${GALAXY_SLOTS:-4}"" --incompatPrior 1e-20 --biasSpeedSamp 1 --fldMax 1000 --fldMean 200 --fldSD 80 --forgettingFactor 0.65 --maxReadOcc 100 --numBiasSamples 2000000 --numAuxModelSamples 5000000 --numPreAuxModelSamples 1000000 --numGibbsSamples 0 --numBootstraps 0 --consensusSlack 0 --vbPrior 0.001 --sigDigits 3; ```. - `syslog`; ```; ip-172-31-30-93 kernel: [ 681.083866] salmon[4167]: segfault at 2641a i",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416364238:564,Depend,Dependency,564,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-416364238,1,['Depend'],['Dependency']
Integrability,"@k3yavi To follow up on this dataset:; The reads were generated using a modified protocol with a 9bp barcode followed by an 8bp UMI. I used the custom length mode to align this data and alignment rate went up to about 45%. I tried the alignment using DropSeq Tools and STAR and got similar alignment rates, so I think the custom length alignment is working properly. I may try using some other reference databases instead of GRCh38.p12 to see if alignment improves. Otherwise it may just be an issue regarding the dataset itself.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-415101431:81,protocol,protocol,81,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-415101431,1,['protocol'],['protocol']
Integrability,"@kikegoni this is something I started to work on but then quickly abandoned. I've uploaded the utility (`transcoorder`) that I started writing (https://github.com/mdshw5/transcoorder) for this purpose. If you find it useful and want to help finish the work please do. Currently the `transcoord` command will take a SAM/BAM, a GTF and matching genomic FASTA, and will convert reads from transcript to genomic coordinates, with appropriate reference names and offsets. However, it is not tested, and will only properly handle reads that fall entirely within an exon. Spliced reads shouldn't be too hard to add, but I just don't have the time right now. . ```; $ transcoord -h; usage: transcoord [-h] [-o OUT] [-t TAG_NAME] [--debug] [--version] gtf bam fasta. positional arguments:; gtf GTF file containing transcripts; bam SAM or BAM files aligned to transcriptome; fasta FASTA format assembly coresponding to GTF. optional arguments:; -h, --help show this help message and exit; -o OUT, --out OUT output file for genomic SAM (default: stdout); -t TAG_NAME, --tag-name TAG_NAME; SAM tag name for storing transcript identifier. default: ZT; --debug enable debugging; --version display version number; ```. The command is veeeeeery slow, but should process a typical RNAseq library in a few hours.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/193#issuecomment-736948709:961,message,message,961,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/193#issuecomment-736948709,1,['message'],['message']
Integrability,"@mdshw5 --- Salmon has definitely become less ""complain-y"" in the newer versions. That is, it will no longer spew out error messages for all of the fragments that show up in an unexpected orientation. However, the summary statistics are currently very ""summary"". There is a file in the quantification directory called `libFormatCounts.txt` that summarizes the number of alignments seen in the different orientations etc. However, I _really_ like your idea of recording the ""violating"" transcripts. That is, we could maintain some ""threshold"" beyond which if there are these many ""incorrectly"" mapping fragments for a transcript, the transcript is recorded and reported to the user as potentially being in the wrong orientation in the index.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/16#issuecomment-144479133:124,message,messages,124,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/16#issuecomment-144479133,1,['message'],['messages']
Integrability,"@rbenel,. If you are using a version prior to 0.14.0, you will also have to pass `--no-version-check` to avoid contamination of stdout by the versioning message.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-507241631:153,message,message,153,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-507241631,1,['message'],['message']
Integrability,"@rob-p Could it be that I am not using the correct command line `salmon quant` options for Lexogen/QuantSeq _(this will be referred to as QS in the rest of the message(s))_ ?. `salmon quant --threads 16 --noLengthCorrection --validateMappings --numBootstraps 100 -l SF -i <path_to_SAF_Gentrome_Index> -r <SE_READ_1.fq> -o <salmon_SE_READ_1>`. I chose the above command line options (`especially --noLengthCorrection`) based on [Rob's message here](https://groups.google.com/d/msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ) and a [thread here](https://github.com/COMBINE-lab/salmon/issues/108). Let me elaborate the big picture of my analyses and give more details about how I came up with the mapping numbers in my original post. Big Picture - DEG identification for samples sequenced by ILMN (whole transcript method) and QS (3' method) - [something similar to this paper](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5393-3). Bioinformatics Pipeline(s) for both ILMN and QS :. 1. HISAT Method : Adapter/Quality Trimming, Hisat2-HTSEQ, Get_Count_Table, DESeq; 2. STAR_RSEM Method: Adapter/Quality Trimming, STAR_RSEM, Get_Count_Table, DESeq; 3. SAF Method: Adapter/Quality Trimming, SAF_SALMON, Get_Count_Table, DESeq; 4. Quasi-Mapping or TXOME Method: Adapter/Quality Trimming, TXOME_SALMON, Get_Count_Table, DESeq. I used UpSetR plots for comparisons of sets of DEGs from each method just [as you have shown in your recent preprint](https://www.biorxiv.org/content/10.1101/657874v1.full). In the ILMN analyses, there is great concordance between the SAF method and HISAT/STAR_RSEM method. However, in the QS analyses, there is very limited concordance between SAF and the HISAT/STAR_RSEM method. For QS analyses, the TXOME method shows great concordance with HISAT/STAR_RSEM. This finding made me wonder if this has to be something with my salmon quant command line options for QS. Therefore, I wanted to check how the QS expected counts for SAF method show up for all samples in",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195:160,message,message,160,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-554768195,2,['message'],['message']
Integrability,"@rob-p I would request that you try out bbduk and bbmap for quality/adapter trimming and contaminant removal.; > Thank you for verifying @zhangchipku, For the time being, I can recommend `fastp` as a fairly efficient / fast trimmer that. It might even be able to work in a streaming fashion so that you could pipe the trimmed reads directly to salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-592995074:68,adapter,adapter,68,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-592995074,1,['adapter'],['adapter']
Integrability,"@rob-p I've taken the time to [update salmon to 0.11.2 in it's respective Galaxy Tool wrapper](https://github.com/bgruening/galaxytools/pull/778) and am still seeing the `salmon quant` segfault when running through SLURM. . bioconda installs of salmon 0.9.1 & 0.11.2 run to completion outside of SLURM on the same machine. I've seen that #268 was opened and closed recently, but I don't have the liberty to resolve the salmon dependency outside of conda (at least very easily/in a timely fashion). Update: Have since filed https://github.com/bioconda/bioconda-recipes/issues/10662",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-415831123:86,wrap,wrapper,86,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-415831123,2,"['depend', 'wrap']","['dependency', 'wrapper']"
Integrability,"@rob-p This is not running twice on same sample. I can see that this run generates a exit code of 1 for that run - however all files are there as needed. Other samples have a exit code 0. I looked up sample runs before and after - they seem to have correct exit codes and ran fine. Even this runs fine, but what triggers that error message - I am not sure. ```; failed to read 8 bytes; salmon quant invoked improperly; ```. I also reran my whole pipeline (qc_trimming etc and finally salmon) - this time with 5 samples only (and included the above sample) - the pipeline runs successfully. Not sure where to investigate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618044865:332,message,message,332,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618044865,1,['message'],['message']
Integrability,"@rob-p can you elaborate on this a bit more: . > The effect of --minScoreFraction depends, to some extent, on how you set the match/mismatch/gap parameters. With the default parameters, 0.9 is actually higher than 90% sequence identity, because the default mismatch penalty is twice the match score. If you assume only matches and mismatches, then the --minScoreFraction you want to set is the one such that x * (match_score * read_length) <= (match_score * read_length) - (m * read_length * match_score) + (m * read_length * mismatch_penalty), where m is the mismatch fraction (0.1 in your case). So, for example, if the match_score is 2 and mismatch penalty is -4, and the read length is 100, you want to set it so that: x * 200 = 200 - (0.1 * 100 * 2) + (0.1 * 100 * -4) = 200 - 20 - 40 = 140 so, the appropriate x would be ~0.7. Of course, if you want to make the calculation simple, you can set the match score to 1 and mismatch penalty to 0, and then the interpretation (modulo gaps) is straightforward (and 0.9 means what you want). Would the two parameter sets mentioned above have the same effect assuming read length 100?. Also, it says Alevin has a default minScoreFraction of 0.87. Would it be safe to assume differentiating between isoforms with Alevin is a similar problem to differentiating between orthologous genes in metagenomics/transcriptomics?. Which parameters would be relevant to control for this?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-2249029869:82,depend,depends,82,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-2249029869,1,['depend'],['depends']
Integrability,"@roryk I don't think an R package is the right answer :) . My real motivation is to load into Degust: http://www.vicbioinformatics.com/degust/. It can be done with simple Unix cut/paste or with a python script too. But I don't want to depend on R for the pipeline, or even littler. @vals I'll take a look at your script, but still be better if part of Salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-240556885:235,depend,depend,235,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-240556885,1,['depend'],['depend']
Integrability,"@zhangchipku,. The default value of `--minScoreFraction` is quite reasonable, I think. It depends on the read length, but for a 100-bp read, it corresponds to 8 mismatches under the default scoring parameters. So the read pair could have up to 16 mismatches before being discarded. I understand that the recommendation to trim reads is a new one, but I think it is a standard best-practice anyway. However, we are looking at the possibility of allowing read-end soft-clipping in future releases, which could mitigate this need in the most common case. It is worth noting that, if you *don't* want to use selective alignment, then the last version of salmon that you can use is the one tagged as `0.15.0`. As of version 1.0.0, the index structure and default mapping algorithm changed, so that selective alignment is ""always on"". This is discussed in some detail in the release notes for version 1.0.0. Generally, we think that the benefits offered by selective-alignment are important, and, unless there is a very strong reason not to, one should generally ensure that reads sharing some exact matches with the reference also produce reasonable quality alignments at the implied loci. However, we also try to be very receptive and responsive to our users' workflows and desiderata, so if the soft-clipping feature is something that would make your experience much smoother, we will certainly consider prioritizing that feature for a future release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586478704:90,depend,depends,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586478704,1,['depend'],['depends']
Integrability,"@zhangchipku,. Yes, it seems that the biggest culprit here is `num_fragments_filtered_vm`. That is the number of fragments filtered because the best alignment failed to reach the threshold for a ""valid"" alignment. Here, `47,470,013` fragments are discarded entirely because they didn't have an alignment meeting the required quality. If these fragments (which do have matching MEMs, because alignment was carried out for them) were mapped, then the overall mapping rate would go up to `50,729,814 + 47,470,013 = 98,199,827 / 107,275,750 = ~91.5%`. Now, I wouldn't expect _all_ of these to be mappable, and some alignments might not be feasible at any reasonable quality whatsoever. My recommendation would be as follows. First, have you trimmed these reads (using e.g. `fastp` or `TrimGalore` or some such)? Very low quality read ends or (more likely) adapter contamination could cause the reads that have matching MEMs to fail to align within the required score threshold. My first recommendation would be to trim the reads and see how the mapping rate changes. Second, the required alignment score is a user-alterable parameter. By changing `--minScoreFraction` to be lower, you can allow reads with even lower alignment scores to be counted for quantification. The default value is `0.65`, so you could explore what happens if you lower this number. The number represents the fraction of the maximum achievable alignment score that a read must obtain to be considered a valid alignment. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586473052:852,adapter,adapter,852,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586473052,1,['adapter'],['adapter']
Integrability,A PR noting the differences in my approach to #269.; The one that I think needs addressing is in `writeFastq` (https://github.com/COMBINE-lab/salmon/compare/develop...PeteHaitch:develop?expand=1#diff-bf2f37cd9ea77a5c454a5bd860a924ee); without some change to this the `UMI` and `CB` are incorrectly extracted for CEL-Seq2. ; I simply commented out the original lines and modified it as needed for CEL-Seq2 in order to test my modified version.; I guess some sort of protocol-specific conditional is needed here. The remainder are minor/cosmetic choices of variable names (please feel free to ignore!).,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/285:465,protocol,protocol-specific,465,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/285,1,['protocol'],['protocol-specific']
Integrability,"A lot of the times when we are assessing our samples before we move on to fragmenting cDNA in to fragments, we look at the distribution of full length cDNA using a Bioanalyzer. See for example panel **a** of [this figure](http://www.nature.com/nprot/journal/v9/n1/fig_tab/nprot.2014.006_F2.html); ![](http://www.nature.com/nprot/journal/v9/n1/images/nprot.2014.006-F2.jpg). With the reference transcriptome, we know the distribution of transcripts with given lengths. We can view the reference transcript length distribution as unweighted distribution of lengths, and the electropherogram as the distribution when weighing transcript lengths by their relative abundances. Thus it seems the distribution of full length cDNA could be informative when inferring the TPMs (relative abundances) in a sample. Do you think it could be possible to integrate with the quantification model?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/56:840,integrat,integrate,840,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/56,1,['integrat'],['integrate']
Integrability,Aborted (core dumped) message at indexing step,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/795:22,message,message,22,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/795,1,['message'],['message']
Integrability,"Add [inDropv2 protocol](https://www.nature.com/articles/nprot.2016.154) to salmon alevin. To use this protocol pass the `--indropV2` flag. The details of library preparation can be seen [here](https://teichlab.github.io/scg_lib_structs/methods_html/inDrop.html). R1 is the biological read and R2 is the metadata read. Briefly, the reads have 8-11 bp barcode1, followed by a `W1` sequence which should be specified using `--w1` flag then 8bp barcode2 and 6 bp UMI sequence follows. . Summary of changes:; 1. `--indropV2` flag added to process indropV2 reads; 2. a local copy of single cell protocol is created before barcodes and UMI are extracted to allow share the positions and avoid searching twice; 3. In case the barcode1 is less than 11bp, `A` is added after joining barcodes 1 and 2 to make the total length 19 bp; 4. If no exact match for w1 is found, a search for w1 with a hamming distance <=2 is performed. It was tested for correlation on run SRR7165069 from GEO submission [GSM3141960](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3141960).; Results:; ![image](https://user-images.githubusercontent.com/12998572/133622734-9b473318-fb39-421d-a322-b018f93ac139.png). ```; Min. 1st Qu. Median Mean 3rd Qu. Max. ; 0.3634 0.8981 0.9655 0.9307 0.9874 0.9976 ; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/703:14,protocol,protocol,14,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/703,3,['protocol'],['protocol']
Integrability,"Add [sci-rna-seq3 protocol](https://www.nature.com/articles/s41586-019-0969-x) to salmon alevin. To use this protocol pass the `--sciseq3` flag. The details of library preparation can be seen [here](https://teichlab.github.io/scg_lib_structs/methods_html/sci-RNA-seq3.html). Briefly, the reads have 9-10 bp hairpin adaptor index, and 10bp reverse transcription index which together make the cell barcode of 19-20 bp in length; an 8 bp UMI which follows a 6bp anchor sequence CAGAGC. . Summary of changes:; 1. `--sciseq3` flag added to process sci-rna-seq3 reads; 2. a local copy of single cell protocol is created before barcodes and UMI are extracted to allow share the position of anchor sequence and avoid searching twice; 3. In case the barcode is 19bp, `A` is added as the last nucleotide to make the cell barcodes length 20 bp for all barcodes. It was tested on data from the [Nature paper](https://www.nature.com/articles/s41586-019-0969-x). Correlation b/w the counts from the GEO submission [GSE119945](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE119945) and sum of spliced, unspliced reads with and without ambiguous counts using `usa` mode in alevin-fry gave reasonable looking correlations. ; Results for one of the fastq files:; ![image](https://user-images.githubusercontent.com/12998572/128923136-eefa8738-f87e-4f67-bba6-5cc1648ce194.png). ```; Min. 1st Qu. Median Mean 3rd Qu. Max. ; 0.4594 0.7805 0.8295 0.8253 0.8736 0.9943 ; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/695:18,protocol,protocol,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/695,3,['protocol'],['protocol']
Integrability,Add sci-rna-seq3 protocol to salmon,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/695:17,protocol,protocol,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/695,1,['protocol'],['protocol']
Integrability,Add supported protocol information and protocol specific notes.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/723:14,protocol,protocol,14,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/723,2,['protocol'],['protocol']
Integrability,"After generating issue #48, I took the recommendation of switching to the standard EM algorithm, but I'm having further problems. However, I don't think the problem was with the Variational EM algorithm, but an issue with how the dataset is behaving. . This is with the same dataset as before (single end, rRNA-depleted, second-strand protocol, extreme depth of 170M+ reads). I have the options --useFSPD and --biasCorrect turned on with library type ""SF""; the full call is . ```; salmon quant -i $SALMON_DIR -l SF -r <(gzip -c -d $IN_FILE) -o $OUTPUT \; --numBootstraps 100 --useFSPD --geneMap $GENES \; --biasCorrect -p 59; ```. I had attempted to use wasabi and run sleuth, but I got an error where the number of transcripts passing the initial filter was ""NA"". I then discovered that for four samples, many of the transcripts had ""-nan"" generated for the ""NumReads"" column, and this led to all of them having ""-nan"" for the TPM column. One sample had ~100 that failed, but the other three had a variable 106K-109K out of 176K total transcripts fail. No warning or error was thrown during the quantifying or EM optimization steps, so I don't know what happened. Interesting, I should note that the NaNs are only generated when both biasCorrect and useFSPD are turned on. NaNs are not generated when I use only one or neither option. (this was only tested with one sample though). If you have immediate suggestions, that would be great. Otherwise, I can work on generating a test dataset.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/50:335,protocol,protocol,335,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/50,1,['protocol'],['protocol']
Integrability,"Ahh, serves me right for trying to write that help message by hand! I'll remove `cite` from the list of ""commands"" in the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/149#issuecomment-325170015:51,message,message,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/149#issuecomment-325170015,1,['message'],['message']
Integrability,"Ahh, that's the number of *mappings* discarded. No need to worry about that. Basically, that's the number of places where seeding was tried, but alignment failed. This is very common in alignment (a seed can't be extended to a high quality alignment). The number of fragments discarded is what matters (number of fragments where all alignment locations failed). The strand bias signifies that your library is likely strand specific, though you are mapping in unstranded mode. This means that even alignments that don't agree with the stranded protocol will be allowed. This looks like ISR (first read from the reverse strand) by the looks of it. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126583954:543,protocol,protocol,543,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126583954,1,['protocol'],['protocol']
Integrability,"Alevin in Salmon v0.11.2. **Describe the bug**; When attempting to run Alevin on [https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/cd14_monocytes](url), with the 10x v1 wrapper, the initialization seems to go smoothly then Alevin produces the following:. ```; [2018-09-13 11:41:47.586] [jointLog] [info] Computed 0 rich equivalence classes for further processing; [2018-09-13 11:41:47.586] [jointLog] [info] Counted 0 total reads in the equivalence classes ; [2018-09-13 11:41:47.593] [jointLog] [warning] Only 0 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2018-09-13 11:41:47.593] [jointLog] [warning] Something seems to be wrong with the calculation of the mapping rate. The recorded ratio is likely wrong. Please file this as a bug report. [2018-09-13 11:41:47.593] [jointLog] [info] Mapping rate = 0%; ```. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:; A downloaded binary Salmon v0.11.2 was executed using the v1 wrapper script compiled locally in a Salmon specific Conda environment. The GRCh38.p12 reference was used. Dataset is linked above in bug description. . Full command used:; `~/bin/salmon/scripts/v1_10x/run.sh salmon alevin -l ISR -1 read-I1_*.fastq.gz -2 read-RA_*.fastq.gz -r read-I1_*.fastq.gz --gemcode -i ../../../index_15_pc -p 10 -o ../../alevin_15_pc --tgMap ../../../txp2gene.tsv --dumpCsvCounts --dumpFeatures --end 5 --umiLength 5 --barcodeLength 14; `; Full terminal output:. ```; (Salmonenv) @compute-1-16: ~/Documents/PBMCStem/cd14/fastqs/flowcell1 $ ~/bin/salmon/scripts/v1_10x/run.sh salmon alevin -l ISR -1 read-I1_*.fastq.gz -2 read-RA_*.fastq.gz -r read-I1_*.fastq.gz --gemcode -i ../../../index_15_pc -p 10 -o ../../alevin_15_pc --tgMap ../../../txp2gene.tsv --dumpCsvCounts --dumpFeatures --end 5 --umiLength 5 --barcodeLength 14; TEMPDIR is /tmp/tm",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/294:195,wrap,wrapper,195,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/294,1,['wrap'],['wrapper']
Integrability,Allow custom geometry single-cell protocols,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734:34,protocol,protocols,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734,1,['protocol'],['protocols']
Integrability,Appears to work that route. Thanks!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409439396:21,rout,route,21,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409439396,1,['rout'],['route']
Integrability,"Argghh --- that's gonna be a thinker. Can you try running it under GDB?. ```; $ gdb salmon; (gdb) r quant \; -i mouse_cdna_38.p3.78_repbase_ercc.fa \; -l IU \; -1 SRP057125_SRS936134_1.fastq \; -2 SRP057125_SRS936134_2.fastq \; -o SRP057125_SRS936134_salmon_out \; -g /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt \; --biasCorrect \; --useFSPD; ```. when it segfaults, you can issue the `bt` command to at least see where. If its still inside of JeMalloc, I can build another binary with just the standard allocator to see if the problem persists there (its strange that it depends on where the file is coming from! I don't have any NFS mounts either to test on).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168428123:631,depend,depends,631,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168428123,1,['depend'],['depends']
Integrability,"As suggested by Nick Schurch, we should be writing non-error output (including simple logging and informative messages) to stdout rather than stderr.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/55:110,message,messages,110,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/55,1,['message'],['messages']
Integrability,"CGAAGTTG_lane-001-chunk-001.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-002-chunk-000.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [2018-12-05 15:10:07.252] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 14, 5) is being used. Updating UMI k-mer length accordingly.; Logs will be written to ./fastq/test/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ gemcode ] => { }; ### [ index ] => { ../transcripts_index_salmon/ }; ### [ threads ] => { 8 }; ### [ output ] => { ./fastq/test/ }; ### [ tgMap ] => { ../hg_transcriptome/tx2tx.tsv }; ### [ end ] => { 5 }; ### [ umiLength ] => { 5 }; ### [ barcodeLength ] => { 14 }; ### [ dumpCsvCounts ] => { }; ### [ dumpFeatures ] => { }; ### [ mates1 ] => { /tmp/tmp.lLLibfwH4G/p1.fa }; ### [ mates2 ] => { /tmp/tmp.lLLibfwH4G/p2.fa }; ### [ unmatedReads ] => { ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-004-chunk-002.fastq.gz ./fastqs/fl",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:3617,protocol,protocol,3617,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['protocol'],['protocol']
Integrability,Cleanup STDOUT and STDERR messages from salmon-0.10.2,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/242:26,message,messages,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/242,1,['message'],['messages']
Integrability,Conda dependency conflict with ICU between Salmon 1.3.0 and R 4.0.3,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/594:6,depend,dependency,6,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/594,1,['depend'],['dependency']
Integrability,Could it be coming from some other part of the code or some dependency?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393623521:60,depend,dependency,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393623521,1,['depend'],['dependency']
Integrability,"Counting (transcript, UMIs) is what ""kallisto pseudo"" with the --umi option; does, right?. Yes, there are a few errors in the UMIs. The Kallisto wrapper tries to; correct them. But this is really very rare. Not sure if it's worth the; time. Like ~100 out of 200.000 reads? I would have to check again.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269043952:145,wrap,wrapper,145,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269043952,1,['wrap'],['wrapper']
Integrability,"Currently the indexer has a --gencode flag to handle the composite fasta headers in GENCODE transcript fasta files and `split the transcript name at the first '|' character`. However, the alignment-based mode doesn't use an index, and the current behavior is to read the fasta headers from -t verbatim. So, if I run the STAR aligner with the standard workflow using GENCODE files as index, the Aligned.toTranscriptome.out.bam output would already be aligned to the transcriptome, with the RNAME fields set in the same way `salmon index --gencode`, for example:. `ST-J00106:110:H5NY5BBXX:3:2211:22495:7240 99 ENSMUST00000195335.1 799 60 76M = 945 222 CTCAGTAGGAAGATTATAACTAATACTCCCCCATCAAACAGTTTTAAGGACAGAAGAGAACAAAGCATGTAAAGTG <AFFFJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJFJJJJJJJJJJJJJJJJFFJA<AFJJFFA NH:i:1 HI:i:1 RG:Z:160212_ST-J00106_0110.3`. As a result, Salmon won't quantify anything if I run Salmon in the Alignment-based mode with the official GENCODE transcripts.fa, for example, `salmon quant -l IU -a Aligned.toTranscriptome.out.bam -o $OUTPUT_DIR -t gencode.vM9.pc_transcripts.fa -g gencode.vM9.annotation.gtf` since the RNAME and the FASTA headers don't match, causing a large number of messages like `WARNING: Transcript ENSMUST00000082421.1|ENSMUSG00000064370.1|-|-|mt-Cytb-201|mt-Cytb|1144|CDS:1-1144| appears in the reference but did not appear in the BAM`. Similarly, the gene quantification mode won't work either, since the names in -t and -g will never match. While for the immediate need I can just trim the fasta headers from the GENCODE transctipts.fa using a simple script, it must be an oversight that the same functionality is provided in quasi-alignment mode only.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/95:1203,message,messages,1203,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/95,1,['message'],['messages']
Integrability,"Damn. There are random numbers, but even setting the seed, the multi-threaded nature of almost all steps leads to non-deterministic behavior. The behavior you describe sounds like some sort of race condition that gets triggered depending on when threads get to different parts of the code. I couldn't get the hanging with the other dataset over multiple (~10) runs. So even if it's completely non-deterministic you seem to be getting it with higher frequency in your system. Is it always in the Gibbs phase? One question / thought, did salmon fetch and build the Intel TBB dependency, or are you using a system version?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266951967:228,depend,depending,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266951967,2,['depend'],"['dependency', 'depending']"
Integrability,"Damn; I get the same behavior on ~~16.10~~ (actually, my box is 16.04, but I'm skeptical that this specific version issue is the cause of the behavior) as I get on 14.10 (using the executable you provided). It runs to completion and modulo our less-than-ideal handling of the `--libType` flag coming after the `--unmatedReads` flag, it completes without the Gibbs warning. When I run with `--seqBias` and `--gcBias`, I get the same behavior (it runs and finishes w/o hanging or outputting the error messages). I'm going to take a look at the relevant code path to see if anything stands out to me.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266938104:499,message,messages,499,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266938104,1,['message'],['messages']
Integrability,"Dear @callumparr,. Thank you for bringing this up. So you are correct that the `--noLengthCorrection` flag should be passed to salmon when quantifying data that does not have a ""fragmentation effect"", that is, where the number of fragments we expect to draw from a transcript is not dependent upon the length of that transcript. In the ONT protocols, it is usually the case that we get 1 read -> 1 transcript, even if we don't read the whole thing. We have tested the effect of this in ONT data with spike ins, and have verified that using `--noLengthCorrection` does generally lead to improved accuracy with respect to quantification estimates. We have informed ONT of this, and I would guess they may optimize the flags that are used soon (we have also developed an error model that works correctly for these long reads, and that should make it into the next release of salmon). Regarding the effect this has on the `NumReads` values reported by salmon, it's not as simple as with the `TPM` estimates. The length affects the assigned reads through the probabilistic model on which inference is done. With the length effect we have that P(f | t_i) ∝ P( position | f, t_i ) * P( alignment | f, t_i) --- forgetting the alignment term for the time being, we have that with length correction P( position | f, t_i ) ∝ 1 / l_i and without length correction the l_i term goes away. In other words, the probability of allocating reads has a term that depends on the effective length when the `--noLengthCorrection` flag is not passed, but that term goes away when it is passed. This is not quite as drastic as with TPM where the normalization includes the length directly in the normalization (note, however, that when the `--noLengthCorrection` flag is passed, this adjusts the TPM as well). Further, the `NumReads` is still better than TPM in this regard because it still encodes the effect size (i.e. `NumReads` will sum to the total number of aligned reads). Anyway TLDR: Passing the `--noLengthCorrectio",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147:283,depend,dependent,283,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147,2,"['depend', 'protocol']","['dependent', 'protocols']"
Integrability,"Dear Rob, thank you for the fast replay. a) I tried to compile but it is not working for me either; ....; _[100%] Linking CXX executable salmon; /usr/bin/ld: ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): in function `find_file_url':; open_trace_file.c:(.text+0xf74): warning: the use of `tempnam' is dangerous, better use `mkstemp'; during IPA pass: icf; lto1: internal compiler error: Segmentation fault; 0xd12487 internal_error(char const*, ...); 	???:0; 0xe4f0b6 varpool_node::get_constructor(); 	???:0; 0xea01ff ipa_icf::sem_item_optimizer::subdivide_classes_by_equality(bool); 	???:0; 0x12ab4cb ipa_icf::sem_item_optimizer::execute(); 	???:0; Please submit a full bug report,; with preprocessed source if appropriate.; Please include the complete backtrace with any bug report.; See <file:///usr/share/doc/gcc-11/README.Bugs> for instructions.; lto-wrapper: fatal error: /usr/bin/c++ returned 1 exit status; compilation terminated.; /usr/bin/ld: error: lto-wrapper failed; collect2: error: ld returned 1 exit status; make[2]: *** [src/CMakeFiles/salmon.dir/build.make:486: src/salmon] Error 1; make[1]: *** [CMakeFiles/Makefile2:665: src/CMakeFiles/salmon.dir/all] Error 2; make: *** [Makefile:166: all] Error 2_. 2) bioconda on a server is a mess. it will be my last resort. 3) I am trying the Docker version and it seems to work!!!; ; PS It seems to me a be a little strange though that the binary version is not working. I tried on three different systems (all with ubuntu 22.04) with Xeon gold and intel i7 . thank you again",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1144000013:890,wrap,wrapper,890,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1144000013,2,['wrap'],['wrapper']
Integrability,"Dear Salmon Team, . Not sure if this message should go here or on the google group, sorry if it shouldn't go here. . I am trying to analyse meta-transcriptome RNAseq data to obtain genes expression from ""complex"" microbial samples (over a 100 strains of bacteria and fungi). I have over 500 millions reads so aligning these reads on references genomes would take forever... Salmon thus looks like a promising solution. . However, i am not sure Salmon is appropriate for meta-transcriptome data. Is there prerequisites if i want to use Salmon for that purpose ? What would be your recommended parameters ?. So far, since i have a reference genome (and thus the associated coding sequences) for all the strains i created a single Salmon Index (comprising all the strains cds) and ran the quantification tool on this index using these parameters: ; salmon quant -i index --libType A --validateMappings --seqBias --incompatPrior 0.0 -r input.fa -o output . I did not include gcbias correction so far because i am not sure it is appropriate in this case. Thanks for you help, . Nathan",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/350:37,message,message,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/350,1,['message'],['message']
Integrability,"Dear alevin team,. I am a developer of Quartz-Seq2 ([Sasagawa Y. et al. Genome Biol. 2018](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1407-3); [Mereu E. et al. bioRxiv](https://www.biorxiv.org/content/10.1101/630087v1)), one of 3’ tagged-end single-cell RNA sequencing. Could you add `Rule` of Quartz-Seq2 protocol to SingleCellProtocols.hpp?. ```; struct QuartzSeq2v31 : Rule{; //Quartz-Seq2 v3.1 starts from 5 end with 14 length; //barcode and 8 length umi & iupac can be; //changed; QuartzSeq2v31(): Rule(14, 8, BarcodeEnd::FIVE, 268435456){}; };. struct QuartzSeq2v32 : Rule{; //Quartz-Seq2 v3.2 starts from 5 end with 15 length; //barcode and 8 length umi & iupac can be; //changed; QuartzSeq2v32(): Rule(15, 8, BarcodeEnd::FIVE, 1073741824){}; };; ```. Best,; Itoshi",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416:331,protocol,protocol,331,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416,1,['protocol'],['protocol']
Integrability,"Dear community,. I have 4 lane files for each sample. I want to run Alevin on these samples. Alevin runs without any error, but the mapping rate is too low (about 5%). I tried different k-mers, different versions of transcriptome datasets, and all protocols (--dropseq / --chromium / --chromiumV3), but my mapping rate is still too low. Let me explain my workflow. These are my samples:. ```; Sample1_S1_L001_I1_001.fastq.gz Sample1_S1_L002_R1_001.fastq.gz Sample1_S1_L003_R2_001.fastq.gz; Sample1_S1_L001_R1_001.fastq.gz Sample1_S1_L002_R2_001.fastq.gz Sample1_S1_L004_I1_001.fastq.gz; Sample1_S1_L001_R2_001.fastq.gz Sample1_S1_L003_I1_001.fastq.gz Sample1_S1_L004_R1_001.fastq.gz; Sample1_S1_L002_I1_001.fastq.gz Sample1_S1_L003_R1_001.fastq.gz Sample1_S1_L004_R2_001.fastq.gz; ```. I generated single I1, R1 and R2 files by concatenating fastq.gz files across lanes; for instance, Sample1_S1_L001_R1_001.fastq.gz + Sample1_S1_L002_R1_001.fastq.gz + Sample1_S1_L003_R1_001.fastq.gz + Sample1_S1_L004_R1_001.fastq.gz -> Single_S1_L001_R1_001.fastq.gz . I indexed my transcriptome by salmon, and I used Alevin using the indexed transcriptome. I used the following command:. ```; salmon alevin -l ISR \; -1 ""Single_S1_L001_R1_001.fastq.gz"" \; -2 ""Single_S1_L001_R2_001.fastq.gz"" \; --chromiumV3 \; -i $my_index \; -p 48 \; -o outputfolder \; --tgMap $my_tgmap \; --expectCells 10000 \; --forceCells 10000; ```. However, my mapping rate is only ~5%. I used cell ranger on the same data and the same transcriptome; the mapping rate is ~95%.; Is there any bug on Alevin? How can I improve the mapping rate?. Thank you!. ```; Alevin log:; [2022-12-03 15:43:12.004] [alevinLog] [info] Found 117342 transcripts(+0 decoys, +35 short and +0 duplicate names in the index); [2022-12-03 15:43:12.072] [alevinLog] [info] Filled with 117377 txp to gene entries; [2022-12-03 15:43:12.083] [alevinLog] [info] Found all transcripts to gene mappings; [2022-12-03 15:43:12.097] [alevinLog] [info] Processing barcodes fi",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/814:248,protocol,protocols,248,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/814,1,['protocol'],['protocols']
Integrability,"Dear salmon authors,. While I was using **salmon (v0.11.0, downloaded executable, on a Ubuntu Linux** server) to process a **single-end RNA-seq library**, it reported the following error message:. ""**[ERROR] Transcript IDs are not in sorted order; please report this bug on GitHub!**"" . Actually I found it reports this error message for over tens of millions of times through greping the log file. And the command line I applied to invoke salmon was like this:. ""**salmon quant -i mySalmonIndexFile(FMD based/transcriptome) -l A -r myLibrary.fastq -p 8**"". It looks like this is something about single-end reads processing, since I arbitrarily picked up another pair-end library, which works prefectly fine with command line ""-1 PE_library_1.fastq -2 PE_library_2.fastq"", however, when I deliberately provide only one end of the library with ""-r PE_library_1/2.fastq"", exactly the same error was recurred immediately. Curiously, salmon could still accomplish the whole procedure and generate the results file with the aformentioned error reported. But I' m worried about its reliability in this situation. I' m wondering if you have any clues about this issue. With many thanks ahead!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/265:187,message,message,187,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/265,2,['message'],['message']
Integrability,"Depending on what environment you install in (other conda software), the default resolver in conda is messed up. You should just explicitly ask for 1.10.2 with “ conda install salmon=1.10.2”. You can also try installing it in a clean conda env which is how I install most of my conda software anyway. Best,; Rob. note: these resolver issues are a conda problem, and there’s nothin we as the salmon devs can do. So if you’d like to be able to avoid specifying the version, even when you put it in an env with arbitrary other software, I suggest making aMWE and opening an issue upstream in conda/bioconda.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784085120:0,Depend,Depending,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784085120,1,['Depend'],['Depending']
Integrability,"Drone is awesome! The problem seems to be related to the ancient image on which we do CI (holy build box) having a version of curl that, just now (in the last day?), became incompatible with github's OpenSSL protocol. I guess they did an update, and now my version of curl is too old. I think we need to update the image.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/199#issuecomment-368083042:208,protocol,protocol,208,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/199#issuecomment-368083042,1,['protocol'],['protocol']
Integrability,"Due to a current default in the boost library (https://github.com/boostorg/math/issues/1211) in boost::math::digamma, there is a performance hit on aarch64. This happens on v1.10.3 of Salmon, with GNU compiler 13 on Linux aarch64. A 4-thread quantization of one of the Salmon tutorials DRR0* series files spends ~15% of time in this routine (called within CollapsedEMOptimizer). On a larger example, we see 7% performance hit over a run that takes 1300 seconds on 4 cores. On x86 this time is small enough to be lost in the noise. `salmon quant -i athal_index -l A ; -1 DRR016125/DRR016125_1.fastq.gz; -2 DRR016125/DRR016125_2.fastq.gz ; -p $threads --validateMappings -o quants/DRR016125_quant`. There is a simple fix which is to ensure the CMake/Makefiles ensure salmon compiles with: ; `-DBOOST_MATH_NO_LONG_DOUBLE_MATH_FUNCTIONS`; or to add that to any file that brings in boost::math via adding `#define BOOST_MATH_NO_LONG_DOUBLE_MATH_FUNCTIONS` at the start. With that change, a 1300 second runtime drops to 1212 for the larger test case, and for the tutorial case is 48 seconds down to 40 on a 4-core r8g.xlarge (Graviton4). Whilst Boost may fix the issue soon - it's likely that older versions of the library will be found installed for some time. It would be helpful to add this define to cmake settings, or the sources.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/966:333,rout,routine,333,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/966,1,['rout'],['routine']
Integrability,"Exactly, I meant that if the dep is not already satisfied, I'll pull the source and compile and install it locally (not that I would bundle the dependency with salmon).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193942045:144,depend,dependency,144,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193942045,1,['depend'],['dependency']
Integrability,"FYI, I'm taking another crack at an official FreeBSD port, but still hitting some gnarly issues with 1.5.2, so it might be a while. https://github.com/outpaddling/freebsd-ports-wip/tree/master/salmon; https://github.com/outpaddling/freebsd-ports-wip/tree/master/pufferfish; https://github.com/COMBINE-lab/salmon/issues/502. 1. The cmake system still forces downloading pufferfish during configure, which is forbidden in the ports system (like many other package managers). All downloads must occur during fetch phase and be verified using locally stored checksums. This would be easy to work around using GH_TUPLE, which downloads additional distfiles during fetch phase, except that fetchPufferfish.sh doesn't just extract the pufferfish dist, but has a long list of ""cp"" commands to copy pieces of it to ${INSTALL_DIR}. That's not something I'm inclined to tamper with since it will likely change with new versions and hence be a headache to maintain over time. It would be ideal if salmon could work with a separately installed pufferfish as it does with many other dependencies. This would make the port much cleaner.; 2. The code is not compatible with onetbb 2021.3, which is the current FreeBSD ports version.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-917642392:1069,depend,dependencies,1069,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-917642392,1,['depend'],['dependencies']
Integrability,"FYI: [https://github.com/outpaddling/freebsd-ports-wip/tree/master/salmon](https://github.com/outpaddling/freebsd-ports-wip/tree/master/salmon). It would be good to update to onetbb 2021 soon. FreeBSD ports still has a 2020.3 legacy port, but we're trying to update everything that depends on it so it can be retired. I think maybe this issue can be closed at this point?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-989322122:282,depend,depends,282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-989322122,1,['depend'],['depends']
Integrability,"Finalky i found that my transcript file was crashed during uploading to my; server; I repeated the process. It works now; Thank you so much. في الاثنين، ٢٢ أغسطس ٢٠٢٢ ٣:٢١ م Rob Patro ***@***.***> كتب:. > Hi @esraagithub <https://github.com/esraagithub>,; >; > Thanks for the bug report. Can you tell me how the specific version of; > salmon you are using was installed (e.g. via source, downloaded from the; > ""releases page"", or installed via bioconda)? Would it be possible to share; > the contigs that cause this error?; >; > Thanks,; > Rob; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/795#issuecomment-1222353941>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AMY4XZX6ZGAO5DOU5YOWTG3V2N5DZANCNFSM57HUQWJQ>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/795#issuecomment-1223885767:859,Message,Message,859,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/795#issuecomment-1223885767,1,['Message'],['Message']
Integrability,Fix typo in CMake message,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/44:18,message,message,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/44,1,['message'],['message']
Integrability,Fixes just a small typo in a user message.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/44:34,message,message,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/44,1,['message'],['message']
Integrability,"Fwiw, the conda resolver is not the only issue:. >conda create -n salmon -c bioconda -c conda-forge salmon=1.10.2. Collecting package metadata (current_repodata.json): done; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): / Killed. Adam H. Freedman, PhD; Data Scientist; Faculty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 8:04 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; Author ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). Depending on what environment you install in (other conda software), the default resolver in conda is messed up. You should just explicitly ask for 1.10.2 with “ conda install salmon=1.10.2”. You can also try installing it in a clean conda env which is how I install most of my conda software anyway. Best,; Rob. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784085120&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=BuO8x-09ODKHZCV2IlEsuaycWlFfWjCrfXJ-22PbmV0x8PssZEMVgCYeWBbR1GlW&s=Ea4-F5juBTywwyjamWmiXQu3PVrQ4kCnIg-68wR1Pa4&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ADBMMUHDLECWA4NGVBBX7R3YBZA5HAVCNFSM6AAAAAA6UYYPGOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTOOBUGA4DKMJSGA&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=BuO8x-09ODKHZCV2IlEsuaycWlFfWjCrfXJ-22PbmV0x8PssZEMVgCYeWBbR1GlW&s=UIOMil_E-TPQw6P8DHvvV7-jaFu1apAxBIJgLzjUtvs&e=>.; You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784119351:806,Depend,Depending,806,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784119351,2,"['Depend', 'Message']","['Depending', 'Message']"
Integrability,"GGCGTTCTTGCATTCCTGGAACCT; +D00585:40:CB7FUANXX:1:2113:18626:8045; BBBBBFFFFFFFFFFFF<FBFFFFFF; ``` . And an extract of the reads fastq:; ```; @D00585:41:CB64LANXX:1:1202:13646:88674; TCTGTTCATGTGTATTTGCTGTCTCTTAGCCCAGACTTCCCGTGTCCTTTCCACCGGGCCTTTGAGAGGTCACAGGGTCTTGATGCTGTGGTCTTCAT; +D00585:41:CB64LANXX:1:1202:13646:88674; BFFF<FFFBFFB<FFFB<FFFBF//FFFFB<FFFF<F///FFFB/BF<//F<7//FBFBB/F<BF</F<FFFFFFFF<</<FFBFBFFBFF<FBBBBB; @D00585:40:CB7FUANXX:1:2113:18626:8045; ATGTGTATTTGCTGTCTCTTAGCCCAGACTTCCCGTGTCCTTTCCACCGGGCCTTTGAGAGGTCACAGGGTCTTGATGCTGTGGTCTTCATCTGCAGG; +D00585:40:CB7FUANXX:1:2113:18626:8045; FFFFFBFFFFFFFFFFFB/FBFFFFBFFFFFFFBBFFFFFFFFFFFFFFFFFFFFFFFFFFFFFBFFFBFFFFFFFFFFFFFFFFFF<FFBFFBBBBB; ``` . This is the log of the analysis:; ```; Version Info: This is the most recent version of salmon.; Logs will be written to /mnt/beegfs/alexmascension/Projects/Single-cell_skin_analysis//Data/Cheng-2018//Alevin/sample/logs; [2019-06-23 18:08:01.732] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 16, 10) is being used. Updating UMI k-mer length accordingly.; [2019-06-23 18:08:01.803] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-23 18:08:01.804] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-06-23 18:08:01.804] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-06-23 18:08:01.804] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-06-23 18:08:01.804] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2019-06-23 18:08:01.805] [alevinLog] [info] Loading Header; [2019-06-23 18:08:01.807] [alevinLog] [info] Loading Transcript Info ; [201",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386:1654,protocol,protocol,1654,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386,1,['protocol'],['protocol']
Integrability,"GitHub supports uploading files directly in the issues, so I'll compile the updated binary and I'll drop it right here (I'll do this today, but it might be an hour or so). Once you have it, you can confirm if it works for you (I'm still on 10.11, so I'll have to build it there, but with the updated dependency).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-259466544:300,depend,dependency,300,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-259466544,1,['depend'],['dependency']
Integrability,"Good Afternoon,. I hope this message finds you well. . I am having a hard time running salmon version 0.14.1 downloaded via bioconda. I am trying to count my reads using alignment-based mode. Whenever I run the program, I get similar error messages to [issue 104](https://github.com/COMBINE-lab/salmon/issues/104). Here is the command I am running:. salmon quant -t trimmed_fasta/SRR1810204_1.trim.fastq -l A -a results/bam_files/SRR1810204_1.trim.fastq.bam -o salmon_test. trimmed_fasta/SRR1810204_1.trim.fastq is a fastq sample that I've obtained following trimmomatic and contains the forward strands of the data. . results/bam_files/SRR1810204_1.trim.fastq.bam is the bam file following bwa alignment of the fastq file here and its reverse strand to a reference database. . Could the issue be that I am not using both forward and reverse strands in the target argument for salmon since they were both used to generate the alignment file? I tried to look at the docs for guidance on the best course of action, and I had a hard time finding info. All help would be very much appreciated. All the best,; Craig",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/520:29,message,message,29,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/520,2,['message'],"['message', 'messages']"
Integrability,"Good morning,. I'm a *nix developer with a lot of experience porting software to various platforms. My preferred method for deployment is build-from-source package managers such as FreeBSD ports, Gentoo Portage, MacPorts, pkgsrc (which I use extensively on CentOS), etc. Package managers in-general minimize problems for end users (and hence reduce PRs for you guys). Build-from-source package managers also allow customizing build options (e.g. adding -march=native), which can sometimes offer significantly better performance than you can get from a generic binary package that has to support older CPUs. Currently, developing such packages for salmon is a challenge due to the way the build system works. I've been looking through the build system and the main barrier to packaging is the unconditional bundling of some dependencies, such as seqlib and htslib. If you were to update the cmake systems so that they first look for *all* dependencies installed externally, as they already do for jemalloc and tbb, then it would be easier for developers to package salmon. Best,. Jason",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/502:823,depend,dependencies,823,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/502,2,['depend'],['dependencies']
Integrability,"Great suggestion, thanks @rob-p and @gmarcais . Somehow, I missed it. I added it in the latest commit. Speed now from 3 runs:; ```; real 1m19.884s 1m15.891s 1m21.462s ; user 8m9.189s 9m1.100s 9m48.764s ; sys 0m5.079s 0m5.170s 0m3.477s; ```; 50% improvement over the past results, i.e., about 33% slower than specific protocol flag now. Although, ideally I should have ran the earlier tests thrice but the sd is small so results should be valid. Nonetheless, I'll do more speed tests with versions in the future. . Let me know what other thoughts you have and what else have I missed. I have some minor improvements in mind too.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013326966:317,protocol,protocol,317,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013326966,1,['protocol'],['protocol']
Integrability,"Great; would you like help testing the pipeline, and integrating it into bcbio? We could help with both :)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-255123178:53,integrat,integrating,53,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-255123178,1,['integrat'],['integrating']
Integrability,"Greetings,. When trying to debug test failure, I ended up with an incomplete error messages which turned out to stem from a typo in the variable name, so I took the liberty to make the whole message a bit more verbose to help with the present and future debugging. I thought you might be interested.; Have a nice day, :); Étienne.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/810:83,message,messages,83,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/810,2,['message'],"['message', 'messages']"
Integrability,"HI @Acribbs ,. Thanks for the very interesting question.; I think the first question in my mind is, do you need intron level deduplicated counts ? If yes, then sadly concatenating the pre-mrna sequence into the transcriptome sequences is probably not a good idea, as in general, the length of intronic sequences are much longer than that of exonic sequence and it may bias alevin deduplication algorithm. However, if you don't need the number of unspliced deduplicated counts and as the nuceli scRNA-seq has more pre-mRNA data if the question is regarding the aligning to genome v transcriptome then we just proposed a solution in our latest [preprint](https://www.biorxiv.org/content/10.1101/657874v1?rss=1). The new SA method is already integrated into salmon but you may have to index the genome+transcriptome using our scripts from [here](https://github.com/COMBINE-lab/SalmonTools). Hope it helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/370#issuecomment-499513288:739,integrat,integrated,739,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/370#issuecomment-499513288,1,['integrat'],['integrated']
Integrability,"HI @gianfilippo ,; I think #245 might help understanding the problem better.; Specifically to answer your questions, I am guessing `737K-august-2016.txt` is all the set of Cellular Barcodes(CB) being whitelisted by 10xGenomics protocol while in Alevin when you are giving external whitelist it assumes that the user is pretty confident about the presence of *all* the given CBs in their experiment. for example if you want to compare Alevin and cellranger apple to apple then you might have to give the `barcodes.tsv`(usually is present along with the `mtx` file) generated by the cellranger. (after removing `-1` from the CB names). ; `[alevinLog] [error] Barcode not found in frequency table`: This error means some of the CB given externally through the whitelist command seems to have no reads at all which violates the above assumption, you can potentially skip this error by using `--debug` flag with alevin (only if have version v0.11.3) but this mode has is yet to be extensively tested.; In case where you don't externally give whitelist CB, Alevin uses knee and KDE based method to identify the cutoff on the knee (and later correct for it) of the CB distribution. Based on your specific dataset it is possible that the method might be overshooting and aggressively identifying less number of clusters. If you can share the log and some part of your data then we can take a look what's going on. Hope this helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-417964393:227,protocol,protocol,227,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-417964393,1,['protocol'],['protocol']
Integrability,"HI @mfansler ,; Thanks for asking the very important question.; Alevin is primarily (till current release) designed to work with 3'-tagged end, droplet based sequencing where the primary assumption is that most of the reads would ideally be sequenced from the 3'-end of the molecule. Although, Salmon is a transcript quantification tool for *bulk* RNA-seq but we believe in singe-cell (3'-tagged) sequencing, generating quantification at transcript level is fundamentally hard problem to solve. Specifically, one of the reason is, a lot of transcripts share the terminal exon, and the features like length effect which are used in bulk RNA-seq to resolve ambiguity is not directly usable in single-cell for resolving the transcript ambiguity making the problem hard.; It's possible in the future that assays are designed to help incorporate more information e.g. sequencing from both 5' or 3' end sequencing or use SMART-seq2 which sequence the full molecule. In latter case people have been using Salmon as-is for generating the transcript level quantification. . _In summary_: We believe it's a trade-off based on your use case i.e. if you wan't to generate transcript level counts then most-likely single cell protocols which sequence from the full length of the molecules like smart-seq2 is better suited but if the motivation is to get higher number of cell coverage w/ decent gene-level molecule counts that's where 3'-end tagged end sequencing protocols shines most. _One Liner_; Alevin generates only gene-level counts for droplet based sequencing (til latest release v0.11.2).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/287#issuecomment-420627713:1213,protocol,protocols,1213,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/287#issuecomment-420627713,2,['protocol'],['protocols']
Integrability,"Hello Again,. I just ran the command and got the same error message as before. Here is my; command:. ```#!/bin/bash -l; #SBATCH -J male_salmon_map; #SBATCH -t 150:00:00; #SBATCH -p high; #SBATCH --cpus-per-task=24; source ~/.bashrc; source activate salmon; cd /home/seboles/abaloneraw/salmon_quantification/SALMON_MALE/; for i in *.qc.fq.gz; do; salmon quant -i maleredabalone_index --libType IU -1; mgonad-2_S121_L006_R1_001.qc.fq.gz; lightreceptor-1_S114_L006_R1_001.qc.fq.gz; mgonad-1_S120_L006_R1_001.qc.fq.gz; lightreceptor-2_S115_L006_R1_001.qc.fq.gz; mgonad-2_S121_L005_R1_001.qc.fq.gz mgonad-1_S120_L005_R1_001.qc.fq.gz; lightreceptor-2_S115_L005_R1_001.qc.fq.gz; lightreceptor-1_S114_L005_R1_001.qc.fq.gz; mgonad-2_S121_L004_R1_001.qc.fq.gz mgonad-1_S120_L004_R1_001.qc.fq.gz; lightreceptor-2_S115_L004_R1_001.qc.fq.gz; lightreceptor-1_S114_L004_R1_001.qc.fq.gz -2; mgonad-2_S121_L006_R2_001.qc.fq.gz; lightreceptor-1_S114_L006_R2_001.qc.fq.gz; mgonad-1_S120_L006_R2_001.qc.fq.gz; lightreceptor-2_S115_L006_R2_001.qc.fq.gz; mgonad-2_S121_L005_R2_001.qc.fq.gz mgonad-1_S120_L005_R2_001.qc.fq.gz; lightreceptor-2_S115_L005_R2_001.qc.fq.gz; lightreceptor-1_S114_L005_R2_001.qc.fq.gz; mgonad-2_S121_L004_R2_001.qc.fq.gz mgonad-1_S120_L004_R2_001.qc.fq.gz; lightreceptor-2_S115_L004_R2_001.qc.fq.gz; lightreceptor-1_S114_L004_R2_001.qc.fq.gz ${i} -o ${i}_quant --seqBias; --gcBias --validateMappings; done```. And here is my output from salmon.log. [2019-07-30 10:40:14.624] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-30 10:40:14.624] [jointLog] [error] You passed paired-end files to; salmon, but you passed 12 files to --mates1 and 13 files to --mates2. You; must pass the same number of files to both flags. Thank you in advance for any tips you may have for me. Sara. On Tue, Jul 30, 2019 at 10:30 AM Sara Boles <seboles@ucdavis.edu> wrote:. > Hi Avi,; >; > Here is the salmon log from one of my PE libraries. There are",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791:60,message,message,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791,1,['message'],['message']
Integrability,"Hello Bob, ; I am trying to implement Salmon 1.5.3 and I have problems running the quant mode. I succeed to prepare the index using decoy protocol and I am trying reads quantification mode.; I; used this command line:; ./src/salmon-1.5.2_linux_x86_64/bin/salmon quant -i salmon_index -l ISF -1 rawDataPE/ERR3537668_1.fastq.gz -2 rawDataPE/ERR3537668_2.fastq.gz --validateMappings -o transcripts_quant_test. and I got this message error:; Exception : [std::bad_alloc]; ./src/salmon-1.5.2_linux_x86_64/bin/salmon quant was invoked improperly.; For usage information, try ./src/salmon-1.5.2_linux_x86_64/bin/salmon quant --help; Exiting. Would you have any idea why I got this message error? Could you please help me to solve this problem?; Best ; Luciana",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/717:138,protocol,protocol,138,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/717,3,"['message', 'protocol']","['message', 'protocol']"
Integrability,"Hello Rob,. Thank you for your quick reply to my question. My MEGAHIT and Trinity assemblies were not built with strand-aware flags. I made decoy-aware transcriptomes using a MEGAHIT assembly, a Trinity Assembly, and a published transcriptome from the same species, and when I ran my read files through salmon using ""A"" as the library type and each of the three indexes, all three were detected as ""most likely library type IU"". It's strange that once all three have been compiled into a single assembly using Evigene, salmon detects the ISR library type. When I change the ""A"" to ""ISR"" or ""IU"", the % mapped changes a lot. ; Is it better to build assemblies with strand-aware flags? If so, does it usually make a large difference to quantification results, or a minor one? I don't know what protocol the sequencing facility used, but I am sure I could ask them. I gather from my recent reading that the extra information gained by using a stranded protocol _is_ worthwhile, so I would expect that the sequencing facility used one, but why doesn't Trinity or MEGAHIT detect the sequecing protocol that was used? Or, if you have to specify it, why do none of the example Trinity commands I've come across include this option? It doesn't strike me as a commonly used specification in making assemblies. Thanks for answering my noobie questions. Holly",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1492849365:792,protocol,protocol,792,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1492849365,3,['protocol'],['protocol']
Integrability,"Hello Rob,; First, thanks for developing Salmon!. When running Salmon quant (v 0.91), I'm getting messages like this "" [warning] couldn't find transcript named [uc022cpe.1] in transcript <-> gene map; returning transcript as it's own gene"" for all the transcripts although the -g option is in use. . This happens even though my file does contain the relevant gene and transcript names, since when I search for the transcripts, I do find them in the GTF file:; grep uc022cpe.1 ~/gtf_files/hg19_UCSCgenes_gene_names.gtf; chrY	hg19_knownGene	exon	28507136	28507239	0.000000	+	.	gene_id ""U6""; transcript_id ""uc022cpe.1"";. My command line was: . ~/miniconda2/envs/salmon/bin/salmon quant -i ~/salmon/hg19_index_v0.91 -l A -1 <(bunzip2 -c my_fastq_1.fastq.bz2) -2 <(bunzip2 -c my_fastq_2.fastq.bz2) -o my_output -g ~/gtf_files/hg19_UCSCgenes_gene_names.gtf. Any suggestion? . Than you for your support,; Doron",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/208:98,message,messages,98,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/208,1,['message'],['messages']
Integrability,"Hello all, . I really wish Salmon was easier to install. . When running: . _cmake -DFETCH_BOOST=TRUE -DCMAKE_INSTALL_PREFIX='/home/.../salmon-master/'_. I get the following message: . _Making Release build; running /home/Documents/apps/salmon-master/scripts/fetchRapMap.sh 2>&1; /home/Documents/apps/salmon-master/scripts/fetchRapMap.sh: line 33: curl: command not found; -- fetch RAPMAP exit code 127. CMake Error at CMakeLists.txt:265 (message):; Could not fetch RapMap source [fetchRapMap.sh returned exit code 127]. -- Configuring incomplete, errors occurred!; See also ""/home/krablab/Documents/apps/salmon-master/CMakeFiles/CMakeOutput.log"".; See also ""/home/krablab/Documents/apps/salmon-master/CMakeFiles/CMakeError.log""._. This seems to be an issue that keeps coming up. What is the proper way to solve it? ; Thanks in advance",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/331:173,message,message,173,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/331,2,['message'],['message']
Integrability,"Hello all, we are trying to use salmon quant on environmental samples using a big index but the quant step keeps crashing. While trying to quant different samples all crashed at the same step with the error message: `Exception : [Failed to read 130159192 bytes from input stream! Read 65079596]`. The system is part of a cluster and we have requested 500gb of RAM and disk available for the job and I kept track of the memory and disk usage which never exceeded 254gb. lsb_release -a; ```; LSB Version:	:base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch; Distributor ID:	Scientific; Description:	Scientific Linux release 6.4 (Carbon); Release:	6.4; Codename:	Carbon; ```. Do you have any idea what can be the causing the error?. Thanks. We are using the precompiled salmon bin and running it with:. `salmon quant -i $index -1 $f1 -2 $f2 -o $output_folder --meta --incompatPrior 0.0 --libType A -p 8 --gcBias --seqBias --numBootstraps 30`. ```; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { ./storage/tmm.idx }; ### [ mates1 ] => { DNA_1.fastq.gz }; ### [ mates2 ] => {DNA_2.fastq.gz }; ### [ output ] => { /DNA_tmm }; ### [ meta ] => { }; ### [ incompatPrior ] => { 0.0 }; ### [ libType ] => { A }; ### [ threads ] => { 8 }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; ### [ numBootstraps ] => { 30 }; Logs will be written to ./storage/logs; [2017-03-15 11:53:20.568] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2017-03-15 11:53:20.568] [jointLog] [info] parsing read library format; [2017-03-15 11:53:20.568] [jointLog] [info] There is 1 library.; [2017-03-15 11:53:20.653] [jointLog] [info] Loading Quasi index; [2017-03-15 11:53:20.683] [jointLog] [info] Loading 64-bit quasi index; [2017-03-15 11:53:20.684] [stderrLog]",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129:207,message,message,207,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129,1,['message'],['message']
Integrability,"Hello there!. I am analysing BD Rhapsody Single cell data and am wondering how to proceed with Salmon Alevin. After alignment I expected to create a Seurat Object with information of sample tags obtained from R2 but I could not achieve this. ### **Background**; This is mice data comprised of 2 sequences: R1 contains CB (27bp divided in three sections of 9bp) and UMI, while R2 contains sample tag information and the transcript info as well. I need to differentiate not only the CB, but also the sampletags present in R2 since there are 5 different samples per cartridge. As stated in page 30 of the [BD Library Preparation Protocol](https://www.bdbiosciences.com/content/dam/bdb/marketing-documents/resources-pdf-folder/Protocol-EnhBead-+-Targeted+-AbSeq-+-ST-ruo.pdf), each sampletag is 70bp long (sampletag + abseq). . I have followed the [BD Single-Cell Multiomics Bioinformatics Handbook](https://scomix.bd.com/hc/article_attachments/9315606097549/23-21713_03__BD_Single-Cell_Multiomics_Bioinformatics_Handbook_EN.pdf), in which page 20 states: . > To account for every Sample Tag, each Sample Tag sequence in the kit is considered during pipeline analysis, whether the Sample Tags are used in the experiment or specified with a sample name.; The pipeline automatically adds the Sample Tag sequences to the FASTA reference file. Reads that align to a Sample Tag sequence and associate with a putative cell are used to identify the sample for that cell. ### **What I have tried so far**. 1. Added the sample tag sequences to the end of gentrome file; ```; [user@remote]$ tail -n 80 m.mus_gentrome.fa.gz; >JH584295.1 dna_sm:scaffold scaffold:GRCm39:JH584295.1:1:1976:1 REF; GGCTGAGCGGTGACATCATGGGCGGCGGGGTCCCAGACAGGAAGTGGGCGTGGCCTCCCA; CACTCACCCTGGCCCGCGGCGTCTGCCAGGTCGCTGTCCGAGATGCCGCCTGTggggggg; [...]; >sampletag11G; GTTGTCAAGATGCTACCGTTCAGAGGGTTGGCTCAGAGGCCCCAGGCTGCGGACGTCGTCGGACTCGCGT; >sampletag12G; GTTGTCAAGATGCTACCGTTCAGAGCTGGGTGCCTGGTCGGGTTACGTCGGCCCTCGGGTCGCGAAGGTC; ```. 2. Added the",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/850:626,Protocol,Protocol,626,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/850,2,['Protocol'],"['Protocol', 'Protocol-EnhBead']"
Integrability,"Hello! I am having some difficulty quantifying RNAseq data with salmon in mapping-based mode. I have been struggling with this for a few days and would be very grateful for any advice on how to move forward. Thank you in advance. Here is my command:; ```; #!/bin/bash -l ; #SBATCH -J male_salmon_map; #SBATCH -t 700:00:00; #SBATCH -p high; #SBATCH --cpus-per-task=24; source ~/.bashrc; source activate salmon; cd /home/seboles/abaloneraw/salmon_quantification/salmon_male/abalone_orfs/; ./bin/salmon -i salmon_index -p 8 -l --libType A -1 *R1_001.qc.fq.gz -2 R2_001.qc.fq.gz --validateMappings -o transcripts_quant; ```; # And here is my error message:. ```; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.347] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.347] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.347] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.347] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/ve",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:644,message,message,644,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['message'],['message']
Integrability,"Hello!. I'm packaging salmon and many of its dependencies for Debian in support of https://github.com/Blahah/transrate/issues/160. I have a messy patch to enable the use of external libraries instead of bundled or downloaded copies at http://anonscm.debian.org/cgit/debian-med/salmon.git/plain/debian/patches/dependency-fix. As I'm not a CMake expert I was only able to make it work for Debian instead of a generic solution that would fall back to the shipped copies or downloading as it is now. Perhaps you all are better with CMake than I am? A generic solution would be best so I don't have to adjust the patch with every change to the CMakeLists.txt. Specifically it would be great to support; - [ ] external copy of spdlog headers and the cereal serialization headers; - linking to external dynamic libraries for; - [ ] boost; - Headers: https://packages.debian.org/sid/amd64/libboost1.58-dev/filelist; - Sample library layout: https://packages.debian.org/sid/amd64/libboost-filesystem1.58-dev/filelist; - [ ] bwa; - Headers & library: https://ftp-master.debian.org/new/bwa_0.7.12-5.html; - [ ] jellyfish; - Headers & library: https://packages.debian.org/sid/amd64/libjellyfish-2.0-dev/filelist; - [ ] tbb; - Headers & library: https://packages.debian.org/sid/amd64/libtbb-dev/filelist; - [ ] libgff; - Headers & library: https://ftp-master.debian.org/new/libgff_1.0-1.html; - [ ] staden IOLib; - Headers & library: https://packages.debian.org/sid/amd64/libstaden-read-dev/filelist. I also have a patch to support the latest release of jellyfish that I can turn into a pull request, should you want it: http://anonscm.debian.org/cgit/debian-med/salmon.git/plain/debian/patches/jellyfish-update. Thanks!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19:45,depend,dependencies,45,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19,2,['depend'],"['dependencies', 'dependency-fix']"
Integrability,"Hello, ; Could someone tell me what this error message means and if there is a way to fix the issue? I'm trying to use salmon for my Master's project data (I break down salmon into two parts to make it easier for myself) but keep getting the error message below during the matrix combination step. I have downloaded edgeR to my home directory on my school's supercomputer, in addition to many other unsuccessful attempts at solving the issue. My main issue is that I've used the same code before without this issue, so I don't know exactly what is wrong now. I'm fairly new to bioinformatics and find it confusing, so any help is appreciated!. Here is my job script:. #!/bin/bash; #SBATCH --partition=debug; #SBATCH --account=PAS1725; #SBATCH --job-name=salmon_part2_cd-hit; #SBATCH --time=01:00:00; #SBATCH --nodes=1; #SBATCH --ntasks-per-node=48. module load python; module load trinityrnaseq/2.15.1; module load samtools; module load salmon/1.4.0; module load R/4.1.0-gnu9.1; R. /apps/trinityrnaseq/2.15.1/util/abundance_estimates_to_matrix.pl --est_method salmon --gene_trans_map /fs/scratch/PAS1725/transcriptomics/trinity_cd-hit_fasta.gene_trans_map --name_sample_by_basedir --out_prefix transcript_counts /fs/scratch/PAS1725/transcriptomics/salmon_part1_cd-hit_output_files/A1/quant.sf ... [other files omitted for space]. Here is my error message:. /apps/trinityrnaseq/2.15.1/util/support_scripts/run_TMM_scale_matrix.pl --matrix transcript_counts.isoform.TPM.not_cross_norm > transcript_counts.isoform.TMM.EXPR.matrixCMD: R --no-save --no-restore --no-site-file --no-init-file -q < transcript_counts.isoform.TPM.not_cross_norm.runTMM.R 1>&2 ; > library(edgeR); Error in library(edgeR) : there is no package called ‘edgeR’; Execution halted; Error, cmd: R --no-save --no-restore --no-site-file --no-init-file -q < transcript_counts.isoform.TPM.not_cross_norm.runTMM.R 1>&2 died with ret (256) at /apps/trinityrnaseq/2.15.1/util/support_scripts/run_TMM_scale_matrix.pl line 105.; Error, CMD: /a",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/855:47,message,message,47,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/855,2,['message'],['message']
Integrability,"Hello, ; Thank you for your message. However, I am working with fission yeast transcriptome and since I am not expecting a lot of splicing junctions with this organism, I read that people recommended using -ax map-ont in this case?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/786#issuecomment-1184348921:28,message,message,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/786#issuecomment-1184348921,1,['message'],['message']
Integrability,"Hello, I am relatively new to bioinformatics/salmon. I am using the newest version of salmon (v1.10.0, downloaded executable). I created two decoy-aware transcriptomes using 1. a Trinity assembly created with 24 RNA-seq samples plus a published genome of the same species (an insect) and 2. a transcriptome compiled using Evigene into which I fed the same Trinity assembly, a MEGAHIT assembly (created with the same read files), and a previously published transcriptome from the same species, along with the same published genome of the same species as above. Running salmon with the two different indexes yields very different results using the same set of paired-end RNA-seq files. With the Trinity assembly-only-index, I get ""expected_format"": ""IU""; whereas with the Evigene index, I get ""expected_format"": ""ISR"". Why would this differ when the read files are exactly the same? Isn't the read file what is being looked at to automatically detect the library type? . For the Trinity index, here is an example from one sample:; ""strand_mapping_bias"": 0.5196075475175259; ; The same sample run with the Evigene index gave:; ""strand_mapping_bias"": 0.00013477965729161834. . For every sample run with the Trinity index, a warning ""Detected a *potential* strand bias > 1% in an unstranded protocol"" appeared, whereas this was very rare for samples run with the Evigene index, even though when using the latter, the strand-mapping_bias was FAR farther from the 0.50 ideal (it was always < 0.01). Why is this the case? I expected similar results using both indexes, because the read files used to create the two transcriptomes were largely the same, and both used Trinity as part (or all) of the transcriptome assembly process. . Thank you in advance for your insight. Holly Williams",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/840:1286,protocol,protocol,1286,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/840,1,['protocol'],['protocol']
Integrability,"Hello, I'm interested in trying out Salmon for the first time. In this analysis, I would like to disentangle a host eukaryote organism's reads for quantification from read data containing it and eight of its microbial symbionts. The host (C. elegans worms) of course has a great genome and transcriptome available.` transcript.fa` is no problem.; The microbes all have genomes and gtfs, but not transcript files (on NCBI). Luckily, I'm not interested in quantifying them - I checked a couple samples with STAR and BBsplit (within the BBmap toolkit) and microbial read abundance is too low for any one bacterium to use in analysis. However, I still need to get those bacteria reads out of the picture when quantifying the host worm reads/transcripts. **What is the best approach to go from a mixed-organism read pool to quantified host transcripts?**. - Perhaps, target-transcriptome = worm_transcripts.fa, with a concatenated decoy composed of worm transcripts, worm genome, and the genomes of the 8 microbes? This seems like the fastest and least error prone method, based on my developing understanding of Salmon. - Or, truly align reads and bin them to new fastq files using genomes+gtfs with STAR/samtools (or just genomes with BBsplit). Then take the putative worm-only reads, and then run Salmon in a single-organisms routine manner? Perhaps this is more accurate in a way?. Thank you for any advice!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/901:1324,rout,routine,1324,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/901,1,['rout'],['routine']
Integrability,"Hello, before writing further, I want to say that I have read through previous related open/closed issues but could not find a suitable answer. The problem: rather different mapping rates depending on library type. I am working with 150+ RNA-seq samples from two dozen tissues. I generated a novel, non-redunant transcriptome from these samples (which also includes the known annotation from ensembl) using ryuto. Following filtering of likely artifacts, predicting non-coding, and lowly expressed transcripts (identified via salmon v1.8.0), a _final_ transcriptome is generated. The selective alignment index (with decoys) is then used for a second and final round of quantification as. ```; salmon quant \; -p {threads} \; --seqBias \; --gcBias \; -i {input.sal_idx} \; -l A \; --numGibbsSamples 100 \; --dumpEq \; -1 {r1} \; -2 {r2} \; -o {params.out_dir}; ```. This is a rather heterogeneous collection of RNA-seq data with ~30% polyA selected and unstranded and ~70% rRNA-depleted and stranded so I expect some _interesting_ results along the way. Included in this collection are a handful of samples with both library preps and this is where I first noticed the problem above. For example, one sample has a polyA mapping rate of 84.01% and a ribo-dep of 46.67% (portion of each _meta_info.json_ below). Both of these however had STAR uniquely mapped reads >90%. Overall, the polyA samples have salmon mapping rates between ~75-90% while the ribo-dep at ~35-60%. I checked for rRNA contamination with RSeQC for a couple of the ribo-dep samples but did not observe anything significant to explain the decrease. I also want to note that these libraries were generated years apart and sequenced at different facilities so I am quite sure that is introducing a fair amount of variance. I guess I still I would have expected more similar mapping rates but apologies if this is the most obvious likely culprit!. My questions are; 1. What could be explaining this difference on the whole or between indi",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/779:188,depend,depending,188,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/779,1,['depend'],['depending']
Integrability,"Hello, salmon developer!; I am working on an arm HPC machine. And when I tried to build with salmon on it. I found a little problem in the CMakeLists.txt. ```; not setting -DHAVE_NUMERIC_LIMITS128; CMake Error at /home/hzwi/arm_software/biosoft/cmake-3.23.0-linux-aarch64/share/cmake-3.23/Modules/FindPackageHandleStandardArgs.cmake:230 (message):; Could NOT find Iconv (missing: Iconv_LIBRARY); Call Stack (most recent call first):; /home/houzhuangwei/arm_software/biosoft/cmake-3.23.0-linux-aarch64/share/cmake-3.23/Modules/FindPackageHandleStandardArgs.cmake:594 (_FPHSA_FAILURE_MESSAGE); /home/hzw/arm_software/biosoft/cmake-3.23.0-linux-aarch64/share/cmake-3.23/Modules/FindIconv.cmake:165 (find_package_handle_standard_args); CMakeLists.txt:362 (find_package); ```; It seems the cmake can not found the right path of libiconv.; So I change the CMakeLists.txt the 362-365 line.; ```; find_package(Iconv REQUIRED); if(NOT Iconv_IS_BUILT_IN); set(ICONV_LIB Iconv::Iconv); endif(); ```; ```; find_package(iconv); if(NOT Iconv_IS_BUILT_IN); set(ICONV_LIB Iconv::Iconv); endif(); ```; or ; I use the -D in the cmake like; ```; cmake -DFETCH_BOOST=TRUE -DBOOST_ROOT=/path/boost -DCMAKE_INSTALL_PREFIX=/path/salmon-1.8.0/salmon_install -DIconv_LIBRARY=/path/libiconv-1.16/iconv_install/lib ; ```; Then the configure was success",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/776:338,message,message,338,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/776,1,['message'],['message']
Integrability,"Hello,. I am doing my best to get the pigx-rnaseq workflow to install locally. Sadly, pigx' test routines bail out with a complaint on a missing sa.bin file as part of the files that are created by `salmon index`. I had tried salmon 1.2 and salmon 1.3 - no sa.bin, also not in your source tree. I placed this as an issue [here](https://github.com/BIMSBbioinfo/pigx_rnaseq/issues/78) and besides grepping through your source tree did some reading also on https://salmon.readthedocs.io . Still, I have no indiation about a missing option or so or if that file was only created in an earlier version. Did I miss this somewhere? Otherwise please kindly consider to explain as part of your documentation what files are to be expected in the index folder. Many thanks and regards,; Steffen",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/553:97,rout,routines,97,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/553,1,['rout'],['routines']
Integrability,"Hello,. I was wondering if it would be possible to add support in Alevin for these two protocols:; https://teichlab.github.io/scg_lib_structs/methods_html/sci-RNA-seq.html; https://teichlab.github.io/scg_lib_structs/methods_html/sci-RNA-seq3.html. The documents there describe the sequencing protocol and primer/barcode/UMI structures (which differ between the two technologies due to the addition of a hairpin sequence in the v3 protocol.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/624:87,protocol,protocols,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/624,3,['protocol'],"['protocol', 'protocols']"
Integrability,"Hello,. Thanks for creating this efficient and rapid tool. I have earlier used Salmon in alignment based-mode and now trying the mapping based mode. I get a ""Version Server Response:Not found"" message on quantification of fast read. I suspect the problem is with my index but I am not entirely sure what exactly. I installed salmon version 1.10.1 from Bioconda, and built the index, which appeared to have executed successfully. Below is the trail of commands:. (salmonenv) nanaaffoh@kenneths-mbp-2 salmon % conda install -c bioconda salmon. Building decoy aware index; (salmonenv) nanaaffoh@kenneths-mbp-2 salmon % grep ""^>"" ../rna_seq_trial/GRCh38.primary_assembly.genome.fa | cut -d "" "" -f -1 > decoys.txt; (salmonenv) nanaaffoh@kenneths-mbp-2 salmon % less decoys.txt; (salmonenv) nanaaffoh@kenneths-mbp-2 salmon % sed -i.bak -e 's/>//g' decoys.txt; (salmonenv) nanaaffoh@kenneths-mbp-2 salmon % cat ../rna_seq_trial/gencode.v43.transcripts.fa ../rna_seq_trial/GRCh38.primary_assembly.genome.fa > gentrome.fa; (salmonenv) nanaaffoh@kenneths-mbp-2 salmon % salmon index -t gentrome.fa -d decoys.txt -p 12 -i salmon_index --gencode. This results in successful building of the index. Then when I attempt a mapping based quantification for a paired end reads FW and RV, as below, I get therefor mentioned. salmon -i salmon_index -l A -1 $FW -2 $RV --validateMappings -o /Volumes/Ultra_Touch/malaria/Salmon/$FILEBASE/. The info.json file from the index folder has these contents:. {; ""index_version"": 4,; ""reference_gfa"": [; ""salmon_index""; ],; ""sampling_type"": ""dense"",; ""k"": 31,; ""num_kmers"": 2662886061,; ""num_contigs"": 37302977,; ""seq_length"": 3781975371,; ""have_ref_seq"": true,; ""have_edge_vec"": false,; ""SeqHash"": ""39d9ea9f308ee7e18cdb034c1d064c3a9722df115147533a2ec237fb7cecfca9"",; ""NameHash"": ""29a75bc06784c090e5e015d4a5a7e895b7b3d91c9855a10528ee0130377edf3d"",; ""SeqHash512"": ""4e84aa54ec0cb1dad420c66197d8a9485e913b0a60805f2d7e44ce71ad0521b8103cf94dad72e1530b05dc0d08f39e5d4b9225345d8e7ffc60cb5",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/851:193,message,message,193,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/851,1,['message'],['message']
Integrability,"Hey @TobiTekath ,. Thanks for the very interesting question. You are right, the unmated reads are not supported yet, but the basic idea was to consume a file with cb and umi attached to the read name, however it's a wip and is not properly supported. . re: any SE single-cell protocol - I am not aware of any.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/522#issuecomment-634378224:276,protocol,protocol,276,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/522#issuecomment-634378224,1,['protocol'],['protocol']
Integrability,"Hey @jeremymsimon! I checked the protocol and the [pipeline code](https://github.com/yjzhang/split-seq-pipeline/blob/master/split_seq/tools.py). The protocol you described is v1 and the Parsebio is v2. I have implemented v2 in salmon and would be testing it this week. v1 can be similarly implemented. I read the paper and other available resources but I am not clear about the random hexamer usage and it's effects on the barcode. Can you please explain what you meant by BC1s being paired and what's the use of random hexamer, please? Thanks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-936331597:33,protocol,protocol,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-936331597,2,['protocol'],['protocol']
Integrability,"Hey @jeremymsimon! I figured out what the issue was. Alevin is fine, but my implementation of the split-seq protocol had an issue. I was able to get good correlation with the submitted counts and good match between barcodes. Here's what I did: . - Used fastp to clean the fastq files. ; - Ran `salmon alevin` with custom geometry flags and `--justAlign`. For index I used human GENCODE v31 reference. ; ```; salmon alevin -i /biodb/human/gencode/v31/salmon_index_wo_decoy/ -l A -1 SRR10174292_trimmed_1.fastq.gz -2 SRR10174292_trimmed_2.fastq.gz -p 44 --bc-geometry 2[11-18,49-56,87-94] --umi-geo 2[1-10] --read-geo 1[1-end] -o runtestdata_custombc --justAlign; ``` ; - Used `alevin-fry` on the output; ```; $ cd runtestdata_custombc; $ alevin-fry generate-permit-list -i ./ -d both --output-dir run -k; 2021-12-06 15:36:39 INFO paired : false, ref_count : 226,030, num_chunks : 7,9282021-12-06 15:36:39 INFO read 2 file-level tags2021-12-06 15:36:39 INFO read 2 read-level tags; 2021-12-06 15:36:39 INFO read 1 alignemnt-level tags; 2021-12-06 15:36:39 INFO File-level tag values FileTags { bclen: 24, umilen: 10 }2021-12-06 15:36:45 INFO observed 39,536,527 reads in 7,928 chunks --- max ambiguity read occurs in 196 refs2021-12-06 15:36:45 INFO max_idx = 170639; 2021-12-06 15:36:45 INFO max_idx = 59128; 2021-12-06 15:36:45 INFO max_idx = 21206; 2021-12-06 15:36:45 INFO max_idx = 10151; 2021-12-06 15:36:45 INFO max_idx = 7852; 2021-12-06 15:36:45 INFO max_idx = 72462021-12-06 15:36:45 INFO max_idx = 70432021-12-06 15:36:45 INFO max_idx = 69602021-12-06 15:36:45 INFO max_idx = 6937; 2021-12-06 15:36:45 INFO max_idx = 6925; 2021-12-06 15:36:45 INFO knee-finding iter = 10; 2021-12-06 15:36:45 INFO max_idx = 6922; 2021-12-06 15:36:45 INFO knee distance method resulted in the selection of 6923 permitted barcodes.; 2021-12-06 15:36:46 INFO total number of distinct corrected barcodes : 333,352; $ alevin-fry collate -i run/ -t 16 -r ./ ; 2021-12-06 15:37:02 INFO filter_type = Filtered; 2021-1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-987334414:108,protocol,protocol,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-987334414,1,['protocol'],['protocol']
Integrability,"Hey @rob-p ,. Thanks for your response. I agree with your suggestion - to have a flag for gff/bed and run either GTF or a BED/GFF file depending on what the end user has. In my case, I have mostly gff files and I need to do some reformatting if I have to use the current shell script.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/384#issuecomment-503632945:135,depend,depending,135,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/384#issuecomment-503632945,1,['depend'],['depending']
Integrability,"Hey Rob,. Regarding file pairs, in some cases e.g. the FW read contains the mRNA Tag and a Cell Barcode, while the RV read contains the UMI and some non-informative sequence. In particular in the 10X Chromium (V1) protocol there are 4 files! FW, RV as well as I5 and I7 index reads. I don't remember exactly which read contains what information right now though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269658634:214,protocol,protocol,214,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269658634,1,['protocol'],['protocol']
Integrability,"Hey Rob. It looks like this was an error in the way I was calling `salmon index`. I've wrapped salmon in a python based pipeline where I manage creation of index files using configuration files. To call `salmon index` I was previously iterating on standard error, capturing your err and logging it after reformatting a bit. It looks like what was happening is:. 1. I opened a subprocess and executed salmon; 2. Salmon worked properly; 3. Salmon stopped producing output on stderr (and sent an EOF marker?) and so my script exited; - killing salmon prematurely; - truncating the salmon index (In a way that salmon found perfectly acceptable during `salmon quant`; - frustrating me quite a bit. I fixed this by doing the right thing and blocking for the process to return an exit code:. ```diff; p = Popen(cmd, stderr=PIPE); - for line in p.stderr:; - line = line.decode(); - if line.endswith('\n'):; - logging.info(line.rstrip()); - else:; - logging.info(line); + _, err = p.communicate(); + logging.info(err); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303738589:87,wrap,wrapped,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303738589,1,['wrap'],['wrapped']
Integrability,"Hey there!; I got the following error when running the command `~/tools/Trinityrnaseq-v2.6.6/util/align_and_estimate_abundance.pl --seqType fq --samples_file gpul_adpul_samples.txt --transcripts Gpul_Adpul_trinity.Trinity.fasta --est_method salmon --trinity_mode --prep_reference`:. _[2020-06-11 01:53:08.809] [jointLog] [warning] NOTE: Read Lib [[ /dev/fd/63, /dev/fd/62]]_. _Detected a potential strand bias > 1% in an unstranded protocol check the file: ADPUL3/lib_format_counts.json for details_. _CMD: /home/curupi/tools/Trinityrnaseq-v2.6.6/util/support_scripts/salmon_trans_to_gene_results.pl ADPUL3/quant.sf /home/curupi/data/pulchella/fastq/trim/Gpul_Adpul_trinity.Trinity.fasta.gene_trans_map > ADPUL3/quant.sf.genes_. strand_mapping_bias: 0.9945332800206606. May anyone help me, please?; Thank you in advance!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/536:432,protocol,protocol,432,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/536,1,['protocol'],['protocol']
Integrability,"Hey, . First, thanks a lot for implementing Alevin for the analysis of scRNA-seq, it is super useful. I would like to open the file ```alevin/quants_tier_mat.gz``` but I am not being able to do it. . When I try to follow the parser instructions [here](https://github.com/k3yavi/vpolo/blob/242b519ea47eae1cce14bb3bafb736a1f3ad7d40/vpolo/alevin/parser.py) I am facing this error when importing sce:; ```; ImportError: cannot import name 'sce' from partially initialized module 'sce' (most likely due to a circular import) (/home/egonie/.local/lib/python3.8/site-packages/sce/__init__.py); ```. I have already imported```vpolo``` which I have installed with: ; ```; pip3 install vpolo; ```. Also I have tested the R library ```fishpond```with the function; ```; fishpond::readEDS(numOfGenes = num.genes, numOfOriginalCells = num.cells, countMatFilename = tier.file, tierImport = T); ```; Which outputs this message:; ```; Error in validObject(x) : ; invalid class ""dgCMatrix"" object: all row indices must be between 0 and nrow-1; ```. Any insight that helps in reading Alevin tiers file would be much appreciated. Thanks in advance and sorry for the inconveniences. Best,. Kike",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/596:904,message,message,904,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/596,1,['message'],['message']
Integrability,"Hey,. What is your cutoff for considering a gene expressed? Salmon puts a small > 0 expression on most genes. Usually we count genes over e.g. 5 reads, or e.g. > 1 TPM, depending analysis.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279958203:169,depend,depending,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279958203,1,['depend'],['depending']
Integrability,"Hey. I am using the CellNet protocol and encountered the following issue. The index I am using is from refgenie. ; Any help would be much appreciated. thank you. ; determining read length; Trimming reads; This is cutadapt 4.2 with Python 3.10.8; Command line parameters: -m 30 -u 18 -u -17 -o ./subset_SRR12820270_trimmed.fq subset_SRR12820270.fastq; Processing single-end reads on 1 core ...; Finished in 99.186 s (2.870 µs/read; 20.90 M reads/minute). === Summary ===. Total reads processed: 34,554,336. == Read fate breakdown ==; Reads that were too short: 778,286 (2.3%); Reads written (passing filters): 33,776,050 (97.7%). Total basepairs processed: 2,555,642,890 bp; Total written (filtered): 1,335,316,421 bp (52.2%); Salmon; Version Info: This is the most recent version of salmon.; ### salmon (selective-alignment-based) v1.10.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 5 }; ### [ index ] => { ref//default }; ### [ libType ] => { U }; ### [ unmatedReads ] => { subset_SRR12820270_trimmed.fq }; ### [ output ] => { salmonRes_SRR12820270 }; Logs will be written to salmonRes_SRR12820270/logs; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/waqasiqbal/opt/miniconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/waqasiqbal/opt/miniconda3/envs/salmon/bin/salmon quant --help; Exiting.; [2023-02-27 15:21:11.968] [jointLog] [info] setting maxHashResizeThreads to 5; [2023-02-27 15:21:11.968] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-02-27 15:21:11.969] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2023-02-27 15:21:11.970] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2023-02-27 15:21:11.970] [jointLog] [info] parsing read library format; [2023-02-27 15:21:1",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/833:28,protocol,protocol,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/833,1,['protocol'],['protocol']
Integrability,"Hi , . I am having issues with calculating the differential splicing using SUPPA. I have tried several times but kept getting the same error message, even though all files required are uploaded. . The error message is below:; ```; Traceback (most recent call last):; File ""/mnt/storage/nobackup/b7070855/april2023/SUPPA/suppa.py"", line 10, in <module>; import psiPerGene as psiPerIsoform; File ""/mnt/storage/nobackup/b7070855/april2023/SUPPA/psiPerGene.py"", line 13, in <module>; from lib.tools import *; ModuleNotFoundError: No module named 'lib.tools'; [1] ""Parsing samples...""; [1] ""Loading ./results/iso_tpm_formatted.txt...""; Error: first_condition %in% colnames(input_file) are not all TRUE; Execution halted; [1] ""Parsing samples...""; [1] ""Loading ./results/events.psi...""; Error in file(file, ""rt"") : cannot open the connection; Calls: read.table -> file; In addition: Warning message:; In file(file, ""rt"") :; cannot open file './results/events.psi': No such file or directory; Execution halted; Traceback (most recent call last):; File ""/mnt/storage/nobackup/b7070855/april2023/SUPPA/suppa.py"", line 10, in <module>; import psiPerGene as psiPerIsoform; File ""/mnt/storage/nobackup/b7070855/april2023/SUPPA/psiPerGene.py"", line 13, in <module>; from lib.tools import *; ModuleNotFoundError: No module named 'lib.tools'; CalculateDifferentialSplicingEvents.sh: line 24: -e: command not found; ```. Could you please help me with this ; **Thank you in advance",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/859:141,message,message,141,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/859,3,['message'],['message']
Integrability,"Hi @ACastanza,. Thanks for reporting both of these. For the first, I think it is just the case that the message needs to be updated. In fact, the `--validateMappings` flag is now deprecated since selective-alignment is used by default (and can't be turned off, except in the single-cell mapping context, with the `--sketchMode` flag, which is currently only in the develop branch). We'll update that message.; Regarding the misplaced newline, the issue is that the other messages are written by the logger, which is asynchronous. So, sometimes it will get to the appropriate place and write a newline before the fragment counter starts, and sometimes it won't. I'll look into if there is a way to better clear the line, even if the update is asynchronous. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/587#issuecomment-729044670:104,message,message,104,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/587#issuecomment-729044670,3,['message'],"['message', 'messages']"
Integrability,"Hi @Anto007,. Sounds like an interesting experiment! A couple of questions: (1) are you quantifying the meta-transcriptome or the metagenomes? What I mean is, are your target sequences the specific genes from the microbes, or the entire microbial genomes? Is the sequencing data RNA-seq from sequencing the mixture of expressed gene transcripts, or DNA-seq of the microbes? This will have an effect on how you expect reads to be generated. The effect of `--minScoreFraction` depends, to some extent, on how you set the match/mismatch/gap parameters. With the default parameters, `0.9` is actually higher than 90% sequence identity, because the default mismatch penalty is twice the match score. If you assume only matches and mismatches, then the `--minScoreFraction` you want to set is the one such that ; x * (match_score * read_length) <= (match_score * read_length) - (m * read_length * match_score) + (m * read_length * mismatch_penalty), where m is the mismatch fraction (0.1 in your case). So, for example, if the match_score is 2 and mismatch penalty is -4, and the read length is 100, you want to set it so that:. x * 200 = 200 - (0.1 * 100 * 2) + (0.1 * 100 * -4) = 200 - 20 - 40 = 140 . so, the appropriate x would be ~0.7. Of course, if you want to make the calculation simple, you can set the match score to 1 and mismatch penalty to 0, and then the interpretation (modulo gaps) is straightforward (and 0.9 means what you want). Finally, I'd typically avoid using `--mimicStrictBT2`, since those are pretty harsh parameters. Of course, you could try mapping both with and without that flag and see how it affects your mapping rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-447589060:475,depend,depends,475,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-447589060,1,['depend'],['depends']
Integrability,"Hi @BW15061999,. I’m not aware of any tagged-end single-cell protocol that uses only 1 read. The most common data types place the UMI and Barcode on one of the reads, while the other “biological” reads are drawn from the transcriptome. This is the case with the Chromimum protocol. The reason you are seeing 0 assigned reads is that no barcodes can be extracted, because the second read is missing. Therefore, no reads can be assigned to any cell. What specific protocol are you using? Do you not have the full read pairs for each sample? Cc @k3yavi as the resident protocol guru. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/769#issuecomment-1107467832:61,protocol,protocol,61,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/769#issuecomment-1107467832,4,['protocol'],['protocol']
Integrability,"Hi @Ci-TJ,. This suggests that the FASTQ files were ""desynchronized"" during / after trimming somehow. Salmon requires that the FASTQ files are synchronized. So, if the trimmer decides to discard a read from the first read file, it must also discard the corresponding read from the second read file. I'm not specifically familiar with RabbitQC, but most quality / adapter trimmers have an option to separate out any reads that become orphaned during trimming so that the output paired FASTQ files remain synchronized. You should make sure that any such options are passed during QC. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/660#issuecomment-846252372:143,synchroniz,synchronized,143,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/660#issuecomment-846252372,3,"['adapter', 'synchroniz']","['adapter', 'synchronized']"
Integrability,"Hi @ECuris,. Indeed, this seems to be a case where the code evolved and the documentation has yet to catch up. The defaults are `fldMean` = 250 and `fldSD` = 25. The relevant code is here (https://github.com/COMBINE-lab/salmon/blob/master/src/SalmonQuantify.cpp#L2260). This defines how default values are set for these parameters. I'll make a note to update the documentation to be consistent with these changes (which were made to be more in line with modern protocols, though there's still no good universal parameters for things that can vary so widely between experiments).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-286760710:461,protocol,protocols,461,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-286760710,1,['protocol'],['protocols']
Integrability,"Hi @Hoohm , ; Thanks for the quick reply and the explanation . I personally am not very well versed in the working of `SCRBseq`. But, as you explained, knowing a set of whitelist CB beforehand is always a plus for the downstream working of the pipeline. Currently, Alevin merge all the observed CB which are 1-edit distance from a known whitelist CB towards the whitelist. The underlying assumption being that the sequencing error (although with low probability) can change CB sequence and we can correct for that. I wonder, is this right to do for your experiment ?. re: >Is there an option for max distance allowed between BC or UMI?; Sorry, but I don't completely understand this question. When you say distance allowed between CB and UMI, do you mean there is a sequence between CB and UMI ( like in in-drop seq)? If that's the case then we might have to tweak a bit in alevin command line flags again. But I suspect what you meant by above statement is -- max distance allowed between CB among themselves. If that's the question then unfortunately we currently allow correcting for only 1-edit distance for both CB and UMI. But if you think more correction is needed by your protocol then we can put this on the feature request list and discuss about working on this on the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402543751:1180,protocol,protocol,1180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402543751,1,['protocol'],['protocol']
Integrability,"Hi @KS751515,. It appears that you have quantified the *genome* (i.e. you have computed an abundance for each chromosome) rather than the transcriptome (i.e. an abundance for each gene transcript). The reference should be the reference transcriptome rather than the reference genome (depending on the specific annotation, this should have on the order of ~150,000-200,000 reference sequences. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/824#issuecomment-1386426735:284,depend,depending,284,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/824#issuecomment-1386426735,1,['depend'],['depending']
Integrability,"Hi @PeteHaitch ,; Thanks for your interest in *Alevin*.; Although in current Alevin we have concentrated mainly on learning more about Droplet based 3'-tagged single cell protocols, especially 10x; we are very much interested in extending it towards other protocols like CEL-seq.; However, there are couple of challenges/difference which should be considered before incorporating it into the Alevin pipeline. Currently Alevin relies on the fact that the droplet based protocols use PCR amplification of the library and the UMI deduplication phase of Alevin assumes an exponential model, I am not sure how true is this with CEL-seq? Another issue is that CEL-seq is a Fluidigm based system while the current application for Alevin is for microfluidics based. In general we have observed that the 10x cell isolation step is pretty robust in reporting the Cellular Barcodes(CB) and although we have a probabilisitic model to handle the CB based uncertainty but the ambiguous case like that are very less frequent, (although not true for Drop-Seq). Having said that, we might have to do some analysis to actually figure out the right model for Barcode correction in Fluidigm based system. Also, please do let us know of your experience in using the solution proposed in #247 . Looking forward to hearing back from you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-414162302:171,protocol,protocols,171,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-414162302,3,['protocol'],['protocols']
Integrability,"Hi @PeteHaitch! I agree with @PeteHaitch here --- I think we should provide an easy way to specify custom cb & umi parameters paired with a particular protocol. For 10x v2, since it's a very standard commercial protocol, I think simply having a `--chromium` flag is probably OK. But we should make it easy for ppl to tweak their CB & UMI lengths.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418580112:151,protocol,protocol,151,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418580112,2,['protocol'],['protocol']
Integrability,"Hi @Rhinogradentia,. This error occurs when there is a binary mismatch between the library used to compile salmon versus that used to run it. Specifically, this occurs when the boost library is _not_ compiled with a modern ABI (Application Binary Interface) — when boost was not compiled in a way compatible with C++11/14/17/20. Are you using the version installed via bioconda, or the pre-compiled binary from github, or have you compiled this yourself? You can [use the `LD_LIBRARY_PATH`](https://stackoverflow.com/questions/13428910/how-to-set-the-environmental-variable-ld-library-path-in-linux) to set things so that the appropriate version of the library is discovered first. You want the version of boost that is found first (the one appearing earliest in the `LD_LIBRARY_PATH`) to be matched to the one with which salmon was compiled.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-696812977:247,Interface,Interface,247,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-696812977,1,['Interface'],['Interface']
Integrability,"Hi @SSaleem94,. As the message suggests, your command is missing the required `--output` argument. Of course, it seems your command includes `-o`. The rest of the errors suggest that the command line is not being properly parsed. It looks like the part after the first line break is not being interpreted as a continuation of the same line. I think this is because the line extension character in the shell is not `/`, but is `\`. Maybe try the following:; ; ```; F=$(cat file_names.txt); for i in ${F}; do; F1=../processed_fastq/${i}_R1_001_val_1.fastq.gz; F2=../processed_fastq/${i}_R2_001_val_2.fastq.gz; echo ""performing salmon quant on ${i}""; salmon quant -i gencode_v43_index -l A -1 ${F1} -2 ${F2} -p 64 \; --validateMappings --writeUnmappedNames -o ${i}; echo ""finish quantifying ${i}""; done; ```. **Also**, as is suggested by the `salmon` message itself, you may want to consider upgrading to the latest version of `salmon`. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/854#issuecomment-1599169394:23,message,message,23,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/854#issuecomment-1599169394,2,['message'],['message']
Integrability,"Hi @Tima-Ze,. This should not cause any trouble with downstream analysis. The indexing procedure is simply informing you that these transcripts (about which you are being warned) are shorter than the seed length used for alignment. This means that it simply won't be possible for fragments to align to these transcripts, and so they will always have a 0 abundance in the resulting `quant.sf` files. This isn't a problem, as these transcripts are too short to be measured via RNA-seq anyway. The indexing messages just let you know this in advance. You can safely ignore these warnings for your downstream analysis.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751366278:504,message,messages,504,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751366278,1,['message'],['messages']
Integrability,"Hi @Tima-Ze,. Yes, salmon can be used to quantify these reads, but the results will depend (somewhat) on the `--fldMean` and `--fldSD` flags that are used. It's important to note that this is not a unique characteristic of salmon, and any transcript-level quantification tool using a probabilistic model (e.g. RSEM, eXpress, BitSeq, etc.) have the same requirement. That is, the fragment length distribution should be known so that _effective_ transcript lengths can be estimated, which have an effect on fragment assignment probabilities. If the wrong fragment length distribution is specified, then the _effective_ transcript lengths will be off and this can affect the assignment of some fragments. This is only a requirement with single-end reads, since with paired-end reads the fragment length distribution is learned from the data. Further, the inference procedure is somewhat robust to these choices (small changes in fld mean and sd don't generally lead to drastically different results). If you have access to the BioAnalyzer results for the sequencing run, those can give information about the fragment length distribution (even in a single end experiment). If not, you can proceed with the default values. Even if they don't exactly match the true distribution in the single-end sample, at least the same values will be applied in all samples and so, ideally, most results of misspecification will wash out in subsequent differential analysis. . Finally, it's worth noting that the same restriction holds in both alignment-based and mapping-based modes. This is because in neither mode do single-end fragments provide sufficient information to estimate the fragment length distribution from the data. We only know where one end of a fragment mapped and cannot infer where the other end would be. This is not an alignment versus mapping (versus selective-alignment) issue, but rather is fundamental to having only observed one side of the entire fragment generated during fragmentation and ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750920243:84,depend,depend,84,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750920243,1,['depend'],['depend']
Integrability,"Hi @Tj-Idowu,. Thanks for the details. The fact that the bioconda install is giving problems is disconcerting, as that should be properly linked against all of the correct libraries etc. I do wonder if it might have something to do with all of the package rebuilding and upgrading that has been going on in bioconda. Would you be able to give [this binary](https://github.com/COMBINE-lab/salmon/files/2099291/salmon-latest_linux_x86_64.tar.gz) a try, and let me know if it works? It was built on our continuous integration server, and should be compatible with a wide variety of different platforms.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/239#issuecomment-400679476:511,integrat,integration,511,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/239#issuecomment-400679476,1,['integrat'],['integration']
Integrability,"Hi @alexg9010,. This is absolutely a cryptic error message. I'm *guessing* it may have something to do with the de-serialization of the index. Would you be able to provide the file on which you build the index? I can see if I can reproduce this error locally. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-376005422:51,message,message,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-376005422,1,['message'],['message']
Integrability,"Hi @antonkulaga,. Indeed. Sailfish-cir was developed by another group, but it has a procedure for linerizing circular RNAs and quantifying them using Sailfish. I believe it would be nice to see support for Salmon added to the same strategy. I believe their tool contains a wrapper tha calls out to Sailfish with a modified transcriptome index, so that should be fairly easy to port to Salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/220#issuecomment-386882962:273,wrap,wrapper,273,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/220#issuecomment-386882962,1,['wrap'],['wrapper']
Integrability,"Hi @antonkulaga,. This is not a particularly useful error message (_sorry for that_), but this is a result of passing both un-paired (`-r`) and paired-end (`-1,-2`) reads to salmon together. This is actually not supported, as the single-end and paired-end models are actually a bit different. I will fix the error checking so that a useful message is printed out if these options are passed in together. Can you let me know if the program runs correctly if you use just the paired-end reads?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/175#issuecomment-346899958:58,message,message,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/175#issuecomment-346899958,2,['message'],['message']
Integrability,"Hi @asher1234,. Thanks for the detailed bug report. The detection of the library type as `MU` certainly does raise some flags as that is not something that would be expected. Moreover, in the v0.12.0 log you posted, we see messages like:. ```; Thread saw mini-batch with a maximum of 90.16% zero probability fragments; ```. Which means that e.g. ~90% of the fragments, even though they map, are being assigned a 0 probability under the model (because of e.g. incompatibility with the library type). Would you be able to share one of these samples and the reference transcriptome against which you are quantifying? Also, do things look any different if you force the library type to be something more common (e.g. `-l IU`)?. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469108517:223,message,messages,223,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469108517,1,['message'],['messages']
Integrability,"Hi @avocado851,. No worries, and welcome to the RNA-seq analysis world! Thanks for choosing salmon :). There's a detailed discussion over in [this](https://github.com/COMBINE-lab/salmon/issues/533) issue describing some reasons you might be seeing a lower than expected mapping rate. The TLDR is, make sure you trim your reads (and / or try mapping with the `--softclip` option) and see if your mapping rate improves to your satisfaction. Even then, it's not uncommon when aligning RNA-seq data to see the kind of mapping rate you're describing *to the annotated transcriptome*. In any given sample, you might see a non-trivial number of reads from outside of the annotation, and the level of this can depend on your tissue type, condition, annotation completeness etc. If there are no issues in your quality report (e.g. are you running this through FastQC / MultiQC etc.?), then this mapping rate alone need not be conclusive evidence of a bad sample.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/571#issuecomment-704947451:702,depend,depend,702,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/571#issuecomment-704947451,1,['depend'],['depend']
Integrability,"Hi @bounlu,. None of these dependencies are explicitly declared for the salmon build. In fact, salmon is one of the packages already migrated to the new conda build 3 system. Could you please raise this issue over in the bioconda repository?. Thanks!. Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/286#issuecomment-419195164:27,depend,dependencies,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/286#issuecomment-419195164,1,['depend'],['dependencies']
Integrability,"Hi @citron96,. The patch is quite simple and i have verified it and it works for salmon-1.1.0 version that i compiled. Here is the patch content:. --- salmon-1.1.0/CMakeLists.txt.orig 2020-03-24 08:50:22.681000000 -0700; +++ salmon-1.1.0/CMakeLists.txt 2020-03-24 08:51:41.786000000 -0700; @@ -596,7 +596,7 @@; message(""Build system will fetch and build Intel Threading Building Blocks""); message(""==================================================================""); # These are useful for the custom install step we'll do later; -set(TBB_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/tbb-2019_U8); +set(TBB_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/oneTBB-2019_U8); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install). if(""${TBB_COMPILER}"" STREQUAL ""gcc""); @@ -610,9 +610,9 @@; externalproject_add(libtbb; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/intel/tbb/archive/2019_U8.tar.gz -o tbb-2019_U8.tgz &&; - ${SHASUM} 7b1fd8caea14be72ae4175896510bf99c809cd7031306a1917565e6de7382fba tbb-2019_U8.tgz &&; + ${SHASUM} 6b540118cbc79f9cbc06a35033c18156c21b84ab7b6cf56d773b168ad2b68566 tbb-2019_U8.tgz &&; tar -xzvf tbb-2019_U8.tgz; - SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/tbb-2019_U8; + SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/oneTBB-2019_U8; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; PATCH_COMMAND ""${TBB_PATCH_STEP}""; CONFIGURE_COMMAND """". Rob, ; I understand that you don't want to push changes to older releases but perhaps one; can issue a README/NOTE for all prior releases that are affected by this. The explanation of; what changed will allow people to create their own patches for their specific releases. Regards,; Nadya",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-603916394:311,message,message,311,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-603916394,2,['message'],['message']
Integrability,"Hi @davidaknowles,. Assuming that the total size of all cell barcodes doesn't exceed 32 nucleotides, then it should be possible to simply specify them using a custom geometry string. Of course for that to work, we need to know where the 4th barcode is located, so that we can generate the correct custom geometry string to extract it. I'll ping @DongzeHE and @k3yavi here to see if either of them are familiar with this chemistry already. As always, I'd also suggest running this through `alevin-fry` (or using the `simpleaf` wrapper). While we continue to support `alevin`, `alevin-fry` (largely interfaced by `simpleaf`) is where most of our development effort is currently going, and hopefully we can make the user experience there as smooth and easy as possible!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1732428996:526,wrap,wrapper,526,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1732428996,2,"['interface', 'wrap']","['interfaced', 'wrapper']"
Integrability,"Hi @davidaknowles,. Indeed — the barcode extraction will happen either in `salmon alevin` or, if you are using the new `piscem` module for mapping prior to quantification (both are exposed in the `simpleaf` wrapper tool to simplify single-cell processing with `alevin-fry`), then it will happen there. We have a new very general and much more capable module in the works that will be able to handle all manners of single-cell geometry, but nothing about the Parse library seems beyond the capabilities of the current geometry processing code. If you share some reads, we can also try and take a look and figure out where the last BC resides. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1733872331:207,wrap,wrapper,207,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1733872331,1,['wrap'],['wrapper']
Integrability,"Hi @davidnboone and @mcfwoodruff,. So, I should have mentioned that if you want to use the pre-compiled binary I provide, you have to put the `lib` folder in your path. One way to accomplish this is to run salmon as follows:. ```; DYLD_FALLBACK_LIBRARY_PATH=<path_to_salmon_folder>/lib <path_to_salmon_folder>/bin/salmon ; ```; Where `<path_to_salmon_folder>` is simply the top-level directory where you decompressed salmon. You can, of course, make a little wrapper script to make launching it less ugly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421417111:459,wrap,wrapper,459,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421417111,1,['wrap'],['wrapper']
Integrability,"Hi @davismcc, . Yes; this is very high-up on our to-do list. Right now, we are primarily limited by people (students and myself) able to actually hack away on the codebase. I would say that adding support for single-cell data is in the top 1-3 features on our todo list right now. I'd also encourage you to voice your support for this feature on our [survey](https://docs.google.com/forms/d/e/1FAIpQLSeWhBNE_fA_0uVHvbAlAulDmfmowv7rAYla879DZpqCARyRTQ/viewform), which we will use to prioritize feature development. In addition to the implementation, the other big ""question"" will be how to support the broadest variety of such data with the most uniform interface and implementation. It seems like barcoding / UMI tagging is a bit ""wild-west"" right now where every protocol uses it's own format to encode the relevant information. I think that, in that case, some form of pre-processing (a la @vals work), might be the best solution.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-282336377:653,interface,interface,653,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-282336377,2,"['interface', 'protocol']","['interface', 'protocol']"
Integrability,"Hi @dhy2002,. The message at the beginning is just a result of salmon not being able to complete the version check — that is not related to any issues building the index. What is at the end of the log file?. Also, I'll note that we've seen before some issues related to building the index directly on a network file system mounted partition — the tool we use for compacted de Bruijn graph construction, TwoPaCo, can create many small intermediate files that causes issues for NFS. If this is the problem, I might suggest building the index on the local scratch disk of a node, and then copying over the completed index when it's finished. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/755#issuecomment-1050468212:18,message,message,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/755#issuecomment-1050468212,1,['message'],['message']
Integrability,"Hi @diyang1354,. It is recommended to do adapter trimming prior to mapping and quantification (standard practices actually involve adapter and _light_ quality trimming of reads). Adapter contamination could affect the mapping rate, especially if selective-alignment, which is recommended, is being used.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/398#issuecomment-511428337:41,adapter,adapter,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/398#issuecomment-511428337,3,"['Adapter', 'adapter']","['Adapter', 'adapter']"
Integrability,"Hi @dritoshi ,. As per your request I've added the support for Quartz-seq2 data in the alevin framework with https://github.com/COMBINE-lab/salmon/commit/f6905b1d1dc6cf6bc4597927ad3be637ba615c9a and should be available with next salmon release. Currently the develop branch has to be compile from source to use the following command line argument.; ![image](https://user-images.githubusercontent.com/8772521/63282768-8df73600-c27d-11e9-832d-f4a1232f17f6.png). Currently I just have on flag i.e. quartzseq2 which assumes 15 length CB and 8 length UMI. Unfortunately adding multiple versioned is gonna be little complicated as I might have to discuss with the alevin team and that might take some time. As you can check through the new code through the commit (linked above) adding just the Rule of new protocol is not enough and we might have to add some helper code with each new protocol which increases the redundancy in the code. Currently we are in the process of figuring out a better way to handle new protocols.; Having said that it should not stop users from using alevin with previous version of quartzseq2, you can use the following command line triplet as `--end 5 --barcodeLength 14 --umiLength 8` along with you other alevin flag and it's gonna behave just like `QuartzSeq2v31` you specified above. If possible, It'd be great if you can share some of the results you get while comparing Quartz-seq2 pipeline with alevin. Hope this helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-522658541:801,protocol,protocol,801,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-522658541,3,['protocol'],"['protocol', 'protocols']"
Integrability,"Hi @dritoshi ,. Thanks for your request. I'd be happy to add the support for Quartz-seq2 into alevin but it'd be great if you can answer a few questions for us. Is it possible to share some reads/fastq file on which we can test alevin ? Also, please excuse my ignorance, what type of PCR amplification is performed in `Quartz-seq2` protocol, is it CelSeq type IVT (linear) amplification or Drop-Seq type template switching PCR amplification ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521747003:332,protocol,protocol,332,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521747003,1,['protocol'],['protocol']
Integrability,"Hi @euduca,. This is a good idea. Currently, there is no easy way to do this apart from hacking the CMake file. If salmon doesnt find jellyfish in a standard location, it just ferches its own copy. Fortunately, in the newest release (scheduled to drop this coming week), we've dropped the dependency on libjellyfish. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/225#issuecomment-392336913:289,depend,dependency,289,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/225#issuecomment-392336913,1,['depend'],['dependency']
Integrability,"Hi @evofish,. Unless you have a particular reason to build from source, it is much easier to install salmon via bioconda, or to simply download our pre-compiled executable from the releases page. Nonetheless, your error stems from not having the `curl` program installed, which is used by the build system to automatically fetch all dependencies.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447689917:333,depend,dependencies,333,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447689917,1,['depend'],['dependencies']
Integrability,"Hi @gnaisha,. Thank you for providing the file to reproduce the issue. So, the difference here is all in the default fragment length mean and standard deviation that salmon and eXpress use. This really only matters in single-end libraries like this, since in paired-end libraries both tools will estimate the fragment length distribution from the data itself. Nonetheless, if not given specific parameters to override the default, salmon assumes μ = 250 and σ = 25, while eXpress assumes μ = 200 and σ = 80. If you run salmon like:. ```; salmon quant -lU -t transcriptome.fa -a sample_nested_transcripts_ENST00000364953-1_ENST00000375633-5.bam --fldMean 200 --fldSD 80 -o quant_directory; ```. Then you will see the following behavior for these transcripts:. ```; ENST00000364953.1 64 23.127 1000000.000000 49.000; ENST00000375633.5 586 384.567 0.000000 0.000; ```. So that the all of the reads are, indeed, allocated to the former. The effect of the transcript length on the assignment probabilities is a direct result of the probabilistic model (and due to the length effect that actually exists in the full-length RNA-seq assay). It's unfortunate that there's not a good way to estimate the fragment length distribution in single-end data, and so we are left with having to set some defaults. Depending on the actual library, different defaults will match better or worse. On the plus side, it's easy to change these values if you have better knowledge of the parameters or reason to believe that one value will work better than another.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-749739255:1296,Depend,Depending,1296,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-749739255,1,['Depend'],['Depending']
Integrability,"Hi @izaakm,. This segfault is unlikely related to the issue here, since that happened in ""mapping mode"" (salmon performing mapping itself), and yours is happening in alignment-based mode (you're feeding SAM files to salmon). Does it fail to occur when you provide _either_ of the SAM files to salmon? That is, does it run to completion with both `data/processed/bwa-mem/SRR10571655.sam` and `data/processed/bwa-mem/SRR10571656.sam` individually? Also, what if you combine them via a pipe (i.e. something like):. ```; ./src/salmon-latest_linux_x86_64/bin/salmon quant --threads $(nproc) --libType U -t GRCh38_latest_rna.fa -a <(cat data/processed/bwa-mem/SRR10571655.sam <(samtools view data/processed/bwa-mem/SRR10571656.sam)) -o _tmp/ ; ```. the double redirect is just to make sure the header isn't included in the second sam file. Also, is the reference that you are passing to the `-t` option identical to the one with which bwa-mem was run? If the problem persists, we might need the sam/bam files to track it down further, since I imagine it may be data-dependent. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707338358:1060,depend,dependent,1060,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707338358,1,['depend'],['dependent']
Integrability,"Hi @jeremymsimon --- I am noticing this as jumping out:. ```; ""num_frags_with_inconsistent_or_orphan_mappings"": 61866895,; ```. Is `ISR` the right protocol for this data, in the manner in which the reads are provided to `alevin`? @Gaura is doing a run with alevin-fry and we'll discuss those results here when we have them. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985043620:147,protocol,protocol,147,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985043620,1,['protocol'],['protocol']
Integrability,"Hi @jeremymsimon — @Gaura is going to take a look at unfiltered permit listing and will share those results here later. Regarding frameshift errors, I think that's certainly out of scope for the alevin -> fry phase, but that type of thing *could* be in scope for `splitp`. Basically, my logic / reasoning is this: I'd like to avoid further complicating the already immense salmon/alevin codebase with special implementations handling problems outside of their core function (e.g. mapping reads to the reference efficiently and quantifying UMIs/barcode). Since most protocols (and the most common) have quite simple barcode geometry, it makes sense for this code to live there. I'm fully supportive of enabling support for more complex barcode geometries and preprocessing requirements if there are folks whom it would help, but it feels like that essential complexity belongs upstream of alevin / fry, so that by the time the reads get to alevin, it can assume a straightforward geometry. So TLDR : I think we'd be willing to investigate what is required to address potential frameshift errors, and how much of a difference that makes, but I think that analysis and eventual implementation (if we decide it's worth it), belongs in `splitp`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837:565,protocol,protocols,565,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837,1,['protocol'],['protocols']
Integrability,"Hi @jeremymsimon! In order to test and validate the implementation I would need a count matrix generated on samples. Do you have a sample and count matrix from that? The Rosenberg submission of the data has an unclear way of specifying barcodes and I have emailed him about it. If you have count matrix and matching fastqs that we can use to validate, we can wrap it up soon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-982878463:359,wrap,wrap,359,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-982878463,1,['wrap'],['wrap']
Integrability,"Hi @jeremymsimon, . Somehow, the notification for this in my e-mail got classified as SPAM. Anyway, thank you for the detailed description! I'm going to ping @Gaura here. @Gaura — this is the alternative protocol I was discussing with you yesterday. As you can see, the main issue here is the ""noisy"" barcodes. Let me know what you think would be necessary to add support for this, and I'm happy to schedule a technical discussion if you want to discuss some options.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-921879305:204,protocol,protocol,204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-921879305,1,['protocol'],['protocol']
Integrability,"Hi @jeremymsimon, to answer your last question:. > As for the barcode detection - my usual approach with alevin at least is to let it try to estimate a ""real"" cell number, but if it's way off from our experimental expectations, to inject --expectCells ncells and let that serve as a starting point (with subsequent filtering). That has worked reasonably well in the past for me , and seems to be an option for alevin-fry as well. I don't know whether that is poor practice in the long run...it came from a place of seeing far too many weak knee plots early in the droplet scRNA-seq days. Are you generally more trusting of these estimates these days?. So one of the nice aspects of the alevin to alevin-fry pipeline is that it's relatively easy to try different filtering approaches since the initial mapping process only has to happen once. In general, the knee detection method is pretty good, and often gives a reasonable cell count. However, this isn't always the case. What we find in the alevin-fry pre-print is that it tends to be slightly more conservative than if you did e.g. unfiltered quantification followed by filtering with something like `DropletUtils` (but usually only slightly). The knee method is basically the iterative knee finding procedure from UMI-tools, with some slight tweaks to the parameters. However, unlike alevin, alevin-fry also supports unfiltered quantification. In this case, you provide an `unfiltered-permitlist`, which is a set of acceptable barcodes (not necessarily all expected to be present), and alevin-fry will correct against this. This will tend to produce a _lot_ of quantified cells, since we quantify any barcode matching 10 or more reads (by default, this value is modifiable on the command line). So, such unfiltered matrices definitely need to be filtered after quantification. However, for protocols with an external permit list, or those where you can reasonably derive a list of potential expected barcodes, it's less stringent and therefore po",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988967759:231,inject,inject,231,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988967759,1,['inject'],['inject']
Integrability,"Hi @jeremymsimon,. Both `--splitseqV1` and `--splitseqV2` assume that cDNA is on R1 and UMI + barcodes are on R2. The geometries used are:; - For `--splitseqV1`:; `NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGAGGCCAGAGCATTCGIIIIIIII`, or; UMI-BC1-FixedSeq-BC2-FixedSeq-BC3; Barcode positions (0-based index): 10, 48, 86; - For `--splitseqV2`: ; `NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGACTGTGGIIIIIIII` or ; UMI-BC1-FixedSeq-BC2-FixedSeq-BC3; Barcode positions (0-based index): 10, 48, 78. where the `IIIIIIII` sequence corresponds to barcode and `NNNNNNNNNN` to UMI. This is from the [pipeline code](https://github.com/yjzhang/split-seq-pipeline/blob/master/split_seq/tools.py) used in [this paper](https://www.nature.com/articles/s41593-021-00872-y) co-authored by the lab that developed the protocol. I previously mentioned this in our initial discussions [here](https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951080577). I think adding this to the documentation is a good idea. I will discuss with Rob and add the information. Thank you. :). Now it seems like it's not behaving as expected for `splitseqV1`? Can you share the command you used and the salmon version?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1184412691:851,protocol,protocol,851,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1184412691,1,['protocol'],['protocol']
Integrability,"Hi @jeremymsimon,. I think this is something that we do want to support. Are you familiar with the protocol and what types of changes / additions might need to be made in order to support processing this type of data?. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/861#issuecomment-1642782444:99,protocol,protocol,99,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/861#issuecomment-1642782444,1,['protocol'],['protocol']
Integrability,"Hi @jirazoqui and @pdellorusso,; beware that if you install via a `.tar.gz` file, you make `conda` ignore *all* dependencies. It's somewhat equivalent to `conda install --no-deps ...` and thus I wouldn't recommend doing something like that.; Until we fix the dependencies in Bioconda, can you, if possible, use a separate Conda environment for `salmon` with `conda create -c bioconda -c conda-forge --name salmon salmon`. In this new environment you wouldn't have any dependency version conflict.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996006:112,depend,dependencies,112,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364996006,3,['depend'],"['dependencies', 'dependency']"
Integrability,"Hi @joshstolz,. Is there a reason you want to restrict the possible mapping to this set of 1800 transcripts? In general, mapping to a small subset of the reference is not ideal, because alignment works based on asking if the ""best hit"" for a read is good enough, so its easy to come up with scenarios where the is a read that matches some transcript very well, and another transcript ""alright"" --- if the transcript it matches very well is in the reference, then it will map there, otherwise it will likely map to the transcript where the match is just ""alright"". TLDR; the set of references included can affect the mappings. That being said, if there is a good technical reason you have for only including a subset of transcripts, that's easy to do. You just build your index on only those transcripts. Salmon treats the reference sequences you feed to it as the ""transcriptome"" and will map to that. Also, you could map to the full transcriptome and just extract the rows for these targets from the `quant.sf` files at the end. Of course, depending on what you want to do downstream, you'll have to be aware of how these 1800 transcripts fit into the bigger picture and how the reads that mapped to the other transcripts affect your belief about things like the effective library size etc.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/681#issuecomment-873025258:1041,depend,depending,1041,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/681#issuecomment-873025258,1,['depend'],['depending']
Integrability,"Hi @juugii , it looks like you are using 10x data and you might need `--chromium` flag to tell alevin the type of datasets. Although it should have given error message much before starting reading the CB. I'll look into this but can you please confirm if you have given the flag to alevin or not?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410321746:160,message,message,160,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410321746,1,['message'],['message']
Integrability,"Hi @k3yavi , thank you for the reply. Yes, you are right, it seems the problem is indeed in the whitelist `known_cb.txt`. However, I cannot seem to find out what exactly is going on with the file. When I wrote a python script to check the length of each cell barcode in `known_cb.txt`, _all_ of them are 16 bp long. This is the python script:. ```; $ cat print_length.py; with open('known_cb.txt') as fh:; for i in fh:; print(len(i)); ```. since each line has 16 bp barcode and a `\n` character, it outputs 17, which is expected. However, when I used `awk` to check the length, I expected `awk` to output 16, but it actually output 17:. ```; $ awk '{print length($0);}' known_cb.txt | head -2; 17; 17; ```. There might be some hidden characters that I missed. Any idea what's going?. Now, I have cleaned the `known_cb.txt`, and `alevin` runs without problem. For combinatorial indexing, good to known that it will be supported in future. I guess depending on assays, it needs to be a bit more flexible than the current options. The current options have only `--chromium` and `--dropseq` available. However, there are a few different combinatorial indexing assays. For `sci-RNA-seq`, the cell barcodes are within `I1.fastq`, `I2.fastq` and `R1.fastq`. Only `R2.fastq` is useful for gene quantification. For `sci-ATAC-seq`, the cell barcodes (this is just my educational guess) are within `I1.fastq` and `I2.fastq`, and both `R1.fastq` and `R2.fastq` contain useful information from the genome. For other plate-based method, there will be well barcodes and plate barcodes, which could be located in any of those 4 fastq files depends on the design. The cell barcodes will be a combination of well barcodes and plate barcodes. Thank you very much for the help. Regards,; Xi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/291#issuecomment-420807198:946,depend,depending,946,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/291#issuecomment-420807198,2,['depend'],"['depending', 'depends']"
Integrability,"Hi @k3yavi ,; Thanks for the info!. We are working on an optimized version of SCRBseq and one of the problems we had with the original protocol is the minimum distance between the cell barcodes being too low. So we increased the number of bases. The original protocol was 6 bc and 10 umi. We just switched the 7 position from umi to barcode. We use a known whitelist of barcodes since it's a well plate based protocol. We know that any other barcode are not cells. Is there an option for max distance allowed between BC or UMI?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402440401:135,protocol,protocol,135,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402440401,3,['protocol'],['protocol']
Integrability,"Hi @k3yavi . Thanks for pointing me to the paper. . Some findings/questions from that paper:. 1. The authors do not mention which version of salmon they are using and whether they are using the TXOME or SA or SAF method. I am assuming they are using salmon v.0.12 or a prior version since they submitted their paper in May 2019 and hence, they are probably using the TXOME method; ; 2. The authors do not mention whether they use QuantSeq FWD or QuantSeq REV protocol. I am assuming they are using QuantSeq REV as they have the` salmon quant libtype to be SR`. 3. I think the authors should have used `-noLengthCorrection` with QuantSeq Data. @rob-p and @k3yavi Isn't this flag/option a salmon unique feature that [Rob introduced exclusively for QuantSeq](https://groups.google.com/forum/#!msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ). . Also @rob-p , weren't you referring to the RSEM caveat with QuantSeq data analysis wherein one cannot ask RSEM to disable lengthCorrection and hence the count statistics might be misleading?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-564848220:459,protocol,protocol,459,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-564848220,1,['protocol'],['protocol']
Integrability,"Hi @k3yavi, ; I just re-read this post and I believe that in the CEL-Seq2 protocol, read_1 has first the UMI and then the CB and then polyT... because the sequencing starts with the Illumina adapter (see image below from paper). . Thanks!; ![13059_2016_938_fig1_html](https://user-images.githubusercontent.com/39304679/49376447-edbda900-f70f-11e8-85d7-b86b15c477d5.gif)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-443709804:74,protocol,protocol,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-443709804,2,"['adapter', 'protocol']","['adapter', 'protocol']"
Integrability,"Hi @k3yavi,. Thanks for the reply!. Let's take the PBMC 4K as example. Looking at the summary sheet from 10x: ; http://cf.10xgenomics.com/samples/cell-exp/2.1.0/pbmc4k/pbmc4k_web_summary.html. They detected 4,340 cells with a median UMI count of 3,866 per cell. That means ~17M UMIs in the count matrix, which is in the same order what I find with Alevin. I am not sure if/where Alevin reports the number of mapped reads (maybe it is the number of hits?), but this is not of much importance. Indeed, the total UMI count is **much** lower than the number of sequenced/mapped/barcoded reads (~190M), which is expected. However, using the `--dumpUmiGraph` option provides a file ""MappedUMI.txt"" which I assume are the number of deduplicated UMIs mapped per cell/barcode (summed over all genes). The sum of over all the barcodes = 17M in this case and the sum per barcode = the sum in the quant_mat. This does not hold for the adapted cel-seq2 protocol. sum mapped UMI != summed quant_mat.gz. I am making a mistake, or is there something wrong?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490098177:940,protocol,protocol,940,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490098177,1,['protocol'],['protocol']
Integrability,"Hi @k3yavi,; Many thanks for you prompt answer, once again. >When you say you try subsampling the Fastq, did you sample randomly across the full Fastq or chose the top X reads. Yes, I did perform a random subsampling, ie. taking a read with a p probability while reading the fastq files, p being the subsampling coefficient I did mention (pE[0;1]). An implementation of this approach as an option during the transcript quantification would be great. I can provide you with the simple python script I use for the subsampling, but I am not sure if it is the proper way to subsample during alevin quantification. >when you say cellranger subsampling, do you mean the cellranger aggregate pipeline?. Yes, sorry for not clearly stating it. I did use the cellranger aggregate function indeed, which by default subsample the expression matrices with high sequencing depth depending on amount of mapped reads, if I understand well. >Use Alevin w/o any modification to the fastq on both of your sample to generate the gene count matrices. I already did that, in downstream analyses I have a batch effect issue related to the sequencing depth. >that's why we recommend using the Seurat package downstream of the Alevin quantified matrices. I have some experience with downstream analyses with Seurat, Pagoda, Scater, scanpy and a few other tools, and I am aware of batch correction methods like CCA or MNN. But that is not what I am looking for here. I did both CCA and MNN but I loose some important information in the resulting eigenspaces or corrected matrix. I believe the proper way to correct my batch effect is to simply fix the difference between my two libraries, ie. the sequencing depth in this case. As I explained in my first message, cellranger aggregate (subsampling based on the amount of mapped reads) works very well in my case, correct the effect without any loss or modification of important genes in our scientific question. Not CCA or MNN. I would like to be able to do the same from the a",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913:865,depend,depending,865,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913,1,['depend'],['depending']
Integrability,"Hi @k3yavi,; There is no more message error. Once the message occurs, it abruptly ends and that's it. > weren't you using the whitelisted CB instead of ""knee"" thresholding?. Yeap, but in the previous dataset. In this one the CB is provided in the dataset, and I don't have to create a whitelist. . The error does not always happen. I have created other random datasets, and they do not always fail. I will try to create a small dataset which fails, for you to replicate. Is there anyway I can privately send it to you?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-505504105:30,message,message,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-505504105,2,['message'],['message']
Integrability,"Hi @kai2june,. Thank you for the _detailed_ report! It's interesting because (a) those functions aren't doing anything too exotic and (b) CentOS is the OS we use on our continuous integration. We'll try and get a better handle of what is going on here. In the mean time, could you tell us if you see the same behavior with the [pre-compiled binary](https://github.com/COMBINE-lab/salmon/releases/download/v1.4.0/salmon-1.4.0_linux_x86_64.tar.gz) available from the downloads page?. P.S. One other thing worth trying. We've noticed that compiler support for interprocedural optimization isn't terrific. You can try building salmon without this option by passing `-DNO_IPO=TRUE` as an additional cmake flag.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/609#issuecomment-751366046:180,integrat,integration,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/609#issuecomment-751366046,1,['integrat'],['integration']
Integrability,"Hi @kbchoi-jax — the index size (i.e. 32 or 64-bit) is dependent only on how long the reference is, not the width of the machine on which you're running Salmon. That is, if the reference is < 2.1G, then a 32-bit index will always be used (even on a 64-bit machine). The purpose of the ""64-bit"" index is that it uses 64-bit indices when building the suffix array, so that it can distinguish positions on much larger reference sequences (up to 9223372036854775808 characters . . . but you'd run out of memory long before that ;P).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-220451342:55,depend,dependent,55,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-220451342,1,['depend'],['dependent']
Integrability,"Hi @kdorman,. Ok, let me refine my response a little bit. When you said that the files were ""unpaired"" I was under the assumption that the synchronization between the left and right files was broken; that is that the read names in the left file are in a different order than the right file. In this case, `salmon` doesn't check explicitly, and it doesn't store reads internally and wait for the mate in the other file. Every time it reads a record from the left and right file together, it assumes they constitute a pair during sequencing. If the files become desynchronized, you will likely observe the behavior I mentioned in my initial response.; ; However, if the reads remain properly paired, then they will be mapped as such. Judging from the total number of reported fragments in the output above, it looks as though it's attempted to map the first `17361911` reads from both files, treating them as paired-end reads (ignoring the extra records in file 1 that have no mate in file 2). You could check if it's the case that these reads are properly paired, and that file 1 just contains some extra reads that were unpaired after filtering.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/793#issuecomment-1220773109:139,synchroniz,synchronization,139,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/793#issuecomment-1220773109,1,['synchroniz'],['synchronization']
Integrability,"Hi @keithgmitchell,. Alevin is designed for droplet-based, tagged-end protocols, and in the vast majority of these protocols, transcript-level quantification isn't really reliable enough to be useful. Since most tagged-end protocols sequence information from only the 3' end of the transcripts, there is a highly-biased coverage signal, and discerning UMI assignment at the transcript level is usually not possible. Therefore, I wouldn't generally recommend trying to obtain transcript-level counts from alevin and we haven't tested it in this context. If you have a particular reason you want to look at transcript counts and believe it may be reasonable in your specific use-case, you can alway pass in a gene-to-transcript map that just maps each transcript to itself, which will result in a transcript-level output matrix. However, I anticipate that the resolution problem will become more difficult in this case, and there will be much more uncertainty in the assignments. @k3yavi, please feel free to add anything you think I may have missed. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/588#issuecomment-729974232:70,protocol,protocols,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/588#issuecomment-729974232,3,['protocol'],['protocols']
Integrability,"Hi @kieranrcampbell,. Indeed, such reads will be un-mappable. The only tricky question here is at which point we should (1) do nothing (2) issue a warning (3) issue an error. Since the reads may not all be of the same size (perhaps the user has quality-trimmed the reads first and not opted to discard the short ones), it's possible we may see some reads too short to consider, but others would not be. We could choose arbitrary cutoffs (warning if greater than 1,000 such reads and an error if greater than 1,000,000), but this will, of course, depend on how large the input data set is. Anyway, I agree that we should notify the user of this and will be happy to add it; do you have any suggestions on the default behavior?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/41#issuecomment-181394180:546,depend,depend,546,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/41#issuecomment-181394180,1,['depend'],['depend']
Integrability,"Hi @knokknok,. Would it be possible to share a small subset of these reads that reproduce the issue? Basic thoughts : does it work without `--validateMappings`? Are the read files synchronized (i.e. are there the same number of left and right reads)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393240942:180,synchroniz,synchronized,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393240942,1,['synchroniz'],['synchronized']
Integrability,"Hi @kvittingseerup,. Basic adapter and quality trimming should be done. There's some [nice work by Matt MacManes](https://www.frontiersin.org/articles/10.3389/fgene.2014.00013/full) showing that you should be careful about aggressive quality trimming, but light quality trimming is usually beneficial. This is particularly important if the underlying aligner isn't doing local alignment (e.g. STAR will likely just softclip bad bases).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/390#issuecomment-506744431:27,adapter,adapter,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/390#issuecomment-506744431,1,['adapter'],['adapter']
Integrability,"Hi @kvittingseerup,. No need to apologize, I think it was I who was not clear. What I am saying is that this is *already* the way that Salmon handles such a case. That is, if you have a paired-end read, and one of the reads maps but the other doesn't (due to e.g., adapter contamination or just very low quality), then Salmon will consider the remaining (mapping) end of the read as representative of an entire fragment, and will resolve the fragment origin accordingly during optimization. Generally, not having both ends of a paired-end read leads to increased ambiguity, but this isn't a particularly big problem if it only happens to a generally small fraction of the reads. Further, since you cannot reliably infer the implied fragment length on a transcript from only a single-end read, such mappings will not contribute to the bias model. Again, however, as long as this doesn't happen to the vast majority of fragments, it should have only a negligible effect on quantification and bias correction. Please let me know if this description makes sense. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997:265,adapter,adapter,265,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997,1,['adapter'],['adapter']
Integrability,"Hi @kvittingseerup,. Sorry for letting this sit for so long without responding. Currently, Salmon does not support mixed paired-end and single-end library types, so this is presumably what is causing the error (granted, the error message here could be considerably better). Practically, I'd be curious what the difference is between allowing this and simply running Salmon with the _non-quality-trimmed_ paired-end reads. Specifically, if Salmon is not able to map a pair concordantly, but it can map one of the ends of the read, then it will already do so. . However, in the case that there's a really compelling reason to want to quality trim the reads prior to quantification (and to include the reads such that the mate has been completely quality-trimmed away), we would be able to support this. It will require a bit of modification to allow different library types to be processed back to back and to contribute to the same quantification estimates. In this case, I imagine what we would want to do for the orphans is essentially what Salmon would do internally if it can't map the mate. That is, we would learn essentially all of the parameters and biases from the pairs that do map concordantly, and then just include the orphaned reads as indicating an entire fragment but of unknown length. Let me know if you have any thoughts about the above, and sorry again for the delay!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353196630:230,message,message,230,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353196630,1,['message'],['message']
Integrability,"Hi @lauraht,. So I decided to explore just one of these to see if I could figure out what might be going on. The below is with respect to `SRR9007475`. So first, even though I processed the data with the latest version of the develop branch (which will become 1.2.0), I got basically identical results to what you reported. Simply aligning the data against an index built on a human Gencode v26 transcriptome (with no decoys) gives me a mapping rate of `0.00378202832148367%`. The first thing I did was to quality and adapter trim the data (using `fastp -i SRR9007475.fastq.gz -o SRR9007475_trimmed.fastq.gz -q 10 -w 8`) and ... whoa. This is the fastp html report [fastp.html.zip](https://github.com/COMBINE-lab/salmon/files/4176345/fastp.html.zip). So the first astounding statistic, the mean read length before trimming is 51bp (these are relatively short single-end reads). The mean read length after trimming is 21bp! So, the average read length is, in fact, less than the k-mer length used for indexing (default is k=31). On the trimmed data, the mapping rate goes up to `2.3545475882931305%`, still very low, but now there's somewhat of an explanation, the average read is shorter than a single k-mer. So, the next thing I tried was indexing with a smaller k; a _really_ small one in this case,`k=15`. Then, I re-ran on the _trimmed_ reads (the fact that the trimming took us from 51-21bp suggests that the reads had a lot of low quality bases, adapter contamination, or both). Under this setting, I still get a very low mapping rate, but it was _much_ higher — `16.766993524863488%`. The final thing I tried was seeing how the mapping rate changed as I altered `--minScoreFraction`, which is the salmon parameter that determines the alignment score that a read must achieve in order to be mapped validly. The default is 0.65. This means that the read cannot have a score < 0.65 * the maximum achievable score for the read given it's length. In the case of a 21bp read, the best score would be ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668:518,adapter,adapter,518,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668,1,['adapter'],['adapter']
Integrability,"Hi @lauraht,. Sure; let me answer these in order. (1) Salmon does not really make use of the read id (we assume the fasta files are synchronized in the input). The one place that not using the `-l` option might raise a complication is if you wish to dump the mappings and examine them (using `--writeMappings`), in which case it will be difficult in the SAM file to discern which read is which just from the names (though the flags should still be valid). (2) Yes, this is normal and expected behavior. Since the online phase of salmon is asynchronous, the online updates may arrive in a slightly different order. This can lead to a slightly different starting condition for the offline phase and, subsequently, small differences in the abundances. However, these differences are generally small and are _inherent_ to the uncertainty in the inference itself. That is, the estimates have inherent uncertainty that is greater than the variation you might see between runs. To assess this you can (and, perhaps should) estimate this uncertainty by asking salmon to draw inferential samples (e.g. Gibbs samples with `--numGibbsSamples`). Best,; Rob. P.S. As a general note, I'd recommending upgrading to the latest version of salmon. We update salmon quite regularly with both small and large improvements (and bug fixes where relevant). There has been quite a lot of progress since version 0.9.1.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/478#issuecomment-578326494:132,synchroniz,synchronized,132,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/478#issuecomment-578326494,1,['synchroniz'],['synchronized']
Integrability,"Hi @lubios,. I'm glad that you were able to address the first issue. The thing that's strange about the second is that somehow the output path you are providing in the command doesn't match the directory name in the error message. Specifically, your command has the output directory as `transcripts_DecoyQuant`, but the error reports not being able to create the directory `transcripts_quant`. Are the command and error here properly paired?. The only situations under which one might expect this issue to occur is if either (1) your user doesn't have sufficient permission to create the location where the output is to be written or (2) the disk on which the output is to be written has insufficient space. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-964546340:222,message,message,222,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-964546340,1,['message'],['message']
Integrability,"Hi @mathog, . You can give ; [this liunux binary](https://github.com/COMBINE-lab/salmon/files/2099291/salmon-latest_linux_x86_64.tar.gz) a try. It's built on our Drone CI box, which uses CentOS 6. You are absolutely right that Boost is a giant PITA. The recommended way to grab the binary is via [bioconda](https://anaconda.org/bioconda/salmon), since that takes care of libraries, dependencies etc. Please let me know if either of these work for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397029798:382,depend,dependencies,382,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397029798,1,['depend'],['dependencies']
Integrability,"Hi @mojakab ,; Thanks for your interest in Alevin. Currently most of our research efforts have gone into developing Alevin for droplet based 3' tag sequencing like 10x chromium and DropSeq. Although similar but Cel-Seq2 relies on a different cell isolation step which can potentially create assay specific bias between the experiments. Basically Alevin is designed to work with single-cell protocols which follows the following criteria:; * Droplet based cell isolation.; * 3' tag sequencing.; * Fragmentation post Amplification. We have similar such request in https://github.com/COMBINE-lab/salmon/issues/269, where the user was able to use Alevin with Cel-Seq2 but currently we have not explored the full potential of Alevin with Cel-Seq2 and might require more careful consideration. If you happen to use Alevin on Cel-Seq2 data we'd appreciate your feedback based on your experience.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-439527284:390,protocol,protocols,390,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-439527284,1,['protocol'],['protocols']
Integrability,"Hi @moschmi ,. Thanks for sharing the file.; You are right the transcript id `PB.40054.21` is indeed present & has the gene mapping in the file you forwarded. Unfortunately, the specific error message was not useful here but the issue is the following: ; ![image](https://user-images.githubusercontent.com/8772521/85436584-45706f00-b557-11ea-9ba2-95ebf4e43bc4.png). If you check the file you forwarded from line number 12,133 - 12,137, it seems a bunch of transcript ids are blank and has no assigned gene-ids. In this case the file parser was not intelligent enough to ignore such empty mappings and end up using the next line (before) tab as the wrong mapped gene-mappings. Later, when alevin sanity checks for the mappings of all transcripts, alevin complaints about not being able to find it for a random transcript much lower in the order. In short, I know you used the bioawk script for making the transcript to gene mapping file, but the script was written with the gencode generated GTF in mind, it seems the one you have has some small difference which is creating the issue. Currently, the easiest fix is to parse the GFF file again and generate the mappings for all the transcript in the proper format. In the future, we will add a sanity check for these type of corner cases, thanks for reporting this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/540#issuecomment-648319730:193,message,message,193,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/540#issuecomment-648319730,1,['message'],['message']
Integrability,"Hi @mugpeng,. This is because it is covered by the custom geometry specification (as laid out in the docs). I agree it's nice to have a specific flag for each geometry, rather than to have to e.g. specify the custom geometry each time. We are working on good solutions to that at a higher level (e.g. in our `simpleaf` tool where users can register their own custom geometry specifications and refer to them by name). However, in `salmon`/`alevin` right now, the named geometries are hard-coded, and so to have a specific `--indropV2` flag, that would have to be added to the argument parser and then mapped to the specific underlying geometry in the code. This isn't hard, but as the number of different chemistries proliferates, it's not ultimately a scalable solution. So, the current recommendation would be to use the custom geometry flags as specified in the documentation, or adopt a wrapper like `simpleaf` and add `indropV2` to your custom geometry specification library. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1758171139:891,wrap,wrapper,891,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1758171139,1,['wrap'],['wrapper']
Integrability,"Hi @nh13,. This is not something for which we currently have support or something that we currently plan. I'd be open to it, but I'm honestly not sure how to cleanly do it in the current architecture, and doing so would certainly incur a performance hit. Salmon runs 2 phases of inference; and online phase and an offline phase. The online phase has access to _fragment-level_ information that is then summarized away during the offline phase (like the specific locations of each read, the length of each observed fragment, etc.). That information goes away when the reads are summarized into range-factorized equivalence classes. Moreover, some of the model parameters learned during the online phase will depend (in their details) on the order in which observations are made. Ostensibly, observing the same data in the same order **and issuing updates to shared model parameters from worker threads in the same order** should result in identical values, however this has never been tested and was never a design goal. The reason for this is that differences between runs are within the bounds of the inherent inferential uncertainty of the estimated parameters anyway. That is, if one is relying on a specific value at a level of precision such that a different run of salmon would produce a value different enough to change a downstream analysis, then one is imparting more precision on the estimates than they can provide. Other methods that produce identical results between runs for these values may produce the same output, but the accuracy of the output at that level shouldn't be trusted in this case. The uncertainty of the parameter estimates can be evaluated based on the Gibb samples (or bootstrap replicates) that salmon computes. Of course, the small differences between runs rarely lead to differences in downstream analysis (almost certainly at the gene level and also at the transcript level if you use a differential testing method that is aware of inferential uncertainty). On the ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538:707,depend,depend,707,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538,1,['depend'],['depend']
Integrability,"Hi @nskbe,. The issue you're seeing with the mapping file name is related to this note in the release notes:. > Note: In the 0.7.2 release, the file provided to --writeMappings must use a qualified path (e.g. --writeMappings=./out.sam rather than --writeMappings=out.sam), this constraint is already addressed on develop and will be fixed in the next release. . Essentially, the code should internally qualify the filepath before checking if a directory exists, but it doesn't. The fix for this is to pass the file name as a qualified path (i.e. adding `./` before the file name when you want it in the current directory). This is already resolved in develop and the fix for this annoyance will make it into the next release. Regarding the issue with writing the information to `stdout`; actually, all of the logging messages are written to `stderr`. If you don't redirect `stdout`, then you'll see everything, but the intended usage for that mode is something like:. ```; salmon quant -i idx [other options] --writeMappings > out.sam; ```. This will redirect standard out to out.sam. You'll still see the logging messages on the console, since they are written to `stderr`, but all of the mapping contents are redirected to the file. Let me know if this resolves your issue. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247072758:817,message,messages,817,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247072758,2,['message'],['messages']
Integrability,"Hi @pabloaledo,. Thanks for the report! I am not familiar with spack. However, the bigget issue here is that I don't believe that salmon, by itself, should require/depend upon libhts. It uses libstaden for its sam/bam parsing, but that should be a self-contained dependency. We should figure out why libhts is being pulled in here. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/866#issuecomment-1664067688:164,depend,depend,164,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/866#issuecomment-1664067688,2,['depend'],"['depend', 'dependency']"
Integrability,"Hi @phickner,. The error message seems to be coming from the library we use to parse the BAM file (https://github.com/jkbonfield/io_lib/blob/master/io_lib/bam.c#L329). Is it possible that somehow the BAM itself is ill-formed? Maybe as determined by [picard ValidateSamFile](https://broadinstitute.github.io/picard/command-line-overview.html#ValidateSamFile) or some such?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-442697747:25,message,message,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-442697747,1,['message'],['message']
Integrability,"Hi @pinin4fjords ,. Apologies for the delayed response and thanks for your interest in Alevin.; Unfortunately, there is no one straight answer for your question. ; Other people have been using Alevin for various microwell based protocols like (CEL-seq https://github.com/COMBINE-lab/salmon/issues/269 ) but from our side we have not extensively tested alevin on non-droplet based protocols. However, we are open to provide any kind of help you may need to test the microwell-seq protocol and extend the support for alevin. If you happen to have been already testing alevin please let us know of your experience and how we can improve aleivn.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/358#issuecomment-490089165:228,protocol,protocols,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/358#issuecomment-490089165,3,['protocol'],"['protocol', 'protocols']"
Integrability,"Hi @pinin4fjords ,; Thanks for raising an important question and running alevin for the training.; I think there is a confusion regarding the `quantmerge` command. That command works only with bulk RNA-seq quants not with alevin output. To answer your question of running multiple alevin instance for multiple file pair, might depend on what are the separate files from, are they from separate lanes or are they separated based on cellular barcode ? The basic intuition is after initial barcode assignment, alevin works on each cell disjointly meaning as long as you are confident that each file pair is cell disjoint then at the end you can just cat the output of the alevin quants. Also, depending on what's the training about you can think of multiple workarounds like you can use very small 100 cell (7 million reads) datasets from 10x and combine it all together in one file if size and multiple files is a problem.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/434#issuecomment-540033932:327,depend,depend,327,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/434#issuecomment-540033932,2,['depend'],"['depend', 'depending']"
Integrability,"Hi @pophipi ,; Sorry for the late response.; We have updated some of the steps for the `v1` pipeline and the relevant How to [document](https://combine-lab.github.io/alevin-tutorial/2018/running-alevin/) has been updated too. Please refer to the tutorial and let us know if you still face the problem. Specifically in your case you might have to do the following things: ; * compile the `wrapper.cpp` file in `salmon/scripts/v1_10x` folder with the command:; ```; g++ -std=c++11 -O3 -I \<PATH TO SALMON INCLUDE DIRECTORY\>-o wrapper wrapper.cpp -lz; ```; * Update the `run.sh` file [here](https://github.com/COMBINE-lab/salmon/blob/master/scripts/v1_10x/run.sh#L17) with the path to the `wrapper` binary created in the above step.; * Use following command to run alevin in v1 mode:; ```; ./run.sh salmon alevin -l ISR -b ./reads/ --gemcode -i ./index_15_pc -p 10 -o ./alevin_15_pc --tgMap ./txp2gene.tsv --dumpCsvCounts --dumpFeatures --end 5 --umiLength 5 --barcodeLength 14; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/294#issuecomment-422198746:388,wrap,wrapper,388,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/294#issuecomment-422198746,4,['wrap'],['wrapper']
Integrability,"Hi @pophipi ,; Thanks for the interesting question, but unfortunately in the current version of Alevin you can't tweak the mismatch rate option although based on the type of error/noise in the reads you can try reducing the size of the k from default 31 to something smaller and see if it helps. We are working on tweaking the mapping algorithm for Alevin allowing mismatches but it's still in testing phase and has not been integrated yet. We'll let you know as soon as we have version supporting that.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/280#issuecomment-416969420:425,integrat,integrated,425,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/280#issuecomment-416969420,1,['integrat'],['integrated']
Integrability,"Hi @ramezrawas,. Can you say precisely what you mean by reproducible? Do you mean that the values in the .sf file are not identical? If so, this is expected behavior. It exists for a number of reasons. The big one is that the initial phase of salmon uses an online inference algorithm so that specific details of the solution are dependent on the order in which the reads are processed (which is random given that multiple threads parse reads and update estimates asynchronously). However, the more important point here is that the inference estimates returned by Salmon (and, for that matter, every other transcript-level expression tool) are the result of a statistical optimization procedure that cannot guarantee a unique global optimal solution (and, in fact, even if a global optimum could be guaranteed, there may be multiple different optima). Thus, there is uncertainty inherent in the statistical problem being solved. Of course, if one ordered updates in the same way and set up the initial conditions precisely the same, there would be convergence to the same result, but any sense of confidence there is illusory. However, Salmon does provide a way to quantify, statistically, confidence in the result. The `--numBootstraps` option will do bootstrap sampling, or the `--numGibbsSamples` option will perform posterior Gibbs sampling. Both of these techniques will provide samples from the posterior distribution, and the variance of these samples will give you some information about the variance in the results that are due purely to the inherent statistical uncertainty in the problem. In the `scripts` folder there is a python script `ConvertBootstrapsToTSV.py` that will convert either the bootstrap or gibbs samples to a easily readable tsv format. These samples represent the estimated number of reads coming from each transcript when sampling from the posterior. These can be used to empirically estimate that statistical uncertainty in the abundance estimates of the different tran",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248:330,depend,dependent,330,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-259464248,1,['depend'],['dependent']
Integrability,"Hi @rbenel,. This message is just salmon letting you know a newer version is available. The installed version should function perfectly fine. If you really want to avoid the message, you can pass `--no-version-check` *before* the salmon command; e.g.:. ` salmon --no-version-check index ...`. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/262#issuecomment-409903345:18,message,message,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/262#issuecomment-409903345,2,['message'],['message']
Integrability,"Hi @rfarouni ,. Is it possible to visualize the above two plots on the same scale ? ; Regarding the few cells not from 10x whitelist, I should have been more clear last time. ; Basically, what I meant earlier when I said that 10x data is clean is that we do observe some cells from the non whitelist file _but_ they have very few UMI and we discard them anyway. I am guessing here your motivation is a bit different i.e. considering very low confidence (even with 1 UMI) barcodes, while generally we discard anything below 10 as noise. Thanks a lot for offering to help with index-hopping idea. I agree, it'd be great to include the model in the alevin framework. Currently I just got the gist of your paper, let us go through the paper in a bit more detail and we'll get back to you as soon as we have some free cycles for the integration.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639137897:828,integrat,integration,828,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639137897,1,['integrat'],['integration']
Integrability,"Hi @rfarouni ,. Thanks a lot for raising the issue.; It looks like a corner case with the custom barcode length and I'd have to push a hot-fix for it. Basically, it's failing in the initial sanity check stage where it assumes we can provide only one single-cell protocol type. Give me like half an hour to make the changes and I'll push the fix to the develop. If you can compile salmon from source that's great, otherwise I can also forward a linux portable binary.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638385340:262,protocol,protocol,262,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638385340,1,['protocol'],['protocol']
Integrability,"Hi @rmurray2,. Thanks again for the detailed question (I answered them in reverse order, so that's why I'm saying ""again"" here). There are a few things going on that could be leading to differences. They are, in the order I think they will have an effect on the result:. * You are using RSEM in a mode that is mapping the reads to the entire genome (using STAR) and then projecting the resulting alignments to the transcriptome. You are using salmon in a way that is performing selective alignment against the transcriptome only. We have recently published [a paper](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8) discussing in detail the effect that some of these choices can have on transcript and gene-level abundance estimation. In general, if you don't include the genome as a mapping target, depending on your sample, there may be certain reads that are assigned to the transcriptome even though they have a better alignment to some other genomic location. This is independent of e.g. salmon and RSEM, and you'd observe the same thing if you ran RSEM using e.g. Bowtie2 as the aligner aligning against the transcriptome. Luckily, you can control this source of variation. Salmon, like RSEM, can accept alignments to the transcriptome produced by STAR. If you want to see how big of an effect this is having in your sample, you can align reads to the genome using STAR (and project them to the transcriptome) to produce a BAM file that salmon can quantify. You can check RSEM's script to see exactly how it invokes STAR, but the parameters are something like `--outFilterType BySJout --alignSJoverhangMin 8 --outFilterMultimapNmax 20 --alignSJDBoverhangMin 1 --outFilterMismatchNmax 999 --outFilterMismatchNoverReadLmax 0.04 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --eadFilesCommand zcat --outSAMtype BAM Unsorted --quantMode TranscriptomeSAM --outSAMattributes NH HI AS NM MD --quantTranscriptomeBan IndelSoftclipSingleend`; note tha",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590:828,depend,depending,828,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590,1,['depend'],['depending']
Integrability,"Hi @rob-p ,. The data downloaded from sra database and use `fastq-dump` to split it only generate one fastq file, and EBI database only show one fastq file per sample. I am not sure if I process the file correctly. And here is a part of the description of the file on the sra database, and the link of one of the file <br class=""Apple-interchange-newline"">[SRR8453531](https://www.ncbi.nlm.nih.gov/sra/SRX5260234[accn]). ```; Instrument: Illumina HiSeq 3000; Strategy: RNA-Seq; Source: TRANSCRIPTOMIC; Selection: cDNA; Layout: SINGLE; Construction protocol: The scRNA-seq libraries were generated using Chromium Single Cell 3' Library & Gel Bead Kit v2 (10X Genomic) according to manufacturer's protocol. Briefly, 10,000-15,000 live cells were FACS-sorted and used to generate single-cell gel-bead in emulsion (GEM). After reverse transcription, GEMs were disrupted. Barcoded cDNA was isolated and amplified by PCR (12 cycles). Following fragmentation, end repair, and A-tailing, sample indexes were added during index PCR (8 cycles). Indexed libraries were multiplexed and sequenced on Illumina HiSeq 3000 instruments according to the manufacturer's instructions (26 cycles of Read 1, 8 cycles of i7 Index, and 98 cycles of Read2).; ```. Best",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/769#issuecomment-1107684572:548,protocol,protocol,548,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/769#issuecomment-1107684572,2,['protocol'],['protocol']
Integrability,"Hi @rob-p . Before I answer your question and layout my logic, I want to mention that I am **_not_** suggesting fastp is not doing its job, **_neither am I stating that fastp is working incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Not",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:266,adapter,adapter,266,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,5,['adapter'],"['adapter', 'adapter-trimming', 'adapters']"
Integrability,Hi @rob-p . Thanks for the elaborate answer - makes a lot of sense. The problem is that adapter contamination typically occures because the fragments were smaller than the sequence length we sequence into the adapters - and it can occur for a larger fraction of the reads (I've seen up to 50% of reads affected in the 3'end) making it non-negligible. That is why I suggested the extension in the first place. I think it makes a lot of sense to trim adapters away - both because they reduce the number of compatible reads - mostly because the failure to do so will result in an overestimation of the fragment length. . Now that I think about it I don't think we should trim reads based on quality as that will lead to an underestimation of the read length - or what do you think?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355909325:88,adapter,adapter,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355909325,3,['adapter'],"['adapter', 'adapters']"
Integrability,"Hi @rob-p . Thanks for the quick reply. Indeed my salmon index does not include lncRNAs, but my sequencing does. For indexing, I only used UCSC RefSeq transcripts (which I believe contains only protein coding transcripts that exclude most of lncRNAs). But this does not seem to suffice to explain the low mapping rate as Wikipedia says ""[Quantitatively, lncRNAs demonstrate ~10-fold lower abundance than mRNAs in a population of cells.](https://en.wikipedia.org/wiki/Long_non-coding_RNA#Abundance)"". To answer your questions:; 1. I used `htseq-count`, and here are the overall statistics (out of 149347870 record pairs processed):; ```; stat	""-s yes""	""-s reverse""; __no_feature	135258158	44917653; __ambiguous	39301	594958; __too_low_aQual	0	0; __not_aligned	0	0; __alignment_not_unique	7430169	7430169; ```. 2. I haven't done quality/adapter trimming as the data really looks clean and of high quality according to FastQC report. 3. Unfortunately I can't share the raw data yet but I will try your suggestion to quantify with STAR at the transcript level.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-847091597:835,adapter,adapter,835,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/661#issuecomment-847091597,1,['adapter'],['adapter']
Integrability,"Hi @rob-p . Totally understood (even more severe current limitations here) - survey completed. I think there'll ""always"" be Illumina-level coding (we use it to multiplex samples or cells), but I suspect most (all?) wild-west method will be some form of using the one read for barcoding. So as long as I can stipulate which bases in the read are which kind of barcode (cell/molecular) that'd be a good start. Of course having more mature methods than the current [drop-seq protocol](http://mccarrolllab.com/wp-content/uploads/2016/03/Drop-seqAlignmentCookbookv1.2Jan2016.pdf) to error correct, remove poly-A, remove adaptor sequences etc. always very welcome. (I suspect @vals is onto something... I still struggle to be entirely convinced that UMIs, as currently used, have the long-term legs that some people think.)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-282741659:472,protocol,protocol,472,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-282741659,1,['protocol'],['protocol']
Integrability,"Hi @rob-p @Gaura and @k3yavi - I actually just had this problem myself, and would now like to confirm what `--splitseqV1` and `--splitseqV2` are doing. I can't seem to find the UMI or barcode geometries these settings assume, can one of you clarify that here? Usually the cDNA is on R1 and UMI + barcodes are on R2, but it seems as though `--splitseqV1` may be assuming the opposite. It's okay and easy enough to reverse the input files like recommended above, but many users may face a similar issue if so. On a related note, it would be great to add these presets to the `alevin` docs, and for these and other geometry presets, spell out exactly which nucleotides on which reads are being extracted. `--splitseqV1` and `--splitseqV2` are not currently mentioned among the other protocol-specific setups in the `alevin` docs. . Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1181068459:780,protocol,protocol-specific,780,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1181068459,1,['protocol'],['protocol-specific']
Integrability,"Hi @rob-p and all,. Thank you for the wonderful tool.; I've been using Salmon for some time now, and have encountered a question.; How is Salmon affected by different read lengths and adapters?. I have a dataset with 5%-15% adapters at 3' of read. How will salmon output be affected if:; 1) I don't remove them; 2) I trim all reads down; 3) use an adapter trimming program - resulting in reads with different length. . Thank you",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/634:184,adapter,adapters,184,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/634,3,['adapter'],"['adapter', 'adapters']"
Integrability,"Hi @rob-p,. I think I have figured out the issue. It seems like there's a dependency conflict with the ICU (international components for unicode) package between Salmon and R. It's been mentioned in this issue as well: https://github.com/COMBINE-lab/salmon/issues/594. I cannot have both the newest version of R and Salmon in the same environment. For context I've been installing Salmon>=1.10.1 through the bioconda channel, and base-r>=4.3.2 through conda-forge. Whenever I have R in the same environment, Salmon defaults to v0.14.1 during use (but the newest version when on the command line). If I remove R, Salmon defaults to the newest version during use and on the command line and works as normal.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/881#issuecomment-1944356621:74,depend,dependency,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/881#issuecomment-1944356621,1,['depend'],['dependency']
Integrability,"Hi @rob-p,. I was finally able to grab some time to try running the beta version you linked (see attached logs). This certainly helped, although I'm still nowhere near a time-frame of ~30min. Here are my results:. The 31-mer running took a bit over an hour and consumed ~17GB of memory. This is about half the running time as the previous version, but approx. the same amount of memory requirement (more on that below). The 17-mer running, took 4.5hrs to complete and consumed ~64GB of memory. This particular running is again, about twice as fast, although the time really depends on the memory limitations I gave it. Since it appears that this version no longer crashes when given less than about 250GB of memory, I also tested with 32G and 16GB of memory, just to see what impact this would have on the times. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, accordi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:574,depend,depends,574,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,1,['depend'],['depends']
Integrability,"Hi @rob-p,. Thanks for the tip, using `--noErrorModel` indeed got rid of the error messages. Also, any advice regarding the best practices using salmon on nanopore data are welcome. Best,; Botond",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-420553174:83,message,messages,83,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-420553174,1,['message'],['messages']
Integrability,"Hi @rob-p,. thank you for the attention. . I noticed that Salmon tries to fetch and install dependencies. It's just that I tried to install a newer version in my home, but the HPC I'm using does not allow an external connection to the Internet. The installed version is a bit obsolete, so I need to wait for administrators to install the newer version (and usually the wait takes days and I like to settle things for myself. haha). Thank you very much. Best, Duca.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/225#issuecomment-392344952:92,depend,dependencies,92,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/225#issuecomment-392344952,1,['depend'],['dependencies']
Integrability,"Hi @rob-p,. thank you for your quick answer. As mentioned already, I started with the full set of options (at least I thought so) and then reduced them to the minimal case to reproduce the error for reporting the problem.; I was mislead by the term 'unrecognized option' and didn't expect the program to ""forget"" options from other modes. But now that you stated that this is the case, I realized that the '-a' in front of the BAM file name was missing, which I overlooked before. After adding it the program at least started to run. (Although it ran into another crirical error, appearantly misinterpreting chromosome and supercontig names from the BAM file header generated by STAR as transcript names.). Maybe it would be a good idea to distinguish in the error messages between 'unrecognised' and 'inappropriate' options to provide a better clue to the user what went wrong.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/343#issuecomment-462761900:765,message,messages,765,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/343#issuecomment-462761900,1,['message'],['messages']
Integrability,"Hi @rob-p,. would it be possible to add a feature similar to `salmon quant` like `--read-geometry 1[1-end]` (as in Alevin) to define which part of both R1 (and R2) should be used for the quantification? That would omit the need for trimming in case of adapters and make salmon workflows even more lightweight. best,; -Alex",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/743:252,adapter,adapters,252,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/743,1,['adapter'],['adapters']
Integrability,"Hi @rob-p,. you wrote that the first phase of the algorithm may yield different results dependent on the order in which reads are observed / processed. How is the order determined? Could you point me to the location in the source where this happens?. Asynchronicity doesn't necessarily have to lead to non-determinism if we can ensure that the assignment of threads of execution to reads is deterministic. I'd be happy to work on this, if you can point me to the locations of interest (and maybe some overview on how the code is supposed to behave). (Note: I'm not a biologist, just a silly hacker, so please be patient when I have silly questions.)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/185#issuecomment-392759884:88,depend,dependent,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/185#issuecomment-392759884,1,['depend'],['dependent']
Integrability,"Hi @rob-p,; thanks a lot for your investigation. Could you please be more verbose on those incorrect Build-Depends? What dependencies can be removed (if not used they should not really harm, thought but you are correct that it makes sense to remove these) and more importantly which can not be used. For instance if we can't use libstaden as packaged we have a problem. All preconditions for a Debian package have to be packaged first. Fetching something from network is not permitted at package build time.; Thus I simply tried changing the cmake options to. ```; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE ..; ```. which does not change the SEGFAULT problem. If the issue belongs to something we need to download from somewhere please let me know what looks suspicious to you. This would be helpful since we could either add it to the Debian package source in debian/missing-sources ... or rather fix the predependency that would break salmon.; Kind regards, Andreas.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464471988:107,Depend,Depends,107,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464471988,2,"['Depend', 'depend']","['Depends', 'dependencies']"
Integrability,"Hi @rudondamba,. The problem is that the sequence on line `30403` is parsed as ""empty"", since there is a space after the initial `>` and before the sequence name. This messes up the state of the underlying parser leading to the (in this case, uninformative) error message you are observing. If you fix the name online `30403`, then you should be able to index the transcriptome as expected. Let me know if this works for you. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/683#issuecomment-880059577:264,message,message,264,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/683#issuecomment-880059577,1,['message'],['message']
Integrability,"Hi @rudondamba,. There are a few options. If it's less than ~10MB, then you can just drop the file into the text box in the GitHub web interface here, and it will upload it and provide a link. If it's a few hundred MB or so, as is typical of many transcriptomes, the best thing to do might be to put it up on Google Drive or Box or Dropbox (whatever you have access to) and share a link. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/683#issuecomment-879989898:135,interface,interface,135,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/683#issuecomment-879989898,1,['interface'],['interface']
Integrability,"Hi @s1corley . As @rob-p mentions, your paper could help assess different methodologies for quantification and also help optimize salmon further for QuantSeq. I would still like you to check if you have used salmon quant command line correctly for QuantSeq data analysis. Your paper briefly alludes to QuantSeq Forward in the Introduction section of the paper; >The QuantSeq Forward kit has an oligo (dT) primer which contains the Illumina-specific Read 2 linker ... but the Methods section of your paper does not specify if you have used QuantSeq FWD or REV. Page 14 of the PDF from the [Lexogen Website data analysis pipeline for QuantSeq FWD](https://www.bluebee.com/wp-content/uploads/2018/11/015UG108V0201-QuantSeq-Data-Analysis-Pipeline_2018-10-18.pdf) recommends using the below htseq command line. ```; htseq-count -m intersection-nonempty -s yes -f bam -r pos $bam; $resource_dir/annotation.gtf > $bam_dir/read_counts.txt; ```; > QuantSeq is a stranded protocol. For the QuantSeq FWD pipeline the argument -s yes indicates; > stranded in the sense orientation. For the QuantSeq REV pipeline -s reverse is used. Similar to the above htseq command line arguments, I think if you are using QuantSeq FWD, the` libType argument from salmon quant should have been SF` . One way I checked these with my datasets was to run the salmon quant command 3 times - once with `libType A`, once with` libType SF` and once with `libType SR` -- with QuantSeq FWD the estimated counts will be almost same with libType A and libType SF. I echo what @rob-p says - Congratulations once again on the paper.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565653150:962,protocol,protocol,962,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565653150,1,['protocol'],['protocol']
Integrability,Hi @s1corley . Thanks for your inputs and thanks for taking the time to respond here. You mention you attached the Salmon meta_info output - I guess the attachment did Not come through. @k3yavi @rob-p - any ideas why the attachment did not make it . Yes - I am surprised with the results using the SR salmon quant option with the QuantSeq FWD protocol.; >I was advised that a FWD library was used - this is a bit confusing given the success of running the SR option. @rob-p What should be the libType option one should set with the QuantSeq FWD protocol - I have explained above why the SF option would be appropriate one (based on what Lexogen recommends for use with htseq-count for QuantSeq FWD),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565686395:343,protocol,protocol,343,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565686395,2,['protocol'],['protocol']
Integrability,"Hi @s1corley,. Congratulations on your publication! The `--noLengthCorrection` flag has been around for a long time (e.g. where it is suggested in the post to which @tamuanand [links](https://groups.google.com/forum/#!msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ)). However, given our limited access to QuantSeq and our limited (student) bandwidth to do extensive testing on alternative tech, we have kept this flag marked as experimental. As I mention above, it was introduced since, _conceptually_, the QuantSeq protocol should not exhibit a length effect and so the one may not wish to account for the length when determining assignment probabilities during the variational Bayesian optimization. However, the empirical testing of this has been limited. Now that your paper is published, and contains what look to be some _very through_ assessment methodologies, we may be able to look into this and determine if there is anything we can do to, perhaps, optimize salmon even more for accurate quantification from the QuantSeq protocol. We would welcome any suggestions or feedback you may have. Congratulations again on the paper!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848:513,protocol,protocol,513,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848,2,['protocol'],['protocol']
Integrability,"Hi @satta,. Thanks for bringing this to my attention. I am of two minds on this proposal. On one hand, I agree that it is cleaner, in theory, to have a RapMap shared library to which Salmon could simply link. Currently, Salmon pulls in the relevant portions of the RapMap code to call what is essentially an ill-defined public API for mapping. On the other hand, I have two concerns about separating the code at this point, one is major the other minor. The major concern is that both Salmon and RapMap are still very much under active development, core code and even the interfaces are undergoing reasonably rapid changes (thus the versioning < 1.0). This allows me to easily add features that may potentially benefit Salmon to the RapMap codebase, and then to synchronize Salmon releases with particular commits (tags) in the RapMap codebase. The current build system makes it very easy to pull in the appropriately versioned RapMap code. On the other hand, I have very little experience in properly versioning shared libraries so I would have to understand that better and how this could be done without complicating the build process. My _minor_ concern is that I don't know what effect, if any, separating the code into a separate shared library might have on compiler optimizations. Right now, since the relevant RapMap code is compiled alongside Salmon and they are linked together into the same module, certain optimizations may be possible that would not be so when linking to a shared library. My educated guess is that the effect of such optimizations would be negligible, but it's something that may be worth some exploration first. Overall, I'm very open to this idea, but I think I need to do some homework on it before we can commit and undertake the change.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/87#issuecomment-246027704:572,interface,interfaces,572,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/87#issuecomment-246027704,2,"['interface', 'synchroniz']","['interfaces', 'synchronize']"
Integrability,"Hi @seanken,. Thank you for reporting this. I agree this error message should always show up. My guess is that this is related to the fact that the error is reported through the asynchronous logger, which is notoriously picky about how it must be torn down to avoid dropping messages on atypical (non-zero) program exit. I'll see if I can make this one show up reliably. By the way, do you have a small pair of FASTQ files that will trigger this error?. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/736#issuecomment-1018119606:63,message,message,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/736#issuecomment-1018119606,2,['message'],"['message', 'messages']"
Integrability,"Hi @shanmugavadivelps,. This is because, to properly find and link libiconv, the build requires a version of CMake that ships with FindIConv.cmake. So, to build salmon from source, you should have at least CMake version 3.12. Internally and on our continuous integration servers, we use version 3.15. . Also, I'll mention that it may not be essential to build from source. Salmon is available via Bioconda, and a docker image is available via DockerHub. Also, we have a pre-compiled binary that should work on many linux distributions available under our [releases](https://github.com/COMBINE-lab/salmon/releases).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557149581:259,integrat,integration,259,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557149581,1,['integrat'],['integration']
Integrability,"Hi @sudeep71,. Can you upload the JSON files in your index directory? The problem seems to be that fields that are expected to exist in the index are missing. Since you built Salmon from source yourself, if you built it in the same directory as a previous version, did you run `cmake ..` first? Since the newest version depends on upstream changes in RapMap, those external dependences need to be re-fetched. In fact, I'd suggest that you remove (or move) the entire build directory, and then make a new one to start the build process from scratch. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/135#issuecomment-299870076:320,depend,depends,320,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/135#issuecomment-299870076,2,['depend'],"['dependences', 'depends']"
Integrability,"Hi @summerrfair ,. I can't see anything obviously wrong with the command line. Do you have a small example of the transcripts.fa and myseq.bam file you could share? The message indicates that salmon thinks its running in mapping-based mode (with input fastq files), but you are clearly running in alignment based mode. Is the behavior any different if you put the -a argument first?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-616870047:169,message,message,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-616870047,1,['message'],['message']
Integrability,"Hi @tamuanand ,; Thanks for raising this doubt. SA is already integrated into the salmon environment i.e. you just have to re index salmon using the `generateDecoyTranscriptome.sh` script from [here](https://github.com/COMBINE-lab/SalmonTools) and run salmon quant as you usually do w/ the `--validateMappings` additional command line flag.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499297622:62,integrat,integrated,62,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499297622,1,['integrat'],['integrated']
Integrability,"Hi @tamuanand,. Sure; is there anything specific about bbduk and bbmap for quality / adapter trimming that you think would be provided beyond or in addition to what fastp provides? Also, we have a beta implementation of soft-clipping and are looking for a wide net of testing data. Any suggestions to that end would be welcome!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597344801:85,adapter,adapter,85,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597344801,1,['adapter'],['adapter']
Integrability,"Hi @tamuanand,. Thank you for the detailed questions! Let me elaborate a bit on a few of @k3yavi's answers. 1&2) Yes; if you want to use SAF, you no longer need mashmap, as what you are essentially doing is treating the entire genome as a ""decoy"". As @k3yavi alludes, SA is still useful when you need to run in a very memory-constrained environment. After adopting the new [pufferfish-based](https://github.com/COMBINE-lab/pufferfish/tree/develop) index, the size of the transcriptome plush mashmap 2 decoys becomes considerably smaller than the previous size of the transcriptome in earlier versions of salmon (<= 0.15.0). However, depending on the organism, indexing the entire genome as decoy, even though it yields the best accuracy, does require a bit more memory, as specified in the release notes for the 0.99 betas and 1.0.0. 3) Yes; it is still possible to use `salmon index` without any decoy sequence. In this case, one can expect results similar to if you had aligned to the target transcriptome using Bowtie2. In this case, you perform indexing by simply not providing any `--decoy` flag to the `index` command. In that case, all of the records in the target fasta will be treated as valid and quantifiable targets. Of course, for reasons detailed in the pre-print --- the high _sensitivity_ of both Bowtie2 and selective-alignment --- we recommend including either mashmap-derived decoys or the organism's genome as a decoy whenever possible. . 4) Related to @k3yavi's response and my elaboration above: we have dropped quasi-mapping from 1.0.0 (though something akin to it may return in the future if there is sufficient demand and if the shortcomings described in the manuscript can be overcome). However, as I mention in part 3 above, this doesn't mean it's not possible to use v1.0.0 without an explicit decoy sequence. The `--decoy` flag of the indexing command is optional, not required. We will update this in the documentation making it more explicit. However, as @k3yavi points ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390:633,depend,depending,633,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390,1,['depend'],['depending']
Integrability,"Hi @tamuanand,. Thanks again for your detailed questions and thoughts on this issue. Just to follow-up / expand a bit on what @k3yavi has said (and to answer your other question): Yes, one would imagine that, given the details of the QuantSeq protocol, turning off length correction would make the most sense. The main reason this flag is listed as _experimental_, is simply that it was designed based on the expected characteristics of the protocol. Conceptually, the protocol is performing tagged-end sequencing, and so there should be little-to-no length effect. However, since we haven't done extensive internal validation on QuantSeq data, we have left this flag as experimental until it is further tested by ourselves or others. > Also @rob-p , weren't you referring to the RSEM caveat with QuantSeq data analysis wherein one cannot ask RSEM to disable lengthCorrection and hence the count statistics might be misleading?. Correct; as far as we are aware, there is no way to disable the built-in length-dependent assumptions of RSEM. One could use the `--estimate-rspd` flag to allow learning of a non-uniform read distribution (the equivalent of `--posBias` in salmon), though it's unclear / unlikely if this would be as effective as fully disabling the length correction for this type of tagged-end data. If you have any good empirical assessment mechanism for QuantSeq data, and a chance to test out these different salmon options, we'd be happy to get feedback and discuss details further!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540:243,protocol,protocol,243,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540,4,"['depend', 'protocol']","['dependent', 'protocol']"
Integrability,"Hi @thu1911,. The strand bias here is actually quite moderate. The calibration of `strand_bias` is such that a value of 0.5 means there is no bias (i.e. half of the fragments start with read 1 on the forward strand and half start with read 1 on the reverse complement strand). Your value is `""strand_mapping_bias"": 0.5258466052704426`, so you are pretty close to the ideal value of 0.5, though there is a _slight_ bias in the data. I wouldn't be concerned about this assuming you were assuming an unstranded protocol. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/422#issuecomment-524643119:508,protocol,protocol,508,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/422#issuecomment-524643119,1,['protocol'],['protocol']
Integrability,"Hi @tillea and @nileshpatra,. Ok, I dug deeper and found out what's going on. The culprit is, in fact, `libcereal`. The problem is that `libcereal` bumped patch versions only since the version corresponding to the headers included in `pufferfish`, but their changes are not, in fact, backwards compatible! This lead to a version mismatch between the headers used in `pufferfish` and the headers found from the installed package, ultimately resulting in an assertion failure in `rapidjson` (which cereal is using) and a segfault. On the plus side, this was relatively easy to fix by bumping the included cereal headers in pufferfish. I also updated the `Findcereal.cmake` module and added a version constraint so that we now require the new version (1.3.2). This is now tagged and released as `salmon 1.10.1`. Please give that a go when you have a chance. I'll note that, before this is added upstream in debian, I'd still advocate for fixing the `libstaden` package to update to the new version. I'd also recommend moving to dependencies like the ones I've included above to remove some really antiquated dependencies that salmon no longer requires but are still being pulled in. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1465096711:1025,depend,dependencies,1025,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1465096711,2,['depend'],['dependencies']
Integrability,"Hi @tillea,. It seems this is exactly the problem. The build deps here are not quite correct. There are dependencies that salmon no longer has, and some of the dependencies it does have are out of date and can't be used from upstream (e.g. libstaden in the latest version, among others). On the bright side, it's not the dynamic linking alone that is problematic. The following works fine on my end:. ```{bash}; $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt-get update; $ apt-get upgrade; $ apt-get install build-essential git libboost-all-dev liblzma-dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev libtbb-dev libtbb12 liblzma-dev libjemalloc2 pkg-config libgff-dev; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ mkdir build && cd build; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE ..; $ make -j8; $ make install; $ make test; ```. This is preferring dynamic linking, and the resulting installed executable runs fine without a segfault. Can you try this on your end? Then the thing to do may be to find what is discordant between the packages I install above and what gets pulled in by `apt build-dep salmon`. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464182279:104,depend,dependencies,104,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464182279,2,['depend'],['dependencies']
Integrability,"Hi @tillea,. So I went through the list of deps pulled in by `apt build-dep salmon` and the minimal set I gave above. I tried to make the smallest number of changes I could to the `apt build-dep salmon` list while also removing things that are clearly outdated (we no longer use jellyfish, rapmap, etc. and we use the header-only version of spdlog). As a result I came up with this list of dependencies. The offending dependency seems to be `libcereal-dev`. Specifically, I was able to install just this list of dependencies (minus `libcereal-dev`) atop a clean `debian:testing` and get a working version where the only thing downloaded from the internet was the appropriate version of the pufferfish files grabbed by `fetchPufferfish.sh` in the `1.10.0` release. Once I installed `libcereal-dev` with `apt-get install`, and rebuilt, then I got the segfault mentioned at the top of this issue. So, it seems that we either have to let `salmon` build it's own libcereal, or figure out what the problem is with the library upstream. Please let me know if this you observe this same behavior as well (also @nileshpatra may want to try this out). If so, perhaps we can get `libstaden` updated upstream, and then use this as the new dep list for `salmon`. I installed these deps with a simple `xargs apt-get install -y < deps_sorted_updated.txt` (without `libcereal-dev` for the working version, and with it included, as below, for the segfault). Best,; Rob. [deps_sorted_updated.txt](https://github.com/COMBINE-lab/salmon/files/10949233/deps_sorted_updated.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464986376:390,depend,dependencies,390,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464986376,3,['depend'],"['dependencies', 'dependency']"
Integrability,"Hi @tmms1 ,. > I think that each such line corresponds to an equivalence class (EC). The first entry on each row is the number of transcripts in the EC. This is followed by the transcripts (more correctly, indices you can use to obtain the transcripts). Then you have the number of reads with in the EC, followed by the number of barcodes (~cells). For each barcode, you have an index that can be used to retrieve the identity of the barcode, followed by the number of UMIs within that barcode, the sequence of the UMI and lastly the number of reads associated with that UMI. This is correct !. Unfortunately you goal is not very clear to me and the output matrix depends on that. I understand that you wan't a matrix of dimension |eq_class X cells| but if you wan't the values in the matrix to be read count then you have to add the counts of all the UMIs in class across the cells; and if you wan't the values in the matrix to be the frequency of the unique UMIs then just count the UMIs you wan't instead of reads.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1029328067:664,depend,depends,664,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1029328067,1,['depend'],['depends']
Integrability,"Hi @tomsing1 ,; Apologies for the slow response, I was out of country for a while. Thanks for your kind words and starting a very interesting suggestion.; It’s fascinating to see, how methods being used in single-cell RNA-seq is coming full circle back to the bulk RNA-seq experiments. We have to do some more digging to say clearly about the caveats of using Alevin with the mentioned 3’ bulk RNA-seq experiments but given the understanding from the picture of the shared image we don’t see any obvious show stoppers; although below mentioned concerns should be kept in mind while using Alevin for bulk data deduplication:. Alevin solves the problem pretty well for protocols where fragmentation of the cDNA molecule happens post PCR amplification. There might be some concerns about over-deduplication of the UMI if fragmenation happens before amplification. Although in current form, Illumina sample index can be given as an external whitelist to Alevin but user should be aware that Alevin performs a sequence correction step before starting any optimizations.; Alevin is designed for droplets based protocols, where one end of Paired end read is just the CB/UMI (i.e. no read sequence) and therefore Alevin can’t optimally use the full paired end information of the bulk 3' protocol if its both end has read-sequence for example the ambiguous mapping resolution based on a previously/empirically known approximate fragment length. We would be more than happy to help/discuss, how does the results look in bulk 3’ tagged protocols or if you have particular suggestions about what improvements can be done in Alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/306#issuecomment-439530193:667,protocol,protocols,667,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/306#issuecomment-439530193,4,['protocol'],"['protocol', 'protocols']"
Integrability,"Hi @uros-sipetic!. Unfortunately, as you suggest, there really is no good way to infer the fragment length distribution from only single-end reads. Rather, this flag determines how the conditional probability of single-end fragments near the beginning (if in the rc orientation) or end (if in the forward orientation) of the transcript are determined. A single-end read does not have any known fragment length. But we do know that e.g. fragments very close to the end or beginning of the transcript are rather unlikely. In this case, we can integrate (sum) over all possibilities to assign a conditional probability. This is what salmon does. For a single-end read (assume forward orientation for simplicity) at position i on a transcript of length n, we consider the conditional fragment length probability to be given by F_n(n-i), where f_n is the conditional fragment length distribution conditioned on the transcript length (maximum observable length) being n and F_n is the cumulative distribution function of f_n. Intuitively, this means that fragments very close to transcript ends will get a smaller conditional probability, while those farther from the end will get larger conditional probabilities. The `--noSingleFragProb` flag simply turns off this conditional probability all together. It is _not_ recommended to disable the single-end fragment length probability modeling. We have evidence from testing that it improves quantification accuracy. Thus, I would suggest _not_ setting the `--noSingleFragProb` flag. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/575#issuecomment-711061553:541,integrat,integrate,541,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/575#issuecomment-711061553,1,['integrat'],['integrate']
Integrability,"Hi @uros-sipetic,. RSEM _does not_ collapse duplicates. This means that it will return quantification estimates for all of the sequence identical transcripts separately. A common scenario may be that it will split the abundances evenly, but this may not always be the case, depending on e.g. the initialization of the EM algorithm etc. The easiest way to try and compare the estimates as closely as possible would probably be to use the `duplicate_clusters.tsv` file produced by salmon to explicitly collapse (add up) the abundances of the duplicate transcripts from the RSEM quantifications before comparing. As always, we'd be interested to hear if you find anything interesting!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/255#issuecomment-628760746:274,depend,depending,274,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/255#issuecomment-628760746,1,['depend'],['depending']
Integrability,"Hi @uveksamoosmeh,. Can you explain a bit your usecase? The `--features` option is designed for indexing short features for specific single-cell protocols (e.g. HTO tags etc.). If you are trying to index a standard transcriptome, this is not the purpose of this option. Rather, for that you should pass the transcriptome `FASTA` file as the input to the regular `salmon index` command. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/865#issuecomment-1664415328:145,protocol,protocols,145,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/865#issuecomment-1664415328,1,['protocol'],['protocols']
Integrability,"Hi @vertesy ,. Thanks for asking the very interesting question.; I'd say the answer might depend on what's your downstream use case. Traditionally, no quantification pipeline, in my knowledge, has used the pre-mRNA counts alone to bump up the gene counts, however, recent method of estimating RNA-velocity does utilizes the intronic counts for extracting the ratio of spliced/unspliced counts. If you are interested in disjoint signals (gene count matrix) for spliced and unspliced molecules you can use the recent scheme of decoy indexing from our latest [preprint](https://www.biorxiv.org/content/10.1101/657874v2). We (mostly @csoneson) have been testing alevin with following scheme for generating spliced and unspliced counts. 1.) Spliced Counts: Index transcriptome w/ pre-mRNA sequence as the decoys.; 2) Unspliced Counts: Index pre-mRNA sequence w/ transcriptome as the decoys. The third case is a little tricky because if you index both pre-mRNA and transcriptome, due to relatively longer length of pre-mRNA sequence compared to transcripts it might end-up biasing the UMI deduplication algorithm towards unspliced counts. To summarize, the best way to have an additive spliced and unspliced counts is still an open area of research.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/450#issuecomment-555136444:90,depend,depend,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/450#issuecomment-555136444,1,['depend'],['depend']
Integrability,"Hi @wdecoster,. Thanks for reporting this. One restriction that needs to be better documented (actually, I have to make sure it is properly documented at all!) is that the library type should come _before_ the reads they describe. That is, you should consider passing `-l SF -r {}` rather than `-r {} -l SF`. The reason for this is that the `-r` and `-1,-2` parameters are repeatable so you could, conceivably, pass multiple reads of different library types. However, this is a feature that nobody uses and frankly doesn't make too much sense (so I'll consider removing it in the future to simplify library type parsing). For the time being, I'll also consider printing a warning message when a read file is encountered without an explicitly pre-defined library type (in that case, the behavior, as you saw, is to assume an unstranded library). Could you let me know if passing `-l` before `-r` resolves the issue for you. As to your other suggestion. The internal capitalization rules follow those for camel-case naming of variables (as opposed to separating words with`_`). However, I realize this is somewhat esoteric and even among those who are familiar with such conventions, an arbitrary preference. I'll look into aliasing this flag (and maybe others) to be usable with different names as well. I just have to check how to do this (and if it is possible) with boost's program options.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/177#issuecomment-347524360:680,message,message,680,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/177#issuecomment-347524360,1,['message'],['message']
Integrability,"Hi Amy,. Unfortunately, when you reply to github via e-mail, it doesn't include attachments. Could you please either upload the files here (the github web interface supports drag-and-drop), or just send me an email. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/96#issuecomment-250982842:155,interface,interface,155,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/96#issuecomment-250982842,1,['interface'],['interface']
Integrability,"Hi Andrea,. The bias correction time depends on the number of expressed transcripts. There is a flag to speed it up `--biasSpeedSamp`. It takes a value by which to downsample the fragment length pmf for bias modeling. The larger this number, the faster bias correction will become. The default is 1, and is super conservative (we are probably going to make the default 5 in the next release because it is much faster with no real difference in modeling quality). In fact, values up to at least 10 seem to work quite well with respect to the baseline. So, I'd recommend testing this parameter on a sample until you are happy with the speed, and then using that on all samples. Let me know how it goes, and if my description makes sense. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/201#issuecomment-369766969:37,depend,depends,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/201#issuecomment-369766969,1,['depend'],['depends']
Integrability,"Hi Andreas,. So I don't know if there is a easy way to get the specific list of reverse dependencies, but then we can cross-check it with my explicit list above:. ```; build-essential; git ; libboost-all-dev ; liblzma-dev ; libbz2-dev ; cmake ; zlib1g-dev ; curl ; unzip ; wget ; libcurl4-openssl-dev ; libtbb-dev ; libtbb12 ; liblzma-dev ; libjemalloc2 ; pkg-config ; libgff-dev; ```. One thing I noticed during build is that, while I included `libjemalloc2` here, the salmon build procedure still downloaded and built `jemalloc`. However, I don't _think_ jemalloc is the thing causing the segfault. Regarding dependencies that can't be used — the current `libstaden` is behind the upstream release. The upstream release contains an important bug fix for a bug (and suggested fix that we proposed to the developer) upon which we rely. More importantly, afaik there is no relevant `libpufferfish-dev` package (we certainly have not made one), and so there is not even e.g. a check in the `CMakeLists.txt` file. Salmon's build always tries to run `fetchPufferfish.sh` to download the relevant `pufferfish` source files needed to build `salmon`. Critically, the relevant `pufferfish` dependencies and `salmon` releases move in lockstep. Each new `salmon` release it accompanied by a new tag in the `pufferfish` repo (so that the specific source used to build a given `salmon` release is fixed and easily trackable). So, I think the easiest way to move forward is to:. * do a diff of my list of packages above with what is pulled in by `apt build-dep salmon`. * figure out why, even when `libjemalloc2` is installed, the build system tries to build `jemalloc` itself (maybe we need the dev package?). * determine what folks want to do upstream about the lockstep pufferfish dependency. Right now, the `fetchPufferfish.sh` script pulls a tagged tarball from github and checks that the sha matches, and moves the relevant source files into place. This is true both when we build our own releases as well as",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464538233:88,depend,dependencies,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464538233,2,['depend'],['dependencies']
Integrability,"Hi Assa,. The problem is that you've not provided the input files via the appropriate `-1` and `-2` flags. For your particular command, the command line should look like . ``` bash; $ salmon quant -p 16 --biasCorrect --libType IU -1 <(zcat ${base}_1.fastq.gz ) -2 <(zcat ${base}_2.fastq.gz) -i ~./Salmon/Salmon.index/Homo_sapiens.GRCh38.rel79/ --numBootstraps 100 -o $base ; ```. Notice this looks almost the same as what you had before, except that the reads are prefixed by the relevant `-1` and `-2` flags, and come directly after the library type flags. Please let me know if this fixes the issue for you. I'll add a more informative message in such a situation.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/65#issuecomment-231729597:638,message,message,638,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/65#issuecomment-231729597,1,['message'],['message']
Integrability,"Hi Carlos,. This is quite interesting, and I have a few hypotheses. My first hypothesis is that the difference could be arising from differences in the annotation --- for salmon you are using reference cdna, and for STAR+RSEM you are mapping against the genome with, presumably, some gtf file used for annotation (I believe that what RSEM does internally is to run STAR with the proper flags to ""project"" mapped reads onto the transcriptome). Are these transcriptomes equivalent? For example, are there differences in annotated rRNAs, which can make a big difference depending on the prep protocol. The other question is the difference in the total assigned number of reads. What do you get when you add up the `NumReads` column from salmon versus the `expected_count` column from RSEM --- there could be some difference in terms of reads mapped to the genome but not properly annotated and, therefore, not contributing to quantification. Finally, you can always pass the BAM file generated by STAR+RSEM to salmon (in alignment mode) to see how that affects the total number of mapped reads. Though there is always the possibility that something unforeseen is causing these differences, they usually seem to wind up being due to something mundane but non-obvious. Here, slight differences in the annotation --- particularly the inclusion or not of rRNA and other RNA species --- would be my first guess.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/212#issuecomment-378954000:567,depend,depending,567,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/212#issuecomment-378954000,2,"['depend', 'protocol']","['depending', 'protocol']"
Integrability,"Hi Dan,. Can you share an example of a dataset where you encounter this? It's a pretty generic message, and I'm not actually certain where it's coming from without some more context. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779409595:95,message,message,95,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779409595,1,['message'],['message']
Integrability,"Hi Gert,. Indeed, the CMake build uses `curl` for downloading relevant dependencies. Presumably, it would be possible to have a fallback to `wget` if `curl` is not available. I will look into the best way to do this. In the meantime, you should be able to use the pre-compiled binary for linux (x86-64) or install Salmon via [bioconda](https://anaconda.org/bioconda/salmon). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-354673470:71,depend,dependencies,71,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-354673470,1,['depend'],['dependencies']
Integrability,"Hi Holley,. Thanks for the response: Here are some followup thoughts . >It's strange that once all three have been compiled into a single assembly using Evigene, salmon detects the ISR library type. When I change the ""A"" to ""ISR"" or ""IU"", the % mapped changes a lot. That does seem strange, but I honestly don't know much about `Evigene` or what it's doing in combining these assemblies. When you specify ""IU"", the mappings will generally be _more_ lenient (i.e. you'd expect to get more mappings) than when you specify ""ISR"". The ""A"" flag just looks at how the first 10,000 reads map and guesses the library type based on that. On thing to make sure of is that your reads aren't ""ordered"" in any way, such that you'd expect the first 10,000 to deviate in any meaningful way from the statistics of the reads of the reads. > Is it better to build assemblies with strand-aware flags? If so, does it usually make a large difference to quantification results, or a minor one? I don't know what protocol the sequencing facility used, but I am sure I could ask them. I gather from my recent reading that the extra information gained by using a stranded protocol is worthwhile, so I would expect that the sequencing facility used one, but why doesn't Trinity or MEGAHIT detect the sequecing protocol that was used? . So there are really 2 questions here. *If* the data are stranded, then yes, it's worthwhile to use stranded flags in both assembly and quantification. This is because stranded protocols will allow you to better disambiguate (a) overlapping genes and (b) reads that are ambiguous between sequence-similar genes that happen to reside on different strands. The *second* question is why Trinity or MEGAHIT wouldn't detect this. The main reason for this is that these are assembly tools. Without access to a reference genome, there is no principled way for these tools to know what the orientation of a read is _a priori_, so they generally rely on the user to specify if the reads are stranded o",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427:990,protocol,protocol,990,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/840#issuecomment-1493034427,1,['protocol'],['protocol']
Integrability,"Hi Mike,. Glad to hear this fixes it. I pushed a commit that does the check, prints out a useful error message (that suggests how you can make a compatible transcriptome fasta) and then bails. Regarding the `libParams` directory --- that is actually a somewhat anachronistic directory anyway. Currently, I've been moving all of the parameters into their own (gzipped) files in the `aux_info` directory. I've kept `libParams` there for backward compatibility sake, but I think it's confusing if the fld appears in multiple places, but the other parameters appear somewhere else, so perhaps it's time to remove it (and note such in the next version's release notes).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-267610178:103,message,message,103,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-267610178,1,['message'],['message']
Integrability,"Hi Mohsen and Rob,. So sorry if you've already been troubleshooting the example data I gave you. I realized that that is not a good example of the problem. In this example, there are snR40 and snR40_genomic transcripts, representing processed and pre-processed isoforms. However, it just so happens that there is residual adapter on some of the reads I provided and the first nucleotide of the adapter sequence actually matches the first nucleotide of the longer, genomic version of this transcript, therefore, the genomic variant gets a slightly better alignment score, as it should. After hard trimming any residual adapter the results for this transcript were a lot better (although still not quite the ratio I would expect). I have quite a few examples like this and I'm fairly sure they are not *all* explained by alignment of adapter sequences. However, I just wanted to let you know in case you were already troubleshooting my example data. I'm aggregating a handful more general examples of the same problem, but ones without a trivial solution like the one I provided. The files are too large to attach on github directly, though, do you have a preferred way to share the files? Maybe a google drive?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-642954815:322,adapter,adapter,322,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-642954815,4,['adapter'],['adapter']
Integrability,"Hi Paul,. Did you reply to the github issue via e-mail and attach it there? In that case, it won't show up. If you post a response via the github interface, you can just drag and drop the file into the text box to have it uploaded.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-442575438:146,interface,interface,146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/323#issuecomment-442575438,1,['interface'],['interface']
Integrability,"Hi Rachel,. So it looks like `output/hs.grch39.index/versionInfo.json` doesn't exist here? Are there any other messages that show up during indexing? Also, v0.8.1 is very outdated at this point. It might be worth checking if this issue is still popping up if you grab the latest version (available both as a linux binary from the releases page, as well as via bioconda).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467194457:111,message,messages,111,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467194457,1,['message'],['messages']
Integrability,"Hi Rich,. The issue with pre-compiled OSX binaries is that they are difficult to make portable across OSX versions. This is why we strongly suggest installing Salmon (especially for OSX) through [Bioconda](https://bioconda.github.io/). This greatly eases installation and updating, and doesn't require admin privileges. On OSX, you can try the following:. ```; $ conda config --add channels conda-forge; $ conda config --add channels bioconda; $ conda create -n salmon salmon=0.9.1; ```. This should take care of all relevant dependencies as well as e.g. library locations and placement. Could you please give this a try and let me know if it works for you?. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-381997508:526,depend,dependencies,526,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-381997508,1,['depend'],['dependencies']
Integrability,"Hi Rob & Team, . First and foremost, my thanks for developing such a great and versatile tool, very grateful for your work. . I'm hoping for some words of wisdom. We've got some data from Lexogen CORALL libraries (parired end + UMI). One of the main benefits in using this kit, is the lack of fragmentation step, instead there is Displacement Stop Primers (DSP) which are theoretically randomly distributed. . One approach we've taken is to trim adapters, and collapse UMIs (from STAR alignment). Following these steps, we've got theoretically clean data, so using `samtools fastq` to make a Salmon-friendly input. We observed a very unusual fragment length distribution with this, it looks largely poisson. I've rationalised this as the fragments being particularly short after UMI + Adaptor trimming, and given the random nature of DSPs, this could make some sense. One thing that stuck out in my mind was ordering of the reads (which were coord sorted), thus they'd be coming into salmon that way, breaking an assumption of the streaming EM algorithm. . We're currently name sorting the reads prior to Salmon quantification, but I wonder if you could explain if this unusual FLD could be a consequence of position sorted fastq, or any other thoughts you have around this situation? The good news is that ultimately, the same high level biology comes out of the quantifications whichever way do it. . Thanks for any insight. Andrew",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/765:446,adapter,adapters,446,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/765,1,['adapter'],['adapters']
Integrability,"Hi Rob, . For example, here is the log output when I try to index the GENCODE Human transcript set v36, using the below code;. salmon index --keepDuplicates -k 35 --gencode -t gencode.v36.transcripts.fa -i Human_v36_Index_k35. Here is where the phrase is found in the log, and is then repeated a lot until the end. Number of ones: 1309432; Number of ones per inventory item: 512; Inventory entries filled: 2558; 1309432; [2021-02-15 04:42:27.548] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2021-02-15 04:42:27.565] [puff::index::jointLog] [info] contig count for validation: 1,309,432; [2021-02-15 04:42:28.338] [puff::index::jointLog] [info] Total # of Contigs : 1,309,432; [2021-02-15 04:42:28.339] [puff::index::jointLog] [info] Total # of numerical Contigs : 1,309,432; [2021-02-15 04:42:28.404] [puff::index::jointLog] [info] Total # of contig vec entries: 7,119,643; [2021-02-15 04:42:28.404] [puff::index::jointLog] [info] bits per offset entry 23; [2021-02-15 04:42:28.590] [puff::index::jointLog] [info] Done constructing the contig vector. 1309433; [2021-02-15 04:42:29.459] [puff::index::jointLog] [info] # segments = 1,309,432; [2021-02-15 04:42:29.459] [puff::index::jointLog] [info] total length = 188,284,293; [2021-02-15 04:42:29.548] [puff::index::jointLog] [info] Reading the reference files ...; [2021-02-15 04:42:31.594] [puff::index::jointLog] [info] positional integer width = 28; [2021-02-15 04:42:31.594] [puff::index::jointLog] [info] seqSize = 188,284,293; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] rankSize = 188,284,293; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] edgeVecSize = 0; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] num keys = 143,763,605; len should not be greater than 64.; ...; ...; ...; len should not be greater than 64.; [2021-02-15 05:07:13.459] [puff::index::jointLog] [info] finished populating pos vector; [2021-02-15 05:07:13.460] [puff::index::jointLog] [info] wr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779416548:483,wrap,wrapping,483,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779416548,1,['wrap'],['wrapping']
Integrability,"Hi Rob, After posting yesterdays message, I generated the vM23 index, and the alignments/quants worked. I had to use mem_free=34G for building index. Is that expected?; I will try building the vM25 index again and and post the update.; In the meantime, sha256sum of my vM25 index that I had generated has some mismatches from the one you created. Below is my sha256sum on vM25 index:; `306e9d98b3460859f579059bf876aa3b6e264c8f38c04cde332b03632edc6dfb complete_ref_lens.bin; 636b3df7e097d58fa846bd85ce650ce5bf72c66dc5b2d7566fc9e3db087c5c9c ctable.bin; 1c7501deaa4524f4700152713228cb03949775dce481384eac67bb45458508be ctg_offsets.bin; dbc575fed0d589b4671c26bd8cbcb4b3d52ef41c299a90de978ab940abb751fc duplicate_clusters.tsv; c3ec09a30adc9d47bc95839157cb2ff66530353106a4fd8e75b167ac5db67820 info.json; 430be78bae99a4592fcedc5c800a42313f2b1252e3953f89f347779056c1ee5b mphf.bin; 2fb0b5151f9f2544c06a9f95d03075f7af0494d0fe31745504a5a7da43edc1b1 pos.bin; 15d3bb6a16bcd8c1a6814852bd3dcfa439b60ec84c706f868ee7ec2d5a90581d pre_indexing.log; 8e665e5fdee5af6fcedabc69fd04eda6e66055ef811ebde6de6f86a66521198a rank.bin; 793c79f5fd6046dfea07bbc9587d2835088e54c78197d652d1b1f205c6b16983 refAccumLengths.bin; c5ea8eccca3fdc299ad7c9d2f07a4ed14c8c830940e83c315e7eaad6905a40aa ref_indexing.log; b580b9c6257254a018a9ae22291a64892c1a3715c69272637f5c504fc5545a70 reflengths.bin; 89679603ac0b28042275e5ff04b222bad3fd431cab573f0c2b61e7455aec43e7 refseq.bin; 46bf28001e00d491b68bf8758b99c1f304523c79bd94a97d7797888856594e84 seq.bin; 4c7e56ba28383774e786826099ef412761326fe18ce69f29033ad2886542985d versionInfo.json; `; Following are different.; `ctable.bin; info.json; mphf.bin; pos.bin; pre_indexing.log; ref_indexing.log; seq.bin; versionInfo.json`. I will try creating the vM25 index with increased memory. Wonder if its not building. Just FYI, my sha256sum on vM23 index is:; `9788716f4ce42b049fe7e865108f45392bb8a5847cfcd47369512783dc918239 complete_ref_lens.bin; 9c2453a47ce1808f54733f049b8c4cf38634c9116eb55ed725b73219caa",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480:33,message,message,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480,1,['message'],['message']
Integrability,"Hi Rob,. I did some follow up using your suggestions, and I had indexed my; transcriptome incorrectly, but now it appears that I am having a separate; issue and was hoping that you might be able to point me in the right; direction? Here is my command:. ```#!/bin/bash -l; #SBATCH -J male_salmon_map; #SBATCH -t 150:00:00; #SBATCH -p high; #SBATCH --cpus-per-task=24; source ~/.bashrc; source activate salmon; cd /home/seboles/abaloneraw/salmon_quantification/SALMON_MALE/; for i in *.qc.fq.gz; do; salmon quant -i maleredabalone_index --libType IU -1 *R1_001.qc.fq.gz -2; *R2_001.qc.fq.gz ${i} -o ${i}_quant --seqBias --gcBias --validateMappings; done```. And here is the error message that I receive:. ```[2019-07-29 14:31:12.352] [jointLog] [error] You passed paired-end files; to salmon, but you passed 12 files to --mates1 and 13 files to --mates2.; You must pass the same number of files to both flags; Name : male_salmon_map; User : seboles; Partition : high; Nodes : c11-71; Cores : 24; GPUs : 0; State : FAILED; Submit : 2019-07-29T14:31:01; Start : 2019-07-29T14:31:02; End : 2019-07-29T14:31:13; Reserved walltime : 6-06:00:00; Used walltime : 00:00:11; Used CPU time : 00:00:09; % User (Computation): 54.66%; % System (I/O) : 45.33%; Mem reserved : 2000M/core; Max Mem used : 0.00 (c11-71); Max Disk Write : 0.00 (c11-71); Max Disk Read : 0.00 (c11-71)```. I have gone back and checked the directory containing the PE reads, and; they are all accounted for, so I am a little stumped at the moment. I; appreciate any advice you may have. Happy Monday,. Sara. On Wed, Jul 24, 2019 at 3:04 PM Rob Patro <notifications@github.com> wrote:. > Hi @seboles <https://github.com/seboles> ,; >; > My guess is that the issue is related to this (non-salmon) error appearing; > before each salmon output:; >; > basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; >; > Try 'basename --help' for more information.; >; >; > it looks like there is an error in the way the paths to the files ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516173395:678,message,message,678,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516173395,1,['message'],['message']
Integrability,"Hi Rob,. I don't have git (don't have root access on the red hat server im on). I downloaded the salmon-master.zip, and then tried running the following:. ```; [bernsteinnj@lngnode1 salmon-master]$ cmake . . -- The C compiler identification is GNU 4.4.7; -- The CXX compiler identification is GNU 4.4.7; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; CMake Error at CMakeLists.txt:69 (message):; Salmon requires g++ 4.7 or greater.; ```. I'm trying now with -k 27 with the original build I had. Keep you updated. Best",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-203018082:700,message,message,700,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-203018082,1,['message'],['message']
Integrability,"Hi Rob,. I've been running another group's samples (single-end, second-strand protocol), and I have a script that iterates through each sample and runs salmon. I'm running the latest version (0.6.0) with the following arguments: salmon quant -i salmon_index --libType SF -r <(gzip -c -d $IN_FILE) -o $OUTPUT --numBootstraps 100 --useVBOpt --useFSPD --geneMap $GENES --biasCorrect -p 59. During the EM iteration step (soon after the 500th round, when salmon recalculates effective lengths), I get this error: . ```; [jointLog] [info] iteration 500, recomputing effective lengths; [jointLog] [info] iteration = 500 | max rel diff. = 64.1299; Exception : [Error in function boost::math::digamma<long double>(long double): Evaluation of function at pole -nan]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; ```. I can't tell if this is just a regular possible occurrence with the non-deterministic algorithm or if this is never supposed to happen. These particular samples are extremely high depth (about ~170-190M reads per sample), so that might be the cause, but I don't understand enough of how the algorithm works to know how to troubleshoot or to put together a toy dataset that reproduces the error. Rerunning the sample that causes the error often works. If I can throw in a feature request here, it would be great to be able to set the seed to make the runs deterministic. Is that possible?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/48:78,protocol,protocol,78,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/48,1,['protocol'],['protocol']
Integrability,"Hi Rob,. Thank you for your swift and elaborate response! It would be most satisfying for me to compare your branch with selective-alignment to the other mappers I used. I had some dependency-issues last time I wanted to compile Salmon on my ubuntu on windows system, so a linux executable would be very welcome. Currently, we aim to only map on a limited number of microbial genomes and the abundance estimation is quite important to us. Thank you for your time!; Klaas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365534279:181,depend,dependency-issues,181,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365534279,1,['depend'],['dependency-issues']
Integrability,"Hi Rob,. Thanks for the clarity regarding the effect of insert size distribution on quantification. That does resolve this issue, and gives me a path going forward using Salmon for this data. However, I am trying to use Salmon for small RNA-Seq data, where the insert size is equal to read length for most reads after adapter trimming. Would it be possible to add a flag to use read length as a proxy for insert size, potentially with a fallback to fldMean/fldSD in the case of full-length, untrimmed reads? This is something I would be willing to contribute myself, if it sounds appropriate. Thanks,; Gautam",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-752064194:318,adapter,adapter,318,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/605#issuecomment-752064194,1,['adapter'],['adapter']
Integrability,"Hi Robb,. I'm getting the following warning message in all my runs of Salmon (0.7.2). Always the same transcript for all the libraries. The transcript reported has, indeed, no gene associated in the genemap file but it appears in the ""quant.gene.sf"" output file. I've checked with a different dataset (different species, libraries and transcriptome reference) and there's always also one transcript reported. I'm feeding Salmon with the genemap in the 2-columns format. Do you have any clue about what could be happening?. Thanks!. ```; Computing gene-level abundance estimates; There were 25081 transcripts mapping to 11607 genes; Parsed 54000 expression linesWARNING: couldn't find transcript named [v3_99998_1_1]; returning transcript as it's own gene. done; Aggregating expressions to gene level . . . done; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/98:44,message,message,44,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/98,1,['message'],['message']
Integrability,"Hi Ryan,. The difficulty is, indeed, exactly as you specify. Given a single-end read, one does not know the length of the _fragment_ from which it originates. In this case the ""right"" thing to do (the best thing we can do) is to consider the read as starting / ending a fragment of every possible length allowed by the user-provided fragment length distribution (with the contribution of each possible fragment weighted by the probability of observing a fragment of that length). In order to make this computationally feasible, one would have to do some clever pre-computation and thing a bit more about how to efficiently update the observed GC model (right now, each mapping contributes a single weight to the model, but under the naive implementation in the single-end case, each mapping would contribute different weights to each bin of the observed GC-bias curve, which would slow things down considerably). Also, as you point out, the quality of the correction would depend somewhat on the user providing appropriate parameters for the fragment length distribution mean and standard deviation — but this seems reasonable in the single-end case. That being said, I'm sure there's a way to handle this efficiently, I'd just have to think about it a bit. Regarding your second question; Salmon learns the fragment length distribution in paired-end data, but not with single-end data. Single-end data can provide a little bit of information (e.g. there is in upper bound on fragment lengths that one can infer based on single-end reads based on how far they map from the end of the transcript), but not enough information to reliably infer a fragment length distribution. cc @mikelove in case he has any thoughts on this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243833424:973,depend,depend,973,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243833424,1,['depend'],['depend']
Integrability,"Hi Ryan,. You're right. This fact is not documented and it should be. I'll update the docs to address this. Using the `A` library type with pre-computed alignments has one additional complication that doesn't arise in the quasi-mapping mode. That is, many aligners offer the user the capability of aligning the reads with a prescribed library type (e.g. TopHat, HISAT, etc.), so that in this case the implied library type depends not only on how the reads map to the underlying transcriptome, but also on the parameters with which the reads were aligned with the upstream alignment tool. . However, I don't suppose this needs to be a ""blocking"" technicality. I'll add this feature to the list for the next minor release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-241603077:422,depend,depends,422,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-241603077,1,['depend'],['depends']
Integrability,"Hi Salmon team. Are there plans afoot to support quantification of scRNA-seq data with unique molecular identifiers (UMIs)? UMIs are very commonly used in scRNA-seq data now, and correct quantification requires ""de-duplication"" of the reads so that each UMI is only counted once for expression quantification. Doing this is not entirely trivial, as a quick survey of tools available shows (e.g. [UMI-tools](https://github.com/CGATOxford/UMI-tools), [umitools](https://github.com/brwnj/umitools), [umis](https://github.com/vals/umis), [umi](https://github.com/aryeelab/umi/wiki)). . Nevertheless, it would be _very_ convenient for those Salmon fans amongst us dealing with scRNA-seq data to be able to process scRNA-seq data with UMIs directly with Salmon. Selfishly, this would be awesome for the Salmon integration with the scater package (now fully implemented). . Not to make a thing of it, but kallisto is now providing some support for UMI quantification (https://pachterlab.github.io/kallisto/singlecell.html) ;P. Best; Davis",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93:804,integrat,integration,804,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93,1,['integrat'],['integration']
Integrability,"Hi `COMBINE-lab/salmon`!. This is a one-off automatically generated pull request from LGTM.com :robot:. You might have heard that we’ve integrated LGTM’s underlying CodeQL analysis engine natively into GitHub. The result is [**GitHub code scanning**](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/about-code-scanning)!. With LGTM fully integrated into code scanning, we are focused on improving CodeQL within the native GitHub code scanning experience. In order to take advantage of current and future improvements to our analysis capabilities, we suggest you enable code scanning on your repository. Please take a look at our [blog post for more information](https://github.blog/2022-08-15-the-next-step-for-lgtm-com-github-code-scanning/). This pull request enables code scanning by adding an auto-generated [`codeql.yml` workflow file for GitHub Actions](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/setting-up-code-scanning-for-a-repository#setting-up-code-scanning-manually) to your repository — take a look! Whilst we've attempted to make use of the existing configuration that you had on LGTM.com, there may be some differences in environment used to build the project. We hope that in most cases it will not require significant changes to achieve a successful analysis. Check [this page](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#editing-a-code-scanning-workflow) for detailed documentation on how to configure a CodeQL workflow. Questions? Check out the FAQ below!. ### FAQ; <details>; <summary>Click here to expand the FAQ section</summary>. #### How often will the code scanning analysis run?; By default, code scanning will trigger a scan with the CodeQL engine on the following events:; * On every pull request — to flag up potential secu",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/815:136,integrat,integrated,136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/815,2,['integrat'],['integrated']
Integrability,"Hi again,. Together with Mark Miller (JHPCE's admin) we ran more tests. We verified that `Salmon` does indeed use at least 2 threads so now I'm always requesting 2 from SGE. We also noticed that when the jobs fail due to memory (the actual issue in this thread) they fail after the `There is 1 library` message as shown below for one test:. ```; [2017-04-05 14:28:09.021] [jointLog] [info] parsing read library format; [2017-04-05 14:28:09.035] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-064/job_scripts/420662: line 31: 28651 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipelin; e/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode; .v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test7/${ID}; ```. Files that work well, keep on going:. ```; [2017-04-05 14:30:23.757] [jointLog] [info] parsing read library format; [2017-04-05 14:30:23.767] [jointLog] [info] There is 1 library.; [2017-04-05 14:30:24.378] [jointLog] [info] Loading Quasi index; ```. I don't know if that hint makes you suspect anything in `Salmon`. . Now, for some tests only task 2 runs and it turns out that task 2 has a smaller fastq file than the other 2:. ```bash; $ ls -lh merged_fastq/R1000[1-3]*; -rw-r--r-- 1 lcollado lieber_jaffe 6.2G Feb 20 12:39 merged_fastq/R10001_D2B1WACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 6.3G Feb 20 12:40 merged_fastq/R10001_D2B1WACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.6G Feb 20 12:42 merged_fastq/R10002_C29P7ACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.7G Feb 20 12:44 merged_fastq/R10002_C29P7ACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:47 merged_fastq/R10003_D19KGACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:50 merged_fastq/R10003_D19KGACXX_read2.fastq.g",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:303,message,message,303,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['message'],['message']
Integrability,"Hi all - this looks like an old version of Trinity. I'd suggest upgrading. For any version of Trinity, you can look at the Dockerfile to see what the; corresponding compatibilities are for versions that get co-installed for a; fully functional package. For example, in the current release, you'll find:. https://github.com/trinityrnaseq/trinityrnaseq/blob/5ce78d2b6d63aaae9fe491408311ebaf158deaa6/Docker/Dockerfile#L235. best,. ~brian. On Fri, Feb 24, 2023 at 1:19 PM Rob Patro ***@***.***> wrote:. > I am not sure how the index here was created, but the actual error; > signifies that you are attempting to quantify the assembled transcripts; > using a recent version of salmon (1.9.0 in this case) against an index; > that was created by a *very old* version of salmon (pre 1.0). This is not; > supported, as the index format completely changed between pre v1.0 and post; > v1.0, and newer versions rely on a completely different data structure.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/832#issuecomment-1444189059>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABZRKX5M6TN6DEQJQCP2AALWZD3TRANCNFSM6AAAAAAVHFUQRA>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/832#issuecomment-1444289845:1268,Message,Message,1268,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/832#issuecomment-1444289845,1,['Message'],['Message']
Integrability,"Hi all,. Thanks for reporting this. It's strange (and unfortunate), since managing the shared libraries on which the programs depend correctly is supposed to be a major raison d'etre for Bioconda to begin with. I'll try and take a look to see if there is e.g. another version of the SO that can be used for Salmon to resolve this conflict.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/147#issuecomment-324679973:126,depend,depend,126,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/147#issuecomment-324679973,1,['depend'],['depend']
Integrability,"Hi and thank you for helping,. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; alevin. **Describe the bug**; Running alevin on 10x v1 data results in the following error:; > [alevinLog] [info] Starting Import of the gene count matrix.; > Exception : [std::bad_alloc]; > alevin was invoked improperly. **To Reproduce**. * Salmon version: Release v0.11.3; * Installed from: Compiled. I also followed the instructions from the [alevin tutorial](https://combine-lab.github.io/alevin-tutorial/2018/running-alevin/) to compile the `scripts/v1_10x/wrapper.cpp` file; * Reference transcriptome: [Homo_sapiens.GRCh37.cdna.all.fa](ftp://ftp.ensembl.org/pub/grch37/release-83/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh37.cdna.all.fa.gz); * Which read files were used? Either the [CD14+ Monocytes from the 10x v1 paper](http://s3-us-west-2.amazonaws.com/10x.files/samples/cell-exp/1.1.0/cd14_monocytes/cd14_monocytes_fastqs.tar) or the [PBMC 3k from the same paper](http://cf.10xgenomics.com/samples/cell-exp/1.0.0/pbmc3k/pbmc3k_fastqs.tar); * Which program options were used?; I ran the following command for the CD14 Monocytes dataset:; `~/software/salmon/scripts/v1_10x/run.sh ~/software/salmon/bin/salmon salmon alevin -l ISR -b ./fastq/fastqs/flowcell1/ --gemcode -i ./transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ./hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpCsvCounts; `; and the following one for the PBMC_3K dataset:; `~/software/salmon/scripts/v1_10x/run.sh ~/software/salmon/bin/salmon alevin -l ISR -b pbmc3k_fastqs/ --gemcode -i ../transcripts_index_salmon/ -p 8 -o alevin_output --tgMap ../hg_transcriptome/tx2gene.tsv --dumpCsvCounts; `. **Screenshots**; CD14+ Monocytes shell log:; ```~/software/salmon/scripts/v1_10x/run.sh salmon alevin -l ISR -b ./fastqs/flowcell1/ --gemcode -i ../transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ../hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpC",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:579,wrap,wrapper,579,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['wrap'],['wrapper']
Integrability,"Hi everyone,. Is there a way to feed pre-transformed files into Alevin? We've been using Valentine's nice umis repository https://github.com/vals/umis as our preprocessing step to put sample, cell and UMI barcodes into the read name. They end up with formats like this:. ```; @ST-K00126:314:HFYL2BBXX:7:1101:1631:1226:CELL_GGGCACTAGCTGATAA:UMI_GGGCCCAACG:SAMPLE_GTAATTGC; GNTGTGGCAGAGCAGCGACCCGCGGCGGGGCGGCATCCCCAGCTGGTTCGGGCCGGGACGGGGCGGCCAGCAGGGACGCGCCCCAGGGGGGCAGCTGT; +; A#-<<F7<AJF-FJ<JAAJJFJJ<AF-7AJF77<FJJJFFFJJ<JA-7-777<-F7<<F--7AA7AAAFF-AF<A-AFFA7J7F--7)-)7--7A<J-; ```; the nice thing about the way umis is doing it is you can specify how to do transformations via a JSON file that has regexes regarding where in the original FASTQ files the UMI/cell/sample barcodes are. For example, for 10x v2:; ```json; {; ""read1"": ""(?P<name>@.*) .*\\n(?P<CB>.{16})(?P<MB>.{10})(.*)\\n\\+(.*)\\n(.*)\\n"",; ""read2"": ""(@.*) .*\\n(?P<seq>.*)\\n\\+(.*)\\n(?P<qual>.*)\\n"",; ""read3"": ""(@.*)\\n(?P<SB>.*)\\n\\+(.*)\\n(.*)\\n""; }; ```; This makes it so end users can write their own transformations to handle arbitrary protocols. . I'd love to plug into Alevin after this step and use Alevin for everything else. Is there a description of what the reads need to look like to work with the downstream steps in Alevin?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/360:1109,protocol,protocols,1109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/360,1,['protocol'],['protocols']
Integrability,"Hi everyone,; Lately I was trying to use Salmon (v0.8.0) along with tximport to study a downloaded single-cell data on gene-level. And I came across something werid that I found almost 20k genes on average per cell, which is way higher than expected. Realistically, the scRNA-seq protocol I followed will only have a gene number detection of roughly 10k. I re-do the analysis with STAR + featurecounts and I observed a per-cell gene number of 6k on average. Just wonder which part of my code goes wrong. Attached please find my code for Salmon and subsequent R script for tximport. Any advice or suggestion will be much appreciated! I do love Salmon for its speed and convenience. Salmon index; #!/bin/bash. salmon index -t /home1/garyhe/workingdir/ref/gencode/gencode.v25.transcripts.ercc.fa -i /home1/garyhe/workingdir/ref/index/salmonindex/v25/19mer --gencode --type quasi -k 19. Salmon quant; #!/bin/bash. cd /home1/garyhe/workingdir/data/bjorklund2016ni/00_raw. for i in $(ls *.gz | cut -c 1-10 | uniq). do. salmon quant -i /home1/garyhe/workingdir/ref/index/salmonindex/v25/19mer \; -l U \; -r ${i}_1.fastq.gz \; --writeMappings=/home1/garyhe/workingdir/data/bjorklund2016ni/01_aligned/${i}.sam \; -o /home1/garyhe/workingdir/data/bjorklund2016ni/02_quant/${i}. Done. R script for tximport; #condense the ensemble transcript ID counts to gene ID counts; library(GenomicFeatures); txdb <- makeTxDbFromGFF(""./Sequencing_run/gencode.vM12.primary_assembly.annotation.ercc.gtf""); k <- keys(txdb, keytype = ""GENEID""); df <- select(txdb, keys = k, keytype = ""GENEID"", columns = ""TXNAME""); tx2gene <- df[, 2:1]; head(tx2gene). library(tximport); library(readr); dir <- ""./Sequencing_run/salmon_output/sc/""; list.files(dir); samples <- read.table(""./Sequencing_run/salmon_output/scsampleinfo.txt"", header=TRUE); samples; files <- file.path(dir, samples$Sample_ID, ""quant.sf""); names(files) <- paste0(samples$Sample_ID); names(files) <- gsub(""[:_:].*$"", """", names(files)). #gene-level; txi.salmon.g <- txi",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/120:280,protocol,protocol,280,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/120,1,['protocol'],['protocol']
Integrability,"Hi guys,. Which existing dependencies would you like to be able to use? There are some of these libraries that cannot be replaced by already installed variants. Specifically,; - BWA --- since the version that is pulled in and used actually requires we expose certain functionality for our lightweight alignment procedure (though this dependency may go away all together if we deprecate lightweight alignment in favor of quasi-mapping).; - Jellyfish --- here, we require the ability to use jellyfish as a library. Specifically, we rely on some headers that are not installed with the standard package. Perhaps here there could be some synergy with Guillaume on making all of the things Salmon uses part of the standard Jellyfish install, but, at least currently, this isn't the case. The CMake build system already looks for existing versions of the following before fetching them:; - Boost; - tbb; - jemalloc. So, the the remaining guys are `libgff` (which is just some small libraryification of a gff parser that I put together a while ago, I don't know that it's in any package manager --- is it? It doesn't even have an associated install script) and `staden IO lib`. For Staden, I'd be happy to have it look for an existing installation, but there is no FindStaden.cmake that I know of, and I don't really know how to write FindX.cmake files appropriately. However, I'd be happy to learn and / or accept pull requests.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193559957:25,depend,dependencies,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193559957,2,['depend'],"['dependencies', 'dependency']"
Integrability,"Hi rob-p,; `gcc -version ` tells me its version `6.3.0` of the GCC compiler. . ```; c+\+ -v; Using built-in specs.; COLLECT_GCC=c++; COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-alpine-linux-musl/6.3.0/lto-wrapper; Target: x86_64-alpine-linux-musl; Configured with: /home/buildozer/aports/main/gcc/src/gcc-6.3.0/configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --build=x86_64-alpine-linux-musl --host=x86_64-alpine-linux-musl --target=x86_64-alpine-linux-musl --with-pkgversion='Alpine 6.3.0' --enable-checking=release --disable-fixed-point --disable-libstdcxx-pch --disable-multilib --disable-nls --disable-werror --disable-symvers --enable-__cxa_atexit --enable-default-pie --enable-cloog-backend --enable-languages=c,c++,objc,java,fortran,ada --disable-libssp --disable-libmpx --disable-libmudflap --disable-libsanitizer --enable-shared --enable-threads --enable-tls --with-system-zlib --with-linker-hash-style=gnu; Thread model: posix; gcc version 6.3.0 (Alpine 6.3.0); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-343658308:205,wrap,wrapper,205,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-343658308,1,['wrap'],['wrapper']
Integrability,"Hi, . I am working on 6 samples (Biological replicates for treatment A = 3, Biological replicate for treatment B = 3) and am attempting to quantify these reads. Some of the samples have both PE and SE read files despite undergoing the same sequencing protocols (due to the sequencing processes that yield orphan read). Plus, as I trimmed the reads using Trimmomatic, more orphan reads are generated. I wonder how can I quantify (mapping-based, transcript-level) both PE and SE reads which should belong to the same library and end up with only one quant.sf file? I want to have the final count of 6 quant.sf file for the 6 samples to proceed with edgeR. . As of now, I am planning to concatenate both PE and SE reads according to their strand-specificity and run salmon in paired-end mode. Should I just input both SE and PE reads separately by using both -1/2 and -r? ; Any input would help! Thank you!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/593:251,protocol,protocols,251,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/593,1,['protocol'],['protocols']
Integrability,"Hi, ; I am having an issue with quantifying my salmon quantify using the following script:. #!/bin/bash; # get input data; F=$(cat file_names.txt); for i in ${F}; do; F1=../processed_fastq/${i}_R1_001_val_1.fastq.gz; F2=../processed_fastq/${i}_R2_001_val_2.fastq.gz; echo ""performing salmon quant on ${i}""; salmon quant -i gencode_v43_index -l A -1 ${F1} -2 ${F2} -p 64 /; --validateMappings --writeUnmappedNames -o ${i}; echo ""finish quantifying ${i}""; done. And I got this error message :; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ###; (mapping-based mode) Exception : [the option '--output' is required but missing].; Please be sure you are passing correct options, and that you are running in the intended mode.; alignment-based mode is detected and enabled via the '-a' flag. Exiting.; quantify.sh: line 19: --validateMappings: command not found; finish quantifying . could you please assist me with that. Thanks",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/854:481,message,message,481,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/854,1,['message'],['message']
Integrability,"Hi, ; I am writing here, because I think this issue is relevant to both @rob-p and @kvittingseerup. I ran my salmon analysis twice with the most recent gencode annotation [https://www.gencodegenes.org/releases/current.html](url) -> PRI. Once with the `--keepDuplicates` option in the indexing and once without (bec I read this post late..). ; When loadind the data into IsoformSwithcAnalyzer the first time (w/o `--keepDuplicates`), I received the following warning message, ""The annotation (count matrix and isoform annotation) contain differences in which isoforms are analyzed... 875 more isoforms than the count matrix..."". Following the run with `--keepDuplicates`, I now receive ""67 more isoforms than the count matrix"". If I am using the `--keepDuplicates` option, what exactly are there 67 isforms?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410512481:466,message,message,466,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-410512481,1,['message'],['message']
Integrability,"Hi, ; I just downloaded the salmon.10.0 version and indexed my transcriptome using the https://www.gencodegenes.org/releases/current.html --> FASTA files --> trasnscript sequences. When I try to run Salmon I receive the above error message. The last time I ran Salmon I used 9.1 and this trasncriptome from ensembl ftp://ftp.ensembl.org/pub/release-92/fasta/homo_sapiens/cdna/...; What is going on here? . The header.json file looks like this: ; {; ""value0"": {; ""IndexType"": 1,; ""IndexVersion"": ""q3"",; ""UsesKmers"": true,; ""KmerLen"": 31,; ""BigSA"": false,; ""PerfectHash"": false; }; }",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/232:232,message,message,232,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/232,1,['message'],['message']
Integrability,"Hi, I am having issues with calculating the differential splicing and I kept getting this error message, even though all files required are uploaded. Could you please help me with this issue. The error message is below :",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/858:96,message,message,96,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/858,2,['message'],['message']
Integrability,"Hi, I follow the instructions for conda - mediated installation, it installs v 0.8.2 not v 0.9.1",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194:42,mediat,mediated,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194,1,['mediat'],['mediated']
Integrability,"Hi, I have some kind the same error of (https://github.com/COMBINE-lab/salmon/issues/251#issue-341161248). I download the prebuild index from refgenie and I got exactly the same error message. refgenie pull hg38/salmon_sa_index <- I downloaded the 16Gb of the index files. [2020-05-04 21:30:58.648] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2020-05-04 21:30:58.648] [jointLog] [info] parsing read library format; [2020-05-04 21:30:58.648] [jointLog] [info] There is 1 library.; [2020-05-04 21:30:58.701] [jointLog] [info] Loading Quasi index; Exception : [rapidjson internal assertion failure: IsObject()]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting. The son files of the index show this;; ls -lrth *json; -rwxrwxrwx 1 usr usr 1007 dic 14 00:41 info.json; -rwxrwxrwx 1 usr usr 96 dic 14 00:44 versionInfo.json. Any idea would be really appreciated,. Kind regards,; Fer",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518:184,message,message,184,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518,1,['message'],['message']
Integrability,"Hi, I have some kind the same error. I download the prebuild index from refgenie and I got exactly the same error message. . refgenie pull hg38/salmon_sa_index <- I downloaded the 16Gb of the index files. [2020-05-04 21:30:58.648] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2020-05-04 21:30:58.648] [jointLog] [info] parsing read library format; [2020-05-04 21:30:58.648] [jointLog] [info] There is 1 library.; [2020-05-04 21:30:58.701] [jointLog] [info] Loading Quasi index; Exception : [rapidjson internal assertion failure: IsObject()]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting. The son files of the index show this;; ls -lrth *json; -rwxrwxrwx 1 usr usr 1007 dic 14 00:41 info.json; -rwxrwxrwx 1 usr usr 96 dic 14 00:44 versionInfo.json. Any idea would be really appreciated,. Kind regards, ; Fer",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-623664770:114,message,message,114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-623664770,1,['message'],['message']
Integrability,"Hi, I'm just starting with RNA-Seq and tryed to install salmon on the HPC of my university. However I get following error message when recompiling with ""$ make"". . ```; [ 6%] Built target libbz2; [ 13%] Built target libgff; [ 19%] Built target libbwa; [ 26%] Built target libjellyfish; [ 27%] Performing build step for 'libstadenio'; Making all in io_lib; Making all in progs; libtool: link: /usr/bin/cc -o convert_trace convert_trace.o ../io_lib/.libs/libstaden-read.a -lz -lm -lpthread -llzma -lbz2; /usr/bin/ld: cannot find -lbz2; ../io_lib/.libs/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xd26): warning: the use of `tempnam' is dangerous, better use `mkstemp'; collect2: error: ld returned 1 exit status; make[5]: *** [convert_trace] Fehler 1; make[4]: *** [all-recursive] Fehler 1; make[3]: *** [all] Fehler 2; make[2]: *** [libstadenio-prefix/src/libstadenio-stamp/libstadenio-build] Fehler 2; make[1]: *** [CMakeFiles/libstadenio.dir/all] Fehler 2; make: *** [all] Fehler 2. ```. Does this have anything to do with ""bzip2"" or ""libbz2"" and how would I provide missing paths to cmake?; I have bzip2 but not libbz2 availible on my system. I would be gratefull for any help.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/216:122,message,message,122,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/216,1,['message'],['message']
Integrability,"Hi, I've been using salmon v1.0.0 to quantify bulk transcripts from fastqs using the genocde v32 reference. Ive used it successfully on several cohorts but on my most recent I received the following warning in my log file (I also attached the entire file):. [2021-05-10 20:51:46.936] [jointLog] [warning] NOTE: Read Lib [[ /gcloud-shared/inputR1.gz, /gcloud-shared/inputR2.gz]] :. Detected a *potential* strand bias > 1% in an unstranded protocol check the file: /gcloud-shared/sample/lib_format_counts.json for details. Here is also the lib_formats_count.json:; {; ""read_files"": ""[ /gcloud-shared/inputR1.gz, /gcloud-shared/inputR2.gz]"",; ""expected_format"": ""IU"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 43142675,; ""num_assigned_fragments"": 43142675,; ""num_frags_with_concordant_consistent_mappings"": 36380775,; ""num_frags_with_inconsistent_or_orphan_mappings"": 7777480,; ""strand_mapping_bias"": 0.5172763911708863,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 18818916,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 17561859,; ""SF"": 2219340,; ""SR"": 5558140,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }. Here is the salmon command I've been using:. salmon --no-version-check quant -i /gcloud-shared/reference -l A -1 ${FASTQR1} -2 ${FASTQR2} \; --validateMappings --seqBias --gcBias --posBias --threads $(nproc) -o /gcloud-shared/sample. The whole process still produces quants files, but having never received this warning with other sample cohorts I want to be sure it's not affecting the results. Any idea why I might be getting this? Am I using the wrong lib type?. Thanks!. [ukbec_quants_gencode_32_filtered_A653_002_logs_salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/6479118/ukbec_quants_gencode_32_filtered_A653_002_logs_salmon_quant.log)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/659:438,protocol,protocol,438,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/659,1,['protocol'],['protocol']
Integrability,"Hi, Rob, thanks for the quick reply! By the way, great job on salmon!. Using ./ did fix the issue. About the stdout issue, I'm running:. ~/programs/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /data/reference/salmon/gencode.grch37.v19/ -r test.fastq --seqBias --gcBias --posBias -p 12 --geneMap /data/reference/salmon/gencode.grch37.v19/geneMap.txt --libType U -o x --writeMappings > out.sam. and not all messages are output to stderr (I'm not using 2> ). The ones starting with ### do, but others end up in out.sam. out.sam starts with:. ESC[1m[2016-09-14 11:37:38.908] [jointLog] [info] parsing read library format; ESC[00mESC[1m[2016-09-14 11:37:38.908] [jointLog] [info] There is 1 library.; ESC[00mESC[1m[2016-09-14 11:37:43.996] [jointLog] [info] Loading Quasi index; ESC[00mESC[1m[2016-09-14 11:37:43.996] [jointLog] [info] Loading 32-bit quasi index; ESC[00mESC[1m[2016-09-14 11:37:43.996] [stderrLog] [info] Loading Suffix Array ; ESC[00mESC[1m[2016-09-14 11:38:06.669] [stderrLog] [info] Loading Transcript Info ; ESC[00mESC[1m[2016-09-14 11:38:12.374] [stderrLog] [info] Loading Rank-Select Bit Array; ESC[00mESC[1m[2016-09-14 11:38:12.444] [stderrLog] [info] There were 95309 set bits in the bit array; ESC[00mESC[1m[2016-09-14 11:38:12.700] [stderrLog] [info] Computing transcript lengths; ESC[00mESC[1m[2016-09-14 11:38:12.700] [stderrLog] [info] Waiting to finish loading hash; ESC[00mESC[1m[2016-09-14 11:39:49.792] [stderrLog] [info] Successfully loaded position hash; ESC[00mESC[1m[2016-09-14 11:39:49.792] [stderrLog] [info] Done loading index; ESC[00mESC[1m[2016-09-14 11:39:49.792] [jointLog] [info] done; ESC[00mESC[1m[2016-09-14 11:39:49.792] [jointLog] [info] Index contained 95309 targets; ESC[00mESC[33mESC[1m[2016-09-14 11:40:18.128] [jointLog] [warning] Fragment GC bias correction is currently only implemented for paired-end libraries. Disabling fragment GC bias correction for this run; ESC[00m@HD VN:1.0 SO:unknown",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247078586:406,message,messages,406,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247078586,1,['message'],['messages']
Integrability,"Hi, Rob.; I've been trying to compile ""salmon"" 1.1.0 from source under Ubuntu 18.04 and managed to get a newer version of ""cmake"" from KitWare, but there are many other dependency problems...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610578989:169,depend,dependency,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610578989,1,['depend'],['dependency']
Integrability,"Hi, thank you for your reply, I prefer to use the pre-built version 1.10.0. * J. Eduardo Martinez-Hernandez*; *PhD Integrative Genomics*. El lun, 5 jun 2023 a las 14:02, Rob Patro ***@***.***>); escribió:. > This *usually* means that the version of the boost library you have was; > not compiled with a C++11-compatible ABI. There is a incompatibility; > between pre C++11 and post C++11 std::string representations, and since; > salmon uses modern C++ (C++14 as of this writing), you need a version of; > boost compiled in a compatible way. How was boost installed on your system?; >; > Of course, if you don't need to compile from source, it's *much* easier; > to install via conda, or to grab the pre-built executable (1.10.0 is; > feature and bugfix identical to 1.10.1).; >; > Best,; > Rob; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/551#issuecomment-1577237260>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AM6EVFLJX45SB67GSQ3RYO3XJYNLBANCNFSM4PG7JFPQ>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/551#issuecomment-1577285952:115,Integrat,Integrative,115,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/551#issuecomment-1577285952,2,"['Integrat', 'Message']","['Integrative', 'Message']"
Integrability,"Hi, we're having trouble with salmon on a stranded library -- we're executing. ```; salmon index --index idx --transcript equCabs.fa --type quasi; ```. and then. ```; salmon quant -i idx -1 leftReads.fq -2 rightReads.fq --libType ISF -o xxx.quant; ```. We then get the warning that there is a big strand bias in an unstranded protocol, despite having specified stranded (S) in libType. Inspection of the libFormatCounts.txt file confirms this, with ""expected format"" specifying ""strandedness:unstranded"".",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/30:326,protocol,protocol,326,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/30,1,['protocol'],['protocol']
Integrability,"Hi, who's concerning,; I was using alevin to run on a PBMC 10xv3 dataset.; Here is my script,; salmon alevin -lISR -1 $fastq1 -2 $fastq2 --chromiumV3 -i $work_p/salmon_index_human -p 12 -o output --tgMap $data_p/test12.tsv --keepCBFraction 1. I kept all CB to make sure I can use emptyDrops. Also, here this index is SAF index followed by your tutorial. Then I got the error message like:; [alevin.log](https://github.com/COMBINE-lab/salmon/files/7035475/alevin.log). Is there any suggestion on how to solve this?; Cheers,; Chloe",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/698:375,message,message,375,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/698,1,['message'],['message']
Integrability,"Hi, you did not say which lab protocol has been used. I assume Illumina Nextera Long-Mate pair protocol? This one gives you RF (reverse&forward) reads but highly contaminated with FR (forward&reverse) reads (ordinary paired-end reads). From normal paired-end sequencing libraries I have just 100% FR reads, as expected (I used `ISF` for salmon).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/206#issuecomment-400077831:30,protocol,protocol,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/206#issuecomment-400077831,2,['protocol'],['protocol']
Integrability,"Hi,. Building salmon with `-DFETCH_BOOST=TRUE` ends with an error that might be caused by the build process looking to iostreams in the wrong place. The end of the ouput on the terminal is:. ```; [ 80%] Built target salmon_core; make -f src/CMakeFiles/salmon.dir/build.make src/CMakeFiles/salmon.dir/depend; make[2]: Entering directory `/opt/local/salmon-index/resources/salmon-0.4.2'; cd /opt/local/salmon-index/resources/salmon-0.4.2 && /usr/bin/cmake -E cmake_depends ""Unix Makefiles"" /opt/local/salmon-index/resources/salmon-0.4.2 /opt/local/salmon-index/resources/salmon-0.4.2/src /opt/local/salmon-index/resources/salmon-0.4.2 /opt/local/salmon-index/resources/salmon-0.4.2/src /opt/local/salmon-index/resources/salmon-0.4.2/src/CMakeFiles/salmon.dir/DependInfo.cmake --color=; make[2]: Leaving directory `/opt/local/salmon-index/resources/salmon-0.4.2'; make -f src/CMakeFiles/salmon.dir/build.make src/CMakeFiles/salmon.dir/build; make[2]: Entering directory `/opt/local/salmon-index/resources/salmon-0.4.2'; make[2]: *** No rule to make target `/usr/lib/libboost_iostreams-mt.a', needed by `src/salmon'. Stop.; make[2]: Leaving directory `/opt/local/salmon-index/resources/salmon-0.4.2'; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; make[1]: Leaving directory `/opt/local/salmon-index/resources/salmon-0.4.2'; make: *** [all] Error 2; ```. Earlier in the output I can spot this:. ```; cc1plus: warning: unrecognized command line option ""-Wno-deprecated-register"" [enabled by default]; make[2]: *** No rule to make target `/usr/lib/libboost_iostreams-mt.a', needed by `src/salmon'. Stop.; make[2]: Leaving directory `/opt/local/salmon-index/resources/salmon-0.4.2'; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; make[1]: Leaving directory `/opt/local/salmon-index/resources/salmon-0.4.2'; make: *** [all] Error 2; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/21:300,depend,depend,300,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/21,2,"['Depend', 'depend']","['DependInfo', 'depend']"
Integrability,"Hi,. I am trying to process scRNAseq Chromium data using alevin. I already have results from cellranger and I wanted to compare them with alevin. I use the following command line; salmon alevin -lISR -1 Fastq1a.fastq.gz Fastq1b.fastq.gz -2 Fastq2a.fastq.gz Fastq2b.fastq.gz --chromium -i gencode.v25.transcripts_index -p 20 -o AlevinOUT --tgMap gencode.v25.txp2gene.tsv --dumpCsvCounts --whitelist 737K-august-2016.txt. I get the following error message at the end of the output; [alevinLog] [error] Barcode not found in frequency table. If I run the exact same files using without the --whitelist flag/file I get some results for a very small set of barcodes. Interestingly the barcodes found by alevin (I only checked 2 or 3) are also in the 737K-august-2016.txt file. . My first question is why alevin does not ""count"" barcodes (zero frequency) with the barcode file, and does estimate frequency for some (at least) barcodes without the barcode file. Considering that the barcodes in the latter case are also found in the whitelist file. . My second question is more about difference between alevin and cellranger. I do get estimated counts for a large number of barcodes (thousands) using cellranger, while barely on the order of a few hundreds, at best, using alevin. Thanks",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/284:446,message,message,446,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/284,1,['message'],['message']
Integrability,"Hi,. I am using Salmon v 1.10.1 do perform selective alignment on paired end RNAseq samples and I have trouble to interpret the output statistics (i.e succesfully mapped pairs ....); Here is my command line on a sample containing 34,462,097 pairs (After cleaning, adapter removal, rRNA trimming). **salmon quant -i $IndexDir -l A -1 $forward -2 $reverse -p 8 --seqBias --gcBias –useVBOpt --discardOrphansQuasi –consensusSlack 0.35 --minScoreFraction 0.8 --decoyThreshold 1 -o $OutputDir/$pairname_Output**. Here is the the output statistics of the alignment; [Salmon_quant_output.txt](https://github.com/COMBINE-lab/salmon/files/11768911/Salmon_quant_output.txt). So I have few questions : . 1- Where is idicated the numer of processed pairs, i.e. the number of pairs in the sample ?. 2- Does the mapping rate correspond to the reads that will be used for the quantification (i.e. succesfully mapped and that were above every filtering thresholds) or this % also takes into account the discarded mapping ? This is of great importance to tell if the mapping step is good or not. 3- Counted 20,588,460 total reads in the equivalence classes What does this mean ? Is it the numner of pairs that mapped (discarded and not discarded or only the ones that are kept for quentification). 4- What is the difference between mapping discarded and fragment discarded ? To count the number if pairs that did not map to my reference should I sum Number of mappings discarded because of alignment score + Number of fragments entirely discarded because of alignment score + Number of fragments discarded because they are best-mapped to decoys + Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets. Thanks in advance for your time and answers,,. Florian Rocher",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/852:264,adapter,adapter,264,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/852,1,['adapter'],['adapter']
Integrability,"Hi,. I am using salmon quant v0.91 to map some reads against ce11 genome. . But the run fails with a cryptic error message, maybe you can help me sort this out.; ```; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.9.1; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/salmon_index }; ### [ libType ] => { A }; ### [ threads ] => { 8 }; ### [ mates1 ] => { /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/trimmed_reads/rluc_2_R1.fastq.gz }; ### [ mates2 ] => { /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/trimmed_reads/rluc_2_R2.fastq.gz }; ### [ output ] => { /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/salmon_output/rluc_2 }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ geneMap ] => { /data/akalin/Base/Annotation/ce11/ENSEMBL91/Caenorhabditis_elegans.WBcel235.91.gtf }; Logs will be written to /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/salmon_output/rluc_2/logs; [2018-03-21 10:00:03.272] [jointLog] [info] parsing read library format; [2018-03-21 10:00:03.272] [jointLog] [info] There is 1 library.; [2018-03-21 10:00:03.517] [stderrLog] [info] Loading Suffix Array; [2018-03-21 10:00:03.501] [jointLog] [info] Loading Quasi index; [2018-03-21 10:00:03.506] [jointLog] [info] Loading 32-bit quasi index; [2018-03-21 10:00:03.846] [stderrLog] [info] Loading Transcript Info; [2018-03-21 10:00:03.980] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-03-21 10:00:03.995] [stderrLog] [info] There were 35448 set bits in the bit array; [2018-03-21 10:00:04.001] [stderrLog] [info] Computing transcript lengths; [2018-03-21 10:00:04.001] [stderrLog] [info] Waiting to finish loading hash; [2018-03-21 10:00:40.560] [stderrLog] [info] Done loading index; [2018-03-21 10:00:40.560] [jointLog] [info] done; [2018-03-21",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/210:115,message,message,115,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/210,1,['message'],['message']
Integrability,"Hi,. I have a public 10xV2 sample that I am reprocessing ([SRR13313130](https://trace.ncbi.nlm.nih.gov/Traces/sra/?run=SRR13313130)). More specifically, I believe that the sample should be **10X Genomics 5' v1**. I am using the following command:. ```; ID=5309-CT-2; R1=../Reads/5309-CT-2_S01_L005_R1_001.fastq.gz; R2=../Reads/5309-CT-2_S01_L005_R2_001.fastq.gz. TYPE=10xV2; #for MAP, download from UCSC Table Browser, and remove 1st line (and then manually add SARS-COV-2 genes); MAP=/path/to/SARS_COV_2-hg38_RefSeq_2column.txt; REF=/path/to/SARS_COV_2-hg38_salmon; CBWL=/path/to/737K-august-2016.txt. salmon alevin -l ISR --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP --whitelist $CBWL; ```. If I use the V3 barcode list, then I _don't_ get an error message. However, I got more discordant cell counts between CellRanger and STARsolo. The Kallisto cell barcode recovery rate was also low (<10%). So, I thought there error was that different cell barcodes should be used for this sample. I think that matches, what I saw on this FAQ page from 10x Genomics:. https://kb.10xgenomics.com/hc/en-us/articles/115004506263-What-is-a-barcode-whitelist-. So, I downloaded the [737k-august-2016.txt](https://github.com/10XGenomics/cellranger/blob/master/lib/python/cellranger/barcodes/737K-august-2016.txt) file from 10x, and I am testing using that. However, I am now receiving the following error message:. ```; [2021-07-07 17:07:44.192] [alevinLog] [info] Done importing white-list Barcodes; [2021-07-07 17:07:44.192] [alevinLog] [error] Wrong whitelist provided; Please check https://salmon.readthedocs.io/en/develop/alevin.html#whitelist; ```. On the [website linked](https://salmon.readthedocs.io/en/develop/alevin.html#whitelist), I see a note saying ""**Not 10x 724k whitelist**"". However, I apologize that I don't think I understand this note (and the exact file name is different). Should I be doing some differently when running Alevin for this sample?. Thank you very much. Sincerely,; C",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682:764,message,message,764,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682,1,['message'],['message']
Integrability,"Hi,. I have had success using Salmon and Alevin after the hash-resize-hotfix issues. However, when I try to compile the latest commit I get an error for an undeclared error. I have tried searching through the external dependencies for the definition of `rapmap::utils::ChainStatus` but I cannot find it. Thanks!. ```; [ 6%] Built target libbwa; [ 12%] Built target libtbb; [ 19%] Built target libcereal; [ 26%] Built target libdivsufsort; [ 32%] Built target libstadenio; [ 38%] Built target libspdlog; [ 45%] Built target libgff; [ 47%] Built target ksw2pp_sse4; [ 49%] Built target alevin_core; [ 54%] Built target ksw2pp_basic; [ 56%] Built target ksw2pp_sse2; [ 57%] Built target ksw2pp; [ 72%] Built target salmon_core; [ 76%] Built target unitTests; [ 77%] Building CXX object src/CMakeFiles/salmon.dir/SalmonQuantify.cpp.o; /u/gww/tmp/salmon2/salmon/src/SalmonQuantify.cpp:790:43: error: 'rapmap::utils::ChainStatus' has not been declared; rapmap::utils::ChainStatus chainStat,; ^; /u/gww/tmp/salmon2/salmon/src/SalmonQuantify.cpp: In function 'int32_t getAlnScore(ksw2pp::KSW2Aligner&, ksw_extz_t&, int32_t, const char*, int32_t, char*, int32_t, int8_t, int8_t, int32_t, int, uint32_t, AlnCacheMap&)':; /u/gww/tmp/salmon2/salmon/src/SalmonQuantify.cpp:794:35: error: 'rapmap::utils::ChainStatus' has not been declared; if (chainStat == rapmap::utils::ChainStatus::PERFECT) {; ^; /u/gww/tmp/salmon2/salmon/src/SalmonQuantify.cpp:813:70: error: 'rapmap::utils::ChainStatus' has not been declared; bool doUngapped{(!invalidStart) and (chainStat == rapmap::utils::ChainStatus::UNGAPPED)};; ^; /u/gww/tmp/salmon2/salmon/src/SalmonQuantify.cpp: In function 'void processReadsQuasi(paired_parser*, ReadExperimentT&, ReadLibrary&, AlnGroupVec<rapmap::utils::QuasiAlignment>&, std::atomic<long unsigned int>&, std::atomic<long unsigned int>&, std::atomic<long unsigned int>&, std::atomic<long unsigned int>&, RapMapIndexT*, std::vector<Transcript>&, ForgettingMassCalculator&, ClusterForest&, FragmentL",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/254:218,depend,dependencies,218,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/254,1,['depend'],['dependencies']
Integrability,"Hi,. I have run a RNAseq sample through Salmon with --l A option (library type); I was told regarding the in-house protocol to generate the library that ""The first read reads off the anti-sense strand, and the second reads off of the sense strand. From what I understand, the first read is reported as the sense strand, and the second read is reported as the anti-sense strand (as the reverse complement)"". i.e. similar to TruSeq (first read comes from anti-sense/reverse strand). That would translate into ISR according to http://salmon.readthedocs.io/en/latest/library_type.html. Yet from the Salmon quant log file = Automatically detected most likely library type as ISF.; If I run the same sample with -l ISF I get the warning:; Greater than 5% of the fragments disagreed with the provided library type; check the file: 2RD_1760_salmon_quant_ISF/lib_format_counts.json for details - ; which shows:; ""expected_format"": ""ISF"",; ""compatible_fragment_ratio"": 0.9281440552329109,; ""num_compatible_fragments"": 8223296,; ""num_assigned_fragments"": 8859935,; ""num_consistent_mappings"": 67110116,; ""num_inconsistent_mappings"": 13842824,; ""MSF"": 0,; ""OSF"": 120231,; ""ISF"": 67110116,; ""MSR"": 0,; ""OSR"": 12968,; ""ISR"": 11405988,; ""SF"": 1926077,; ""SR"": 353507,. I would be very grateful for a possible explanation. Thank you very much!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/206:115,protocol,protocol,115,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/206,1,['protocol'],['protocol']
Integrability,"Hi,. I just encountered an unexpected behaviour of alevin when unmated reads are provided. Are unmated reads supported by alevin at all? I did not find anything in the alevin documentation, but the parameter is there. I tried to quantify some public Illumina SureCell data. Apparently the number of threads is set to 0 (because there are no file pairs?), which is of course not a good idea. The behaviour consists if I specify the number of threads manually (e.g. -p 1). Side note: There is a typo in the threads warning message (I think). ---; Salmon v1.2.1, installed from conda. #### Error message:. ```; ## alevin (dscRNA-seq quantification) v1.2.1; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { A }; ### [ index ] => { ../salmon/index/ }; ### [ unmatedReads ] => { ../samples/sc.fastq.gz }; ### [ output ] => { sc/ }; ### [ tgMap ] => { tx2gene.tsv }; ### [ end ] => { 3 }; ### [ umiLength ] => { 8 }; ### [ barcodeLength ] => { 6 }. Can't make user of more parsing threads than file (pairs); setting # of parsing threads to 0. Segmentation fault (core dumped); ```; ---. **To Reproduce**. The index is based on a gencode reference and works fine for bulk data (salmon quant). Command:; ```; salmon alevin -l A -i ../salmon/index/ --unmatedReads ../samples/sc.fastq.gz -o sc/ --tgMap tx2gene.tsv --end 3 --umiLength 8 --barcodeLength 6; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/522:521,message,message,521,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/522,2,['message'],['message']
Integrability,"Hi,. I know there has been some interest in quantifying transcripts from bulk RNA-Seq data using UMI-deduplicated reads, and I was wondering if this is a feature that is being worked on. I understand that Alevin contains a lot of the functionality necessary for UMI-deduplicated counting, but that it is not directly applicable to standard bulk RNA-Seq protocols https://github.com/COMBINE-lab/salmon/issues/306#issuecomment-439530193. I am interested in contributing to get this feature implemented, if this isn't already being developed. Is this functionality something that you would be open to adding to Salmon?. Thanks,; Gautam",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/610:353,protocol,protocols,353,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/610,1,['protocol'],['protocols']
Integrability,"Hi,. I read the preprinted Salmon paper but I couldn't understand the mathematics. Thus, I am not sure how NumReads and TPMs in the quantification file are generated, and my following questions might seem very naive. . My library is 3' selected. ([Sub-figure B] (http://www.rna-seqblog.com/for-model-species-the-3-rna-seq-method-might-more-accurately-detect-differential-expression/) ) Therefore, the number of fragments from each transcripts is not dependent on the length of the transcript. In theory, 1 transcript should only produce 1 fragment that originates from the 3' end. . Would there be any issue using Salmon to quantify a library like this? ; Should I use NumReads instead of TPM to measure transcript abundance, since I don't want my read counts to be normalized by length of transcript? ; If I am just comparing gene expression between samples, does it matter whether I use NumReads or TPM, since any normalization would cancel out when I calculate fold change?; Or should I use TPM with --posBias enabled to account for the 3' bias of my library? My concern about this approach is explained in a different [post](https://github.com/COMBINE-lab/salmon/issues/165). Thanks.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/166:450,depend,dependent,450,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/166,1,['depend'],['dependent']
Integrability,"Hi,. I'm running into an issue with quant and hope you could help. Get this error message saying my index/versionInfo.json does not seem to exist (screenshot attached). I have single end reads spread across 5 fastq files per sample. Just trying to run one sample as a test before looping it. . I have tried building an index both with Salmon v 0.8.1 using a conda install as well as salmon v0.9.1 installing directly the binary on a linux computing cluster. . I've attached a screenshot of the indexing process (it boots me out at the end but I cant tell from the outputs if it was cut short, last thing it notes is writing sequence data to the file). I've also attached a screenshot of the generated index folder contents. The index is the most recent Ensembl FASTA cDNA download for mouse. I tried indexing a transcripts FASTA file from Gencode as well and am running into the same issue, so dont think its the specific reference. The reference transcript files are 54 and 56mb respectively, so no issues downloading and transferring to our cluster. . Any thoughts are much appreciated! Thanks!. Paul. ![screen shot 2018-02-12 at 15 37 54](https://user-images.githubusercontent.com/23369975/36214991-d3b453ec-1178-11e8-8331-d641a334c47b.png); ![screen shot 2018-02-12 at 12 41 33](https://user-images.githubusercontent.com/23369975/36214993-d3bf729a-1178-11e8-9c78-38158e423b9b.png); ![screen shot 2018-02-12 at 15 33 53](https://user-images.githubusercontent.com/23369975/36214994-d3cb52cc-1178-11e8-9f74-6cfd554ccb0a.png); ![screen shot 2018-02-12 at 15 35 16](https://user-images.githubusercontent.com/23369975/36214995-d3d50376-1178-11e8-81c3-90de0a347763.png)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/197:82,message,message,82,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/197,1,['message'],['message']
Integrability,"Hi,. If I don't trim the adaptors and still use --ont will I still get correct quantification? Is adaptor trimming very essential? Is there a way I can use salmon without adaptor trimming?. Also, can you please clarify about the secondary alignmenmts if these are included in Salmon or not?. Thanks,; Harsha; ________________________________; From: Feng Yan ***@***.***>; Sent: 08 January 2024 23:30; To: COMBINE-lab/salmon ***@***.***>; Cc: Harshangda Karan Puri ***@***.***>; Author ***@***.***>; Subject: Re: [COMBINE-lab/salmon] Quantification in Alignment mode for Nanopore Data (Issue #903). also interested to know how Salmon uses secondary alignment. Because I found this tutorial https://combine-lab.github.io/salmon-tutorials/2021/ont-long-read-quantification/ [combine-lab.github.io]<https://urldefense.com/v3/__https://combine-lab.github.io/salmon-tutorials/2021/ont-long-read-quantification/__;!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTnGob8fw$> actually includes secondary alignments.; And based on my experience, secondary alignments are used by Salmon, because when I give a BAM before and after removing secondary (-F 256 flag in samtools), the results are different. —; Reply to this email directly, view it on GitHub [github.com]<https://urldefense.com/v3/__https://github.com/COMBINE-lab/salmon/issues/903*issuecomment-1881982972__;Iw!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTEiG0xQE$>, or unsubscribe [github.com]<https://urldefense.com/v3/__https://github.com/notifications/unsubscribe-auth/A3SZAPCLOZYB72ZEIEEXH43YNR6S7AVCNFSM6AAAAABANBCPNSVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTQOBRHE4DEOJXGI__;!!PDiH4ENfjr2_Jw!GTZeAEdMSJcSBTPXhWuSsmLuX2WDzuNuNgqT04lADpRqOWyHssr_JALdqVa1JBOS9RHGRa9M6SeJKoxo6T7o5_O0bvsV-KkgNb45i4uTntkMlxE$>.; You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/903#issuecomment-1884769339:1968,Message,Message,1968,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/903#issuecomment-1884769339,1,['Message'],['Message']
Integrability,"Hi,. My salmon quant program killed itself with the following message. Have no idea what's going on. Maybe because of the memory? I use MacBook pro with 16GB of memory. command =======; conda activate salmon; salmon quant -i salmon_sa_index -l ISR -1 testData/XX_R1.fastq.gz -2 testData/XX_R2.fastq.gz --validateMappings -o XX_2. error message: =======; validateMappings -o XX_2; Version Info: This is the most recent version of salmon.; ### salmon (selective-alignment-based) v1.3.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { salmon_sa_index }; ### [ libType ] => { ISR }; ### [ mates1 ] => { testData/XX_R1.fastq.gz }; ### [ mates2 ] => { testData/XX_R2.fastq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { XX_2 }; Logs will be written to XX_2/logs; [2020-08-13 09:35:38.575] [jointLog] [info] setting maxHashResizeThreads to 12; [2020-08-13 09:35:38.576] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-08-13 09:35:38.576] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-08-13 09:35:38.576] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-08-13 09:35:38.576] [jointLog] [info] parsing read library format; [2020-08-13 09:35:38.577] [jointLog] [info] There is 1 library.; [2020-08-13 09:35:38.642] [jointLog] [info] Loading pufferfish index; [2020-08-13 09:35:38.642] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 11.256 s; -----------------------------------------; size = 36981178; -----------------------------------------; | Loading contig offsets | Time = 127.43 ms; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 3.7792 ms; -------------------------------",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/560:62,message,message,62,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/560,2,['message'],['message']
Integrability,"Hi,. Quick question- if I have the reads for a library spread across multiple files, is it appropriate to run Alevin separately on each file pair and combine with quantmerge, rather than processing together? I'm looking to run Alevin via Galaxy for some training, and the available wrapper doesn't currently allow supplying multiple inputs. My feeling is that all files should be processed together for robust thresholding etc, but I may be worrying about nothing.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/434:282,wrap,wrapper,282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/434,1,['wrap'],['wrapper']
Integrability,"Hi,. after salmon installation (from source, on Ubuntu 16), 'make test' is failing all 3 tests. So I will go through them one by one. *Test 1*: fails with the `No file or directory` message. ; As I can see from the logs, the executed command `/usr/bin/cmake -DTOPLEVEL_DIR=/usr/local -P /home/rad/packages/salmon-0.10.2/cmake/UnitTests.cmake` sets the toplevel directory to `/usr/local` and fails to find the `tests/UnitTests.cpp` in there. When I set the `-DTOPLEVEL_DIR` to salmons root folder everything works just fine. ; So, is there something missing? If so, how can I fix it?. *Test 2 and 3*: fail with no output but ` Error running ` . When I execute the respective command from the log file ; `salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd`; (and also `salmon index ...` on different data) the error is `Segmentation fault (core dumped)`. Any idea what goes wrong here? . *Aditional info*; * Which version of salmon was used? 0.10.2; * How was salmon installed? Compiled; * Which reference (e.g. transcriptome) was used? samples provided in the sample_data folder ; * Which read files were used? samples provided in the sample_data folder ; * OS: Ubuntu 16 (have to stick to the old version due to group policy) ; * output of `uname -a` : Linux AGRadWS1 4.15.0-24-generic #26~16.04.1-Ubuntu SMP Fri Jun 15 14:35:08 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux; * and `lsb_release -a`: ; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 16.04.4 LTS; Release:	16.04; Codename:	xenial",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250:182,message,message,182,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250,1,['message'],['message']
Integrability,"Hi,. first of all congratulations on a great tool, the expansion to scRNA-seq analysis is especially appreciated!. I was wondering what the reason for setting an upper limit on the barcode length in alevin is - would longer barcodes affect the computation in some manner? We are working with barcodes of length 27, which are incompatible with the hardcoded upper barcode length limit [here](https://github.com/COMBINE-lab/salmon/blob/2ebc89c3fa744b8fc8794c9ab538ae50e41c1adc/src/AlevinUtils.cpp#L578). I manually raised the limit on a modified alevin version, and the final output looks as expected, so if there is no risk that I am unaware of, would you consider raising or removing the barcode length limit altogether?. Thank you for you help!. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; alevin. **Describe the bug**; Using the manual barcode and UMI specification with `--end`, `--barcodeLength`, and `--umiLength` fails for barcodes longer than 20 with the error message:; ```; Barcode length (27) was not in the required length range [1, 20].; ```; The barcode length upper limit is hardcoded [here](https://github.com/COMBINE-lab/salmon/blob/2ebc89c3fa744b8fc8794c9ab538ae50e41c1adc/src/AlevinUtils.cpp#L578). **To Reproduce**; In Salmon 1.0.0, run `salmon alevin [...] --end 5 --barcodeLength 27 --umiLength 8` (or any `barcodeLength` value above 20). * Which version of salmon was used? 1.0.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? bioconda; * Which reference (e.g. transcriptome) was used? not relevant; * Which read files were used? not relevant; * Which which program options were used? `--end 5 --barcodeLength 27 --umiLength 8`. **Expected behavior**; Ideally, barcode longer than 20 would be processed as normal. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Mac OS X; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/445:1010,message,message,1010,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/445,1,['message'],['message']
Integrability,"Hi,; I don't want to report a bug, but rather have 2 (unrelated) questions:; Because we don't generate that many RNA-seq data sets, I am using Salmon every now and then. I really like the program (speed!) and the obtained results. - Since I don't use Salmon on a daily basis, I usually have (would like) to update Salmon to its latest release. For these the binaries you (used to) provide are very convenient. I noticed that these are not explicitly linked to anymore on the page `https://github.com/COMBINE-lab/salmon/releases`, although these still are available through [this link](https://github.com/COMBINE-lab/salmon/files/2099291/salmon-latest_linux_x86_64.tar.gz) that is regularly posted on this Github 'forum'. Please note that I learned you favor the Bioconda route for keeping Salmon up to date. Nevertheless, provided it doesn't take too much effort, I would appreciate it very much if you could still make the binaries available. - My 2nd question has to do with some basic QC-ing: I am currently analyzing a set of 96 mouse samples. While running Salmon, I noticed most samples do have a nice percentage of mapped reads (>80%), but I also noticed that for samples this percentage was much lower (<50%).; Q: Is there an easy way of obtaining these numbers (""percent_mapped"") for all samples that were mapped in a Salmon run (without manually reviewing all 96 samples the 'meta_info.json' file)? In other words, how to obtain an 'overall log file'?. Thanks,; Guido",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/252:771,rout,route,771,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/252,1,['rout'],['route']
Integrability,"Hi,; I was skimming through some of the code and other open issues on support for other library (cell barcode/umi) designs. It looks like there is code for supporting inDrop libraries, but I wasn't sure which parameters I'd need to set. I have inDrop v2 libraries that I'd like to process and am just trying to figure out if we'll need to write our own extensions or if there is already code in place that we can test. Related to some of the comments about the best model for UMI correction in #269 ; The inDrop (at least the v2 protocol) is based on the CEL-Seq like chemistry -- which uses (in vitro transcription) IVT for the initial amplification rather than PCR. From what I've seen so far, the 2 main flavors of single cell RNA-Seq library construction chemistry are; 1. CelSeq/inDrop; polyA capture -> Reverse transcription (RT) for 1st strand cDNA synthesis -> 2nd strand synthesis -> IVT (linear) amplification -> fragmentation -> RT again to convert back to cDNA -> final PCR to amplify library and add Illumina adapters. 2. DropSeq/10X; polyA capture -> RT with template switching -> PCR amplification of cDNA -> fragmentation followed by variable library construction (either transposon/Nextera based or more traditional --frag, end repair, a-tail and adapter ligation) -> final PCR to amplify library and add Illumina adapters. Thanks so much!; Julie",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/339:529,protocol,protocol,529,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/339,4,"['adapter', 'protocol']","['adapter', 'adapters', 'protocol']"
Integrability,"Hi,; I'm coming back to salmon after a ""long"" time not using it. I'm a little bit confused with an error message from the last version (0.14.1) when trying to create an index.; The message complains about a non existing file, but the file does exists; and in fact, with old versions of salmon (0.7.2), it does build an index with the exact same command:. ```; [curis@info124 __Index]$ ls; génome.rat_084.fa.gz@ génôme_rat.v_6-0__Ensemble_084/ test/ test.fa. [curis@info124 __Index]$ salmon_0.14.1 index -t test.fa -i test; Version Info: This is the most recent version of salmon.; The file [test.fa] provided for the transcriptome does not appear to exist.[curis@info124 __Index]$ . [curis@info124 __Index]$ salmon_0.9.1 index -t test.fa -i test; Version Info: ### PLEASE UPGRADE SALMON ###; [...]; The file [test.fa] provided for the transcriptome does not appear to exist.[curis@info124 __Index]$ . [curis@info124 __Index]$ salmon_0.7.2 index -t test.fa -i test; Version Info: ### A newer version of Salmon is available. ####; [...]; [2019-08-22 18:11:33.022] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; ```; I guess I'm missing something obvious, due to some change in a previous version of salmon (around 0.9.1 ?), but I do not understand why salmon does not find the file when it is present...; Thanks in advance for any help",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/420:105,message,message,105,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/420,2,['message'],['message']
Integrability,"Hi,; Thank you vey much for explaining the reasons in detail. So, the main challenge in deduplication at the read level is that some reads are aligned to multiple positions, right?. I also have a question regrading the third point. My understanding is that reads that map to the same genomic location and have the same UMI and CB will be treated as PCR duplicates, and only one of such reads will be retained in the deduplication process. Can you elaborate on why ""a UMI from a single gene can come from a range of genomic loci""? Do 3' scRNA-seq protocols also involve CDNA fragmentation?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/574#issuecomment-713083907:546,protocol,protocols,546,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/574#issuecomment-713083907,1,['protocol'],['protocols']
Integrability,"Hi,; This is not an bug, but I'm trying to understand something. I get this message when running salmon quant: ""replaced 53 non-ACGT nucleotides with random nucleotides."" Can you please explain what this means?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/843:76,message,message,76,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/843,1,['message'],['message']
Integrability,"Hi,; When generating an index for the latest human gencode transcriptome (release 35) I noticed this message:; `[2020-11-25 09:42:04.534] [puff::index::jointLog] [warning] Entry with header [ENST00000674361.1|ENSG00000241743.4|OTTHUMG00000022220.5|OTTHUMT00000530527.1|XACT-203|XACT|347561|lncRNA|] was longer than 200000 nucleotides. This is probably a chromosome instead of a transcript.`. Since I don't recall that I have seen this notification before when doing previous analyses, I had a look at this particular transcript. It turns out it indeed has been annotated as a (very long!), but apparently true transcript (a lncRNA):; `Transcript: XACT-203 ENST00000674361.1, Exons: 2, Coding exons: 0, Transcript length: 347,561 bps. Manual annotation (determined on a case-by-case basis) from the Havana project.`; See [here](http://www.ensembl.org/Homo_sapiens/Transcript/Summary?db=core;g=ENSG00000241743;r=X:113616300-114059289;t=ENST00000674361).; ; I realize that this is not really a bug (you have to set such cutoff at some (likely arbitrary??) value), and it applies to only a single human transcript, but considering this case, would it also be OK to set the cutoff to e.g. 400k (instead of 200k)?. Thanks for addressing my curiosity!; Guido. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; - salmon 1.3.0; **To Reproduce**; - I followed [this workflow](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/) but using the latest human gencode files.; **Desktop (please complete the following information):**; - OS: Linux Fedora",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/591:101,message,message,101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/591,1,['message'],['message']
Integrability,"Hi,; this problem was considered in issue 104 and I have been following the instructions given there. I am running Salmon in alignment mode on bam files generated by STAR (unsorted and in transcriptome coordinates). I generated a transcriptome fasta file for Salmon (according to issue 104) with ; gffread -w all_transcripts.fa -g Homo_sapiens.GRCh38.dna.primary_assembly.fa Homo_sapiens.GRCh38.103.gtf; where the two genome files (fa and gtf) were used with STAR. ; When running Salmon with this fasta file, I get the following output and error message:. Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.4.0; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { all_transcripts.fa }; # [ libType ] => { A }; # [ threads ] => { 10 }; # [ alignments ] => { /groups/inah/test_Salmon/4010760_5_mono_S58_L001_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam /groups/inah/test_Sal; mon/4010760_5_mono_S58_L002_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam /groups/inah/test_Salmon/4010760_5_mono_S58_L003_R1_001.fastq_AT; _QT.fastq.gz.STAR_aligned.toTranscriptome.bam /groups/inah/test_Salmon/4010760_5_mono_S58_L004_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.b; am }; # [ output ] => { 4010760_5_mono_S58_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam.salmon_quant }; Logs will be written to 4010760_5_mono_S58_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam.salmon_quant/logs; [2021-03-05 18:20:21.015] [jointLog] [info] setting maxHashResizeThreads to 10; [2021-03-05 18:20:21.015] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; parseThreads = 5; [2021-03-05 18:20:21.314] [jointLog] [info] numQuantThreads = 5; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""/groups/inah/",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/638:546,message,message,546,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/638,1,['message'],['message']
Integrability,"Hi,; would you mind cleaning up the STDOUT and STDERR output from `salmon quant` and `salmon index`? Commonly `STDOUT` should be used for normal output messages and `STDERR` for errors or at worst warnings. Salmon writes most of the messages to `STDERR`. 1. `Version Info: This is the most recent version of Salmon.` is output to `STDOUT`. I find it useless. If salmon run some network connection to figure out its version it is `a)` prone to errors, `b)` I would expect a fat warning in the documentation a `phone home` feature is builtin, `c)` it is likely to fail on more network-restricted installations. Or, `d)`, the message is incorrect. I suggest drop the message altogether. 2. `salmon quant` writes a lot of normal messages to `STDERR`. Please use `STDOUT` instead. If a program exits with a non-zero exit code it is common to read its `STDERR` output to learn what was the cause for the error. It is awkward to realize there is lots of unrelated text. Please follow common rules on Unix. 3. The docs at http://salmon.readthedocs.io/en/latest/salmon.html did not mention the `fmd` index is just a plain index from `bwa`. Why don't you instruct users to use `bwa index` instead? It would be clearer (if that is the type of index you employ). 4. `salmon index` behavior. ```; salmon index -t Homo_sapiens.GRCh38.cdna.all.fa -i Homo_sapiens.GRCh38.cdna.all --type quasi -k 31; index [""Homo_sapiens.GRCh38.cdna.all""] did not previously exist . . . creating it; [2018-06-25 19:25:57.122] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; [2018-06-25 19:25:57.176] [jointLog] [warning] Entry with header [ENST00000434970.2], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-06-25 19:25:57.176] [jointLog] [warning] Entry with header [ENST00000448914.1], had length less than the k-mer length of 31 (perhaps after poly-A clipping); ...; [2018-06-25 19:26:07.297] [jointLog] [warning] Entry with header [ENST00000579054.1], had length l",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/242:152,message,messages,152,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/242,5,['message'],"['message', 'messages']"
Integrability,"Hi. I have a general question pertaining to quantifying QuantSeq data and comparing Salmon vs the alignment methods recommended by Lexogen (Star/Bowtie followed by htseq to get read counts per gene). Has anyone compared the 2 methods - would be very interested to know the findings. [I happen to see this issue which is still stated as ""Open""](https://github.com/COMBINE-lab/salmon/issues/108) - probably it should be marked as Closed?. . Based on the above issue and also [this issue](https://github.com/COMBINE-lab/salmon/issues/177), I assume using `--noLengthCorrection` would be the recommended way to use Salmon for quantifying QuantSeq data - is that right?. In general, I am planning to use Salmon this way:. 1. index the transcriptome; 2. `salmon quant -i {input.index} -l A -1 {input.R1} -2 {input.R2} -o {output} --noLengthCorrection --validateMappings --gcBias --seqBias --posBias`. While using Salmon for quantification, are there any subtleties to be aware of based on the QuantSeq protocol (FWD vs REV) ?. Please advise. Thanks in advance,",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/365:996,protocol,protocol,996,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/365,1,['protocol'],['protocol']
Integrability,"Hi:; Recently, I learned to use salmon in our lncRNA research project. I am confused in a point. ; As shown in the documentation (https://salmon.readthedocs.io/en/latest/salmon.html), according to our understanding, if we want those incompatible mappings will be discarded, the incompatPrior should be set as 0.0. And our RNA-Seq library type is dUTP based strand-specific RNA-Seq, so we should use ISR. ; But I am confused with https://gitter.im/COMBINE-lab/salmon?at=594a76d402c480e67268f02b and https://github.com/COMBINE-lab/salmon/issues/116; we want the expression level of antisense. Since there are about 0.5~1% reads can be the wrong reads mapped to the reverse strand of the gene (dUTP stranded protocol, the strand error (i.e. % of reads sequenced from the wrong strand of the RNA) is typically 0.5-1%). Can we use the incompatPrior option and get the expression level of antisense(right) in a single run?; This is our command line `salmon quant -i Ath_TX.index -l ISR -1 test_R1.fq.gz -2 test_R2.fq.gz -o TEST_TX_QUANT --incompatPrior 0.0 --seqBias --gcBias --threads 20`.; That those wrong mapped alignments (they didn't follow the ISR fule, maybe the error from the error of process of library construction) will be discarded.; Thank you and all the best.; Linhua",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/182:705,protocol,protocol,705,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/182,1,['protocol'],['protocol']
Integrability,Holy cloud-computing charges! I'm sorry to hear about this. We can certainly rate-limit this message. I'll work on fixing this upstream. Sorry for the trouble.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-328981463:93,message,message,93,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-328981463,1,['message'],['message']
Integrability,How do I apply the custom length settings if I am utilizing the wrapper for v1 10x data? I have v1 data that has a 5bp instead of 10bp UMI but everything else is the same. Can i just add `--umiLength 5`?; Data:; [https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/cd14_monocytes](url),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-418803087:64,wrap,wrapper,64,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-418803087,1,['wrap'],['wrapper']
Integrability,"I actually think that (as @mr-c points out), the `config.h` file isn't necessary with newer versions of Jellyfish. I'm removing the dependency upstream.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195644865:132,depend,dependency,132,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195644865,1,['depend'],['dependency']
Integrability,I am also seeing this. The most highly estimated and shortest isoform of KIT has no supporting read but a TPM of 40. ![image](https://github.com/COMBINE-lab/salmon/assets/631218/f250e8cd-3f99-4fcb-8032-bc1897ca9322). Using DRAGEN RNA version 4.2.4 which I think wraps Salmon. In any of your BAM files?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/133#issuecomment-2048928795:262,wrap,wraps,262,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/133#issuecomment-2048928795,1,['wrap'],['wraps']
Integrability,"I am encountering two issues when I follow the instructions for installing salmon 1.10.1:https://salmon.readthedocs.io/en/latest/building.html#installation; I am installing on a mac studio (M2 max) running Ventura. . The first issue I run into is that my understanding of the instructions suggests that I should be in the ""build"" directory when I run cmake. However, if I do that it returns an error about CMakeLists.txt not being in that location. I noticed that is in the salmon directory so I ran cmake from there and it seemed to work fine. But, I'm not sure if that is leading to the problems I am having downstream. . The second issue is when I run make I get an error associated with configuring liblzma (error 77). I have pasted the console log below. I appreciate any suggestions and apologize if I missed something obvious. . This file contains any messages produced by compilers while; running configure, to aid debugging if configure makes a mistake. It was created by XZ Utils configure 5.2.2, which was; generated by GNU Autoconf 2.69. Invocation command line was. $ /Users/jeremybono/Downloads/salmon-1.10.1/external/xz-5.2.2/configure --prefix=/Users/jeremybono/Downloads/salmon-1.10.1/external/install CC=/Library/Developer/CommandLineTools/usr/bin/cc CXX=/Library/Developer/CommandLineTools/usr/bin/c++ CFLAGS= CPPFLAGS= LDFLAGS=. ## --------- ##; ## Platform. ##; ## --------- ##. hostname = Jeremys-Mac-Studio.local; uname -m = arm64; uname -r = 22.6.0; uname -s = Darwin; uname -v = Darwin Kernel Version 22.6.0: Wed Jul 5 22:21:53 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T6020. /usr/bin/uname -p = arm; /bin/uname -X = unknown. /bin/arch = unknown; /usr/bin/arch -k = unknown; /usr/convex/getsysinfo = unknown; /usr/bin/hostinfo = Mach kernel version:; 	 Darwin Kernel Version 22.6.0: Wed Jul 5 22:21:53 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T6020; Kernel configured for up to 12 processors.; 12 processors are physically available.; 12 processors are logically ava",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/912:859,message,messages,859,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/912,1,['message'],['messages']
Integrability,"I am intending to run salmon on a set of RNA-Seq data lying in our lab for a long time. They are for mm9 and since there are >50 samples I was intending to run it using Salmon `version : 0.6.0`. I have used earlier versions of salmon on hg19 data from both UCSC, NCBI (spiked-in and non-spiked in data) without alignment mode and have run them successfully. Recently we were able to download the latest version and compile and trying to run the indexing on the UCSC mm9 genome.fa file so that I can use quasi-mapping indexes that can be then used to run quant for my samples downstream so getting read counts as well as TPM much faster than any other tool. Can you tell me what is the problem. . Command line used; `salmon index -t /path_to/genome.fa -i salmonquasi-indexes --type quasi -k 31`. Here is the error message while using the Ram-Map. ```; Version Info: This is the most recent version of Salmon.; index [""salmonquasi-indexes""] did not previously exist . . . creating it; [2016-03-17 10:41:34.655] [jointLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; Elapsed time: 53.9731s. Replaced 96385738 non-ATCG nucleotides; Clipped poly-A tails from 0 transcripts; Building rank-select dictionary and saving to disk done; Elapsed time: 0.196609s; Writing sequence data to file . . . done; Elapsed time: 1.56391s; [info] Building 64-bit suffix array (length of generalized text is 2654911539 ); Building suffix array . . . success; saving to disk . . . done; Elapsed time: 126.003s; done; Elapsed time: 883.472s; processed 615000000 positionssalmon: /home/vagrant/salmon/external/install/include/sparsehash/internal/densehashtable.h:782: void google::dense_hashtable<Value, Key, HashFcn, ExtractKey, SetKey, EqualKey, Alloc>::clear_to_size(google::dense_hashtable<Value, Key, HashFcn, ExtractKey, SetKey, EqualKey, Alloc>::size_type) [with Value = std::pair<const long unsigned int, rapmap::utils::SAInterval<long int> >; Key = long unsigned int; HashFcn = rapmap::utils",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/49:813,message,message,813,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/49,1,['message'],['message']
Integrability,"I am running salmon and I am getting this error. . ### salmon (mapping-based) v0.13.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 5 }; ### [ index ] => { ~/CellNet/CellNetLocal/ref/salmon.index.mouse.052617.tgz }; ### [ libType ] => { U }; ### [ unmatedReads ] => { subset_SRR2070946_trimmed.fq }; ### [ output ] => { salmonRes_SRR2070946 }; Logs will be written to salmonRes_SRR2070946/logs; [2024-02-28 02:07:19.419] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2024-02-28 02:07:19.419] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2024-02-28 02:07:19.419] [jointLog] [info] parsing read library format; [2024-02-28 02:07:19.419] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file ~/CellNet/CellNetLocal/ref/salmon.index.mouse.052617.tgz/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; ~/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try ~/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; ./salmonRes_SRR2070926/quant.sf ; Error in file(file, ""rt"") : cannot open the connection; In addition: Warning message:; In file(file, ""rt"") :; cannot open file './salmonRes_SRR2070926/quant.sf': No such file or directory. I can see versionInfo.json in the salmon.index.mouse.052617.tgz. I am not sure why it can not see it.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/914:1683,message,message,1683,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/914,1,['message'],['message']
Integrability,"I am running salmon as part of a pipeline and this error message is being displayed:. running salmon quant...; Version Server Response: Not Found; exception : [unrecognised option '--biasCorrect']. Exiting.; pipeline failed at expression quantification!. Here are the options which the script uses: ; salmon quant -t ${transcript_fa} ${ltype} -a ${rna_bam} -o ${sm_odir} -p $nproc --biasCorrect; check_file ${sm_out} ""pipeline failed at expression quantification!"". I have the latest version of salmon installed.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/873:57,message,message,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/873,1,['message'],['message']
Integrability,"I am trying to quantify these data at the transcript level which is why the number of features is this big. For the PBMC3k I was trying with a transcript to gene --tgMap but was still seeing the same error. I realized I forgot to update the path to the run.sh script when calling the 0.12.0 binary (I updated the path to the binary but no to the script). When running the wrapper in the 0.12.0 folder I could succesfully run alevin on the CD14 dataset, with or without the --forceCells 4000 flag. I tried to run alevin-0.12.0 on the PBMC 3k dataset but I got the same error. I am now trying to run it on all the FACS-sorted samples and I will see how that goes. I feel this is happening slightly inconsistently (although very frequently). Notably, it either happens after `Clearing EqMap; Might take some time.` or `Starting Import of the gene count matrix of size 5344x167268.`. I have had it happen once in the middle of the `Analyzed xxx cells (yy% of all)` phase. I just managed to succesfully process the CD19+ B cells from the 10x v1 dataset, I'll attempt to process the other FACS sorted samples overnight and let you know how it went. Thank you",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445109075:372,wrap,wrapper,372,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445109075,1,['wrap'],['wrapper']
Integrability,"I appreciate to your answer.; Thanks a lot; ; ; Ki-Wook Lee; Student; Department of Integrative Biotechnology; College of Biotechnology & Bioengineering; Sungkyunkwan University; Biotechnology and Bioengineering Building 2, Rm 62156; 2066 Seobu-ro, Jangan-gu, Suwon, Gyeonggi, 16419, Republic of Korea; Tel: +82-10-5580-1770 Fax:+82-31-290-7870; ; -----Original Message-----; From: ""Anthony S. ***@***.***>; To: ***@***.***>;; Cc: ***@***.***>; ***@***.***>;; Sent: 2021-06-09 (수) 05:16:26 (GMT+09:00); Subject: Re: [COMBINE-lab/salmon] Quant.sf index issue (#640); ; Not affiliated with the Salmon team, but since you didn't get an answer here...; When building an index with transcriptomes from Gencode, you should pass the flag ""--gencode"" to the indexer. This allows salmon to split the record names on the | character and gives you the expected ""ENST00000456328.2 or ENSG00000223972.5"" style names.; —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub, or unsubscribe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/640#issuecomment-857337814:84,Integrat,Integrative,84,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/640#issuecomment-857337814,2,"['Integrat', 'Message']","['Integrative', 'Message']"
Integrability,"I built salmon 0.7.2 on OSX 10.13.3, then ran 'make test'. Test #1 fails, other two succeed. Looking at file Testing/Temporary/LastTest.log, it says:. ```; ""unit_tests"" start time: Mar 03 20:31 PST; Output:; ----------------------------------------------------------; CMake Error at /Users/tedtoal/src/salmon-0.7.2/cmake/UnitTests.cmake:7 (message):; Error running No such file or directory. ```. I looked in the tests directory and find program ""unitTests"", and when I run it, it succeeds:. ```; ===============================================================================; All tests passed (158 assertions in 4 test cases). ```. leading me to believe that actually, test1 succeeds, but something is wrong with the test system and it doesn't see that it succeeded.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/204:340,message,message,340,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/204,1,['message'],['message']
Integrability,I can try that later today. Does your list of installed dependencies look different?. The thing that's strange about this is that the main motivation for releasing 1.10 was a discovery of an intermittent segfault due to UB at exactly this spot. But that was resolved in the associated tagged pufferfish upstream and checked further with both valgrind and asan.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463629042:56,depend,dependencies,56,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463629042,1,['depend'],['dependencies']
Integrability,"I cloned salmon v1.8.0 and tried to install it on my server. However, when I run make I receive an error at the final step ""Linking CXX executable salmon"". The error. `[100%] Linking CXX executable salmon; /usr/bin/ld: ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): in function `find_file_url':; open_trace_file.c:(.text+0xf4e): warning: the use of `tempnam' is dangerous, better use `mkstemp'; during IPA pass: icf; lto1: internal compiler error: Segmentation fault; Please submit a full bug report,; with preprocessed source if appropriate.; See <file:///usr/share/doc/gcc-9/README.Bugs> for instructions.; lto-wrapper: fatal error: /usr/bin/c++ returned 1 exit status; compilation terminated.; /usr/bin/ld: error: lto-wrapper failed; collect2: error: ld returned 1 exit status; make[2]: *** [src/CMakeFiles/salmon.dir/build.make:454: src/salmon] Error 1; make[1]: *** [CMakeFiles/Makefile2:663: src/CMakeFiles/salmon.dir/all] Error 2; make: *** [Makefile:163: all] Error 2`. Prior to this step, I ran cmake as follows:. `cmake -DFETCH_BOOST=TRUE -DTBB_INSTALL_DIR= ~/anaconda3/pkgs/tbb-2021.5.0-hd09550d_0/ -DCMAKE_INSTALL_PREFIX= ~/salmon/`. OS: Ubuntu Linux 20.04",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/778:648,wrap,wrapper,648,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/778,2,['wrap'],['wrapper']
Integrability,"I do have an explanation. The data was generated using an rRNA-depletion protocol. From what I've seen elsewhere, it turns out that the mapping rate is expected to be 30-40% because many of the reads are intronic, or otherwise map outside the known transcriptome, since you have all non-rRNA (PolyA+ and PolyA-). Hope that helps! Happy Easter!. > On Mar 27, 2016, at 09:31, Rob Patro notifications@github.com wrote:; > ; > Great; one thing I did notice is that the mapping rates for this data seemed surprisingly low. I don't think that's related to the NaNs you were seeing, but it did catch my attention, since we don't normally see mapping rates like that. Is there a hypothesis why this may be the case (e.g. it's not just Salmon's quasi-mapping, the mapping rate remains the same (or even becomes lower) when I use an aligner)?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly or view it on GitHub",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-202127752:73,protocol,protocol,73,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-202127752,1,['protocol'],['protocol']
Integrability,"I don't know how difficult it would be to use PCRE2, I have never used it directly. Can we write a thin struct wrapper structure that is defined as the boost object by default, but with` #ifdef ` can be implemented by PCRE2 if we wish? (well, if cmake finds pcre2). Keeping with boost, we should also try https://www.boost.org/doc/libs/1_78_0/doc/html/xpressive.html . That does not add a new dependency. Don't know about the speed.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023366519:111,wrap,wrapper,111,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023366519,2,"['depend', 'wrap']","['dependency', 'wrapper']"
Integrability,"I don't really have a feel for the RAW and BAM interfaces for Salmon `quant`, but given that they have different help screens and usage, maybe consider splitting them into separate commands?. This is just a minor suggestion, coming from a n00b user of Salmon.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/75:47,interface,interfaces,47,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/75,1,['interface'],['interfaces']
Integrability,I get the following error when installing `salmon`:. ```; cd /var/tmp/sjackman/salmon20150803-27338-1qoka2g/salmon-0.4.2/external && /gsc/btl/linuxbrew/Cellar/cmake/3.3.0/bin/cmake -P /var/tmp/sjackman/salmon20150803-27338-1qoka2g/salmon-0.4.2/libcereal-prefix/src/libcereal-stamp/extract-libcereal.cmake; -- extracting...; src='/var/tmp/sjackman/salmon20150803-27338-1qoka2g/salmon-0.4.2/external/cereal-v1.0.0.tgz'; dst='/var/tmp/sjackman/salmon20150803-27338-1qoka2g/salmon-0.4.2/external/cereal-1.0.0'; -- extracting... [tar xfz]; CMake Error: Problem with archive_write_finish_entry(): Can't restore time; CMake Error: Problem extracting tar: /var/tmp/sjackman/salmon20150803-27338-1qoka2g/salmon-0.4.2/external/cereal-v1.0.0.tgz; -- extracting... [error clean up]; CMake Error at /var/tmp/sjackman/salmon20150803-27338-1qoka2g/salmon-0.4.2/libcereal-prefix/src/libcereal-stamp/extract-libcereal.cmake:33 (message):; error: extract of; '/var/tmp/sjackman/salmon20150803-27338-1qoka2g/salmon-0.4.2/external/cereal-v1.0.0.tgz'; failed; ```. Is it possible to compile `salmon` with its external dependencies provided externally rather than vendored into `salmon`? What is `cereal`?,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10:911,message,message,911,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10,2,"['depend', 'message']","['dependencies', 'message']"
Integrability,"I have been trying to use the salmon docker container available on docker hub. When I run salmon quant I am able to load all of the files and start the program, but I get a killed message while loading hash. I get an empty log file and empty folders created after the container is killed. **To Reproduce**; I run the following command to run the container:; `docker run -v /Users/caz3so/workspaces/salmon_docker:/temp -w /temp -ti combinelab/salmon`. The following is the output:; <img width=""1389"" alt=""screenshot 2018-06-27 11 15 56"" src=""https://user-images.githubusercontent.com/31480706/41983246-8296bb76-79fb-11e8-9710-c38ec051b7e7.png"">. **Expected behavior**; I have salmon installed on my machine and was able to run these files with no problem. It is only when I am using the docker container, so it could be a docker related problem. . **Desktop (please complete the following information):**; I am using a 2017 Macbook pro with 16 GB 2133 MHz LPDDR3 memory and a 2.8 GHz Intel Core i7 processor.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/243:180,message,message,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/243,1,['message'],['message']
Integrability,"I have single ended reads in a fastq file which I aligned with bowtie against the transcriptome. Now I am running the following command:; ./bin/salmon quant -t ../Data/DRR029379.fq -p 6 -l A -a ../Data/DRR029379_after_bowtie.bam -o ../Data/DRR029379_after_salmon; and this the error I am getting. Version Info: This is the most recent version of Salmon.; # salmon (alignment-based) v0.7.2; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { ../Data/DRR029379.fq }; # [ threads ] => { 6 }; # [ libType ] => { A }; # [ alignments ] => { ../Data/DRR029379_after_bowtie.bam }; # [ output ] => { ../Data/DRR029379_after_salmon }; Error: @RG lines are at odds with binary encoded reference data; ============; Exception : [ERROR: Failed to open file ../Data/DRR029379_after_bowtie.bam, exiting!; ]; ============; ./bin/salmon alignment-quant was invoked improperly.; For usage information, try ./bin/salmon quant --help-alignments; Exiting. I cannot figure out anything from this message. Please help. Thank you",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/113:991,message,message,991,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/113,1,['message'],['message']
Integrability,I have the same issue. But doing 'cmake -DFETCH_BOOST=TRUE ..' or 'cmake ..' gives the same error message 'does not appear to contain CMakeLists.txt'. I downloaded version 'salmon-0.12.0_linux_x86_64'.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/139#issuecomment-449017473:98,message,message,98,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/139#issuecomment-449017473,1,['message'],['message']
Integrability,"I have updated my homebrew index and installed Salmon on my Macbook (0S X Sierra). However, when I run `salmon` or `salmon -h` on the command line I get the following error message. ```; salmon(41538,0x7fffc4f5a3c0) malloc: *** malloc_zone_unregister() failed for 0x7fffc4f50000; ```. `brew doctor` doesn't show any unexpected issues. Any ideas what might be going on?. Thanks!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/142:173,message,message,173,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/142,1,['message'],['message']
Integrability,I haven't kept up with khmer so I'm not sure what it does. Can I do something equivalent of this with khmer?. ```; mkfifo /tmp/1.fastq && \; mkfifo /tmp/2.fastq && \; samtools sort -n input.cram | samtools fastq -1 /tmp/1.fastq -2 /tmp/2.fastq & salmon -i index -l IU -1 /tmp/1.fastq -2 /tmp/2.fastq -o /tmp/salmon_out && \; mv /tmp/salmon_out && \; rm /tmp/1.fastq && \; rm /tmp/2.fastq; ```. I just want to be able to do these sorts of things without wrapper scripts that obfuscate and complicate things... But maybe a robust bash wrapper is the best way to go.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168534703:453,wrap,wrapper,453,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168534703,2,['wrap'],['wrapper']
Integrability,"I just conda installed salmon fresh. I got error when I ran it. . ```; $ conda create -n salmon salmon; Collecting package metadata (current_repodata.json): done; Solving environment: done. ## Package Plan ##. environment location:~/miniconda3/envs/salmon. added / updated specs:; - salmon. The following NEW packages will be INSTALLED:. _libgcc_mutex conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge; _openmp_mutex conda-forge/linux-64::_openmp_mutex-4.5-1_gnu; bzip2 conda-forge/linux-64::bzip2-1.0.8-h7f98852_4; icu conda-forge/linux-64::icu-64.2-he1b5a44_1; jemalloc conda-forge/linux-64::jemalloc-5.2.1-h9c3ff4c_5; libgcc-ng conda-forge/linux-64::libgcc-ng-9.3.0-h2828fa1_18; libgomp conda-forge/linux-64::libgomp-9.3.0-h2828fa1_18; libstdcxx-ng conda-forge/linux-64::libstdcxx-ng-9.3.0-h6de172a_18; salmon bioconda/linux-64::salmon-1.4.0-hf69c8f4_0; tbb conda-forge/linux-64::tbb-2021.1.1-h4bd325d_1; zlib conda-forge/linux-64::zlib-1.2.11-h516909a_1010. Proceed ([y]/n)? y. Preparing transaction: done; Verifying transaction: done; Executing transaction: done; #; # To activate this environment, use; #; # $ conda activate salmon; #; # To deactivate an active environment, use; #; # $ conda deactivate. $ conda activate salmon; $ salmon; salmon: symbol lookup error: salmon: undefined symbol: _ZN3tbb8internal24concurrent_queue_base_v818internal_push_moveEPKv; ```. I think this is related with rob-p commented on Sep 22, 2020. ; I have a naive question: Is it possible to fix this in the recipe by adding the problematic dependencies?; I am using centOS 8.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-805608173:1532,depend,dependencies,1532,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-805608173,1,['depend'],['dependencies']
Integrability,"I just noticed there is something wrong with my input file, sorry for my mistake. . The basic question stays the same: Are unmated reads supported by Alevin? Is there a single-cell protocol that produces 'single-end' files?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/522#issuecomment-632647047:181,protocol,protocol,181,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/522#issuecomment-632647047,1,['protocol'],['protocol']
Integrability,"I just tried it on a fresh docker image of ubuntu 16.04 and am unable to install salmon. After `apt-get install build-essential cmake g++ gcc curl autoconfig libdevsufsort-dev`, `cmake -DFETCH_BOOST=TRUE` passes, but `make install` fails with following output:; ```; [ 6%] Built target liblzma; [ 12%] Built target libbz2; [ 18%] Built target libjemalloc; [ 19%] Performing download step (verify and extract) for 'libdivsufsort'; -- verifying file...; file='/home/salmon-0.10.2/external/libdivsufsort.zip'; -- verifying file... warning: did not verify file - no URL_HASH specified?; -- extracting...; src='/home/salmon-0.10.2/external/libdivsufsort.zip'; dst='/home/salmon-0.10.2/external/libdivsufsort-master'; CMake Error at /home/salmon-0.10.2/libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake:11 (message):; error: file to extract does not exist:; '/home/salmon-0.10.2/external/libdivsufsort.zip'. CMakeFiles/libdivsufsort.dir/build.make:90: recipe for target 'libdivsufsort-prefix/src/libdivsufsort-stamp/libdivsufsort-download' failed; make[2]: *** [libdivsufsort-prefix/src/libdivsufsort-stamp/libdivsufsort-download] Error 1; CMakeFiles/Makefile2:137: recipe for target 'CMakeFiles/libdivsufsort.dir/all' failed; make[1]: *** [CMakeFiles/libdivsufsort.dir/all] Error 2; Makefile:160: recipe for target 'all' failed; make: *** [all] Error 2; ```; It confuses me, as the error seems to be in the libdevsufsort, which should be installed.; (sorry for all the mess, really)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404455397:824,message,message,824,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404455397,1,['message'],['message']
Integrability,"I mean the additional barcodes you can get with this protocol if people use CITE-seq like approaches, see https://www.10xgenomics.com/solutions/single-cell/. . On 18 June 2019 23:53:55 BST, Avi Srivastava <notifications@github.com> wrote:; >Hi @pinin4fjords ,; >; >Thanks for the question, do you mean the longer UMI/CB length or you; >are talking about some other feature ?; >; >; >; >-- ; >You are receiving this because you were mentioned.; >Reply to this email directly or view it on GitHub:; >https://github.com/COMBINE-lab/salmon/issues/381#issuecomment-503341361. -- ; Sent from my Android device with K-9 Mail. Please excuse my brevity.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/381#issuecomment-503442543:53,protocol,protocol,53,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/381#issuecomment-503442543,1,['protocol'],['protocol']
Integrability,"I ran salmon alevin 0.14.0 with a custom transcriptome reference and the following options: --chromium --dumpFeatures --dumpMtx --whitelist mylist.txt. Everything ran through OK. However, when I tried to load the .mtx file with readMM() in R, I got the error: ; ` Error: readMM(): column values 'j' are not in 1:nc `. When I tried to read directly the binary file into a matrix, there's a warning:; ```; counts <- readBin(quants_mat.gz, what = 'numeric', n = length(genes)*length(cells)); close.connection(quants_mat.gz); Warning message:; In matrix(data = counts, nrow = length(cells), ncol = length(genes), :; data length [391335] is not a sub-multiple or multiple of the number of rows [4942]; ```; It seems like there's issue with the dimensions; [out.zip](https://github.com/COMBINE-lab/salmon/files/3296080/out.zip); of the output matrix. I've attached my log file as well as my output files (both .mtx and binary). Thank you.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/380:530,message,message,530,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/380,1,['message'],['message']
Integrability,"I realize my mistake, I was confused by the error message.; Pseudoaligment seems to work now. [...]; [2018-08-03 20:13:23.083] [jointLog] [info] Computed 312565 rich; equivalence classes for further processing; [2018-08-03 20:13:23.083] [jointLog] [info] Counted 120065952 total; reads in the equivalence classes; [2018-08-03 20:13:23.084] [jointLog] [warning] Found 9775 reads with `N`; in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-08-03 20:13:23.084] [jointLog] [info] Mapping rate = 63.2442%. [2018-08-03 20:13:23.084] [jointLog] [info] finished quantifyLibrary(); [2018-08-03 20:13:26.208] [alevinLog] [info] Starting optimizer. ERROR: Txp to Gene Map not found for 203027 transcripts. Exiting(salmon). I just have a problem with my tx2gene file. Here is the head of my file:. ENST00000013125	MAP4K5; ENST00000215368	EFNA2; ENST00000200453	PPP1R15A; ENST00000202028	EPB41L1; ENST00000204679	GNPTG; ENST00000175506	ASNS; ENST00000215574	CDC34; ENST00000167106	VASH1; ENST00000074304	INPP4A; ENST00000055077	RFC2. The transcript ID is probably not consistent with the one from the; alevin output. However, I used to perform some pseudo-alignments using; salmon on bulk RNAseq with the same transcriptome references and the; same tx2gene file that I used here (postprocessed using R) and it work.; What could be wrong here? Could you provide me with an example of the; tx2gene file needed?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410337209:50,message,message,50,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410337209,1,['message'],['message']
Integrability,I recently debugged an issue of low mapping rate which turned out to be due to the reads in the forward and reverse paired FASTQ files being sorted in different orders. Maybe there could be a warning message written out if e.g. the headers in the first read pairs are mismatched?,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/151:200,message,message,200,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/151,1,['message'],['message']
Integrability,"I recently upgraded to v0.9.1 and am analyzing 2x75 total RNA. The kit is stranded with the first read originating from the reverse strand, thus I specified the libType as ISR. Command used to invoke salmon quant:. ```; salmon quant -i /home/benjohnson/Documents/references/hg19/salmon/salmon_hg19 -1 $pair1 -2 $pair2 -o $SAMPLE --seqBias --gcBias -p 28 --useVBOpt --numBootstraps 100 -l ISR; ```. Output following invocation:. ```; ### salmon (mapping-based) v0.9.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/benjohnson/Documents/references/hg19/salmon/salmon_hg19 }; ### [ mates1 ] => { GO537F1_L000_R1_001.fastq.gz }; ### [ mates2 ] => { GO537F1_L000_R2_001.fastq.gz }; ### [ output ] => { GO537F1 }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ threads ] => { 28 }; ### [ useVBOpt ] => { }; ### [ numBootstraps ] => { 100 }; ### [ libType ] => { ISR }; ```. Warning received about strand bias in library:. ```; Detected a *potential* strand bias > 1% in an unstranded protocol check the file: GO537F1/lib_format_counts.json for details; ```. lib_format_counts.json output:. ```; {; ""read_files"": ""( GO537F1_L000_R1_001.fastq.gz, GO537F1_L000_R2_001.fastq.gz )"",; ""expected_format"": ""IU"",; ""compatible_fragment_ratio"": 0.997983099568402,; ""num_compatible_fragments"": 18521739,; ""num_assigned_fragments"": 18559171,; ""num_consistent_mappings"": 44944769,; ""num_inconsistent_mappings"": 16315669,; ""strand_mapping_bias"": 0.97668914484798,; ""MSF"": 0,; ""OSF"": 3095,; ""ISF"": 1047701,; ""MSR"": 0,; ""OSR"": 139809,; ""ISR"": 43897068,; ""SF"": 3206477,; ""SR"": 12956987,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```. I'm a bit confused as to whether this is normal behavior and not impacting output (I haven't necessarily investigated if this is the case) or if it is ignoring my ISR option. I've tried using -l as ISR; ""ISR"" and also with --libType ISR; ""ISR"" with the same output. . Thanks for your time!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/187:1018,protocol,protocol,1018,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/187,1,['protocol'],['protocol']
Integrability,"I suspect you're running this on a Mac, correct? ; I had the same issue, Salmon would index for the better part of a day, use ~30 gb of swap space, then die (killed 9 message). The versionInfo.json error is slightly misleading, most likely what happened is that the indexing didn't finish and since that file is only created if it finishes correctly, that's the error you get.; Running the indexing with the same code, with similar resources completed on our AWS node so I wonder if this is a Mac specific problem...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/559#issuecomment-738480434:167,message,message,167,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/559#issuecomment-738480434,1,['message'],['message']
Integrability,"I tested changing the parameters, and I am still getting the same error message:. ```; [2021-07-08 16:05:50.979] [alevinLog] [info] Done importing white-list Barcodes; [2021-07-08 16:05:50.979] [alevinLog] [error] Wrong whitelist provided; Please check https://salmon.readthedocs.io/en/develop/alevin.html#whitelist; ```. However, I will look into the other information and see if I can understand what is happening. I can also test not using a white list and see if that changes the number to be something like an order of magnitude different that what I would expect from the other sample. So, I will post an update when I can run alevin without an error message, and try to give some sense of the results that are quantified.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-877303669:72,message,message,72,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-877303669,2,['message'],['message']
Integrability,"I think something like this (like samtools, kallisto etc. ```; salmon v0.6.0 - description here. Usage: salmon <COMMAND> [-h | options]. Commands:; index Create a salmon index; quant Count blah; swim Whatever; ```. would be _much_ clearer than the current help. ```; salmon --help; Allowed Options:; -v [ --version ] print version string; --no-version-check don't check with the server to see if this is the; latest version; -h [ --help ] produce help message. Salmon v0.6.0; ===============. Please invoke salmon with one of the following commands {index, quant, swim}.; For more information on the options for these particular methods, use the -h; flag along with the method name. For example:. salmon index -h. will give you detailed help information about the index command.; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/72:452,message,message,452,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/72,1,['message'],['message']
Integrability,"I think that's the right binary. You can check the sha256 sum:. ```; rob at Robs-MacBook-Pro in ~/Salmon-0.8.2_macOX_10.12; $ shasum -a256 bin/salmon; 7be1c57e1a83956cc9c18f75aed3b2376c93595de7dec215041fe3065528b527 bin/salmon; ```. You can also check the libraries that `salmon` is seeing:. ```; rob at Robs-MacBook-Pro in ~/Salmon-0.8.2_macOX_10.12; $ otool -L bin/salmon; 	bin/salmon:; 	/usr/lib/libz.1.dylib (compatibility version 1.0.0, current version 1.2.8); 	/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1238.0.0); 	/usr/lib/libbz2.1.0.dylib (compatibility version 1.0.0, current version 1.0.5); 	@rpath/libtbbmalloc_proxy.dylib (compatibility version 0.0.0, current version 0.0.0); 	@rpath/libtbbmalloc.dylib (compatibility version 0.0.0, current version 0.0.0); 	@rpath/libtbb.dylib (compatibility version 0.0.0, current version 0.0.0); 	/usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 307.4.0); ```. but, again, the library of interest with respect to this message (jemalloc) is linked statically. Out of curiosity, is this message a warning or error (i.e. does salmon run or return a non-zero exit code). The message you're seeing is actually expected if jemalloc was compiled without debug mode turned off (because apple did some funny business with the allocator in OS X 10.12).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-294852033:1018,message,message,1018,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-294852033,3,['message'],['message']
Integrability,I tried re-installing salmon today after seeing your message. A simple `conda install salmon` worked for me this time. I don't know why it was giving me an error back then and not one now though....,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1137154359:53,message,message,53,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1137154359,1,['message'],['message']
Integrability,"I tried this again today with salmon 1.2.1 on CentOS 8 (with cmake 3.17.1). This time it could find libtbb but it still could not find Staden IO_LIB and libgff. In addition for it to use Boost169 it was necessary to modify the CmakeLists.txt file like so. ```; --- CMakeLists.txt.dist 2020-04-21 22:31:07.000000000 -0700; +++ CMakeLists.txt 2020-06-08 17:13:23.295499154 -0700; @@ -419,6 +419,8 @@; find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); +message(""Forcing Boost_FOUND to TRUE""); +set(Boost_FOUND TRUE); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; ```. and to invoke cmake with:. ```; module load cmake; module load io_lib; module load libgff; module load libtbb; mkdir build; cd build; cmake \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_08.log; ```; Inkscape was built using cmake a couple of weeks ago on the same system and the -D flags for Boost in the cmake invocation were sufficient, there was no need to modify its CMakeLists.txt. Perhaps you might to compare that CMakeLIsts.txt with salmon's to see why theirs works and salmon's does not. I reiterate my plea for salmon's cmake file to accept some form of ROOT_LIBGFF, ROOT_LIBSTADEN, and ROOT_LIBTBB. Those modules ; were all defined but cmake could only figure out TBB this time, and for all I know it won't next time around (since it failed to do so for no apparent reason on CentOS 7). Salmon is a useful program but it has so far failed to build using existing libraries on this OS (unless extraordinary measures were applied) for CO 6, 7, and now 8! This is the information it had to work with:. ```; echo $PATH; /usr/common/modules/el8/x86_64/software/libgff/1.2-CentOS-vanilla/bin:/usr/common/modules/el8/x86_64/software/io_lib/1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-640962684:495,message,message,495,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-640962684,4,['message'],['message']
Integrability,"I tried using Homo_sapiens.GRCh38.94.chr_patch_hapl_scaff.gtf.gz for the annotation file and ftp://ftp.ensembl.org/pub/release-94/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz to build the index but got a similar error. Here are the logs (I modified the salmon log a bit because it didn't have the error message that printed to stdout). [alevin.log](https://github.com/COMBINE-lab/salmon/files/3224429/alevin.log); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/3224440/salmon_quant.log). One curious thing that I noticed:. ```; Index contained 175,775 targets; ...; ERROR: Txp to Gene Map not found for 175775 transcripts; ```; It seems to not be finding any of the transcripts? This was also the case for the gencode attempt that I made previously.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496258062:317,message,message,317,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496258062,1,['message'],['message']
Integrability,"I tried wrapping the code around alphaSum but it didn't work.; I also set digammaMin to 1e-9 but no change.; What I find weird is that the following code works... ```cpp; #include <boost/math/special_functions/digamma.hpp>. int main() {; double logNorm = boost::math::digamma(1e-50);; printf(""%f\n"", logNorm);; return logNorm;; }; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393598770:8,wrap,wrapping,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393598770,1,['wrap'],['wrapping']
Integrability,"I understand that salmon does not use read quality scores when performing alignment/quantitation but, as it stands, running with `--writeMappings` it also doesn't output the qualities in its SAM-format output. That may not impact most downstream applications of the data but it does limit some. I'd be particularly interested in using reads that have been aligned and assigned to transcripts with an EM algorithm to investigate RNA editing. The most advanced methods of doing this integrate the quality of base calls from the sequencer into the models and, as such, cannot currently run on the data output. Although it may save a few CPU cycles in not reading and outputting the qualities - I can understand the choice when running with default settings - when running with `--writeMappings` that nominal difference in speed needs to be weighed up against downstream utility. Could this be looked into?. Cheers! George",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/756:481,integrat,integrate,481,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/756,1,['integrat'],['integrate']
Integrability,"I used salmon 0.9.1 successfully a few weeks ago. I am using the latest update according to miniconda. Now after typing in this script in the command line in my Terminal on my Mac, I get the following error message. I have tried to trouble shoot but I have not been able to solve the problem. . salmon quant -i cs_index -l A -r fastqtrimd/BOD19_5R1trimd.fastq.gz -o quant/BOD19_5R1_quant —seqBias --gcBias --writeUnmappedNames. Here is the error message in the command line:. Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.9.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { cs_index }; ### [ libType ] => { A }; ### [ unmatedReads ] => { BOD19_5R1trimd.fastq.gz }; ### [ output ] => { BOD19_5R1_quant }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ writeUnmappedNames ] => { }; Logs will be written to BOD19_5R1_quant/logs; [2018-03-19 12:13:21.295] [jointLog] [info] parsing read library format; [2018-03-19 12:13:21.295] [jointLog] [info] There is 1 library.; [2018-03-19 12:13:21.402] [jointLog] [info] Loading Quasi index; [2018-03-19 12:13:21.403] [jointLog] [info] Loading 32-bit quasi index; Exception : [Failed to read 8 bytes from input stream! Read 0]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; [2018-03-19 12:13:21.403] [stderrLog] [info] Loading Suffix Array . Does anyone have any ideas what is wrong? Sorry I am a novice!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/209:207,message,message,207,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/209,2,['message'],['message']
Integrability,"I was running some quantification on Google Compute Engine and a particular study repeatedly printed ""couldn't dequeue read chunk"" for 2.5 days. By the time I discovered it, over 300GB of Egress traffic (sending the message to my local computer) had accumulated. Cost me close to $100 between Google's egress charges and my ISPs bandwidth overage charges. It would be nice if the message didn't print so much. I'm now running Salmon commands with `timeout 1h` prefix to prevent this but might run into an issue with 1 hour not being long enough for all quantification runs.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152:216,message,message,216,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152,2,['message'],['message']
Integrability,"I was trying to troubleshoot the contemplation period of salmon with monitoring utilities and just stumbled upon this issue upon submitting my own. The failed version check gets buried by the spew of warnings for too short/long transcripts for hg38 mrna.fna in my case. The current behaviour is particularly irritating as I assumed, that `salmon index -h` just runs into a loop accidentally. The check takes multiple minutes to timeout. I am behind a proxy. Please remove the version check by default, as this is not common behaviour of command line tools or anticipated by the user. Or at least please add a verbose message before checking ""Checking for upgrades online..."".",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/277#issuecomment-474388032:617,message,message,617,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/277#issuecomment-474388032,1,['message'],['message']
Integrability,"I was wondering: when using options --seqBias, --gcBias, and/or --posBias with several fastq files generated from different flowcells (but same sample and library, i.e. technical replicates), is it better (in terms of the different model assumptions) to process the fastq files independently (because the estimated parameters depend on the flowcell) or to use the space-separated ""trick"" (because there is more data to estimate the parameters from)?; Thanks!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/313:326,depend,depend,326,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/313,1,['depend'],['depend']
Integrability,"I'd rather not bundle the dependency. Troubleshooting bundled dependencies is crazy making. The `cmake` script could check that the dependency is satisfied and report an error message if it's not. Or I suppose install the dependency if it's not satisfied. Perhaps that's what you were thinking.; In any case, here's the web site: http://tukaani.org/xz/; and git repository: http://git.tukaani.org/; Here's a GitHub mirror. I don't know whether it's current: https://github.com/nobled/xz",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193941254:26,depend,dependency,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193941254,5,"['depend', 'message']","['dependencies', 'dependency', 'message']"
Integrability,I'm having problems installing salmon from source. . When running `make` I get the following error. ```Consolidate compiler generated dependencies of target tbb; [ 73%] Built target tbb; Consolidate compiler generated dependencies of target tbbmalloc; [ 75%] Linking C shared library ../../gnu_11.4_cxx14_64_release/libtbbmalloc.so; lto1: fatal error: bytecode stream in file ‘CMakeFiles/tbbmalloc.dir/backend.cpp.o’ generated with LTO version 11.3 instead of the expected 12.0; compilation terminated.; lto-wrapper: fatal error: /usr/bin/cc returned 1 exit status; compilation terminated.; /usr/bin/ld: error: lto-wrapper failed; collect2: error: ld returned 1 exit status; make[5]: *** [src/tbbmalloc/CMakeFiles/tbbmalloc.dir/build.make:178: gnu_11.4_cxx14_64_release/libtbbmalloc.so.2.11] Error 1; make[4]: *** [CMakeFiles/Makefile2:196: src/tbbmalloc/CMakeFiles/tbbmalloc.dir/all] Error 2; make[3]: *** [Makefile:156: all] Error 2; make[2]: *** [CMakeFiles/libtbb.dir/build.make:87: libtbb-prefix/src/libtbb-stamp/libtbb-build] Error 2; make[1]: *** [CMakeFiles/Makefile2:253: CMakeFiles/libtbb.dir/all] Error 2; make: *** [Makefile:166: all] Error 2; ```. For cmake I used the following command:; `sudo cmake -DNO_IPO=TRUE -DBOOST_ROOT=/usr/include/boost/ -DCMAKE_INSTALL_PREFIX=/usr/local/bin/ ..`. **Desktop (please complete the following information):**; - OS: Ubuntu 22.04; - Version: 6.5.0-35-generic # 35~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue May 7 09:00:52 UTC 2 x86_64 x86_64 x86_64 GNU/Linux; - gcc (Ubuntu 12.3.0-1ubuntu1~22.04) 12.3.0,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/936:134,depend,dependencies,134,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/936,4,"['depend', 'wrap']","['dependencies', 'wrapper']"
Integrability,"I'm interested in this as well. Note that the (Harvard) inDrops v3 library protocol differs from v2, and is documented here: https://iccb.med.harvard.edu/files/iccb/files/sequencing_indrops_libraries_02_28_18.pdf. For reference, bcbio supports inDrops and Dropseq barcodes, but it'd be great it if we could better integrate this workflow with alevin: https://bcbio-nextgen.readthedocs.io/en/latest/contents/pipelines.html",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/339#issuecomment-474551107:75,protocol,protocol,75,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/339#issuecomment-474551107,2,"['integrat', 'protocol']","['integrate', 'protocol']"
Integrability,"I'm quantifying reads from a Lexogen QuantSeq experiment, using `-l SF and --noLengthCorrection`. I just downloaded the latest release 0.9.0. Full command (using nu parallel); `salmon quant -i path_to_index -r {} -l SF --noLengthCorrection -o {.} -p 5`. Which gives the following settings information:; ```; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/wdecoster/databases/Homo_sapiens/hg38/transcriptome/GRCh38-full-transcriptome-index }; ### [ unmatedReads ] => { pt_d10046-11.fastq.gz }; ### [ libType ] => { SF }; ### [ noLengthCorrection ] => { }; ### [ output ] => { pt_d10046-11.fastq }; ### [ threads ] => { 5 }; ```. But I get the following warning for each sample:; `Detected a *potential* strand bias > 1% in an unstranded protocol check the file: samplename/lib_format_counts.json for details`. That file looks as below:. ```; {; ""read_files"": ""pt_d10040-14.fastq.gz"",; ""expected_format"": ""U"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 2836170,; ""num_assigned_fragments"": 2836170,; ""num_consistent_mappings"": 10375916,; ""num_inconsistent_mappings"": 0,; ""strand_mapping_bias"": 0.9229587055253724,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 0,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 0,; ""SF"": 9576542,; ""SR"": 799374,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```. This suggests my libType SF is ignored?. (Less important: If you could make --libtype an alias for --libType that would be great, random internal capitalization is quite annoying imho)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/177:862,protocol,protocol,862,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/177,1,['protocol'],['protocol']
Integrability,I'm still experiencing this `cmake` error:. ```; -- extracting... [tar xfz]; CMake Error: Problem with archive_write_finish_entry(): Can't restore time; CMake Error: Problem extracting tar: /var/tmp/sjackman/salmon20160307-4399-1vksuoo/salmon-0.6.0/external/libdivsufsort.zip; -- extracting... [error clean up]; CMake Error at /var/tmp/sjackman/salmon20160307-4399-1vksuoo/salmon-0.6.0/libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake:33 (message):; error: extract of; '/var/tmp/sjackman/salmon20160307-4399-1vksuoo/salmon-0.6.0/external/libdivsufsort.zip'; failed; ```. Here's a gist of the logs:; https://gist.github.com/sjackman/2bbfcf212c555fb20505#file-02-make-L397-L404,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193515060:463,message,message,463,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193515060,1,['message'],['message']
Integrability,"I'm surprised that the `@rpath` showed up, when I thought that we had disabled that. So long as `brew install salmon` works on Mac, I wouldn't worry about downloading and installing dependencies. Leave that chore to the package manager.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239604008:182,depend,dependencies,182,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239604008,1,['depend'],['dependencies']
Integrability,"I'm trying to build salmon on FreeBSD. . First issue, fetchRapMap.sh fails because it calls /bin/bash. Bash on FreeBSD is in /usr/local/bin/bash.; This is easily worked around with a symlink. Second issue: libbwa fails to build. . ```; [ 34%] Performing build step for 'libbwa'; make[3]: ""/usr/home/esiefker/salmon/salmon/external/bwa-master/Makefile"" line 17: Missing dependency operator; make[3]: ""/usr/home/esiefker/salmon/salmon/external/bwa-master/Makefile"" line 19: Need an operator; make[3]: Fatal errors encountered -- cannot continue; make[3]: stopped in /usr/home/esiefker/salmon/salmon/external/bwa-master; *** Error code 1; ```; In addition to failing to build bwa, bwa is present in ports and already installed on this machine. Cmake should check for this.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162:369,depend,dependency,369,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162,1,['depend'],['dependency']
Integrability,"I'm trying to update the 0.9.1 brew/conda package to 1.0; What version of `openssl` does it need?; I've tried `curl-openssl/lib/libcurl.a (found version ""7.66.0"")` without luck too.; Nothing stated at https://salmon.readthedocs.io/en/latest/building.html#. ```; /home/linuxbrew/.linuxbrew/bin/ld: /home/linuxbrew/.linuxbrew/lib/libcurl.a(libcurl_la-openssl.o): in function `Curl_ossl_sha256sum':; openssl.c:(.text+0x11c): undefined reference to `EVP_MD_CTX_create'; /home/linuxbrew/.linuxbrew/bin/ld: openssl.c:(.text+0x124): undefined reference to `EVP_sha256'; /home/linuxbrew/.linuxbrew/bin/ld: openssl.c:(.text+0x131): undefined reference to `EVP_DigestInit_ex'; /home/linuxbrew/.linuxbrew/bin/ld: openssl.c:(.text+0x13f): undefined reference to `EVP_DigestUpdate'; /home/linuxbrew/.linuxbrew/bin/ld: openssl.c:(.text+0x14f): undefined reference to `EVP_DigestFinal_ex'; /home/linuxbrew/.linuxbrew/bin/ld: openssl.c:(.text+0x157): undefined reference to `EVP_MD_CTX_destroy'; /home/linuxbrew/.linuxbrew/bin/ld: /home/linuxbrew/.linuxbrew/lib/libcurl.a(libcurl_la-openssl.o): in function `Curl_ossl_md5sum':; ```. Also this:; ```; CMake Warning at /home/linuxbrew/.linuxbrew/lib/cmake/boost_iostreams-1.71.0/libboost_iostreams-variant-static.cmake:59 (message):; Target Boost::iostreams already has an imported location; '/home/linuxbrew/.linuxbrew/lib/libboost_iostreams-mt.a', which will be; overwritten with '/home/linuxbrew/.linuxbrew/lib/libboost_iostreams.a'; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/443:1255,message,message,1255,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/443,1,['message'],['message']
Integrability,"I've addressed this in a recent [commit](https://github.com/COMBINE-lab/salmon/commit/05859ef8412687be14de5084f3b1e0e688fb3e76). Now, `version`, `help`, `cite` and `swim` will print to stdout, while other normal logging messages will print to stderr. Basically, if it was specifically requested by the user, send it to stdout; otherwise send it to stderr.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/148#issuecomment-378405708:220,message,messages,220,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/148#issuecomment-378405708,1,['message'],['messages']
Integrability,"I've been previously processing my data using Salmon Alevin. We've just got our results back from a SevenBridges analysis of our single cell sequencing data, and there's a substantial difference in PCR duplicate rate between the two platforms. Here are the numbers for SevenBridges (three samples were analysed separately):. Sample,Aligned_Reads,Molecules,RSEC_Molecules,Raw_Depth,RSEC_Depth,Saturation; S1,1152169399,251097626,226949623,4.59,5.08,93.82; S2,1021623258,258701917,238156437,3.95,4.29,92.49; S3,1232889654,268962282,242417971,4.58,5.09,93.72. In other words, a PCR duplication rate of 4-5X (columns 4 & 5), depending on what statistic is chosen. For salmon alevin, here's our metadata* for the whole run:. ```; {; ""total_reads"": 4579183639,; ""reads_with_N"": 59361,; ""noisy_cb_reads"": 977033360,; ""noisy_umi_reads"": 152773,; ""used_reads"": 3601938145,; ""mapping_rate"": 54.155827599470509,; ""reads_in_eqclasses"": 2479894797,; ""total_cbs"": 37916487,; ""used_cbs"": 137766,; ""no_read_mapping_cbs"": 1,; ""final_num_cbs"": 136196,; ""deduplicated_umis"": 402386555,; ""mean_umis_per_cell"": 2954,; ""mean_genes_per_cell"": 896; }; ```. \* total reads have been corrected by adding 2^32. From my understanding of the numbers, this suggests a PCR duplication rate of either 8.95X (comparing ""used reads"" with ""deduplicated umis"") or 6.16X (comparing ""reads in eqclasses"" with ""deduplicated umis""). I had a go at trying to ""manually"" count (via awk/grep/sort/uniq/etc.) the cell barcodes and UMIs associated with the MT-ND1 gene:. ND1-matching reads with good cell barcode QC (barcodes linkable to expected cell barcodes), and good mapping (>60bp matching): 5292134; Unique cell/UMI pairs (subset from the above data): 1590232; => PCR duplication rate ~= 3.32 reads per unique molecule. So it seems like the duplication rate might be closer to the SevenBridges estimate than the Alevin estimate. The Alevin documentation seems to suggest that cell/transcript/UMI triplets are being used for UMI collapsing (",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/808:621,depend,depending,621,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/808,1,['depend'],['depending']
Integrability,"I've been using 0.7.1 without problems until today.; I'm trying to index the transcriptome (made with gffread) of human GRCh37 from archived Ensembl 60. The process has been running for hours, with no messages beyond this:. ```; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases ; contains some new features and minor bug fixes; please upgrade at your; earliest convenience.; ###; [2016-11-04 13:45:38.583] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers. ```. This is all there is in the index.log. `[2016-11-04 13:45:38.583] [jLog] [info] building index`. None of me previous indexes have taken so long, especially not in total silence. So I'm guessing it gets stuck somewhere, but where? Why?. I know there is a newer version, but getting our busy sysadmin to install things takes time and I didn;t see anything critical for my usage case listed in the release notes.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/100:201,message,messages,201,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/100,1,['message'],['messages']
Integrability,"I've just been testing Salmon using Illumina TruSeq stranded (dUTP) libraries. Using either `ISF` (correct libType) or `ISR` I get a **ton** of messages like this:. ```; expected = Library format { type: }; paired end, relative orientation:inwardexpected = Library format { type:paired end, relative orientation:Library format { type:paired end, relative orientation:inwardpaired endinward, strandedness:, relative orientation:inward, strandedness:(sense, antisense) }; observed = Library format { type:paired end, relative orientation:inward, strandedness:(antisense, sense) }; (sense, antisense)expected = , strandedness:(sense, antisense), strandedness:(sense, antisense) }; observed = }; Library format { type:paired end, relative orientation:inward, strandedness:(sense, antisense) }; observed = Library format { type:paired end, relative orientation:inward, strandedness:(antisense, sense) }; expected = Library format { type:observed = Library format { type: }; paired endLibrary format { type:paired end, relative orientation:, relative orientation:inward, strandedness:(sense, antisense) }; observed = Library format { type:paired end, relative orientation:inward, strandedness:observed = inward, strandedness:(antisense, sense) }; (antisense, sense) }paired end, relative orientation:inward, strandedness:(antisense, sense) }; expected = Library format { type:paired end, relative orientation:inward, strandedness:(sense, antisense)expected = Library format { type:Library format { type:; }paired endpaired endexpected = Library format { type:paired end, relative orientation:; , relative orientation:inwardinward, strandedness:(sense, antisense)observed = , strandedness:(antisense, sense) }; }; observed = Library format { type:paired end, relative orientation:inward, strandedness:(antisense, sense) }expected = Library format { type:, relative orientation:Library format { type:paired end; ```. and so on... It seems that the [`LibraryFormat` class](https://github.com/COMBINE-lab/salmon",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/16:144,message,messages,144,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/16,1,['message'],['messages']
Integrability,"I've just started working in a single-cell genomics core facility, **alevin** looks really useful for our 10X runs! ; But I also have a substantial number of samples processed with the CEL-Seq and CEL-Seq2 protocols (also 3'-tag protocols). ; I'm interested in adding support for these protocols to Alevin. 1. Is that something you'd be interested in incorporating?; 2. Any hints on where to start messing around in the code to implement this would be much appreciated!. Cheers,; Pete",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269:206,protocol,protocols,206,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269,3,['protocol'],['protocols']
Integrability,"I've run into this (or a similar) issue attempting to install Salmon on the UC Berkeley HPC cluster. Iconv was present within one of our Python installs, but that didn't seem to have the header files, so I installed libiconv/1.16 thinking this was a dependency issue. Unfortunately this didn't seem to help. Any guidance would be greatly appreciated. Here is my build script to the point of failure:; ```sh; #!/bin/sh ; MODULE_HOME=/clusterfs/vector/home/groups/software/sl-7.x86_64; PACKAGE_NAME=salmon; GITHUB_URL=https://api.github.com/repos/COMBINE-lab/salmon/releases/latest; VERSION=$(curl -s $GITHUB_URL | \; grep '""tag_name"":' | \; cut -d : -f 2,3 | \; tr -d \"",v | \; xargs); LATEST_RELEASE=$(curl -s $GITHUB_URL | \; grep '""tarball_url""' | \; cut -d : -f 2,3 | \; tr -d \"", | \; xargs); module load gcc/7.4.0 cmake/3.15.1 boost/1.70.0-gcc libiconv/1.16; export CC=`which gcc`; export CXX=`which c++`. cd $MODULE_HOME; mkdir -p source/$PACKAGE_NAME/$VERSION; INSTALL_DIR=$MODULE_HOME/modules/$PACKAGE_NAME/$VERSION; mkdir -p $INSTALL_DIR; mkdir -p modfiles/$PACKAGE_NAME. cd source/$PACKAGE_NAME/$VERSION; wget $LATEST_RELEASE -O - | tar -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:250,depend,dependency,250,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,1,['depend'],['dependency']
Integrability,"I've tried to reproduce the issue in docker by using the Build-Depends that are used in Debian:. $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt update; $ apt upgrade; $ apt build-dep salmon; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ mkdir build && cd build; $ cmake -DNO_IPO=TRUE ..; $ make -j8; make -j8; [ 3%] Built target ksw2pp_sse4; [ 6%] Built target ntcard; [ 15%] Built target twopaco; [ 18%] Built target graphdump; [ 21%] Built target ksw2pp_sse2; [ 27%] Built target ksw2pp_basic; [ 43%] Built target salmon_core; [ 67%] Built target puffer; [ 68%] Built target ksw2pp; [ 69%] Built target UnitTestsMain; [ 73%] Built target alevin_core; [ 74%] Linking CXX executable unitTests; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-psl.o): in function `Curl_psl_destroy':; (.text+0x21): undefined reference to `psl_free'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-psl.o): in function `Curl_psl_use':; (.text+0xbc): undefined reference to `psl_latest'; /usr/bin/ld: (.text+0x157): undefined reference to `psl_builtin'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-version.o): in function `curl_version':; (.text+0x129): undefined reference to `BrotliDecoderVersion'; /usr/bin/ld: (.text+0x16f): undefined reference to `ZSTD_versionNumber'; /usr/bin/ld: (.text+0x1e3): undefined reference to `idn2_check_version'; /usr/bin/ld: (.text+0x20e): undefined reference to `psl_get_version'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-version.o): in function `curl_version_info':; (.text+0x386): undefined reference to `idn2_check_version'; /usr/bin/ld: (.text+0x3ad): undefined reference to `BrotliDecoderVersion'; /usr/bin/ld: (.text+0x3b8): undefined reference to `BrotliDecoderVersion'; /usr/bin/ld: (.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855:63,Depend,Depends,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855,1,['Depend'],['Depends']
Integrability,"If I install Salmon Binary:; [100%] Building CXX object src/CMakeFiles/salmon.dir/BAMUtils.cpp.o; [100%] Linking CXX executable salmon; /usr/bin/ld: ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): in function `find_file_url':; open_trace_file.c:(.text+0xf4e): warning: the use of `tempnam' is dangerous, better use `mkstemp'; during IPA pass: icf; lto1: internal compiler error: Segmentation fault; Please submit a full bug report,; with preprocessed source if appropriate.; See <file:///usr/share/doc/gcc-9/README.Bugs> for instructions.; lto-wrapper: fatal error: /usr/bin/c++ returned 1 exit status; compilation terminated.; /usr/bin/ld: error: lto-wrapper failed; collect2: error: ld returned 1 exit status; make[2]: *** [src/CMakeFiles/salmon.dir/build.make:421: src/salmon] Error 1; make[1]: *** [CMakeFiles/Makefile2:659: src/CMakeFiles/salmon.dir/all] Error 2; make: *** [Makefile:163: all] Error 2",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/592#issuecomment-734935424:578,wrap,wrapper,578,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/592#issuecomment-734935424,2,['wrap'],['wrapper']
Integrability,"If an adapter is not trimmed, will it affect the mapping rate?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/398:6,adapter,adapter,6,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/398,1,['adapter'],['adapter']
Integrability,"If i use the smaller set of barcodes, then I progress further. However, I still receive an error message (and there no **quants_mat_rows.txt** file):. ```; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0.00 UMI after deduplicating.; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0 BiDirected Edges.; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0 UniDirected Edges.; [2021-07-13 13:59:07.134] [alevinLog] [info] Finished optimizer; /var/spool/slurmd/job3050767/slurm_script: line 23: 10494 Floating point exception../../Ref_Generation/salmon-1.5.1_linux_x86_64/bin/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP --whitelist $CBWL. ```. If the barcode is on the opposite read, then I am not sure if I should really be using the reverse or reverse complement (possibly even for the full barcode list)?. However, for the sake of this discussion, I will now test not providing any white list. If that works, then I will close the ticket again. **Update (7/14/2021)**: I have added the full log file here: [cluster_log.log](https://github.com/COMBINE-lab/salmon/files/6819402/cluster_log.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879497561:97,message,message,97,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879497561,1,['message'],['message']
Integrability,"If you are not building from source, then `0.10.1` is identical to `0.10.0`, there are no new features, behavior changes, or bug fixes. The entire purpose of `0.10.1` is to fix the source build on specific versions of Debian linux using system versions of dependencies. Thus, the pre-compiled versions of `0.10.0` and `0.10.1` (which are not build on a Debian system and which downloads and builds the dependencies directly) will not have any differences.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/841#issuecomment-1542672313:256,depend,dependencies,256,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/841#issuecomment-1542672313,2,['depend'],['dependencies']
Integrability,"If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2020-12-26 10:49:06.448] [puff::index::jointLog] [info] Replaced 151,122,967 non-ATCG nucleotides; [2020-12-26 10:49:06.448] [puff::index::jointLog] [info] Clipped poly-A tails from 1,829 transcripts; wrote 231443 cleaned references; [2020-12-26 10:49:09.969] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers; [2020-12-26 10:49:40.159] [puff::index::jointLog] [info] ntHll estimated 2628436199 distinct k-mers, setting filter size to 2^36; Threads = 12; Vertex length = 31; Hash functions = 5; Filter size = 68719476736; Capacity = 2; Files:; salmon-decoy-sa-index/ref_k31_fixed.fa; --------------------------------------------. **So using gffread I created a transcripts.fa file:; gffread -w salmon_transcripts.fa -g GRCh38.primary_assembly.genome.fa gencode.v36.annotation.gtf. using this new transcripts.fa I run again the above mentioned salmon index with decoy command, but the warning message was shown up again:**. [Step 1 of 4] : counting k-mers; [2020-12-26 11:30:08.799] [puff::index::jointLog] [warning] Entry with header [ENST00000473810.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:08.951] [puff::index::jointLog] [warning] Entry with header [ENST00000603775.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:10.751] [puff::index::jointLog] [warning] Entry with header [ENST00000632684.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:12.936] [puff::index::jointLog] [warning] Entry with header [ENST00000543745.1], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping); [2020-12-26 11:30:13.188] [puff::index::jointLog] [warning] Entry with header [ENST00000415118.1], had length less than equal to the k-mer length of 31 (perhaps after po",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354493:14971,message,message,14971,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751354493,1,['message'],['message']
Integrability,"In Salmon v1.2.0, `--posBias` is listed in the help message without any hints on being ""experimental"". At the same time, the read the docs manual still lists it as an experimental feature. Does someone know if it is now considered as a stable feature?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/474#issuecomment-615160502:52,message,message,52,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/474#issuecomment-615160502,1,['message'],['message']
Integrability,"In my experience it is normal to get a **much lower** transcriptome mapping rate for rRNA-depleted samples vs polyA-selected samples. . I'm getting ~21% mapping rate (using Gencode 41 transcripts) on human brain RNAseq samples sequenced several years ago using rRNA-depletion protocol (older Illumina Ribo Zero kits).; I was initially shocked (being used to seeing >90% mapping rates from HISAT2/STAR for these samples) but it turns out **this is normal** for this kind of samples, in this context.; HISAT2 reports 96% mapping rate on the same samples, but QC metrics (rnaseqc) for these HISAT2 alignments (using the same Gencode annotation) show a **65% intronic rate** and a **%23.5 exonic rate** (the rest being intergenic etc). So the _exonic rate_ is getting close to what Salmon is showing (and what it measures), thus I suppose it makes sense to see such a low mapping rate for Salmon on these samples.; (kallisto also reports ~21% pseudoaligned percentage on the same samples). I am only a bit disappointed that when I use `--validateMappings` with decoy sequences (whole genome) added, the mapping rate goes down to about **16.7%** -- as some reads map better to the decoys in that case (partially intronic reads etc.), but I also see a `higher number of fragments entirely discarded because of alignment score` (higher `num_fragments_filtered_vm` and much higher `num_alignments_below_threshold_for_mapped_fragments_vm`).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474291747:276,protocol,protocol,276,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474291747,1,['protocol'],['protocol']
Integrability,"In terms of an intermediate update:. **Setting 1**:. _Command 1_:; `/path/to/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP`; _End of Log 1_:; ```; [2021-07-13 20:12:34.651] [alevinLog] [info] Starting white listing of 814 cells; [2021-07-13 20:12:34.651] [alevinLog] [info] Starting to make feature Matrix; [2021-07-13 20:12:34.654] [alevinLog] [info] Done making feature Matrix; [2021-07-13 20:12:35.447] [alevinLog] [info] Finished white listing; [2021-07-13 20:12:36.158] [alevinLog] [info] Finished optimizer; 0.0408521	8.9925e-05	0.000114595	636780	18682.9	; 0.0290163	6.61624e-05	0.000111685	230922	8010.3	; ```; _Size of quants_mat_rows.txt 1_: 814 lines/barcodes. **Setting 2:**:; _Command 1_:; `/path/to/salmon alevin -l ISR --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP`; _End of Log 1_:; ```; [2021-07-14 09:51:38.564] [alevinLog] [info] Starting white listing of 814 cells; [2021-07-14 09:51:38.564] [alevinLog] [info] Starting to make feature Matrix; [2021-07-14 09:51:38.566] [alevinLog] [info] Done making feature Matrix; [2021-07-14 09:51:39.347] [alevinLog] [info] Finished white listing; [2021-07-14 09:51:39.541] [alevinLog] [info] Finished optimizer; [2021-07-14 09:51:39.564] [jointLog] [warning] NOTE: Read Lib [[ ../Reads/5309-CT-2_S01_L005_R1_001.fastq.gz, ../Reads/5309-CT-2_S01_L005_R2_001.fastq.gz]] :. Greater than 5% of the fragments disagreed with the provided library type; check the file: 5309-CT-2/lib_format_counts.json for details. 0.0408521	8.9925e-05	0.000114595	636780	18682.9	; 0.0290163	6.61624e-05	0.000111685	230922	8010.3	; ```; _Size of quants_mat_rows.txt 1_: 814 lines/barcodes. Technically, this means that the program ran without generating an error message, but this seems strange to me. So, I think I would prefer to keep the issue open a little bit longer.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-880273749:1743,message,message,1743,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-880273749,1,['message'],['message']
Integrability,"Including '^' didn't change the speed, and '$' can't be added as there are extra bases (not in protocol spec) at end which can vary in number.; ```; real 1m19.392s; user 9m38.357s; sys 0m4.176s; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013381545:95,protocol,protocol,95,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013381545,1,['protocol'],['protocol']
Integrability,Interesting. One thing that changed is that we finally upgraded the Docker image used in our continuous integration server from CentOS5 to CentOS6; I wonder if that might cause some portability issues. Could you try installing via Bioconda to see if that executable gives you the same trouble?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394752905:104,integrat,integration,104,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394752905,1,['integrat'],['integration']
Integrability,Is it necessary to trim adapters before using salmon?,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/398:24,adapter,adapters,24,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/398,1,['adapter'],['adapters']
Integrability,"Is salmon suggesting this is stranded?. `Detected a *potential* strand bias > 1% in an unstranded protocol check the file: 142-salmon-quant/lib_format_counts.json for details`. . The libraries are generated using the [smart-seq2](http://www.nature.com/nmeth/journal/v10/n11/full/nmeth.2639.html) protocol which as far I know does not retain strand information. From the article . ""Currently, Smart-seq2 is limited to poly(A)+ RNAs and does not retain strand or molecule information, although it is compatible with partial-molecule counting.""",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/144#issuecomment-319669636:98,protocol,protocol,98,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/144#issuecomment-319669636,2,['protocol'],['protocol']
Integrability,Issue with error message that doesn't always appear,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/736:17,message,message,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/736,1,['message'],['message']
Integrability,"It appears that you're trying to index the entire mm9 genome using salmon. Both salmon and rapmap are designed to work with a smaller sequence space such as what you would find in a transcriptome. Your log file shows that salmon processes 615,000,000 bases from the genome and then aborts. Depending on how many transcripts are in your feature file, a human transcriptome [might be 5-10X smaller](http://seqanswers.com/forums/showthread.php?t=5298).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197862096:290,Depend,Depending,290,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197862096,1,['Depend'],['Depending']
Integrability,"It depends what type of ""replicates"" these are. If these are biological replicates, then they should _definitely_ be run separately. Biological replicates contain crucial information about the variability of expression that can be expected in a given condition, and all downstream differential expression tools will use this information. If these are ""technical"" replicates, then there should be little harm in quantifying them together (of course, then one has a 2 condition experiment with only 1 biological replicate per-condition ... which is a big problem if one wishes to analyze e.g. differential expression).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/190#issuecomment-400080695:3,depend,depends,3,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/190#issuecomment-400080695,1,['depend'],['depends']
Integrability,"It does run with each of the two files separately, but when I try the command with the double redirect I get a message like the one below for many/all[?] of the sequences in the reference and quant.sf is empty (except the header). ```; [2020-10-12 17:05:47.406] [jointLog] [warning] Transcript XM_024446103.1 appears in the reference but did not appear in the BAM; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707347734:111,message,message,111,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707347734,1,['message'],['message']
Integrability,"It doesn’t have a problem with a single bam file. Which is the reason make; me wonder maybe my command is wrong.; Sure, I can share some of the bam files later today. On Thu, Mar 21, 2024 at 4:48 PM Alex D Hill ***@***.***>; wrote:. > Can you head any of the bam files? The fact that they are all *.txt.bam; > seems suspiciously like they are renamed text files.; >; > Does this happen if you run a single bam file at once?; >; > Would also be helpful to fill out the rest of the missing info requested; > (To Reproduce, Expected Behavior, Desktop, etc.); >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/920#issuecomment-2013705067>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHJBWLH4NQP66UEUFSFESXDYZNBRHAVCNFSM6AAAAABFBYUNKOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDAMJTG4YDKMBWG4>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/920#issuecomment-2013709916:936,Message,Message,936,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/920#issuecomment-2013709916,1,['Message'],['Message']
Integrability,"It is possible to output gene counts directly, but using `tximport` is the preferred and officially supported method. The reason for this is that the gene-level aggregation built into salmon is _per-sample_, that is each sample is aggregated to the gene level independently. On the other hand, `tximport` considers all samples in an experiment to determine e.g. the average expressed length of a gene over all samples. This leads to better aggregation. Likewise, `tximport` (specifically via `tximeta`) provides a nice interface to track and propagate reference annotation provenance, which ultimately leads to more reproducible analyses.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-1535065239:519,interface,interface,519,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-1535065239,1,['interface'],['interface']
Integrability,"It's still not working. If I type ./bin/salmon I get:. salmon(68460,0x7fffdb32f3c0) malloc: **\* malloc_zone_unregister() failed for 0x7fffdb325000; version : 0.7.1. So maybe it's working okay but it's still printing the error message.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-259472964:227,message,message,227,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/103#issuecomment-259472964,1,['message'],['message']
Integrability,"Just chiming in, we have bulk RNA-seq data using a NuGen protocol that has the UMI (for paired end data) in the index read. This is very common in the DNA-seq circles so not a one-off protocol. Would be nice if UMIs could be used for PE reads in distinguishing duplicates.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-277223659:57,protocol,protocol,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-277223659,2,['protocol'],['protocol']
Integrability,Just here to upvote support for inDrop v2 protocol 👍,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/339#issuecomment-464872433:42,protocol,protocol,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/339#issuecomment-464872433,1,['protocol'],['protocol']
Integrability,"Just wanted to put an opinion in. I am currently using Salmon v1.1.0 and noticed that `--posBias` wasn't listed in the help messages, but I found it in your read the docs. I tested it out and it made a significant improvement in my calculations. I know it is considered ""experimental"", but it helped in my research and will publish that I used it when we get the manuscript out. Also, do you think you could give a brief explanation on what `--forgettingFactor` is doing and how it could be affecting quantification calculations?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/474:124,message,messages,124,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/474,1,['message'],['messages']
Integrability,Library format checking for stranded libraries gives uninformative debugging messages,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/16:77,message,messages,77,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/16,1,['message'],['messages']
Integrability,"Looks like I have some sort of conflict going on:. UnsatisfiableError: The following specifications were found to be in conflict:; - libboost -> libcxx >=4.0.1 -> clangdev ==5.0.0 -> llvmdev ==5.0.0; - libcxx 4.0.0* -> clangdev ==4.0.0 -> llvmdev ==4.0.0; Use ""conda info <package>"" to see the dependencies for each package. [https://sites.google.com/site/ummslogos/_/rsrc/1489610858836/home/apple-icon-76x76.png]. Javier E. Irazoqui, PhD; Associate Professor; Department of Microbiology and Physiological Systems; UMass Medical School. 368 Plantation Street; Albert Sherman Center; Room AS8.1053; Worcester, MA 01605. (774) 455-3797; Skype: javierirazoqui. Confidentiality Notice:; This e-mail message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential, proprietary and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender immediately and destroy or permanently delete all copies of the original message. On Feb 11, 2018, at 11:01 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. I can't seem to reproduce this locally (OSX 10.13.1). However, what happens if you try:. > conda install salmon=0.9.1. do you see this version as available? Does it try to install it?. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364824034>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AiohHaDPT6VtnW3toOd9kEKLLo2Zjvvcks5tT7e0gaJpZM4SAonB>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364941997:294,depend,dependencies,294,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/194#issuecomment-364941997,3,"['depend', 'message']","['dependencies', 'message']"
Integrability,Maybe SLURM is killing your job because of too less memory allocation and the error message is just really wired?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-415887826:84,message,message,84,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-415887826,1,['message'],['message']
Integrability,"Maybe it is a little off-topic, but here is the code for the v3 sample that ran without generating error messages:. ```; ID=5k_pbmc_v3. R1a=../Reads/5k_pbmc_v3_S1_L001_R1_001.fastq.gz; R1b=../Reads/5k_pbmc_v3_S1_L002_R1_001.fastq.gz; R1c=../Reads/5k_pbmc_v3_S1_L003_R1_001.fastq.gz; R1d=../Reads/5k_pbmc_v3_S1_L004_R1_001.fastq.gz. R2a=../Reads/5k_pbmc_v3_S1_L001_R2_001.fastq.gz; R2b=../Reads/5k_pbmc_v3_S1_L002_R2_001.fastq.gz; R2c=../Reads/5k_pbmc_v3_S1_L003_R2_001.fastq.gz; R2d=../Reads/5k_pbmc_v3_S1_L004_R2_001.fastq.gz. TYPE=10xV3; #for MAP, download from UCSC Table Browser, and remove 1st line (and then manually add SARS-COV-2 genes); MAP=../../Ref_Generation/SARS_COV_2-hg38_RefSeq_2column.txt; REF=../../Ref_Generation/SARS_COV_2-hg38_salmon; CBWL=/net/isi-dcnl/ifs/user_data/Seq/Chromium_data/3M-february-2018.txt. ../../Ref_Generation/salmon-1.5.1_linux_x86_64/bin/salmon alevin -l ISR --chromium -1 $R1a $R1b $R1c $R1d -2 $R2a $R2b $R2c $R2d -i $REF -p 4 -o $ID --tgMap $MAP --whitelist $CBWL; ```. That v3 white list is even **larger** than the v2 white list:. ```; cwarden$ wc -l /net/isi-dcnl/ifs/user_data/Seq/Chromium_data/3M-february-2018.txt; 6794880 /net/isi-dcnl/ifs/user_data/Seq/Chromium_data/3M-february-2018.txt; ```. So, that is part of why I was confused. However, before I start running the analysis with the shorter set of barcodes unique for this sample, here are the commands that I believe you were asking about. ```; cwarden$ wc -l ../CellRanger/5309-CT-2/outs/raw_feature_bc_matrix/barcodes.tsv; 737280 ../CellRanger/5309-CT-2/outs/raw_feature_bc_matrix/barcodes.tsv; cwarden$ wc -l ../CellRanger/5309-CT-2/outs/filtered_feature_bc_matrix/barcodes.tsv; 9974 ../CellRanger/5309-CT-2/outs/filtered_feature_bc_matrix/barcodes.tsv; ```. I would prefer to have an option where I could potentially conclude the cell count is different than provided by CellRanger. . However, I will at least check to confirm this solves the problem with the error message that I am seei",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879347665:105,message,messages,105,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879347665,1,['message'],['messages']
Integrability,"Modified the CMakeLists.txt file to use dynamic libraries unconditionally, edited that section down to:. `set (Boost_USE_STATIC_LIBS OFF); `; Changed the CMakeLists.txt to try everything I could think of and then finally force the issue:. ```; set(Boost_ADDITIONAL_VERSIONS ""1.57"" ""1.57.0"" ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62"" ""1.63"" ""1.64"" ""1.65"" ""1.66""); find_package(Boost 1.57 COMPONENTS iostreams filesystem system thread timer chrono program_options); message(""Boost_FOUND 1.57 = ${Boost_FOUND}""); find_package(Boost 1.57.0 COMPONENTS iostreams filesystem system thread timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND 1.57.0 = ${Boost_FOUND}""); set(Boost_FOUND ""1""); message(""Boost_FOUND FORCED = ${Boost_FOUND}""); include(ExternalProject); ```; This emits:; ```. -- Could NOT find Boost; Boost_FOUND 1.57 = 0; -- Could NOT find Boost; BOOST_INCLUDEDIR = /usr/include/boost157; BOOST_LIBRARYDIR = /usr/lib64; Boost_FOUND 1.57.0 = 0; Boost_FOUND FORCED = 1; BOOST INCLUDE DIR = /usr/include/boost157; BOOST INCLUDE DIRS = /usr/include/boost157; BOOST LIB DIR = /usr/lib64; BOOST LIBRARIES = ; ```; That at least allowed cmake to complete when it was run with:. `nice scl enable devtoolset-4 '~/bin/cmake -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON -DBoost_NO_BOOST_CMAKE=BOOL:ON -DBOOST_LIBRARYDIR=/usr/lib64 -DBOOST_INCLUDEDIR=/usr/include/boost157 ../CMakeLists.txt' >try_cmake.log 2>&1 &; `. Then tried to build it. ```; cd ..; nice scl enable devtoolset-4 'make' >build_2018_06_13d.log 2>&1 &. ```. It failed at this command because of missing boost symbols in a link operation, my reading is that the command does not include anything to link boost libraries. So telling cmake where the libraries are, where the include files are, and that boost was found was not sufficient. There must be some other set of symbols which need to be defined. `/opt/rh/devtoolset-4/root/usr/bin/c++ -pthread -ftree-ve",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:455,message,message,455,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,5,['message'],['message']
Integrability,"My preference would be to throw a warning if any reads are shorter than the; kmer length and throw an error if all are. So if any reads are less then; k-mer length report ""Warning: x% of reads were found to be less than k used; to build index. Consider rebuilding index with smaller k. Minimum read size; found was [min read size]"" and then halt execution if x% is 100%. Would; that sound reasonable?. Thanks,. Kieran. On 8 February 2016 at 14:25, Rob Patro notifications@github.com wrote:. > Hi @kieranrcampbell https://github.com/kieranrcampbell,; > ; > Indeed, such reads will be un-mappable. The only tricky question here is; > at which point we should (1) do nothing (2) issue a warning (3) issue an; > error. Since the reads may not all be of the same size (perhaps the user; > has quality-trimmed the reads first and not opted to discard the short; > ones), it's possible we may see some reads too short to consider, but; > others would not be. We could choose arbitrary cutoffs (warning if greater; > than 1,000 such reads and an error if greater than 1,000,000), but this; > will, of course, depend on how large the input data set is. Anyway, I agree; > that we should notify the user of this and will be happy to add it; do you; > have any suggestions on the default behavior?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/COMBINE-lab/salmon/issues/41#issuecomment-181394180.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/41#issuecomment-181396844:1101,depend,depend,1101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/41#issuecomment-181396844,1,['depend'],['depend']
Integrability,"NC00337-001|LINC00337|1302|l""..., 8191) = 8191; read(4, ""\0\0\0\0ENST00000377728.7|ENSG000001""..., 8191) = 8191; read(4, ""|z\0\0\0\0\0\0\0ENST00000470648.5|ENSG0""..., 8191) = 8191; read(4, [1m[2017-04-05 16:40:33.297] [stderrLog] [info] Loading Transcript Info ; [00mread(4, ""35271.1|ENSG00000234546.3|OTTHUM""..., 8191) = 8191; read(4, ""00005018.1|UBE4B-003|UBE4B|2299|""..., 8191) = 8191; read(4, ""ding|x\0\0\0\0\0\0\0ENST00000468348.1|E""..., 8191) = 8191; read(4, ""005558.1|MTOR-001|MTOR|8677|prot""..., 8191) = 8191; read(4, ""rotein_coding|x\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""|\177\0\0\0\0\0\0\0ENST00000439324.2|ENSG0""..., 8191) = 8191; read(4, ""36.1|OTTHUMG00000009500.2|OTTHUM""..., 8191) = 8191; read(4, ""G00000175147.11|OTTHUMG000000020""..., 8191) = 8191; read(4, ""rotein_coding|}\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""ed_transcript|z\0\0\0\0\0\0\0ENST000004""..., 8191) = 8191; read(4, ""1|549|processed_transcript|{\0\0\0\0""..., 8191) = 8191; read(4, ""0006250.3|CROCC-002|CROCC|3931|p""..., 8191) = 8191; read(4, ""nscript|y\0\0\0\0\0\0\0ENST00000466151.""..., 8191) = 8191; read(4, ""R4|536|processed_transcript|q\0\0\0""..., 8191) = 8191; read(4, "".13|OTTHUMG00000002712.2|OTTHUMT""..., 8191) = 8191; read(4, ""0375079.6|ENSG00000158816.15|OTT""..., 8191) = 8191; ```. (First 500 lines, job is running well). ## Next steps. We are hoping that this info will give you an idea on what could be the source of the problem. Maybe `Salmon` requires a newer version of its dependencies than those that we have installed at JHPCE. . Under a scenario where `Salmon` doesn't change (and it's not a dependency issue), we could try running `Salmon` with increasing amounts of memory until we find a point where it doesn't fail for any of our samples (fastq files go to to 13 GB per read in a read pair, so 26 GB total for this particular dataset). We know that 90 GB total memory works, but like I've said before it's a pretty inefficient use of our cluster resources. Best,; Leo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:170218,depend,dependencies,170218,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['depend'],"['dependencies', 'dependency']"
Integrability,No worries - and that is exactly what I thought could be possible :-). Just out of curiosity - how would Salmon currently handle if half of a read could be quasi-mapped to a transcript but the second half did not fit anywhere (due to it being very low quality or sequencing adapter contamination)?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353287536:274,adapter,adapter,274,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353287536,1,['adapter'],['adapter']
Integrability,No worries. I've had issues with grabbing Jellyfish from the existing URL depending on the network setup as well. I may just copy that tarball to a GitHub artifact an have the makefile pull from GitHub instead. --Rob,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/5#issuecomment-110493426:74,depend,depending,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/5#issuecomment-110493426,1,['depend'],['depending']
Integrability,"Oh wow; I had no idea about libgff :). Regarding Jellyfish, there's not a source ""change"" required upstream, rather the fact that I seem to require the `config.h` file that is not installed during the ""normal"" Jellyfish install process. I don't know if you have any idea how one might get around that. Regarding staden, thanks for brining this to my attention. It will probably take a bit for me to wrap my head around the right way to access this information in CMake, but I'll see what I can manage to cobble together on that front (I really wish there was something better, with a less horrendous ""language"" than CMake, but nothing I know of exists that works nearly as well ""out of the box"").",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195436157:399,wrap,wrap,399,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195436157,1,['wrap'],['wrap']
Integrability,"Oh, I should've pushed my PR sooner!; Thanks!; I'll take a look how it compares to what I did. ; One thing to note is that it'd be useful to be able to specify the length of the CB - we use 8 bp in our slightly-adapted CEL-Seq2 protocol.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418579796:228,protocol,protocol,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418579796,1,['protocol'],['protocol']
Integrability,"Ok, I pushed a commit to develop that wraps this in try/catch (and also tries to print out the relevant value of the argument from the context). Please let me know if (1) this averts the uncaught exception and (2) what argument to digamma is triggering this strange behavior :)!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393610533:38,wrap,wraps,38,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393610533,1,['wrap'],['wraps']
Integrability,"Ok, salmon V1.0.0 finished in 5H 15 min, so about 5 times faster, the exact same library and parameters, and achieved almost the same mapping rate (85.1058% with V1.2.0 vs 84.6341% with V1.0.0) attaching log. I must add I did not trim this library for adapters nor quality, nor did anything to it. Just mapped as is. But fastQC showed excellent levels of quality even at the ends and no or minimal adapter content. ; Also no changes have been done one my OS other than regular updates, but still Ubuntu 18.04. I don't remember any specific changes I've done to it. ; Pearson's correlation in transcript abundance (isoform lelvel) is 0.9984013. Spearman's is 0.9899048. ; Also, I did checked that salmon was actually using 4 threads in both cases, and it was fully using those.; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4707443/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127:252,adapter,adapters,252,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127,2,['adapter'],"['adapter', 'adapters']"
Integrability,"Ok, thank you very much.; The problem I had was RAM availability. I enlarged it for 48 and it works.; However, to quantify I had another problem.; I use this command line and I increase to 56 RAM. srun ./salmon-1.5.2_linux_x86_64/bin/salmon quant -i salmon_index \; -l A \; -1 ERR3537668_1.fastq.gz \; -2 ERR3537668_2.fastq.gz \; -o transcripts_DecoyQuant \; --validateMappings \; --numBootstraps 100 \; --gcBias \; --seqBias\; -p 12. And I got this error message:; [2021-11-08 14:35:28.348] [jointLog] [info] Finished Bootstrapping; ERROR: Could not create the directory [""transcripts_quant""]. Please check; that. But actually, it was created.; I really don't understand the message error. Best wishes,; Luciana. On Fri, Nov 5, 2021 at 5:56 PM Rob Patro ***@***.***> wrote:. > Hi @lubios <https://github.com/lubios>,; >; > This suggests that the machine was not able to allocate enough memory to; > perform the requested operation. I would try the following things in order; > to see if they fix the issue. First, try quantifying without the; > decoy-aware index. This doesn't provide the benefits of the decoy sequence,; > but it will ensure that this is, in fact, the problem you are having. If; > that works, try building the decoy-aware index with the --sparse; > parameter. This will build the sparse index instead of the dense index,; > which is a bit smaller and may therefore fit in RAM on the machine where; > you are doing quantification.; >; > Best,; > Rob; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-962058307>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ADRT5CUYGXBSY3UOX24RTYDUKQLETANCNFSM5HOIMSQQ>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-963995631:456,message,message,456,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/717#issuecomment-963995631,2,['message'],['message']
Integrability,"Ok, when I attempt the build the way you say above, I get the following error during CMake:. ```; -- fetch PUFFERFISH exit code 127; CMake Error at CMakeLists.txt:317 (message):; Could not fetch pufferfish source [fetchPufferfish.sh returned exit code; 127]. -- Configuring incomplete, errors occurred!; See also ""/salmon-1.10.0/build/CMakeFiles/CMakeOutput.log"".; ```. It seems `wget`, `curl` and `unzip` were missing, and I had to install them. After that, I was able to build and install. At that point, I was able to reproduce the issue! So, it seems to me the underlying problem is coming from one of the upstream dependencies (i.e. libraries being linked to). I will try see if I can find the offender. In general, we like to statically link salmon for exactly this reason. Outside of package systems with which I am familiar (e.g. conda), we don't have a lot of experience in specifying dependent package version constrains, which I believe to be at fault here.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463973824:168,message,message,168,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463973824,3,"['depend', 'message']","['dependencies', 'dependent', 'message']"
Integrability,"On 11/04/2020 01:04, Rob Patro wrote:; > I saw no performance regressions, so 1.2.0 is built without the ; > offending flag. Thanks for the heads up. Hi, Rob. Thanks for fixing the problem so quickly!. Tony. -- ; Minke Informatics Limited, Registered in Scotland - Company No. SC419028; Registered Office: 3 Donview, Bridge of Alford, AB33 8QJ, Scotland (UK); tel. +44(0)19755 63548 http://minke-informatics.co.uk; mob. +44(0)7985 078324 mailto:tony.travis@minke-informatics.co.uk",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-612423808:317,Bridg,Bridge,317,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-612423808,1,['Bridg'],['Bridge']
Integrability,"One fast way using pseudo-alignments should be Kallisto+[Manta|Pizzly], but I haven't tried that myself. We decided to go with full transcriptome alignments instead and integrated EricScript into bcbio. We'd still be interested in something more modern, though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-280827732:169,integrat,integrated,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-280827732,1,['integrat'],['integrated']
Integrability,"Pinging @k3yavi / @DongzeHE here in case they have an idea of what would be used for this protocol. If we know the fragment geometry, I imagine we could just use the custom geometry flag.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1753070571:90,protocol,protocol,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1753070571,1,['protocol'],['protocol']
Integrability,Quantification matrix with adapted Celseq2 protocol,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361:43,protocol,protocol,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361,1,['protocol'],['protocol']
Integrability,"Right, the issue seems to be that the right binary is not getting created. My (re)compilation using the same script you shared above seems to be giving different help.; ```; alevin-specific Options:; -v [ --version ] print version string; -h [ --help ] produce help message; -o [ --output ] arg Output quantification directory.; -p [ --threads ] arg (=1) The number of threads to use; concurrently.; --tgMap arg transcript to gene map tsv file; --dropseq Use DropSeq Single Cell protocol for; the library; --chromiumV3 Use 10x chromium v3 Single Cell; protocol for the library.; --chromium Use 10x chromium v2 Single Cell; protocol for the library.; --gemcode Use 10x gemcode v1 Single Cell protocol; for the library.; --celseq Use CEL-Seq Single Cell protocol for; the library.; --celseq2 Use CEL-Seq2 Single Cell protocol for; the library.; ```. May I suggest removing the `CMakeCache.txt` file from the build folder of salmon and running `make -j 4 install` again. After recompilation using the `salmon` binary inside the `bin` folder should ideally give you the above updated help. However, If it doesn't resolve after that, I am compiling a linux binary and will share it to you to be used directly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443518366:266,message,message,266,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443518366,7,"['message', 'protocol']","['message', 'protocol']"
Integrability,"Rob,. 	I let you know on the forum page, but just ot make sure it worked and I was ; able to index my transcriptome. Thank you!. Best wishes,; Rich; > On Apr 17, 2018, at 9:44 AM, Rob Patro <notifications@github.com> wrote:; > ; > Hi Rich,; > ; > The issue with pre-compiled OSX binaries is that they are difficult to make portable across OSX versions. This is why we strongly suggest installing Salmon (especially for OSX) through Bioconda. This greatly eases installation and updating, and doesn't require admin privileges. On OSX, you can try the following:; > ; > $ conda config --add channels conda-forge; > $ conda config --add channels bioconda; > $ conda create -n salmon salmon=0.9.1; > ; > This should take care of all relevant dependencies as well as e.g. library locations and placement. Could you please give this a try and let me know if it works for you?; > ; > Best,; > Rob; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.; > . Richard A. Friedman, PhD; Associate Research Scientist,; Biomedical Informatics Shared Resource; Herbert Irving Comprehensive Cancer Center (HICCC); Lecturer,; Department of Biomedical Informatics (DBMI); Room 825; Irving Cancer Research Center ; Columbia University Herbert and Florence Irving Medical Center; 1130 St. Nicholas Ave; New York, NY 10032; (212)851-4765 (voice); raf4@cumc.columbia.edu. http://www.columbia.edu/~raf4/index.html. “Will there still be ""Classics Illustrated” by the time I have children? I cannot; imagine raising kids without ""Classics Illustrated” .” -Rose Friedman, age 20",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-382031768:738,depend,dependencies,738,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-382031768,1,['depend'],['dependencies']
Integrability,"Rob,; Rob,. Thank you. It worked. I was able to make my index without error messages. Best wishes,; Rich",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-382031294:76,message,messages,76,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/215#issuecomment-382031294,1,['message'],['messages']
Integrability,"Running Salmon-0.7.2_linux_x86_64 with --writeMappings=map.out and it crashes with:. Exception : [boost::filesystem::create_directory: No such file or directory]. When I run without a file name, it outputs to stdout, but it also outputs messages such as:; ESC[1m[2016-09-14 11:06:07.550] [jointLog] [info] parsing read library format; ESC[00mESC[1m[2016-09-14 11:06:07.550] [jointLog] [info] There is 1 library.; ESC[00mESC[1m[2016-09-14 11:06:08.300] [jointLog] [info] Loading Quasi index; ESC[00mESC[1m[2016-09-14 11:06:08.300] [jointLog] [info] Loading 32-bit quasi index; So the output is not a clean .sam file. ~/programs/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /data/reference/salmon/gencode.grch37.v19/ -r test.fastq --seqBias --gcBias --posBias -p 12 --writeMappings=map.out --geneMap /data/reference/salmon/gencode.grch37.v19/geneMap.txt --libType U -o x",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/90:237,message,messages,237,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/90,1,['message'],['messages']
Integrability,Salmon also depends on `libz` when compiling `bwa`.; https://gist.github.com/anonymous/a50569adddca1b8605f7#file-02-make-L118-L120. ```; /usr/bin/gcc-4.8 -c -g -Wall -Wno-unused-function -O2 -DHAVE_PTHREAD -DUSE_MALLOC_WRAPPERS utils.c -o utils.o; utils.c:33:18: fatal error: zlib.h: No such file or directory; #include <zlib.h>; ```,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193959265:12,depend,depends,12,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193959265,1,['depend'],['depends']
Integrability,Salmon depends on Staden depends on xz for lzma.h,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45:7,depend,depends,7,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45,2,['depend'],['depends']
Integrability,Salmon error message: salmon quant was invoked improperly,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/209:13,message,message,13,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/209,1,['message'],['message']
Integrability,"Salmon is version 0.9.1. This is happening for lots of samples, the error message is always `Exception : [Failed to read 879238456 bytes from input stream! Read 851443704]` regardless of the fastq files that are provided. . Nothing else too special is going on. It doesn't seem to have this problem with other indexes. Can you try to load and map again with 0.9.1?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442569984:74,message,message,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442569984,1,['message'],['message']
Integrability,"Seems to work on some of the test at my end, let me know if its still a problem. The command to use would be; ```; salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21; ```. One thing to note, since it's a 5' protocol, you might have to change `-lISR` to `-lISF` since the 5` protocol expects the single-cell reads from the forward strand, unlike 3' where we expect the reads from reverse. It should not be a problem for the guide/feature barcodes though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638444905:266,protocol,protocol,266,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638444905,2,['protocol'],['protocol']
Integrability,"So I got the data and am trying to repro the issue now (thanks!). Quick question. I noticed in your example command you have `--libType ISF`. However, you have single-end reads, so the appropriate library type would be `SF` (i.e., they can't be ""inward"" facing reads, b/c there is no mate for each read). When I run your command as is, but replace `ISF` as `SF`, my run completes successfully, and I don't get any `errorminEQClassWeight` output. Could you let me know if this makes any difference for you (also, sorry that, apparently, we're not outputting a useful error message when one passes in a paired-end library type with single-end data). edit: Actually, it's even stranger. I noticed that in your command the library type comes *after* the reads to which it refers, but in this case, Salmon will not apply that library type to those reads (which explains why you're not getting a warning message). The restriction that the `--libType` flag comes before the reads it describes is buried in [the docs](http://salmon.readthedocs.io/en/latest/salmon.html#using-salmon), but I definitely need to make that clearer. Anyway, the point is that, in this case, Salmon should apply the ""default"" single-end library type (i.e., `U`) to your reads. So, presumably, that was what was happening when you saw the strange behavior during Gibbs sampling (and is also what was happening when my Gibbs sampling run completed successfully).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266927204:572,message,message,572,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266927204,2,['message'],['message']
Integrability,"So after struggling, and failing for a little bit I looked into linuxbrew - its pretty much the best thing ever. I'm honestly not sure what my original issue was derived from but using linuxbrew to install the dependancies and then salmon itself worked perfectly. Honestly much easier to install it this way. . Salmon seems to be working now so I'd say my install issues are resolved. Thanks for your help, and an extra thanks for introducing me to linuxbrew, its going to make my work a lot easier.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314548472:210,depend,dependancies,210,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314548472,1,['depend'],['dependancies']
Integrability,"So, it turns out that with the dependency setup that is pulled in, I can't even get `salmon` to build without `USE_SHARED=TRUE`. I think at this point, it's not clear the segfault is due to something that is broken / can be fixed in the salmon code itself. Rather, it's likely due to a misversioning of a dependency that is pulled in and then linked against. For the time being, I think the options are to do a more ""standard"" build (i.e. like the first one I suggested that pull in only that minimal set of dependencies and let salmon itself statically link the rest), or to try and look at the upstream shared libraries being linked and figure out which of them is misversioned. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464124885:31,depend,dependency,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464124885,3,['depend'],"['dependencies', 'dependency']"
Integrability,Strange the updated error message has @PG not @pg,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387498610:26,message,message,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387498610,1,['message'],['message']
Integrability,"Strangely enough - with the above error message of mine. when I go to the logs directory and look up salmon_quant.log, it has correct info (last line below); ```; [2020-04-22 19:45:18.487] [jointLog] [info] Finished Bootstrapping; ```. And the output directory has a `quant.sf` file and it has all the records I want -- however, salmon is exiting with the above error message",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618027626:40,message,message,40,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618027626,2,['message'],['message']
Integrability,"Strictly speaking, barcodes.tsv**.gz** files are provided. I was viewing the uncompressed file in Notepad++, so I think that number (from the line numbers on the left) should be correct. I will double-check the next time that I am on my work computer. I will test using the smaller number of barcodes. However, unlike the larger file, I think this would be different for every sample. If part of the reason that I wanted to run Alevin is that I wanted an independent quantification (which takes less time), then that may be a notable limitation. However, for whatever reason, this seems to only be an issue with the v2 sample (the v3 sample worked fine). So, I will test that, and I will at least confirm if I see the same error message or not.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878693769:729,message,message,729,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878693769,1,['message'],['message']
Integrability,"Strictly speaking, if I use the barcodes.tsv (decompressed) files from CellRanger (for the _same sample_), I still get the same error message. I get the error message below, with or without ""-1"" at the end of the barcodes:. ```; [2021-07-12 15:55:48.717] [alevinLog] [info] Done importing white-list Barcodes; [2021-07-12 15:55:48.717] [alevinLog] [error] Wrong whitelist provided; Please check https://salmon.readthedocs.io/en/develop/alevin.html#whitelist; ```. If I **don't** use any white list, then I think that should be one possible resolution (mentioned before). However, in case others have a similar question, I have at least temporarily re-opened the ticket. This is the command that I am currently using:. ```; ID=5309-CT-2; R1=../Reads/5309-CT-2_S01_L005_R1_001.fastq.gz; R2=../Reads/5309-CT-2_S01_L005_R2_001.fastq.gz. TYPE=10xV2; #for MAP, download from UCSC Table Browser, and remove 1st line (and then manually add SARS-COV-2 genes); MAP=../../Ref_Generation/SARS_COV_2-hg38_RefSeq_2column.txt; REF=../../Ref_Generation/SARS_COV_2-hg38_salmon; CBWL=../CellRanger/5309-CT-2/outs/raw_feature_bc_matrix/barcodes.tsv. /path/to/salmon-1.5.1_linux_x86_64/bin/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP --whitelist $CBWL; ```. **Is there anything that you think I should change, if I wanted to confirm that I can run the analysis with some sort of white list?**",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878688294:134,message,message,134,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878688294,2,['message'],['message']
Integrability,"Sure --- since, at this point, I don't seem able to reproduce the issue any more. Just for a sanity check, can you md5sum the binary you have? I have `fc39599b6c027eb97bb2f4c7bdd361f3`. Previously, I was getting the same segfault as you, but now it finishes cleanly:. ```; [2016-01-02 13:13:10.643] [jointLog] [info] iteration = 4500 | max rel diff. = 0.0100814; [2016-01-02 13:13:10.703] [jointLog] [info] iteration = 4508 | max rel diff. = 0.00999839; [2016-01-02 13:13:10.714] [jointLog] [info] Finished optimizer; [2016-01-02 13:13:10.714] [jointLog] [info] writing output. [2016-01-02 13:13:10.871] [jointLog] [warning] NOTE: Read Lib [( /dev/fd/63, /dev/fd/62 )] :. Detected a strand bias > 1% in an unstranded protocol check the file: salmon_flux_quant_nofspd/libFormatCounts.txt for details. [2016-01-02 13:13:10.871] [jointLog] [warning] NOTE: Read Lib [( /dev/fd/63, /dev/fd/62 )] :. Greater than 5% of the alignments (but not, necessarily reads) disagreed with the provided library type; check the file: salmon_flux_quant_nofspd/libFormatCounts.txt for details. rob@feynman:~/SoftwareStaging/salmon/build/tmp; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168413403:717,protocol,protocol,717,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168413403,1,['protocol'],['protocol']
Integrability,"Sure, works for me. Is it possible to add an argument that indicates that the dependencies (like `xz`) should be provided by the host, and any missing dependencies are an error, rather than installing them automatically?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193944377:78,depend,dependencies,78,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193944377,2,['depend'],['dependencies']
Integrability,"Sure; the other thing you may want to consider is what is in your index. For example, if you had a ribo-zero protocol here, you may get a higher mapping rate if you include rRNA. Otherwise, is there a significant degree of intron retention?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/170#issuecomment-341735839:109,protocol,protocol,109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/170#issuecomment-341735839,1,['protocol'],['protocol']
Integrability,Tell to cmake the different places for the dependencies,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/225:43,depend,dependencies,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/225,1,['depend'],['dependencies']
Integrability,"Thank *you* for providing this software to the community.; BTW, it seems you're making an effort to support externally installed dependencies, for which I'm grateful. I did have to patch around a few bundled deps (e.g. libgff), which are downloaded unconditionally. Many package managers (e.g. FreeBSD ports, Gentoo Portage, MacPorts, pkgsrc, ...) do not allow manual downloads by upstream build systems, for obvious security reasons. I'm hoping it will be possible to avoid all such downloads without patching in the future, by preinstalling and having them discovered by find_package(), as you're already doing for things like bzip2. This will make it easier to package salmon in many of the numerous package managers out there (and eliminate the need for you to install dependencies via cmake). Cheers!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420352699:129,depend,dependencies,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420352699,2,['depend'],['dependencies']
Integrability,"Thank @rob-p and @gmarcais, that clarifies it. There's only a handful of reads that seem to fall in this category.; Just a suggestion would it better to have just a one line summary on the amount of reads that are categorised as such and then make quite the error messages?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1422213426:264,message,messages,264,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1422213426,1,['message'],['messages']
Integrability,Thank you for the response. I suspect the same. mapping works fine normally but keeps giving me this error when I follow their protocol. They have this .R file that they say is bundled up with the index. Anyways I am not an expert in the field. Thank you for your quick response.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/833#issuecomment-1451389744:127,protocol,protocol,127,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/833#issuecomment-1451389744,1,['protocol'],['protocol']
Integrability,"Thanks @Gaura! Sounds promising. . Can you clarify what differences you saw between v1/v2 protocols? My understanding was that the only changes were slight differences in barcode positions within the barcode read, ie something that could be handled with different `bc-geometry`, but maybe that's all you meant in terms of differing implementations. Regarding the BC1 and how it could be two sequences for the same sample - this is confusing to explain in text format, but all comes down to the sequential nature of how the cells acquire barcodes in this protocol. We start with a 96-well plate, where each of the top 48 wells contain BOTH an oligo-dT barcode and random hexamer barcode. The samples then get added to each well. Biochemistry happens. Then you pool all the cells together, split them back out into 48 wells again, and each well gets its own BC2. Then repeat for BC3. . So a given transcript may get amplified via one of two amplification primers (oligo-dT or random hexamer), but after that, will get a single BC2 sequence and BC3 sequence added after that. In Fig 1A of the Rosenberg paper, it's as though there isn't _just_ an orange sequence carrying out reverse transcription, there are actually two different (known) sequences associated with different routes of amplification per cell. . The net effect is that a given cell can contain transcripts that have a sequence like this:; AACGTGAT-CTGTAGCC-ACACAGAA. or like this:; GATAGACA-CTGTAGCC-ACACAGAA. where maybe the first sequence was amplified by oligo-dT and the second was amplified via a random hexamer. Because they have the same BC2 and BC3 sequence, and the BC1 sequences match a known pairing, we know they come from the same cell and therefore the data should be merged. . Any lab running these experiments will have a table of known pairings (ie the two barcodes added to each of first 48 wells), so that they can be merged and treated as though they came from the same cell. This can either be handled upstream of sal",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-937918722:90,protocol,protocols,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-937918722,2,['protocol'],"['protocol', 'protocols']"
Integrability,"Thanks @Ryan-Zhu for your feedbacks and the suggestion.; I apologize for the trouble you had to face while working with the alevin output.; We will prepare better from the next release and try updating the external dependencies first before making an official release. ; Just wanted to give you the heads up that I have also updated the bug for the scientific notation in the `mtx` format. It's in the develop branch of alevin, if you have time please let me know if it works for you. Thanks again.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-502828416:215,depend,dependencies,215,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-502828416,1,['depend'],['dependencies']
Integrability,"Thanks @molwizard,. We've added a more informative error message in 0.13.0. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/343#issuecomment-469843098:57,message,message,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/343#issuecomment-469843098,1,['message'],['message']
Integrability,"Thanks @rob-p I am glad you and others have found it useful. The actual bbmap.sh and bbduk.sh commands for SE data are in the links to Phil Ewels' multiqc GH. . Just like salmon indexing kmer size choice, one can tinker with the **_```k, hdist, minq and other parameters```_** of bbduk depending on how good/bad the data is. Needless to state, bbduk is the swiss-army-knife for sequence reads quality assessment with whole range of parameters to tweak . https://jgi.doe.gov/data-and-tools/bbtools/bb-tools-user-guide/bbduk-guide/ suggests; ![image](https://user-images.githubusercontent.com/8467214/78302368-a3695980-7508-11ea-990d-4b6e008e3f07.png)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-608105756:286,depend,depending,286,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-608105756,1,['depend'],['depending']
Integrability,"Thanks Jeremy! Yes, that's what I was hinting at with different v1/v2 protocols. From their code, you can see differences in amplicon sequences:; - For v1: 'NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGAGGCCAGAGCATTCGIIIIIIII'; - For v2: 'NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGACTGTGGIIIIIIII'; where the `IIIIIIII` sequence corresponds to barcode. This is from the pipeline code I mentioned earlier used for [this paper](https://www.nature.com/articles/s41593-021-00872-y). Do you have a the pairing file for the BC1 barcodes? Is it the Supp Table S12 in the Rosenberg paper? It is needed for development and testing.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951080577:70,protocol,protocols,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951080577,1,['protocol'],['protocols']
Integrability,Thanks Rob - haven't had the message pop up in the last few days. All seems to be running smoothly. Thanks again!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-349358819:29,message,message,29,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-349358819,1,['message'],['message']
Integrability,"Thanks a lot @k3yavi for the code.; It doesn't seems to work, I don't think it normalize in a proper way: genes that are highly expressed (RPS/L, ACTB, B2M, etc...) are much more duplicated during the PCR than lowly expressed genes. So lots of reads, but less much counts after quantification (and summarization at the UMI level). So if one sequences deeply any sample, it would affect in a very uneven way both the cells and genes, depending on the level of transcriptional activity of the cell (cycling...) and the level of expression of a given gene. Then subsampling the fastq files before any quantification would be more fair, what do you think?. You can also see the notes on:; https://github.com/theislab/scanpy/pull/340",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-435356841:433,depend,depending,433,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-435356841,1,['depend'],['depending']
Integrability,Thanks for the detailed report! I wonder if we can bump the max version on salmon 1.4.0. I seem to remember icu 67 conflicting with another dependency before. We'll have to look into that.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/594#issuecomment-736155340:140,depend,dependency,140,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/594#issuecomment-736155340,1,['depend'],['dependency']
Integrability,"Thanks for the recommendation. I'll definitely take a look at it. It is true that we typically suggest that you drop singletons if they are created during e.g. adapter / quality trimming etc.. However, it is also the case that one really may only want to consider very ""light"" quality trimming for RNA-seq data [as suggested by Matt MacManes](https://www.frontiersin.org/articles/10.3389/fgene.2014.00013/full). . If the trimming leads to the loss of a large number of reads, my initial reaction would be to try an understand why. One could always ""re-synchronize"" the singletons by providing them with fake mates, which would cause them to be mapped and treated as orphans during quantification. However, again, it's probably worth understanding why an experiment ends up with a lot of singletons before going through the trouble of accounting for them.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-400061755:160,adapter,adapter,160,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-400061755,2,"['adapter', 'synchroniz']","['adapter', 'synchronize']"
Integrability,"Thanks for the thorough suggestions. Actually, we fall into the easier case since Salmon does not support mixing single and paired-end reads in a single BAM file. When performing quantification on a single sample, the reads for that sample must follow a uniform library type. For paired-end reads, the BAM file can contain paired-end and single-end alignments (i.e. orphans), but the reads must all have been paired _in sequencing_. Mixing different library types in the BAM file makes it difficult to assess the compatibility of a fragment with the expected library type, especially if fragments from the different library types are expected to exist in a specific ratio in the input. Anyway, my main motivation for having the separate `AS` and `AP` types was to prevent the need to ""peek"" in the file, since, currently, there is not an easy way to peek the first read without opening the first file twice. However, I've decided that the benefit of having the same uniform (and simpler) interface of `A` always representing automatic library type detection is probably worth it, so I've pushed this implementation (commit 6116b2a). So, when the user provides the `A` library type, Salmon will peek into the first record in the BAM file to determine if the fragment was paired in sequencing or not, and will then set the single / paired-end status on that basis. The only corollary to this is that, in alignment-based mode, the `A` flag is not compatible with an input stream (i.e. the input must be a regular file). I will be sure to document this when I update the docs for the version bump.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463:988,interface,interface,988,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463,1,['interface'],['interface']
Integrability,"Thanks for your patience Rob - I am new to github.; Here are the files you requested. On Sun, Oct 2, 2016 at 1:20 PM, Rob Patro notifications@github.com wrote:. > Hi Amy,; > ; > Unfortunately, when you reply to github via e-mail, it doesn't include; > attachments. Could you please either upload the files here (the github web; > interface supports drag-and-drop), or just send me an email.; > ; > Thanks,; > Rob; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/COMBINE-lab/salmon/issues/96#issuecomment-250982842,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/AVgEwlnL21CDlhAcRpCEHgNo2UcN-mpPks5qv-fCgaJpZM4KLJrJ; > . ## . Amy K. Voltz, Ph.D.; avoltz@umd.edu; Assistant Clinical Professor; First-Year Innovation & Research Experience; Terrapin Genome Project; Office: Microbiology 1126B; **\* check out our new lab space in BioPsych Building room 2217 ***",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/96#issuecomment-250983890:330,interface,interface,330,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/96#issuecomment-250983890,1,['interface'],['interface']
Integrability,"Thanks sir. On Thu, Nov 21, 2019 at 9:27 PM Rob Patro <notifications@github.com> wrote:. > Hi @shanmugavadivelps <https://github.com/shanmugavadivelps>,; >; > This is because, to properly find and link libiconv, the build requires a; > version of CMake that ships with FindIConv.cmake. So, to build salmon from; > source, you should have at least CMake version 3.12. Internally and on our; > continuous integration servers, we use version 3.15.; >; > Also, I'll mention that it may not be essential to build from source.; > Salmon is available via Bioconda, and a docker image is available via; > DockerHub. Also, we have a pre-compiled binary that should work on many; > linux distributions available under our releases; > <https://github.com/COMBINE-lab/salmon/releases>.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/453?email_source=notifications&email_token=AN2V7HW3GLUZR52T4BJKOFLQU2VYHA5CNFSM4JP7NHKKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEE2W3DI#issuecomment-557149581>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AN2V7HTVJB3TCKRKDY6YKI3QU2VYHANCNFSM4JP7NHKA>; > .; >. -- ; *Shanmugavadivel, P. S.*; *Scientist (Agricultural Biotechnology),*. *#216, Block A,*; *ICAR-Indian Institute of Pulses Research,*. *Min. of Agriculture & Farmers Welfare,*. *Govt. of India,Kanpur - 208 024.*; *email: shanmugavadivel.ps@icar.gov.in <shanmugavadivel.ps@icar.gov.in>*; *www.iipr.res.in <http://www.iipr.res.in>*",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557774568:403,integrat,integration,403,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557774568,1,['integrat'],['integration']
Integrability,"Thanks, @lgautier! I think that ideally, we will create a github repo for all dependencies, so that we can control such availability issues.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/23#issuecomment-152302062:78,depend,dependencies,78,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/23#issuecomment-152302062,1,['depend'],['dependencies']
Integrability,"Thanks, I usually do not trim reads. I am surprised to see such a difference from version 0.8.3. Do you have a recommendation for --minScoreFraction if I do not trim reads? Or maybe I should go back to NOT using --validateMappings?; For testing purposes, I will try trimming the reads for this sample. Will report back.; Oh, and this sample was prepared by ultra-low RNA input protocol, so the issues of adapter contamination could be present.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673:377,protocol,protocol,377,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673,2,"['adapter', 'protocol']","['adapter', 'protocol']"
Integrability,"Thanks, I was good with linking against external jemalloc after your first reply. Mainly interested in knowing the details of your concern, so thanks for elaborating. We use pkgsrc for most of our CentOS installs, and now I feel safe using devel/jemalloc as a dependency. We also use FreeBSD, and in this case, I just patched out the dependency altogether, since jemalloc is FreeBSD's default allocator. Cheers!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420343097:260,depend,dependency,260,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420343097,2,['depend'],['dependency']
Integrability,"Thanks, Rob. I'll add `unzip` to the build dependencies of `salmon`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367802780:43,depend,dependencies,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367802780,1,['depend'],['dependencies']
Integrability,That sounds like a very good way of doing it :-). I'm sorry I was not clear enough - my question was acutally meant for a single sequence - let me try again:; Lets say we have a read pair where one mate maps fine - but the other mate have a problem - half of it is an adapter (or low quality sequence with to many errors). How would Salmon currently handle this situation where the first half of a sequence (e.g. nt 1-50) could be quasi-mapped to a transcript but the second half (nt 51-100) did not match anywhere? Would the the second half cause the whole sequence to be discarded or would it be enough that the first half matched for it to be considered/counted?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-354955072:268,adapter,adapter,268,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-354955072,1,['adapter'],['adapter']
Integrability,"The CMakeLists.txt refuses to handle anything except GNU and Clang compilers. It should be easy to support Intel as well since it understands most/all(?) GNU compiler flags. CMAKE will report the compiler type as ""Intel"" and [C++11 is supported from 14.0 and forward](https://software.intel.com/en-us/articles/c0x-features-supported-by-intel-c-compiler). My rough wip to get this building uses the following:. ```; diff --git a/CMakeLists.txt b/CMakeLists.txt; index c95f755..30f1223 100755; --- a/CMakeLists.txt; +++ b/CMakeLists.txt; @@ -118,8 +118,30 @@ elseif (""${CMAKE_CXX_COMPILER_ID}"" MATCHES ""Clang""); else(); set (PTHREAD_LIB ""pthread""); endif(); +elseif (""${CMAKE_CXX_COMPILER_ID}"" MATCHES ""Intel""); + execute_process(; + COMMAND ${CMAKE_CXX_COMPILER} -dumpversion OUTPUT_VARIABLE INTEL_VERSION); + if (NOT (INTEL_VERSION VERSION_GREATER 14.0 OR INTEL_VERSION VERSION_EQUAL 14.0)); + message(FATAL_ERROR ""${PROJECT_NAME} requires intel 14.0 or greater. Found ${INTEL_VERSION}""); + endif (); +; + set (INTEL TRUE); + set (PTHREAD_LIB ""pthread""); + set (CMAKE_CXX_FLAGS ""-pthread -funroll-loops -fPIC -fomit-frame-pointer -Ofast -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -std=c++11 -Wreturn-type -Werror=return-type""); +; + # If we're on Linux (i.e. not OSX) and we're using ; + # gcc, then set the -static-libstdc++ flag; + if (NOT APPLE) ; + set (CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -static-libstdc++""); + endif(); +; + set (WARNING_IGNORE_FLAGS ""${WARNING_IGNORE_FLAGS} -Wno-unused-local-typedefs""); + set (BOOST_TOOLSET ""intel""); + set (BOOST_CONFIGURE_TOOLSET ""--with-toolset=gcc""); + set (BCXX_FLAGS ""-std=c++11""); + set (BOOST_EXTRA_FLAGS toolset=gcc cxxflags=${BCXX_FLAGS}); else (); - message(FATAL_ERROR ""Your C++ compiler does not support C++11.""); + message(FATAL_ERROR ""Your C++ compiler (${CMAKE_CXX_COMPILER_ID}) does not support C++11.""); endif (). ## TODO: Figure out how to detect this automatically; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/9:894,message,message,894,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/9,3,['message'],['message']
Integrability,"The Klein group has a new inDrop protocol that has the 4 file format as well that should be cropping up in publications sometime soon. Not sure if it is nicked from the 10x folks but it is:. ```; {; ""read1"": ""(?P<name>[^\\s]+).*\\n(?P<seq>.*)\\n\\+(.*)\\n(?P<qual>.*)\\n"",; ""read2"": ""(.*)\\n(?P<CB1>.*)\\n(.*)\\n(.*)\\n"",; ""read3"": ""(.*)\\n(?P<SB>.*)\\n(.*)\\n(.*)\\n"",; ""read4"": ""(.*)\\n(?P<CB2>.{8})(?P<MB>.{6})\\n(.*)\\n(.*)\\n""; }; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269662717:33,protocol,protocol,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269662717,1,['protocol'],['protocol']
Integrability,"The ability to guess RNAseq library format is very useful when quantifying numerous heterogeneous data sets. I tested Salmon's ability to guess library format using a public SRA dataset (PRJNA543304; PMID: 31216476). This dataset was generated using a paired-end stranded protocol (TruSeq Stranded Total RNA Library Prep Kit, Illumina, Cat. 20020597). Based on my understanding, the library format using Salmon's notation would be ISR. Briefly, with the help of several R packages (GenomicRanges, Biostrings, and rtracklayer) I generated my own FASTA file using the human genome sequence and exon annotations both from Ensembl. I extracted the sequences of both mature transcripts and their premature precursors. I was sure to get the reverse complement sequences of genes on the minus strand. I generated an index from this FASTA file without decoys (salmon index -k 31) and quantified the FASTQ files using the following sample code:. ```; # Shuffle FASTQ files; paste <(cat SRR9071838_1.fastq) <(cat SRR9071838_2.fastq) | paste - - - - | shuf --random-source=SRR9071838_1.fastq | \; awk -F '\t' -v std=""$SLURM_TMPDIR"" '{ OFS=""\n""; print $1,$3,$5,$7 > (std ""/SRR9071838_1.fastq""); print $2,$4,$6,$8 > (std ""/SRR9071838_2.fastq"") }'. # Quantify; ./software/salmon-1.4.0_linux_x86_64/bin/salmon quant -i ./shared_data/annotations/Salmon/noDecoys \; -o ./Salmon_out_final_shuf_a_noDecoys/SRR9071838 -l A -p 8 \; -1 $SLURM_TMPDIR/SRR9071838_1.fastq -2 $SLURM_TMPDIR/SRR9071838_2.fastq; ```; I then briefed over the resulting lib_format_counts.json files and noticed that in all but one case, Salmon inferred that the library format is IU, not the expected ISR. Here is a summary:. ```; > salmon.guess.auto; read_files expected_format compatible_fragment_ratio num_compatible_fragments num_assigned_fragments num_frags_with_concordant_consistent_mappings; 1: [SRR9071838_1.fastq, SRR9071838_2.fastq] IU 1.0 46378505 46378505 55523877; 2: [SRR9071839_1.fastq, SRR9071839_2.fastq] ISR 1.0 50070023 50070023",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655:272,protocol,protocol,272,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655,1,['protocol'],['protocol']
Integrability,"The current behavior, which I think is the most reasonable for now, is to keep logging messages to stderr, even if they are not errors. This lets us use stdout for output which may need to be redirected to other programs (e.g. mapping results).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-245804636:87,message,messages,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-245804636,1,['message'],['messages']
Integrability,"The issue relates to the error message, so maybe I will close the issue in terms of being able to run the program without generating the error message. However, I think something still doesn't seem right, and I thought I should make that clear. <table>; <tbody>; <tr>; <th align=""center"">Method</th>; <th align=""center"">SRR13313130</th>; <th align=""center"">10x_pbmc_5k</th>; </tr>; <tr>; 	 <td align=""left"">CellRanger</td>; <td align=""center"">9,974 cells</td>; <td align=""center"">4,956 cells</td>; </tr>; <tr>; 	 <td align=""left"">STARsolo</td>; <td align=""center"">7,587 cells</br><i>(Summary.csv)</i></td>; <td align=""center"">4,586 cells</br><i>(Summary.csv)</i></td>; </tr>; <tr>; 	 <td align=""left"">Alevin</td>; <td align=""center""><b>814 cell barcodes?</b></td>; <td align=""center""> 856,224 cell barcodes</td>; </tr>; <tr>; 	 <td align=""left"">Kallisto</td>; <td align=""center"">79,254 cells</br><i>(BUSpaRse)</i></td>; <td align=""center"">47,598 cells</br><i>(BUSpaRse)</i></td>; </tr>; <tr>. </tbody>; </table>. For Alevin and Kallisto, I am not so worried about the exact values for cell barcodes (versus cells), since I was expecting extra work was needed to estimate a cell count from a distribution of measurements for each cell barcode. However, the number of cell barcodes should be larger than the number of cells, and that seems to match for everything except Alevin for this sample (SRR13313130). In other words, for sample, I think that this is the command that generates the fewest errors/warnings/notes:. `/path/to/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP`. However, I think the cell barcode count is too small. **Is there anything else that you would recommend trying?**",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-882751952:31,message,message,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-882751952,2,['message'],['message']
Integrability,The languages of both autotools and CMake are pretty terrible. I actually like the Make language; I think it gets a bad wrap. Other than `config.h` was there any other files of Jellyfish that were missing from the install that you needed?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195461547:120,wrap,wrap,120,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-195461547,1,['wrap'],['wrap']
Integrability,"The response by genomax [here](https://www.biostars.org/p/444853/) is spot on too. There are many, independent, overlapping reads here. If you have some other reason to believe this is wrong, we’d be happy to investigate further. However, I’m going to close the issue for the time being. . P.S. Yes, salmon is the right tool for full-length, plate-based protocols. Alevin is for tagged end (mostly droplet-based) protocols.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/539#issuecomment-647038324:354,protocol,protocols,354,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/539#issuecomment-647038324,2,['protocol'],['protocols']
Integrability,The segfault seems to be happening with Jemalloc (an external dependency). I'm going to see if switching to tcmalloc in the binary build fixes it.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168361093:62,depend,dependency,62,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168361093,1,['depend'],['dependency']
Integrability,"The specific error message seems to be coming from [the serialization library we use](https://github.com/USCiLab/cereal/blob/master/include/cereal/archives/portable_binary.hpp#L245). This was upgraded recently, so I'm hoping that they didn't introduce a new bug upstream. As soon as I can reproduce this, I can test if rolling back the version of the serialization library fixes the issue (which I don't believe occurred in 0.7.2).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287255919:19,message,message,19,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287255919,1,['message'],['message']
Integrability,"The standard is the code chunk in the vignette:. ```; txi <- tximport(files, type = ""salmon"", tx2gene = tx2gene); # then below...; dds <- DESeqDataSetFromTximport(txi, sampleTable, ~condition); ```. Or even better, you can use tximeta:. ```; se <- tximeta(coldata); gse <- summarizeToGene(se); dds <- DESeqDataSet(gse, ~condition); ```. If you have a special protocol which does not involve fragmentation of a full length transcript, then you do something else. But if you are fragmenting molecules and sequencing from along the entire transcript, use those code chunks from the vignette.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719734272:359,protocol,protocol,359,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719734272,1,['protocol'],['protocol']
Integrability,"There has been a small amount of discussion about the BD Rhapsody barcode / sequence format (e.g. see [here](https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-551083490)), but it would be great if the option could be integrated into the code. BD has produced a [Single Cell Genomics Bioinformatics Handbook](https://www.bd.com/documents/guides/user-guides/GMX_BD-Rhapsody-genomics-informatics_UG_EN.pdf) which has the following information about the R1 read structure on pg 14:. 5' CLS1 - L1 - CLS2 - L2 - CLS3 - UMI - poly(T); 9 12 9 13 9 8 18; [1-9] [22-30] [44-52][53-60]. > **Cell Label** Information of the cell label is captured by bases in three sections (CLS1, CLS2, CLS3) along each R1 read. Two common sequences (L1, L2) separate the three CLSs, and the presence of L1 and L2 relates to the way the capture oligonucleotide probes on the beads are constructed. By design, each CLS has one of 96 predefined sequences, which has a Hamming distance of at least four bases and an edit distance of at least two bases apart. A cell label is defined by the unique combination of predefined sequences in the three CLSs. Thus, the maximum possible number of cell labels is 96^3 (884,736). A cell label is represented by an index between 1–96^3. > Reads are first checked for perfect matches in all three pre-designed CLS sequences at the expected locations, CLS1:; position 1–9, CLS2: position 22–30, and CLS3: position 44–52. Reads with perfect matches are kept. In other words...; - Concatenate subsequences 1-9, 22-30, and 44-52 to form a 27-base cell label; - Extract subsequence 53-60 as the UMI . > **UMI** By design, the UMI is a string of eight randomers immediately downstream of CLS3. If the CLSs have perfect matches or base substitutions, the UMI sequence is at position 53–60. For reads with insertions or deletions within the CLSs, the UMI sequence is eight bases immediately following the end of the identified CLS3. R2 reads are transcript-only, and are expected to match a",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/628:229,integrat,integrated,229,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/628,1,['integrat'],['integrated']
Integrability,"There should be easy ways to handle reading line-buffered input from two file descriptors, where both file descriptors could be identical, and then passing these streams internally to buffers to be chunked for multithreaded processing. This would give you one code path for ingesting data, and the command line interface could remain the same as it is currently, with the possible addition of mapping the `-` symbol to `/dev/fd/0`. Is there really much to be gained from buffering all input in byte chunks up front? Remembering that unix pipes are buffered somewhat by default anyway? There has to be an acceptable way to handle line-based input in a more flexible way. In Python I would do:. ``` python; import argparse. example_parser = argparse.ArgumentParser(); example_parser.add_argument('-fq1', type=argparse.FileType('r')); example_parser.add_argument('-fq2', type=argparse.FileType('r')); args = parser.parse_args(). for line1, line2 in zip(args.fq1, args.fq2):; do_stuff_with_lines(); ```. You could then call the program flexibly:. ``` bash; $ example -fq1 file1.fq -fq2 file2.fq; $ example -fq1 <(gzip -dc file1.fq.gz) -fq2 <(gzip -dc file2.fq.gz); $ other_interleaved_process | example -fq1 - -fq2 -; ```. The caveat for the code above is that you would want to replace `argparse.FileType` with some class that reads 4 lines at a time - I'm sure there's no shortage of Python FASTQ readers that do that. And I know that you're looking for C++ libraries that perform well for your purposes, and my Python example is just a toy, but I think designing the option parser to at least **accept** streams and file-like objects and handle them using the same code path would be a worthy reason to refactor a bit.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168545456:311,interface,interface,311,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168545456,1,['interface'],['interface']
Integrability,"These messages have been removed in 0.9.0. Also, the read parser has had a considerable overhaul to avoid simply busy waiting in a situation like this where the processing is much slower than the disk. Let me know if this problem is resolved on your end.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-346981211:6,message,messages,6,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-346981211,1,['message'],['messages']
Integrability,"This PR addresses issue #699. To use the protocol, pass the `--splitseqV2` or `--splitseqV1` flag. To test the implementation correlation analysis was done on [data](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE137941) submitted with the [article](https://www.sciencedirect.com/science/article/pii/S1934590920300552). Thanks @jeremymsimon for pointing to the data. Here are the results of correlation b/w the alevin output and published counts. This test run was done as mentioned in [here](https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988185505). ![image](https://user-images.githubusercontent.com/12998572/145128352-6efe899a-ea06-49bf-9223-24ad4ba70223.png). ```; > summary(cr); Min. 1st Qu. Median Mean 3rd Qu. Max. ; 0.2966 0.7128 0.8690 0.8163 0.9448 0.9963 ; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/726:41,protocol,protocol,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/726,1,['protocol'],['protocol']
Integrability,"This PR introduces a new feature that will allow users to specify custom single cell protocols and use with alevin. Custom Geometry (--custom-geo) should be used when:; 1. Barcode or umi have variable lengths; 2. There is known fixed sequence in the reads; 3. There is some sequence to be excluded; From the input peglib spec it creates a regex. Boost regex library is used to parse the reads. Apart from small tests on multiple outlier cases, it was tested on a sci-RNA-seq3 sample SRR7827207 for speed. For this the spec is `--custom-geo 1{b[9-10]f[CAGAGC]u[8]b[10]}2{r}`. It says:; - Read 1 starts with barcode of variable length 9-10 bp, followed by; - A fixed sequence CAGAGC, then; - A umi of length 8, and lastly; - barcode of length 10.; - The second read is all biological. The barcodes are concatenated in the output and a padding sequence is added to make the length as max length + 1. The extra base is added so that we don't introduce spurious matches in barcode. For example, if the barcodes have length 3-4 bp and the two barcodes are `ATG` and `ATGA`, after padding they will be `ATGAC` and `ATGAA` resp. Adding just `A` to shorter barcode would result in a spurious match. . Since `--custom-geo` uses regex, it is slower than protocol specific flag. The time with 8 threads on a large Ubuntu 20 machine:. 1. Using `--sciseq3`:; ```; real 1m0.425s; user 7m21.501s; sys 0m2.964s; ```; 2. Using `--custom-geo`; ```; real 1m39.887s; user 11m55.602s; sys 0m6.839s; ```; Notably, it is about 66% slower. However, it allows support for almost all current and future protocols. . There will be a tutorial shortly on how and when to use this and how is it different from other flags such as `--umi-geometry`, `--read-geometry` and `--bc-geomtery`. There is scope of speed improvement in the future along with integration of all custom geometry processing protocols.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734:85,protocol,protocols,85,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734,5,"['integrat', 'protocol']","['integration', 'protocol', 'protocols']"
Integrability,This doesn't necessarily mean the protocol is stranded. You can inspect the contents of lib_format_counts.json to see the exact extent of the mapping bias.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/144#issuecomment-319676557:34,protocol,protocol,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/144#issuecomment-319676557,1,['protocol'],['protocol']
Integrability,"This in the compile error I get for the Staden package, FYI:. ```; ❯ make VERBOSE=1 [12:30:35]; /usr/local/Cellar/cmake/3.13.4/bin/cmake -S/Users/gabriel/Projects/salmon-0.13.1 -B/Users/gabriel/Projects/salmon-0.13.1/build --check-build-system CMakeFiles/Makefile.cmake 0; /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_progress_start /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/progress.marks; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/Makefile2 all; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libcereal.dir/build.make CMakeFiles/libcereal.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libcereal.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libcereal.dir/build.make CMakeFiles/libcereal.dir/build; make[2]: Nothing to be done for `CMakeFiles/libcereal.dir/build'.; [ 8%] Built target libcereal; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/depend; cd /Users/gabriel/Projects/salmon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:669,depend,depend,669,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,1,['depend'],['depend']
Integrability,"This is a question related to a strange message in the log out file after Salmon indexing on a very small genome with my own generated transcriptome and decoy. I'm running Salmon v1.0.0 index on the transcriptome of Candida parapsilosis which has a small genome of 26mbp. I created the transcriptome using Cufflinks gffread on my reference genome fasta and gff3. I created the decoy by concatenating the whole genome to the transcriptome [as it was described in the manual](https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indices-mapping-based-mode). . I am running using the following options:. `salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i cpar_salmon_index -k 31; `. After indexing using a kmer size threshold of -k 31, I see the following message in the log out file ""filter size not provided. ntHll estimated 12754610 distinct k-mers, setting filter size to 2^28."" . 2^28 seems very high compared to 31 bp set using -k 31. I'm also curious why, after setting a k size, it printed the message ""filter size not provided."". I've pasted a more complete snippet of the log out file text below. Does everything look like it's run successfully? I'm concerned since I am running on a small genome and with my own generated decoy and transcriptome. Does it look like this running as it should, or is there a bug that I should provide more details about?. > [puff::index::jointLog] [info] Filter size not provided; ; > estimating from number of distinct k-mers; > [puff::index::jointLog] [info] ntHll estimated 1275461; > 0 distinct k-mers, setting filter size to 2^28; > Threads = 12; > Vertex length = 31; > Hash functions = 5; > Filter size = 268435456; > Capacity = 2; > Files: ; > cpar_salmon_index/ref_k31_fixed.fa; > --------------------------------------------------------------------------------; > Round 0, 0:268435456; > Pass	Filling	Filtering; > 1	0	8	; > 2	4	0; > True junctions count = 18712; > False junctions count = 40617; > Hash table size = 59329; > ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/510:40,message,message,40,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/510,2,['message'],['message']
Integrability,"This is concerned with alevin, using a cite-seq like method with a different UMI barcode length. I believe this is similar to #531. running the command like this:. ```; salmon alevin \; -l ISR \; -i ${PROJECT}/adt_index \; -1 $R1_ADT \; -2 $R2_ADT \; --end 5 \; --umiLength 10 \; --barcodeLength 16 \; -o $PROJECT/alevin_adt \; -p 24 \; --featureStart 1 --featureLength 15 \; --naiveEqclass \; --citeseq; ```; Produces the error `ERROR: Please specify one and only one scRNA protocol;`. whereas removing the `--citeseq` argument like this:; ```; salmon alevin \; -l ISR \; -i ${PROJECT}/adt_index \; -1 $R1_ADT \; -2 $R2_ADT \; --end 5 \; --umiLength 10 \; --barcodeLength 16 \; -o $PROJECT/alevin_adt \; -p 24 \; --featureStart 1 --featureLength 15 \; --naiveEqclass; ```; Produces the error `[alevinLog] [critical] Transcript to Gene Map File not provided. Exiting Now.`. This is based on salmon 1.8.0 installed via bioconda on ubuntu 18.04",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/770:475,protocol,protocol,475,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/770,1,['protocol'],['protocol']
Integrability,"This isn't strictly speaking a bug with salmon per-se, but when installing salmon from conda, its impossible to have both R 4.0.3 and Salmon 1.3.0 installed in the same environment (which is frustrating due to the downstream analysis of Salmon data with wasabi/sleuth then requiring a separate environment). The core incompatibility seems to be with the International Components for Unicode package. Salmon requires; ""icu >=64.2,<65.0a0"",; Whereas in one of the R dependencies when installing 4.0.3 in the environment solve the following is specified; ""icu >=67.1,<68.0a0"",. This seems to be the only conflict I could identify.; This seems to be a new incompatibility introduced with R 4.0.3 and Salmon can coexist alongside R 4.0.2 without issue, so this isn't a huge problem but something I thought should probably be on your radar if it isn't already. Output from the conda dry-run as follows: ; [salmon_solve.txt](https://github.com/COMBINE-lab/salmon/files/5619618/salmon_solve.txt); [r-base_solve.txt](https://github.com/COMBINE-lab/salmon/files/5619619/r-base_solve.txt)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/594:464,depend,dependencies,464,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/594,1,['depend'],['dependencies']
Integrability,"This seems to be a separate issue than the other (and a more informative exception). Once I've resolved the other issue, I would probably try to bug you for a sample that causes this --- though I have a reasonable idea about how to fix it. It would be nice to have the fix for both issues in the same hotfix. To be more specific : this is, as the exception says, a numeric underflow issue when evaluating the digamma function. The solution here is just to bump up the value that is required before evaluating this function. This should be straightforward, but I suspect the issue is also related to this log message:. > [2018-05-31 17:08:11.488] [jointLog] [info] Marked 1 weighted equivalence classes as degenerate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393571565:608,message,message,608,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393571565,1,['message'],['message']
Integrability,This should be fixed with the [seurat_wrapper](https://github.com/satijalab/seurat-wrappers) repo.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/436#issuecomment-821498452:83,wrap,wrappers,83,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/436#issuecomment-821498452,1,['wrap'],['wrappers']
Integrability,"To whom it may concern,. I have been using Salmon to quantify RNA-seq data using a new long-read RNA sequencing-based GTF I have developed. When I run Salmon on RNA-seq samples from TCGA (read length = 50 bp, kmer length = 21), I tend to get ~95% of reads mapping to my transcriptome. However, when I use the same script to run my pipeline on in-house sequenced data (read length = 150 bp, kmer length = 21), I am getting only around 80-85% of reads mapping to my transcriptome. According to STAR, >90% (usually >95%) of these same in-house samples mapped to the genome. Why am I getting lower mapping rates? Could read length have something to do with it? Thanks so much for any advice or guidance you can provide. Script: ; [5_runSalmon.sh.zip](https://github.com/COMBINE-lab/salmon/files/10262688/5_runSalmon.sh.zip); (The only difference between my TCGA and in-house runs are that for TCGA I use ""-i IU"" and for my in-house samples I use ""-i ISR"" due to differences in the strandedness of the prep protocols). Yours most sincerely,; Ryan Englander",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/819:1002,protocol,protocols,1002,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/819,1,['protocol'],['protocols']
Integrability,"URE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE; $ make; $ tar xaf sample_data.tgz; $ src/salmon index -t sample_data/transcripts.fasta -i sample_salmon_quasi_index; Version Info: This is the most recent version of salmon.; [2023-03-08 17:30:38.873] [jLog] [warning] The salmon index is being built without any decoy sequences. It is recommended that decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be provided during indexing. Further details can be found at https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indices-mapping-based-mode.; [2023-03-08 17:30:38.873] [jLog] [info] building index; out : sample_salmon_quasi_index; [2023-03-08 17:30:38.873] [puff::index::jointLog] [info] Running fixFasta; ; [Step 1 of 4] : counting k-mers; ; [2023-03-08 17:30:38.879] [puff::index::jointLog] [info] Replaced 0 non-ATCG nucleotides; [2023-03-08 17:30:38.879] [puff::index::jointLog] [info] Clipped poly-A tails from 0 transcripts; wrote 15 cleaned references; Segmentation fault. * Version 1.9.0 as well as version 1.10.0 are affected. Unfortunately we did not managed to package version 1.7.0 and 1.8.0 but I confirm that version 1.6.0 was not affected by the described problem.; * Salmon was build as Debian package as well as built from source (see above); * The reference was taken from the `sample_data` shipped with the release tarball. **Expected behavior**; Clean processing without SEGFAULT. **Desktop (please complete the following information):**; - OS: Debian (testing or unstable). **Additional context**; * You can find some debug logs inside the [Debian bug log](https://bugs.debian.org/1028713). ; * There is a build log which includes the said salmon call above as [build time test](https://salsa.debian.org/med-team/salmon/-/jobs/4031000); * When ignoring the package build time test the [Continuous Integration log](https://salsa.debian.org/med-team/salmon/-/jobs/3980059) might be interesting as well. Kind regards, Andreas.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835:2755,Integrat,Integration,2755,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835,1,['Integrat'],['Integration']
Integrability,"Ubuntu 20.04 LTS, with gcc version 9.3.0 (Ubuntu 9.3.0-17ubuntu1~20.04) ; fails to compile salmon due to an internal compiler error.; The problem occurs for both the 1.4.0 release as well as the current; git master branch during the final linking of the salmon executable:. ```; git clone https://github.com/COMBINE-lab/salmon.git; mkdir salmon/build; cd salmon/build ; cmake -DFETCH_BOOST=TRUE -DCMAKE_INSTALL_PREFIX=${PREFIX} ..; make; ```. ```; [100%] Linking CXX executable salmon; /usr/bin/ld: ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): in function `find_file_url':; open_trace_file.c:(.text+0xf4e): warning: the use of `tempnam' is dangerous, better use `mkstemp'; during IPA pass: icf; lto1: internal compiler error: Segmentation fault; Please submit a full bug report,; with preprocessed source if appropriate.; See <file:///usr/share/doc/gcc-9/README.Bugs> for instructions.; lto-wrapper: fatal error: /usr/bin/c++ returned 1 exit status; compilation terminated.; /usr/bin/ld: error: lto-wrapper failed; collect2: error: ld returned 1 exit status; make[2]: *** [src/CMakeFiles/salmon.dir/build.make:456: src/salmon] Error 1; make[1]: *** [CMakeFiles/Makefile2:689: src/CMakeFiles/salmon.dir/all] Error 2; make: *** [Makefile:163: all] Error 2; ```. With VERBOSE=1, this is the final command that fails:; ```; /usr/bin/c++ -O3 -DNDEBUG -flto -fno-fat-lto-objects CMakeFiles/salmon.dir/EMUtils.cpp.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedCellOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/Graph.cpp.o CMakeFiles/salmon.dir/DedupUMI.cpp.o CMakeFiles/salmon.dir/Alevin.cpp.o CMakeFiles/salmon.dir/AlevinHash.cpp.o CMakeFiles/salmon.dir/SalmonAlevin.cpp.o CMakeFiles/salmon.dir/WhiteList.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMa",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/664:928,wrap,wrapper,928,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/664,1,['wrap'],['wrapper']
Integrability,"We currently are using a protocol that uses a barcode strategy similar to Rhapsody, where you have 3, 8nt barcodes separated by two constant regions. I am trying to use the bc-geometry flag using the following command . "" salmon alevin -l ISR -i ~/Data/salmon/cell_hash -1 R1.fq.gz -2 R2.fq.gz --umi-geometry 1[51-56] --bc-geometry 1[3-8,24-29,45-50] --read-geometry 2[1-end] -o outs/ --citeseq --featureStart 0 --featureLength 15"". I am getting an output table that appears to be mapping correctly, however the cell barcodes in the table are 16 nt long instead of the 18 nt specified in the bc-geometry command. Is there something I am missing?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/670:25,protocol,protocol,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/670,1,['protocol'],['protocol']
Integrability,We fix it by adding the tbb package (I also added the libgcc but I think it is not mandatory) :. ```; name: salmon; channels:; - bioconda; - conda-forge; - defaults; dependencies:; - libgcc-ng=9.1.0=hdf63c60_0; - tbb=2020.2=hc9558a2_0; - salmon=1.4.0=hf69c8f4_0; ```,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-802751914:166,depend,dependencies,166,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/565#issuecomment-802751914,1,['depend'],['dependencies']
Integrability,"We have that here, right? https://salmon.readthedocs.io/en/latest/alevin.html#single-cell-protocol-specific-notes",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1753075151:90,protocol,protocol-specific-notes,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1753075151,1,['protocol'],['protocol-specific-notes']
Integrability,"We tried to run salmon with broken linked files (as in, we accidently linked to the wrong directory). This led to salmon getting to the kmer counting stage and then permanently pausing there (see output below). You can see a version of the broken protocol here: https://github.com/ngs-docs/2017-ucsc-metagenomics/blob/cd417dc4b384b668eda2a477fd805ebb3b30cd00/salmon_tutorial.rst. So, it would be nice if salmon could compensate for this misstep on our part and notify us if a broken linked file is given as input, rather than just pausing. . `tx160085@js-104-35:~/Salmon-0.7.2_linux_x86_64/data$ salmon index -t metagG.ffn -i transcript_index -; -type quasi -k 31; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and minor bug fixes; please upgrade at your; earliest convenience.; ###; index [""transcript_index""] did not previously exist . . . creating it; [2017-04-23 17:02:32.614] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers`. Thank you!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/134:247,protocol,protocol,247,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/134,1,['protocol'],['protocol']
Integrability,"Where does `extract-libdivsufsort.cmake` live? I don't find it in the `salmon` repository. Is it generated automatically by `cmake`? The following patch/hack using `unzip` works around the `cmake -E tar xfz` bug for me. It seems to only affect extracting the `libdivsufsort.zip`, perhaps because it's a `.zip`. If that is the case, and there's a `.tar.gz` distribution of `libdivsufsort`, then there may be a simple fix. ``` diff; --- libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake.orig 2016-03-07 22:02:35.000000000 -0800; +++ libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake 2016-03-07 22:06:49.000000000 -0800; @@ -23,7 +23,7 @@; # Extract it:; #; message(STATUS ""extracting... [tar xfz]""); -execute_process(COMMAND ${CMAKE_COMMAND} -E tar xfz ${filename}; +execute_process(COMMAND unzip ${filename}; WORKING_DIRECTORY ${ut_dir}; RESULT_VARIABLE rv). ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193623757:701,message,message,701,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193623757,1,['message'],['message']
Integrability,"With the extra `--expectCells 10000` parameter, Alevin finished running without error messages and 10,641 cell barcodes in **quants_mat_rows.txt**. I am not sure how much of a difference it makes if I expect 8,000 cells versus 10,000 cells. However, this looks much closer to the expected number, and I am closing the ticket. Thanks again!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-884309748:86,message,messages,86,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-884309748,1,['message'],['messages']
Integrability,Would alevin work with QIAseq UPX 3' protocol?,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/406:37,protocol,protocol,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/406,1,['protocol'],['protocol']
Integrability,"Wow. Thanks for getting back so fast. I’ll update more info about the machine. It’s got 16GB of RAM and only 3GB of swap, so I do think it was memory pressure. In fact, I just looked through the system kernel messages and found the OOM routine killed my process:. ```Out of memory: Kill process 12997 (R) score 846 or sacrifice child │10-03 22:39 INFO Encountered FastxParser destructor while parser was still marked active (or while parsing threads were ; Killed process 12997, UID 1506502601, (R) total-vm:17105100kB, anon-rss:15306012kB, file-rss:12kB ; ```. Sorry I didn’t check this earlier!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538606398:209,message,messages,209,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538606398,2,"['message', 'rout']","['messages', 'routine']"
Integrability,"Yea. Both are frustrating, which is why we spam warning messages to the console when we remove duplicates. Sorry if this default behavior caused you any trouble, but hopefully its easy to recover these quants without rerunning anything using the map of collapsed transcripts.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-381584892:56,message,messages,56,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-381584892,1,['message'],['messages']
Integrability,"Yes, I'm aware of refgenie however, I was unable to identify for the hg38 salmon indices which specific transcriptome source (and additionally which version of said source) was used to build them.; Additionally, my use case here isn't entirely personal, I work for GSEA-MSigDB and GenePattern, we're in the process of improving the end-to-end analysis pipeline we offer to users, and one of the things we've been working on were wrapping the Salmon indexer, Salmon quant, and Alevin into GenePattern modules so that we can offer them to users who may want to run them on arbitrary transcriptomes in addition to the ones we offer specifically for GSEA compatibility. This issue was something we encountered when considering potential sources of inconsistency at different points in the pipeline.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738180982:429,wrap,wrapping,429,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738180982,1,['wrap'],['wrapping']
Integrability,"Yes, but it was a while ago. I think I had realised that I aligned to the; genome (Step 2 in my original post), when Salmon documentation specifically; says you should align to the transcriptome. So I redid the alignment and it; worked, if I'm remembering correctly. On Thu, 18 Jul 2024, 16:41 YIGUIz, ***@***.***> wrote:. > Hi, I encountered the same issue. Have you managed to solve it?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/863#issuecomment-2236553993>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AOFX65IGY6W3PKGRNNK7WOLZM7AY5AVCNFSM6AAAAABLCWZAB2VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMZWGU2TGOJZGM>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/863#issuecomment-2241619736:770,Message,Message,770,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/863#issuecomment-2241619736,1,['Message'],['Message']
Integrability,"Yes, this is a set of transcripts assembled using a few different Trinity and Velvet/Oases protocols, merged together. I'm testing reduction with different tools along with relative abundance estimation.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204098008:91,protocol,protocols,91,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204098008,1,['protocol'],['protocols']
Integrability,"Yup this geometry is correct! As for a pairing file for the BC1 barcodes, this _may_ depend on the version and/or implementation in the lab. For ParseBio (""v2""), it seems to be consistent thus far, and I've linked a pairing table for that below. For homemade SPLiT-seq (""v1""), which barcodes end up in which wells, and which wells actually get utilized may vary. Additionally, some other labs may not use random hexamers at all, meaning we should have some flexibility such that users provide their own table and also an option for whether this pairing table is strictly required. In [this barcode sharing file](https://github.com/COMBINE-lab/salmon/files/7418722/ParseBio_barcodeSharing.txt), the first column represents the oligo-dT BC1 sequences, and the second column are the paired random hexamer BC1 sequences. Note this file is the same as [this one here on my github](https://github.com/jeremymsimon/SPLITseq).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951974369:85,depend,depend,85,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951974369,1,['depend'],['depend']
Integrability,"[I confirmed with the developer of zUMIs](https://github.com/sdparekh/zUMIs/issues/298) that no frameshift detection/correction is happening in their approach for SPLiT-seq libraries, so the barcode discovery should be fairly consistent with what alevin is already doing (ie with fixed geometry positions). So, likely no need to incorporate this into `splitp` at the moment but if we/others determine that frameshifts are frequent enough and the data can improve in some noticeable way with correcting them, we can revisit later as you suggested. . As for the barcode detection - my usual approach with `alevin` at least is to let it try to estimate a ""real"" cell number, but if it's way off from our experimental expectations, to inject `--expectCells ncells` and let that serve as a starting point (with subsequent filtering). That has worked reasonably well in the past for me , and seems to be an option for `alevin-fry` as well. I don't know whether that is poor practice in the long run...it came from a place of seeing far too many weak knee plots early in the droplet scRNA-seq days. Are you generally more trusting of these estimates these days?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988184912:731,inject,inject,731,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988184912,1,['inject'],['inject']
Integrability,"] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2022-01-20 13:56:19.915] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2022-01-20 13:56:19.915] [jointLog] [info] parsing read library format; ```. But no errors/no other outputs after that. I reran many times with slightly different settings, including different set of reads and a different reference with the same results, but only got an error when I ran: . ```; salmon quant -p 1 -i $index -1 $read1 -2 $read2 –o res_new -l OSR; ```. Which returned the error:. ```; [2022-01-20 14:39:44.578] [jointLog] [error] Failed to successfully parse any complete read libraries. Please make sure you provided arguments properly to -1, -2 (for paired-end libraries) or -r (for single-end libraries), and that the library format option (-l) *comes before* the read libraries.; ```. This error allowed me to fix the original command (running now, yay!) but I only got that error after changing up the arguments I used (for whatever reason the original arguments did not allow for the error to be reported correctly to the user) and updating the name of the output I used (ran the exact same command that gave me the error with the old output name (res) and it did not give an error. Note I did not delete the output between tests). Not a huge issue, but figured it could affect others in the future as well (took me quite a while to figure out the issue due to the lack of error message) so should report it. ## Expected behavior. When -l comes before -1/-2, the error message:. ```; [2022-01-20 14:39:44.578] [jointLog] [error] Failed to successfully parse any complete read libraries. Please make sure you provided arguments properly to -1, -2 (for paired-end libraries) or -r (for single-end libraries), and that the library format option (-l) *comes before* the read libraries.; ```. should be reported regardless of other arguments given.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/736:2522,message,message,2522,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/736,2,['message'],['message']
Integrability,"________________________________; From: tamuanand <notifications@github.com>; Sent: Saturday, 14 December 2019 4:42 PM; To: COMBINE-lab/salmon <salmon@noreply.github.com>; Cc: Susan Corley <s.corley@unsw.edu.au>; Mention <mention@noreply.github.com>; Subject: Re: [COMBINE-lab/salmon] Salmon SAF method - Read mapping issue with Lexogen/QuantSeq data?? (#449). Hi @s1corley<https://github.com/s1corley>. Thanks for your inputs and thanks for taking the time to respond here. You mention you attached the Salmon meta_info output - I guess the attachment did Not come through. @k3yavi<https://github.com/k3yavi> @rob-p<https://github.com/rob-p> - any ideas why the attachment did not make it. Yes - I am surprised with the results using the SR salmon quant option with the QuantSeq FWD protocol. I was advised that a FWD library was used - this is a bit confusing given the success of running the SR option. @rob-p<https://github.com/rob-p> What should be the libType option one should set with the QuantSeq FWD protocol - I have explained above why the SF option would be appropriate one (based on what Lexogen recommends for use with htseq-count for QuantSeq FWD). —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/449?email_source=notifications&email_token=AC4A5AHH5I66447AJKAIA6LQYRW4BA5CNFSM4JOIEHZ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEG33A6Y#issuecomment-565686395>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AC4A5AEBKTGGPZ22F7IVIA3QYRW4BANCNFSM4JOIEHZQ>. Sample S1. meta_info.json. ""salmon_version"": ""0.9.1"",; ""samp_type"": ""none"",; ""quant_errors"": [],; ""num_libraries"": 1,; ""library_types"": [; ""SR""; ],; ""frag_dist_length"": 1001,; ""seq_bias_correct"": true,; ""gc_bias_correct"": true,; ""num_bias_bins"": 4096,; ""mapping_type"": ""mapping"",; ""num_targets"": 202863,; ""serialized_eq_classes"": false,; ""eq_class_properties"": [],; ""length_classes"": [; 513,; 656",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565692581:784,protocol,protocol,784,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565692581,1,['protocol'],['protocol']
Integrability,"`Transcript chr19 appeared in the BAM header, but was not in the provided FASTA file`; (note here that it's an entire chromosome??? And these are the only ""transcripts"" that don't appear in the fasta- they're all just the chromosome names.); This happened regardless of whether I used the Stringtie fasta or the SQNATI-annotated fasta. This is the salmon command I had run:; `$salmon quant --ont -t $transcriptome -l SF -a $bam -o $outdir/$name`. As suggested, I used gffread to generate a new transcriptome fasta as follows:; `gffread -w salmon_fix.fa -g chm13v2.0.fa chm13v2.0_RefSeq_Liftoff_v5.1.gff3`. I reran the above salmon command using this new fasta file, but got the same error and warnings: there are transcripts in the BAM not in the fasta and vice versa. Again, the ""transcripts"" not in the fasta were chromosome names. I also tried with the short read SAM files, and still got the same error. I'm not sure how to fix either the warnings or the errors and would really appreciate your help. ### Software information; I used salmon v1.10.0 (though I also tried v1.10.1). In the case of v1.10.0, I had downloaded the pre-compiled binary, and in the case of v1.10.1, the admins of the HPC cluster I used installed it- not sure how. Regardless, all the runs were on HPC clusters, which run on Linux CentOS (I use two different HPC clusters, depending on their availability). Cluster1:; ```; $ uname -a; Linux rescomp1.hpc.in.bmrc.ox.ac.uk 3.10.0-1160.92.1.el7.x86_64 #1 SMP Tue Jun 20 11:48:01 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux; $ lsb_release -a; -bash: lsb_release: command not found; ```. Cluster2:; ```; $ uname -a; Linux htc-login02 4.18.0-348.7.1.el8_5.x86_64 #1 SMP Wed Dec 22 13:25:12 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux; $ lsb_release -a; LSB Version: :core-4.1-amd64:core-4.1-noarch; Distributor ID: CentOS; Description: CentOS Linux release 8.5.2111; Release: 8.5.2111; Codename: n/a; ```. Please let me know if I need to provide any more information. Thank you so much!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/863:2878,depend,depending,2878,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/863,1,['depend'],['depending']
Integrability,"```. But apparently that wasn't enough, because:. ```; cmake \; -DCMAKE_INSTALL_PREFIX:PATH=$TOPDIR \; .. ...; TBB_LIBRARIES = ; -- Configuring done; CMake Error at external/pufferfish/external/twopaco/CMakeLists.txt:11 (add_dependencies):; The dependency target ""tbb"" of target ""graphdump"" does not exist.; ```. This doesn't work obviously, but here are the mods to CMakeLists.txt that I tried:. ```; diff -au CMakeLists.txt.dist CMakeLists.txt; --- CMakeLists.txt.dist 2019-12-06 10:40:58.430641796 -0800; +++ CMakeLists.txt 2019-12-06 13:14:57.292041895 -0800; @@ -387,7 +387,10 @@; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0""); if (NOT BOOST_RECONFIGURE); -find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); +set(BOOST_INCLUDEDIR ""/usr/include/boost169""); +set(BOOST_LIBRARYDIR ""/usr/lib64/boost169""); +set(Boost_FOUND 1); +; message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); @@ -571,7 +574,22 @@; endif(); ; ## Try and find TBB first; -find_package(TBB 2018.0 COMPONENTS tbb tbbmalloc tbbmalloc_proxy); +if(DEFINED ENV{ROOT_LIBTBB}); + message(""ROOT_LIBTBB in env""); + set(ROOT_LIBTBB ); + set(TBB_DIR $ENV{ROOT_LIBTBB}); + set(TBB_INCLUDE_DIRS ${TBB_DIR}/include); + set(TBB_INCLUDE_DIR ${TBB_DIR}/include); + set(TBB_LIBRARY_DIRS ${TBB_DIR}/lib); + set(TBB_LIBRARY ${TBB_DIR}/lib); + set(TBB_LIB_DIR ${TBB_DIR}/lib); + set(TBB_VERSION ""2019.6""); + set(TBB_FOUND TRUE); +else(); + message(""ROOT_LIBTBB NOT in env""); + find_package(TBB 2018.0 COMPONENTS tbb tbbmalloc tbbmalloc_proxy); +endif(); +; ; if (${TBB_FOUND}); if (${TBB_VERSION} VERSION_GREATER_EQUAL 2018.0); @@ -696,7 +714,19 @@; #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""); ; -find_package(libgff); +if(DEFINED ENV{ROOT_LIBGFF}); + messa",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460:3423,message,message,3423,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460,3,['message'],['message']
Integrability,"```; > ; > ```; > Version Info: This is the most recent version of salmon.; > # salmon (alignment-based) v1.4.0; > # [ program ] => salmon ; > # [ command ] => quant ; > # [ targets ] => { mRNA.fasta }; > # [ threads ] => { 20 }; > # [ libType ] => { A }; > # [ alignments ] => { SRR3212847.Aligned.SortedByName.bam }; > # [ output ] => { SRR3212847.Aligned.SortedByName }; > Logs will be written to SRR3212847.Aligned.SortedByName/logs; > [2021-01-08 13:02:04.845] [jointLog] [info] setting maxHashResizeThreads to 20; > [2021-01-08 13:02:04.845] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; > [2021-01-08 13:02:04.878] [jointLog] [info] numQuantThreads = 14; > parseThreads = 6; > Checking that provided alignment files have consistent headers . . . done; > Populating targets from aln = ""SRR3212847.Aligned.SortedByName.bam"", fasta = ""mRNA.fasta"" . . .done; > ; > processed 0 reads in current roundSegmentation fault (core dumped); > ```; > ; > (Which is the same as the 1st error. Actually, each time I re-run those two errors switched.); > ; > I tried running Salmon on the sorted-by-coordinates bam, and it didn't fail:; > ; > ```; > nohup salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.SortedByCoord.bam \; > -o SRR3212847.Aligned.SortedByCoord \; > > SRR3212847.Aligned.SortedByCoord.out &; > ```; > ; > Even so, `SRR3212847.Aligned.SortedByCoord.out` contained ~3.5GB worth of the warnings above.; > ; > Any help would be much appreciated. Thanks!. hello,i have the same problem,thanks for your answer. Your SRR3212847.Aligned.SortedByCoord.out contained ~3.5GB worth of the warnings above, What is the warning message? And in my log file,the warning as follow:. ![image](https://user-images.githubusercontent.com/45484925/206608510-b5cc88bd-18ac-42eb-bfa1-a5be862b0873.png); Can i ignore these warnings?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456:5242,message,message,5242,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456,1,['message'],['message']
Integrability,`cmake` fails when extracting external dependencies for me. See #10. I'd also like to be able to use the existing installed versions of dependencies. For me they're installed by Linuxbrew.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193514127:39,depend,dependencies,39,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193514127,2,['depend'],['dependencies']
Integrability,"and <notifications@github.com>; Sent: Saturday, 14 December 2019 4:42 PM; To: COMBINE-lab/salmon <salmon@noreply.github.com>; Cc: Susan Corley <s.corley@unsw.edu.au>; Mention <mention@noreply.github.com>; Subject: Re: [COMBINE-lab/salmon] Salmon SAF method - Read mapping issue with Lexogen/QuantSeq data?? (#449). Hi @s1corley<https://github.com/s1corley>. Thanks for your inputs and thanks for taking the time to respond here. You mention you attached the Salmon meta_info output - I guess the attachment did Not come through. @k3yavi<https://github.com/k3yavi> @rob-p<https://github.com/rob-p> - any ideas why the attachment did not make it. Yes - I am surprised with the results using the SR salmon quant option with the QuantSeq FWD protocol. I was advised that a FWD library was used - this is a bit confusing given the success of running the SR option. @rob-p<https://github.com/rob-p> What should be the libType option one should set with the QuantSeq FWD protocol - I have explained above why the SF option would be appropriate one (based on what Lexogen recommends for use with htseq-count for QuantSeq FWD). —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/449?email_source=notifications&email_token=AC4A5AHH5I66447AJKAIA6LQYRW4BA5CNFSM4JOIEHZ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEG33A6Y#issuecomment-565686395>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AC4A5AEBKTGGPZ22F7IVIA3QYRW4BANCNFSM4JOIEHZQ>. Sample S1. meta_info.json. ""salmon_version"": ""0.9.1"",; ""samp_type"": ""none"",; ""quant_errors"": [],; ""num_libraries"": 1,; ""library_types"": [; ""SR""; ],; ""frag_dist_length"": 1001,; ""seq_bias_correct"": true,; ""gc_bias_correct"": true,; ""num_bias_bins"": 4096,; ""mapping_type"": ""mapping"",; ""num_targets"": 202863,; ""serialized_eq_classes"": false,; ""eq_class_properties"": [],; ""length_classes"": [; 513,; 656,; 1013,; 2240,; 104301; ],; ""index_seq_hash""",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565692581:1010,protocol,protocol,1010,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565692581,1,['protocol'],['protocol']
Integrability,"at my transcript fasta, I noticed a problem with it, as you suggested. Long story short, half the premature transcripts had the wrong orientation and complementarity. Long story:. Oddly, the mature sequences were fine even though I used an identical approach to subset premature and mature transcripts from the genome reference!. Briefly my approach relied on three R packages rtracklayer, GenomicRanges, and Biostrings. 1. I used rtracklayer to load a gtf formatted exon annotations acquired from Ensembl. The file is loaded as a GenomicRanges object which essentially describes the locus of each exon (the transcribed strand [+ or -], chromosome, start and end positions relative to the reference strand) and its associated gene and transcript. 2. I used the GRanges object to generate pre-RNA coordinates that span all exons of a transcript. 3. I loaded the reference genome fasta acquired from Ensembl using the Biostrings package. GRanges and Biostrings are tightly integrated, allowing me to subset sequences from a Biostrings object using the GRanges object. **I believe the problem lies here.** It appears that when subsetting the mature exonic sequences from Biostrings using GRanges, the strand field in the GRanges object **was not** utilized. I.e., I needed to get the reverse complement of the extracted sequences for transcripts on the minus strand. I had done that and assumed that this behaviour would be consistent. However, for reasons I have not been able to pinpoint (potentially a bug), the strand information **was accounted for** when I used GRanges to subset the premature sequences. I **did not** need to get the reverse complement of the premature sequences on the minus strand as I had to do for the mature sequences. Yet, I did that anyway. I initially did test my protocol to ensure it produced identical transcript sequences to Gencode, but I only did this for mature sequences. All seemed fine for both + and - strand transcripts. After your feedback, I compared the pr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:1514,integrat,integrated,1514,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['integrat'],['integrated']
Integrability,"can you share the contents of the file `../../alevin_15_pc/lib_format_counts.json` ?; Basically what it's saying is that the assumption made to explicitly define the library type in the command line flag i.e. `-lISR` which means that the library is stranded and the reads are coming from the reverse strand is getting violated. In 10x protocols we generally expects that the read follow the `ISR` standard but it looks like some 5% of the reads are not following this property and that's what Alevin is complaining. It is possible since this is v1, we might expect some non-trivial fraction of reads to be non-stranded but too hard to say .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/294#issuecomment-422618229:335,protocol,protocols,335,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/294#issuecomment-422618229,1,['protocol'],['protocols']
Integrability,cmake/TestSalmonQuasi.cmake: more verbose test failure messages.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/810:55,message,messages,55,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/810,1,['message'],['messages']
Integrability,"common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; THELUA=/usr/common/modules/el8/x86_64/modules/all/${package}/${pversion}-CentOS-vanilla.lua; cd /usr/common/src; git clone -b develop https://github.com/COMBINE-lab/salmon.git; mv ${package} ${package}-${pversion}; cd ${package}-${pversion}; cp CMakeLists.txt CMakeLists.txt.dist; cat >mypatch <<'EOD'; --- CMakeLists.txt.dist	2020-04-21 22:31:07.000000000 -0700; +++ CMakeLists.txt	2020-06-09 14:55:02.733885772 -0700; @@ -419,6 +419,10 @@; find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); +message(""Forcing Boost_FOUND to TRUE""); +set(Boost_FOUND TRUE); +set(Boost_LIBRARY_DIRS ""/usr/lib64/boost169""); +set(Boost_LIBRARIES -lboost_iostreams -lboost_filesystem -lboost_system -lboost_timer -lboost_chrono -lboost_program_options); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; EOD; patch -p0 <mypatch; module load cmake; module load io_lib; module load libgff; module load libtbb; # module load pufferfish #ignored even if set; mkdir build; cd build; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_23.log; make -j 4 2>&1 | tee build_2020_06_23.log; make test # both passed; make install 2>&1 | tee install_2020_06_23.log; cd ..; cp sample_data.tgz $TOPDIR; module_generate_from_directory.sh \; $package \; $pversion \; CentOS/vanilla \; $TOPDIR \; ""Fast highly-accurate, transcript-level quantification estimates from RNA-seq data."" \; ""https://github.com/COMBINE-lab/salmon""; ```. When the following commands are run in an XFCE4 terminal or an uxterm (black text, white background) using the sample data provid",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/541:723,message,message,723,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/541,4,['message'],['message']
Integrability,"cript. 3. I loaded the reference genome fasta acquired from Ensembl using the Biostrings package. GRanges and Biostrings are tightly integrated, allowing me to subset sequences from a Biostrings object using the GRanges object. **I believe the problem lies here.** It appears that when subsetting the mature exonic sequences from Biostrings using GRanges, the strand field in the GRanges object **was not** utilized. I.e., I needed to get the reverse complement of the extracted sequences for transcripts on the minus strand. I had done that and assumed that this behaviour would be consistent. However, for reasons I have not been able to pinpoint (potentially a bug), the strand information **was accounted for** when I used GRanges to subset the premature sequences. I **did not** need to get the reverse complement of the premature sequences on the minus strand as I had to do for the mature sequences. Yet, I did that anyway. I initially did test my protocol to ensure it produced identical transcript sequences to Gencode, but I only did this for mature sequences. All seemed fine for both + and - strand transcripts. After your feedback, I compared the premature sequences in my transcript fasta against the transcript fasta from Gencode. As you can see in the smoothed dot plots below, the premature sequences of transcripts on the minus strand are in the wrong orientation and have the wrong complementarity!. ![Screenshot from 2021-04-24 00-35-05](https://user-images.githubusercontent.com/10429333/115947355-0d96c880-a495-11eb-92a6-d8d2233c8d2b.png). I included my R code below for this test case for anyone who might stumble upon this issue. Under the code headers “Mature transcript sequences” and “Premature transcript sequences”, you can observe that I used identical protocols for sequence subsetting, yet in the mature case the strand information in the GRanges seems to be disregarded when subsetting from Biostrings, but in the premature case the strand information is used. Of cou",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:2336,protocol,protocol,2336,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,1,['protocol'],['protocol']
Integrability,"d on GitHub.com; your repository will automatically benefit from the most recently released version. #### The analysis doesn’t seem to be working; If you get an error in GitHub Actions that indicates that CodeQL wasn’t able to analyze your code, please [follow the instructions here](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/troubleshooting-the-codeql-workflow) to debug the analysis. #### How do I disable LGTM.com?; If you have LGTM’s automatic pull request analysis enabled, then you can [follow these steps to disable the LGTM pull request analysis](https://lgtm.com/help/lgtm/managing-automated-code-review#disabling-pr-integration). You don’t actually need to remove your repository from LGTM.com; it will automatically be removed in the next few months as part of the deprecation of LGTM.com ([more info here](https://github.blog/2022-08-15-the-next-step-for-lgtm-com-github-code-scanning/)). #### Which source code hosting platforms does code scanning support?; GitHub code scanning is deeply integrated within GitHub itself. If you’d like to scan source code that is hosted elsewhere, we suggest that you create a mirror of that code on GitHub. #### How do I know this PR is legitimate?; This PR is filed by the official LGTM.com GitHub App, in line with the [deprecation timeline that was announced on the official GitHub Blog](https://github.blog/2022-08-15-the-next-step-for-lgtm-com-github-code-scanning/). The proposed GitHub Action workflow uses the [official open source GitHub CodeQL Action](https://github.com/github/codeql-action/). If you have any other questions or concerns, please join the discussion [here](https://github.com/orgs/community/discussions/29534) in the official GitHub community!. #### I have another question / how do I get in touch?; Please join the discussion [here](https://github.com/orgs/community/discussions/29534) to ask further questions and send us suggestions!. </details>",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/815:4365,integrat,integrated,4365,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/815,1,['integrat'],['integrated']
Integrability,"d::atomic<long unsigned int>&) [with ProtocolT = alevin::protocols::Chromium; single_parser = fastx_parser::FastxParser<fastx_parser::ReadSeq>; CFreqMapT = cuckoohash_map<std::__cxx11::basic_string<char>, unsigned int, BarcodeGroupStringHasher>]::<lambda(uint32_t&)>; Args = {int}; Key = std::__cxx11::basic_string<char>; T = unsigned int; Hash = BarcodeGroupStringHasher; KeyEqual = std::equal_to<std::__cxx11::basic_string<char> >; Allocator = std::allocator<std::pair<const std::__cxx11::basic_string<char>, unsigned int> >; long unsigned int SLOT_PER_BUCKET = 4ul]::<lambda(cuckoohash_map<std::__cxx11::basic_string<char>, unsigned int, BarcodeGroupStringHasher>::mapped_type&)>, int> (fn=..., key=..., this=<optimized out>); at /u/user/tmp/salmon/include/cuckoohash_map.hh:529; #15 upsert<std::__cxx11::basic_string<char>&, densityCalculator(single_parser*, AlevinOpts<ProtocolT>&, std::mutex&, CFreqMapT&, std::atomic<long unsigned int>&, std::atomic<long unsigned int>&) [with ProtocolT = alevin::protocols::Chromium; single_parser = fastx_parser::FastxParser<fastx_parser::ReadSeq>; CFreqMapT = cuckoohash_map<std::__cxx11::basic_string<char>, unsigned int, BarcodeGroupStringHasher>]::<lambda(uint32_t&)>, int> (fn=..., key=..., this=<optimized out>); at /u/user/tmp/salmon/include/cuckoohash_map.hh:554; #16 densityCalculator<alevin::protocols::Chromium> (parser=<optimized out>, aopt=..., ioMutex=..., freqCounter=...,; usedNumBarcodes=..., totNumBarcodes=...) at /u/user/tmp/salmon/src/Alevin.cpp:137; #17 0x0000000000ba4970 in std::execute_native_thread_routine (__p=<optimized out>); at ../../../.././libstdc++-v3/src/c++11/thread.cc:84; #18 0x00007fff7fbc7064 in start_thread (arg=0x7ffcf97e7700) at pthread_create.c:309; #19 0x00007fff7e95b62d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111; (gdb); #0 0x00007fff7e8a8067 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56; #1 0x00007fff7e8a9448 in __GI_abort () at abort.c:89; #2 0x0000000000b",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234:11690,Protocol,ProtocolT,11690,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234,3,"['Protocol', 'protocol']","['ProtocolT', 'protocols']"
Integrability,"e *full* decoy index is substantially larger than the index on just the transcriptome (after all, it is indexing the entire human genome in addition to the transcriptome). One thing you might try to test this hypothesis, other than requesting to build on a node with more RAM, is to compute a hash (e.g. md5 or sha256 sum) on all of the files in the index, and also record their sizes. Then we can build the index on the same version of the files on our end and compare. Second — and perhaps more importantly for your end goal — the main purpose of the decoy-aware index is to improve specificity rather than sensitivity. That is, the decoys are designed to help avoid _spurious_ mapping of reads to an annotated transcript when a better explanation for the read exists elsewhere in the genome. However, the reads that are mapped to decoys are not otherwise used for quantification. Thus, using the decoy aware transcriptome index is unlikely to improve your mapping rate. I agree that your mapping rate does seem rather low. There are a few potential culprits here, and some diagnostics we can look at to see what might be going wrong. First, you can take a look at the file `aux_info/meta_info.json` in the salmon quantification directories to get a few more details about why reads were not mapped. If you share one of those files here I can describe the relevant fields. Also, I have two more rather common things to consider that might affect the mapping rate. One is to add the sequence for the ribosomal RNAs to your transcriptome before indexing and then quantifying. If your mapping rate increases considerably, this is evidence of rather inefficient depletion prior to sequencing. The other thing to consider is to do basic adapter / quality trimming on the reads to see if that affects your mapping rate at all. I hope these two different responses are useful, and I'll keep this issue open so feel free to reply here with any further questions or discoveries you make regarding the above.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850:2071,adapter,adapter,2071,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850,1,['adapter'],['adapter']
