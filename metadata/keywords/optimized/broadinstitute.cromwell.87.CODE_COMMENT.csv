quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,filename,wiki,url,total_similar,target_keywords,target_matched_words
Availability,"""""""; Copy down workflow and PAPI operations metadata from GCS if needed to test Local.; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py:10,down,down,10,scripts/metadata_comparison/test/lib/test_digester_helper.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py,1,['down'],['down']
Availability,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive digester testing. The metadata is stored; in GCS and copied down to the local machine if not already present from an earlier run. The digester can run; against either local or GCS paths using `ComparisonPath`s. Local is nicer to iterate on than GCS since it; runs so much more quickly. Since GCS testing is slow it's turned off by default, it can be turned on by setting; the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:135,down,down,135,scripts/metadata_comparison/test/test_digester.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py,1,['down'],['down']
Availability,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive operations digester testing.; The metadata is stored in GCS and copied down to the local machine if not already present from an earlier run.; Operations digesters can run against either local or GCS paths using `ComparisonPath`s. Since GCS testing is; slow it's turned off by default, it can be turned on by setting the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py:146,down,down,146,scripts/metadata_comparison/test/test_operations_digesters.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py,1,['down'],['down']
Deployability,"""""""; Reads the operations metadata for any supported pipelines API version.; Returns a python dict; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py:53,pipeline,pipelines,53,scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,1,['pipeline'],['pipelines']
Deployability,"""""""Reads the operations metadata for a pipelines API v1 job ID. Returns a python dict""""""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py:39,pipeline,pipelines,39,scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,1,['pipeline'],['pipelines']
Deployability,"""""""Reads the operations metadata for a pipelines API v2alpha1 job ID. Returns a python dict""""""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py:39,pipeline,pipelines,39,scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,1,['pipeline'],['pipelines']
Deployability,"""""""Reads the operations metadata for a pipelines API v2beta job ID. Returns a python dict""""""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py:39,pipeline,pipelines,39,scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,1,['pipeline'],['pipelines']
Deployability,"#!/usr/bin/env python3; #; # comparer.py; #; # Purpose: Compare performance metadata JSON files produced by Digester and produce result in CSV format; #; # Usage: python3 -m metadata_comparison.comparer [-h] [-v] [--force]; # --name1 NAME_FOR_DIGEST_1 --name2 NAME_FOR_DIGEST_2; # --digest1 PATH_TO_DIGEST_1 --digest2 PATH_TO_DIGEST_2 --output-path OUTPUT_PATH; # [--call-prefix-to-remove [CALL_PREFIX_TO_REMOVE [CALL_PREFIX_TO_REMOVE ...]]]; #; # For ExomeGermlineSingleSample workflows the local call names are globally unique so all; # FQN prefixes can be removed for ease of interpretation. An invocation to compare PAPI v1; # to PAPI v2 might look like:; #; # python3 -m metadata_comparison.comparer --name1 PAPIv1 --name2 PAPIv2 \; # --digest1 papiv1.json --digest2 papiv2.json --output-path comparison.csv \; # --call-prefix-to-remove ExomeGermlineSingleSample.AggregatedBamQC. \; # ExomeGermlineSingleSample.BamToCram. ExomeGermlineSingleSample.BamToGvcf.VariantCalling. \; # ExomeGermlineSingleSample.UnmappedBamToAlignedBam. ExomeGermlineSingleSample.; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:1130,install,install,1130,scripts/metadata_comparison/metadata_comparison/comparer.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py,5,"['install', 'upgrade']","['install', 'upgrade']"
Deployability,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:259,install,install,259,scripts/metadata_comparison/metadata_comparison/digester.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py,7,"['install', 'upgrade']","['install', 'upgrade']"
Deployability,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:307,install,install,307,scripts/metadata_comparison/metadata_comparison/extractor.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py,11,"['install', 'upgrade']","['install', 'upgrade']"
Deployability,"### Main loop; #; # It continuously measures runtime metrics every MEASUREMENT_TIME_SEC,; # and reports them to Stackdriver Monitoring API every REPORT_TIME_SEC.; #; # However, if it detects a container termination signal,; # it *should* report the final metric; # right after the current measurement, and then exit normally.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py:23,continuous,continuously,23,supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py,1,['continuous'],['continuously']
Energy Efficiency,"#; # ($85 / month) / (30.436875 days / month) = $2.792667 / day; # ($2.792667 / day) / (24 hours / day) = $0.116361 / hour; #; # So as we're currently using it the reference disk alone is more expensive than the VM for 90+ % of the jobs; # in the ExomeGermlineSingleSample v1.3 workflows.; #; # Can this be improved? Sure, for EGSS v1.3 a 500 GB disk is way bigger than it needs to be. Making it 50 GB; # instead reduces disk cost by a factor of 10 for a rate of $0.011636 per hour. Better but relative to; # machine pricing that's still way too high. Switching from HDD to SSD also helps:; #; # $0.011636/hour * (HDD / SSD = 0.04 / 0.17 = $0.00273790/hour; #; # Given that running times here; #; # https://docs.google.com/spreadsheets/d/1x8TqiVUGZ7nHU-mxPHFdGnJ3U58fPk5l5dR839XsOBI/edit#gid=804873366; #; # were reduced by < 10%, even after making these adjustments (and that's assuming the performance; # benefits of a 500GB SSD will carry over to a 50GB HDD, which they likely won't, and this is one more; # thing we shouldn't make rosy assumptions about), is using a reference disk going to reduce or increase cost?; # It's possible the disk size could be reduced even more, but mostly this needs test runs.; #; # A machine type-weighted dictionary used for getting more accurate cost estimates.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:413,reduce,reduces,413,scripts/metadata_comparison/metadata_comparison/comparer.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py,4,['reduce'],"['reduce', 'reduced', 'reduces']"
Integrability,"""""""; Abstract Base Class for Local and GCS paths sharing an interface for the purpose of PAPI metadata comparison.; There's nothing particularly ""Comparison"" about these paths, I just couldn't think of a better name.; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/comparison_paths.py:60,interface,interface,60,scripts/metadata_comparison/metadata_comparison/lib/comparison_paths.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/comparison_paths.py,1,['interface'],['interface']
Integrability,"""""""; Abstract Base Class for PAPI operation subclasses sharing an interface for the purpose of treating digesters; uniformly regardless of PAPI version.; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py:66,interface,interface,66,scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py,1,['interface'],['interface']
Integrability,"# The logic below is highly dependent on events being sorted by start timestamp oldest to newest.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_window.py:28,depend,dependent,28,scripts/backpressure_report/backpressure_report/lib/backpressure_window.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_window.py,1,['depend'],['dependent']
Integrability,"# pod names for which we have seen a ""backpressure start"" log messages and for which we are now awaiting a matching; # ""backpressure stop"" log message for the same pod name.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:62,message,messages,62,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,2,['message'],"['message', 'messages']"
Modifiability,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive digester testing. The metadata is stored; in GCS and copied down to the local machine if not already present from an earlier run. The digester can run; against either local or GCS paths using `ComparisonPath`s. Local is nicer to iterate on than GCS since it; runs so much more quickly. Since GCS testing is slow it's turned off by default, it can be turned on by setting; the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:481,variab,variable,481,scripts/metadata_comparison/test/test_digester.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py,1,['variab'],['variable']
Modifiability,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive operations digester testing.; The metadata is stored in GCS and copied down to the local machine if not already present from an earlier run.; Operations digesters can run against either local or GCS paths using `ComparisonPath`s. Since GCS testing is; slow it's turned off by default, it can be turned on by setting the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py:425,variab,variable,425,scripts/metadata_comparison/test/test_operations_digesters.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py,1,['variab'],['variable']
Modifiability,"""""""; Validates then extract the root of the Cromwell URL from the various URL strings which might be provided.; Deliberately flexible because it's tedious to remember which script requires which type of format.; eg:; 'http://localhost' => 'http://localhost'; 'http://localhost:8000' => 'http://localhost:8000'; 'http://localhost:8000/' => 'http://localhost:8000'; 'http://localhost:8000/api/workflows/' => 'http://localhost:8000'; 'http://localhost:8000/custom/prefix/api/workflows/' => 'http://localhost:8000/custom/prefix'; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/argument_regex.py:125,flexible,flexible,125,scripts/metadata_comparison/metadata_comparison/lib/argument_regex.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/argument_regex.py,1,['flexible'],['flexible']
Modifiability,"# Skip slow GCS testing unless this environment variable is set.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:48,variab,variable,48,scripts/metadata_comparison/test/test_digester.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py,2,['variab'],['variable']
Modifiability,"### Define constants; # Cromwell variables passed to the container; # through environmental variables",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py:33,variab,variables,33,supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py,2,['variab'],['variables']
Performance,"""""""; GcsComparisonPaths are somewhat expensive to create so cache them.; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py:60,cache,cache,60,scripts/metadata_comparison/test/lib/test_digester_helper.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py,1,['cache'],['cache']
Performance,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive digester testing. The metadata is stored; in GCS and copied down to the local machine if not already present from an earlier run. The digester can run; against either local or GCS paths using `ComparisonPath`s. Local is nicer to iterate on than GCS since it; runs so much more quickly. Since GCS testing is slow it's turned off by default, it can be turned on by setting; the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:48,perform,performance,48,scripts/metadata_comparison/test/test_digester.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py,1,['perform'],['performance']
Performance,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive operations digester testing.; The metadata is stored in GCS and copied down to the local machine if not already present from an earlier run.; Operations digesters can run against either local or GCS paths using `ComparisonPath`s. Since GCS testing is; slow it's turned off by default, it can be turned on by setting the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py:48,perform,performance,48,scripts/metadata_comparison/test/test_operations_digesters.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py,1,['perform'],['performance']
Performance,"# A cache of expensive-to-create GCS comparison paths.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:4,cache,cache,4,scripts/metadata_comparison/test/test_digester.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py,2,['cache'],['cache']
Performance,"# This script should only ever be pointed at successful workflow metadata. All jobs that have a backend status; # other than `Success` must have later been re-run successfully, so any un`Success`ful attempts are ignored.; # It's possible that a future version of the digester might actually want to look at these jobs since they; # may have completed some lifecycle events which could be useful in accumulating more performance data.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:416,perform,performance,416,scripts/metadata_comparison/metadata_comparison/digester.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py,1,['perform'],['performance']
Performance,"#!/usr/bin/env python3; #; # comparer.py; #; # Purpose: Compare performance metadata JSON files produced by Digester and produce result in CSV format; #; # Usage: python3 -m metadata_comparison.comparer [-h] [-v] [--force]; # --name1 NAME_FOR_DIGEST_1 --name2 NAME_FOR_DIGEST_2; # --digest1 PATH_TO_DIGEST_1 --digest2 PATH_TO_DIGEST_2 --output-path OUTPUT_PATH; # [--call-prefix-to-remove [CALL_PREFIX_TO_REMOVE [CALL_PREFIX_TO_REMOVE ...]]]; #; # For ExomeGermlineSingleSample workflows the local call names are globally unique so all; # FQN prefixes can be removed for ease of interpretation. An invocation to compare PAPI v1; # to PAPI v2 might look like:; #; # python3 -m metadata_comparison.comparer --name1 PAPIv1 --name2 PAPIv2 \; # --digest1 papiv1.json --digest2 papiv2.json --output-path comparison.csv \; # --call-prefix-to-remove ExomeGermlineSingleSample.AggregatedBamQC. \; # ExomeGermlineSingleSample.BamToCram. ExomeGermlineSingleSample.BamToGvcf.VariantCalling. \; # ExomeGermlineSingleSample.UnmappedBamToAlignedBam. ExomeGermlineSingleSample.; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:64,perform,performance,64,scripts/metadata_comparison/metadata_comparison/comparer.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py,1,['perform'],['performance']
Performance,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:63,perform,performance,63,scripts/metadata_comparison/metadata_comparison/digester.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py,1,['perform'],['performance']
Performance,"#; # ($85 / month) / (30.436875 days / month) = $2.792667 / day; # ($2.792667 / day) / (24 hours / day) = $0.116361 / hour; #; # So as we're currently using it the reference disk alone is more expensive than the VM for 90+ % of the jobs; # in the ExomeGermlineSingleSample v1.3 workflows.; #; # Can this be improved? Sure, for EGSS v1.3 a 500 GB disk is way bigger than it needs to be. Making it 50 GB; # instead reduces disk cost by a factor of 10 for a rate of $0.011636 per hour. Better but relative to; # machine pricing that's still way too high. Switching from HDD to SSD also helps:; #; # $0.011636/hour * (HDD / SSD = 0.04 / 0.17 = $0.00273790/hour; #; # Given that running times here; #; # https://docs.google.com/spreadsheets/d/1x8TqiVUGZ7nHU-mxPHFdGnJ3U58fPk5l5dR839XsOBI/edit#gid=804873366; #; # were reduced by < 10%, even after making these adjustments (and that's assuming the performance; # benefits of a 500GB SSD will carry over to a 50GB HDD, which they likely won't, and this is one more; # thing we shouldn't make rosy assumptions about), is using a reference disk going to reduce or increase cost?; # It's possible the disk size could be reduced even more, but mostly this needs test runs.; #; # A machine type-weighted dictionary used for getting more accurate cost estimates.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:892,perform,performance,892,scripts/metadata_comparison/metadata_comparison/comparer.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py,1,['perform'],['performance']
Safety,"### Main loop; #; # It continuously measures runtime metrics every MEASUREMENT_TIME_SEC,; # and reports them to Stackdriver Monitoring API every REPORT_TIME_SEC.; #; # However, if it detects a container termination signal,; # it *should* report the final metric; # right after the current measurement, and then exit normally.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py:183,detect,detects,183,supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py,1,['detect'],['detects']
Security,"""""""Gets the relevant client for accessing a PAPI API, or makes a new instance if necessary""""""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py:32,access,accessing,32,scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,1,['access'],['accessing']
Security,"""""""Makes a new client for accessing a specified PAPI API""""""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py:26,access,accessing,26,scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,1,['access'],['accessing']
Security,"# + hash(self.disk_type)",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py:4,hash,hash,4,scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py,1,['hash'],['hash']
Security,"# Controversial and doesn't seem to work for the tests anyway, YMMV.; # warnings.filterwarnings(""ignore"", ""Your application has authenticated using end user credentials"")",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/logging.py:128,authenticat,authenticated,128,scripts/metadata_comparison/metadata_comparison/lib/logging.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/logging.py,1,['authenticat'],['authenticated']
Testability,"""""""; Build a list of BackpressureEvents from the specified logs, using matched ""start"" and ""end"" events for a particular; pod to delimit the duration of the BackpressureEvent. :param logs: a list of JSON log files, each of which is a list of JSON objects each representing a log entry.; :return: a list of BackpressureEvents.; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:59,log,logs,59,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,4,['log'],"['log', 'logs']"
Testability,"""""""; Copy down workflow and PAPI operations metadata from GCS if needed to test Local.; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py:75,test,test,75,scripts/metadata_comparison/test/lib/test_digester_helper.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py,1,['test'],['test']
Testability,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive digester testing. The metadata is stored; in GCS and copied down to the local machine if not already present from an earlier run. The digester can run; against either local or GCS paths using `ComparisonPath`s. Local is nicer to iterate on than GCS since it; runs so much more quickly. Since GCS testing is slow it's turned off by default, it can be turned on by setting; the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:84,test,testing,84,scripts/metadata_comparison/test/test_digester.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py,2,['test'],['testing']
Testability,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive operations digester testing.; The metadata is stored in GCS and copied down to the local machine if not already present from an earlier run.; Operations digesters can run against either local or GCS paths using `ComparisonPath`s. Since GCS testing is; slow it's turned off by default, it can be turned on by setting the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py:95,test,testing,95,scripts/metadata_comparison/test/test_operations_digesters.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py,2,['test'],['testing']
Testability,"# Already-processed log entry ids to ignore duplicates in overlapping log file ranges.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:20,log,log,20,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,2,['log'],['log']
Testability,"# Complete BackpressureEvent objects corresponding to a matched pair of backpressure start and stop log entries for; # a pod.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:100,log,log,100,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,1,['log'],['log']
Testability,"# Controversial and doesn't seem to work for the tests anyway, YMMV.; # warnings.filterwarnings(""ignore"", ""Your application has authenticated using end user credentials"")",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/logging.py:49,test,tests,49,scripts/metadata_comparison/metadata_comparison/lib/logging.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/logging.py,1,['test'],['tests']
Testability,"# Currently just a smoke test to assert not-completely-insane results for both v1 and v2 digesters.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:25,test,test,25,scripts/metadata_comparison/test/test_digester.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py,2,"['assert', 'test']","['assert', 'test']"
Testability,"# Merge the logs so the sorting covers all log entries.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:12,log,logs,12,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,2,['log'],"['log', 'logs']"
Testability,"# Remove confusing duplication in subworkflow call names.; # A parent workflow would name a subworkflow call ""parent_wf.sub_wf"".; # The subworkflow would name its calls ""sub_wf.sub_call"".; # If those call components were simply joined the result would be; # ""parent_wf.sub_wf.sub_wf.sub_call"". This logic removes the duplication of ""sub_wf"",; # resulting in ""parent_wf.sub_wf.sub_call"".",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py:299,log,logic,299,scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py,1,['log'],['logic']
Testability,"# Skip slow GCS testing unless this environment variable is set.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:16,test,testing,16,scripts/metadata_comparison/test/test_digester.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py,2,['test'],['testing']
Testability,"# The logic below is highly dependent on events being sorted by start timestamp oldest to newest.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_window.py:6,log,logic,6,scripts/backpressure_report/backpressure_report/lib/backpressure_window.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_window.py,1,['log'],['logic']
Testability,"# There are actually two timestamps in the JSON log entries which appear to represent different concepts:; # time emitted ('jsonPayload.localTimestamp') versus time added to the log ('timestamp'). Time emitted would; # seem to be preferable but that value is not specified with a timezone and is ambiguously interpreted by; # the parsing code as being EST when it's actually UTC. This can make reading the report a bit confusing or; # misleading. In practice the timestamps only seem to differ by small amounts, so no big deal to use; # 'timestamp' with its explicit UTC timezone.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:48,log,log,48,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,2,['log'],['log']
Testability,"# insert more intelligent assertions here",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:26,assert,assertions,26,scripts/metadata_comparison/test/test_digester.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py,1,['assert'],['assertions']
Testability,"# pod names for which we have seen a ""backpressure start"" log messages and for which we are now awaiting a matching; # ""backpressure stop"" log message for the same pod name.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:58,log,log,58,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,2,['log'],['log']
Testability,"#!/usr/bin/env python3; #; # comparer.py; #; # Purpose: Compare performance metadata JSON files produced by Digester and produce result in CSV format; #; # Usage: python3 -m metadata_comparison.comparer [-h] [-v] [--force]; # --name1 NAME_FOR_DIGEST_1 --name2 NAME_FOR_DIGEST_2; # --digest1 PATH_TO_DIGEST_1 --digest2 PATH_TO_DIGEST_2 --output-path OUTPUT_PATH; # [--call-prefix-to-remove [CALL_PREFIX_TO_REMOVE [CALL_PREFIX_TO_REMOVE ...]]]; #; # For ExomeGermlineSingleSample workflows the local call names are globally unique so all; # FQN prefixes can be removed for ease of interpretation. An invocation to compare PAPI v1; # to PAPI v2 might look like:; #; # python3 -m metadata_comparison.comparer --name1 PAPIv1 --name2 PAPIv2 \; # --digest1 papiv1.json --digest2 papiv2.json --output-path comparison.csv \; # --call-prefix-to-remove ExomeGermlineSingleSample.AggregatedBamQC. \; # ExomeGermlineSingleSample.BamToCram. ExomeGermlineSingleSample.BamToGvcf.VariantCalling. \; # ExomeGermlineSingleSample.UnmappedBamToAlignedBam. ExomeGermlineSingleSample.; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:1271,log,login,1271,scripts/metadata_comparison/metadata_comparison/comparer.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py,2,['log'],['login']
Testability,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:444,log,login,444,scripts/metadata_comparison/metadata_comparison/digester.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py,2,['log'],['login']
Testability,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:564,log,login,564,scripts/metadata_comparison/metadata_comparison/extractor.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py,2,['log'],['login']
Testability,"#; # ($85 / month) / (30.436875 days / month) = $2.792667 / day; # ($2.792667 / day) / (24 hours / day) = $0.116361 / hour; #; # So as we're currently using it the reference disk alone is more expensive than the VM for 90+ % of the jobs; # in the ExomeGermlineSingleSample v1.3 workflows.; #; # Can this be improved? Sure, for EGSS v1.3 a 500 GB disk is way bigger than it needs to be. Making it 50 GB; # instead reduces disk cost by a factor of 10 for a rate of $0.011636 per hour. Better but relative to; # machine pricing that's still way too high. Switching from HDD to SSD also helps:; #; # $0.011636/hour * (HDD / SSD = 0.04 / 0.17 = $0.00273790/hour; #; # Given that running times here; #; # https://docs.google.com/spreadsheets/d/1x8TqiVUGZ7nHU-mxPHFdGnJ3U58fPk5l5dR839XsOBI/edit#gid=804873366; #; # were reduced by < 10%, even after making these adjustments (and that's assuming the performance; # benefits of a 500GB SSD will carry over to a 50GB HDD, which they likely won't, and this is one more; # thing we shouldn't make rosy assumptions about), is using a reference disk going to reduce or increase cost?; # It's possible the disk size could be reduced even more, but mostly this needs test runs.; #; # A machine type-weighted dictionary used for getting more accurate cost estimates.",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:1201,test,test,1201,scripts/metadata_comparison/metadata_comparison/comparer.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py,1,['test'],['test']
Usability,"# Remove confusing duplication in subworkflow call names.; # A parent workflow would name a subworkflow call ""parent_wf.sub_wf"".; # The subworkflow would name its calls ""sub_wf.sub_call"".; # If those call components were simply joined the result would be; # ""parent_wf.sub_wf.sub_wf.sub_call"". This logic removes the duplication of ""sub_wf"",; # resulting in ""parent_wf.sub_wf.sub_call"".",MatchSource.CODE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py:221,simpl,simply,221,scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py,1,['simpl'],['simply']
