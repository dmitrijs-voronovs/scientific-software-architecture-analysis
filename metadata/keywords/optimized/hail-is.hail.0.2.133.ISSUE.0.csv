quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Availability,"	--master-machine-type=n1-highmem-8 --worker-machine-type=n1-highmem-8 \; 	--num-workers=300	--num-secondary-workers=0 \; 	--worker-boot-disk-size=1000 \; 	--properties=dataproc:dataproc.logging.stackdriver.enable=true,dataproc:dataproc.monitoring.stackdriver.enable=true; ```; We are currently receiving a spark error when using this cluster for our larger dataset. ```; [Stage 10:=====> (69 + 656) / 729]; raise err; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 98, in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); File ""/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py"", line 1304, in __call__; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 31, in deco; raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.project-.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.gbsc-project.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:1463,failure,failure,1463,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['failure'],['failure']
Availability,"	G,*,AG,CG	596	PASS	AC=2,4,6,1;AF=1.23e-03,5.550e-05,4.44e-05,2.00e-04;AN=265;AS_AltDP=10,0,3,10;AS_BaseQRankSum=0.000,.,0.100,0.500;AS_FS=7.777,.,2.144,8.001;AS_MQ=55.75,.,38.98,40.20;AS_MQRankSum=0.200,.,-1.050,-0.500;AS_QD=0.50,0.00,0.25,0.52;AS_ReadPosRankSum=-0.200,.,0.500,-0.220;AS_SOR=2.300,.,1.600,3.000;BaseQRankSum=0.200;DP=600000;ExcessHet=0.0477;FS=0.900;MQ=55.02;MQRankSum=-0.553;QD=1.00;ReadPosRankSum=-0.162;SOR=0.792;VarDP=650	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0/0:.:21:30	0/0:.:300:20	0/0:.:30:72	0/0:.:31:98	0|1:29,3,0,0,0:33:78:0|1:113_GG_G:78,0,1100,140,1400,1200,172,1600,1200,1000,175,1100,1100,1300,1000:113:19,19,2,1	0/0:.:20:19	0/0:.:19:20	0/0:.:25:50		0|1:90,2,0,0,0:30:40:0|1:113_GG_G:40,0,600,70,650,600,90,640,900,300,60,800,400,900,900:113:2,14,2,0	0/0:.:20:10	0/0:.:9:20	0/0:.:30:40	0/0:.:37:38		0/4:5,0,0,0,1:5:33:.:.:30,40,400,50,220,220,38,270,270,270,0,200,200,200,202:.:5,0,0,1	. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:22); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:22); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1921); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7$adapted(LoadVCF.scala:1909); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:515); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at __C678stream_Let.apply(Emit.scala); 	at is.hail.expr.ir.CompileIterator$$anon$2.step(Compile.scala:302); 	at is.hail.expr.ir.CompileIterator$LongIteratorWrapper.hasNext(Compile.scala:155); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:7327,Error,ErrorHandling,7327,https://hail.is,https://github.com/hail-is/hail/issues/14102,2,['Error'],['ErrorHandling']
Availability,	at is.hail.expr.ApplyMethod$$anonfun$toIR$12$$anonfun$apply$58.apply(AST.scala:844); 	at is.hail.expr.ApplyMethod$$anonfun$toIR$12$$anonfun$apply$58.apply(AST.scala:844); 	at scala.Option.map(Option.scala:146); 	at is.hail.expr.ApplyMethod$$anonfun$toIR$12.apply(AST.scala:844); 	at is.hail.expr.ApplyMethod$$anonfun$toIR$12.apply(AST.scala:842); 	at scala.Option.flatMap(Option.scala:171); 	at is.hail.expr.ApplyMethod.toIR(AST.scala:842); 	at is.hail.expr.StructConstructor$$anonfun$toIR$5.apply(AST.scala:410); 	at is.hail.expr.StructConstructor$$anonfun$toIR$5.apply(AST.scala:410); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.expr.StructConstructor.toIR(AST.scala:410); 	at is.hail.table.Table.select(Table.scala:512); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: devel-a870693; Error summary: ClassCastException: java.lang.Integer cannot be cast to java.lang.Double; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3436:6797,Error,Error,6797,https://hail.is,https://github.com/hail-is/hail/issues/3436,1,['Error'],['Error']
Availability,	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); E 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:47); E 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:454); E 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:490); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:75); E 	at is.hail.utils.package$.using(package.scala:635); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:75); E 	at is.hail.utils.package$.using(package.scala:635); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:63); E 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:342); E 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$1(SparkBackend.scala:487); E 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); E 	at is.hail.backend.spark.SparkBackend.executeEncode(SparkBackend.scala:486); E 	at jdk.internal.reflect.GeneratedMethodAccessor72.invoke(Unknown Source); E 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); E 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); E 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); E 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); E 	at py4j.Gateway.invoke(Gateway.java:282); E 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); E 	at py4j.commands.CallCommand.execute(CallCommand.java:79); E 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182); E 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106); E 	at java.base/java.lang.Thread.run(Thread.java:834); E ; E ; E ; E Hail version: 0.2.109-c163bcb21073; E Error summary: AssertionError: assertion failed. hail/backend/py4j_backend.py:35: FatalError. ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12754#issuecomment-1456467229:6547,Error,Error,6547,https://hail.is,https://github.com/hail-is/hail/pull/12754#issuecomment-1456467229,1,['Error'],['Error']
Availability,	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829); Caused by: is.hail.utils.HailException: cannot set missing field for required type +PFloat64; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:207); 	at is.hail.io.vcf.VCFLine.parseAddInfoArrayDouble(LoadVCF.scala:1034); 	at is.hail.io.vcf.VCFLine.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	... 21 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.Resiza,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:9191,Error,ErrorHandling,9191,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['Error'],['ErrorHandling']
Availability,	at is.hail.rvd.RVD$class.take(RVD.scala:251); 	at is.hail.rvd.OrderedRVD.take(OrderedRVD.scala:32); 	at is.hail.table.Table.take(Table.scala:637); 	at is.hail.table.Table.showString(Table.scala:673); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)is.hail.utils.HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1012); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.RVD$$anonfun$4$$anon$1.hasNext(RVD.scala:226); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1015); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); 	at is.hail.utils.richUtils.R,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:8462,error,error,8462,https://hail.is,https://github.com/hail-is/hail/issues/4055,1,['error'],['error']
Availability,"	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). is.hail.utils.HailException: found out of bounds index -1; Resulted from trying to merge -0.0; Indices are [0.0, 2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0, 18.0, 20.0, 22.0, 24.0, 26.0, 28.0, 30.0, 32.0, 34.0, 36.0, 38.0, 40.0, 42.0, 44.0, 46.0, 48.0, 50.0, 52.0, 54.0, 56.0, 58.0, 60.0, 62.0, 64.0, 66.0, 68.0, 70.0, 72.0, 74.0, 76.0, 78.0, 80.0, 82.0, 84.0, 86.0, 88.0, 90.0, 92.0, 94.0, 96.0, 98.0, 100.0, 102.0, 104.0, 106.0, 108.0, 110.0, 112.0, 114.0, 116.0, 118.0, 120.0, 122.0, 124.0, 126.0, 128.0, 130.0, 132.0, 134.0, 136.0, 138.0, 140.0, 142.0, 144.0, 146.0, 148.0, 150.0, 152.0, 154.0, 156.0, 158.0, 160.0, 162.0, 164.0, 166.0, 168.0, 170.0, 172.0, 174.0, 176.0, 178.0, 180.0, 182.0, 184.0, 186.0, 188.0, 190.0, 192.0, 194.0, 196.0, 198.0, 200.0]; Binary search index was -1; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.stats.HistogramCombiner.merge(HistogramCombiner.scala:42); 	at is.hail.annotations.aggregators.RegionValueHistogramAggregator.seqOp(RegionValueHistogramAggregator.scala:31); 	at is.hail.codegen.generated.C95.apply(Unknown Source); 	at is.hail.codegen.generated.C95.apply(Unknown Source); 	at is.hail.expr.ir.Interpret$$anonfun$27.apply(Interpret.scala:809); 	at is.hail.expr.ir.Interpret$$anonfun$27.apply(Interpret.scala:808); 	at is.hail.rvd.RVD$$anonfun$20$$anonfun$apply$11.apply(RVD.scala:551); 	at is.hail.rvd.RVD$$anonfun$20$$anonfun$apply$11.apply(RVD.scala:550); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$20.apply(RVD.scala:550); 	at is.hail.rvd.RVD$$anonfun$20.apply(RVD.scala:547); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$32.apply(ContextRD",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:10371,Error,ErrorHandling,10371,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['Error'],['ErrorHandling']
Availability,	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.fold(TraversableOnce.scala:212); 	at scala.collection.AbstractIterator.fold(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1$$anonfun$20.apply(RDD.scala:1095); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1$$anonfun$20.apply(RDD.scala:1095); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). is.hail.utils.HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.io.LoadMatrixParser.parseLine(LoadMatrix.scala:33); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:383); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:377); 	at is.hail.utils.WithContext.wrap(Context.scala:41); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$count$2.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:12687,Error,Error,12687,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['Error'],['Error']
Availability,	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); 	at scala.collection.Iterator$class.foreach(Iterator.scala:891); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1334); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1334); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.34-914bd8a10ca2; Error summary: HailException: cannot set missing field for required type +PCStruct{info:PCStruct{ALLELEID:PInt32}}; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:118368,Error,Error,118368,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['Error'],['Error']
Availability,	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)is.hail.utils.HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1011); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.io.RichContextRDDRegionValue$.writeRowsPartition(RowStore.scala:1071); 	at is.hail.io.RichContextRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:1096); 	at is.hail.io.RichContextRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:1096); 	at is.hail.utils.richUtils.RichContextRDD$$anonfun$1.apply(RichContextRDD.scala:42); 	at is.hail.utils.richUtils.RichContextRDD$$anonfun$1.apply(RichContextRDD.scala:27); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$22.app,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4096:8271,Error,ErrorHandling,8271,https://hail.is,https://github.com/hail-is/hail/issues/4096,1,['Error'],['ErrorHandling']
Availability,	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)is.hail.utils.HailException: ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf: caught java.util.NoSuchElementException: key not found: GT; offending line: 22	16050075	rs587697622	A	G	100	PASS	AC=1;AF=0.000199681;AN=...; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.utils.Context.wrapException(Context.scala:23); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:761); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); 	at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:413); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:815); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:815); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3467:7684,Error,ErrorHandling,7684,https://hail.is,https://github.com/hail-is/hail/issues/3467,1,['Error'],['ErrorHandling']
Availability," 	at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(SparkBackend.scala:305); 	at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(SparkBackend.scala:304); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:20); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:18); 	at is.hail.utils.package$.using(package.scala:609); 	at is.hail.annotations.Region$.scoped(Region.scala:18); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:18); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:230); 	at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:304); 	at is.hail.backend.spark.SparkBackend.executeJSON(SparkBackend.scala:324); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.53-e245ebe1d9a6; Error summary: HailException: Index 5 is out of bounds for axis 0 with size 2; ```. Numpy:; ```sh; In [22]: hl.eval(ndarray_t[5,0:1000]) ; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-22-0643c9661056> in <module>; ----> 1 hl.eval(ndarray_t[5,0:1000]). IndexError: index 5 is out of bounds for axis 0 with size 2; ```. The stack trace is uninformative, and the typical Hail user will not want to see it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9226:4774,Error,Error,4774,https://hail.is,https://github.com/hail-is/hail/issues/9226,1,['Error'],['Error']
Availability," ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:35,400	job.py	schedule_job:473	error while scheduling job (93, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:7355,ERROR,ERROR,7355,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['ERROR'],['ERROR']
Availability," ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,364	job.py	schedule_job:473	error while scheduling job (90, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:11856,ERROR,ERROR,11856,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['ERROR'],['ERROR']
Availability," ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,390	job.py	schedule_job:473	error while scheduling job (97, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:13861,ERROR,ERROR,13861,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['ERROR'],['ERROR']
Availability," ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,435	job.py	schedule_job:473	error while scheduling job (101, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:15866,ERROR,ERROR,15866,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['ERROR'],['ERROR']
Availability," ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,447	job.py	schedule_job:473	error while scheduling job (102, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:17872,ERROR,ERROR,17872,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['ERROR'],['ERROR']
Availability," ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:39,193	job.py	schedule_job:473	error while scheduling job (99, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:22021,ERROR,ERROR,22021,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['ERROR'],['ERROR']
Availability," ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:39,204	job.py	schedule_job:473	error while scheduling job (100, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:24026,ERROR,ERROR,24026,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['ERROR'],['ERROR']
Availability," ### What went wrong (all error messages here, including the full java stack trace): HailException: optimization changed type!; before: Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{ABHet:Float64,ABHom:Float64,AC:Array[Int32],AF:Array[Float64],AN:Int32,AS_BaseQRankSum:Array[Float64],AS_FS:Array[Float64],AS_InbreedingCoeff:Array[Float64],AS_InsertSizeRankSum:Array[Float64],AS_MQ:Array[Float64],AS_MQRankSum:Array[Float64],AS_QD:Float64,AS_ReadPosRankSum:Array[Float64],AS_SOR:Array[Float64],BaseQRankSum:Float64,DP:Int32,DS:Boolean,ExcessHet:Float64,FS:Float64,HRun:Int32,HaplotypeScore:Float64,InbreedingCoeff:Float64,LikelihoodRankSum:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,OND:Float64,QD:Float64,RPA:Array[Int32],RU:String,ReadPosRankSum:Float64,ReverseComplementedAlleles:Boolean,SOR:Float64,STR:Boolean,SwappedAlleles:Boolean},a_index:Int32,was_split:Boolean,old_locus:Locus(GRCh37),old_alleles:Array[String]},entry:Struct{AB:Float64,AD:Array[+Int32],DP:Int32,GQ:Int32,GT:Call,MQ0:Int32,PL:Array[+Int32],SB:Array[+Int32]}}; after: Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{ABHet:Float64,ABHom:Float64,AC:Array[Int32],AF:Array[Float64],AN:Int32,AS_BaseQRankSum:Array[Float64],AS_FS:Array[Float64],AS_InbreedingCoeff:Array[Float64],AS_InsertSizeRankSum:Array[Float64],AS_MQ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4827:405,error,error,405,https://hail.is,https://github.com/hail-is/hail/issues/4827,1,['error'],['error']
Availability," ### What you did: ; Ran hail's maximal independent set method with the following code:. ```; related_samples_to_drop_ranked = hl.maximal_independent_set(related_pairs.id1_rank, related_pairs.id2_rank,keep=False, tie_breaker=tie_breaker); ```. where related pairs is structured as:. ```; ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'i': struct {; data_type: str, ; s: str; } ; 'j': struct {; data_type: str, ; s: str; } ; 'id1_rank': struct {; id: struct {; data_type: str, ; s: str; }, ; rank: int32; } ; 'id2_rank': struct {; id: struct {; data_type: str, ; s: str; }, ; rank: int32; } ; ----------------------------------------; Key: ['i', 'j']; ----------------------------------------; ```. and tie_breaker is :. ```; def tie_breaker(l, r):; return hl.or_else(l.rank, max_rank + 1) - hl.or_else(r.rank, max_rank + 1); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; FatalError Traceback (most recent call last); <ipython-input-220-88e7ce1066ed> in <module>; 11 return hl.or_else(l.rank, max_rank + 1) - hl.or_else(r.rank, max_rank + 1); 12 ; ---> 13 related_samples_to_drop_ranked = hl.maximal_independent_set(related_pairs.id1_rank, related_pairs.id2_rank,keep=False, tie_breaker=tie_breaker); 14 #return related_samples_to_drop_ranked.select(**related_samples_to_drop_ranked.node.id).key_by('data_type', 's'). <decorator-gen-1024> in maximal_independent_set(i, j, keep, tie_breaker). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. /home/hail/hail.zip/hail/methods/misc.py in maximal_independent_set(i, j, keep, tie_breaker); 142 ; 143 edges = t.key_by().select('i', 'j'); --> 144 nodes_in_set = Env.hail()",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4857:965,error,error,965,https://hail.is,https://github.com/hail-is/hail/issues/4857,1,['error'],['error']
Availability," ### What you did:. copied from gitter:. I'm using hail 0.1 on dataproc and trying to import a vcf from the local filesystem; run(""wget ftp://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh{0}/clinvar.vcf.gz -O /tmp/clinvar.vcf.gz"".format(args.genome_version)); run(""ls -l /tmp/clinvar.vcf.gz""); vds = hc.import_vcf(""file:///tmp/clinvar.vcf.gz"", force=True); The output is; ls -l /tmp/clinvar.vcf.gz; -rw-r--r-- 1 root root 16218805 Jun 14 20:21 /tmp/clinvar.vcf.gz; Traceback (most recent call last):; File ""/tmp/7417fcfbbeee44d0b3f4c0b3750121a7/load_clinvar_to_es_pipeline.py"", line 31, in <module>; vds = hc.import_vcf(""file:///tmp/clinvar.vcf.gz"", force=True); File ""<decorator-gen-502>"", line 2, in import_vcf; File ""/tmp/7417fcfbbeee44d0b3f4c0b3750121a7/hail-0.1-es-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputF",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:1264,failure,failure,1264,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['failure'],['failure']
Availability," && ab >= 0.9))')`. ### What went wrong (all error messages here, including the full java stack trace):; ```; Python 2.7.14 |Anaconda, Inc.| (default, Oct 16 2017, 17:29:19); [GCC 7.2.0] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/02/22 20:29:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/02/22 20:29:10 WARN Utils: Your hostname, CompyWompy resolves to a loopback address: 127.0.1.1; using 192.168.1.122 instead (on interface eth0); 18/02/22 20:29:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.14 (default, Oct 16 2017 17:29:19); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(spark.sparkContext); Running on Apache Spark version 2.0.2; SparkUI available at http://192.168.1.122:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-20613ed; >>> table = hc.import_table('data/1kg_annotations.txt', impute=True).key_by('Sample'); 2018-02-22 20:29:45 Hail: INFO: Reading table to impute column types; 2018-02-22 20:29:45 Hail: INFO: Finished type imputation; Loading column `Sample' as type String (imputed); Loading column `Population' as type String (imputed); Loading column `SuperPopulation' as type String (imputed); Loading column `isFemale' as type Boolean (imputed); Loading column `PurpleHair' as type Boolean (imputed); Loading column `CaffeineConsumption' as type Int (imputed); >>> common_vds = hc.read('/mnt/d/metistream/hail/data/1kg.vds'); >>> common_vds = common_vds.annotate_samples_table(table, root='sa'); SLF4J: Failed to load class ""org.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2966:2047,avail,available,2047,https://hail.is,https://github.com/hail-is/hail/issues/2966,1,['avail'],['available']
Availability," &{map[""apiVersion"":""v1"" ""kind"":""Namespace"" ""metadata"":map[""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""] ""name"":""batch-pods"" ""namespace"":""""]]}; from server for: ""deployment.yaml"": namespaces ""batch-pods"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get namespaces in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""/v1, Resource=serviceaccounts"", GroupVersionKind: ""/v1, Kind=ServiceAccount""; Name: ""batch-svc"", Namespace: ""batch-pods""; Object: &{map[""kind"":""ServiceAccount"" ""metadata"":map[""name"":""batch-svc"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""apiVersion"":""v1""]}; from server for: ""deployment.yaml"": serviceaccounts ""batch-svc"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get serviceaccounts in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=roles"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=Role""; Name: ""batch-pods-admin"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""Role"" ""metadata"":map[""name"":""batch-pods-admin"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""rules"":[map[""apiGroups"":[""""] ""resources"":[""pods""] ""verbs"":[""get"" ""list"" ""watch"" ""create"" ""update"" ""patch"" ""delete""]] map[""apiGroups"":[""""] ""resources"":[""pods/log""] ""verbs"":[""get""]]]]}; from server for: ""deployment.yaml"": roles.rbac.authorization.k8s.io ""batch-pods-admin"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get roles.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609:1301,Error,Error,1301,https://hail.is,https://github.com/hail-is/hail/issues/4609,2,"['Error', 'error']","['Error', 'error']"
Availability," 'hail_version=""0.2.124-13536b531342"";' > python/hail/docs/_static/hail_version.js; printf 'hail_pip_version=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.propertie",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:3222,echo,echo,3222,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['echo'],['echo']
Availability," (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/dateutil/dateutil/blob/master/NEWS"">python-dateutil's changelog</a>.</em></p>; <blockquote>; <h1>Version 2.8.2 (2021-07-08)</h1>; <h2>Data updates</h2>; <ul>; <li>Updated tzdata version to 2021a. (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1128"">#1128</a>)</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Fixed a bug in the parser where non-<code>ValueError</code> exceptions would be raised; during exception handling; this would happen, for example, if an; <code>IllegalMonthError</code> was raised in <code>dateutil</code> code. Fixed by Mark Bailey.; (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/981"">#981</a>, pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/987"">#987</a>).</li>; <li>Fixed the custom <code>repr</code> for <code>dateutil.parser.ParserError</code>, which was not; defined due to an indentation error. (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/991"">#991</a>, gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/993"">#993</a>)</li>; <li>Fixed a bug that caused <code>b'</code> prefixes to appear in parse_isodate exception; messages. Reported and fixed by Paul Brown (<a href=""https://github.com/pawl""><code>@pawl</code></a>) (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1122"">#1122</a>)</li>; <li>Make <code>isoparse</code> raise when trying to parse times with inconsistent use of; <code>:</code> separator. Reported and fixed by <a href=""https://github.com/mariocj89""><code>@mariocj89</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1125"">#1125</a>).</li>; <li>Fixed <code>tz.gettz()</code> not returning local time when passed an empty string.; Reported by <a href=""https://github.com/labrys""><code>@labrys</code><",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:5416,error,error,5416,https://hail.is,https://github.com/hail-is/hail/pull/11518,1,['error'],['error']
Availability," - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiOGQwNmE2Yi00MTg0LTRhMzAtOGMxYi0wYzNhZDVkZDk",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14045:1288,avail,available,1288,https://hail.is,https://github.com/hail-is/hail/pull/14045,1,['avail'],['available']
Availability," --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:8712,ERROR,ERROR,8712,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['ERROR'],['ERROR']
Availability," --conf spark.executor.extraClassPath=./hail-all-spark.jar \; --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \; --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator\; ""$@"". ```; Here is a sample of the yarn log....; ...; SLF4J: Class path contains multiple SLF4J bindings.; SLF4J: Found binding in [jar:file:/data04/hadoop/yarn/local/usercache/farrell/filecache/40/__spark_libs__5184408978318087972.zip/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: Found binding in [jar:file:/usr/hdp/2.4.0.0-169/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.; SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]; 19/01/22 13:11:40 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; ERROR: dlopen(""/data05/hadoop/yarn/local/usercache/farrell/appcache/application_1542127286896_0174/container_e2435_1542127286896_0174_01_000011/tmp/libhail6914320507038502759.so""): /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.18' not found (required by /data05/hadoop/yarn/local/usercache/farrell/appcache/application_1542127286896_0174/container_e2435_1542127286896_0174_01_000011/tmp/libhail6914320507038502759.so); FATAL: caught exception java.lang.UnsatisfiedLinkError: /data05/hadoop/yarn/local/usercache/farrell/appcache/application_1542127286896_0174/container_e2435_1542127286896_0174_01_000011/tmp/libhail6914320507038502759.so: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.18' not found (required by /data05/hadoop/yarn/local/usercache/farrell/appcache/application_1542127286896_0174/container_e2435_1542127286896_0174_01_000011/tmp/libhail6914320507038502759.so); java.lang.UnsatisfiedLinkError: /data05/hadoop/yarn/local/usercache/farrell/appcache/application_1542127286896_0174/container_e2435_1542127286896_0174_01_000011/tmp/libhail691432050703",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456518258:2791,ERROR,ERROR,2791,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456518258,1,['ERROR'],['ERROR']
Availability," / / [1 files][286.6 MiB/369.7 MiB] - \ \ [1 files][342.1 MiB/369.7 MiB] |; Operation completed over 2 objects/369.7 MiB.; | [2 files][369.7 MiB/369.7 MiB] 2024/01/17 20:59:27 Localization script execution complete.; 2024/01/17 20:59:38 Done localization.; 2024/01/17 20:59:39 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint=/bin/bash hailgenetics/hail@sha256:3f22576793ce3161893aed2bd40949b1fc822d2b7e6517dc0ac993b62badaff8 /cromwell_root/script; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.81879b1c; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.81879b1c; 24/01/17 20:59:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 3.3.2; SparkUI available at http://523bc6a27b69:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-bb535cd096c5; LOGGING: writing to /cromwell_root/hail-20240117-2059-0.2.127-bb535cd096c5.log; 2024-01-17 21:01:32.019 Hail: INFO: Found 34523 samples in fam file.; 2024-01-17 21:01:32.020 Hail: INFO: Found 18377527 variants in bim file.; 2024-01-17 21:02:45.920 Hail: INFO: Found 34523 samples in fam file.; 2024-01-17 21:02:45.920 Hail: INFO: Found 18377527 variants in bim file.; Traceback (most recent call last):; File ""<stdin>"", line 38, in <module>; File ""<decorator-gen-1366>"", line 2, in write; File ""/usr/local/lib/python3.10/dist-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/usr/local/lib/python3.10/dist-packages/hail/matrixtable.py"", line 2807, in write; Env.backend().execute(ir.MatrixWrite(self._mir, writer)); File ""/usr/local/lib/python3.10/dist-packages/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14168:11300,avail,available,11300,https://hail.is,https://github.com/hail-is/hail/issues/14168,1,['avail'],['available']
Availability, /batch/990e17d5209d429196c84ce010acab9d; 2024-11-05 02:43:37.202 JVMEntryway: INFO: 3: /batch/990e17d5209d429196c84ce010acab9d/log; 2024-11-05 02:43:37.202 JVMEntryway: INFO: 4: gs://hail-query-daaf463550/jars/4c60fddb171a52c21f41a81995c53a28e375c26b.jar; 2024-11-05 02:43:37.202 JVMEntryway: INFO: 5: driver; 2024-11-05 02:43:37.202 JVMEntryway: INFO: 6: execute(...); 2024-11-05 02:43:37.202 JVMEntryway: INFO: 7: gs://cpg-bioheart-hail/batch-tmp/tmp/hail/sRjJqvkZ3l9nmKuUErfNZv/jHpWQ6lemx/in; 2024-11-05 02:43:37.202 JVMEntryway: INFO: 8: gs://cpg-bioheart-hail/batch-tmp/tmp/hail/sRjJqvkZ3l9nmKuUErfNZv/jHpWQ6lemx/out; 2024-11-05 02:43:37.202 JVMEntryway: INFO: Yielding control to the QoB Job.; 2024-11-05 02:43:37.206 ServiceBackendAPI$: INFO: BatchClient allocated.; 2024-11-05 02:43:37.207 ServiceBackendAPI$: INFO: BatchConfig parsed.; 2024-11-05 02:43:37.209 GoogleStorageFS$: INFO: Initializing google storage client from service account key; 2024-11-05 02:43:37.783 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]; 	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:?]; 	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]; 	at java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119) [jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]; 	at java.lang.Th,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14749:2160,ERROR,ERROR,2160,https://hail.is,https://github.com/hail-is/hail/issues/14749,1,['ERROR'],['ERROR']
Availability," /etc/prometheus; /dev/sda1 94.3G 46.4G 47.9G 49% /dev/termination-log; /dev/sda1 94.3G 46.4G 47.9G 49% /etc/resolv.conf; /dev/sda1 94.3G 46.4G 47.9G 49% /etc/hostname; /dev/sda1 94.3G 46.4G 47.9G 49% /etc/hosts; shm 64.0M 0 64.0M 0% /dev/shm; tmpfs 14.7G 12.0K 14.7G 0% /var/run/secrets/kubernetes.io/serviceaccount; tmpfs 14.7G 0 14.7G 0% /proc/acpi; tmpfs 64.0M 0 64.0M 0% /proc/kcore; tmpfs 64.0M 0 64.0M 0% /proc/keys; tmpfs 64.0M 0 64.0M 0% /proc/timer_list; tmpfs 14.7G 0 14.7G 0% /proc/scsi; tmpfs 14.7G 0 14.7G 0% /sys/firmware; ```. Which isn't much larger than it was before the scaling tests. It appears to slowly increase the amount of memory it needs:; ```; 1 0 nobody S 30.9g103.7 1 11.5 /bin/prometheus --config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/prometheus --web.console.libraries=/usr/share/prometheus/console_libraries --web.console.templates=/usr/share/prometheus/consoles --web.external; ```. caping out at 31.5 GB (the disk is 31.2 GB). Now, it is presumably trying to recover. It's been up for about 7 minutes. Still unavailable:; ```; /prometheus $ wget localhost:9090/monitoring/prometheus; Connecting to localhost:9090 (127.0.0.1:9090); wget: server returned error: HTTP/1.1 503 Service Unavailable; /prometheus $ ; ```. https://github.com/prometheus/prometheus/issues/5727#issuecomment-510818825; https://github.com/prometheus/prometheus/issues/4324#issuecomment-460243182. ```; # k logs -n monitoring prometheus-0 ; level=info ts=2019-07-31T15:45:51.990Z caller=main.go:286 msg=""no time or size retention was set so using the default time retention"" duration=15d; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:322 msg=""Starting Prometheus"" version=""(version=2.10.0, branch=HEAD, revision=d20e84d0fb64aff2f62a977adc8cfb656da4e286)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:323 build_context=""(go=go1.12.5, user=root@a49185acd9b0, date=20190525-12:28:13)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:324 host_details=""(L",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6773:1868,recover,recover,1868,https://hail.is,https://github.com/hail-is/hail/issues/6773,1,['recover'],['recover']
Availability," /usr/lib/spark/python/lib/py4j-src.zip/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /usr/local/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 223 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 224 'Hail version: %s\n'; --> 225 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 226 except pyspark.sql.utils.CapturedException as e:; 227 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NoSuchElementException: key not found: GRCh37. ```. ### Traces No. 1: . ```java ; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 16.0 failed 4 times, most recent failure: Lost task 15.3 in stage 16.0 (TID 178, ip-172-31-1-20.ec2.internal, executor 4): org.json4s.package$MappingException: unknown error; 	at org.json4s.Extraction$.extract(Extraction.scala:43); 	at org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21); 	at is.hail.io.index.IndexReader$.readMetadata(IndexReader.scala:65); 	at is.hail.io.index.IndexReader.<init>(IndexReader.scala:90); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:879); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:877); 	at scala.Option.map(Option.scala:146); 	at is.hail.HailContext$$anon$3.compute(HailContext.scala:877); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at or",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:5371,error,error,5371,https://hail.is,https://github.com/hail-is/hail/issues/7044,1,['error'],['error']
Availability," 0.2.128-ce3ca9c77507; Error summary: SocketTimeoutException: connect timed out; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/py4j_backend.py"", line 223, in _rpc; raise fatal_error_from_java_error_triplet(; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/table.py"", line 2002, in write; Env.backend().execute(; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/test.py"", line 6, in <module>; ht.write('gs://ehigham-hail-tmp/test_hail_in_notebook.ht'); hail.utils.java.FatalError: SocketTimeoutException: connect timed out. Java stack trace:; java.io.IOException: Error getting access token from metadata server at: http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:11649,Error,Error,11649,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699,1,['Error'],['Error']
Availability," 0.20.1.; notebook 6.5.6 has requirement pyzmq<25,>=17, but you have pyzmq 25.1.2.; aiohttp-devtools 1.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **444/1000** <br/> **Why?** Has a fix available, CVSS 4.6 | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14109:1619,avail,available,1619,https://hail.is,https://github.com/hail-is/hail/pull/14109,1,['avail'],['available']
Availability," 1.1/1.1 MB 68.3 MB/s eta 0:00:00; 897 | amazon-ebs: Collecting aiohttp_session<2.8,>=2.7; 898 | amazon-ebs: Downloading aiohttp_session-2.7.0-py3-none-any.whl (14 kB); 899 | amazon-ebs: Collecting asyncinit<0.3,>=0.2.4; 900 | amazon-ebs: Downloading asyncinit-0.2.4-py3-none-any.whl (2.8 kB); 901 | amazon-ebs: Collecting avro<1.12,>=1.10; 902 | amazon-ebs: Downloading avro-1.11.1.tar.gz (84 kB); 903 | amazon-ebs:  84.2/84.2 kB 22.0 MB/s eta 0:00:00; 904 | amazon-ebs: Installing build dependencies: started; 905 | amazon-ebs: Installing build dependencies: finished with status 'done'; 906 | amazon-ebs: Getting requirements to build wheel: started; 907 | amazon-ebs: Getting requirements to build wheel: finished with status 'done'; 908 | amazon-ebs: Preparing metadata (pyproject.toml): started; 909 | amazon-ebs: Preparing metadata (pyproject.toml): finished with status 'done'; 910 | amazon-ebs: Collecting azure-identity==1.6.0; 911 | amazon-ebs: Downloading azure_identity-1.6.0-py2.py3-none-any.whl (108 kB); 912 | amazon-ebs:  108.5/108.5 kB 28.5 MB/s eta 0:00:00; 913 | amazon-ebs: Collecting azure-storage-blob==12.11.0; 914 | amazon-ebs: Downloading azure_storage_blob-12.11.0-py3-none-any.whl (346 kB); 915 | amazon-ebs:  346.4/346.4 kB 41.0 MB/s eta 0:00:00; 916 | amazon-ebs: Collecting bokeh<2.0,>1.3; 917 | amazon-ebs: Downloading bokeh-1.4.0.tar.gz (32.4 MB); 918 | amazon-ebs:  32.4/32.4 MB 48.4 MB/s eta 0:00:00; 919 | amazon-ebs: Preparing metadata (setup.py): started; 920 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 921 | amazon-ebs: Requirement already satisfied: boto3<2.0,>=1.17 in /usr/local/lib/python3.7/site-packages (1.24.78); 922 | amazon-ebs: Requirement already satisfied: botocore<2.0,>=1.20 in /usr/local/lib/python3.7/site-packages (1.27.78); 923 | amazon-ebs: Collecting de",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:2891,Down,Downloading,2891,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability," 10)); Without this filter it runs OK. This file is a merged vcf file from Lumpy. Some sites may have no alternate alleles called (all 0/0 or ./.). ### What went wrong (all error messages here, including the full java stack trace):; [Stage 2:> (0 + 72) / 125]Traceback (most recent call last):; File ""/restricted/projectnb/casa/wgs.hg38/hail/lumpy/models.all.py"", line 80, in <module>; print(""Filtered Passed Rows:"",passed.count_rows()); File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 2072, in count_rows; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: NegativeArraySizeException: null. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 30 in stage 2.0 failed 4 times, most recent failure: Lost task 30.3 in stage 2.0 (TID 91, scc-q05.scc.bu.edu, executor 9): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.codegen.generated.C4.apply(Unknown Source); 	at is.hail.codegen.generated.C4.apply(Unknown Source); 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:649); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:246); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:219); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$czip$1$$anon$1.next(ContextRDD.scala:322); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:912); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:1434,failure,failure,1434,https://hail.is,https://github.com/hail-is/hail/issues/3901,1,['failure'],['failure']
Availability," 13 mt.s.show(); 14. /restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/matrixtable.py in count(self); 2129 Number of rows, number of cols.; 2130 """"""; -> 2131 r = self._jmt.count(); 2132 return r._1(), r._2(); 2133. /share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container marked as failed: container_e2435_1542127286896_0109_02_000004 on host: scc-q06.scc.bu.edu. Exit status: 1. Diagnostics: Exception from container-launch.; Container id: container_e2435_1542127286896_0109_02_000004; Exit code: 1; Stack trace: ExitCodeException exitCode=1:; at org.apache.hadoop.util.Shell.runCommand(Shell.java:576); at org.apache.hadoop.util.Shell.run(Shell.java:487); at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:753); at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:371); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:303); at org.apache.hadoop.yarn.server.nodemanager.containermanag",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-446057705:1630,failure,failure,1630,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-446057705,1,['failure'],['failure']
Availability," 19.15.1 requires aiohttp, which is not installed.; aiohttp-session 2.12.0 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5NGM3N2YwYy0xN2JkLTRkMzQtYmJhOS1iNzBiNmVhMDl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14039:1479,avail,available,1479,https://hail.is,https://github.com/hail-is/hail/pull/14039,1,['avail'],['available']
Availability," 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@25004c63{/api,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@36f9d98a{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@302922c9{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 SparkUI: INFO: Bound SparkUI to 0.0.0.0, and started at http://10.48.225.55:4040; 2019-01-22 13:11:23 DomainSocketFactory: WARN: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-22 13:11:23 Client: INFO: Requesting a new application from cluster with 21 NodeManagers; 2019-01-22 13:11:23 Client: INFO: Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-22 13:11:23 Client: INFO: Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-22 13:11:23 Client: INFO: Setting up container launch context for our AM; 2019-01-22 13:11:23 Client: INFO: Setting up the launch environment for our AM container; 2019-01-22 13:11:24 Client: INFO: Preparing resources for our AM container; 2019-0",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:13872,AVAIL,AVAILABLE,13872,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability, 3 * 10^16. ~~I can't find the referenced case analysis in Google's latest code. [It is present in this fork](https://github.com/leogamas/java-storage/blob/2af8dfd95cdebc9e4d8252b0bbe3f092844d9f2c/google-cloud-storage/src/main/java/com/google/cloud/storage/BlobWriteChannel.java#L68-L198) from a few years ago.~~. Here's the [referenced case analysis in 2.17.1](https://github.com/googleapis/java-storage/blame/v2.17.1/google-cloud-storage/src/main/java/com/google/cloud/storage/BlobWriteChannel.java). There seems to have been a rewrite [two months ago](https://github.com/googleapis/java-storage/blame/main/google-cloud-storage/src/main/java/com/google/cloud/storage/BlobWriteChannel.java) (here's [the main commit](https://github.com/googleapis/java-storage/commit/1b52a1053130620011515060787bada10c324c0b)). That landed in [2.25.0](https://github.com/googleapis/java-storage/releases/tag/v2.25.0) which was released in July. ```; is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-2LzGioRNy6RqIS2pfXIoSO&uploadType=resumable&upload_id=ADPycdvZ5HhnGfOKt5TE1qXWiHpqIpZnXVTYWuWUCXNPRF9HqyCB-4LvRsxNX6SUWRgk13pYrzYaa9-wXlvNZt1oct0ptaEz0bS3; chunkOffset: 16777216; chunkLength: 8388608; localOffset: 268435456; remoteOffset: 285212672; lastChunk: false. 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:267); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at co,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911:1311,recover,recover,1311,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911,1,['recover'],['recover']
Availability," 656) / 729]; raise err; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 98, in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); File ""/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py"", line 1304, in __call__; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 31, in deco; raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.project-.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.gbsc-project.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGS",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:1857,failure,failure,1857,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['failure'],['failure']
Availability," 90) / 30468]Traceback (most recent call last):; File ""/restricted/projectnb/casa/wgs.hg38/pipelines/bayestyper/merge/./vcf2mt_all.py"", line 10, in <module>; hl.import_vcf(vcf,force_bgz=True).write(mt); File ""<decorator-gen-1213>"", line 2, in write; File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/matrixtable.py"", line 2524, in write; Env.backend().execute(ir.MatrixWrite(self._mir, writer)); File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/backend/spark_backend.py"", line 296, in execute; result = json.loads(self._jhc.backend().executeJSON(jir)); File ""/share/pkg.7/spark/2.4.3/install/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/backend/spark_backend.py"", line 41, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: SocketException: Too many open files. Java stack trace:; java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:28); at is.hail.backend.spark.SparkBackend.is$hail$backend$spark$SparkBackend$$_execute(SparkBackend.scala:317); at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(SparkBackend.scala:304); at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293:2777,Error,Error,2777,https://hail.is,https://github.com/hail-is/hail/issues/9293,1,['Error'],['Error']
Availability," : INFO: RegionPool: REPORT_THRESHOLD: 257.0K allocated (129.0K blocks / 128.0K chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-22 19:11:12.486 : INFO: RegionPool: REPORT_THRESHOLD: 577.0K allocated (193.0K blocks / 384.0K chunks), regions.size = 4, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-22 19:11:12.486 GoogleStorageFS$: INFO: createNoCompression: gs://neale-bge/foo.ht/rows/parts/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79; 2023-09-22 19:11:12.625 GoogleStorageFS$: INFO: close: gs://neale-bge/foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index; 2023-09-22 19:11:12.656 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=656384, peakBytesReadable=641.00 KiB, chunks requested=4, cache hits=2; 2023-09-22 19:11:12.656 : INFO: RegionPool: FREE: 641.0K allocated (257.0K blocks / 384.0K chunks), regions.size = 5, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-22 19:11:12.656 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_382]; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_382]; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]; 	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(T",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:9221,ERROR,ERROR,9221,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['ERROR'],['ERROR']
Availability," </code></pre>; <p>The Apache Commons Codec package contains simple encoder and decoders for; various formats such as Base64 and Hexadecimal. In addition to these; widely used encoders and decoders, the codec package also maintains a; collection of phonetic encoding utilities.</p>; <p>Feature and fix release.</p>; <p>Changes in this version include:</p>; <p>New features:; o CODEC-290: Base16Codec and Base16Input/OutputStream. Thanks to Adam Retter.; o CODEC-291: Hex encode/decode with existing arrays. Thanks to Adam Retter.</p>; <p>Fixed Bugs:; o CODEC-264: MurmurHash3: Ensure hash128 maintains the sign extension bug.; Thanks to Andy Seaborne.</p>; <p>Changes:; o CODEC-280: Base32/Base64/BCodec: Added strict decoding property to control; handling of trailing bits. Default lenient mode discards them; without error. Strict mode raise an exception.; o CODEC-289: Base32/Base64 Input/OutputStream: Added strict decoding property; to control handling of trailing bits. Default lenient mode; discards them without error. Strict mode raise an exception.; o Update tests from JUnit 4.12 to 4.13. Thanks to Gary Gregory.; o Update actions/checkout from v1 to v2.3.2 <a href=""https://github-redirect.dependabot.com/apache/commons-codec/issues/50"">#50</a>, <a href=""https://github-redirect.dependabot.com/apache/commons-codec/issues/56"">#56</a>.; Thanks to Dependabot.; o Update actions/setup-java from v1.4.0 to v1.4.1 <a href=""https://github-redirect.dependabot.com/apache/commons-codec/issues/57"">#57</a>.; Thanks to Dependabot.</p>; <p>For complete information on Apache Commons Codec, including instructions on how; to submit bug reports, patches, or suggestions for improvement, see the; Apache Commons Codec website:</p>; <p><a href=""https://commons.apache.org/proper/commons-codec/"">https://commons.apache.org/proper/commons-codec/</a></p>; <p>Download page: <a href=""https://commons.apache.org/proper/commons-codec/download_codec.cgi"">https://commons.apache.org/proper/commons-codec/download",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12385:1385,error,error,1385,https://hail.is,https://github.com/hail-is/hail/pull/12385,1,['error'],['error']
Availability," <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1791"">jupyter/nbconvert#1791</a></li>; <li>Fix fonts overriden by user stylesheet by inheriting styles by <a href=""https://github.com/dakoop""><code>@dakoop</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1793"">jupyter/nbconvert#1793</a></li>; <li>Fix lab template output alignment by <a href=""https://github.com/dakoop""><code>@dakoop</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1795"">jupyter/nbconvert#1795</a></li>; <li>Add qtpdf and qtpng exporters by <a href=""https://github.com/davidbrochart""><code>@davidbrochart</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1611"">jupyter/nbconvert#1611</a></li>; <li>Fix linters by <a href=""https://github.com/martinRenou""><code>@martinRenou</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1825"">jupyter/nbconvert#1825</a></li>; <li>Remove downloaded CSS from repository by <a href=""https://github.com/martinRenou""><code>@martinRenou</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1827"">jupyter/nbconvert#1827</a></li>; <li>escape_html: prevent escaping quotes on widgets JSON reprs (<a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/issues/1829"">#1829</a>) by <a href=""https://github.com/martinRenou""><code>@martinRenou</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1830"">jupyter/nbconvert#1830</a></li>; <li>Remove tests from bdist by <a href=""https://github.com/TiagodePAlves""><code>@TiagodePAlves</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1822"">jupyter/nbconvert#1822</a></li>; <li>Encode SVG image data as UTF-8 before calling lxml cleaner (fixes <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/issues/1836"">#1836</a>) by <a href=""https://github.com/emarsden""><code>@e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12126:3073,down,downloaded,3073,https://hail.is,https://github.com/hail-is/hail/pull/12126,1,['down'],['downloaded']
Availability," <a href=""https://pandas.pydata.org/pandas-docs/version/1.4.1/whatsnew/v1.4.1.html"">full whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <h2>Pandas 1.4.0</h2>; <p>This release includes some new features, bug fixes, and performance improvements. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4.0/whatsnew/v1.4.0.html"">full whatsnew</a> for a list of all the changes. pandas 1.4.0 supports Python 3.8 and higher.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install -c conda-forge pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <h2>Pandas 1.4.0rc0</h2>; <p>We are pleased to announce a release candidate for pandas 1.4.0. If all goes well, we'll release pandas 1.4.0 in about two weeks.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4/whatsnew/v1.4.0.html"">whatsnew</a> for a list of all the changes. pandas 1.4.0 supports Python 3.8 and higher.</p>; <p>The release will be available on conda-forge and PyPI.</p>; <p>The release can be installed from PyPI</p>; <pre><code>python -m pip install --upgrade --pre pandas==1.4.0rc0; </code></pre>; <p>Or from conda-forge</p>; <pre><code>conda install -c conda-forge/label/pandas_rc pandas==1.4.0rc0; </code></pre>; <p>Please report any issues with the release candidate on the pandas issue tracker.</p>; <h2>Pandas 1.3.5</h2>; <!-- raw HTM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11539:1312,avail,available,1312,https://hail.is,https://github.com/hail-is/hail/pull/11539,1,['avail'],['available']
Availability," <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14211:2415,Error,Error,2415,https://hail.is,https://github.com/hail-is/hail/pull/14211,1,['Error'],['Error']
Availability," <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `40.5.0 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14365:2485,Error,Error,2485,https://hail.is,https://github.com/hail-is/hail/pull/14365,1,['Error'],['Error']
Availability," <li>; <p>Fixed calling putpalette() on L and LA images before load() <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7187"">#7187</a>; [radarhere]</p>; </li>; <li>; <p>Fixed saving TIFF multiframe images with LONG8 tag types <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7078"">#7078</a>; [radarhere]</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python-pillow/Pillow/commit/6e28ed1f36d0eb74053af54e1eddc9c29db698cd""><code>6e28ed1</code></a> 10.0.0 version bump</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/c827f3b30f50bf04fd65daeeba6bbfd56fc7b50e""><code>c827f3b</code></a> Merge pull request <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7246"">#7246</a> from radarhere/deallocate</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/39a3b1d83edcf826c3864e26bedff5b4e4dd331b""><code>39a3b1d</code></a> Fixed deallocating mask images</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/8c1dc819fd91471825da01976ac0e0bc8789590f""><code>8c1dc81</code></a> Update CHANGES.rst [ci skip]</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/e37b25087d39bd54495380a9898c8c7a2a4698d1""><code>e37b250</code></a> Merge pull request <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7244"">#7244</a> from radarhere/imagefont_max_string_length</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/d398fedb9d5af22316c715d2066176d15031d439""><code>d398fed</code></a> Added underscores for readability</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/1fe1bb49c452b0318cad12ea9d97c3bef188e9a7""><code>1fe1bb4</code></a> Added ImageFont.MAX_STRING_LENGTH</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/7c945f5131cf8596084b32af582f90a43b090540""><code>7c945f5</code></a> Merge pull request <a href=""https://redirect.gi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13321:13027,mask,mask,13027,https://hail.is,https://github.com/hail-is/hail/pull/13321,1,['mask'],['mask']
Availability," <li>; <p>Fixed handling for <code>AttributeError</code> when calculating length of files obtained; by <code>Tarfile.extractfile()</code>. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5239"">#5239</a>)</p>; </li>; <li>; <p>Fixed urllib3 exception leak, wrapping <code>urllib3.exceptions.InvalidHeader</code> with; <code>requests.exceptions.InvalidHeader</code>. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5914"">#5914</a>)</p>; </li>; <li>; <p>Fixed bug where two Host headers were sent for chunked requests. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5391"">#5391</a>)</p>; </li>; <li>; <p>Fixed regression in Requests 2.26.0 where <code>Proxy-Authorization</code> was; incorrectly stripped from all requests sent with <code>Session.send</code>. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5924"">#5924</a>)</p>; </li>; <li>; <p>Fixed performance regression in 2.26.0 for hosts with a large number of; proxies available in the environment. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5924"">#5924</a>)</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/requests/blob/main/HISTORY.md"">requests's changelog</a>.</em></p>; <blockquote>; <h2>2.27.1 (2022-01-05)</h2>; <p><strong>Bugfixes</strong></p>; <ul>; <li>Fixed parsing issue that resulted in the <code>auth</code> component being; dropped from proxy URLs. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/6028"">#6028</a>)</li>; </ul>; <h2>2.27.0 (2022-01-03)</h2>; <p><strong>Improvements</strong></p>; <ul>; <li>; <p>Officially added support for Python 3.10. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5928"">#5928</a>)</p>; </li>; <li>; <p>Added a <code>requests.exceptions.JSONDecodeError</code> to unify JSON exceptions between; Python 2 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11528:3198,avail,available,3198,https://hail.is,https://github.com/hail-is/hail/pull/11528,2,['avail'],['available']
Availability," <li>; <p>Fixed handling for <code>AttributeError</code> when calculating length of files obtained; by <code>Tarfile.extractfile()</code>. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5239"">#5239</a>)</p>; </li>; <li>; <p>Fixed urllib3 exception leak, wrapping <code>urllib3.exceptions.InvalidHeader</code> with; <code>requests.exceptions.InvalidHeader</code>. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5914"">#5914</a>)</p>; </li>; <li>; <p>Fixed bug where two Host headers were sent for chunked requests. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5391"">#5391</a>)</p>; </li>; <li>; <p>Fixed regression in Requests 2.26.0 where <code>Proxy-Authorization</code> was; incorrectly stripped from all requests sent with <code>Session.send</code>. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5924"">#5924</a>)</p>; </li>; <li>; <p>Fixed performance regression in 2.26.0 for hosts with a large number of; proxies available in the environment. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5924"">#5924</a>)</p>; </li>; <li>; <p>Fixed idna exception leak, wrapping <code>UnicodeError</code> with; <code>requests.exceptions.InvalidURL</code> for URLs with a leading dot (.) in the; domain. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5414"">#5414</a>)</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/psf/requests/commit/31a89d9c8463c3394ca00f408f4b86d814421a09""><code>31a89d9</code></a> v2.27.1</li>; <li><a href=""https://github.com/psf/requests/commit/8fa9724398c4f44090997ff430a1dd3e935a9057""><code>8fa9724</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/psf/requests/issues/6028"">#6028</a> from nateprewitt/prox_auth_fix</li>; <li><a href=""https://github.com/psf/requests/commit/38f3f8ecb93cadfac03a6b7b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11528:6309,avail,available,6309,https://hail.is,https://github.com/hail-is/hail/pull/11528,2,['avail'],['available']
Availability," <li>; <p>increases the weight of user specifiable priorities.; The weights of following priority plugins are increased</p>; <ul>; <li><code>TaintTolerations</code> to 3 - as leveraging node tainting to group nodes in the cluster is becoming a widely-adopted practice</li>; <li><code>NodeAffinity</code> to 2</li>; <li><code>InterPodAffinity</code> to 2</li>; </ul>; </li>; <li>; <p>Won't have <code>HealthzBindAddress</code>, <code>MetricsBindAddress</code> fields (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104251"">kubernetes/kubernetes#104251</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@ravisantoshgudimetla</code></a>)</p>; </li>; </ul>; </li>; <li>Introduce v1beta2 for Priority and Fairness with no changes in API spec. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104399"">kubernetes/kubernetes#104399</a>, <a href=""https://github.com/tkashem""><code>@tkashem</code></a>)</li>; <li>JSON log output is configurable and now supports writing info messages to stdout and error messages to stderr. Info messages can be buffered in memory. The default is to write both to stdout without buffering, as before. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104873"">kubernetes/kubernetes#104873</a>, <a href=""https://github.com/pohly""><code>@pohly</code></a>)</li>; <li>JobTrackingWithFinalizers graduates to beta. Feature is enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105687"">kubernetes/kubernetes#105687</a>, <a href=""https://github.com/alculquicondor""><code>@alculquicondor</code></a>)</li>; <li>Kube-apiserver: Fixes handling of CRD schemas containing literal null values in enums. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104969"">kubernetes/kubernetes#104969</a>, <a href=""https://github.com/liggitt""><code>@liggitt</code></a>)</li>; <li>Kube-apiserver: The <code>rbac.authorization.k8s.io/v1alp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:6967,error,error,6967,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['error'],['error']
Availability," <li><a href=""https://github.com/jupyter/jupyter_client/commit/51e071a973b232deaefd4cbf11f003f112c24f1a""><code>51e071a</code></a> Automated Changelog Entry for 7.3.4 on main</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/ca4cb2d6a4b95a6925de85a47b323d2235032c74""><code>ca4cb2d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/804"">#804</a> from blink1073/fix-docs-build</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/2c545599e1da419c096abffcd81f922fb709e239""><code>2c54559</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/803"">#803</a> from ccordoba12/fix-threaded-client</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/30ce7539778e2a25ff5e6eba4ccb6c08b8a0fe20""><code>30ce753</code></a> fix sphinx 5.0 support</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/a2e90574645052320de861bb84ba1752e25ef2dd""><code>a2e9057</code></a> ignore type error</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/3c6fc38e8dda754aba4a1217733eb1a0146b4c57""><code>3c6fc38</code></a> Run qtconsole test suite as a another downstream project</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/dcb45960b337fb089e04b0c3dde880e8f0f10ae5""><code>dcb4596</code></a> Revert changes related to _handle_recv in ThreadedZMQSocketChannel</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/01bfdd18c2eb8ea34cbb9915cb2bc7d9806f81a4""><code>01bfdd1</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/799"">#799</a> from jupyter/pre-commit-ci-update-config</li>; <li>Additional commits viewable in <a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.1...v7.3.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12110:9009,error,error,9009,https://hail.is,https://github.com/hail-is/hail/pull/12110,1,['error'],['error']
Availability," = ir.typ._from_encoding(result); 102 return (value, timings) if timed else value. File ~/mambaforge/lib/python3.9/site-packages/py4j/java_gateway.py:1304, in JavaMember.__call__(self, *args); 1298 command = proto.CALL_COMMAND_NAME +\; 1299 self.command_header +\; 1300 args_command +\; 1301 proto.END_COMMAND_PART; 1303 answer = self.gateway_client.send_command(command); -> 1304 return_value = get_return_value(; 1305 answer, self.gateway_client, self.target_id, self.name); 1307 for temp_arg in temp_args:; 1308 temp_arg._detach(). File ~/mambaforge/lib/python3.9/site-packages/hail/backend/py4j_backend.py:21, in handle_java_exception.<locals>.deco(*args, **kwargs); 19 import pyspark; 20 try:; ---> 21 return f(*args, **kwargs); 22 except py4j.protocol.Py4JJavaError as e:; 23 s = e.java_exception.toString(). File ~/mambaforge/lib/python3.9/site-packages/py4j/protocol.py:330, in get_return_value(answer, gateway_client, target_id, name); 326 raise Py4JJavaError(; 327 ""An error occurred while calling {0}{1}{2}.\n"".; 328 format(target_id, ""."", name), value); 329 else:; --> 330 raise Py4JError(; 331 ""An error occurred while calling {0}{1}{2}. Trace:\n{3}\n"".; 332 format(target_id, ""."", name, value)); 333 else:; 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; 336 format(target_id, ""."", name)). Py4JError: An error occurred while calling o83._1. Trace:; java.lang.NegativeArraySizeException: -1966455376; 	at py4j.Base64.encodeToChar(Base64.java:681); 	at py4j.Base64.encodeToString(Base64.java:734); 	at py4j.Protocol.encodeBytes(Protocol.java:154); 	at py4j.ReturnObject.getPrimitiveReturnObject(ReturnObject.java:150); 	at py4j.Gateway.getReturnObject(Gateway.java:188); 	at py4j.Gateway.invoke(Gateway.java:283); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.base/java.lang.Thread.run(Thread.java:829); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12035#issuecomment-1186014691:3191,error,error,3191,https://hail.is,https://github.com/hail-is/hail/issues/12035#issuecomment-1186014691,3,['error'],['error']
Availability," = sumstats[variants.locus]). # handle strand/allele flips; variants = variants.annotate_rows(beta = hl.case(); .when(((variants.alleles[0] == variants.ss.nt1) &; (variants.alleles[1] == variants.ss.nt2)) | ; ((flip_text(variants.alleles[0]) == variants.ss.nt1) & ; (flip_text(variants.alleles[1]) == variants.ss.nt2)),; (-1*variants.ss.ldpred_inf_beta)); .when(((variants.alleles[0] == variants.ss.nt2) &; (variants.alleles[1] == variants.ss.nt1)) | ; ((flip_text(variants.alleles[0]) == variants.ss.nt2) & ; (flip_text(variants.alleles[1]) == variants.ss.nt1)),; variants.ss.ldpred_inf_beta); .or_missing()). variants = variants.filter_rows(hl.is_defined(variants.beta)); variants.beta.show(); ```. ### What went wrong (all error messages here, including the full java stack trace): When I went to try to show the beta column, Scala ""crashed"" such that I had to type in ""localhost:4040"" to reconnect and go into my application history to see what happened. I didn't get any errors in the Notebook I was using--it just stopped doing any work. . In the Scala tasks console, all of my workers had the following error:; ```; java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TBinary$.allocate(TBinary.scala:101); 	at is.hail.annotations.RegionValueBuilder.fixupBinary(RegionValueBuilder.scala:263); 	at is.hail.annotations.RegionValueBuilder.fixupStruct(RegionValueBuilder.scala:319); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:288); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$31$$anonfun$apply$21.apply(Relational.scala:975); 	at is.hail.expr.MatrixMapRows$$anonfun$31$$anonfun$apply$21.apply(Relational.scala:964); 	at scala.collection.Iterator$$",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508:2802,error,errors,2802,https://hail.is,https://github.com/hail-is/hail/issues/3508,1,['error'],['errors']
Availability, Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:111; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all_from_cache /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:115; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:91; STACK Bio::EnsEMBL::VEP::BaseRunner::get_all_AnnotationSources /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/BaseRunner.pm:175; STACK Bio::EnsEMBL::VEP::Runner::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/Runner.pm:123; STACK Bio::EnsEMBL::VEP::Runner::run /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/Runner.pm:194; STACK toplevel /opt/vep/src/ensembl-vep/vep:225; Date (localtime) = Mon Apr 29 23:53:34 2024; Ensembl API version = 95; ---------------------------------------------------. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:19); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:19); 	at is.hail.utils.package$.fatal(package.scala:89); 	at is.hail.methods.VEP$.waitFor(VEP.scala:73); 	at is.hail.methods.VEP.$anonfun$execute$5(VEP.scala:244); 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.utils.richUtils.RichContextRDD$$anon$1.hasNext(RichContextRDD.scala:77); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at __C1310collect_distributed_array_table_native_writer.apply_region1_87(Unknown Source); 	at __C1310collect_distributed_array_table_native_writer.apply(Unknown Source); 	at __C1310collect_distributed_array_table_native_writer.apply(Unknown Source); 	at is.h,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:6073,Error,ErrorHandling,6073,https://hail.is,https://github.com/hail-is/hail/issues/14513,2,['Error'],['ErrorHandling']
Availability," Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File ~/projects/hail/hail/python/hail/table.py:2112, in Table.persist(self, storage_level); 2076 @typecheck_method(storage_level=storage_level); 2077 def persist(self, storage_level='MEMORY_AND_DISK') -> 'Table':; 2078 """"""Persist this table in memory or on disk.; 2079 ; 2080 Examples; (...); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self). File ~/projects/hail/hail/python/hail/backend/backend.py:208, in Backend.persist(self, dataset); 206 from hail.context import TemporaryFilename; 207 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 208 persisted = dataset.checkpoint(tempfile.__enter__()); 209 self._persisted_locations[persisted] = (tempfile, dataset); 210 return persisted. File <decorator-gen-1232>:2, in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). File ~/projects/hail/hail/python/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File ~/projects/hail/hail/python/hail/table.py:1331, in Table.checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1328 hl.current_backend().validate_file(output); 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert_type = self._type; 1333 _load_refs = False. File <decorator-gen-1234>:2, in write(self, output, overwrite, stage_locally, _codec_spec). File ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13788:2566,checkpoint,checkpoint,2566,https://hail.is,https://github.com/hail-is/hail/issues/13788,1,['checkpoint'],['checkpoint']
Availability," Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Use of a Broken or Risky Cryptographic Algorithm <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6149518](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6149518) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **451/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.3 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgrad",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14236:1246,avail,available,1246,https://hail.is,https://github.com/hail-is/hail/pull/14236,1,['avail'],['available']
Availability," Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **444/1000** <br/> **Why?** Has a fix available, CVSS 4.6 | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **429/1000** <br/> **Why?** Has a fix available, CVSS 4.3 | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **501/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.3 | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""mediu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14109:3151,Error,Error,3151,https://hail.is,https://github.com/hail-is/hail/pull/14109,1,['Error'],['Error']
Availability," Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3YjUwZjkzNy0zZjY4LTRkZjItYjliMC0zZjRiYzUyNmIwNWIiLCJldmVudCI6IlBSIHZpZXd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14244:1833,avail,available,1833,https://hail.is,https://github.com/hail-is/hail/pull/14244,1,['avail'],['available']
Availability," Feb 5 entropy minimized: asynchttp + uvloop; - [ ] Stretch ?: route by pod ip instead of svc name: DNS propagation latency significantly longer than pod instantiation time, which sucks for users, both because notebook instances will look broken when they're not, and because if we mask that the apparent latency to first useful operation is multiples of that needed. new: ; Cotton is right, mysql is adding too much complexity for the minimal use case, esp. with gevent conflicting with PyMySQL, necessitating per route handler connection. old:; Not ready to be merged, would like to improve SQL connection handling. 6a4599df5dfe0affdb5e367dd9cdc70cca59fd17 onward dependent on this. MySQL use is unoptimized because PyMySQL doesn't play well with gevent in the following way: initial impression from reading was that monkey.patch_all() before creation of global connection should result in connection spawned for each new request, or to at least private to a greenlet. Doesn't appear to be the case, plenty of connection errors. So establishing connection within each request, which is slow. . Python C library also out, because it does not play well with Python threading/greenlet/monkey patch implementations. MySQL Connector is an option, provides thread pools, but is also slowest option, by up to 10x, for small requests, like our are likely to be. However, that will be next implementation, for velocity/documentation reasons. . A better, third, more unwieldy solution is to use the C library (MySQLDb) establish a connection pool, N threads, and use deqeue. No implementation for waiting state, but will be the same; effectively, browser will connect to notebook socket server, notebook will issue periodic updates. Same thing, just . Need help/ok to update gateway to test this in production environment. Preferably, as I mentioned to Dan, we would have a staging gateway, which *.dev.hail.is points to, and which is used for more than automated / ci testing, allowing for human interaction",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215:1670,error,errors,1670,https://hail.is,https://github.com/hail-is/hail/pull/5215,1,['error'],['errors']
Availability," File ""<decorator-gen-1213>"", line 2, in write; File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/matrixtable.py"", line 2524, in write; Env.backend().execute(ir.MatrixWrite(self._mir, writer)); File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/backend/spark_backend.py"", line 296, in execute; result = json.loads(self._jhc.backend().executeJSON(jir)); File ""/share/pkg.7/spark/2.4.3/install/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/backend/spark_backend.py"", line 41, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: SocketException: Too many open files. Java stack trace:; java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:28); at is.hail.backend.spark.SparkBackend.is$hail$backend$spark$SparkBackend$$_execute(SparkBackend.scala:317); at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(SparkBackend.scala:304); at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(SparkBackend.scala:303); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:20); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:18); at is.hai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293:2966,error,error,2966,https://hail.is,https://github.com/hail-is/hail/issues/9293,1,['error'],['error']
Availability," File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 239, in execute; await self._query(query); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 457, in _query; await conn.query(q); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 428, in query; await self._read_query_result(unbuffered=unbuffered); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 622, in _read_query_result; await result.read(); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 1105, in read; first_packet = await self.connection._read_packet(); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 593, in _read_packet; packet.check_error(); File \""/usr/local/lib/python3.6/dist-packages/pymysql/protocol.py\"", line 220, in check_error; err.raise_mysql_exception(self._data); File \""/usr/local/lib/python3.6/dist-packages/pymysql/err.py\"", line 109, in raise_mysql_exception; raise errorclass(errno, errval); pymysql.err.IntegrityError: (1062, \""Duplicate entry '27-122310' for key 'PRIMARY'\""). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py\"", line 418, in start; resp = await task; File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py\"", line 458, in _handle; resp = await handler(request); File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_middlewares.py\"", line 119, in impl; return await handler(request); File \""/usr/local/lib/python3.6/dist-packages/aiohttp_session/__init__.py\"", line 152, in factory; response = await handler(request); File \""/usr/local/lib/python3.6/dist-packages/prometheus_async/aio/_decorators.py\"", line 42, in time_decorator; rv = await wrapped(*args, **kw); File \""/usr/local/lib/python3.6/dist-packages/gear/auth.py\"", line 57, in wrapped; return await fun(request, userdata, *args, **kwargs);",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8307:1865,error,errorclass,1865,https://hail.is,https://github.com/hail-is/hail/pull/8307,1,['error'],['errorclass']
Availability," INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-40-d6d936b012db>"", line 3, in <module>; covariates=[1.0]); File ""<decorator-gen-1697>"", line 2, in linear_regression_rows; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py"", line 370, in linear_regression_rows; return ht_result.persist(); File ""<decorator-gen-1111>"", line 2, in persist; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:1883,error,error,1883,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['error'],['error']
Availability," In the following code snippet we use ssl_client_session which should probably be; > called in_cluster_ssl_client_session. It's supposed to be used to communicate; > with other services in the cluster. That needs to be changed back to; > aiohttp.ClientSession which loads the normal system certificates (including the; > VeriSign root certs that signed the public certs that gateway uses, different; > from the internal certs that our services use).; >; > In particular, note that the error says ""unable to get local issuer; > certificate."" That means that the local trust store lacks a certificate that; > trusts the remote server's certificate. In Dania's case, the default python on; > OS X lacks all certificates, so every remote server is untrusted. In notebook's; > case, ssl_client_session creates an SSL/TLS session that only trusts Hail; > internal services (in particular, it does not trust the certificates that; > gateway uses for incoming public traffic). The error also says that the server; > in question is workshop.hail.is which is a public domain (note the hail.is), so; > that traffic is going through the public gateway with its public certificates.; >; > ```; > # don't have dev credentials to connect through internal.hail.is; > ready_url = deploy_config.external_url(; > service,; > f'/instance/{notebook[""notebook_token""]}/?token={notebook[""jupyter_token""]}'); > try:; > async with ssl_client_session(; > timeout=aiohttp.ClientTimeout(total=1),; > headers=headers,; > cookies=cookies) as session:; > async with session.get(ready_url) as resp:; > ```. I also changed the names and functionality of the functions in tls. Now; `in_cluster_ssl_context` will error if there is no ssl configuration found; instead of silently (and confusingly) using an SSLContext suited for public; communication (and wrong for in-cluster communication). I added `get_context_specific_client_ssl_context` which should only be used in; publicly consumable tools (*never* in a service). This function",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9120:1087,error,error,1087,https://hail.is,https://github.com/hail-is/hail/pull/9120,1,['error'],['error']
Availability," Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-WHEEL-3180413](https://snyk.io/vuln/SNYK-PYTHON-WHEEL-3180413) | `wheel:` <br> `0.30.0 -> 0.38.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2NTQzMzZlYi02MmRmLTQ0ODAtOTFkOS0xZDg4N2FmNmQwMTUiLCJl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:10210,avail,available,10210,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['avail'],['available']
Availability," Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-WHEEL-3180413](https://snyk.io/vuln/SNYK-PYTHON-WHEEL-3180413) | `wheel:` <br> `0.30.0 -> 0.38.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3YmFjNzAzOC00ZmQzLTQ3YmItOGUwMy0yNjRmYTUxNDRlNGQiLCJl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14108:9194,avail,available,9194,https://hail.is,https://github.com/hail-is/hail/pull/14108,1,['avail'],['available']
Availability," RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getting this committed, I have not made changes relating to logging and; error messages. The DLL's are still in the jar, and I think it has to stay that way because; all nodes need to see libhail.so. The header files are also in the jar, and have to be; unpacked in a convoluted way, and that could probably be simplified if/when we change; the approach to packaging. Once this goes in, I can follow it with a PR which adds the NativePackDecoder in RowStore.scala,; controlled by whether environment variable ""HAIL_ENABLE_CPP_CODEGEN"" is defined; (so defaulting to using the JVM bytecode CompiledPackDecoder).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:2069,error,error,2069,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863,1,['error'],['error']
Availability," TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-09-22 19:11:13.126 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-22 19:11:13.127 : INFO: RegionPool: initialized for thread 10: pool-2-thread-2; 2023-09-22 19:11:13.127 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-09-22 19:11:13.127 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-22 19:11:13.127 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-22 19:11:13.138 : ERROR: GoogleJsonResponseException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/1-day/o/parallelizeAndComputeWithIndex%2FO3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=%2Fresult.0?alt=media; No such object: 1-day/parallelizeAndComputeWithIndex/O3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=/result.0; From is.hail.relocated.com.google.cloud.storage.StorageException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/1-day/o/parallelizeAndComputeWithIndex%2FO3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=%2Fresult.0?alt=media; No such object: 1-day/parallelizeAndComputeWithIndex/O3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=/result.0; 	at is.hail.relocated.com.google.cloud.storage.StorageException.translate(StorageException.java:165); 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:298); 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.load(HttpStorageRpc.java:729); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.lambda$readAllBytes$20(StorageImpl.java:610); 	at com.google.api.gax.retrying.DirectRetryingExecuto",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:4033,down,download,4033,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['down'],['download']
Availability," The error I get when I run the code you provide is; ```; ""Key type mismatch: cannot index table with given expressions:; Table key: <<<empty key>>>; Index Expressions: locus<GRCh38>, array<str>, set<str>, array<array<struct{GQ: int32, AB: float64, DP: int32, GT: call, sampleId: str, sampleType: str, individualGuid: str, familyGuid: str, affected_id: int32}>>, array<array<struct{GQ: int32, AB: float64, DP: int32, GT: call, sampleId: str, sampleType: str, individualGuid: str, familyGuid: str, affected_id: int32}>>, struct{z_score: float32}, struct{region_type_ids: array<int32>}, locus<GRCh37>, str, array<struct{amino_acids: str, canonical: int32, codons: str, gene_id: str, hgvsc: str, hgvsp: str, transcript_id: str, biotype_id: int32, consequence_term_ids: array<int32>, is_lof_nagnag: bool, lof_filter_ids: array<int32>, transcript_rank: int32}>, str, int64, struct{PHRED: float32}, struct{alleleId: int32, conflictingPathogenicities: array<struct{pathogenicity_id: int32, count: int32}>, goldStars: int32, pathogenicity_id: int32, assertion_ids: array<int32>}, struct{REVEL_score: float32, VEST4_score: float32, MutPred_score: float32, SIFT_pred_id: int32, Polyphen2_HVAR_pred_id: int32, MutationTaster_pred_id: int32, fathmm_MKL_coding_pred_id: int32}, struct{Eigen_phred: float32}, struct{AF_POPMAX: float3",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13882#issuecomment-1830257465:687,error,error,687,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1830257465,1,['error'],['error']
Availability," WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 2022-10-06 15:56:03 WARN NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 3.1.3; SparkUI available at http://192.168.248.80:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.100-2ea2615a797a; LOGGING: writing to /; --------------------------------------------------------------------------; mt.filter_rows(mt.locus.position==2867101).count_rows(); ```; ### Expected ; Return a count of rows with that condition. ### Error ; ```; FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:208); at is.hail.expr.ir.LoweredTableReader$.makeCoercer(TableIR.scala:135); at is.hail.expr.ir.GenericTableValue.getLTVCoercer(GenericTableValue.scala:137); at is.hail.expr.ir.GenericTableValue.toTableStage(GenericTableValue.scala:162); at is.hail.io.vcf.MatrixVCFReader.lower(LoadVCF.scala:1798); at is.hail.expr.ir.lowering.LowerTableIR$.applyTable(LowerTableIR.scala:717); at is.hail.expr.ir.lowering.LowerTableIR$.lower$2(LowerTableIR.scala:697); at is.hail.expr.ir.lowering.LowerTableIR$.applyTable(LowerTableIR.scala:903); at is.hail.expr.ir.lowering.LowerTableIR$.lower$1(LowerTableIR.scala:467); at is.hail.expr.ir.lowering.LowerTableIR$.apply(LowerTableIR.scala:472); at is.hail.expr.ir.lowering.LowerToCDA$.lower(LowerToCDA.scala:73); at is.hail.expr.ir.lowering.LowerToCDA$.apply(LowerToCDA.scala:18); at is.hail.expr.ir.lowering.LowerToDistributedArrayPas",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12280:1968,Error,Error,1968,https://hail.is,https://github.com/hail-is/hail/issues/12280,1,['Error'],['Error']
Availability," Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.1-0320a61; Error summary: HailException: arguments refer to no files; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:2425,Error,ErrorHandling,2425,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583,2,['Error'],"['Error', 'ErrorHandling']"
Availability," [NaN, Infinity, -Infinity]}; line: 1, column: 17]; 	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1581); 	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:533); 	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._handleOddValue(ReaderBasedJsonParser.java:1602); 	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.nextToken(ReaderBasedJsonParser.java:689); 	at org.json4s.jackson.JValueDeserializer.deserialize(JValueDeserializer.scala:26); 	at org.json4s.jackson.JValueDeserializer.deserialize(JValueDeserializer.scala:42); 	at org.json4s.jackson.JValueDeserializer.deserialize(JValueDeserializer.scala:35); 	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3736); 	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2726); 	at org.json4s.jackson.JsonMethods$class.parse(JsonMethods.scala:20); 	at org.json4s.jackson.JsonMethods$.parse(JsonMethods.scala:50); 	at is.hail.table.Table.annotateGlobalJSON(Table.scala:476); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: devel-2d80e80610df; Error summary: JsonParseException: Non-standard token 'NaN': enable JsonParser.Feature.ALLOW_NON_NUMERIC_NUMBERS to allow; at [Source: {""__uid_3"": [NaN, Infinity, -Infinity]}; line: 1, column: 17]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3785:7147,Error,Error,7147,https://hail.is,https://github.com/hail-is/hail/issues/3785,1,['Error'],['Error']
Availability," \; 884 | amazon-ebs: --exclude 'test/' \; 885 | amazon-ebs: --exclude '*.log' \; 886 | amazon-ebs: python/ build/deploy/; 887 | amazon-ebs: # Clear the bdist build cache before building the wheel; 888 | amazon-ebs: cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; 889 | ==> amazon-ebs: /usr/local/lib/python3.7/site-packages/setuptools/installer.py:30: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.; 890 | ==> amazon-ebs: SetuptoolsDeprecationWarning,; 891 | ==> amazon-ebs: /usr/local/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.; 892 | ==> amazon-ebs: setuptools.SetuptoolsDeprecationWarning,; 893 | amazon-ebs: sed '/^pyspark/d' python/requirements.txt \| grep -v '^#' \| xargs python3 -m pip install -U; 894 | amazon-ebs: Collecting aiohttp==3.8.1; 895 | amazon-ebs: Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB); 896 | amazon-ebs:  1.1/1.1 MB 68.3 MB/s eta 0:00:00; 897 | amazon-ebs: Collecting aiohttp_session<2.8,>=2.7; 898 | amazon-ebs: Downloading aiohttp_session-2.7.0-py3-none-any.whl (14 kB); 899 | amazon-ebs: Collecting asyncinit<0.3,>=0.2.4; 900 | amazon-ebs: Downloading asyncinit-0.2.4-py3-none-any.whl (2.8 kB); 901 | amazon-ebs: Collecting avro<1.12,>=1.10; 902 | amazon-ebs: Downloading avro-1.11.1.tar.gz (84 kB); 903 | amazon-ebs:  84.2/84.2 kB 22.0 MB/s eta 0:00:00; 904 | amazon-ebs: Installing build dependencies: started; 905 | amazon-ebs: Installing build dependencies: finished with status 'done'; 906 | amazon-ebs: Getting requirements to build wheel: started; 907 | amazon-ebs: Getting requirements to build wheel: finished with status 'done'; 908 | amazon-ebs: Preparing meta",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:1704,Down,Downloading,1704,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability," ```; root@test-batch:/# curl -H ""Authorization: Bearer $(cat test-jwt/jwt)"" batch.pr-6604-default-ov5tgx24rrou/api/v1alpha/batches/9; {""id"": 9, ""state"": ""running"", ""complete"": false, ""closed"": 1, ""jobs"": [{""batch_id"": 9, ""job_id"": 1, ""state"": ""Running""}; ```. The batch is somehow in the state ""running"" and the only job is also in the; state ""Running"". Only two lines of code transition to the state 'Running'. They; both appear in the suffix of `Job._create_pod`:. ```python; pod, err = await app['k8s'].create_pod(body=pod_template); if err is not None:; if err.status == 409:; log.info(f'pod already exists for job {self.full_id}'); n_updated = await db.jobs.update_record(*self.id, compare_items={'state': self._state}, state='Running'); if n_updated == 0:; log.warning(f'changing the state for job {self.full_id} failed due to the expected state {self._state} not in db'); return; traceback.print_tb(err.__traceback__); log.info(f'pod creation failed for job {self.full_id} '; f'with the following error: {err}'); return. n_updated = await db.jobs.update_record(*self.id, compare_items={'state': self._state}, state='Running'); if n_updated == 0:; log.warning(f'changing the state for job {self.full_id} failed due to the expected state {self._state} not in db'); ```. For either of these database updates to succeed, the thread of control must have; thought the `_state` was `Cancelled` or we moved through some intermediate; state. We continue under the assumption that we went directly to `Running`. Who calls `_create_pod`?. - `start_pod`, but it checks that the state is in `Ready`; - `mark_complete`, but that's only if there's a ""next task"", this job has only; one task. That leaves `create_if_ready` and `mark_unscheduled`. `create_if_ready` is only; called by methods that are triggered when a parent with children finishes. We; have no parent-child relationships here. By process of elimination, `mark_unscheduled` must be the culprit. But how?; `mark_unscheduled` is called when a p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6617:18023,error,error,18023,https://hail.is,https://github.com/hail-is/hail/issues/6617,1,['error'],['error']
Availability," all been implemented and are available for experimentation.</p>; <p>Given not all public api surface of <code>google-cloud-storage</code> classes are supported for gRPC a new annotation <code>@TransportCompatibility</code> has been added to various classes, methods and fields/enum values to signal where that thing can be expected to work. As we implement more of the operations these annotations will be updated.</p>; <p>All new gRPC related APIs are annotated with <code>@BetaApi</code> to denote they are in preview and the possibility of breaking change is present. At this time, opting to use any of the gRPC transport mode means you are okay with the possibility of a breaking change happening. When the APIs are out of preview, we will remove the <code>@BetaApi</code> annotation to signal they are now considered stable and will not break outside a major version.</p>; <p><strong><em>NOTICE</em></strong>: Using the gRPC transport is exclusive. Any operations which have not yet been implemented for gRPC will result in a runtime error. For those operations which are not yet implemented, please continue to use the existing HTTP transport.</p>; <p>Special thanks (in alphabetical order) to <a href=""https://github.com/BenWhitehead""><code>@BenWhitehead</code></a>, <a href=""https://github.com/frankyn""><code>@frankyn</code></a>, <a href=""https://github.com/jesselovelace""><code>@jesselovelace</code></a> and <a href=""https://github.com/sydney-munro""><code>@sydney-munro</code></a> for their hard work on this effort.</p>; <h4>Notable Improvements</h4>; <ol>; <li>; <p>For all gRPC media related operations (upload/download) we are now more resource courteous then the corresponding HTTP counterpart. Buffers are fixed to their specified size (can't arbitrarily grow without bounds), are allocated lazily and only if necessary.</p>; <ol>; <li>Investigation into the possibility of backporting these improvements to the HTTP counterparts is ongoing</li>; </ol>; </li>; <li>; <p>Preview su",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12456:3255,error,error,3255,https://hail.is,https://github.com/hail-is/hail/pull/12456,4,['error'],['error']
Availability," an array of const class simdpp::arch_avx2::uint8<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:26,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:102:7: note: class simdpp::arch_avx2::uint64<2> declared here; class uint64<2, void> : public any_int64<2, uint64<2,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int16<8>; T = simdpp::arch_avx2::uint8<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int16<8>; T = simdpp::arch_avx2::uint8<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int16<8>; T = simdpp::arch_avx2::uint8<16>]; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:62:35: required from simdpp::arch_avx2::int16<8>& simdpp::arch_avx2::int16<8>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint8<16>]; libsimdpp-2.0-rc2/simdpp/detail/insn/shuffle_bytes16.h:45:11: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int16<8> with private member simdpp::arch_avx2::int16<8>::d_ from an array of const class simdpp::arch_avx2::uint8<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file in",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:15592,Mask,MaskCastOverride,15592,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.5</h2>; <p>Maintenance:</p>; <ul>; <li>Publish signed artifacts to Gradle plugin portal</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.4</h2>; <p>Bug fixes:</p>; <ul>; <li>Fix deadlock in <code>DownloadExtension</code> if <code>max-workers</code> equals 1 (thanks to <a href=""https://github.com/beatbrot""><code>@beatbrot</code></a> for spotting this, see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/205"">#205</a>)</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1b5d69760d19cb7f88cbc837ee46456c494c0696""><code>1b5d697</code></a> Bump up version number to 5.2.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/7d6de83037ca41cd2f2f31830b43e43720e45b3a""><code>7d6de83</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1da8f078e22412475b694ce07b890148b8a5e4fc""><code>1da8f07</code></a> Add comment</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/9703f764df56c52626f7d6f44bca8b1d51312389""><code>9703f76</code></a> Use pooling connection manager instead of basic one</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/306172e4c6532e185c8a6a9998bca7d22d2d0c63""><code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:2758,down,download-task,2758,https://hail.is,https://github.com/hail-is/hail/pull/12332,2,"['Mainten', 'down']","['Maintenance', 'download-task']"
Availability," and service-worker caching. In this project we will likely use all three. Server caching is an excellent strategy for pages that serve only public data. In this strategy we pre-generate the static html, serve that, and invalidate the cache once in a while. An example of this can be found in https://github.com/hail-is/hail/pull/5162/commits/e131a931c58a204104d45d0010341423b1ab9500; * Care needs to be taken with the server-side option, not to leak authentication state, since this will, at least by default, be shared across all users. . # Styleguide; 1. Typescript everywhere. # Performance; 1. [React SSR vs Nunjucks](https://malloc.fi/performance-cost-of-server-side-rendered-react-node-js) ; * [React SSR performance (well, React DOM in general) is a focus for 2019](https://github.com/facebook/react/issues/13525); ![v2-chart-1](https://user-images.githubusercontent.com/5543229/51345305-9af24380-1a68-11e9-8f5c-024ca96e42c1.png); 2. React vs VanillaJS. Depends on what you measure, it's either 50% slower or many times faster.; * https://github.com/krausest/js-framework-benchmark; * React authors claim this is an unrealistic environment, and that their scheduler is tuned to provide smooth/non-hitching UI interactions, at some cost to the speed with which 100,000 elements can be appended to a page. ; * Some consider this to be more reliable: https://localvoid.github.io/uibench/; * Here React performs many times better than vanilla JS for some operations.; * I should probably figure out exactly why. In practice, React in 2019 will likely be the best performing UI solution available, with of course the exception of some very well optimized JS. This is because of React Fiber's time slice mode, which will effectively allow UI operations, like user input, [to preempt other operations](https://reactjs.org/blog/2018/03/01/sneak-peek-beyond-react-16.html). ### How React works; React Fiber, the new reconciling/scheduling algorithm: https://github.com/acdlite/react-fiber-architecture",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:15607,reliab,reliable,15607,https://hail.is,https://github.com/hail-is/hail/pull/5162,2,"['avail', 'reliab']","['available', 'reliable']"
Availability," args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 561 return __original_func(*args_, **kwargs_); 562 ; 563 return wrapper. /home/hail/hail.zip/hail/table.py in aggregate(self, expr, _localize); 1138 ; 1139 if _localize:; -> 1140 return Env.backend().execute(agg_ir); 1141 else:; 1142 return construct_expr(agg_ir, expr.dtype). /home/hail/hail.zip/hail/backend/backend.py in execute(self, ir); 91 return ir.typ._from_json(; 92 Env.hail().backend.spark.SparkBackend.executeJSON(; ---> 93 self._to_java_ir(ir))); 94 ; 95 def value_type(self, ir):. /usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 226 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 227 'Hail version: %s\n'; --> 228 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 229 except pyspark.sql.utils.CapturedException as e:; 230 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: HailException: found out of bounds index -1; Resulted from trying to merge -0.0; Indices are [0.0, 2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0, 18.0, 20.0, 22.0, 24.0, 26.0, 28.0, 30.0, 32.0, 34.0, 36.0, 38.0, 40.0, 42.0, 44.0, 46.0, 48.0, 50.0, 52.0, 54.0, 56.0, 58.0, 60.0, 62.0, 64.0, 66.0, 68.0, 70.0, 72.0, 74.0, 76.0, 78.0, 80.0, 82.0, 84.0, 86.0, 88.0, 90.0, 92.0, 94.0, 96.0, 98.0, 100.0, 102.0, 104.0, 106.0, 108.0, 110.0, 112.0, 114.0, 116.0, 118.0, 120.0, 122.0, 124.0, 126.0, 128.0, 130.0, 132.0, 134.0, 136.0, 138.0, 140.0, 142.0, 144.0, 146.0, 148.0, 150.0, 152.0, 154.0, 156.0, 158.0, 160.0, 162.0, 164.0, 166.0, 168.0, 170.0, 172.0, 174.0, 176.0, 178.0, 180.0, 182.0, 184.0, 186.0, 188.0, 190.0, 192.0, 194.0, 196.0, 198.0, 200.0]; Binary search index",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:1755,Error,Error,1755,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['Error'],['Error']
Availability," array of const class simdpp::arch_avx2::uint16<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:27,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:91:7: note: class simdpp::arch_avx2::uint64<4> declared here; class uint64<4, void> : public any_int64<4, uint64<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::uint64<2>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::uint64<2>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::uint64<2>]; libsimdpp-2.0-rc2/simdpp/types/float64x2.h:58:37: required from simdpp::arch_avx2::float64<2>& simdpp::arch_avx2::float64<2>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint64<2>]; libsimdpp-2.0-rc2/simdpp/detail/insn/shuffle2x2.h:342:31: required from simdpp::arch_avx2::uint64<2> simdpp::arch_avx2::detail::insn::i_shuffle2x2(const simdpp::arch_avx2::uint64<2>&, const simdpp::arch_avx2::uint64<2>&) [with unsigned int s0 = 1; unsigned int s1 = 2]; libsimdpp-2.0-rc2/simdpp/core/shuffle1.h:58:47: required from typename simdpp::arch_avx2::detail::get_expr2_nomask<V1, V2>::empty simdpp::arch_avx2::shuffle1(const simdpp::arch_avx2::any_vec64<N, V1>&, const simdpp::arc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:144657,Mask,MaskCastOverride,144657,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," array of const class simdpp::arch_avx2::uint16<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:104:7: note: class simdpp::arch_avx2::uint32<4> declared here; class uint32<4, void> : public any_int32<4, uint32<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint16<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint16<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint16<16>]; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:114:36: required from simdpp::arch_avx2::uint32<8>& simdpp::arch_avx2::uint32<8>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:136:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<8> with private member simdpp::arch_avx2::uint32<8>::d_ from an array of const class simdpp::arch_avx2::uint16<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:37556,Mask,MaskCastOverride,37556,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," array of const class simdpp::arch_avx2::uint16<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:26,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:102:7: note: class simdpp::arch_avx2::uint64<2> declared here; class uint64<2, void> : public any_int64<2, uint64<2,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint16<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint16<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint16<16>]; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:114:36: required from simdpp::arch_avx2::uint64<4>& simdpp::arch_avx2::uint64<4>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/mem_unpack.h:471:8: required from void simdpp::arch_avx2::detail::insn::v_mem_unpack4_impl16_128(T&, T&, T&, T&) [with T = simdpp::arch_avx2::uint16<16>]; libsimdpp-2.0-rc2/simdpp/detail/insn/mem_unpack.h:585:29: required from void simdpp::arch_avx2::detail::insn::mem_unpack4(simdpp::arch_avx2::uint16<N>&, simdpp::arch_avx2::uint16<N>&, simdpp::arch_avx2::uint16<N>&, simdpp::arch_avx2::uint16<N>&) [with unsigned int N =",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:142142,Mask,MaskCastOverride,142142,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," array of const class simdpp::arch_avx2::uint32<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:21,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:104:7: note: class simdpp::arch_avx2::uint16<8> declared here; class uint16<8, void> : public any_int16<8, uint16<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint32<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint32<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint32<8>]; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:115:37: required from simdpp::arch_avx2::uint16<16>& simdpp::arch_avx2::uint16<16>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint32<8, simdpp::arch_avx2::expr_bit_and<simdpp::arch_avx2::uint32<8, simdpp::arch_avx2::uint16<16> >, simdpp::arch_avx2::uint32<8, simdpp::arch_avx2::uint32<8> > > >]; libsimdpp-2.0-rc2/simdpp/detail/insn/unzip_lo.h:107:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint16<16> with private member simdpp::arch_avx2::uint16<16>::d_ from an array of const class simdpp::",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:33745,Mask,MaskCastOverride,33745,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," array of const class simdpp::arch_avx2::uint64<2>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:21,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:104:7: note: class simdpp::arch_avx2::uint16<8> declared here; class uint16<8, void> : public any_int16<8, uint16<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint64<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint64<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint64<4>]; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:115:37: required from simdpp::arch_avx2::uint16<16>& simdpp::arch_avx2::uint16<16>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint64<4, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:488:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint16<16> with private member simdpp::arch_avx2::uint16<16>::d_ from an array of const class simdpp::arch_avx2::uint64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:54135,Mask,MaskCastOverride,54135,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," array of const class simdpp::arch_avx2::uint64<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:37,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32.h:86:7: note: class simdpp::arch_avx2::uint32<16> declared here; class uint32<N, void> : public any_int32<N, uint32<N,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4>]; libsimdpp-2.0-rc2/simdpp/types/float64x2.h:58:37: required from simdpp::arch_avx2::float64<2>& simdpp::arch_avx2::float64<2>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:590:8: required from void simdpp::arch_avx2::detail::insn::v_sse_transpose32x4(V&, V&, V&, V&) [with V = simdpp::arch_avx2::float32<4>; D = simdpp::arch_avx2::float64<2>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:549:63: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::float64<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:100020,Mask,MaskCastOverride,100020,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," array of const class simdpp::arch_avx2::uint8<32>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:22,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:33:7: note: class simdpp::arch_avx2::int16<16> declared here; class int16<16, void> : public any_int16<16, int16<16,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int16<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int16<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int16<16>]; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int16<16>]; libsimdpp-2.0-rc2/simdpp/detail/insn/shuffle_bytes16.h:91:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<32> with private member simdpp::arch_avx2::uint8<32>::d_ from an array of const class simdpp::arch_avx2::int16<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:20972,Mask,MaskCastOverride,20972,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," at org.apache.spark.rdd.RDD.treeReduce(RDD.scala:1037); at is.hail.methods.SampleQC$.results(SampleQC.scala:206); at is.hail.methods.SampleQC$.apply(SampleQC.scala:221); at is.hail.methods.SampleQC.apply(SampleQC.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745)is.hail.utils.HailException: invalid allele ""<DEL>""; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:29); at is.hail.methods.SampleQCCombiner$.alleleIndices(SampleQC.scala:44); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:178); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:175); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:175); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:170); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsR",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:7447,Error,ErrorHandling,7447,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['Error'],['ErrorHandling']
Availability," audit log versions, deprecated since 1.13, have been removed. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108092"">kubernetes/kubernetes#108092</a>, <a href=""https://github.com/carlory""><code>@carlory</code></a>)</li>; <li>Kube-apiserver: the <code>metadata.selfLink</code> field can no longer be populated by kube-apiserver; it was deprecated in 1.16 and has not been populated by default since 1.20+. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107527"">kubernetes/kubernetes#107527</a>, <a href=""https://github.com/wojtek-t""><code>@wojtek-t</code></a>)</li>; <li>Kubelet external Credential Provider feature is moved to Beta. Credential Provider Plugin and Credential Provider Config API's updated from v1alpha1 to v1beta1 with no API changes. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108847"">kubernetes/kubernetes#108847</a>, <a href=""https://github.com/adisky""><code>@adisky</code></a>)</li>; <li>Make STS available replicas optional again. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/109241"">kubernetes/kubernetes#109241</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@ravisantoshgudimetla</code></a>)</li>; <li>MaxUnavailable for StatefulSets, allows faster RollingUpdate by taking down more than 1 pod at a time. The number of pods you want to take down during a RollingUpdate is configurable using maxUnavailable parameter. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/82162"">kubernetes/kubernetes#82162</a>, <a href=""https://github.com/krmayankk""><code>@krmayankk</code></a>)</li>; <li>Non-graceful node shutdown handling is enabled for stateful workload failovers (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108486"">kubernetes/kubernetes#108486</a>, <a href=""https://github.com/sonasingh46""><code>@sonasingh46</code></a>)</li>; <li>Omit enum declarations from the static opena",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:9479,avail,available,9479,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['avail'],['available']
Availability," available. <code>+k8s:conversion-gen</code> tags can be used with the <code>k8s.io/code-generator</code> component to generate conversions. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/90018"">kubernetes/kubernetes#90018</a>, <a href=""https://github.com/wojtek-t""><code>@wojtek-t</code></a>) [SIG API Machinery, Apps and Testing]</li>; <li>Kube-proxy: add <code>--bind-address-hard-fail</code> flag to treat failure to bind to a port as fatal (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89350"">kubernetes/kubernetes#89350</a>, <a href=""https://github.com/SataQiu""><code>@SataQiu</code></a>) [SIG Cluster Lifecycle and Network]</li>; <li>Kubebuilder validation tags are set on metav1.Condition for CRD generation (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92660"">kubernetes/kubernetes#92660</a>, <a href=""https://github.com/damemi""><code>@damemi</code></a>) [SIG API Machinery]</li>; <li>Kubelet's --runonce option is now also available in Kubelet's config file as <code>runOnce</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89128"">kubernetes/kubernetes#89128</a>, <a href=""https://github.com/vincent178""><code>@vincent178</code></a>) [SIG Node]</li>; <li>Kubelet: add '--logging-format' flag to support structured logging (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91532"">kubernetes/kubernetes#91532</a>, <a href=""https://github.com/afrouzMashaykhi""><code>@afrouzMashaykhi</code></a>) [SIG API Machinery, Cluster Lifecycle, Instrumentation and Node]</li>; <li>Kubernetes is now built with golang 1.15.0-rc.1.; <ul>; <li>The deprecated, legacy behavior of treating the CommonName field on X.509 serving certificates as a host name when no Subject Alternative Names are present is now disabled by default. It can be temporarily re-enabled by adding the value x509ignoreCN=0 to the GODEBUG environment variable. (<a href=""https://gi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:9820,avail,available,9820,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['avail'],['available']
Availability," basic one</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/306172e4c6532e185c8a6a9998bca7d22d2d0c63""><code>306172e</code></a> Bump up version number to 5.2.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b9df0c0daa080450772c365f16a9406fe0ca607a""><code>b9df0c0</code></a> Document eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/05a4433770f7020ff845add9348bdc12c82793dd""><code>05a4433</code></a> Add eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/09d1eca91afbf21ace3672be24c68d9028ee1e33""><code>09d1eca</code></a> Document runAsync method</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/800e3df1647c5ce65bffdd25c3240dfa5244e6c5""><code>800e3df</code></a> Add runAsync method to download extension</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/80f04c6a46fe7df053ac55bcfc6f90ff74c4b873""><code>80f04c6</code></a> Bump up version number to 5.1.3</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=3.2.0&new-version=5.2.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will reb",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:4640,down,download-task,4640,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['down'],['download-task']
Availability," call last):; File ""/tmp/8d5cc778-fdc7-4210-a60b-5efd1f67c45f/subset_genotype_pca.py"", line 8, in <module>; print(mt.count_cols()); File ""/home/hail/hail.zip/hail/matrixtable.py"", line 1950, in count_cols; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/home/hail/hail.zip/hail/utils/java.py"", line 206, in deco; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.expr.MatrixValue.filterSamplesKeep(Relational.scala:110); 	at is.hail.expr.MatrixValue.filterCols(Relational.scala:133); 	at is.hail.expr.FilterCols.execute(Relational.scala:333); 	at is.hail.variant.MatrixTable.value$lzycompute(MatrixTable.scala:536); 	at is.hail.variant.MatrixTable.value(MatrixTable.scala:534); 	at is.hail.variant.MatrixTable.x$16$lzycompute(MatrixTable.scala:541); 	at is.hail.variant.MatrixTable.x$16(MatrixTable.scala:541); 	at is.hail.variant.MatrixTable.colValues$lzycompute(MatrixTable.scala:541); 	at is.hail.variant.MatrixTable.colValues(MatrixTable.scala:541); 	at is.hail.variant.MatrixTable.numCols(MatrixTable.scala:2378); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-3cf3108; Error summary: AssertionError: assertion failed; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3173:2578,Error,Error,2578,https://hail.is,https://github.com/hail-is/hail/issues/3173,1,['Error'],['Error']
Availability," come with 2 CPU and 7.5 GB each, but not all of that is allocatable to our pods. In reality, somewhere between 5.7-5.9GB ([GCP Docs](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture) say 5.7, GKE console says 5.9) of memory and 1.9CPU are available for us to use. Some of our Big services request 1 CPU and 3.75GB, but then we can never fit two big pods on one node. This is an attempt to standardize our requests so their easier to reason about while hopefully getting better packing. . | resource | Big | Medium | Small |; | --- | --- | --- | --- |; | CPU | 600m | 100m | 20m |; | Memory | 2G | 200M | 20M |. The intentions here are:; - always be able to comfortably get 2 Big pods on a node; - medium pods shouldn't have to force new nodes to spin up just because there's a Big pod there already; - small pods take up minimal resources; - there's ample room for small pods (which are mostly on HPA) to scale up considering most nodes shouldn't be at their medium pod capacity. The ratios don't match exactly, because I didn't want to assign CPU lower than 20m to prevent HPA thrashing we saw with auth and see a bit now with router. Setting it to 20m should hopefully convince k8s that idle small apps don't need to be scaled up under normal fluctuation. ## Big; - query; - batch-driver; - shuffler; - memory. ## Medium; - grafana; - ukbb-browser; - ukbb-static; - blog; - ci; - internal-gateway. ## Small; - amundsen; - router; - gateway; - site; - batch; - address; - atgu; - router-resolver; - ci/test statefulset & deployment; - auth-driver; - echo; - benchmark; - image-fetcher. ### Fun surprises I found along the way; - CI test statefulsets and deployment are getting .5GB and .5 CPU each; - We run a lot of image fetchers because a daemon set gets added per PR namespace. EDIT: It seems that discrepancy between GCP docs and GKE console is the console counts kube-system pods in ""Allocatable Memory"", and it really does take 2GB to run the Kubernetes Engine ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10117:1594,echo,echo,1594,https://hail.is,https://github.com/hail-is/hail/pull/10117,1,['echo'],['echo']
Availability," count in genotypes, for each ALT allele, in the same order as listed"">; ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency, for each ALT allele, in the same order as listed"">; ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">; ##INFO=<ID=BaseQRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities"">; ##INFO=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth; some reads may have been filtered"">; ##INFO=<ID=DS,Number=0,Type=Flag,Description=""Were any of the samples downsampled?"">; ##INFO=<ID=ExcessHet,Number=1,Type=Float,Description=""Phred-scaled p-value for exact test of excess heterozygosity"">; ##INFO=<ID=FS,Number=1,Type=Float,Description=""Phred-scaled p-value using Fisher's exact test to detect strand bias"">; ##INFO=<ID=InbreedingCoeff,Number=1,Type=Float,Description=""Inbreeding coefficient as estimated from the genotype likelihoods per-sample when compared against the Hardy-Weinberg expectation"">; ##INFO=<ID=MLEAC,Number=A,Type=Integer,Description=""Maximum likelihood expectation (MLE) for the allele counts (not necessarily the same as the AC), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MLEAF,Number=A,Type=Float,Description=""Maximum likelihood expectation (MLE) for the allele frequency (not necessarily the same as the AF), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MQ,Number=1,Type=Float,Description=""RMS Mapping Quality"">; ##INFO=<ID=MQRankSum,Number=1,Type=Float,Description=""Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities"">; ##INFO=<ID=QD,Number=1,Type=Float,Description=""Variant Confidence/Quality by Depth"">; ##INFO=<ID=RAW_MQ,Number=1,Type=Float,Description=""Raw data for RMS Mapping Quality"">; ##INFO=<ID=ReadPosRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt vs. Ref read position bias"">; ##INFO=<ID=SOR,Number=1,Type=Float,Description=""Symme",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:7859,down,downsampled,7859,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['down'],['downsampled']
Availability," creating a managed identity to run terraform through (instead of the current service principal), to creating a VM to run the bootstrap process off of, through all following steps until running bootstrap.py; - Adds the root CA certificate that azure uses to sign the MySQL server certificates so that we can connect to the database with `VERIFY_CA`. Unlike gcp, however, this still doesn't allow us to use mTLS since it doesn't look like we can request a client cert/key for our database. Still this is not so bad for now.; - Creates a separate k8s module for terraform. This currently just holds the global-config and sql-config resources, but establishes a boundary between the cloud-specific terraform and purely k8s terraform. Later on I'll refactor the GCP terraform to use the k8s module so that different clouds can use the same k8s configuration.; - Adds a pool of spot instances to the AKS cluster and adds the required toleration to all of our preemptible deployments. Part of the node selection process for a pod requires that exist a toleration on the pod for every taint on the node. In other words, it is ok for a pod to have redundant tolerations, so it's fine to have azure-specific tolerations even if we're running in gcp.; - Refactor the az-create-worker-image.sh script to complete the entire batch worker image creation process from start to finish. This involved sending a command over ssh that previously had to be executed by hand. This meant we could combine the two-script process into one shell script. This fully matches the google setup we have currently up until running `bootstrap.py`, which is still google-specific, mainly w.r.t. gcp service accounts. The next step is to adapt this to azure, but I think we need to come to a decision about exactly how we're representing application credentials (just service principals vs managed identities?). Once we have that figured out the rest of the terraform/bootstrap process should follow pretty quickly. Stacked on #10911",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10919:1141,toler,toleration,1141,https://hail.is,https://github.com/hail-is/hail/pull/10919,4,"['redundant', 'toler']","['redundant', 'toleration', 'tolerations']"
Availability," deep record data; Python: AVRO-2914 Drop Python 2 support; Python: AVRO-3004 Drop Python 3.5 support; Ruby: AVRO-3108 Drop Ruby 2.5 support</p>; <p>For the first time, the 1.11.0 release includes experimental support for; Rust. Work is continuing on this donated SDK, but we have not versioned and; published official artifacts for this release.</p>; <p>Python: The avro package fully supports Python 3. We will no longer publish a; separate avro-python3 package</p>; <p>And of course upgraded dependencies to latest versions, CVE fixes and more:; <a href=""https://issues.apache.org/jira/issues/?jql=project%3DAVRO%20AND%20fixVersion%3D1.11.0"">https://issues.apache.org/jira/issues/?jql=project%3DAVRO%20AND%20fixVersion%3D1.11.0</a></p>; <p>The link to all fixed JIRA issues and a brief summary can be found at:; <a href=""https://github.com/apache/avro/releases/tag/release-1.11.0"">https://github.com/apache/avro/releases/tag/release-1.11.0</a></p>; <p>In addition, language-specific release artifacts are available:</p>; <ul>; <li>C#: <a href=""https://www.nuget.org/packages/Apache.Avro/1.11.0"">https://www.nuget.org/packages/Apache.Avro/1.11.0</a></li>; <li>Java: from Maven Central,</li>; <li>Javascript: <a href=""https://www.npmjs.com/package/avro-js/v/1.11.0"">https://www.npmjs.com/package/avro-js/v/1.11.0</a></li>; <li>Perl: <a href=""https://metacpan.org/release/Avro"">https://metacpan.org/release/Avro</a></li>; <li>Python 3: <a href=""https://pypi.org/project/avro/1.11.0"">https://pypi.org/project/avro/1.11.0</a></li>; <li>Ruby: <a href=""https://rubygems.org/gems/avro/versions/1.11.0"">https://rubygems.org/gems/avro/versions/1.11.0</a></li>; </ul>; <p>Thanks to everyone for contributing!</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/apache/avro/compare/release-1.10.0...release-1.11.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11475:2076,avail,available,2076,https://hail.is,https://github.com/hail-is/hail/pull/11475,1,['avail'],['available']
Availability," deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,005"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:255"", ""message"": ""Tasks have all completed."", ""hail_log"": 1}; ```. Test duration endpoint; ```python; @routes.get('/api/v1alpha/wait'); async def wait_seconds(request):; """"""; Wait query.duration seconds before returning the request.; """"""; duration = request.query.get('duration'); try:; duration = int(duration); except Exception as e:; return web.json_response({; 'error': f'Invalid parameter duration ""{duration}"": {e}',; }, status=422). await asyncio.sleep(int(duration)); e = os.getenv(""TEST_VALUE"", ""None""); return web.json_response({""d"": f""You waited '{duration}' seconds!!"", ""env"": e}); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10106:2785,error,error,2785,https://hail.is,https://github.com/hail-is/hail/pull/10106,1,['error'],['error']
Availability," devel-6bb4670. ### What you did:; A number of variant QC steps, then a `vds.write`; The error is probably caused by one of the previous steps. If it helps I can comment out earlier parts to narrow down what actually triggers the error. ### What went wrong (all error messages here, including the full java stack trace):; ```; [Stage 6:> (0 + 8) / 5000]; [Stage 6:> (0 + 4) / 5000]; [Stage 6:> (0 + 8) / 5000]Traceback (most recent call last):; File ""/home/hail/hail.zip/hail/utils/java.py"", line 185, in handle_py4j; File ""/home/hail/hail.zip/hail/table.py"", line 1058, in aggregate; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o30335.query.; : org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 6.0 failed 20 times, most recent failure: Lost task 7.19 in stage 6.0 (TID 179, robert1-w-0.c.ccdg-wgs.internal, executor 4): java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.annotations.RegionValueBuilder.endStruct(RegionValueBuilder.scala:109); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2645); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2615); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.colle",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:1260,failure,failure,1260,https://hail.is,https://github.com/hail-is/hail/issues/3063,1,['failure'],['failure']
Availability," directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of linux, we can reevaluate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:1515,down,download,1515,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414,1,['down'],['download']
Availability," discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2-e60bdb1a125a. ### What you did:; ```; def get_counts_agg_expr2(mt: hl.MatrixTable):; return (hl.case(missing_false=True); #0x; .when(hl.is_missing(mt.gt1) & ~mt.missing1,; hl.case(missing_false=True); .when(hl.is_missing(mt.gt2) & ~mt.missing2,[1,0,0,0,0,0,0,0,0]); .when(mt.gt2.is_het(), [0,1,0,0,0,0,0,0,0]); .when(mt.gt2.is_hom_var(), [0,0,1,0,0,0,0,0,0]); .default([0,0,0,0,0,0,0,0,0])); #1x; .when(mt.gt1.is_het(),; hl.case(missing_false=True); .when(hl.is_missing(mt.gt2) & ~mt.missing2,[0,0,0,1,0,0,0,0,0]); .when(mt.gt2.is_het(), [0,0,0,0,1,0,0,0,0]); .when(mt.gt2.is_hom_var(), [0,0,0,0,0,1,0,0,0]); .default([0,0,0,0,0,0,0,0,0])); #2x; .when(mt.gt1.is_hom_var(),; hl.case(missing_false=True); .when(hl.is_missing(mt.gt2) & ~mt.missing2,[0,0,0,0,0,0,1,0,0]); .when(mt.gt2.is_het(), [0,0,0,0,0,0,0,1,0]); .when(mt.gt2.is_hom_var(), [0,0,0,0,0,0,0,0,1]); .default([0,0,0,0,0,0,0,0,0])); .default([0,0,0,0,0,0,0,0,0])); mt = mt.annotate_rows(gt_counts=hl.agg.array_sum(get_counts_agg_expr2(mt))); ```; ### What went wrong (all error messages here, including the full java stack trace):; `gt_counts` is `[]` everywhere:; ```; mt.show(); +---------------+------------+---------------+------------+--------------+; | locus2 | alleles2 | locus1 | alleles1 | gt_counts |; +---------------+------------+---------------+------------+--------------+; | locus<GRCh37> | array<str> | locus<GRCh37> | array<str> | array<int64> |; +---------------+------------+---------------+------------+--------------+; | 1:69173 | [""A"",""T""] | 1:69166 | [""G"",""T""] | [] |; | 1:69946 | [""G"",""A""] | 1:69359 | [""G"",""A""] | [] |; | 1:69947 | [""A"",""G""] | 1:69359 | [""G"",""A""] | [] |; | 1:69735 | [""A"",""G""] | 1:69438 | [""T"",""C""] | [] |; | 1:69496 | [""G"",""A""] | 1:69453 | [""G"",""A""] | [] |; +---------------+------------+---------------+------------+--------------+; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4757:1291,error,error,1291,https://hail.is,https://github.com/hail-is/hail/issues/4757,1,['error'],['error']
Availability," documentation</li>; <li>Add integration tests for Gradle 8.0.1</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4c983ed5cd229fa64912294737c858c2ba8486d6""><code>4c983ed</code></a> Bump up version number to 5.4.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/cc20442ab67bf37687c08e67af7e7de3a21c8fbe""><code>cc20442</code></a> Add integration tests for Gradle 8.0.2</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/472920e572e4cf45d321868874ced50ad8d1e2d5""><code>472920e</code></a> Add possibility to set request method and body</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/82e70cae2a8d48b4f5165a9b543d4e65bb793d88""><code>82e70ca</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86a15f1c16eb729dc71b6caf30237d07b8e0bb01""><code>86a15f1</code></a> Fix compiler warnings and deprecations</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86363072c8239330b28976109a622bdd073507b6""><code>8636307</code></a> Negative timeouts are actually not allowed</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4ff0ff0e63e0dd45f231990d0dcebffde6e6b709""><code>4ff0ff0</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a1858b494b5f3a51ccef7580c243c6dfdf520731""><code>a1858b4</code></a> Merge pull request <a href=""https://redirect.github.com/michel-kraemer/gradle-download-task/issues/295"">#295</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/c1e212c0fb41b3ea9185a9ea463fb1ea7142f748""><code>c1e212c</code></a> Add integration tests for Gradle 8.0 and 8.0.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:1446,down,download-task,1446,https://hail.is,https://github.com/hail-is/hail/pull/12893,1,['down'],['download-task']
Availability," execute; self._to_java_ir(ir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/utils/java.py"", line 227, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): is.hail.utils.HailException: foo: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; offending line: 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.utils.Context.wrapException(Context.scala:19); 	at is.hail.utils.WithContext.wrap(Context.scala:43); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:575); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:573); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:2886,Error,ErrorHandling,2886,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['Error'],['ErrorHandling']
Availability," extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0f43ce67de72bd511d849c07bd7728c0d6f2e6dd""><code>0f43ce6</code></a> Document path and relativePath properties</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a8504f9d60d0264808894e4bb80d4a73b8086a3e""><code>a8504f9</code></a> Bump up version number to 5.3.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/708067cd11c4a013da7a8c15d91f7f946967cf94""><code>708067c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0fdebf3c7ad43ed4739",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:2919,Mainten,Maintenance,2919,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['Mainten'],['Maintenance']
Availability," extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.5</h2>; <p>Maintenance:</p>; <ul>; <li>Publish signed artifacts to Gradle plugin portal</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.4</h2>; <p>Bug fixes:</p>; <ul>; <li>Fix deadlock in <code>DownloadExtension</code> if <code>max-workers</code> equals 1 (thanks to <a href=""https://github.com/beatbrot""><code>@beatbrot</code></a> for spotting this, see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/205"">#205</a>)</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1b5d69",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:2200,Mainten,Maintenance,2200,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['Mainten'],['Maintenance']
Availability," figure out what the tests are doing. We pay about 2 USD per PR test, which is not very high but still higher than I would like. I investigated why and looked at eight recent PR tests (all after Daniel's QoB test reduction):. 1. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1695065243258&to=1695070128973&var-namespace=pr-13643-default-w484n4ke6oeg&orgId=1; 2. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1694628837271&to=1694632585473&var-namespace=pr-12468-default-y8okmle5k65x&orgId=1; 3. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1695078157872&to=1695080578446&var-namespace=pr-13644-default-phtb7scq3qln&orgId=1; 4. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1694729270680&to=1694730449193&var-namespace=pr-13376-default-biulo4i0wohp&orgId=1; 5. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1694628896138&to=1694632029521&var-namespace=pr-12468-default-y8okmle5k65x&orgId=1; 6. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1695077856969&to=1695080563275&var-namespace=pr-13644-default-phtb7scq3qln&orgId=1; 7. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1694625081745&to=1694626754800&var-namespace=pr-13430-default-hf2v0q29kgqy&orgId=1; 8. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1694729252321&to=1694730683820&var-namespace=pr-13376-default-biulo4i0wohp&orgId=1. In every case, we spin up 32 cores of highcpu VMs but, apparently, never use them. They are live for 20-40 minutes depending on the tests. For the non-preemptible VM, thats about 0.40 USD for 30 minutes. We use 16 highmem cores once for about two minutes but we otherwise let them run idle the whole time. This PR accepts that we will wait 2-3min for a highmem to start when we need it. In exchange, we save about a dollar per PR (50%). I am also investigating why we seem to keep 80 cores alive for about 10 minutes despite being unused. My best guess is fragmentation, probably not much to do about that. cc: @daniel-goldstein, @jigold.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13667:1972,alive,alive,1972,https://hail.is,https://github.com/hail-is/hail/pull/13667,1,['alive'],['alive']
Availability," fixed version:; - hail/python/dev/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed.; jupyter 1.0.0 requires qtconsole, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed.; argon2-cffi-bindings 21.2.0 requires cffi, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **461/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.5 | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3MThjYjgyZC1jNGU3LTRlNWEtODgzZi02NjQ0NjlmYzA4MGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjcxOG",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14070:1278,Error,Error,1278,https://hail.is,https://github.com/hail-is/hail/pull/14070,1,['Error'],['Error']
Availability," for example, a compromised `notebook` from masquerading as `batch`. I agree that additionally verifying that the certificate came from a single root certificate (that we, perhaps, destroy after everything is signed) would additionally prevent a malicious user from inserting their certificates into the trusted certificates list. AFAICT, python's `ssl` module has no support for this verification strategy. We could probably build an SSLContext shim that contained two SSLContexts one with a root cert and one with the trusted certs and require certification verification to pass both. Seems easy to get wrong, so I'm inclined to not take this path. ### trusted cert lists. Yeah, it felt a little silly to duplicate the cert in each secret. However, this seems like the simplest approach if I require each principal to only trust a subset of incoming/outgoing principals. If I had one secret per principal, then I have to modify build.yaml or deployment.yamls if I modify the trust sets. That seemed error prone. If I had one secret with all the certs, then when a service starts up it has to select the trusted ones and only insert those into its certificate store. This seems OK, but a little harder to inspect. Duplicating a cert for each trust list to which it belongs occupies what seems like a good spot to me from a developer ergonomics perspective:; - O(trusts) modifications necessary to update/revoke the cert; - O(1) configuration to load a trust list; - no pod-start-time configuration; - the trust list is on the container's file system, so its easy to inspect. Small point: I don't pin the incoming certs yet due to the mTLS challenges. ### create on each deploy. Only creating certs if they don't exist is an easy change. Seems fine, though leaves unresolved how to rotate the certs. I guess I'm inclined to always recreate because it makes rotation the common case, forcing us to make it work well. I think the only way to do a no-downtime rotation is:; 1. create fresh certs; 2. crea",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561#issuecomment-617428243:1894,error,error,1894,https://hail.is,https://github.com/hail-is/hail/pull/8561#issuecomment-617428243,1,['error'],['error']
Availability," from an array of const class simdpp::arch_avx2::uint16<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:32:7: note: class simdpp::arch_avx2::int8<32> declared here; class int8<32, void> : public any_int8<32, int8<32,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int32<4>; T = simdpp::arch_avx2::int64<2>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int32<4>; T = simdpp::arch_avx2::int64<2>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int32<4>; T = simdpp::arch_avx2::int64<2>]; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:62:35: required from simdpp::arch_avx2::int32<4>& simdpp::arch_avx2::int32<4>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::int64<2>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:260:13: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int32<4> with private member simdpp::arch_avx2::int32<4>::d_ from an array of const class simdpp::arch_avx2::int64<2>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:67105,Mask,MaskCastOverride,67105,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," from an array of const class simdpp::arch_avx2::uint32<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:37,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32.h:31:7: note: class simdpp::arch_avx2::int32<16> declared here; class int32<N, void> : public any_int32<N, int32<N,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int32<8>; T = simdpp::arch_avx2::uint32<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int32<8>; T = simdpp::arch_avx2::uint32<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int32<8>; T = simdpp::arch_avx2::uint32<8>]; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:55:35: required from simdpp::arch_avx2::int32<8>& simdpp::arch_avx2::int32<8>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint32<8>]; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:48:73: required from simdpp::arch_avx2::int32<8>::int32(const simdpp::arch_avx2::uint32<8, E>&) [with E = void]; libsimdpp-2.0-rc2/simdpp/core/combine.h:73:69: required from simdpp::arch_avx2::int32<(N * 2)> simdpp::arch_avx2::combine(const simdpp::arch_avx2::int32<N, E>&, const simdpp::arch_avx2::int32<N, E2>&) [with unsigned int N = 4; E1 = void; E2 = void]; libsimdpp-2.0-rc2/simdpp/detail/insn/to_int32.h:188:26: required from here; libsimdpp-2.0-rc2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:130737,Mask,MaskCastOverride,130737,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," from an array of const class simdpp::arch_avx2::uint32<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:33:7: note: class simdpp::arch_avx2::int32<4> declared here; class int32<4, void> : public any_int32<4, int32<4,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int32<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int32<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int32<8>]; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int32<8>]; libsimdpp-2.0-rc2/simdpp/detail/extract128.h:40:82: required from simdpp::arch_avx2::int32x4 simdpp::arch_avx2::detail::extract128(const int32x8&) [with unsigned int s = 0; simdpp::arch_avx2::int32x4 = simdpp::arch_avx2::int32<4>; simdpp::arch_avx2::int32x8 = simdpp::arch_avx2::int32<8>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_reduce_add.h:356:49: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<32> ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:120259,Mask,MaskCastOverride,120259,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," from an array of const class simdpp::arch_avx2::uint32<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:32:7: note: class simdpp::arch_avx2::int32<8> declared here; class int32<8, void> : public any_int32<8, int32<8,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::int64<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::int64<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::int64<4>]; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:114:36: required from simdpp::arch_avx2::uint64<4>& simdpp::arch_avx2::uint64<4>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int64<4>]; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:107:73: required from simdpp::arch_avx2::uint64<4>::uint64(const simdpp::arch_avx2::int64<4, E>&) [with E = void]; libsimdpp-2.0-rc2/simdpp/core/combine.h:79:49: required from simdpp::arch_avx2::int64<(N * 2)> simdpp::arch_avx2::combine(const simdpp::arch_avx2::int64<N, E>&, const simdpp::arch_avx2::int64<N, E2>&) [with unsigned int N = 4; E1 = void; E2 = void]; libsimdpp-2.0-rc2/simdpp/detail/insn/to_int64.h:70:26: required from here; libsimdpp-2.0-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:132936,Mask,MaskCastOverride,132936,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," from an array of const class simdpp::arch_avx2::uint64<2>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:33:7: note: class simdpp::arch_avx2::int32<4> declared here; class int32<4, void> : public any_int32<4, int32<4,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::int32<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::int32<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::int32<4>]; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:129:36: required from simdpp::arch_avx2::uint64<2>& simdpp::arch_avx2::uint64<2>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::int32<4, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:272:42: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint64<2> with private member simdpp::arch_avx2::uint64<2>::d_ from an array of const class simdpp::arch_avx2::int32<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:74206,Mask,MaskCastOverride,74206,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," from an array of const class simdpp::arch_avx2::uint64<2>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:26,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:33:7: note: class simdpp::arch_avx2::int64<2> declared here; class int64<2, void> : public any_int64<2, int64<2,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::uint64<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::uint64<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::uint64<4>]; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:55:35: required from simdpp::arch_avx2::int64<4>& simdpp::arch_avx2::int64<4>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint64<4>]; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:48:73: required from simdpp::arch_avx2::int64<4>::int64(const simdpp::arch_avx2::uint64<4, E>&) [with E = void]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:307:25: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int64<4> with private member simdpp::arch_avx2::int64<4>::d_ from an array of const class simdpp::arch_avx2::uin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:110039,Mask,MaskCastOverride,110039,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," from an array of const class simdpp::arch_avx2::uint64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:32:7: note: class simdpp::arch_avx2::int32<8> declared here; class int32<8, void> : public any_int32<8, int32<8,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::int8<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::int8<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::int8<16>]; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:133:36: required from simdpp::arch_avx2::uint8<16>& simdpp::arch_avx2::uint8<16>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::int8<16, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_avg_trunc.h:64:25: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<16> with private member simdpp::arch_avx2::uint8<16>::d_ from an array of const class simdpp::arch_avx2::int8<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:83325,Mask,MaskCastOverride,83325,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," from an array of const class simdpp::arch_avx2::uint64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:27,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:32:7: note: class simdpp::arch_avx2::int64<4> declared here; class int64<4, void> : public any_int64<4, int64<4,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int8<32>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int8<32>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int8<32>]; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:114:36: required from simdpp::arch_avx2::uint8<32>& simdpp::arch_avx2::uint8<32>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int8<32>]; libsimdpp-2.0-rc2/simdpp/core/bit_xor.h:38:8: required from typename simdpp::arch_avx2::detail::get_expr2<V1, V2>::empty simdpp::arch_avx2::bit_xor(const simdpp::arch_avx2::any_vec<N, V>&, const simdpp::arch_avx2::any_vec<N, V2>&) [with unsigned int N = 32; V1 = simdpp::arch_avx2::int8<32>; V2 = simdpp::arch_avx2::uint8<32>; typename simdpp::arch_avx2::detail::get_expr2<V1, V2>::empty = simdpp::arch_avx2::uint8<32, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_avg.h:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:111987,Mask,MaskCastOverride,111987,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," from an array of const class simdpp::arch_avx2::uint8<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:19,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:33:7: note: class simdpp::arch_avx2::int8<16> declared here; class int8<16, void> : public any_int8<16, int8<16,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int8<32>; T = simdpp::arch_avx2::uint8<32>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int8<32>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int8<32>; T = simdpp::arch_avx2::uint8<32>]; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:55:35: required from simdpp::arch_avx2::int8<32>& simdpp::arch_avx2::int8<32>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32>]; libsimdpp-2.0-rc2/simdpp/detail/insn/shuffle_zbytes16.h:87:11: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int8<32> with private member simdpp::arch_avx2::int8<32>::d_ from an array of const class simdpp::arch_avx2::uint8<32>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:90499,Mask,MaskCastOverride,90499,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," from an array of const class simdpp::arch_avx2::uint8<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:21,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:33:7: note: class simdpp::arch_avx2::int16<8> declared here; class int16<8, void> : public any_int16<8, int16<8,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::int16<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::int16<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::int16<8>]; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:129:36: required from simdpp::arch_avx2::uint8<16>::uint8(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::int16<8>]; libsimdpp-2.0-rc2/simdpp/detail/insn/shuffle_bytes16.h:51:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<16> with private member simdpp::arch_avx2::uint8<16>::d_ from an array of const class simdpp::arch_avx2::int16<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:17389,Mask,MaskCastOverride,17389,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," from an array of const class simdpp::arch_avx2::uint8<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:33:7: note: class simdpp::arch_avx2::int32<4> declared here; class int32<4, void> : public any_int32<4, int32<4,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int64<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int64<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int64<4>]; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int64<4>]; libsimdpp-2.0-rc2/simdpp/detail/extract128.h:42:82: required from simdpp::arch_avx2::int64x2 simdpp::arch_avx2::detail::extract128(const int64x4&) [with unsigned int s = 0; simdpp::arch_avx2::int64x2 = simdpp::arch_avx2::int64<2>; simdpp::arch_avx2::int64x4 = simdpp::arch_avx2::int64<4>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_reduce_max.h:478:40: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<32> ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:124373,Mask,MaskCastOverride,124373,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability," has requirement docutils<0.20,>=0.14, but you have docutils 0.20.1.; sphinx-rtd-theme 1.3.0 has requirement docutils<0.19, but you have docutils 0.20.1. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **624/1000** <br/> **Why?** Has a fix available, CVSS 8.2 | Arbitrary Code Execution <br/>[SNYK-PYTHON-IPYTHON-2348630](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-2348630) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; !",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14108:1462,avail,available,1462,https://hail.is,https://github.com/hail-is/hail/pull/14108,1,['avail'],['available']
Availability," href=""https://github.com/pallets/jinja/releases"">jinja2's releases</a>.</em></p>; <blockquote>; <h2>3.1.3</h2>; <p>This is a fix release for the 3.1.x feature branch.</p>; <ul>; <li>Fix for <a href=""https://github.com/pallets/jinja/security/advisories/GHSA-h5c8-rqwp-cp95"">GHSA-h5c8-rqwp-cp95</a>. You are affected if you are using <code>xmlattr</code> and passing user input as attribute keys.</li>; <li>Changes: <a href=""https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-3"">https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-3</a></li>; <li>Milestone: <a href=""https://github.com/pallets/jinja/milestone/15?closed=1"">https://github.com/pallets/jinja/milestone/15?closed=1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/jinja/blob/main/CHANGES.rst"">jinja2's changelog</a>.</em></p>; <blockquote>; <h2>Version 3.1.3</h2>; <p>Released 2024-01-10</p>; <ul>; <li>Fix compiler error when checking if required blocks in parent templates are; empty. :pr:<code>1858</code></li>; <li><code>xmlattr</code> filter does not allow keys with spaces. GHSA-h5c8-rqwp-cp95</li>; <li>Make error messages stemming from invalid nesting of <code>{% trans %}</code> blocks; more helpful. :pr:<code>1918</code></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/jinja/commit/d9de4bb215fd1cc8092a410fb834c7c4060b1fc1""><code>d9de4bb</code></a> release version 3.1.3</li>; <li><a href=""https://github.com/pallets/jinja/commit/50124e16561f17f6c1ec85a692f6551418971cdc""><code>50124e1</code></a> skip test pypi</li>; <li><a href=""https://github.com/pallets/jinja/commit/9ea7222ef3f184480be0d0884e30ccfb4172b17b""><code>9ea7222</code></a> use trusted publishing</li>; <li><a href=""https://github.com/pallets/jinja/commit/da703f7aae36b1e88baaa20de334d7ff6378fdde""><code>da703f7</code></a> use trusted publishing</li>; <li><a href=""https",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14144:1133,error,error,1133,https://hail.is,https://github.com/hail-is/hail/pull/14144,3,['error'],['error']
Availability," in RFC 2246. This new version was backwards-incompatible and was; thus given a new name: Transport Layer Security. In common discussion, SSL; and TLS are used interchangeable. Indeed, the python TLS library is called; `ssl`. [2] Forward secrecy is a property of an encryption system. Forward secrecy means; a message cannot be decrypted in the future by an adversary who learned one; of the private keys. For example, imagine you are sending sensitive messages; to another individual. If that individual is later coerced into revealing; their secret key, forward secrecy would prevent the coercer from reading; your messages. Forward secrecy is achieved by negotiating a shared private; key between the two parties that is only used for a ""session"" and then; discarded. If the session key is securely discarded and neither key can; recreate it without cooperation from the other key, then *one* leaked key is; insufficient to reveal the messages. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the `http`; section and the `proxy.conf` file in any proxying sections?; - Do the SSLContext's from `ssl.py` and the nginx configurations generated by; `create_certs.py` actually ensure security?. Post-merge actions:; - deploy gateway; - deploy internal-gateway; - deploy router-resolver. Anticipated outages:. - Before a service is redeployed it will be inaccessible from the outside; because the router will try to speak to it on HTTPS. Services that speak to; one another (ci<->batch, everyone<->auth) will lose connections while the; deploy is happening. Deploy should move smoothly because CI will completely; transmit the deploy batch to batch before batch goes dark.; - dev namespaces will be broken until the owner redeploys the router, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:13267,outage,outages,13267,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['outage'],['outages']
Availability," in __call__(self, *args); 1302 ; 1303 answer = self.gateway_client.send_command(command); -> 1304 return_value = get_return_value(; 1305 answer, self.gateway_client, self.target_id, self.name); 1306 . /databricks/spark/python/pyspark/sql/utils.py in deco(*a, **kw); 115 def deco(*a, **kw):; 116 try:; --> 117 return f(*a, **kw); 118 except py4j.protocol.Py4JJavaError as e:; 119 converted = convert_exception(e.java_exception). /databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 324 value = OUTPUT_CONVERTER[type](answer[2:], gateway_client); 325 if answer[1] == REFERENCE_TYPE:; --> 326 raise Py4JJavaError(; 327 ""An error occurred while calling {0}{1}{2}.\n"".; 328 format(target_id, ""."", name), value). Py4JJavaError: An error occurred while calling o504.pyPersistTable.; : is.hail.utils.HailException: 1 samples and 12 covariates (including x) implies -11 degrees of freedom.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:11); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:11); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.methods.LinearRegressionRowsSingle.execute(LinearRegression.scala:51); 	at is.hail.expr.ir.functions.WrappedMatrixToTableFunction.execute(RelationalFunctions.scala:51); 	at is.hail.expr.ir.TableToTableApply.execute(TableIR.scala:2936); 	at is.hail.expr.ir.TableIR.analyzeAndExecute(TableIR.scala:57); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:27); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyPersistTable$2(SparkBackend.scala:502); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:46); 	a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11413:3808,Error,ErrorHandling,3808,https://hail.is,https://github.com/hail-is/hail/issues/11413,1,['Error'],['ErrorHandling']
Availability," in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in execute; raise HailUserError(message_and_trace) from None; hail.utils.java.HailUserError: Error summary: HailException: Index 12 is out of bounds for axis 1 with size 1; ------------; Hail stack trace:; File ""better_error_test.py"", line 5, in <module>; ht = ht.annotate(bar = ht.foo[0:4, 12]). File ""<decorator-gen-707>"", line 2, in __getitem__. File ""/Users/johnc/Code/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 3709, in __getitem__; hl.str(""Index "") + hl.str(s) + hl.str(f"" is out of bounds for axis {i} with size "") + hl.str(dlen). File ""<decorator-gen-1299>"", line 2, in or_error. File ""/Users/johnc/Code/hail/hail/python/hail/expr/builders.py"", line 311, in or_error; die_ir.save_error_info(); ```. (Note that ndarray bounds checking internally uses a case builder, which is why this example works).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9398:2089,Error,Error,2089,https://hail.is,https://github.com/hail-is/hail/pull/9398,1,['Error'],['Error']
Availability," in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; cl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9554:1531,error,error,1531,https://hail.is,https://github.com/hail-is/hail/pull/9554,1,['error'],['error']
Availability," in write; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 481, in _typecheck; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 1956, in write; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: NumberFormatException: For input string: ""-66.2667,0,-25.4754"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 48 in stage 2.0 failed 4 times, most recent failure: Lost task 48.3 in stage 2.0 (TID 536, scc-q14.scc.bu.edu, executor 1): is.hail.utils.HailExcput string: ""-66.2667,0,-25.4754""; offending line: chr2 130824417 DEL00068296 AGAACAGGACATCCCAGGCAGCTACAGCCCATC...; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.utils.Context.wrapException(Context.scala:23); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:741); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:412); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:750); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1$$anonfun$apply$2$$anonfun$apply$3$$anonfun$apply$4.apply(RowStore.scala:774); at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1$$anonfun$apply$2$$anonfun$apply$3$$anon",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3361:2334,Error,ErrorHandling,2334,https://hail.is,https://github.com/hail-is/hail/issues/3361,1,['Error'],['ErrorHandling']
Availability," is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:9); 	at is.hail.backend.Backend.execute(Backend.scala:56); 	at is.hail.backend.Backend.executeJSON(Backend.scala:62); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:745). org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3, localhost, executor driver): is.hail.utils.HailException: Hail only supports 8-bit probabilities, found 16.; 	at is.hail.codegen.generated.C_bgen_rdd_decoder_13.apply(Unknown Source); 	at is.hail.codegen.generated.C_bgen_rdd_decoder_13.apply(Unknown Source); 	at is.hail.io.bgen.BgenRecordIteratorWithoutFilter.next(BgenRDD.scala:222); 	at is.hail.io.bgen.BgenRecordIteratorWithoutFilter.next(BgenRDD.scala:206); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410); 	at scala.collection.TraversableOnce$FlattenOps$$anon$1.hasNext(TraversableOnce.scala:464); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); 	at scala.collection.Iterator$class.foreach(Iterator.scala:891); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); 	at is.hail.io.RichContextRDDRegionValue$$ano",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:4150,failure,failure,4150,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['failure'],['failure']
Availability," is.hail.rvd.RVD$$anonfun$37.apply(RVD.scala:1059); at is.hail.rvd.RVD$$anonfun$37.apply(RVD.scala:1057); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$27.apply(ContextRDD.scala:355); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$27.apply(ContextRDD.scala:355); at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:135); at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:135); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310). Hail version: 0.2-721af83bc30a; Error summary: OutOfMemoryError: Java heap space; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1035, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 883, in send_command; response = connection.send_command(command); File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1040, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635:10674,Error,Error,10674,https://hail.is,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635,4,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability," issuing a warning as we cannot help users facing issues with implementations other than OpenSSL. (<code>[#3020](https://github.com/urllib3/urllib3/issues/3020) &lt;https://github.com/urllib3/urllib3/issues/3020&gt;</code>__)</li>; <li>Deprecated URLs which don't have an explicit scheme (<code>[#2950](https://github.com/urllib3/urllib3/issues/2950) &lt;https://github.com/urllib3/urllib3/pull/2950&gt;</code>_)</li>; <li>Fixed response decoding with Zstandard when compressed data is made of several frames. (<code>[#3008](https://github.com/urllib3/urllib3/issues/3008) &lt;https://github.com/urllib3/urllib3/issues/3008&gt;</code>__)</li>; <li>Fixed <code>assert_hostname=False</code> to correctly skip hostname check. (<code>[#3051](https://github.com/urllib3/urllib3/issues/3051) &lt;https://github.com/urllib3/urllib3/issues/3051&gt;</code>__)</li>; </ul>; <h1>2.0.2 (2023-05-03)</h1>; <ul>; <li>Fixed <code>HTTPResponse.stream()</code> to continue yielding bytes if buffered decompressed data; was still available to be read even if the underlying socket is closed. This prevents; a compressed response from being truncated. (<code>[#3009](https://github.com/urllib3/urllib3/issues/3009) &lt;https://github.com/urllib3/urllib3/issues/3009&gt;</code>__)</li>; </ul>; <h1>2.0.1 (2023-04-30)</h1>; <ul>; <li>Fixed a socket leak when fingerprint or hostname verifications fail. (<code>[#2991](https://github.com/urllib3/urllib3/issues/2991) &lt;https://github.com/urllib3/urllib3/issues/2991&gt;</code>__)</li>; <li>Fixed an error when <code>HTTPResponse.read(0)</code> was the first <code>read</code> call or when the internal response body buffer was otherwise empty. (<code>[#2998](https://github.com/urllib3/urllib3/issues/2998) &lt;https://github.com/urllib3/urllib3/issues/2998&gt;</code>__)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/urllib3/urllib3/commit/56f01e08",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13852:11043,avail,available,11043,https://hail.is,https://github.com/hail-is/hail/pull/13852,1,['avail'],['available']
Availability, issuing a warning as we cannot help users facing issues with implementations other than OpenSSL. (<code>[#3020](https://github.com/urllib3/urllib3/issues/3020) &lt;https://github.com/urllib3/urllib3/issues/3020&gt;</code>__)</li>; <li>Deprecated URLs which don't have an explicit scheme (<code>[#2950](https://github.com/urllib3/urllib3/issues/2950) &lt;https://github.com/urllib3/urllib3/pull/2950&gt;</code>_)</li>; <li>Fixed response decoding with Zstandard when compressed data is made of several frames. (<code>[#3008](https://github.com/urllib3/urllib3/issues/3008) &lt;https://github.com/urllib3/urllib3/issues/3008&gt;</code>__)</li>; <li>Fixed <code>assert_hostname=False</code> to correctly skip hostname check. (<code>[#3051](https://github.com/urllib3/urllib3/issues/3051) &lt;https://github.com/urllib3/urllib3/issues/3051&gt;</code>__)</li>; </ul>; <h1>2.0.2 (2023-05-03)</h1>; <ul>; <li>Fixed <code>HTTPResponse.stream()</code> to continue yielding bytes if buffered decompressed data; was still available to be read even if the underlying socket is closed. This prevents; a compressed response from being truncated. (<code>[#3009](https://github.com/urllib3/urllib3/issues/3009) &lt;https://github.com/urllib3/urllib3/issues/3009&gt;</code>__)</li>; </ul>; <h1>2.0.1 (2023-04-30)</h1>; <ul>; <li>Fixed a socket leak when fingerprint or hostname verifications fail. (<code>[#2991](https://github.com/urllib3/urllib3/issues/2991) &lt;https://github.com/urllib3/urllib3/issues/2991&gt;</code>__)</li>; <li>Fixed an error when <code>HTTPResponse.read(0)</code> was the first <code>read</code> call or when the internal response body buffer was otherwise empty. (<code>[#2998](https://github.com/urllib3/urllib3/issues/2998) &lt;https://github.com/urllib3/urllib3/issues/2998&gt;</code>__)</li>; </ul>; <h1>2.0.0 (2023-04-26)</h1>; <p>Read the <code>v2.0 migration guide &lt;https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html&gt;</code>__ for help upgrading to the latest ver,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13768:10691,avail,available,10691,https://hail.is,https://github.com/hail-is/hail/pull/13768,2,['avail'],['available']
Availability," mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 13:51:03 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN Utils: Your hostname, <my computer name> resolves to a loopback address: <my local IP>; using <my IP> instead (on interface enp3s0); 18/01/08 13:51:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; ```. And the other initialize hail like this (crashes with the stack trace/error in the issue):; ```; from pyspark import *; from hail import *; conf = SparkConf(); conf.set('spark.sql.files.maxPartitionBytes','60000000000') ; conf.set('spark.sql.files.openCostInBytes','60000000000') ; conf.set('spark.driver.cores','1') #test with 1 core; sc = SparkContext(conf=conf); hc = HailContext(sc); ```. With startup messages looking like this:; ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 15:16:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 15:16:23 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 15:16:23 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:7161,error,error,7161,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783,1,['error'],['error']
Availability," multi, and `describe()`, `count()`, and `_force_count_rows()` all behave as expected. ```; import hail as hl. giab_gs_path = 'gs://xxxxxxxx'; giab_ds = hl.import_vcf(giab_gs_path, reference_genome='GRCh38'); giab_sm = hl.SplitMulti(giab_ds); giab_ds = giab_sm.result(); giab_ds.describe(); gaib_ds.count(); gaib_ds._force_count_rows(); # all good. sent_gs_path = 'gs://xxxxxxxxxxx'; sent_ds = hl.import_vcf(sent_gs_path, reference_genome='GRCh38'); sent_sm = hl.SplitMulti(sent_ds); sent_ds = sent_sm.result(); sent_ds.describe(); sent_ds.count(); sent_ds._force_count_rows(); # all good. # then this gives the stack trace below. giab_22_ds = hl.filter_intervals(giab_ds, [hl.parse_locus_interval('chr22', reference_genome='GRCh38')]); ```. Stack trace:. ```; FatalError: ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 20 times, most recent failure: Lost task 0.19 in stage 19.0 (TID 312, gilson-validation-test-2-w-4.c.perfect-atrium-179917.internal, executor 2): java.lang.ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5; 	at is.hail.expr.TableMapRows$$anonfun$execute$5.apply(Relational.scala:1641); 	at is.hail.expr.TableMapRows$$anonfun$execute$5.apply(Relational.scala:1637); 	at is.hail.sparkextras.ContextRDD$$anonfun$mapPartitions$1.apply(ContextRDD.scala:151); 	at is.hail.sparkextras.ContextRDD$$anonfun$mapPartitions$1.apply(ContextRDD.scala:151); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19$$anonfun$apply$20.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19$$anonfun",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:1145,failure,failure,1145,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410,1,['failure'],['failure']
Availability," of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0OWRkZWE4YS05NjJjLTQ4ODktYjgwMC0zZDY0YjgyYTBiMzgiLCJldmVudCI6IlBSIHZpZXd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14109:4596,avail,available,4596,https://hail.is,https://github.com/hail-is/hail/pull/14109,1,['avail'],['available']
Availability," of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0ZDFlNzI4ZS0yNjljLTQ5YTItYTJkMC1iZjFjMDQ5NjZlMjkiLCJldmVudCI6IlBSIHZpZXd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14026:3271,avail,available,3271,https://hail.is,https://github.com/hail-is/hail/pull/14026,1,['avail'],['available']
Availability," of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiYzkzNDY4ZC02OGU5LTRmYWMtYTMzNS1mODcyNjE3MDZmNDgiLCJldmVudCI6IlBSIHZpZXd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14211:3860,avail,available,3860,https://hail.is,https://github.com/hail-is/hail/pull/14211,1,['avail'],['available']
Availability," of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `40.5.0 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1MTRiNWVkZS0yNmZhLTQxMDYtODMxMC1jMmNlZWQ3YzA4YTkiLCJldmVudCI6IlBSIHZpZXd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14365:3930,avail,available,3930,https://hail.is,https://github.com/hail-is/hail/pull/14365,1,['avail'],['available']
Availability," of transient error. We pick 22 random characters from a 62 character alphabet. Odds of collision are minuscule:; ```; In [2]: (1/62)**22; Out[2]: 3.693029961058969e-40; ```; I verified `SecureRandom` with no constructor uses a randomly chosen seed. There's three exceptions there (all the same one). The deepest one came during a write. The next two came during closes. The outermost exception is from the `using` cleaning up. I'm not sure where the middle exception comes from, I can't imagine who would try to `close` the stream other than `using`. Regardless, it appears that the upload fails in some unrecoverable way. We're writing 2GiB in 256 8MiB chunks in this test, so we have more chances for something to go wrong. Maybe we just have to retry the entire partition when this happens?. https://ci.hail.is/batches/7404773/jobs/145; ```; starting test is.hail.fs.gs.GoogleStorageFSSuite.testSeekMoreThanMaxInt...; Exception:; is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-6BO4gZ18Lheigp3ir9RSOh&uploadType=resumable&upload_id=ADPycduiXx2Jtiy_0Ll131_pPeEYKnnA23Hlk28_9TFESUMaubA9OqLK_n8Td5rPhTXnlpssGo796Q4bJxUeblhmSaYcCSWAMg2k; chunkOffset: 16777216; chunkLength: 8388608; localOffset: 1325400064; remoteOffset: 1342177280; lastChunk: false. 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:267); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756:1116,recover,recover,1116,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756,1,['recover'],['recover']
Availability, org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); at is.hail.utils.richUtils.RichRDD$.countPerPartition$extension(RichRDD.scala:121); at is.hail.rvd.RVD$class.countPerPartition(RVD.scala:185); at is.hail.rvd.OrderedRVD.countPerPartition(OrderedRVD.scala:19); at is.hail.variant.MatrixTable.partitionCounts(MatrixTable.scala:535); at is.hail.variant.MatrixTable.countRows(MatrixTable.scala:1128); at is.hail.variant.MatrixTable.count(MatrixTable.scala:1126); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748)java.lang.ClassCastException: null; at . Hail version: devel-e6de08e; Error summary: ClassCastException: null; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3447:3341,Error,Error,3341,https://hail.is,https://github.com/hail-is/hail/issues/3447,1,['Error'],['Error']
Availability," other people have seen this too with the latest release of jinja2:. https://github.com/holoviz/panel/issues/3260. This may be transient and may be solved by bokeh / jinja2 folks but thought I'd let you know in case you hit this issue. ```; ../conda/envs/glow/lib/python3.7/site-packages/bokeh/core/templates.py:43: in <module>; from jinja2 import Environment, Markup, FileSystemLoader; E ImportError: cannot import name 'Markup' from 'jinja2' (/home/circleci/conda/envs/lib/python3.7/site-packages/jinja2/__init__.py); [error] java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; [error] 	at scala.Predef$.require(Predef.scala:281); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14(build.sbt:288); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14$adapted(build.sbt:278); [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49); [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62); [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67); [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:280); [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19); [error] 	at sbt.Execute.work(Execute.scala:289); [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:280); [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); [error] 	at java.lang.Thread.run(Thread.java:748); [error] (hail / hailtest) java.lang.Illeg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705:1286,error,error,1286,https://hail.is,https://github.com/hail-is/hail/issues/11705,1,['error'],['error']
Availability," output_uri: str) -> bytes:; assert self._batch; ; try:; driver_output = await self._async_fs.open(output_uri); except FileNotFoundError as exc:; raise FatalError('Hail internal error. Please contact the Hail team and provide the following information.\n\n' + yamlx.dump({; 'service_backend_debug_info': self.debug_info(),; 'batch_debug_info': await self._batch.debug_info(); })) from exc; ; async with driver_output as outfile:; success = await read_bool(outfile); if success:; return await read_bytes(outfile); ; short_message = await read_str(outfile); expanded_message = await read_str(outfile); error_id = await read_int(outfile); ; reconstructed_error = fatal_error_from_java_error_triplet(short_message, expanded_message, error_id); if ir is None:; raise reconstructed_error; > raise reconstructed_error.maybe_user_error(ir); E hail.utils.java.FatalError: NativeIoException: readAddress(..) failed: Connection reset by peer; E ; E Java stack trace:; E io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer; E 	at ; E ; E ; E ; E Hail version: 0.2.115-330031a5d973; E Error summary: NativeIoException: readAddress(..) failed: Connection reset by peer. /usr/local/lib/python3.8/dist-packages/hail/backend/service_backend.py:477: FatalError; ------------------------------ Captured log call -------------------------------; INFO batch_client.aioclient:aioclient.py:753 created batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO backend.service_backend:java.py:190 _make_tsm: found 1000 variants after filtering out monomorphic sites.; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:7",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12980:4406,Error,Errors,4406,https://hail.is,https://github.com/hail-is/hail/issues/12980,1,['Error'],['Errors']
Availability," own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also considering modifying the `load_datasets()` function a bit to only require one `version` parameter, to be consistent with the way the version strings are formatted in `annotation_db.json`, and to avoid having to check if the version and reference genome are available separately. Something like this:. ```; mt_1kg = hl.experimental.load_dataset(name='1000_Genomes_autosomes',; version='phase_3-GRCh37', ; region='us'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9496:2494,avail,available,2494,https://hail.is,https://github.com/hail-is/hail/pull/9496,2,['avail'],['available']
Availability," pc=0x00007fa4b25e18cd, pid=6637, tid=0x00007f9a4f1fc700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-1~deb9u1-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # J 8451 C2 is.hail.annotations.Region$.loadBit(JJ)Z (33 bytes) @ 0x00007fa4b25e18cd [0x00007fa4b25e18a0+0x2d]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /tmp/cac7924b3c14494b9702ac2689c0c52d/hs_err_pid6637.log; ```; with this pipeline:; ```; def normalize_contig(input_contig: hl.expr.StringExpression) -> hl.expr.StringExpression:; return input_contig.replace(""^chr"", """"). def downsample_matrix_table(mt: hl.MatrixTable, n_divisions: int, p_threshold: float) -> hl.Table:;  mt = mt.choose_cols(list(range(10))); ; x = mt.locus.global_position(); y = -hl.log10(mt.Pvalue); ; downsampled = mt.annotate_cols(; binned=hl.agg.filter(; mt.Pvalue > p_threshold,; hl.agg.downsample(; x,; y,; label=[; normalize_contig(mt.locus.contig),; hl.str(mt.locus.position),; hl.str(mt.Pvalue),; ],; n_divisions=n_divisions; ); ),; unbinned=hl.agg.filter(; mt.Pvalue <= p_threshold,; hl.agg.collect(hl.struct(; pval=mt.Pvalue,; chrom=normalize_contig(mt.locus.contig),; pos=mt.locus.position,; ac=mt.AC,; af=mt.AF,; an=mt.N,; alleles=mt.alleles,; beta=mt.BETA,; consequence=hl.if_else(; hl.is_defined(mt.annotation),; mt.annotation,; ""N/A""; ),; gene_name=mt.gene,; is_binned=False; ); ); ); ); ; downsampled = downsampled.select_cols(; binned=downsampled.binned.map(; lambda a_bin: hl.struct(; pval=hl.float64(a_bin[2][2]),; chrom=a_bin[2][0],; pos=hl.int32(a_bin[2][1]),; ac=hl.literal(0.0),; af=hl.literal(0.0),; an=hl.literal(0),; alleles=hl.literal(['N', 'A']),; beta=hl.literal(0.0),; consequence=""N/A"",; gene_name=""N/A"",; is_binned=True,; ; ); ),; unbinned=downsampled.unbinned,; ); ; do",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8240:1175,down,downsampled,1175,https://hail.is,https://github.com/hail-is/hail/issues/8240,1,['down'],['downsampled']
Availability," recipe continues but it is also passed literally to the shell*. The docs page you linked directly addresses our use case and suggests we put the command inside of a make variable (thus triggering normal backslash-newline rules rather than the special recipe line rules). > Sometimes you want to split a long line inside of single quotes, but you dont want the backslash/newline to appear in the quoted content. This is often the case when passing scripts to languages such as Perl, where extraneous backslashes inside the script can change its meaning or even be a syntax error. One simple way of handling this is to place the quoted string, or even the entire command, into a make variable then use the variable in the recipe. In this situation the newline quoting rules for makefiles will be used, and the backslash/newline will be removed. If we rewrite our example above using this method:; > ; > ```; > HELLO = 'hello \; > world'; > ; > all : ; @echo $(HELLO); > ```; > ; > we will get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less legible than literal JSON. Putting the whole JSON array on one line is quite long. I guess we can go with double quotes for now. I tested on Make 3.81 and Make 4.4.1. The first EDIT and the original comment follow for context. ---. EDIT: Nope, I still appear to be wrong. Hold on. ---. I have bash 3.2.57; ```; (base) dking@wm28c-761 /tmp % make print-shell; /bin/sh; (base) dking@wm28c-761 /tmp % /bin/sh --version; GNU bash, version 3.2.57(1)-release (arm64-apple-darwin22); Copyright (C) 2007 Fr",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:1448,echo,echo,1448,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324,1,['echo'],['echo']
Availability," remove redundant definition of npy_nextafter [wheel build]</li>; </ul>; <h2>Checksums</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/numpy/numpy/commit/85f38ab180ece5290f64e8ddbd9cf06ad8fa4a5e""><code>85f38ab</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/23159"">#23159</a> from charris/prepare-1.24.2-release</li>; <li><a href=""https://github.com/numpy/numpy/commit/124252537f526a059b6a5ee3ac1e3bf1442bbc13""><code>1242525</code></a> REL: Prepare for the NumPy 1.24.2 release</li>; <li><a href=""https://github.com/numpy/numpy/commit/de0ee415e45b09c86d1ddc04f51c11192b1e2fe6""><code>de0ee41</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/23161"">#23161</a> from mattip/npy_nextafter</li>; <li><a href=""https://github.com/numpy/numpy/commit/ed09037473581908f6b52ecc3cabc82a414e2a54""><code>ed09037</code></a> BLD: remove redundant definition of npy_nextafter [wheel build]</li>; <li><a href=""https://github.com/numpy/numpy/commit/bc47a5ba6798a942d4a76e38f1089fc38f81f50d""><code>bc47a5b</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/23150"">#23150</a> from charris/backport-23144</li>; <li><a href=""https://github.com/numpy/numpy/commit/e5452b91b87523853b2e33c0f7f6788a9a22c1b4""><code>e5452b9</code></a> TYP,MAINT: Add a missing explicit <code>Any</code> parameter to the <code>npt.ArrayLike</code> defi...</li>; <li><a href=""https://github.com/numpy/numpy/commit/2433fe5b66016a640dd9337d9e114d7076f55861""><code>2433fe5</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/23149"">#23149</a> from charris/backport-23128</li>; <li><a href=""https://github.com/numpy/numpy/commit/8dfa47db1eb6472490b33d5f380513308f3e1a2d""><code>8dfa47d</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/23148"">#23148</a> from c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12898:4494,redundant,redundant,4494,https://hail.is,https://github.com/hail-is/hail/pull/12898,1,['redundant'],['redundant']
Availability," repeatedly getting this error on when attempting to run vep GRCh38 on a dataproc cluster started using hailctl with 25 preemptible nodes, and otherwise default params.; ```; 2019-07-14 20:54:55 TaskSetManager: INFO: Finished task 1611.1 in stage 8.0 (TID 21696) in 49183 ms on bw2-sw-dp3j.c.seqr-project.internal (executor 1) (1601/10000); 2019-07-14 20:54:57 TaskSetManager: INFO: Starting task 1559.1 in stage 8.0 (TID 21702, bw2-sw-dp3j.c.seqr-project.internal, executor 1, partition 1559, PROCESS_LOCAL, 8800 bytes); 2019-07-14 20:54:57 TaskSetManager: INFO: Finished task 1570.1 in stage 8.0 (TID 21697) in 45412 ms on bw2-sw-dp3j.c.seqr-project.internal (executor 1) (1602/10000); 2019-07-14 20:55:04 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Disabling executor 1.; 2019-07-14 20:55:04 DAGScheduler: INFO: Executor lost: 1 (epoch 0); 2019-07-14 20:55:04 BlockManagerMasterEndpoint: INFO: Trying to remove executor 1 from BlockManagerMaster.; 2019-07-14 20:55:04 TransportClient: ERROR: Failed to send RPC RPC 7115985797891097797 to /10.128.0.126:36044: java.nio.channels.ClosedChannelException; java.nio.channels.ClosedChannelException; at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source); 2019-07-14 20:55:04 BlockManagerMasterEndpoint: INFO: Removing block manager BlockManagerId(1, bw2-sw-dp3j.c.seqr-project.internal, 43693, None); 2019-07-14 20:55:04 BlockManagerMaster: INFO: Removed 1 successfully in removeExecutor; 2019-07-14 20:55:04 YarnSchedulerBackend$YarnSchedulerEndpoint: WARN: Attempted to get executor loss reason for executor id 1 at RPC address 10.128.0.126:36052, but got no response. Marking as slave lost.; java.io.IOException: Failed to send RPC RPC 7115985797891097797 to /10.128.0.126:36044: java.nio.channels.ClosedChannelException; at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:357); at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(Tra",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6635:994,ERROR,ERROR,994,https://hail.is,https://github.com/hail-is/hail/issues/6635,1,['ERROR'],['ERROR']
Availability," return decorator(_typecheck); /home/hail/hail.zip/hail/matrixtable.py in repartition(self, n_partitions, shuffle); 2505 Repartitioned dataset.; 2506 """"""; -> 2507 jvds = self._jvds.coalesce(n_partitions, shuffle); 2508 return MatrixTable(jvds); 2509 ; /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:; /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'; FatalError: AssertionError: assertion failed; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 7.0 failed 20 times, most recent failure: Lost task 4.19 in stage 7.0 (TID 601, mycluster-w-0.c.ukbb-all-phenos.internal, executor 2): java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.annotations.Region.loadAddress(Region.scala:63); at is.hail.expr.types.TBaseStruct.loadField(TBaseStruct.scala:215); at is.hail.annotations.RegionValueBuilder.addField(RegionValueBuilder.scala:335); at is.hail.annotations.RegionValueBuilder.addField(RegionValueBuilder.scala:341); at is.hail.annotations.WritableRegionValue.setSelect(WritableRegionValue.scala:38); at is.hail.rvd.OrderedRVD$$anonfun$getKeys$1$$anonfun$apply$9.apply(OrderedRVD.scala:511); at is.hail.rvd.OrderedRVD$$anonfun$getKeys$1$$anonfun$apply$9.apply(OrderedRVD.scala:510); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); at is.hail.rvd.OrderedRVPartitionInfo$.apply(OrderedRVPartit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3507:2196,failure,failure,2196,https://hail.is,https://github.com/hail-is/hail/issues/3507,1,['failure'],['failure']
Availability, scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.MatrixValue.filterSamples(Relational.scala:156); at is.hail.expr.FilterSamples.execute(Relational.scala:326); at is.hail.variant.VariantSampleMatrix.value$lzycompute(VariantSampleMatrix.scala:490); at is.hail.variant.VariantSampleMatrix.value(VariantSampleMatrix.scala:488); at is.hail.variant.VariantSampleMatrix.x$13$lzycompute(VariantSampleMatrix.scala:493); at is.hail.variant.VariantSampleMatrix.x$13(VariantSampleMatrix.scala:493); at is.hail.variant.VariantSampleMatrix.globalAnnotation$lzycompute(VariantSampleMatrix.scala:493); at is.hail.variant.VariantSampleMatrix.globalAnnotation(VariantSampleMatrix.scala:493); at is.hail.variant.VariantDatasetFunctions$.filterGenotypes$extension(VariantDataset.scala:463); at is.hail.variant.VariantDatasetFunctions.filterGenotypes(VariantDataset.scala:449); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748); ```. Hail version: 0.1-20613ed; Error summary: ClassNotFoundException: is.hail.asm4s.AsmFunction2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2966:16760,Error,Error,16760,https://hail.is,https://github.com/hail-is/hail/issues/2966,1,['Error'],['Error']
Availability," secret generic secretesfile --from-file=prod/env.txt`. The .env for the web app, where localhost would be replaced by our sub.domain. If you get it running, you may notice there isn't a way to log out... I ripped out all of the UI stuff after speaking with Cotton, and began writing a minimal interface. Just clear the cookie if you need to log out. ```; AUTH0_CLIENT_ID=TD78k23CcdM4pMWoYZwYwKJbQPBj06jY; AUTH0_DOMAIN=hail.auth0.com; AUTH0_SCOPE='opened profile repo read:users read:user_idp_tokens'; AUTH0_AUDIENCE='hail'; AUTH0_REDIRECT_URI='https://localhost/auth0callback'; SCORECARD_URL='https://scorecard.localhost/json'; SCORECARD_USER_URL='https://scorecard.localhost/json/users'; GRAPHQL_URL='https://localhost/api/graphql'; ```. The .env for the gateway; ```; AUTH0_WEB_KEY_SET_URL=https://hail.auth0.com/.well-known/jwks.json; AUTH0_AUDIENCE=hail; AUTH0_DOMAIN=https://hail.auth0.com/. AUTH0_MANAGEMENT_API_CLIENT=eqDY6HWOKd6MzC8kWCFaZUAoZgNUHypA; AUTH0_MANAGEMENT_API_SECRET=<I'll give this>; AUTH0_MANAGEMENT_API_TOKEN_URL=https://hail.auth0.com/oauth/token; AUTH0_MANAGEMENT_API_URL=https://hail.auth0.com/api/v2/users; AUTH0_MANAGEMENT_API_AUDIENCE=https://hail.auth0.com/api/v2/; ```. Organization of the web app is simple. There is a pages directory. Routes match the folder structure. Pages that don't need to maintain their own state look a lot like HTML wrapped in a function:. ```js; export default function() { <div>Hello World </div> }; ```. or in JS ES6 form:; ```js; export default () => <div>Hello World</div>; ``` . Performance is excellent. SSR should run about as fast as jinja2 (will be getting faster in 2019). Client side interactions are obviously far more performant. Bundle sizes are on a downward trajectory; react + react-dom is about as big as jQuery today, and reducing that is a focus on facebook in 2019. There are alternatives to react-dom that are under 10kb, but in practice 20kb is nothing to worry about, especially when initial load doesn't require it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-454271935:3793,down,downward,3793,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-454271935,1,['down'],['downward']
Availability," set request method and body</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/82e70cae2a8d48b4f5165a9b543d4e65bb793d88""><code>82e70ca</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86a15f1c16eb729dc71b6caf30237d07b8e0bb01""><code>86a15f1</code></a> Fix compiler warnings and deprecations</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86363072c8239330b28976109a622bdd073507b6""><code>8636307</code></a> Negative timeouts are actually not allowed</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4ff0ff0e63e0dd45f231990d0dcebffde6e6b709""><code>4ff0ff0</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a1858b494b5f3a51ccef7580c243c6dfdf520731""><code>a1858b4</code></a> Merge pull request <a href=""https://redirect.github.com/michel-kraemer/gradle-download-task/issues/295"">#295</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/c1e212c0fb41b3ea9185a9ea463fb1ea7142f748""><code>c1e212c</code></a> Add integration tests for Gradle 8.0 and 8.0.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/304f68e25f53633a92a4d2d6ce003a4986929503""><code>304f68e</code></a> Fix type inference issue</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.1...5.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.1&new-version=5.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as lo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:2158,down,download-task,2158,https://hail.is,https://github.com/hail-is/hail/pull/12893,1,['down'],['download-task']
Availability," should print a message such as:. ```; The vds ""/users/dking/projects/hail-data/profile225.vds"" cannot be read by this version of hail. It must be regenerated from the VCF source using this version of hail.; ```. Actual behavior:. ```; dking@wmb16-359 # python; >>> from hail import *; >>> hc = HailContext(); hc.reaUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; d9""/projecRunning on Apache Spark version 2.0.2; SparkUI available at http://10.10.99.215:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-6ee2919; WARNING: This is an unstable development build.; >>> hc.read(""/users/dking/projects/hail-data/profile225.vds""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-606>"", line 2, in read; File ""/Users/dking/projects/hail/python/hail/java.py"", line 121, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: MappingException: Did not find value which can be converted into java.lang.String. Java stack trace:; org.json4s.package$MappingException: No usable value for sample_schema; Did not find value which can be converted into java.lang.String; 	at org.json4s.reflect.package$.fail(package.scala:96); 	at org.json4s.Extraction$ClassInstanceBuilder.org$json4s$Extraction$ClassInstanceBuilder$$buildCtorArg(Extraction.scala:462); 	at org.json4s.Extraction$ClassInstanceBuilder$$anonfun$14.apply(Extraction.scala:482); 	at org.json4s.Extraction$ClassInstanceBuilder$$anonfun$14.apply(Extraction.scala:482); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.sc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2159:1162,Error,Error,1162,https://hail.is,https://github.com/hail-is/hail/issues/2159,1,['Error'],['Error']
Availability," simple hash-based cache: no need to walk complex graph to normalize cache, because in most cases I'm perfectly fine with not re-using cache across different queries (that may have some shared fields). Apollo does something ""smarter"", but much slower: walks a query, checks that the requested fields for a node are the same, and that the node's id is the same, as some other query. 2) no runtime validation of query shape via graphql-tag...uses simple template strings, which are free. We don't care about schema validation in the client...because the server will error when schema is invalid. This should be compile time validated instead, in this case via integration tests. Also removed react-icons... I was going to use this in place of material-design-icons, because I thought loading the full font, when I needed only a few icons, would be unnecessarily expensive. It turns out that I cannot find a library where a single icon import (react-icons or MaterialUI) is smaller than Google's entire material design font: a single font (there are several needed to cover all icons) is ~500B. A single react-icons icon is ~2KB on dev (production may be smaller due to tree shaking). Also, am opposed to CSS-in-JS: slower, worse tooling, larger. Benefits are dynamic selectors, which are really no advantage that I can see (without them can still dynamically apply classes, as in the yee ol days of pleb vanilla js). Home page down to <2kb when not logged in, and 3.1KB logged in. This includes header, simple body, and dark mode button.; <img width=""2636"" alt=""screen shot 2018-12-19 at 11 49 59 pm"" src=""https://user-images.githubusercontent.com/5543229/50264482-ed4c3000-03e8-11e9-80d1-81d195a7b37a.png"">; <img width=""2636"" alt=""screen shot 2018-12-19 at 11 50 33 pm"" src=""https://user-images.githubusercontent.com/5543229/50264483-ed4c3000-03e8-11e9-8180-1409ca16573f.png"">. edit: Further .1KB shaved (gzipped) by replacing the dark mode icon svg with a reference to the material-design-icons font.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-448868665:1517,down,down,1517,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-448868665,1,['down'],['down']
Availability," stack trace):; ```; Traceback (most recent call last):; File ""/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-53-73b5a6c78295>"", line 1, in <module>; ht.show(); File ""/Users/laurent/tools/hail-release/devel/hail.zip/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/laurent/tools/hail-release/devel/hail.zip/hail/table.py"", line 1169, in show; print(self._show(n,width, truncate, types)); File ""/Users/laurent/tools/hail-release/devel/hail.zip/hail/table.py"", line 1172, in _show; return self._jt.showString(n, joption(truncate), types, width); File ""/Users/laurent/tools/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/laurent/tools/hail-release/devel/hail.zip/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: AssertionError: assertion failed; Java stack trace:; java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:78); at is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:7); at is.hail.expr.ir.Emit$.emit(Emit.scala:42); at is.hail.expr.ir.Emit$.apply(Emit.scala:28); at is.hail.expr.ir.Compile$.apply(Compile.scala:49); at is.hail.expr.ir.Compile$.apply(Compile.scala:31); at is.hail.expr.ir.Compile$.apply(Compile.scala:62); at is.hail.expr.TableExplode.execute(Relational.scala:2201); at is.hail.expr.TableUnkey.execute(Relational.scala:1883); at is.hail.expr.TableMapRows.execute(Relational.scala:2090); at is.hail.expr.TableKeyBy.execute(Relational.scala:1846); at is.hail.expr.TableMapRows.execute(Relational.scala:2090); at is.hail.table.Table.value$lzycompute(Table.scala:243); at is.hail.table.Table.value(Table.scala:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3744:2509,Error,Error,2509,https://hail.is,https://github.com/hail-is/hail/issues/3744,1,['Error'],['Error']
Availability," that I can tell between the current build and the previous times I've tried. 1. I was using a local installation of spark when it worked, whereas now I am using the HPC's version of spark 2.1.0. However, it passed the tests just fine when I was using a local copy of spark 2.0.2 on both my laptop and HPC. . 2. Initially I followed the recommendations on the doc pages to setup the python path references to py4j under `alias hail=""PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.4-src.zip:$HAIL_HOME/python SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar python""` This perhaps didn't export the PYTHONPATH to the py4j 10.4 .zip library if I hadn't run the `hail` command before I tried testing. My initial reaction was to just install a local copy of py4j via pip in my local copy of python since the tests were failing out with complaints about missing py4j module. That worked to get a little farther in the test script, to the point where it was failing out with the breeze function. But, since then I've re-jiggered the PYTHONPATH in the .bash_profile to always be defined to point to the SPARK_HOME version of py4j. This doesn't seem like it would be a problem as the py4j versions via pip and and SPARK_HOME are both 10.4, and moreover this setup worked with spark 2.0.2, but a possible confound. Perhaps change the getting started docs so the PYTHONPATH is always defined to point to the spark version of py4j?. Anyway, here are the current paths as you requested. . `echo $SPARK_HOME /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7`. `echo $PYTHONPATH; /home/stockham/bin/python/Python-2.7.12:/share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python:/share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip:/scratch/PI/dpwall/computeEnvironments/hail/python`. `echo $HAIL_HOME; /scratch/PI/dpwall/computeEnvironments/hail`. Thank you, and if you have any ideas why the above tests are failing I would love to hear it. Thanks again.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1419#issuecomment-281846721:2319,echo,echo,2319,https://hail.is,https://github.com/hail-is/hail/issues/1419#issuecomment-281846721,3,['echo'],['echo']
Availability," the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 		at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		... 48 more; Caused by: com.google.api.client.http.HttpResponseException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 	at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-que",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:27268,error,error,27268,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['error'],['error']
Availability," the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceb",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:9387,error,error,9387,https://hail.is,https://github.com/hail-is/hail/issues/9939,2,['error'],['error']
Availability," the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-5b299ddae758. ### What you did:. ```; conc.describe(); ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'locus': locus<GRCh37> ; 'alleles': array<str> ; 'a_index': int32 ; 'was_split': bool ; 'concordance': array<struct {; concordance_matrix: struct {; n_discordant: int64, ; concordance: array<array<int64>>; }, ; meta: dict<str, str>; }> ; 'metrics': array<struct {; score: float64, ; positive_train: bool, ; negative_train: bool, ; rank: int64, ; meta: dict<str, str>; }> ; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. conc.aggregate(hl.agg.count_where(hl.sum(conc.concordance[0].concordance_matrix.concordance[:2].map(lambda x: hl.sum(x[:2])))>0)). ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-143-c80e74dd23d2> in <module>(); ----> 1 conc.aggregate(hl.agg.count_where(hl.sum(conc.concordance[0].concordance_matrix.concordance[:2].map(lambda x: hl.sum(x[:2])))>0)). /home/hail/hail.zip/hail/table.py in aggregate(self, expr); 1107 analyze('Table.aggregate', expr, self._global_indices, {self._row_axis}); 1108 ; -> 1109 result_json = base._jt.aggregateJSON(expr._ast.to_hql()); 1110 return expr.dtype._from_json(result_json); 1111 . /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalE",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3729:1078,error,error,1078,https://hail.is,https://github.com/hail-is/hail/issues/3729,1,['error'],['error']
Availability," the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; sphinx 5.3.0 has requirement docutils<0.20,>=0.14, but you have docutils 0.20.1.; sphinx-rtd-theme 1.3.0 has requirement docutils<0.19, but you have docutils 0.20.1.; notebook 6.5.6 has requirement pyzmq<25,>=17, but you have pyzmq 25.1.1.; matplotlib 3.5.3 requires numpy, which is not installed.; matplotlib 3.5.3 requires pillow, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13871:1291,avail,available,1291,https://hail.is,https://github.com/hail-is/hail/pull/13871,1,['avail'],['available']
Availability," the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2; ### What you did:. 1. edited build.gradle to it will accept my spark version like this if (sparkVersion == '2.2.0.2.6.3.0-235') {. 2. Then I ran ./gradlew -Dspark.version=2.2.0.2.6.3.0-235 shadowJar archiveZip command. ### What went wrong (all error messages here, including the full java stack trace):; bild fails. ```; [luffy@wp-hdp-ctrl03 hail]$ ./gradlew -Dspark.version=2.2.0.2.6.3.0-235 shadowJar archiveZip --stacktrace; 1f253167d53c; :compileJava UP-TO-DATE; :generateBuildInfo; :nativeLib; tar -xzf libsimdpp-2.0-rc2.tar.gz; g++ -O3 -march=native -g -std=c++11 -Ilibsimdpp-2.0-rc2 -Wall -Werror -fPIC -ggdb -c -o ibs.o ibs.cpp; cc1plus: error: unrecognized command line option ""-std=c++11""; make: *** [ibs.o] Error 1; :nativeLib FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':nativeLib'.; > Process 'command 'make'' finished with non-zero exit value 2. * Try:; Run with --info or --debug option to get more log output. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':nativeLib'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:69); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35); at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:66); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3705:1005,FAILURE,FAILURE,1005,https://hail.is,https://github.com/hail-is/hail/issues/3705,1,['FAILURE'],['FAILURE']
Availability," this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; jupyter 1.0.0 requires qtconsole, which is not installed.; jupyter 1.0.0 requires notebook, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed.; argon2-cffi-bindings 21.2.0 requires cffi, which is not installed.; aiohttp-devtools 1.1 requires watchfiles, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14042:1279,avail,available,1279,https://hail.is,https://github.com/hail-is/hail/pull/14042,1,['avail'],['available']
Availability," thought I'd let you know in case you hit this issue. ```; ../conda/envs/glow/lib/python3.7/site-packages/bokeh/core/templates.py:43: in <module>; from jinja2 import Environment, Markup, FileSystemLoader; E ImportError: cannot import name 'Markup' from 'jinja2' (/home/circleci/conda/envs/lib/python3.7/site-packages/jinja2/__init__.py); [error] java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; [error] 	at scala.Predef$.require(Predef.scala:281); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14(build.sbt:288); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14$adapted(build.sbt:278); [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49); [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62); [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67); [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:280); [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19); [error] 	at sbt.Execute.work(Execute.scala:289); [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:280); [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); [error] 	at java.lang.Thread.run(Thread.java:748); [error] (hail / hailtest) java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; ```. To report a bug, fill in the information below. ; For support and feature requests, please use",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705:1468,Error,ErrorHandling,1468,https://hail.is,https://github.com/hail-is/hail/issues/11705,1,['Error'],['ErrorHandling']
Availability," timed); 97 # print(self._hail_package.expr.ir.Pretty.apply(jir, True, -1)); 98 try:; ---> 99 result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); 100 (result, timings) = (result_tuple._1(), result_tuple._2()); 101 value = ir.typ._from_encoding(result). /opt/conda/lib/python3.7/site-packages/py4j/java_gateway.py in __call__(self, *args); 1321 answer = self.gateway_client.send_command(command); 1322 return_value = get_return_value(; -> 1323 answer, self.gateway_client, self.target_id, self.name); 1324 ; 1325 for temp_arg in temp_args:. /opt/conda/lib/python3.7/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 29 tpl = Env.jutils().handleForPython(e.java_exception); 30 deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); ---> 31 raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; 32 except pyspark.sql.utils.CapturedException as e:; 33 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.4 in stage 1.0 (TID 10) (all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_e01_1690206305672_0001_01_000007 on host: all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal. Exit status: 137. Diagnostics: [2023-07-24 13:52:49.515]Container killed on request. Exit code is 137; [2023-07-24 13:52:49.517]Container exited with a non-zero exit code 137. ; [2023-07-24 13:52:49.518]Killed by external signal; .; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.4 in stage 1.0 (TID 10) (all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad no",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287:5027,failure,failure,5027,https://hail.is,https://github.com/hail-is/hail/issues/13287,1,['failure'],['failure']
Availability," timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:33,503	job_private.py	schedule_jobs_loop_body:142	starting scheduling jobs for jpim job-private; INFO	2022-03-02 19:06:33,533	job_private.py	schedule_jobs_loop_body:186	scheduled 0 jobs for jpim job-private; INFO	2022-03-02 19:06:34,964	pool.py	create_instances:244	pool highcpu n_instances 0 {'pending': 0, 'active': 0, 'inactive': 0, 'deleted': 0} free_cores 0.0 live_free_cores 0.0 ready_cores 0.0; ERROR	2022-03-02 19:06:35,376	job.py	schedule_job:473	error while scheduling job (94, 2) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/li",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:5350,ERROR,ERROR,5350,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['ERROR'],['ERROR']
Availability," to <code>*string</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104624"">kubernetes/kubernetes#104624</a>, <a href=""https://github.com/Haleygo""><code>@Haleygo</code></a>)</li>; <li>Kubernetes is now built using go 1.17. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/103692"">kubernetes/kubernetes#103692</a>, <a href=""https://github.com/justaugustus""><code>@justaugustus</code></a>)</li>; <li>Performs strict server side schema validation requests via the <code>fieldValidation=[Strict,Warn,Ignore]</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105916"">kubernetes/kubernetes#105916</a>, <a href=""https://github.com/kevindelgado""><code>@kevindelgado</code></a>)</li>; <li>Promote <code>IPv6DualStack</code> feature to stable.; Controller Manager flags for the node IPAM controller have slightly changed:; <ol>; <li>When configuring a dual-stack cluster, the user must specify both <code>--node-cidr-mask-size-ipv4</code> and <code>--node-cidr-mask-size-ipv6</code> to set the per-node IP mask sizes, instead of the previous <code>--node-cidr-mask-size</code> flag.</li>; <li>The <code>--node-cidr-mask-size</code> flag is mutually exclusive with <code>--node-cidr-mask-size-ipv4</code> and <code>--node-cidr-mask-size-ipv6</code>.</li>; <li>Single-stack clusters do not need to change, but may choose to use the more specific flags. Users can use either the older <code>--node-cidr-mask-size</code> flag or one of the newer <code>--node-cidr-mask-size-ipv4</code> or <code>--node-cidr-mask-size-ipv6</code> flags to configure the per-node IP mask size, provided that the flag's IP family matches the cluster's IP family (--cluster-cidr). (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104691"">kubernetes/kubernetes#104691</a>, <a href=""https://github.com/khenidak""><code>@khenidak</code></a>)</li>; </ol>; </li>; <li>Remove <code>NodeLease</code> feature gate that ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:10612,mask,mask-size-,10612,https://hail.is,https://github.com/hail-is/hail/pull/11957,4,['mask'],"['mask', 'mask-size', 'mask-size-']"
Availability," to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9822:1158,error,error,1158,https://hail.is,https://github.com/hail-is/hail/pull/9822,1,['error'],['error']
Availability," transient and may be solved by bokeh / jinja2 folks but thought I'd let you know in case you hit this issue. ```; ../conda/envs/glow/lib/python3.7/site-packages/bokeh/core/templates.py:43: in <module>; from jinja2 import Environment, Markup, FileSystemLoader; E ImportError: cannot import name 'Markup' from 'jinja2' (/home/circleci/conda/envs/lib/python3.7/site-packages/jinja2/__init__.py); [error] java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; [error] 	at scala.Predef$.require(Predef.scala:281); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14(build.sbt:288); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14$adapted(build.sbt:278); [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49); [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62); [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67); [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:280); [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19); [error] 	at sbt.Execute.work(Execute.scala:289); [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:280); [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); [error] 	at java.lang.Thread.run(Thread.java:748); [error] (hail / hailtest) java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; ```. To report a bug, fill in the informati",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705:1412,error,error,1412,https://hail.is,https://github.com/hail-is/hail/issues/11705,1,['error'],['error']
Availability," typ; self._compute_type(); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/ir/matrix_ir.py"", line 40, in _compute_type; self._type = Env.backend().matrix_type(self); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/backend/backend.py"", line 121, in matrix_type; jir = self._to_java_ir(mir); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/backend/backend.py"", line 102, in _to_java_ir; ir._jir = ir.parse(r(ir), ir_map=r.jirs); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/ir/base_ir.py"", line 163, in parse; return Env.hail().expr.ir.IRParser.parse_matrix_ir(code, ref_map, ir_map); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/utils/java.py"", line 240, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: MatchError: 17 (of class java.lang.Integer). Java stack trace:; scala.MatchError: 17 (of class java.lang.Integer); 	at org.json4s.scalap.scalasig.ClassFileParser$$anonfun$37.apply(ClassFileParser.scala:119); 	at org.json4s.scalap.scalasig.ClassFileParser$$anonfun$37.apply(ClassFileParser.scala:119); 	at org.json4s.scalap.Rule$$anonfun$flatMap$1.apply(Rule.scala:33); 	at org.json4s.scalap.Rule$$anonfun$flatMap$1.apply(Rule.scala:32); 	at org.json4s.scalap.Rule$$anonfun$mapResult$1.apply(Rule.scala:43); 	at org.json4s.scalap.Rule$$anonfun$mapResult$1.apply(Rule.scala:43); 	at org.json4s.scalap.Rules$DefaultRule.apply(Rules.scala:67); 	at org.json4s.scalap.Rules$DefaultRule.apply(Rules.scala:65); 	at org.json4s.scalap.StateRules$class.rep$2(Rules.scala:137); 	at org.json4s.scalap.StateRules$$anonfun$repeatUntil$1.apply(Rules.scala:143); 	at org.json4s.scalap.StateRules$$anonfun$repeatUntil$1.app",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6299:8873,Error,Error,8873,https://hail.is,https://github.com/hail-is/hail/issues/6299,1,['Error'],['Error']
Availability," url, **kwargs); usr/local/lib/python3.9/dist-packages/hailtop/aiocloud/common/session.py:105: in request; return await retry_transient_errors(self._request_with_valid_authn, method, url, **kwargs); usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py:780: in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py:796: in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); usr/local/lib/python3.9/dist-packages/hailtop/aiocloud/common/session.py:117: in _request_with_valid_authn; return await self._http_session.request(method, url, **kwargs); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. async def request_and_raise_for_status():; json_data = kwargs.pop('json', None); if json_data is not None:; if kwargs.get('data') is not None:; raise ValueError('data and json parameters cannot be used at the same time'); kwargs['data'] = aiohttp.BytesPayload(; value=orjson.dumps(json_data),; # https://github.com/ijl/orjson#serialize; #; # ""The output is a bytes object containing UTF-8""; encoding=""utf-8"",; content_type=""application/json"",; ); resp = await self.client_session._request(method, url, **kwargs); if raise_for_status:; if resp.status >= 400:; # reason should always be not None for a started response; assert resp.reason is not None; body = (await resp.read()).decode(); await resp.release(); > raise ClientResponseError(; resp.request_info,; resp.history,; status=resp.status,; message=resp.reason,; headers=resp.headers,; body=body,; ); E hailtop.httpx.ClientResponseError: 400, message='Bad Request', url=URL('http://internal.hail/pr-14351-default-yojxd4mck4io/batch/api/v1alpha/batches/321/update-fast') body=""400: error while inserting job group 1 into batch 321: (1213, 'Deadlock found when trying to get lock; try restarting transaction')""; ```. ### Version. 0.2.128. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14413:3740,error,error,3740,https://hail.is,https://github.com/hail-is/hail/issues/14413,1,['error'],['error']
Availability," used by multiple threads. This fixes an issue that could cause an <code>IllegalStateException</code> with the message <code>Connection is still allocated</code>. Thanks to <a href=""https://github.com/dmarks2""><code>@dmarks2</code></a> for spotting this.</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>eachFile</code> method that adds an action to be applied to each source URL before it is downloaded. The action can be used to modify the filename of the target file.</li>; <li>Add <code>runAsync</code> method to download extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https:/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:2167,down,download-task,2167,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download-task']
Availability," used by multiple threads. This fixes an issue that could cause an <code>IllegalStateException</code> with the message <code>Connection is still allocated</code>. Thanks to <a href=""https://github.com/dmarks2""><code>@dmarks2</code></a> for spotting this.</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>eachFile</code> method that adds an action to be applied to each source URL before it is downloaded. The action can be used to modify the filename of the target file.</li>; <li>Add <code>runAsync</code> method to download extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.5</h2>; <p>Maintenance:</p>; <ul>; <li>Publish signed artifacts to Gradle plugin portal</li>; <li>Update dependencies</li>; </ul>; <h2>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:1448,down,download-task,1448,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['down'],['download-task']
Availability," v0.23, pytest-asyncio attaches an asyncio event loop to each item of the test suite (i.e. session, packages, modules, classes, functions) and allows tests to be run in those loops when marked accordingly. Pytest-asyncio currently assumes that async fixture scope is correlated with the new event loop scope. This prevents fixtures from being evaluated independently from the event loop scope and breaks some existing test suites (see <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/706"">#706</a>). For example, a test suite may require all fixtures and tests to run in the same event loop, but have async fixtures that are set up and torn down for each module. If you're affected by this issue, please continue using the v0.21 release, until it is resolved.</p>; <h2>pytest-asyncio 0.23.5.post1</h2>; <h1>0.23.5 (2024-02-09)</h1>; <ul>; <li>Declare compatibility with pytest 8 <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/737"">#737</a></li>; <li>Fix typing errors with recent versions of mypy <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/769"">#769</a></li>; <li>Prevent DeprecationWarning about internal use of <code>asyncio.get_event_loop()</code> from affecting test cases <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/757"">#757</a></li>; </ul>; <h2>Known issues</h2>; <p>As of v0.23, pytest-asyncio attaches an asyncio event loop to each item of the test suite (i.e. session, packages, modules, classes, functions) and allows tests to be run in those loops when marked accordingly. Pytest-asyncio currently assumes that async fixture scope is correlated with the new event loop scope. This prevents fixtures from being evaluated independently from the event loop scope and breaks some existing test suites (see <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/706"">#706</a>). For example, a test suite may require all fixtures and tests to run in the same event loop, but have as",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14507:1514,error,errors,1514,https://hail.is,https://github.com/hail-is/hail/pull/14507,1,['error'],['errors']
Availability," with 354 partitions; 	Traceback (most recent call last):; 	 File ""test_11_cluster_sampleqc.py"", line 20, in <module>; 		print(""\n[PASS] with"", N, ""partitions:"", Y.count()); 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/matrixtable.py"", line 2426, in count; 		return Env.backend().execute(count_ir); 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/backend/spark_backend.py"", line 296, in execute; 		result = json.loads(self._jhc.backend().executeJSON(jir)); 	 File ""/bmrn/apps/spark/2.4.5/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/backend/spark_backend.py"", line 41, in deco; 		'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 	hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: ResultStage 9 (runJob at RVD.scala:688) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:882) at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:878) at scala.collection.Iterator$class.foreach(Iterator.scala:891) at scala.collection.AbstractIterator.foreach(Iterator.scala:1334) at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:878) at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:691) at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:3888,failure,failure,3888,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['failure'],['failure']
Availability," write; Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 103, in execute; bucket=self._bucket); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 48, in request; return async_to_blocking(retry_transient_errors(self.async_request, endpoint, **data)); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 114, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/Users/dking/miniconda3/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 379, in retry_transient_errors; return await f(*args, **kwargs); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 44, in async_request; raise FatalError(f'Error from server: {result[""value""]}'); FatalError: Error from server: java.util.NoSuchElementException: key not found: RefEquality(WriteMetadata(Let(__iruid_465,CollectDistributedArray(StreamZip(ArrayBuffer(MakeStream(ArrayBuffer(Literal(struct{start: int32, end: int32},[0,10]), Literal(struct{start: int32, end: int32},[10,20]), Literal(struct{start: int32, end: int32},[20,30]), Literal(struct{start: int32, end: int32},[30,40]), Literal(struct{start: int32, end: int32},[40,50]), Literal(struct{start: int32, end: int32},[50,60]), Literal(struct{start: int32, end: int32},[60,70]), Literal(struct{start: int32, end: int32},[70,80]), Literal(struct{start: int32, end: int32},[80,90]), Literal(struct{start: int32, end: int32},[90,100])),stream<struct{start: int32, end: int32}>,false), MakeStream(ArrayBuffer(Str(""part-00-""), Str(""part-01-""), Str(""part-02-""), Str(""part-03-""), Str(""part-04-""), Str(""part-05-""), Str(""part-06-""), Str(""part-07-""), Str(""part-08-""), Str(""part-09-"")),stream<str>,false)),ArrayBuffe",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9856#issuecomment-756194693:1903,Error,Error,1903,https://hail.is,https://github.com/hail-is/hail/issues/9856#issuecomment-756194693,2,['Error'],['Error']
Availability," write; Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 103, in execute; bucket=self._bucket); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 48, in request; return async_to_blocking(retry_transient_errors(self.async_request, endpoint, **data)); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 116, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/Users/dking/miniconda3/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 395, in retry_transient_errors; return await f(*args, **kwargs); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 44, in async_request; raise FatalError(f'Error from server: {result[""value""]}'); FatalError: Error from server: java.util.NoSuchElementException: key not found: RefEquality(WriteMetadata(Let(__iruid_369,CollectDistributedArray(StreamZip(ArrayBuffer(MakeStream(ArrayBuffer(Literal(struct{start: int32, end: int32},[0,10]), Literal(struct{start: int32, end: int32},[10,20]), Literal(struct{start: int32, end: int32},[20,30]), Literal(struct{start: int32, end: int32},[30,40]), Literal(struct{start: int32, end: int32},[40,50]), Literal(struct{start: int32, end: int32},[50,60]), Literal(struct{start: int32, end: int32},[60,70]), Literal(struct{start: int32, end: int32},[70,80]), Literal(struct{start: int32, end: int32},[80,90]), Literal(struct{start: int32, end: int32},[90,100])),stream<struct{start: int32, end: int32}>,false), MakeStream(ArrayBuffer(Str(""part-00-""), Str(""part-01-""), Str(""part-02-""), Str(""part-03-""), Str(""part-04-""), Str(""part-05-""), Str(""part-06-""), Str(""part-07-""), Str(""part-08-""), Str(""part-09-"")),stream<str>,false)),ArrayBuffe",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9856#issuecomment-772011601:2183,Error,Error,2183,https://hail.is,https://github.com/hail-is/hail/issues/9856#issuecomment-772011601,2,['Error'],['Error']
Availability," wrong (all error messages here, including the full java stack trace):. ```; Error; Traceback (most recent call last):; File ""/Users/jbloom/anaconda/envs/py36/lib/python3.6/unittest/case.py"", line 59, in testPartExecutor; yield; File ""/Users/jbloom/anaconda/envs/py36/lib/python3.6/unittest/case.py"", line 605, in run; testMethod(); File ""/Users/jbloom/hail/python/hail/tests/test_api.py"", line 1557, in test_force_bug; b=mt2[mt.row_idx, mt.col_idx].x)._force_count_rows(); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 1171, in select_entries; return self._select_entries(""MatrixTable.select_entries"", hl.struct(**entry)); File ""/Users/jbloom/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2844, in _select_entries; base, cleanup = self._process_joins(s); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2503, in _process_joins; return process_joins(self, exprs, broadcast_f); File ""/Users/jbloom/hail/python/hail/utils/misc.py"", line 356, in process_joins; left = j.join_func(left); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2414, in joiner; col_exprs = {col_uid: src_cols_indexed.index(*col_exprs)[col_uid]}); File ""/Users/jbloom/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2443, in _annotate_all; analyze(""MatrixTable.annotate_rows"", row_struct, self._row_indices); File ""/Users/jbloom/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/jbloom/hail/python/hail/expr/expressions/expression_utils.py"", line 105, in analyze; raise errors[0]; hail.expr.expressions.base_expression.ExpressionException: MatrixTable.annotate_rows expects an expression from source <hail.matrixtable.MatrixTable object at 0x10889c908>, found expression derived from <hail.matrixtable.MatrixTable object at 0x108acbf60>; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3763:2881,error,errors,2881,https://hail.is,https://github.com/hail-is/hail/issues/3763,1,['error'],['errors']
Availability,"![Finally.](https://media.giphy.com/media/yIsbuPCEOgNHO/giphy.gif). - update endpoints to handle the ""zen"" that GitHub sends when a web hook is created. - update `make run-local` and friends for the new IP of the `dk-test` micro instance. - remove the unused `refresh_statuses` (this was intended to recover build state from github's commit statuses, but the commit status description is limited to like 120 characters, so I gave up on this a while ago, but never removed the code). - `.strip()` the GitHub token in case there are newlines. - print the SHA being deployed in the log statement. - add `hail-ci-build.sh` to CI, which just invokes `make test-in-cluster`(which in turn runs `test-in-cluster.sh`. - `test-in-cluster.sh` copies the secrets for testing to the expected locations and exposes the pod in which it is running with an internal service, recent changes to `site` [redirect sub URLs of ci.test.is to services named using this scheme](https://github.com/hail-is/hail/blob/master/site/hail.nginx.conf#L38-L41). GitHub uses these URLs to send updates to the CI under test about the watched repositories. - `test-locally.sh` now installs `../batch` into the currently running `pip` before testing (NB: if you edit batch and run the tests without committing the changes you've made to batch, this will pass tests but fail when pushed to a PR!). - `test-locally.sh` activates the `hail-ci` conda environment itself because it was not being propagated from the `Makefile`. I don't know why, but this is a simple fix. - `test-locally.sh` starts the ci after the repository is created. CI will print error messages if a watched repository doesn't exist. - `test/test-ci.py` now uses access tokens for all interaction with GitHub, previously it relied on the latent privileges that I and Cotton had in our environments. - `test/test-ci.py` uses a temporary, but not automatically deleted, directory when the environment variable `IN_CLUSTER` is set to `true` (to which it is set by `test-in-c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4474:300,recover,recover,300,https://hail.is,https://github.com/hail-is/hail/pull/4474,1,['recover'],['recover']
Availability,"![Screen Shot 2022-06-10 at 10 08 59 AM](https://user-images.githubusercontent.com/106194/173083939-aea57012-ddcc-4240-9ad0-55163eb6df04.png). Average utilization is marginally improved (maybe 2.5% -> 5%), but total number of wasted cores goes way down because the total number of cores is 16 rather than 16 * 8 = 128. This also suggests the autoscaler/scheduler could be made substantially smarter.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11902#issuecomment-1152405036:248,down,down,248,https://hail.is,https://github.com/hail-is/hail/pull/11902#issuecomment-1152405036,1,['down'],['down']
Availability,""" height=""0""/>;  [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr).  [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings).  [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""4d1e728e-269c-49a2-a2d0-bf1c04966e29"",""prPublicId"":""4d1e728e-269c-49a2-a2d0-bf1c04966e29"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr);  [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr);  [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14026:6284,avail,available,6284,https://hail.is,https://github.com/hail-is/hail/pull/14026,1,['avail'],['available']
Availability,""", line 215, in main; status = self.run(options, args); File ""/usr/lib/python3/dist-packages/pip/commands/install.py"", line 342, in run; requirement_set.prepare_files(finder); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 821, in unpack_url; hashes=hashes; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 659, in unpack_http_url; hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 882, in _download_http_url; _download_url(resp, link, content_file, hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 603, in _download_url; hashes.check_against_chunks(downloaded_chunks); File ""/usr/lib/python3/dist-packages/pip/utils/hashes.py"", line 46, in check_against_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 571, in written_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/utils/ui.py"", line 139, in iter; for x in it:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 560, in resp_read; decode_content=False):; File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 436, in stream; data = self.read(amt=amt, decode_content=decode_content); File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 401, in read; raise IncompleteRead(self._fp_bytes_read, self.length_remaining); File ""/usr/lib/python3.6/contextlib.py"", line 99, in __exit__; self.gen.throw(type, value, traceback); File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 307, in _error_catcher; raise ReadTimeoutError(self._pool, None, 'Read timed out.'); urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhoste",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8390:2089,down,download,2089,https://hail.is,https://github.com/hail-is/hail/issues/8390,1,['down'],['download']
Availability,""",""from"":""0.8.4"",""to"":""2.0.3""},{""name"":""nbconvert"",""from"":""5.6.1"",""to"":""6.3.0b0""},{""name"":""notebook"",""from"":""5.7.16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr);  [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr);  [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13835:10845,avail,available,10845,https://hail.is,https://github.com/hail-is/hail/pull/13835,1,['avail'],['available']
Availability,""",""from"":""0.8.4"",""to"":""2.0.3""},{""name"":""nbconvert"",""from"":""5.6.1"",""to"":""6.3.0b0""},{""name"":""notebook"",""from"":""5.7.16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr);  [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr);  [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13866:10871,avail,available,10871,https://hail.is,https://github.com/hail-is/hail/pull/13866,1,['avail'],['available']
Availability,"""/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2963, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-9-304965820738>"", line 1, in <module>; x.key_by('y').show(); File ""<decorator-gen-598>"", line 2, in show; File ""/Users/konradk/Dropbox/src/python/hail/typecheck/check.py"", line 486, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/Users/konradk/Dropbox/src/python/hail/table.py"", line 1101, in show; print(self._show(n,width, truncate, types)); File ""/Users/konradk/Dropbox/src/python/hail/table.py"", line 1104, in _show; return self._jt.showString(n, joption(truncate), types, width); File ""/Users/konradk/programs/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/konradk/Dropbox/src/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: AssertionError: assertion failed; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 49, localhost, executor driver): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:926); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:349); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:433); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:433); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.sparkextras.C",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3516:1546,Error,Error,1546,https://hail.is,https://github.com/hail-is/hail/issues/3516,1,['Error'],['Error']
Availability,"""/tmp/3c5f402fed564ccd85257c0919d4bffb/assign_subpops.py"", line 157, in <module>; main(args); File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/assign_subpops.py"", line 98, in main; pca_mt = hl.ld_prune(pca_mt, r2=0.1, n_cores=args.num_cores); File ""<decorator-gen-788>"", line 2, in ld_prune; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/typecheck/check.py"", line 490, in _typecheck; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/methods/statgen.py"", line 2918, in ld_prune; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 530 in stage 9.0 failed 20 times, most recent failure: Lost task 530.19 in stage 9.0 (TID 19101, gt1-w-78.c.broad-mpg-gnomad.internal, executor 199): java.lang.ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:643); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9$$anonfun$apply$10.apply(RVD.scala:222); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9$$anonfun$apply$10.apply(RVD.scala:221); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:221); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:220); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collectio",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:1084,failure,failure,1084,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627,1,['failure'],['failure']
Availability,"""/tmp/a913d6ce5b814a63ad7af31060416237/pyscripts_Xr0D99.zip/gnomad_hail/slack_utils.py"", line 77, in try_slack; File ""/tmp/a913d6ce5b814a63ad7af31060416237/generate_qc_annotations.py"", line 247, in main; generate_call_stats(mt).write(annotations_mt_path(data_type, 'call_stats'), args.overwrite); File ""<decorator-gen-556>"", line 2, in write; File ""/tmp/a913d6ce5b814a63ad7af31060416237/hail-devel-a1d6ecc71ce3.zip/hail/typecheck/check.py"", line 481, in _typecheck; File ""/tmp/a913d6ce5b814a63ad7af31060416237/hail-devel-a1d6ecc71ce3.zip/hail/matrixtable.py"", line 2027, in write; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/a913d6ce5b814a63ad7af31060416237/hail-devel-a1d6ecc71ce3.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: IllegalArgumentException: requirement failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 9716 in stage 1.0 failed 20 times, most recent failure: Lost task 9716.19 in stage 1.0 (TID 10060, exomes3-sw-dfpw.c.broad-mpg-gnomad.internal, executor 134): java.lang.IllegalArgumentException: requirement failed; 	at scala.Predef$.require(Predef.scala:212); 	at is.hail.variant.Call$.alleleByIndex(Call.scala:128); 	at is.hail.expr.FunctionRegistry$$anonfun$11.apply$mcIII$sp(FunctionRegistry.scala:685); 	at is.hail.expr.FunctionRegistry$$anonfun$11.apply(FunctionRegistry.scala:685); 	at is.hail.expr.FunctionRegistry$$anonfun$11.apply(FunctionRegistry.scala:685); 	at is.hail.expr.BinaryFun.apply(Fun.scala:122); 	at is.hail.codegen.generated.C9.apply(Unknown Source); 	at is.hail.codegen.generated.C9.apply(Unknown Source); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:84); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:82); 	at is.hail.expr.Parser$$anonfun$is$hail$expr$Parser$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail.variant.MatrixTable$$anonfun$selectEntries$2.apply(MatrixTable",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:1688,failure,failure,1688,https://hail.is,https://github.com/hail-is/hail/issues/3465,1,['failure'],['failure']
Availability,"""/usr/lib/python3.6/json/encoder.py\"", line 180, in default\n o.__class__.__name__)\nTypeError: Object of type 'datetime' is not JSON serializable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:21:06,541"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:21:41,499"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:22:42,128"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6707:3834,ERROR,ERROR,3834,https://hail.is,https://github.com/hail-is/hail/issues/6707,1,['ERROR'],['ERROR']
Availability,"""/usr/local/lib/python3.6/dist-packages/hailtop/utils/utils.py"", line 33, in blocking_to_async; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/lib/python3.6/concurrent/futures/thread.py"", line 56, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/lib/python3.6/dist-packages/hailtop/utils/utils.py"", line 33, in <lambda>; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/local/lib/python3.6/dist-packages/batch/google_storage.py"", line 53, in _read_gs_file; content = f.download_as_string(); File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 697, in download_as_string; self.download_to_file(string_buffer, client=client, start=start, end=end); File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 638, in download_to_file; _raise_from_invalid_response(exc); File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 2034, in _raise_from_invalid_response; raise exceptions.from_http_status(response.status_code, message, response=response); google.api_core.exceptions.Forbidden: 403 GET https://www.googleapis.com/download/storage/v1/b/hail-batch2-nru9x/o/cd50b95a89914efb897965a5e982a29d%2F1%2F1%2Fsetup%2Fjob.log?alt=media: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>); ```. - The first error is caused by the driver object is only available on the batch2-driver instance. Now the front end sends a request to the driver to get the logs if the job is running. I purposefully left the driver and front end calling the same function in case the job terminates before the driver handles the request from the front end. - Unified the Instance_ID between the front_end and the driver. I thought this was causing the second bug where gcs was unauthorized, but Tim was running in the default namespace, so they had the same instance id. - I checked and we're loading the same gsa-key in both the front end and driver.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7412:5608,down,download,5608,https://hail.is,https://github.com/hail-is/hail/pull/7412,3,"['avail', 'down', 'error']","['available', 'download', 'error']"
Availability,"""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:35,400	job.py	schedule_job:473	error while scheduling job (93, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:7409,error,error,7409,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['error'],['error']
Availability,"""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,364	job.py	schedule_job:473	error while scheduling job (90, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:11910,error,error,11910,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['error'],['error']
Availability,"""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,390	job.py	schedule_job:473	error while scheduling job (97, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:13915,error,error,13915,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['error'],['error']
Availability,"""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:39,193	job.py	schedule_job:473	error while scheduling job (99, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:22075,error,error,22075,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['error'],['error']
Availability,""":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.30.0"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JINJA2-6150717"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PROMPTTOOLKIT-6141120"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494,539,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr);  [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr);  [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14257:12275,avail,available,12275,https://hail.is,https://github.com/hail-is/hail/pull/14257,1,['avail'],['available']
Availability,""":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""40.5.0"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.32.2"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JINJA2-6150717"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PROMPTTOOLKIT-6141120"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494,539,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr);  [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr);  [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14364:12628,avail,available,12628,https://hail.is,https://github.com/hail-is/hail/pull/14364,1,['avail'],['available']
Availability,""":\""chr20\"",\""position\"":17994753},\""alleles\"":[\""A\"",\""<NON_REF>\""]},\""includeStart\"":true,\""includeEnd\"":true},{\""start\"":{\""locus\"":{\""contig\"":\""chr20\"",\""position\"":17994753},\""alleles\"":[\""A\"",\""<NON_REF>\""]},\""end\"":{\""locus\"":{\""cont...""] ; !s20 = ToStream(%29) [False]; !s21 = StreamMap(!s20) { (%elt10) =>; SelectFields(%elt10) [; (partitionCounts distinctlyKeyed firstKey; lastKey)]; }; !37 = ToArray(!s21); !38 = WriteMetadata(!37) [""{\""name\"":\""TableSpecWriter\"",\""path\"":\""/tmp/foo.ht\"",\""typ\"":{\""rowType\"":\""Struct{locus:Locus(GRCh38),alleles:Array[String],data:Array[Struct{}]}\"",\""key\"":[\""locus\"",\""alleles\""],\""globalType\"":\""Struct{new_globals:Array[Struct{}]}\""},\""rowRelPath\"":\""rows\"",\""globalRelPath\"":\""globals\"",\""refRelPath\"":\""references\"",\""log\"":true}""]; !39 = Begin(!34, !36, !38); WriteMetadata(!39) [""{\""name\"":\""RelationalWriter\"",\""path\"":\""/tmp/foo.ht\"",\""overwrite\"":true,\""maybeRefs\"":{\""references\"":[\""GRCh38\""]}}""]. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:23); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:23); 	at is.hail.utils.package$.fatal(package.scala:89); 	at is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:17); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:29); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:205); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14245:15601,Error,ErrorHandling,15601,https://hail.is,https://github.com/hail-is/hail/issues/14245,1,['Error'],['ErrorHandling']
Availability,""">#133</a>). Thanks to <a href=""https://github.com/jmsmkn""><code>@jmsmkn</code></a> and <a href=""https://github.com/adamchainz""><code>@adamchainz</code></a>!</li>; <li>Fix incorrect documentation for <a href=""https://www.curlylint.org/docs/rules/no_autofocus""><code>no_autofocus</code></a> and <a href=""https://www.curlylint.org/docs/rules/tabindex_no_positive""><code>tabindex_no_positive</code></a>.</li>; </ul>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.13.0"">v0.13.0</a> 2021-04-25</h2>; <p>This release comes with a blog post! Read on <a href=""https://www.curlylint.org/blog/quality-of-life-improvements"">Quality-of-life improvements</a>.</p>; <h3>Added</h3>; <ul>; <li>Implement --template-tags CLI flag (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/25"">#25</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/77"">#77</a>).</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Add more descriptive error message for missing whitespace between HTML attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/23#issuecomment-700622837"">#23 (comment)</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Move development dependencies from extras to separate <code>requirements.txt</code> (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Declare support for Python 3.9.</li>; <li>Tentatively declare support for Python 3.10 (tested with <code>Python 3.10.0a6+</code>).</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix Python 3.10 deprecation warning by importing Iterable from collections.abc (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; </ul>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.2"">v0.12.2</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The <code>image_alt</code> rule no longer crashes when encou",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11713:5047,error,error,5047,https://hail.is,https://github.com/hail-is/hail/pull/11713,1,['error'],['error']
Availability,"""><code>8f7f078</code></a> Limit expensive decorator function (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1407"">#1407</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/98280b57b5ed3db8a4d431cb60e21f136f6c70de""><code>98280b5</code></a> Add Position to the nodes.<strong>init</strong> (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1408"">#1408</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/a5bd030bf0c420e6773369dc0125b34b39681496""><code>a5bd030</code></a> Revert &quot;Use importlib instead of pkg_resources for determining namespace pack...</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/a62f37ddae2d6fdb6f8ec0f2e5b6a0a41e5f883e""><code>a62f37d</code></a> Add position attribute for nodes (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1393"">#1393</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/514c832a6957c7589aa3e14973189e2e245de961""><code>514c832</code></a> Fix recursion error for inference of self-referencing class attribute (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1392"">#1392</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/astroid/compare/astroid-version-1.0.0...v2.10.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11463:5494,error,error,5494,https://hail.is,https://github.com/hail-is/hail/pull/11463,2,['error'],['error']
Availability,"""><code>@mmichilot</code></a>)</li>; <li>Fix Shift + L not working in stdin <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15440"">#15440</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15499"">#15499</a>: Adopt ruff format <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15564"">#15564</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Pin <code>actions/labeler</code> to v4 to fix failing CI action <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15496"">#15496</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Fix URLs in debugger-extension <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15462"">#15462</a> (<a href=""https://github.com/fcollonval""><code>@fcollonval</code></a>)</li>; <li>More robust galata/UI tests <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15355"">#15355</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; </ul>; <h3>Documentation improvements</h3>; <ul>; <li>Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15499"">#15499</a>: Adopt ruff format <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15564"">#15564</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyterlab/jupyterlab/blob/@jupyterlab/lsp@4.0.11/CHANGELOG.md"">jupyterlab's changelog</a>.</em></p>; <blockquote>; <h2>4.0.11</h2>; <!-- raw HTML omitted -->; <!-- raw HTML omitted -->; <h2>4.0.10</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/compare/v4.0.9...b9bc3002b1ab89b9a1c4d2a3007c43275",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14184:5479,robust,robust,5479,https://hail.is,https://github.com/hail-is/hail/pull/14184,1,['robust'],['robust']
Availability,"""><code>@mmichilot</code></a>)</li>; <li>Fix Shift + L not working in stdin <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15440"">#15440</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15499"">#15499</a>: Adopt ruff format <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15564"">#15564</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Pin <code>actions/labeler</code> to v4 to fix failing CI action <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15496"">#15496</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Fix URLs in debugger-extension <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15462"">#15462</a> (<a href=""https://github.com/fcollonval""><code>@fcollonval</code></a>)</li>; <li>More robust galata/UI tests <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15355"">#15355</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; </ul>; <h3>Documentation improvements</h3>; <ul>; <li>Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15499"">#15499</a>: Adopt ruff format <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15564"">#15564</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/graphs/contributors?from=2023-11-18&amp;to=2023-12-29&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Aafshin+updated%3A2023-11-18..2023-12-29&amp;type=Issues""><code>@afshin</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Abrichet+updated%3A",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14184:8712,robust,robust,8712,https://hail.is,https://github.com/hail-is/hail/pull/14184,1,['robust'],['robust']
Availability,""">atomicwrites</a> dependency on windows with [os.replace]{.title-ref}.</li>; </ul>; <h2>7.1.2</h2>; <h1>pytest 7.1.2 (2022-04-23)</h1>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9726"">#9726</a>: An unnecessary <code>numpy</code> import inside <code>pytest.approx</code>{.interpreted-text role=&quot;func&quot;} was removed.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9820"">#9820</a>: Fix comparison of <code>dataclasses</code> with <code>InitVar</code>.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9869"">#9869</a>: Increase <code>stacklevel</code> for the <code>NODE_CTOR_FSPATH_ARG</code> deprecation to point to the; user's code, not pytest.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9871"">#9871</a>: Fix a bizarre (and fortunately rare) bug where the [temp_path]{.title-ref} fixture could raise; an internal error while attempting to get the current user's username.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pytest-dev/pytest/commit/4645bcd44915c2fd6043b101626e5bf1a983ac07""><code>4645bcd</code></a> Remove incorrect output in how-to/fixtures.rst</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/fadfb4f3463bc828535f86682300907a30f240e9""><code>fadfb4f</code></a> Prepare release version 7.1.3</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/ab96ea88e829af05e1491c30214b924c9553697b""><code>ab96ea8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/10258"">#10258</a> from pytest-dev/backport-10252-to-7.1.x</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/fc0e024b118fa63e84637bd5c9242b2b382e58fd""><code>fc0e024</code></a> [7.1.x] Fix regendoc</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/8f5088f4126b61ff76ac9809d5eb27cdbc31f0",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12187:3521,error,error,3521,https://hail.is,https://github.com/hail-is/hail/pull/12187,1,['error'],['error']
Availability,""">https://pypi.org/project/nbsphinx/0.8.4/</a></p>; <ul>; <li>Support for <code>mathjax3_config</code> (for Sphinx &gt;= 4)</li>; <li>Force loading MathJax on HTML pages generated from notebooks (can be disabled with <code>nbsphinx_assume_equations = False</code>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/spatialaudio/nbsphinx/blob/master/NEWS.rst"">nbsphinx's changelog</a>.</em></p>; <blockquote>; <p>Version 0.8.8 -- 2021-12-31 -- PyPI__ -- diff__</p>; <ul>; <li>Support for the <code>sphinx_codeautolink</code> extension</li>; <li>Basic support for the <code>text</code> builder</li>; </ul>; <p>__ <a href=""https://pypi.org/project/nbsphinx/0.8.8/"">https://pypi.org/project/nbsphinx/0.8.8/</a>; __ <a href=""https://github.com/spatialaudio/nbsphinx/compare/0.8.7...0.8.8"">https://github.com/spatialaudio/nbsphinx/compare/0.8.7...0.8.8</a></p>; <p>Version 0.8.7 -- 2021-08-10 -- PyPI__ -- diff__</p>; <ul>; <li>Fix assertion error in LaTeX build with Sphinx 4.1.0+</li>; </ul>; <p>__ <a href=""https://pypi.org/project/nbsphinx/0.8.7/"">https://pypi.org/project/nbsphinx/0.8.7/</a>; __ <a href=""https://github.com/spatialaudio/nbsphinx/compare/0.8.6...0.8.7"">https://github.com/spatialaudio/nbsphinx/compare/0.8.6...0.8.7</a></p>; <p>Version 0.8.6 -- 2021-06-03 -- PyPI__ -- diff__</p>; <ul>; <li>Support for Jinja2 version 3</li>; </ul>; <p>__ <a href=""https://pypi.org/project/nbsphinx/0.8.6/"">https://pypi.org/project/nbsphinx/0.8.6/</a>; __ <a href=""https://github.com/spatialaudio/nbsphinx/compare/0.8.5...0.8.6"">https://github.com/spatialaudio/nbsphinx/compare/0.8.5...0.8.6</a></p>; <p>Version 0.8.5 -- 2021-05-12 -- PyPI__ -- diff__</p>; <ul>; <li>Freeze Jinja2 version to 2.11 (for now, until a bugfix is found)</li>; <li>Add <code>theme_comparison.py</code> tool for creating multiple versions; (with different HTML themes) of the docs at once</li>; </ul>; <p>__ <a href=""https://pypi.org/project/nbsph",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11477:2352,error,error,2352,https://hail.is,https://github.com/hail-is/hail/pull/11477,1,['error'],['error']
Availability,"""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 18:18:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 18:18:30 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:1608,avail,available,1608,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583,1,['avail'],['available']
Availability,"""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 19:16:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 19:16:02 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel.vcf').write('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel_1.vds'); hail: info: No",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:1446,avail,available,1446,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506,1,['avail'],['available']
Availability,"""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 08:41:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 08:41:32 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 12 2017 14:00:23); SparkSession available as 'spark'. In [1]: ; ```; -----------------------------; Step2 : read the file with sc.textFile; ```; In [1]: rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); ```; -----------------------------; Step3, import hail and read the file with hail:; ```; In [2]: from hail import *; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-2-3181c5d8fca5> in <module>(); ----> 1 from hail import *. /opt/Software/hail/python/hail/__init__.py in <module>(); ----> 1 import hail.expr; 2 from hail.representation import *; 3 from hail.context import HailContext; 4 from hail.dataset import VariantDataset; 5 from hail.expr import *. /opt/Software/hail/python/hail/expr.py in <module>(); 1 import abc; 2 from hail.java import scala_object, Env, jset; ----> 3 from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; 4 ; 5 . /opt/Software/hail/python/hail/represent",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-321420160:2032,avail,available,2032,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321420160,1,['avail'],['available']
Availability,"""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 09:10:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 09:10:21 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:1557,avail,available,1557,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071,1,['avail'],['available']
Availability,"""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/15 08:58:31 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile(""/hail/test/BRCA1.raw_indel.vcf"").count(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 1008, in count; return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 999, in sum; return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 873, in fold; vals = self.mapPartitions(func).collect(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 776, in collect; port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd()); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/sql/utils",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367:1364,avail,available,1364,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367,1,['avail'],['available']
Availability,"""bootDiskSizeGb"": 10; }; },; ""softwareConfig"": {; ""imageVersion"": ""1.1.15"",; ""properties"": {; ""distcp:mapreduce.map.java.opts"": ""-Xmx2457m"",; ""distcp:mapreduce.map.memory.mb"": ""3072"",; ""distcp:mapreduce.reduce.java.opts"": ""-Xmx4915m"",; ""distcp:mapreduce.reduce.memory.mb"": ""6144"",; ""mapred:mapreduce.map.cpu.vcores"": ""1"",; ""mapred:mapreduce.map.java.opts"": ""-Xmx2457m"",; ""mapred:mapreduce.map.memory.mb"": ""3072"",; ""mapred:mapreduce.reduce.cpu.vcores"": ""2"",; ""mapred:mapreduce.reduce.java.opts"": ""-Xmx4915m"",; ""mapred:mapreduce.reduce.memory.mb"": ""6144"",; ""mapred:yarn.app.mapreduce.am.command-opts"": ""-Xmx4915m"",; ""mapred:yarn.app.mapreduce.am.resource.cpu-vcores"": ""2"",; ""mapred:yarn.app.mapreduce.am.resource.mb"": ""6144"",; ""spark:spark.driver.maxResultSize"": ""1920m"",; ""spark:spark.driver.memory"": ""3840m"",; ""spark:spark.executor.cores"": ""2"",; ""spark:spark.executor.memory"": ""5586m"",; ""spark:spark.yarn.am.memory"": ""5586m"",; ""spark:spark.yarn.am.memoryOverhead"": ""558"",; ""spark:spark.yarn.executor.memoryOverhead"": ""558"",; ""yarn:yarn.nodemanager.resource.memory-mb"": ""12288"",; ""yarn:yarn.scheduler.maximum-allocation-mb"": ""12288"",; ""yarn:yarn.scheduler.minimum-allocation-mb"": ""1024""; }; }; },; ""status"": {; ""state"": ""RUNNING"",; ""stateStartTime"": ""2016-12-15T19:00:51.004Z""; },; ""clusterUuid"": ""fb371071-cdd1-4bed-bd1b-3ce3049d07e5"",; ""statusHistory"": [; {; ""state"": ""CREATING"",; ""stateStartTime"": ""2016-12-15T18:59:19.745Z""; }; ],; ""metrics"": {}; }; ```. # Analysis Thus Far. The job doesn't terminate on its own. After stopping the job in the Google Cloud UI, subsequent jobs don't seem to be accepted (i.e. they hang before I see the Spark progress bar). The source of the error is a log statement. Apparently a task failure is triggering a giant log statement. The [log statement (from Spark 2.0 branch)](https://github.com/apache/spark/blob/branch-2.0/core/src/main/scala/org/apache/spark/scheduler/TaskSetManager.scala#L693) seems innocuous. So the real question is why are the tasks failing?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027:6283,error,error,6283,https://hail.is,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027,2,"['error', 'failure']","['error', 'failure']"
Availability,"""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:2143,avail,available,2143,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949,1,['avail'],['available']
Availability,"""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9488"">#9488</a>: If custom subclasses of nodes like <code>pytest.Item</code>{.interpreted-text role=&quot;class&quot;} override the; <code>__init__</code> method, they should take <code>**kwargs</code>. See; <code>uncooperative-constructors-deprecated</code>{.interpreted-text role=&quot;ref&quot;} for details.</p>; <p>Note that a deprection warning is only emitted when there is a conflict in the; arguments pytest expected to pass. This deprecation was already part of pytest; 7.0.0rc1 but wasn't documented.</p>; </li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9355"">#9355</a>: Fixed error message prints function decorators when using assert in Python 3.8 and above.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9396"">#9396</a>: Ensure <code>pytest.Config.inifile</code>{.interpreted-text role=&quot;attr&quot;} is available during the <code>pytest_cmdline_main &lt;_pytest.hookspec.pytest_cmdline_main&gt;</code>{.interpreted-text role=&quot;func&quot;} hook (regression during <code>7.0.0rc1</code>).</li>; </ul>; <h2>Improved Documentation</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9404"">#9404</a>: Added extra documentation on alternatives to common misuses of [pytest.warns(None)]{.title-ref} ahead of its deprecation.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9505"">#9505</a>: Clarify where the configuration files are located. To avoid confusions documentation mentions; that configuration file is located in the root of the repository.</li>; </ul>; <h2>Trivial/Internal Changes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9521"">#9521</a>: Add test coverage to assertion rewrite path.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <detail",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11516:2938,avail,available,2938,https://hail.is,https://github.com/hail-is/hail/pull/11516,3,['avail'],['available']
Availability,"""offer"": null,; ""publisher"": null,; ""resourceGroup"": ""dgoldste"",; ""sharedGalleryImageId"": null,; ""sku"": null,; ""version"": null; },; ""osDisk"": {; ""caching"": ""ReadOnly"",; ""createOption"": ""FromImage"",; ""deleteOption"": ""Delete"",; ""diffDiskSettings"": null,; ""diskSizeGb"": 30,; ""encryptionSettings"": null,; ""image"": null,; ""managedDisk"": {; ""diskEncryptionSet"": null,; ""id"": ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.Compute/disks/batch-worker-pr-11144-default-nbthv8fduvd6-highcpu-robv5-os"",; ""resourceGroup"": ""dgoldste"",; ""storageAccountType"": ""Standard_LRS""; },; ""name"": ""batch-worker-pr-11144-default-nbthv8fduvd6-highcpu-robv5-os"",; ""osType"": ""Linux"",; ""vhd"": null,; ""writeAcceleratorEnabled"": null; }; },; ""tags"": {; ""batch-worker"": ""1"",; ""namespace"": ""pr-11144-default-nbthv8fduvd6""; },; ""type"": ""Microsoft.Compute/virtualMachines"",; ""userData"": null,; ""virtualMachineScaleSet"": null,; ""vmId"": ""4eaaa3a5-69ce-4eb0-ba8c-266bd66c821e"",; ""zones"": null; },; {; ""additionalCapabilities"": null,; ""applicationProfile"": null,; ""availabilitySet"": null,; ""billingProfile"": {; ""maxPrice"": -1.0; },; ""capacityReservation"": null,; ""diagnosticsProfile"": null,; ""evictionPolicy"": ""Delete"",; ""extendedLocation"": null,; ""extensionsTimeBudget"": null,; ""hardwareProfile"": {; ""vmSize"": ""Standard_E4d_v4"",; ""vmSizeProperties"": null; },; ""host"": null,; ""hostGroup"": null,; ""id"": ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.Compute/virtualMachines/batch-worker-pr-11144-default-nbthv8fduvd6-highmem-13t6m"",; ""identity"": {; ""principalId"": null,; ""tenantId"": null,; ""type"": ""UserAssigned"",; ""userAssignedIdentities"": {; ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.ManagedIdentity/userAssignedIdentities/batch-worker"": {; ""clientId"": ""890af904-42f1-4136-810a-c52f4e132c6b"",; ""principalId"": ""b952a3bb-1091-4f11-803b-9d5199219a27""; }; }; },; ""instanceView"": null,; """,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11144#issuecomment-990039686:5577,avail,availabilitySet,5577,https://hail.is,https://github.com/hail-is/hail/pull/11144#issuecomment-990039686,1,['avail'],['availabilitySet']
Availability,"""offer"": null,; ""publisher"": null,; ""resourceGroup"": ""dgoldste"",; ""sharedGalleryImageId"": null,; ""sku"": null,; ""version"": null; },; ""osDisk"": {; ""caching"": ""ReadOnly"",; ""createOption"": ""FromImage"",; ""deleteOption"": ""Delete"",; ""diffDiskSettings"": null,; ""diskSizeGb"": 30,; ""encryptionSettings"": null,; ""image"": null,; ""managedDisk"": {; ""diskEncryptionSet"": null,; ""id"": ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.Compute/disks/batch-worker-pr-11144-default-nbthv8fduvd6-highmem-13t6m-os"",; ""resourceGroup"": ""dgoldste"",; ""storageAccountType"": ""Standard_LRS""; },; ""name"": ""batch-worker-pr-11144-default-nbthv8fduvd6-highmem-13t6m-os"",; ""osType"": ""Linux"",; ""vhd"": null,; ""writeAcceleratorEnabled"": null; }; },; ""tags"": {; ""batch-worker"": ""1"",; ""namespace"": ""pr-11144-default-nbthv8fduvd6""; },; ""type"": ""Microsoft.Compute/virtualMachines"",; ""userData"": null,; ""virtualMachineScaleSet"": null,; ""vmId"": ""2612958c-ef4e-4678-8482-29726290ae20"",; ""zones"": null; },; {; ""additionalCapabilities"": null,; ""applicationProfile"": null,; ""availabilitySet"": null,; ""billingProfile"": {; ""maxPrice"": -1.0; },; ""capacityReservation"": null,; ""diagnosticsProfile"": null,; ""evictionPolicy"": ""Delete"",; ""extendedLocation"": null,; ""extensionsTimeBudget"": null,; ""hardwareProfile"": {; ""vmSize"": ""Standard_D16d_v4"",; ""vmSizeProperties"": null; },; ""host"": null,; ""hostGroup"": null,; ""id"": ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.Compute/virtualMachines/batch-worker-pr-11144-default-nbthv8fduvd6-standard-i4sun"",; ""identity"": {; ""principalId"": null,; ""tenantId"": null,; ""type"": ""UserAssigned"",; ""userAssignedIdentities"": {; ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.ManagedIdentity/userAssignedIdentities/batch-worker"": {; ""clientId"": ""890af904-42f1-4136-810a-c52f4e132c6b"",; ""principalId"": ""b952a3bb-1091-4f11-803b-9d5199219a27""; }; }; },; ""instanceView"": null,;",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11144#issuecomment-990039686:9920,avail,availabilitySet,9920,https://hail.is,https://github.com/hail-is/hail/pull/11144#issuecomment-990039686,1,['avail'],['availabilitySet']
Availability,"""the implementations should rely directly on java.util.Random"" Umm, why? From my outsiders perspective I would have assumed that high quality software worked on by the Broad Institute would use a half decent Random Number Generator (RNG). . If I had time to spend on this I would be pushing to change it to something else, perhaps the Apache Commons RNG: commons.apache.org/proper/commons-rng/userguide/rng.html I'm not a Java programmer though, and don't really aspire to be. . The C++ standard rand() function is also well known to be quite bad, though C++11 distributions use an ok implementation (I think default is Mersenne Twister, but there are also other options http://en.cppreference.com/w/cpp/numeric/random). In some C code I was replacing rand() and found this nice library: http://www.pcg-random.org/ no Java implementation though http://www.pcg-random.org/download.html#java-implementation T.T, but the PCG algorithm is actually really simple to implement. The PCG site is worth exploring in general to understand the important differences between RNGs. The GNU Scientific Library also provides C/C++ coders with some RNG implementations https://www.gnu.org/software/gsl/manual/html_node/Random-Number-Generation.html . I realize that it is quite early in development (in terms of versioning, 0.2) so maybe this seems like an insignificant thing, but I also hear that it is actively being used, so.... it also may not matter much, I just would like to bring some attention to it in case it hasn't been considered because I know that the RNG is something that is frequently overlooked.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2314#issuecomment-384085976:871,down,download,871,https://hail.is,https://github.com/hail-is/hail/issues/2314#issuecomment-384085976,1,['down'],['download']
Availability,"# Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; sphinx 5.3.0 has requirement docutils<0.20,>=0.14, but you have docutils 0.20.1.; sphinx-rtd-theme 1.3.0 has requirement docutils<0.19, but you have docutils 0.20.1.; notebook 6.5.6 has requirement pyzmq<25,>=17, but you have pyzmq 25.1.1.; aiohttp-devtools 1.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14043:1258,avail,available,1258,https://hail.is,https://github.com/hail-is/hail/pull/14043,1,['avail'],['available']
Availability,"# Current situation. In several places, we call a method `emitNDArrayStandardStrides`, which has the effect of calling `emitDeforestedNDArray`, since that is known to always emit things in column major order. However, the downside of this is that we were doing unnecessary copies of the data, even when it was already in column major order, by constructing an `NDArrayEmitter` that just emitted an NDArray and then looked up values from it:. ```; case _ =>; val ndt = emit(x); val ndAddress = mb.genFieldThisRef[Long](); val setup = (ndAddress := ndt.value[Long]); val xP = x.pType.asInstanceOf[PNDArray]. val shapeAddress = new Value[Long] {; def get: Code[Long] = xP.shape.load(ndAddress); }; val shapeTuple = new CodePTuple(xP.shape.pType, shapeAddress). val shapeArray = (0 until xP.shape.pType.nFields).map(i => shapeTuple.apply[Long](i)). new NDArrayEmitter[C](nDims, shapeArray,; xP.shape.pType, xP.elementType, setup, ndt.setup, ndt.m) {; override def outputElement(elemMB: EmitMethodBuilder[C], idxVars: IndexedSeq[Value[Long]]): Code[_] =; xP.loadElementToIRIntermediate(idxVars, ndAddress, elemMB); }; ```. # New Situation. We now have `emitNDArrayColumnMajorStrides`, which calls `emit` on an ndarray, checks if the emitted thing is column major, and only does a copy if it needs to. This uses new `LinalgCodeUtils` methods `checkColumnMajor` and `createColumnMajorCode`. Everything else in `LinalgCodeUtils` was unused / old style and I removed them.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9428:222,down,downside,222,https://hail.is,https://github.com/hail-is/hail/pull/9428,1,['down'],['downside']
Availability,"# Hail version:. eb5d13fe97fc. ### What you did:. ```; t1 = hl.Table.parallelize([; {'a': 'foo', 'b': 1},; {'a': 'bar', 'b': 2},; {'a': 'bar', 'b': 2}],; hl.tstruct(a=hl.tstr, b=hl.tint32),; key='a'); t2 = hl.Table.parallelize([; {'t': 'foo', 'x': 3.14},; {'t': 'bar', 'x': 2.78},; {'t': 'bar', 'x': -1},; {'t': 'quam', 'x': 0}],; hl.tstruct(t=hl.tstr, x=hl.tfloat64),; key='t'). t1.join(t2, how='outer').show(). # or. t1.join(t2, how='right').show(); ```. ### What went wrong (all error messages here, including the full java stack trace):. FatalError: HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 1 times, most recent failure: Lost task 0.0 in stage 19.0 (TID 24, localhost, executor driver): is.hail.utils.HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1012); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.RVD$$anonfun$4$$anon$1.hasNext(RVD.scala:226); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1015); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); 	at is.hail.utils.richUtils.R",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:952,error,error,952,https://hail.is,https://github.com/hail-is/hail/issues/4055,1,['error'],['error']
Availability,"## Basic philosophy; https://developers.google.com/web/fundamentals/performance/prpl-pattern/. Hybrid server-side client-side rendered application, with eager pre-loading of resources. First page visited is server rendered. All client-side code asynchronously fetched, using service workers if available. HTML is ""hydrated""/bound by React, and from then on has the responsiveness of a client-side application. This is what we have in the current pull request. Initial view / first page ready in ~10ms, DOMContentLoaded in ~60-120ms (excluding network latency). ## Why not static/HTML web?; In practice: there is no such thing. Even document-centric sites often need dynamic templates, and will therefore use PHP, Python, NodeJS, Go, Rust, etc. These only work on a server, and only serve interpolated, static documents. Any interactive elements require Javascript. As soon as you need Javascript, the choice becomes Vanilla JS, JQuery, or something more structured. Vanilla JS requires a lot of boilerplate (verbose event binding, DOM modification, needs polyfills since browser incompatibilities). JQuery makes this easier, but is 1) very slow, 2) provides no structure. Vanilla JS and JQuery tend to devolve to soup of global state-modifying code, with a lot of time spent on figuring out how to update values in DOM elements. . React/Next make DOM modification declarative, and very very easy. They provide a great deal of structure (especially with Next handling tooling), and thanks to the virtual dom / reconciliation process, performs, in many cases, much faster than directly modifying the DOM (HTML) (i.e plain JS). React also handles necessities like properly escaping all inputs, for XSS attack prevention. All of this in a bundle size that isn't significantly bigger than JQuery, without all of those benefits (and React is rapidly shrinking). It's possible to avoid Javascript. One can simulate interactivity by issuing a server GET request for a new page, i.e click on a link with a GET ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931:294,avail,available,294,https://hail.is,https://github.com/hail-is/hail/pull/4931,1,['avail'],['available']
Availability,"## Bug fixes to enable Azure deployment. Most of these bugs were discovered in deploying the MySQL server from scratch, specifically deploying version 8.0. ; Some were encountered when we hit certificate issues in trying to run the `./bootstrap.sh deploy_unmanaged` step multiple times within 24hrs. Documentation was clarified in order to resolve this issue. - build.yaml; - Step one fails on rerun since the /repo directory exists, -p to fix; - ci/create_database.py; - In MySQL 8 a new error was introduced [4006](https://dev.mysql.com/doc/mysql-errors/8.0/en/server-error-reference.html#error_er_cannot_user_referenced_as_definer); - This error gets triggered on the CREATE USER IF NOT EXISTS commands for both user and admin if the user was previously created and set a a definer on any events/triggers.; - Really this statement should be a no-op given that the user exists, but for some reason the error triggers anyway.; - To get around this I added a manual check if the user/admin exists and if they do simply skip the create user command. This fixes the bug and allows the MySQL db deploy to finish properly. - dev-docs/letsencrypt.md; - Debugging was confusing since the revoke command addressed ids we were unable to find.; - After extensive searching I added to the documentation how to find your existing cert IDs if you need to revoke them. - infra/azure/README.md; - Added clarity to the Azure deployment documentation. - infra/azure/bootstrap.sh; - Added the passing of additional flag arguments to terraform; - In our case the passing of the `-upgrade` flag to the terraform init step was required in order to continue. - infra/azure/main.tf, infra/azure/modules/batch/main.tf, infra/azure/modules/batch/variables.tf infra/azure/variables.tf; - Add additional argument for the az_storage_account.; - The name must be globally unique in Azure, so the original argument failed on our deployment since it shared the name with the Hail team's Azure deployment",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12065:489,error,error,489,https://hail.is,https://github.com/hail-is/hail/pull/12065,5,['error'],"['error', 'error-reference', 'errors']"
Availability,"## Change Description. Config and records relating to the appsec deployment instance. Necessary for future maintenance and management of the appsec instance. ## Security Assessment. - This change has no security impact. ### Impact Description. No impact because this relates only to the parallel appsec instance, not the main production instance. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14726:107,mainten,maintenance,107,https://hail.is,https://github.com/hail-is/hail/pull/14726,1,['mainten'],['maintenance']
Availability,"## Change Description. Corrects our gsa-key copying instructions (from #14664) to copy the key contents, not the entire secret metadata. The batch service seems resilient to these badly formed secrets, but the rotate_keys.py script was not. ## Security Assessment. Delete all except the correct answer:; - This change has a low security impact. ### Impact Description. - Not a production change; - Does not add any new information to the secrets, only formats them a useable way. ; - Only in dev namespaces. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14735:161,resilien,resilient,161,https://hail.is,https://github.com/hail-is/hail/pull/14735,1,['resilien'],['resilient']
Availability,"## Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed.; jupyter 1.0.0 requires qtconsole, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed.; argon2-cffi-bindings 21.2.0 requires cffi, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **461/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.5 | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3M",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14070:1242,avail,available,1242,https://hail.is,https://github.com/hail-is/hail/pull/14070,1,['avail'],['available']
Availability,"## Mill setup. There is a mill wrapper script `millw` checked into the repo in the `hail/` subdirectory. You can either invoke it directly, as we did with `gradlew`, or copy it somewhere on your path and rename it `mill`. This way you can just run `mill ...`, and it will identify the correct version of mill to use for the project you're in and invoke that. For more details on the installation options, see the github for the wrapper script [here](https://github.com/lefou/millw). To verify that it's working, and download the actual mill jar, run `./millw --version` (or `mill --version` if you put it on your path) from the `hail/` subdirectory. It should report version `0.11.6`. ## Mill from the command line. * `mill clean` - delete all output files (in `hail/hail/out`). Or only delete the output of one target, e.g. `mill clean test.compile`; * `mill compile` - compiles the root module (not including tests); * `mill test.compile` - compiles tests (and, transitively, the rest of the root module); * `mill test.test`, or for short `mill test` - run all tests. You can pass options to the test runner (TestNG currently), e.g.* * `mill test -methods is.hail.expr.ir.CallFunctionsSuite.constructors` to run one test, or `mill test -threadcount 4 -parallel classes` to use 4 threads and parallelize over test classes; * `mill test.testOnly is.hail.expr.ir.CallFunctionsSuite` - run all tests in one or more specified classes. You can use `*` to match anything, e.g. `mill test.testOnly ""*.CallFunctionsSuite""`, or `mill test.testOnly ""is.hail.expr.ir.*""`. You can pass options to the test runner (TestNG currently) after a `--`, e.g. `mill test.testOnly ""is.hail.expr.ir.*"" -- -parallel classes`; * `mill __.testCached` - once the codebase is more modularized, will run tests on only modules whose dependencies have changed since the last test run; * `mill reformat` - runs scalafmt on all sources in the root module (currently that's all scala sources, but hopefully not for long). `mill __.ref",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14147:516,down,download,516,https://hail.is,https://github.com/hail-is/hail/pull/14147,1,['down'],['download']
Availability,"## The DSL. For IBS2, we need this mess:. ``` c; __m256i nxor = _mm256_xor_si256(_mm256_xor_si256(x, y), allones);. // if both bits are one, then the genotype is missing; __m256i xna_tmp = _mm256_xor_si256(_mm256_xor_si256(allNA, x), allones);; __m256i xna = _mm256_and_si256(_mm256_srli_epi64(xna_tmp, 1), xna_tmp);; __m256i yna_tmp = _mm256_xor_si256(_mm256_xor_si256(allNA, y), allones);; __m256i yna = _mm256_and_si256(_mm256_srli_epi64(yna_tmp, 1), yna_tmp);; // if either sample is missing a genotype, we ignore that genotype pair; __m256i na = _mm256_and_si256(_mm256_or_si256(xna, yna), rightAllele);; // 1. shift the left alleles over the right ones; // 2. and the alleles; // 3. mask to the right ones; __m256i ibs2 = _mm256_andnot_si256(na, _mm256_and_si256(_mm256_and_si256(_mm256_srli_epi64(nxor, 1), nxor), rightAllele));; // 4. popcnt; uint64_t ibs2sum = _mm_popcnt_u64(_mm256_extract_epi64(ibs2, 0));; ibs2sum += _mm_popcnt_u64(_mm256_extract_epi64(ibs2, 1));; ibs2sum += _mm_popcnt_u64(_mm256_extract_epi64(ibs2, 2));; ibs2sum += _mm_popcnt_u64(_mm256_extract_epi64(ibs2, 3));; ```. It'd be nice to specify it as:. ``` racket; (define (bit-eq x y) (negate (xor x y))). (let ((nxor (bit-eq x y)); (xna (bit-eq allNA x)); (yna (bit-eq allNA x)); (na (and (or xna yna) rightAllele))); (popcnt (andnot na (and (and (>>64 nxor 1) nxor) rightAllele)))); ```. And then have a little compiler that can generate C code for 128/256/512-wide registers and 2/4/16/256 alleles.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1082#issuecomment-260067923:689,mask,mask,689,https://hail.is,https://github.com/hail-is/hail/issues/1082#issuecomment-260067923,1,['mask'],['mask']
Availability,"### Change Description. Jobs within our CI pipeline often invoke `mill` indirectly through `Makefile` prerequisites.; By staging mill's build area to and from `/derived/{release/debug}/hail/out`, mill will not rebuild artefacts from previous steps.; Exposing `MILLOPTS` in `hail/Makefile` allows us to build in CI without a compilation server. ; Using a compilation server may have been why we experienced intermittent failures between building the jar and copying to its final destination.; Note that the `--no-server` option must be the first argument to `millw`. ### Security Assessment; - [x] This change has no security impact. Description of the security impact and necessary mitigations:. Only derived files from the mill + python build process are staged and unstaged.; No secrets or otherwise sensitive information are contained therein. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14709:419,failure,failures,419,https://hail.is,https://github.com/hail-is/hail/pull/14709,1,['failure'],['failures']
Availability,"### Change Description. This change exists as part of larger refactoring work. Herein, I've exchanged; hard-coded contextual strings passed to `ExecutionTimer.time` with implict; contexts, drawing inspiration from scalatest. These contexts are now supplied after entering functions like `Compile` and; `Emit` instead of before (see `ExecuteContext.time`). By sprinking calls to ; `time` throughout the codebase after entering functions, we obtain a nice trace; of the timings with `sourcecode.Enclosing`, minus the previous verbosity. See [1] for more information about what pre-built macros are available. We can; always build our own later. See comments in [pull request id] for example output.; Note that `ExectionTimer.time` still accepts a string to support uses like; `Optimise` and `LoweringPass` where those contexts are provided already.; It is also exception-safe now. This change exposed many similarities between the implementations of query; execution across all three backends. I've stopped short of full unification; which is a greater work, I've instead simplified and moved duplicated result; encoding into the various backend api implementations. More interesting changes are to `ExecuteContext`, which now supports; - `time`, as discussed above; - `local`, a generalisation for temporarily overriding properties of an ; `ExecuteContext` (inspired by [2]). While I've long wanted this for testing,; we were doing some questionable things when reporting timings back to python,; for which locally overriding the `timer` of a `ctx` has been very useful.; We also follow this pattern for local regions. [1] https://github.com/com-lihaoyi/sourcecode; [2] https://hackage.haskell.org/package/mtl-2.3.1/docs/Control-Monad-Reader.html#v:local. ### Security Assessment. This change has no security impact as it's confined to refactoring of existing non-security-related code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14683:596,avail,available,596,https://hail.is,https://github.com/hail-is/hail/pull/14683,1,['avail'],['available']
Availability,"### Change Description. `test_dataproc-*` is failing with:; ```; ERROR: (gcloud.dataproc.clusters.create) unrecognized arguments: --public-ip-address (did you mean '--no-address'?) ; ```; Went into the pushed `ci-utils` image, and verified that gcloud didn't have the `--public-ip-address` flag. Version 495 is current and has the flag. ### Security Assessment. - [x] This change has a low security impact",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14707:65,ERROR,ERROR,65,https://hail.is,https://github.com/hail-is/hail/pull/14707,1,['ERROR'],['ERROR']
Availability,"### Description. In this pull request, I add a function to perform a Cochran-Mantel-Haenszel statistical test for association. This pull request closes #13481. ### Testing. I add unit tests. Since I have not used R before (the [associated GitHub issue](https://github.com/hail-is/hail/issues/13481) suggests using R to create test cases), I created the unit tests from examples that I found on the internet. I linked these sources in the code for the unit tests. I built the documentation locally and inspected it to confirm that it matches my expectations. I am having trouble testing the docstring examples locally. When I run `make -C hail doctest-query`, the tests error due to a checksum exception. ### Discussion. ~I have not added an example to the documentation that uses a matrix table yet. (This is an acceptance criteria in #13481.) I wanted to get some advice about the best way to do this. I think ideally, the example would have a binary phenotype, an allele to test for association, and some stratifying variable. I tried to search through the existing code to find suitable example matrix tables in the docstrings, but I didn't find anything promising. I would appreciate help here.~. Update: thanks to @patrick-schultz's recommendation, I have added an example using a matrix table.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14255:669,error,error,669,https://hail.is,https://github.com/hail-is/hail/pull/14255,1,['error'],['error']
Availability,"### Description. In this pull request, I fix an error in the MatrixTable tutorial. The tutorial shows some genotype data and erroneously states that all the genotypes that are shown are homozygous reference (0/0). In fact, there are also some heterozygous (0/1) and homozygous alternate (1/1) genotypes in the displayed data. In this pull request, I remove the erroneous statement. ### Testing. I ran the notebook to confirm that the notebook displays a mix of genotypes, not just homozygous reference. You can view the erroneous version of the tutorial [here](https://hail.is/docs/0.2/tutorials/07-matrixtable.html#MatrixTable-operations).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14239:48,error,error,48,https://hail.is,https://github.com/hail-is/hail/pull/14239,1,['error'],['error']
Availability,"### Hail version: 0.2.8. ### What you did:. ```python; smt = hl.methods.balding_nichols_model(3, 100, 200); smt = smt.annotate_cols(s=hl.str(smt.sample_idx)).key_cols_by('s'); smt.make_table().to_pandas(); ```; ### What went wrong (all error messages here, including the full java stack trace):. ```; 2019-01-26 19:03:28 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 100 samples, and 200 variants...; 2019-01-26 19:03:28 Hail: INFO: Coerced sorted dataset; 2019-01-26 19:03:29 Hail: INFO: Coerced sorted dataset; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-59-9addf4eaf59b> in <module>; 1 smt = hl.methods.balding_nichols_model(3, 100, 200); 2 smt = smt.annotate_cols(s=hl.str(smt.sample_idx)).key_cols_by('s'); ----> 3 smt.make_table().to_pandas(). <decorator-gen-1366> in to_pandas(self, flatten). ~/anaconda3/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. ~/anaconda3/lib/python3.6/site-packages/hail/table.py in to_pandas(self, flatten); 2703 ; 2704 """"""; -> 2705 return Env.spark_backend('to_pandas').to_pandas(self, flatten); 2706 ; 2707 @staticmethod. ~/anaconda3/lib/python3.6/site-packages/hail/backend/backend.py in to_pandas(self, t, flatten); 66 ; 67 def to_pandas(self, t, flatten):; ---> 68 return self.to_spark(t, flatten).toPandas(); 69 ; 70 def from_pandas(self, df, key):. ~/anaconda3/lib/python3.6/site-packages/hail/backend/backend.py in to_spark(self, t, flatten); 63 if flatten:; 64 t = t.flatten(); ---> 65 return pyspark.sql.DataFrame(t._jt.toDF(Env.hc()._jsql_context), Env.sql_context()); 66 ; 67 def to_pandas(self, t, flatten):. ~/anaconda3/lib/python3.6/site-packages/py4j/jav",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5212:236,error,error,236,https://hail.is,https://github.com/hail-is/hail/issues/5212,1,['error'],['error']
Availability,"### Hail version: ; 0.1-74bf1eb. ### What you did: ; Export vcf to local file:// path. ### What went wrong (all error messages here, including the full java stack trace): ; When exporting vcf to path that begins with 'file://', I get the error: `ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found`. I am using Spark 2.2.1 (prebuilt with hadoop2.7) with AWS-Hadoop 2.7.4. I have the following settings in spark config and am using a custom directParquetOutputCommitter. Standard writes to 'file://' of Spark dataframes work without issue. Thanks for any help!. ```; spark.sql.parquet.output.committer.class org.apache.spark.sql.parquet.DirectParquetOutputCommitter; spark.hadoop.mapred.output.committer.class org.apache.hadoop.mapred.DirectFileOutputCommitter; spark.hadoop.mapreduce.use.directfileoutputcommitter true; spark.hadoop.spark.sql.parquet.output.committer.class org.apache.spark.sql.parquet.DirectParquetOutputCommitter; ```. Code and stack trace:; ```; ================================================================================================== FAILURES ===================================================================================================; __________________________________________________________________________________________ TestHAIL.test_export_vcf ___________________________________________________________________________________________. self = <test_hail.TestHAIL testMethod=test_export_vcf>. def test_export_vcf(self):; # define files; bgen_file = os.path.join(self.testdir, 'example.10bits.bgen'); sample_file = os.path.join(self.testdir, 'example.sample'); # make index; self.hc.index_bgen(bgen_file); # load to vds; bgen_vds = self.hc.import_bgen(bgen_file, sample_file=sample_file); # export vcf; out_path = 'file://' + os.path.join(self.tmpdir, 'test_vcf_export.vcf.bgz'); > bgen_vds.export_vcf(out_path, export_pp=False, parallel=False). tests/hail/test_hail.py:55:; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3946:112,error,error,112,https://hail.is,https://github.com/hail-is/hail/issues/3946,2,['error'],['error']
Availability,"### Hail version: ; 0.2.9-8588a25687af. ### What you did: ; tbl.export(""filename"", header=False, types_file=None). ### What went wrong (all error messages here, including the full java stack trace):; No errors, but two files were written to my working directory; None and .None.crc. The file contains column types as if the 'types_file = None' was interpreted as 'types_file = ""None""'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5266:140,error,error,140,https://hail.is,https://github.com/hail-is/hail/issues/5266,2,['error'],"['error', 'errors']"
Availability,"### Hail version:. 9e4ca83b6b0d. ### What you did:. ### What went wrong (all error messages here, including the full java stack trace):. `hl.eval_expr(hl.is_snp(hl.literal('A'), hl.literal('A')))` should return false, i.e. ['A', 'A'] shouldn't be considered a snp.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3712:77,error,error,77,https://hail.is,https://github.com/hail-is/hail/issues/3712,1,['error'],['error']
Availability,"### Hail version:. Irrelevant feature branch based on `abfb656e2`. ### What you did:. 1. `cd batch ; make run`; 2. ; ```; curl -XPOST localhost:5000/jobs/create -H 'Content-Type: application/json' -d '{ ; ""spec"" : {; ""containers"" : [; { ""name"" : ""foobarbaz""; , ""image"" : ""alpine:3.8""; , ""command"": [""/bin/sh"", ""-c"", ""echo hi""] }] } }'; ```; 3. ; ```; curl localhost:5000/jobs; ```; 4. the job never transitions to Complete and the server log shows:; ```; (hail-batch) # make run; BATCH_USE_KUBE_CONFIG=1 python -c 'import batch.server; batch.server.serve()'; INFO	| 2018-11-13 18:12:19,124 	| server.py 	| <module>:25 | REFRESH_INTERVAL_IN_SECONDS 300; INFO	| 2018-11-13 18:12:19,125 	| server.py 	| <module>:28 | instance_id = 63aeb0cd4fa840a9864cfd909ce7f682; INFO	| 2018-11-13 18:12:19,130 	| server.py 	| run_forever:391 | run_forever: run target kube_event_loop; INFO	| 2018-11-13 18:12:19,130 	| server.py 	| run_forever:391 | run_forever: run target polling_event_loop; INFO	| 2018-11-13 18:12:19,131 	| server.py 	| run_forever:391 | run_forever: run target flask_event_loop; * Serving Flask app ""batch"" (lazy loading); * Environment: production; WARNING: Do not use the development server in a production environment.; Use a production WSGI server instead.; * Debug mode: off; INFO	| 2018-11-13 18:12:19,168 	| _internal.py 	| _log:88 | * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit); INFO	| 2018-11-13 18:12:20,141 	| server.py 	| refresh_k8s_state:360 | started k8s state refresh; INFO	| 2018-11-13 18:12:20,159 	| server.py 	| refresh_k8s_state:379 | k8s state refresh complete; INFO	| 2018-11-13 18:12:20,160 	| _internal.py 	| _log:88 | 127.0.0.1 - - [13/Nov/2018 18:12:20] ""POST /refresh_k8s_state HTTP/1.1"" 204 -; INFO	| 2018-11-13 18:12:55,902 	| _internal.py 	| _log:88 | 127.0.0.1 - - [13/Nov/2018 18:12:55] ""GET /jobs HTTP/1.1"" 200 -; INFO	| 2018-11-13 18:17:20,174 	| server.py 	| refresh_k8s_state:360 | started k8s state refresh; INFO	| 2018-11-13 18:17:20,179 	| serv",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4773:317,echo,echo,317,https://hail.is,https://github.com/hail-is/hail/issues/4773,1,['echo'],['echo']
Availability,"### Hail version:. d5007d8878f2dc330dd2f01c1c0251785f259dac. ### What you did:. ```; ds = hl.import_vcf(resource(""sample.vcf"")); ds_duplicate = ds.annotate_rows(duplicate = [1,2]); ds_duplicate = ds_duplicate.explode_rows(ds_duplicate['duplicate']); result = hl.ld_prune(ds_duplicate.GT); result.show(); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; Java stack trace:; java.lang.AssertionError: assertion failed: absoluteUpperIndexBounds length 197 did not match GridPartition nRows 394; 	at scala.Predef$.assert(Predef.scala:170); 	at is.hail.methods.UpperIndexBounds$.computeCoverByUpperTriangularBlocks(UpperIndexBounds.scala:69); 	at is.hail.linalg.BlockMatrix.filteredEntriesTable(BlockMatrix.scala:1198); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3835:334,error,error,334,https://hail.is,https://github.com/hail-is/hail/issues/3835,1,['error'],['error']
Availability,"### Hail version:. de61119ceec6. ### What you did:; ```; ht1 = hl.Table.parallelize([; {'k': 'foo', 'b': 1},; {'k': 'bar', 'b': 2},; {'k': 'bar', 'b': 2}],; hl.tstruct(k=hl.tstr, b=hl.tint32),; key='k'). # IllegalArgumentException: requirement failed; ht1.group_by().aggregate(mean_b = hl.agg.mean(ht1.b)).show(). # ClassCastException: is.hail.rvd.UnpartitionedRVD cannot be cast to is.hail.rvd.OrderedRVD; ht1.group_by('k').aggregate(mean_b = hl.agg.mean(ht1.b)).show(); ```; ### What went wrong (all error messages here, including the full java stack trace):. bad error messages",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4070:502,error,error,502,https://hail.is,https://github.com/hail-is/hail/issues/4070,2,['error'],['error']
Availability,"### Hail version:. eb5d13fe97fc. ### What you did:. ```; t1 = hl.Table.parallelize([; {'a': 'foo', 'b': 1},; {'a': 'bar', 'b': 2},; {'a': 'bar', 'b': 2}],; hl.tstruct(a=hl.tstr, b=hl.tint32),; key='a'); t2 = hl.Table.parallelize([; {'t': 'foo', 'x': 3.14},; {'t': 'bar', 'x': 2.78},; {'t': 'bar', 'x': -1},; {'t': 'quam', 'x': 0}],; hl.tstruct(t=hl.tstr, x=hl.tfloat64),; key='t'). t1.join(t2, how='outer').show(). # or. t1.join(t2, how='right').show(); ```. ### What went wrong (all error messages here, including the full java stack trace):. FatalError: HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 1 times, most recent failure: Lost task 0.0 in stage 19.0 (TID 24, localhost, executor driver): is.hail.utils.HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1012); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.RVD$$anonfun$4$$anon$1.hasNext(RVD.scala:226); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1015); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); 	at is.hail.utils.richUtils",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:484,error,error,484,https://hail.is,https://github.com/hail-is/hail/issues/4055,4,"['error', 'failure']","['error', 'failure']"
Availability,"### Hail version:. f2b0dca9f506. ### What you did:; ```; ht = hl.Table.parallelize([; {'a': '1', 'c': .5,'d': 'foo'},; {'a': '1', 'c': .6,'d': 'foo'},; ], hl.tstruct(a=hl.tstr,; c=hl.tfloat32, d=hl.tstr)); mt = ht.to_matrix_table(['a'], ['d']). mt.entries().show(); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 7, localhost, executor driver): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.RegionValueBuilder.endArray(RegionValueBuilder.scala:167); 	at is.hail.expr.ir.TableToMatrixTable$$anonfun$75$$anonfun$apply$25.apply(MatrixIR.scala:1878); 	at is.hail.expr.ir.TableToMatrixTable$$anonfun$75$$anonfun$apply$25.apply(MatrixIR.scala:1849); 	at is.hail.utils.FlipbookIterator$$anon$4.<init>(FlipbookIterator.scala:133); 	at is.hail.utils.FlipbookIterator.map(FlipbookIterator.scala:131); 	at is.hail.expr.ir.TableToMatrixTable$$anonfun$75.apply(MatrixIR.scala:1849); 	at is.hail.expr.ir.TableToMatrixTable$$anonfun$75.apply(MatrixIR.scala:1840); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$18.apply(ContextRDD.scala:293); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$18.apply(ContextRDD.scala:293); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$22$$anonfun$apply$23.apply(ContextRDD.scala:310); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$22$$anonfun$apply$23.apply(ContextRDD.scala:310); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1014); 	at scala.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4114:296,error,error,296,https://hail.is,https://github.com/hail-is/hail/issues/4114,3,"['error', 'failure']","['error', 'failure']"
Availability,"### Hail version:; 0.1 only - this already works in 0.2. ### What you did:; I'm calling kt.export_elasticsearch(..) on this keytable schema:. ```; ...; aIndex: Int,; alt: String,; codingGeneIds: Set[String],; contig: String,; docId: String,; domains: Set[String],; end: Int,; filters: Set[String],; geneIds: Set[String],; pos: Int,; ref: String,; rsid: String,; start: Int,; variantId: String,; vep: Array[Struct{; gene_id: String,; gene_symbol: String,; protein_id: String,; transcript_id: String,; hgvs: String,; major_consequence: String,; major_consequence_rank: Int,; category: String; }],; wasSplit: Boolean,; ```. ### What went wrong (all error messages here, including the full java stack trace):. Having `vep: Array[Struct..]` in the schema leads to . ```; 2018-09-02 07:06:06,821 INFO ==> exporting data to elasticasearch. Write mode: upsert, blocksize: 1000; Config Map(es.batch.size.entries -> 1000, es.index.auto.create -> true, es.mapping.id -> docId, es.write.operation -> upsert, es.port -> 9200, es.nodes -> 10.56.10.4); [Stage 3:> (0 + 100) / 1000]Traceback (most recent call last):; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 734, in <module>; run_pipeline(); File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 726, in run_pipeline; hc, vds = step2_export_to_elasticsearch(hc, vds, args); File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 565, in step2_export_to_elasticsearch; disable_index_for_fields=(""sortedTranscriptConsequences"", ),; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 358, in export_to_elasticsearch; verbose=True,; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail_scripts.zip/hail_scripts/v01/utils/elasticsearch_client.py"", line 140, in export_vds_to_elasticsearch; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail_scripts.zip/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; File ""<decorator-gen-143>"", line 2, in expo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:646,error,error,646,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['error'],['error']
Availability,"### Hail version:; 18d0195e6; ### What you did:; ```; import hail as hl; contigs = {'0{}'.format(x):str(x) for x in range(1, 10)}; mt = hl.methods.import_bgen('gs://fc-7d5088b4-7673-45b5-95c2-17ae00a04183/imputed/ukb_imp_chr22_v3.bgen',; ['GT'],; sample_file='gs://phenotype_31063/ukb31063.autosomes.sample',; contig_recoding=contigs,; min_partitions=100); sampleids = hl.import_table('gs://ukb31063-mega-gwas/qc/ukb31063.gwas_samples.txt', delimiter='\s+').key_by('s'); og_sample = mt.filter_cols(hl.is_defined(sampleids[mt.s])); og_sample = og_sample.annotate_rows(pca_af=hl.agg.mean(og_sample.GT.n_alt_alleles()) / 2); og_sample._force_count_rows(); ```; The important part is that I used `annotate_rows` on a sufficiently large dataset.; ### What went wrong (all error messages here, including the full java stack trace):; Container failures; ```; Job aborted due to stage failure: Task 5 in stage 9.0 failed 20 times, most recent failure: Lost task 5.19 in stage 9.0 (TID 603, dk-w-0.c.broad-ctsa.internal, executor 63): ExecutorLostFailure (executor 63 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 15.9 GB of 12 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.; ```; This is due to `collectPerPartition` allowing regions to grow without bound.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3920:767,error,error,767,https://hail.is,https://github.com/hail-is/hail/issues/3920,4,"['error', 'failure']","['error', 'failure', 'failures']"
Availability,"### Hail version:; 1f253167d53c; ### What you did:; ```; hl.eval_expr(hl.literal(hl.tuple([3]))); hl.eval_expr(hl.literal(hl.literal(3))); ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-3-4a1008efb336> in <module>(); ----> 1 hl.eval_expr(hl.literal(hl.tuple([3]))[0]). ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/expr/expressions/expression_utils.py in eval_expr(expression); 136 Result of evaluating `expression`.; 137 """"""; --> 138 return eval_expr_typed(expression)[0]; 139 ; 140 . ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/expr/expressions/expression_utils.py in eval_expr_typed(expression); 172 analyze('eval_expr_typed', expression, Indices(expression._indices.source)); 173 ; --> 174 return expression.collect()[0], expression.dtype; 175 ; 176 . ~/projects/hail/python/hail/expr/expressions/base_expression.py in collect(self); 762 """"""; 763 uid = Env.get_uid(); --> 764 t = self._to_table(uid); 765 return [r[uid] for r in t._select(""collect"", None, hl.struct(**{uid: t[uid]})).collect()]; 766 . ~/projects/hail/python/hail/expr/expressions/base_expression.py in _to_table(self, name); 582 # scalar expression; 583 df = Env.dummy_table(); --> 584 df = df.select(**{name: self}); 585 return df; 586 elif len(axes) == 0:. ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrap",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3708:169,error,error,169,https://hail.is,https://github.com/hail-is/hail/issues/3708,1,['error'],['error']
Availability,"### Hail version:; 1f253167d; ### What you did:; ```; import hail as hl; t = hl.utils.range_table(10); hl.methods.maximal_independent_set(t.idx, t.idx // 2, tie_breaker = lambda i, j: hl.signum(i - j)) ; ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; ---------------------------------------------------------------------------; LookupError Traceback (most recent call last); <ipython-input-8-b09a26588332> in <module>(); ----> 1 hl.methods.maximal_independent_set(t.idx, t.idx // 2, tie_breaker = lambda i, j: hl.signum(i - j)). ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/methods/misc.py in maximal_independent_set(i, j, keep, tie_breaker); 139 .select()); 140 ; --> 141 edges = t.key_by(None).select('i', 'j'); 142 nodes_in_set = Env.hail().utils.Graph.maximalIndependentSet(edges._jt.collect(), node_t._jtype, joption(tie_breaker_hql)); 143 . ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/table.py in select(self, *exprs, **named_exprs); 863 row = get_select_exprs('Table.select',; 864 exprs, named_exprs, self._row_indices,; --> 865 protect_keys=True); 866 return self._select('Table.select', value_struct=hl.struct(**row)); 867 . ~/projects/hail/python/hail/utils/misc.py in get_select_exprs(caller, exprs, named_exprs, indices, protect_keys); 314 def get_select_exprs(caller, exprs, named_exprs, indices, protect_keys=True):; 315 from hail.expr.expressions import to_expr, ExpressionException, TopLevelReference, Select; --> 316 exprs = [to_expr(e) ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3706:234,error,error,234,https://hail.is,https://github.com/hail-is/hail/issues/3706,1,['error'],['error']
Availability,"### Hail version:; 2018-06-04; ### What you did:; ### What went wrong (all error messages here, including the full java stack trace):; The docs for [`liftover`](https://hail.is/docs/devel/functions/genetics.html?highlight=liftover#hail.expr.functions.liftover) confusingly use `.value` to convert an expression to a value. Users are apt to copy paste them and not understand what the `.value` is doing. We should uniformly use `hl.eval_expr` which is less surprising.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3709:75,error,error,75,https://hail.is,https://github.com/hail-is/hail/issues/3709,1,['error'],['error']
Availability,"### Hail version:; 6195693b3; ### What you did:; ```mt.filter_cols(hl.literal(set(max_downsample1)).contains(mt.col_idx))```. ### What went wrong (all error messages here, including the full java stack trace):; ```Hail cannot automatically impute type of <class 'numpy.int64'>: 129```. Hail should understand the usual numpy int types.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3699:151,error,error,151,https://hail.is,https://github.com/hail-is/hail/issues/3699,1,['error'],['error']
Availability,"### Hail version:; Hail version: 0.1-20613ed; Error summary: ClassNotFoundException: is.hail.asm4s.AsmFunction2. Hail JAR appears to not be visible on workers despite setting `--jars`, `--driver-class-path`, and `--conf spark.executor.extraClassPath`. . ### What you did:; 1) Downloaded pre-built binaries for 2.0.2. 2) Zipped the hail/python/hail folder into hail.zip. 3) Launched a local pyspark shell as follows:; ```; pyspark --jars $HAIL_HOME/jars/hail-all-spark.jar \; > --driver-class-path ./hail-all-spark.jar \; > --conf spark.executor.extraClassPath=./hail-all-spark.jar \; > --py-files $HAIL_HOME/python/hail.zip \; > --conf spark.sql.files.openCostInBytes=1099511627776 \; > --conf spark.sql.files.maxPartitionBytes=1099511627776 \; > --conf spark.hadoop.parquet.block.size=1099511627776; ```. 4) Attempted to run the Hail tutorial, received an error when calling `common_vds = common_vds.filter_genotypes('let ab = g.ad[1] / g.ad.sum() in ((g.isHomRef && ab <= 0.1) || (g.isHet && ab >= 0.25 && ab <= 0.75) ||(g.isHomVar && ab >= 0.9))')`. ### What went wrong (all error messages here, including the full java stack trace):; ```; Python 2.7.14 |Anaconda, Inc.| (default, Oct 16 2017, 17:29:19); [GCC 7.2.0] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/02/22 20:29:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/02/22 20:29:10 WARN Utils: Your hostname, CompyWompy resolves to a loopback address: 127.0.1.1; using 192.168.1.122 instead (on interface eth0); 18/02/22 20:29:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.14 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2966:46,Error,Error,46,https://hail.is,https://github.com/hail-is/hail/issues/2966,3,"['Down', 'Error', 'error']","['Downloaded', 'Error', 'error']"
Availability,"### Hail version:; Latest build of `devel` from https://storage.googleapis.com/hail-common/distributions/devel/Hail-devel-5d0f74cef4f2-Spark-2.2.0.zip. ### What you did:; 1. Import VCF file into MatrixTable.; 2. Annotate VCF file with `output = hl.vep(input, 'vep.properties', csq=True)`.; 3. Attempt to view output with `output.rows().show()`. With `csq=False`, step 3 succeeds. ### What went wrong (all error messages here, including the full java stack trace):; ```; 2018-06-19 17:15:41 Hail: INFO: vep: annotated 2 variants; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/opt/hail/python/hail/table.py"", line 1195, in show; print(self._show(n,width, truncate, types)); File ""/opt/hail/python/hail/table.py"", line 1198, in _show; return self._jt.showString(n, joption(truncate), types, width); File ""/opt/spark-2.2.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;). Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 11.0 failed 1 times, most recent failure: Lost task 0.0 in stage 11.0 (TID 11, localhost, executor driver): scala.MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;); 	at is.hail.annotations.RegionValueBuilder.addAnnotation(RegionValueBuilder.scala:489); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:350); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:345); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(Or",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790:405,error,error,405,https://hail.is,https://github.com/hail-is/hail/issues/3790,1,['error'],['error']
Availability,"### Hail version:; `08224c6ab`; ### What you did:; Tried to load a plink dataset that was split by chromosome.; ```; files = [(; f'gs://fc-9a7c5487-04c9-4182-b3ec-13de7f6b409b/genotype/ukb_cal_chr{i}_v2.bed',; f'gs://fc-9a7c5487-04c9-4182-b3ec-13de7f6b409b/genotype/ukb_snp_chr{i}_v2.bim'; ) for i in range(1,23)]; mts = [hl.import_plink(bed=f[0],bim=f[1],fam=""gs://phenotype_31063/ukb31063.fam"") for f in files]; mt = mts[0].union_rows(*mts[1:]); ```; ### What went wrong (all error messages here, including the full java stack trace):; It loaded each plink file serially rather than in parallel, thus wasting many cores of my cluster (and my time).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3975:478,error,error,478,https://hail.is,https://github.com/hail-is/hail/issues/3975,1,['error'],['error']
Availability,"### Hail version:; `30bc2bcdf2ba`; ### What you did:; ```python; t = hl.import_table('/path/to/thing', ; delimiter='\s+',; impute=True); ```; on a file with two extra new lines at the end.; ### What went wrong (all error messages here, including the full java stack trace):; The task failed 14 times in the background rather than eagerly failing.; ```; is.hail.utils.HailException: pheno_31063_eur_gwas_skin_color.clumped.gz: expected 13 fields, but found 1 offending line: 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20) 	at is.hail.utils.package$.fatal(package.scala:26) 	at is.hail.utils.Context.wrapException(Context.scala:19) 	at is.hail.utils.WithContext.foreach(Context.scala:51) 	at is.hail.utils.TextTableReader$$anonfun$5$$anonfun$apply$2.apply(TextTableReader.scala:126) 	at is.hail.utils.TextTableReader$$anonfun$5$$anonfun$apply$2.apply(TextTableReader.scala:126) 	at scala.collection.Iterator$class.foreach(Iterator.scala:893) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336) 	at is.hail.utils.TextTableReader$$anonfun$5.apply(TextTableReader.scala:126) 	at is.hail.utils.TextTableReader$$anonfun$5.apply(TextTableReader.scala:122) 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797) 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87) 	at org.apache.spark.scheduler.Task.run(Task.scala:108) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) 	at java.lang.Thread.run(Thread.java:748) Caused by: is.hail.uti",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4100:215,error,error,215,https://hail.is,https://github.com/hail-is/hail/issues/4100,3,"['Error', 'error']","['ErrorHandling', 'error']"
Availability,"### Hail version:; `6d4d50458`; ### What you did:; ```; label_expr = (hl.case(missing_false=True); .when(ht[tp_col] & ~ht[fp_col], ""TP""); .when(ht[fp_col] & ~ht[tp_col], ""FP)); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; Im getting an error that reads,; Traceback (most recent call last):; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/variantqc.py"", line 567, in <module>; try_slack(args.slack_channel, main, args); File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/pyscripts_SuuLaL.zip/gnomad_hail/utils/slack.py"", line 112, in try_slack; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/pyscripts_SuuLaL.zip/gnomad_hail/utils/slack.py"", line 95, in try_slack; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/variantqc.py"", line 508, in main; run_hash = train_rf(data_type, args) if args.train_rf else args.run_hash; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/variantqc.py"", line 422, in train_rf; fp_to_tp=args.fp_to_tp); File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/variantqc.py"", line 240, in sample_rf_training_examples; train_col: train_expr}); File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/hail-6d4d50458.zip/hail/table.py"", line 720, in annotate; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/hail-6d4d50458.zip/hail/utils/misc.py"", line 336, in get_annotate_exprs; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/hail-6d4d50458.zip/hail/utils/misc.py"", line 336, in <dictcomp>; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/hail-6d4d50458.zip/hail/expr/expressions/base_expression.py"", line 102, in to_expr; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/hail-6d4d50458.zip/hail/expr/expressions/base_expression.py"", line 93, in impute_type; hail.expr.expressions.base_expression.ExpressionException: Hail cannot automatically impute type of <class 'hail.expr.builders.CaseBuilder'>: <hail.expr.builders.CaseBuilder object at 0x7f2ad03c74e0>; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3696:208,error,error,208,https://hail.is,https://github.com/hail-is/hail/issues/3696,2,['error'],['error']
Availability,"### Hail version:; `784ab2796878`; ### What you did:; ```; In [1]: import hail as hl; ...: ; ...: t1kg = hl.balding_nichols_model(3, 100, 100); ...: print(t1kg.describe()); ...: t1kg = t1kg_sm.repartition(500) ; ...: t1kg = t1kg._filter_partitions([1]); ...: t1kg = hl.split_multi(t1kg); ...: t1kg._force_count_rows(); ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; FatalError: HailException: optimization changed type!; before: Matrix{global:Struct{bn:Struct{n_populations:Int32,n_samples:Int32,n_variants:Int32,n_partitions:Int32,pop_dist:Array[Int32],fst:Array[Float64],mixture:Boolean}},col_key:[sample_idx],col:Struct{sample_idx:Int32,pop:Int32},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],ancestral_af:Float64,af:Array[Float64],a_index:Int32,was_split:Boolean,old_locus:Locus(GRCh37),old_alleles:Array[String]},entry:Struct{GT:Call}}; after: Matrix{global:Struct{bn:Struct{n_populations:Int32,n_samples:Int32,n_variants:Int32,n_partitions:Int32,pop_dist:Array[Int32],fst:Array[Float64],mixture:Boolean}},col_key:[sample_idx],col:Struct{sample_idx:Int32,pop:Int32},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],ancestral_af:Float64,af:Array[Float64],a_index:Int32,was_split:Boolean,old_locus:Locus(GRCh37),old_alleles:Array[String]},entry:Struct{GT:Call}}; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4527:349,error,error,349,https://hail.is,https://github.com/hail-is/hail/issues/4527,1,['error'],['error']
Availability,"### Hail version:; ```; 0.2.8-590ea4ae3b83; ```; ### What you did:; ```; hl.import_bgen(; ""/Users/dking/projects/hail-data/caitlin/ukb_imp_chr22_v3.bgen"",; entry_fields=[]; ).count_rows(); ```. ### What went wrong (all error messages here, including the full java stack trace):; A spark stage was triggered. I expected it to read the number of rows from the index.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5182:219,error,error,219,https://hail.is,https://github.com/hail-is/hail/issues/5182,1,['error'],['error']
Availability,"### Hail version:; `a230321`; ### What you did:; `mt.GT[1]` on a haploid call; ### What went wrong (all error messages here, including the full java stack trace):; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 9716 in stage 3.0 failed 20 times, most recent failure: Lost task 9716.19 in stage 3.0 (TID 10515, pbt-sw-nkpn.c.broad-mpg-gnomad.internal, executor 306): java.lang.IllegalArgumentException: requirement failed; at scala.Predef$.require(Predef.scala:212); at is.hail.variant.Call$.alleleByIndex(Call.scala:128); at is.hail.expr.FunctionRegistry$$anonfun$11.apply$mcIII$sp(FunctionRegistry.scala:682); at is.hail.expr.FunctionRegistry$$anonfun$11.apply(FunctionRegistry.scala:682); at is.hail.expr.FunctionRegistry$$anonfun$11.apply(FunctionRegistry.scala:682); at is.hail.expr.BinaryFun.apply(Fun.scala:122); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3713:104,error,error,104,https://hail.is,https://github.com/hail-is/hail/issues/3713,3,"['error', 'failure']","['error', 'failure']"
Availability,"### Hail version:; `devel-62679fc21687`; ### What you did:; [ran a PRS script](https://gist.github.com/danking/9c9d77afb3ff318adc7bf79bb52d4f7d); Cluster had 100 pre-emptibles.; ![tasks page showing failures due to container exit](https://user-images.githubusercontent.com/106194/44540204-293de580-a6d4-11e8-90b8-1ecaaec45443.png); ![Job 12 page show mapPartitionsWithIndex running](https://user-images.githubusercontent.com/106194/44540205-293de580-a6d4-11e8-9893-af8edc382906.png); ![executors page showing 202 active executors, 100 dead](https://user-images.githubusercontent.com/106194/44540178-15927f00-a6d4-11e8-99e1-78755df3756c.png). This `mapPartitionsWithIndex` call is in the tree aggregate of context rdd. Judging from the fact that it's the first one, this is probably the first step of the aggregation.; ; ### What went wrong (all error messages here, including the full java stack trace):; Workers exceed memory limits, e.g. (from hail.log):; ```; 2018-08-22 17:28:37 YarnSchedulerBackend$YarnSchedulerEndpoint: WARN: Container killed by YARN for exceeding memory limits. 12.2 GB of 12 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.; 2018-08-22 17:28:37 YarnScheduler: ERROR: Lost executor 431 on pca-sw-pd61.c.daly-ibd.internal: Container killed by YARN for exceeding memory limits. 12.2 GB of 12 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.; 2018-08-22 17:28:37 TaskSetManager: WARN: Lost task 1047.0 in stage 16.0 (TID 20251, pca-sw-pd61.c.daly-ibd.internal, executor 431): ExecutorLostFailure (executor 431 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 12.2 GB of 12 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.; 2018-08-22 17:28:37 TaskSetManager: WARN: Lost task 1046.0 in stage 16.0 (TID 20250, pca-sw-pd61.c.daly-ibd.internal, executor 431): ExecutorLostFailure (executor 431 exited caused by one of the running tasks) ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4202:199,failure,failures,199,https://hail.is,https://github.com/hail-is/hail/issues/4202,2,"['error', 'failure']","['error', 'failures']"
Availability,"### Hail version:; devel-10a75bb57a6f; ### What you did:. ```; def test_rekey_correct_partition_key(self):; ht = hl.utils.range_table(5); ht = ht.add_index('a'); ht = ht.key_by('idx', 'a'); ht = ht.annotate(b=ht.idx); ht = ht.key_by('idx', 'b'); self.assertEqual(ht.aggregate(agg.sum(ht.idx)), 10); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.rvd.OrderedRVDType.<init>(OrderedRVDType.scala:21); 	at is.hail.rvd.OrderedRVDType.copy(OrderedRVDType.scala:121); 	at is.hail.expr.TableKeyBy.execute(Relational.scala:1857); 	at is.hail.expr.TableMapRows.execute(Relational.scala:2090); 	at is.hail.expr.TableKeyBy.execute(Relational.scala:1846); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:520); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:39); 	at is.hail.table.Table.aggregate(Table.scala:465); 	at is.hail.table.Table.aggregate(Table.scala:446); 	at is.hail.table.Table.aggregateJSON(Table.scala:436); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3748:329,error,error,329,https://hail.is,https://github.com/hail-is/hail/issues/3748,1,['error'],['error']
Availability,"### Hail version:; fd300f29c00349d2a9d26835e35be2b142a3505f; ### What you did:; `make -C src/main/c prebuilt && ./gradlew testCppCodegen`; ### What went wrong (all error messages here, including the full java stack trace):; ```; testCppCodegen; :compileJava UP-TO-DATE; :generateBuildInfo; :nativeLib; tar -xzf libsimdpp-2.1.tar.gz; :compileScala UP-TO-DATE; :processResources UP-TO-DATE; :classes UP-TO-DATE; :compileTestJava UP-TO-DATE; :compileTestScala UP-TO-DATE; :processTestResources UP-TO-DATE; :testClasses UP-TO-DATE; :testCppCodegen; Running test: Test method testReadWrite(is.hail.annotations.AnnotationsSuite). Gradle suite > Gradle test > is.hail.annotations.AnnotationsSuite.testReadWrite FAILED; org.apache.spark.SparkException at AnnotationsSuite.scala:76; Caused by: java.lang.AssertionError; Running test: Test method testEmptyKeys(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testEmptyKeys FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIntervalIterator(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIntervalIterator FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIntervalIteratorWorksWithGeneralEndpoints(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIntervalIteratorWorksWithGeneralEndpoints FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIterateFromUntil(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIterateFromUntil FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testLowerBound(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testLowerBound FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testQueryByKey(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testQueryByKey FAILED; java.lang.AssertionError at",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4718:164,error,error,164,https://hail.is,https://github.com/hail-is/hail/issues/4718,1,['error'],['error']
Availability,"### Hail version:; latest master. ### What you did:; remove `region.clear()` from the `it.map` function inside `RVD.persistRVRDD`. ### What went wrong (all error messages here, including the full java stack trace):. `LDPruneSuite.testNoPrune` fails giving 313 variants instead of 338.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3398:156,error,error,156,https://hail.is,https://github.com/hail-is/hail/issues/3398,1,['error'],['error']
Availability,"### Hail version:; master branch version. ### What you did; ./gradlew -Dspark.version=2.1.0 shadowJar archiveZip. ### What went wrong (all error messages here, including the full java stack trace):. -XPS-8700:~/Downloads/hail$ ./gradlew -Dspark.version=2.1.0 shadowJar archiveZip; 669187030305. FAILURE: Build failed with an exception. * Where:; Build file '/home/test/Downloads/hail/build.gradle' line: 57. * What went wrong:; A problem occurred evaluating root project 'hail'.; > Unknown Spark version 2.1.0. Set breeze.version and py4j.version properties for Spark 2.1.0. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 2.33 secs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3001:139,error,error,139,https://hail.is,https://github.com/hail-is/hail/issues/3001,4,"['Down', 'FAILURE', 'error']","['Downloads', 'FAILURE', 'error']"
Availability,"### Hail version:; reported on Jan 11 9:45 by @nikbaya on [zulip](https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/import_table.20IncompleteParseError). `00f9b64d8`; ### What you did:. ```; import hail as hl; phesant_still_more1 = hl.import_table('gs://ukb31063-mega-gwas/phenotype-files/still-more-phesant/neale_lab_parsed_and_restricted_to_QCed_samples_cat_variables_both_sexes.1.tsv',; missing='',impute=True,types={'all_sexes$userId':hl.tstr}).rename({'all_sexes$userId':'s'}); ```; ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; IncompleteParseError Traceback (most recent call last); <ipython-input-2-ebe253e83367> in <module>(); 1 phesant_still_more1 = hl.import_table('gs://ukb31063-mega-gwas/phenotype-files/still-more-phesant/neale_lab_parsed_and_restricted_to_QCed_samples_cat_variables_both_sexes.1.tsv',; ----> 2 missing='',impute=True,types={'all_sexes$userId':hl.tstr}).rename({'all_sexes$userId':'s'}); 3 # phesant_still_more2 = hl.import_table('gs://ukb31063-mega-gwas/phenotype-files/still-more-phesant/neale_lab_parsed_and_restricted_to_QCed_samples_cat_variables_both_sexes.2.tsv',; 4 # missing='',impute=True,types={'all_sexes$userId':hl.tstr}). <decorator-gen-1108> in import_table(paths, key, min_partitions, impute, no_header, comment, delimiter, missing, types, quote, skip_blank_lines, force_bgz). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561; 562 return wrapper. /home/hail/hail.zip/hail/methods/impex.py in import_table(paths, key, min_partitions, impute, no_header, comment, delimiter, missing, types, quote, skip_blank_lines, force_bgz); 1327 delimiter, missing, no_header, impu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5119:539,error,error,539,https://hail.is,https://github.com/hail-is/hail/issues/5119,1,['error'],['error']
Availability,"### Problem Description. `ExportPlink` was previously modified to resiliently handle failure of a; Spark task by including a per-task UUID. `copyMerge` was not modified to; correctly handle the directories generated by this modified; `ExportPlink`. For example, if exactly one task out of N fails during `ExportPlink`, the; temporary output directory will contain N+1 partition files. One of; these partition files is corrupted and invalid. The other N are the; output of successful task completion. The invalid file should simply be; ignored by `copyMerge`. ### Changes Made. This PR modifies `copyMerge` to take an optional list of files to; merge. If that argument is set to `None`, the original behavior; persists. The original behavior is used by `RichRDD.writeTable` and; `RichRDDByteArray.saveFromByteArrays`. These two methods use the default; Spark parallel export system. This system is not resilient to all task; failures, but *does* ensure failed tasks do not generate garbage; partitions in the output directory. Ergo, they can safely use the; original behavior of `copyMerge`. ### On Testing. I do not test this behavior because failing a task during write is a; little bit tricky. I have verified that all users of `copyMerge` now use; `copyMerge` correctly. Adding a test to `ExportPlink` would not save us; from incorrectly using `copyMerge` in the future. A longer term testing strategy that includes a Chaos Monkey that kills; entire containers during Hail Scala tests execution would protect; against this type of bug. ---. Fixes #4932",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4938:66,resilien,resiliently,66,https://hail.is,https://github.com/hail-is/hail/pull/4938,4,"['failure', 'resilien']","['failure', 'failures', 'resilient', 'resiliently']"
Availability,"### What happened?. # Executive Summary. We will pin to `orjson<=3.9.11` until https://github.com/ijl/orjson/pull/457 merges and addresses the root cause of these segfaults. This issue is resolved when orjson merges orjson#457, releases a new version, and we upgrade to it. # Details. Tests that use the py4j_backend and thus rely on orjson to (de)serialize data have been intermittently segfaulting:; ```; [2024-02-08 22:36:47] test/hail/matrixtable/test_file_formats.py::test_backward_compatability_ht[/io/resources/backward_compatability/1.6.0/table/6.ht/] Fatal Python error: Segmentation fault. Thread 0x00007fa51d817640 (most recent call first):; File ""/usr/lib/python3.9/selectors.py"", line 416 in select; File ""/usr/lib/python3.9/socketserver.py"", line 232 in serve_forever; File ""/usr/lib/python3.9/threading.py"", line 917 in run; File ""/usr/lib/python3.9/threading.py"", line 980 in _bootstrap_inner; File ""/usr/lib/python3.9/threading.py"", line 937 in _bootstrap. Thread 0x00007fa5273ff640 (most recent call first):; File ""/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py"", line 58 in run; File ""/usr/lib/python3.9/threading.py"", line 980 in _bootstrap_inner; File ""/usr/lib/python3.9/threading.py"", line 937 in _bootstrap. Current thread 0x00007fa52bd6b000 (most recent call first):; File ""/usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py"", line 217 in _rpc; File ""/usr/local/lib/python3.9/dist-packages/hail/backend/backend.py"", line 212 in table_type; ...; ```. Line 217 only does one thing: call `orjson.dumps`. https://github.com/hail-is/hail/blob/b3df76360f931f54688bb03bf5774643c0b8205e/hail/python/hail/backend/py4j_backend.py#L216-L218. Indeed, `orjson` has had [this issue since 3.9.12](https://github.com/ijl/orjson/issues/452) and we just recently updated orjson from 3.9.10 to 3.9.12:. ```; commit d2615543476bde5d01061499c92f26124b85caf3; Author: Dan King <daniel.zidan.king@gmail.com>; Date: Fri Feb 2 14:21:47 2024 -0500. [dependencies] mass upd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14299:573,error,error,573,https://hail.is,https://github.com/hail-is/hail/issues/14299,2,"['error', 'fault']","['error', 'fault']"
Availability,"### What happened?. **A Motivating Example**. The statement:. `hl.experimental.load_dataset(""gnomad_pca_variant_loadings"", version='2.1', reference_genome='GRCh38')`. raises the following error:. ```; AssertionError Traceback (most recent call last); Cell In[32], line 1; ----> 1 hl.experimental.load_dataset(""gnomad_pca_variant_loadings"", version='2.1', reference_genome='GRCh38'). File ~/.local/lib/python3.8/site-packages/hail/experimental/datasets.py:115, in load_dataset(name, version, reference_genome, region, cloud); 107 raise ValueError(f'Region {repr(region)} not available for dataset'; 108 f' {repr(name)} on cloud platform {repr(cloud)}.\n'; 109 f'Available regions: {regions}.'); 111 path = [dataset['url'][cloud][region]; 112 for dataset in datasets[name]['versions']; 113 if all([dataset['version'] == version,; 114 dataset['reference_genome'] == reference_genome])]; --> 115 assert len(path) == 1; 116 path = path[0]; 117 if path.startswith('s3://'):. AssertionError: ; ```. I'm a new Hail user and don't have the full context here, but it seems like there are at least three problems:. 1. An assert failed in production code, which indicates either the presence of a bug or an incorrect use of assert (e.g. using assert to check for value errors).; 2. The assert has no corresponding error message, so the user learns that something has gone wrong but can't easily tell what.; 3. The assert is bare. Bare asserts can get optimized out of code in ways that are difficult to foresee in advance, and are generally deprecated in favor of the `if error_condition: raise AssertionError(...)` pattern (see: https://discuss.python.org/t/stop-ignoring-asserts-when-running-in-optimized-mode/13132). **The Big Picture**. The bare assert pattern is used over 3k times in Hail. To be fair, many of these usages occur in test directories, where they're fine. But they also occur in application code, and often in the dangerous form `assert(expr1, expr2)` which will never fail (because a tuple wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12952:188,error,error,188,https://hail.is,https://github.com/hail-is/hail/issues/12952,3,"['Avail', 'avail', 'error']","['Available', 'available', 'error']"
Availability,"### What happened?. - Tried to import VariantSpark version 0.5.2 into a Google Colab notebook running Python 3.9.16, with Hail version 0.2.112 and Apache Spark version 3.3.2. When trying to import VariantSpark, the following error occurred:; `import hail as hl; import varspark.hail as vshl; vshl.init()`; `using variant-spark jar at '/usr/local/lib/python3.9/dist-packages/varspark/jars/variant-spark_2.12-0.5.2-all.jar'; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-6-3d2ff0083f18>](https://localhost:8080/#) in <cell line: 3>(); 1 import hail as hl; 2 import varspark.hail as vshl; ----> 3 vshl.init(). 4 frames; <decorator-gen-1907> in init(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, backend, driver_cores, driver_memory, worker_cores, worker_memory, gcs_requester_pays_configuration, regions). <decorator-gen-1909> in init_spark(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, gcs_requester_pays_configuration). [/usr/local/lib/python3.9/dist-packages/hail/context.py](https://localhost:8080/#) in init_spark(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, gcs_requester_pays_configuration); 425 app_name = app_name or 'Hail'; 426 gcs_requester_pays_project, gcs_requester_pays_buckets = convert_gcs_requester_pays_configuration_to_hadoop_conf_style(gcs_requester_pays_configuration); --> 427 backend = SparkBackend(; 428 idempotent, sc, spark_conf, app_name, master, local, log,; 429 quiet, append, min",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12859:225,error,error,225,https://hail.is,https://github.com/hail-is/hail/issues/12859,1,['error'],['error']
Availability,"### What happened?. - [ ] Document the AsyncFS interface, RouterAsyncFS, and the three clouds.; - [ ] Do a critical pass of the interfaces and make sure public methods don't have underscores and private methods do. When in doubt, make it private.; - [ ] Same as above but for parameters. For this, be particularly aggressive about making parameters private!; - [ ] Downgrade positional arguments to keyword-arguments as much as is feasible without severely degrading UX. ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14021:365,Down,Downgrade,365,https://hail.is,https://github.com/hail-is/hail/issues/14021,1,['Down'],['Downgrade']
Availability,### What happened?. 1. Make a copy of https://docs.google.com/document/d/1deV-i3_oMGBwUreDUKEhovdLawBdf0feshcP1h11wR0/edit; 2. Fill it out; 3. Ping #hail-on-terra in Broad Institute slack to determine next steps for publicly rolling out Batch in Azure-Terra. ### Version. 0.2.126. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13953:143,Ping,Ping,143,https://hail.is,https://github.com/hail-is/hail/issues/13953,1,['Ping'],['Ping']
Availability,"### What happened?. > I'm hitting a 500 error when I try to open a notebook on a dataproc cluster started with hail 0.2.116. hailctl dataproc connect mw nb will open the google bucket and I am able to see all ipynb files but when I try opening one, I'm met with the 500. I have no issue with hail 0.2.113. Error from the logs:. ```; May 16 14:17:07 mw116-m python[8309]: [D 14:17:07.035 NotebookApp] Path notebook/css/override.css served from /opt/conda/miniconda3/lib/python3.10/site-packages/notebook/static/notebook/css/override.css; May 16 14:17:07 mw116-m python[8309]: [E 14:17:07.041 NotebookApp] Uncaught exception GET /notebooks/gnomad-mwilson/v4/sample_qc_defs.ipynb (127.0.0.1); May 16 14:17:07 mw116-m python[8309]: HTTPServerRequest(protocol='http', host='localhost:8123', method='GET', uri='/notebooks/gnomad-mwilson/v4/sample_qc_defs.ipynb', version='HTTP/1.1', remote_ip='127.0.0.1'); May 16 14:17:07 mw116-m python[8309]: Traceback (most recent call last):; May 16 14:17:07 mw116-m python[8309]: File ""/opt/conda/miniconda3/lib/python3.10/site-packages/tornado/web.py"", line 1786, in _execute; May 16 14:17:07 mw116-m python[8309]: result = await result; May 16 14:17:07 mw116-m python[8309]: File ""/opt/conda/miniconda3/lib/python3.10/site-packages/tornado/gen.py"", line 786, in run; May 16 14:17:07 mw116-m python[8309]: yielded = self.gen.send(value); May 16 14:17:07 mw116-m python[8309]: File ""/opt/conda/miniconda3/lib/python3.10/site-packages/notebook/notebook/handlers.py"", line 95, in get; May 16 14:17:07 mw116-m python[8309]: self.write(self.render_template('notebook.html',; May 16 14:17:07 mw116-m python[8309]: File ""/opt/conda/miniconda3/lib/python3.10/site-packages/notebook/base/handlers.py"", line 507, in render_template; May 16 14:17:07 mw116-m python[8309]: return template.render(**ns); May 16 14:17:07 mw116-m python[8309]: File ""/opt/conda/miniconda3/lib/python3.10/site-packages/jinja2/environment.py"", line 1301, in render; May 16 14:17:07 mw116-m python[8309",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13059:40,error,error,40,https://hail.is,https://github.com/hail-is/hail/issues/13059,2,"['Error', 'error']","['Error', 'error']"
Availability,"### What happened?. > In regards to the https vs hail-az, I get an error for https:; > hailctl config set batch/remote_tmpdir https://kahlquisrefsa.blob.core.windows.net/test; > Error: bad value 'https://kahlquisrefsa.blob.core.windows.net/test' for parameter 'batch/remote_tmpdir' should be valid cloud storage URI such as gs://my-bucket/batch-tmp/. ### Version. 0.2.116. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13049:67,error,error,67,https://hail.is,https://github.com/hail-is/hail/issues/13049,2,"['Error', 'error']","['Error', 'error']"
Availability,"### What happened?. > Laura Gauthier: I'm struggling with some DRAGEN data that probably doesn't quite meet the VCF spec. I got the import working, but once I go to split multi-allelics, one of the annotations seems to be the wrong length because I get an array index out of bounds exception. Is there anyway to get more info on the variant that's causing the problem? VCFtool validator found a bunch of issues with FORMAT annotations and I've turned them all into count=1 strings, but there must be something else.; > ...; > Tim Poterba (he/him): yeah, the answer is that this isn't a parse failure, it's a failure of the split_multi_hts method to support haploid sex chromosome calls; > Tim Poterba (he/him): the right plan is to support sex chromosomes The Right Way and update all of Hail to infer, track, and use appropriate ploidy but that's not at all what the system looks like right now. ### Version. 0.2.117. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13149:592,failure,failure,592,https://hail.is,https://github.com/hail-is/hail/issues/13149,2,['failure'],['failure']
Availability,"### What happened?. A job that is attempted more than, say, 5 times, is probably going wrong. We should at the least log an error. Users should probably be able to set hard limits on the number of alerts. See also: https://github.com/hail-is/hail/issues/13395. ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13927:124,error,error,124,https://hail.is,https://github.com/hail-is/hail/issues/13927,1,['error'],['error']
Availability,"### What happened?. A simple `hl.init()` fails, that used to work. Maybe an error with Spark, not an expert. ### Version. 0.2.108. ### Relevant log output. ```shell; ~  python3; Python 3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)] on darwin; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; >>> hl.init(); 2023-01-27 17:15:28.940 WARN NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1758>"", line 2, in init; File ""/opt/homebrew/lib/python3.10/site-packages/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/homebrew/lib/python3.10/site-packages/hail/context.py"", line 345, in init; return init_spark(; File ""<decorator-gen-1760>"", line 2, in init_spark; File ""/opt/homebrew/lib/python3.10/site-packages/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/homebrew/lib/python3.10/site-packages/hail/context.py"", line 424, in init_spark; backend = SparkBackend(; File ""/opt/homebrew/lib/python3.10/site-packages/hail/backend/spark_backend.py"", line 188, in __init__; self._jbackend = hail_package.backend.spark.SparkBackend.apply(; File ""/opt/homebrew/lib/python3.10/site-packages/py4j/java_gateway.py"", line 1304, in __call__; return_value = get_return_value(; File ""/opt/homebrew/lib/python3.10/site-packages/py4j/protocol.py"", line 326, in get_return_value; raise Py4JJavaError(; py4j.protocol.Py4JJavaError: An error occurred while calling z:is.hail.backend.spark.SparkBackend.apply.; : java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x4d740d85) cannot access class sun.n",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12630:76,error,error,76,https://hail.is,https://github.com/hail-is/hail/issues/12630,1,['error'],['error']
Availability,"### What happened?. A user running RHEL 9 [reported an error](https://discuss.hail.is/t/hail-fails-after-installing-it-on-a-single-computer/3653) importing movie lens data when running 0.2.126 but succeeded on 0.2.120. This error did not reproduce on MacOS. We should verify which version of hail this error is introduced and whether the hail installation is fully broken or for some reason is just movie lens/a subset of functionality. ### Version. 0.2.126. ### Relevant log output. ```shell; 2023-11-20 18:25:51.813 Hail: WARN: This Hail JAR was compiled for Spark 3.3.0, running with Spark 3.3.3.; Compatibility is not guaranteed.; 2023-11-20 18:25:53.340 Hail: INFO: SparkUI: http://xxxxx:4040; 2023-11-20 18:25:54.037 Hail: INFO: Running Hail version 0.2.126-ee77707f4fab; 2023-11-20 18:27:48.120 Hail: INFO: downloading MovieLens-100k data ...; Source: https://files.grouplens.org/datasets/movielens/ml-100k.zip; 2023-11-20 18:27:50.320 Hail: INFO: importing users table and writing to data/users.ht ...; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14049:55,error,error,55,https://hail.is,https://github.com/hail-is/hail/issues/14049,4,"['down', 'error']","['downloading', 'error']"
Availability,"### What happened?. After I ran the ""make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.18 SPARK_VERSION=3.5.0"", I get the following error. > Configure project :; WARNING: Hail primarily tested with Spark 3.3.2, use other versions at your own risk. > Task :compileScala; [Error] /gpfs/fs1/home/jl/Hail2/hail/hail/src/main/scala/is/hail/HailContext.scala:127:21: value implOpMulMatrix_DMD_DVD_eq_DVD is not a member of object breeze.linalg.DenseMatrix; one error found. > Task :compileScala FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileScala'.; > Compilation failed. * Try:; > Run with --info option to get more log output.; > Run with --scan to get full insights. BUILD FAILED in 4m 52s; 2 actionable tasks: 2 executed; make: *** [build/libs/hail-all-spark.jar] Error 1. ### Version. Hail 0.2.13. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14235:148,error,error,148,https://hail.is,https://github.com/hail-is/hail/issues/14235,5,"['Error', 'FAILURE', 'error']","['Error', 'FAILURE', 'error']"
Availability,"### What happened?. After sorting our costs into ""cost of goods"", ""operating expenses"", and ""capital expenses"", I realized there are four ""operating expenses"" that are not tracked and reported with the other expenses. I regressed these costs against the core-hours to estimate the cost per core-hour. resource | intercept (USD) | cost (USD/core-hour); -- | -- | --; GCP Support Variable fee | 3.46403 +- 0.49155 | 0.00123 +- 0.00007; System logs costs SKU#1 | 13.09991 +- 3.13991 | 0.00093 +- 0.00039; System logs costs SKU#2 | 7.87838 +- 0.81695 | 0.00027 +- 0.00012; Job specifications | 5.41150 +- 0.36608 | 0.00025 +- 0.00005; Firewall policy | 0.51216 +- 0.03185 | 0.00012 +- 0.00000. To fully recover the operating expenses at our current revenue, we need an additional 0.005 USD per core-hour (which is 0.002 more than the sum of intercepts). This issue is complete after we add a new product:. resource | cost (USD/core-hour); -- | --; support-logs-specs-and-firewall-fees/1 | 0.005. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13526:699,recover,recover,699,https://hail.is,https://github.com/hail-is/hail/issues/13526,1,['recover'],['recover']
Availability,### What happened?. All batch workers should have the Ops Agent so that we have RAM and disk usage available in GCP Monitoring. This is critical for diagnosing issues on workers. ### Version. 0.2.124. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13903:99,avail,available,99,https://hail.is,https://github.com/hail-is/hail/issues/13903,1,['avail'],['available']
Availability,"### What happened?. Although it is not possible to avoid all cross-region access (and thus costs), there are some obvious preventable misuses. For example, the following pipeline should error:. ```; b = hb.Batch(regions=['us-east1']); x = b.read_input('gs://bucket-in-central1/'); b.new_job(f'cat {x}'); b.run(); ```; But the following pipeline should not error:; ```; b = hb.Batch(regions=['us-east1']); x = b.read_input('gs://bucket-in-central1/'); j = b.new_job(f'cat {x}'); j.regions(['us-central1']); ```; The following should error because the job *could* be in us-east1:; ```; b = hb.Batch(regions=['us-east1', 'us-central1']); x = b.read_input('gs://bucket-in-central1/'); b.new_job(f'cat {x}'); b.run(); ```; The following should error:; ```; b = hb.Batch(regions=['us-east1']) # remote_tmpdir is set in config file as a us-centra1 bucket; j = b.new_job(f'echo hi > {j.f}'); j2 = b.new_job(f'cat {j.f}'); b.run(); ```. ### Version. 0.2.119. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13232:186,error,error,186,https://hail.is,https://github.com/hail-is/hail/issues/13232,5,"['echo', 'error']","['echo', 'error']"
Availability,"### What happened?. At time of writing, building hail with `SPARK_VERSION=3.4.0` errors with the following message:. ```; hail/src/main/scala/is/hail/HailContext.scala:119:21: value implOpMulMatrix_DMD_DVD_eq_DVD is not a member of object breeze.linalg.DenseMatrix; ```. This is due to a major version upgrade and breaking change in the Breeze library on which spark and hail depend. The exact error is a rename and refactor. The method `DenseMatrix.implOpMulMatrix_DMD_DVD_eq_DVD` is now `HasOps.impl_OpMulMatrix_DMD_DVD_eq_DVD`. Notice the method name change and the fact that `HasOps` does not exist in the version of Breeze (1.x) that is used in Spark 3.3. Hail should build with Spark 3.4, but since we only officially support one version of Spark (whichever Dataproc currently is running), it would be reasonable to wait to fully upgrade to Spark 3.4 when [Dataproc 2.2](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.2) is GA instead of trying to do something hacky to support both versions of Breeze. ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13971:81,error,errors,81,https://hail.is,https://github.com/hail-is/hail/issues/13971,2,['error'],"['error', 'errors']"
Availability,### What happened?. Bad error message. Should be a user-level nice error. https://discuss.hail.is/t/error-while-ld-pruning-variants-hail-utils-java-fatalerror-illegalargumentexception-requirement-failed/3371. ### Version. 0.2.114. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12971:24,error,error,24,https://hail.is,https://github.com/hail-is/hail/issues/12971,3,['error'],"['error', 'error-while-ld-pruning-variants-hail-utils-java-fatalerror-illegalargumentexception-requirement-failed']"
Availability,"### What happened?. Batch workers appear to take ~2 minutes to start up but; ```; time gcloud compute instances create --machine-type n1-standard-16 dk-test --zone us-central1-a; ```. Takes 9.389s. This task is complete when:; 1. We know the average time between a create API call and the worker accepting its first job.; 2. We know, down to 5 second granularity what is blocking the worker from starting.; 3. We have reduced the average total time to 50% of the value in (1). ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13976:334,down,down,334,https://hail.is,https://github.com/hail-is/hail/issues/13976,1,['down'],['down']
Availability,"### What happened?. Below is a high level overview of how the batch driver communicates scheduled jobs to worker nodes. Scheduling loop on the driver:; 1. Select N ready jobs from the database to schedule on available workers; 2. Compute placement of a subset of the jobs in available slots in the worker pool; 3. Concurrently call `/api/v1alpha/batches/jobs/create` on available workers for each placed job. If/when the request completes successfully, the job is marked as scheduled.; 4. Once all requests complete, goto 1. On the worker, what happens inside `/api/v1alpha/batches/jobs/create`:; 1. Read metadata describing the job to schedule from the request body; 2. Using that information, load the full job spec from blob storage; 3. Spawn a task to run the job asynchronously; 4. Respond to the driver with a 200. The key point relevant to this issue is that the driver currently must wait for all the requests to workers in an iteration to complete before it starts the next iteration of the scheduler. This leaves the scheduler vulnerable to problematic workers or workers that happen to be preempted during the scheduling process. So, the driver sets a [2 second timeout](https://github.com/hail-is/hail/blob/b27737f67bf9e69f1abed2fec07fc7c921790ef8/batch/batch/driver/job.py#L585) on the call to `/api/v1alpha/batches/jobs/create`. Additionally, this general design means that in the event of a request timeout or transient error, Batch cannot guarantee that there is always at most one concurrent running attempt for a given job. This ends up being a fine (and intentional) concession in practice because the idempotent design of preemptible jobs tends to cover this scenario, but it is regardless wasted compute and cost to users. Nevertheless, we strive to minimize cases where we might halt the scheduling loop or double-schedule work, and one way to do that in the current design is to minimize the variance in latency of `/api/v1alpha/batches/jobs/create`. The largest source of this ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14456:208,avail,available,208,https://hail.is,https://github.com/hail-is/hail/issues/14456,3,['avail'],['available']
Availability,"### What happened?. Ben W reports that he can reliably cause a batch worker VM to become non-responsive, triggering the driver to kill the VM, and the job to get rescheduled. https://hail.zulipchat.com/#narrow/stream/300487-Hail-Batch-Dev/topic/workers.20which.20suddenly.20stop.20responding/near/400852561. This ticket is complete when:; 1. We have reproduced Ben's behavior on a main commit before or including 06183480d2. ; 2. We have reduced Ben's test case to something we can add as a test. ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13992:46,reliab,reliably,46,https://hail.is,https://github.com/hail-is/hail/issues/13992,1,['reliab'],['reliably']
Availability,### What happened?. Ben tried to submit a batch with 0.2.126 and it kept failing with errors due to not able to enter into a task. A quick google search showed this could be a bad nest_asyncio interaction. I recommended downgrading to 0.2.120 before this possibly related PR (#13614) went in and that unblocked Ben. I could not replicate this behavior on 3.9 or 3.11 on my laptop with 0.2.126. This error occurred on a fresh install for Ben for 3.9 and 3.11. https://hail.zulipchat.com/#narrow/stream/223457-Hail-Batch-support/topic/RuntimeError.3A.20Cannot.20enter.20into.20task/near/404939884. ### Version. 0.2.126. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14051:86,error,errors,86,https://hail.is,https://github.com/hail-is/hail/issues/14051,3,"['down', 'error']","['downgrading', 'error', 'errors']"
Availability,"### What happened?. Currently, Query on Batch waits for the full stage of workers to complete before collecting the results even in the event of a failure. Now that Query on Batch uses Job Groups, we can use the job group `cancel_after_n_failures` functionality to cancel remaining jobs in the stage after a certain number have failed. Query on Batch should set `cancel_after_n_failures = 1` so that the user can see the error of the failed partition without waiting for all the partitions to run (and paying for them). ### Version. 0.2.131. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14597:147,failure,failure,147,https://hail.is,https://github.com/hail-is/hail/issues/14597,2,"['error', 'failure']","['error', 'failure']"
Availability,"### What happened?. Currently, interacting with the billing report is a very manual process with lots of room for error. We could improve this with:. - ""This month"" / ""last month"" / ""last week"" auto-filter buttons (alongside the current manual date-entry fields); - Hide `trials`, hide `_tests`, hide `ci`, hide `benchmark`, hide `< $0.01`? (Need to be manually filtered out during a billing export); - ""Copy table contents"" button. Puts the current table contents into the user's clipboard in CSV format. Replacing the current manual ""Drag-select and copy"" action with a single button press. ### Version. Current. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14658:114,error,error,114,https://hail.is,https://github.com/hail-is/hail/issues/14658,1,['error'],['error']
Availability,"### What happened?. Dear developers,. During the process of reading a large set of VCF files from an exome sequencing study into Hail (version 0.2.126-ee77707f4fab run on Terra container terra-jupyter-hail:1.1.8 using Spark 3.3.0), I ran into an unexpected error. Using a script I have been using for years for sequence datasets, I now run into an error during parsing of certain lines from the VCF file. Specifically, the Hail outputs the error ""cannot set missing field for required type +PFloat64"". I was concerned that there may have been issues in the actual VCF file, and therefore I tested the script on older datasets that I managed to process without any problem previously; the error was recapitulated on all these old datasets. Therefore I do not think there is an intrinsic issue in the VCFs, but rather in the way the current version of Hail (inside the terra container) is parsing information from the lines. I was not capable of running older versions of the Terra container (1.0.x) because the versions of Hail implemented there are not compatible with the current version of Spark on Terra. . I hope you may have a solution to this irritating problem. I have added the scripts and logs below. . Thanks in advance,; Sean Jurgens. ### Version. 0.2.126-ee77707f4fab. ### Relevant log output. ```shell; ## PLEASE NOTE: to protect privacy as much as possible, I have removed almost all entries shown by the code, and for the few line entries that remain I have changed/randomized the numeric values. The order and structure is preserved for enrtries nonetheless. `#import libraries; import os; import hail as hl; from pprint import pprint. #### Start hail; hl.init(); hl.spark_context()`. /opt/conda/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:44: UserWarning:. Reading spark-defaults.conf to determine GCS requester pays configuration. This is deprecated. Please use `hailctl config set gcs_requester_pays/project` and `hailctl config set gcs_requester_pays/buc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:257,error,error,257,https://hail.is,https://github.com/hail-is/hail/issues/14102,4,['error'],['error']
Availability,"### What happened?. Double quote `""""` is frequently used to mean just one `""` when it appears inside a quoted field a la:. ```; a	b; 1	""""""""; ```; This contains one row whose value for column a is `1` and whose value for column b is `""`. The outer quotes are redundant indicators of the bounds of that column for that row. A less trivial case involves having a tab inside the column:. ```; a	b; 1	""	""""	""; ```; In this file, the b column's value in the first row has length three and consists of a tab, a quote character and a tab: `	""	`. Another test case. The `test.txt` contains:; ```; a	b	c; ""hello"",""a""""b"",""goodbye""; ```; This code,; ```python3; hl.import_table(""test.txt"", quote='""').collect(); ```; should return:; ```python3; [hl.Struct(a=""hello"", b=""a\""b"", c=""goodbye"")]; ```. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13563:258,redundant,redundant,258,https://hail.is,https://github.com/hail-is/hail/issues/13563,1,['redundant'],['redundant']
Availability,"### What happened?. Due to limited GPU availability, it is common for GPU private jobs (esp. preemptible) to fail multiple times with exhausted resource errors before obtaining a VM. When this happens, Batch still changes for the attempt. An example is batch 8166586, job 1, attempt ZMkGaS, instance ID batch-worker-default-job-private-u4fxc which failed with ZONE_RESOURCE_POOL_EXHAUSTED. ### Version. SaaS. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14505:39,avail,availability,39,https://hail.is,https://github.com/hail-is/hail/issues/14505,2,"['avail', 'error']","['availability', 'errors']"
Availability,### What happened?. Example failure: https://batch.azure.hail.is/batches/3883658 (nb: driver job failed even though its marked success). User report: https://hail.zulipchat.com/#narrow/stream/223457-Hail-Batch-support/topic/problem.20writing.20output.3F. ### Version. 0.2.116. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13061:28,failure,failure,28,https://hail.is,https://github.com/hail-is/hail/issues/13061,1,['failure'],['failure']
Availability,"### What happened?. Figure out why the k8s cache fails. Is this due to asyncio task cancellation? Is it a known rare transient error?. If this is a rare transient error, we should retry this a limited number of times. Example: https://batch.hail.is/batches/8071211/jobs/186. ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13909:127,error,error,127,https://hail.is,https://github.com/hail-is/hail/issues/13909,2,['error'],['error']
Availability,"### What happened?. Filtering a locus-keyed dataset will throw an assertion error if any comparison operator other than equality is used on the contig, e.g. `mt.locus.contig != 'X'`. The relevant assertion is [here](https://github.com/hail-is/hail/blob/728f43bab4a474442b61d746e1881fa450f7ade5/hail/src/main/scala/is/hail/expr/ir/ExtractIntervalFilters.scala#L644). We should add support for at least not-equals. Inequalities would technically also make sense to add, but are probably not likely to be used. If we don't add them, we should at least improve the error. ### Version. 0.2.127. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14288:76,error,error,76,https://hail.is,https://github.com/hail-is/hail/issues/14288,2,['error'],['error']
Availability,### What happened?. From Mike Wilson on hail zulip [here](https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/hail.200.2E2.2E132.20streamconstraintsexception/near/453934859). > I'm running the new vds combiner on ~340 DRAGEN gVCFs and have hit this error; >; > ```; > Error summary: StreamConstraintsException: String length (20054016) exceeds the maximum length (20000000); > ```. ### Version. 0.2.132. ### Relevant log output. ```shell; Full java stack trace:. Java stack trace:; com.fasterxml.jackson.core.exc.StreamConstraintsException: String length (20054016) exceeds the maximum length (20000000); at com.fasterxml.jackson.core.StreamReadConstraints.validateStringLength(StreamReadConstraints.java:324); at com.fasterxml.jackson.core.util.ReadConstrainedTextBuffer.validateStringLength(ReadConstrainedTextBuffer.java:27); at com.fasterxml.jackson.core.util.TextBuffer.finishCurrentSegment(TextBuffer.java:939); at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._finishString2(UTF8StreamJsonParser.java:2584); at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._finishAndReturnString(UTF8StreamJsonParser.java:2560); at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.getText(UTF8StreamJsonParser.java:335); at is.hail.relocated.org.json4s.jackson.JValueDeserializer._deserialize$1(JValueDeserializer.scala:26); at is.hail.relocated.org.json4s.jackson.JValueDeserializer._deserialize$1(JValueDeserializer.scala:48); at is.hail.relocated.org.json4s.jackson.JValueDeserializer.deserialize(JValueDeserializer.scala:57); at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323); at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:2105); at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1481); at is.hail.relocated.org.json4s.jackson.JsonMethods.parse(JsonMethods.scala:35); at is.hail.relocated.org.json4s.jackson.JsonMethods.parse$(J,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14650:277,error,error,277,https://hail.is,https://github.com/hail-is/hail/issues/14650,2,"['Error', 'error']","['Error', 'error']"
Availability,### What happened?. GCS library throws a `StorageException: Unknown Error` on 503s resulting in the below stacktrace. Such a transient error should be gracefully retried. ### Version. 0.2.124. ### Relevant log output. ```shell; hail.utils.java.FatalError: NullPointerException: null. Java stack trace:; is.hail.relocated.com.google.cloud.storage.StorageException: Unknown Error; 	|> PUT https://storage.googleapis.com/upload/storage/v1/b/aou_analysis/o?name=250k/data/utils/aou_variant_qc_250k.ht/index/part-57205-e0113aa0-c1e8-43fc-af14-ccb68d989bd5.idx/index&uploadType=resumable&upload_id=ABPtcPrw7n_weAuHvL4cEyCdL-JKVVX-HaG7fnwAjTgRn4Uxm0JdIcWYasCHyuvK36Fc1UgVJkDC8kvlFgWcDkBcEy-_jxjQZpEFxJb2W8gLRkOavA; 	|> content-range: bytes 0-50129/50130; 	|> x-goog-gcs-idempotency-token: 5e36e53c-5dce-4690-844b-2cfd6f553861; 	| ; 	|< HTTP/1.1 503 Service Unavailable; 	|< content-length: 0; 	|< content-type: text/plain; charset=utf-8; 	|< x-guploader-uploadid: ABPtcPrw7n_weAuHvL4cEyCdL-JKVVX-HaG7fnwAjTgRn4Uxm0JdIcWYasCHyuvK36Fc1UgVJkDC8kvlFgWcDkBcEy-_jxjQZpEFxJb2W8gLRkOavA; 	| ; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:185); 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:117); 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:106); 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionPutTask.call(JsonResumableSessionPutTask.java:224); 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.lambda$put$0(JsonResumableSession.java:81); 	at is.hail.relocated.com.google.cloud.storage.Retrying.lambda$run$0(Retrying.java:102); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); 	at is.hail.relocated.com.google.cloud.RetryHelper.run(Retry,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13937:68,Error,Error,68,https://hail.is,https://github.com/hail-is/hail/issues/13937,3,"['Error', 'error']","['Error', 'error']"
Availability,"### What happened?. Hail propagates nicely explained error messages from java to python when an exception is thrown in the user's pipeline. However, the hail python front end does not handle a situation where the java backend disappears entirely, which can happen in the case of an OOM killer killing the JVM. The result is an error as seen below. In such a scenario, the python front end should add a useful message suggesting that the backend is not reachable and might have run out of memory. ### Version. 0.2.130. ### Relevant log output. ```shell; File ~/Library/Python/3.9/lib/python/site-packages/hail/table.py:2814, in Table.collect(self, _localize, _timed); 2812 e = construct_expr(rows_ir, hl.tarray(t.row.dtype)); 2813 if _localize:;  2814 return Env.backend().execute(e._ir, timed=_timed); 2815 else:; 2816 return e. File ~/Library/Python/3.9/lib/python/site-packages/hail/backend/backend.py:188, in Backend.execute(self, ir, timed); 186 payload = ExecutePayload(self._render_ir(ir), {name:StreamBufferSpec}, timed); 187 try:;  188 result, timings = self._rpc(ActionTag.EXECUTE, payload); 189 except FatalError as e:; 190 raise e.maybe_user_error(ir) from None. File ~/Library/Python/3.9/lib/python/site-packages/hail/backend/py4j_backend.py:218, in Py4JBackend._rpc(self, action, payload); 216 path = action_routes[action]; 217 port = self._backend_server_port;  218 resp = self._requests_session.post(fhttp://localhost:{port}{path}', data=data); 219 if resp.status_code >= 400:; 220 error_json = orjson.loads(resp.content). File ~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:637, in Session.post(self, url, data, json, **kwargs); 626 def post(self, url, data=None, json=None, **kwargs):; 627 r""""Sends a POST request. Returns :class:Response object.; 628; 629 :param url: URL for the new :class:Request object.; (); 634 :rtype: requests.Response; 635 ;  637 return self.request(POST, url, data=data, json=json, **kwargs). File ~/Library/Python/3.9/l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14557:53,error,error,53,https://hail.is,https://github.com/hail-is/hail/issues/14557,2,['error'],['error']
Availability,"### What happened?. Hello,. I installed hail into an empty, new Python 3.12.2 virtual environment, and was not able to import it. I see a failure like this:. ```; (venv) (py312) alex@rpi400:~/hail $ python; Python 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 20:38:53) [GCC 12.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/alex/hail/venv/lib/python3.12/site-packages/hail/__init__.py"", line 2, in <module>; import pkg_resources; ModuleNotFoundError: No module named 'pkg_resources'; ```. It looks like in Python 3.12, the bundled setuptools was removed and new virtual environments will not have setuptools in them, it needs to be specifically installed through pip: https://github.com/python/cpython/issues/95299. This could be fixed either by adding `setuptools` to hail's requirements so that it will be installed when users install hail, or hail could remove usage of setuptools & its associated modules (`pkg_resources`) at runtime, as some other projects have done: https://github.com/TDAmeritrade/stumpy/issues/950. At a glance, the cleanest thing to do here may be to move off of the deprecated `pkg_resources` and to the recommended `importlib` if it has what you need: https://setuptools.pypa.io/en/latest/pkg_resources.html. I also have to admit that I discovered this while playing around with hail on a Raspberry Pi 4, so it is possible that something else broken caused this failure, but I believe I understand what's happening. Here's my full `pip freeze` for reference:. ```; (venv) (py312) alex@rpi400:~/hail $ pip freeze; aiodns==2.0.0; aiohttp==3.9.3; aiosignal==1.3.1; attrs==23.2.0; avro==1.11.3; azure-common==1.1.28; azure-core==1.30.1; azure-identity==1.15.0; azure-mgmt-core==1.4.0; azure-mgmt-storage==20.1.0; azure-storage-blob==12.19.1; bokeh==3.4.0; boto3==1.34.73; botocore==1.34.73; cachetools==5.3.3; certifi==2024.2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14428:138,failure,failure,138,https://hail.is,https://github.com/hail-is/hail/issues/14428,1,['failure'],['failure']
Availability,"### What happened?. Hello,; I have some gwas results that I have converted into a pandas dataframe. Typically with dataframes I pickle my outputs for speed and easily maintaining data types. Within All of Us we have separate analysis environments whether we're using hail or not. The environment that doesn't have hail is much cheaper for simple analyses and does not have pyspark installed. You can see in the error below when I try to reread the pickled dataframe, I get an error that it can't find the pyspark from within a hail module. If I write the dataframe as a csv, read it back in, and then pickle it then the error goes away. This suggests to me that the dataframe created by hail maintains reference to hail objects and pandas is attempting to recreate these objects when unpickling. I suspect this is not intentional. ```python; # Hail environment; vat_simplified_file = os.path.join(bucket, 'vat.ht'); gwas = hl.read_table(gwas_results_file_no_sex_chr); vat = hl.read_table(vat_simplified_file); gwas = gwas.filter(gwas.p_value <= 1e-4); combined = gwas.join(vat, how='left'); combined_pandas = combined.to_pandas(). gwas_pandas_file = os.path.join(bucket, 'gwas_results.pkl'); combined_pandas.to_pickle(gwas_pandas_file); ```. ```python; # Non hail environment without pyspark; combined_pandas = pd.read_pickle(gwas_pandas_file). ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /opt/conda/lib/python3.7/site-packages/pandas/io/pickle.py in read_pickle(filepath_or_buffer, compression, storage_options); 216 # expected ""IO[bytes]""; --> 217 return pickle.load(handles.handle) # type: ignore[arg-type]; 218 except excs_to_catch:. /opt/conda/lib/python3.7/site-packages/hail/__init__.py in <module>; 32 # E402 module level import not at top of file; ---> 33 from .table import Table, GroupedTable, asc, desc # noqa: E402; 34 from .matrixtable import MatrixTable, GroupedMatrixTable # noqa: E402. /opt/conda",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14004:411,error,error,411,https://hail.is,https://github.com/hail-is/hail/issues/14004,3,['error'],['error']
Availability,"### What happened?. Hi,; I am on a macOS Ventura and I have successfully installed hail (v 0.2.109) on a conda env. Everything seems to run properly, except that I don't get any plots. Bokeh was installed in the env, v1.4.0., pysark =3.13 and scala=2.11.8 are some relevant packages that may contribute to this issue. When starting Hail, this is the output I get:. 2023-02-20 11:07:38.798 WARN NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 3.1.3; SparkUI available at http://amaru-2.local:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.109-b71b065e4bb6; LOGGING: writing to /Users/alanmejiamaza/hail-20230220-1107-0.2.109-b71b065e4bb6.log. It seems to be that the issue comes from the spark version? which is the correct spark version for a conda env on a mac? I have followed the tutorials and seemed to work fine except for the plots. I don't have any output when invoking commands for plots. Can anyone tell me the specific versions needed to run all Hail properties?. Thanks. ### Version. 0.2.109. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12717:698,avail,available,698,https://hail.is,https://github.com/hail-is/hail/issues/12717,1,['avail'],['available']
Availability,"### What happened?. I added ""Huang"" to a billing project. This user name does not exist. It should have given me an error. ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13858:116,error,error,116,https://hail.is,https://github.com/hail-is/hail/issues/13858,1,['error'],['error']
Availability,"### What happened?. I am trying to install Hail v0.2.120 on AWS EMR 6.9.0. Versions:; - Python 3.8.16; - Java 1.8.0; - Spark 3.3.0. After updating Python to 3.8 and cloning hail repo, I compile hail using the command below. ```sh; sudo make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.0; ```. Here I get an error. ```sh ; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.aWUFJ1BMnP; ../check_pip_requirements.sh: line 13: pip-compile: command not found; ```. While I do have pip-compile installed. ```sh ; pip-compile --help; Usage: pip-compile [OPTIONS] [SRC_FILES]... Compiles requirements.txt from requirements.in, pyproject.toml, setup.cfg,; or setup.py specs. Options:; ```. Note that `make clean` did not solve the issue. see logs attached. ### Version. 0.2.120. ### Relevant log output. ```shell; BUILD SUCCESSFUL in 2m 46s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; /usr/lib64/python3.8/distutils/dist.py:274: UserWarning: Unknown distribution option: 'long_description_content_type'; warnings.warn(msg); installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.120.dist-info/WHEEL; creating 'dist/hail-0.2.120-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13445:345,error,error,345,https://hail.is,https://github.com/hail-is/hail/issues/13445,1,['error'],['error']
Availability,"### What happened?. I executed; ```; vds = hl.vds.filter_intervals(vds, pca_snps, keep=True); ```; And got this error. `pca_snps` is a Table. ; ```; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1640>"", line 2, in filter_intervals; File ""/Users/juliasealock/opt/miniconda3/lib/python3.9/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/juliasealock/opt/miniconda3/lib/python3.9/site-packages/hail/vds/methods.py"", line 739, in filter_intervals; return _parameterized_filter_intervals(vds, intervals, keep=keep,; File ""<decorator-gen-1636>"", line 2, in _parameterized_filter_intervals; File ""/Users/juliasealock/opt/miniconda3/lib/python3.9/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/juliasealock/opt/miniconda3/lib/python3.9/site-packages/hail/vds/methods.py"", line 613, in _parameterized_filter_intervals; ref_intervals = intervals.map(; AttributeError: 'list' object has no attribute 'map'; ```. ### Version. 0.2.113. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12920:112,error,error,112,https://hail.is,https://github.com/hail-is/hail/issues/12920,1,['error'],['error']
Availability,"### What happened?. I expected this to not error but it did.; ```python3; import hail as hl. x = [hl.import_vcf(f, force_bgz=True, reference_genome='GRCh38', min_partitions=k).rows().select() for f, k in (; ('hail/src/test/resources/gvcfs/HG00096.g.vcf.gz', 100),; ('hail/src/test/resources/gvcfs/HG00268.g.vcf.gz', 1); )]; hl.Table.multi_way_zip_join(x, 'data', 'new_globals').write('/tmp/foo.ht', overwrite=True); ```; The error:; ```; 2024-02-02 15:39:35.977 Hail: INFO: scanning VCF for sortedness...; 2024-02-02 15:39:37.571 Hail: INFO: Coerced sorted VCF - no additional import work to do; 2024-02-02 15:39:38.925 Hail: INFO: wrote table with 234687 rows in 1 partition to /tmp/__iruid_1841-E0rqVWB0ysj7E0SIeJeumv; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); Cell In[2], line 7; 1 import hail as hl; 3 x = [hl.import_vcf(f, force_bgz=True, reference_genome='GRCh38', min_partitions=k).rows().select() for f, k in (; 4 ('hail/src/test/resources/gvcfs/HG00096.g.vcf.gz', 100),; 5 ('hail/src/test/resources/gvcfs/HG00268.g.vcf.gz', 1); 6 )]; ----> 7 hl.Table.multi_way_zip_join(x, 'data', 'new_globals').write('/tmp/foo.ht', overwrite=True). File <decorator-gen-1242>:2, in write(self, output, overwrite, stage_locally, _codec_spec). File ~/projects/hail/hail/python/hail/typecheck/check.py:584, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 581 @decorator; 582 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 583 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 584 return __original_func(*args_, **kwargs_). File ~/projects/hail/hail/python/hail/table.py:2002, in Table.write(self, output, overwrite, stage_locally, _codec_spec); 1976 """"""Write to disk.; 1977 ; 1978 Examples; (...); 1997 If ``True``, overwrite an existing file at the destination.; 1998 """"""; 2000 hl.current_backend().validate_file(output); -> 2002 Env.backend().",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14245:43,error,error,43,https://hail.is,https://github.com/hail-is/hail/issues/14245,2,['error'],['error']
Availability,"### What happened?. I expected this to raise an error with a message like ""when indexing a matrix table, you must provide a row key and column key"".; ```; In [3]: import hail as hl; ...: mt = hl.balding_nichols_model(1, 1, 1); ...: mt2 = hl.balding_nichols_model(1,1,1); ...: ; ...: mt.annotate_rows(x=mt2[mt.locus, mt.alleles]); 2024-02-01 13:16:23.573 Hail: INFO: balding_nichols_model: generating genotypes for 1 populations, 1 samples, and 1 variants...; 2024-02-01 13:16:23.594 Hail: INFO: balding_nichols_model: generating genotypes for 1 populations, 1 samples, and 1 variants...; ---------------------------------------------------------------------------; ExpressionException Traceback (most recent call last); Cell In[3], line 5; 2 mt = hl.balding_nichols_model(1, 1, 1); 3 mt2 = hl.balding_nichols_model(1,1,1); ----> 5 mt.annotate_rows(x=mt2[mt.locus, mt.alleles]). File ~/projects/hail/hail/python/hail/matrixtable.py:818, in MatrixTable.__getitem__(self, item); 815 col_key = wrap_to_tuple(exprs[1]); 817 try:; --> 818 return self.index_entries(row_key, col_key); 819 except TypeError as e:; 820 raise invalid_usage from e. File ~/projects/hail/hail/python/hail/matrixtable.py:3193, in MatrixTable.index_entries(self, row_exprs, col_exprs); 3191 return self.index_entries(tuple(row_exprs[0].values()), col_exprs); 3192 elif len(row_exprs) != len(self.row_key):; -> 3193 raise ExpressionException(; 3194 f'Key mismatch: matrix table has {len(self.row_key)} row key fields, '; 3195 f'found {len(row_exprs)} index expressions'; 3196 ); 3197 else:; 3198 raise ExpressionException(; 3199 f""Key type mismatch: Cannot index matrix table with given expressions\n""; 3200 f"" MatrixTable row key: {', '.join(str(t) for t in self.row_key.dtype.values())}\n""; 3201 f"" Row index expressions: {', '.join(str(e.dtype) for e in row_exprs)}""; 3202 ). ExpressionException: Key mismatch: matrix table has 2 row key fields, found 1 index expressions; ```. ### Version. 0.2.127. ### Relevant log output. _No r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14237:48,error,error,48,https://hail.is,https://github.com/hail-is/hail/issues/14237,1,['error'],['error']
Availability,### What happened?. I expected to see no error messages in the logs for a JVM container. Instead I found errors relating to assertion errors when setting up log4j. https://console.cloud.google.com/logs/query;query=%2528%0Aresource.type%3D%22gce_instance%22%0AlogName:%22jvm-2%22%0Alabels.%22compute.googleapis.com%2Fresource_name%22:%22batch-worker-default-standard-np-xj3g%22%0A%2529;timeRange=PT1H;summaryFields=:false:32:beginning;cursorTimestamp=2023-07-13T18:49:03.668876534Z?project=hail-vdc. ### Version. 0.2.119. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13242:41,error,error,41,https://hail.is,https://github.com/hail-is/hail/issues/13242,3,['error'],"['error', 'errors']"
Availability,"### What happened?. I expected when I submitted a Batch job with `attributes={'foo': 1}` that it would return an error telling me the values must be strings. Instead, I got a 500 error from the server. ### Version. 0.2.128. ### Relevant log output. ```shell; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/aiohttp/web_protocol.py"", line 452, in _handle_request; resp = await request_handler(request); File ""/usr/local/lib/python3.9/dist-packages/aiohttp/web_app.py"", line 543, in _handle; resp = await handler(request); File ""/usr/local/lib/python3.9/dist-packages/aiohttp/web_middlewares.py"", line 114, in impl; return await handler(request); File ""/usr/local/lib/python3.9/dist-packages/aiohttp/web_middlewares.py"", line 114, in impl; return await handler(request); File ""/usr/local/lib/python3.9/dist-packages/gear/csrf.py"", line 27, in check_csrf_token; return await handler(request); File ""/usr/local/lib/python3.9/dist-packages/batch/utils.py"", line 19, in unavailable_if_frozen; return await handler(request); File ""/usr/local/lib/python3.9/dist-packages/gear/metrics.py"", line 28, in monitor_endpoints_middleware; response = await prom_async_time(REQUEST_TIME.labels(endpoint=endpoint, verb=verb), handler(request)) # type: ignore; File ""/usr/local/lib/python3.9/dist-packages/prometheus_async/aio/_decorators.py"", line 55, in measure; rv = await future; File ""/usr/local/lib/python3.9/dist-packages/aiohttp_session/__init__.py"", line 199, in factory; response = await handler(request); File ""/usr/local/lib/python3.9/dist-packages/gear/auth.py"", line 67, in wrapped; return await fun(request, userdata); File ""/usr/local/lib/python3.9/dist-packages/batch/utils.py"", line 45, in wrapped; return await fun(request, *args, **kwargs); File ""/usr/local/lib/python3.9/dist-packages/batch/front_end/front_end.py"", line 1531, in create_batch_fast; await _create_job_groups(db, batch_id, update_id, user, job_groups); File ""/usr/local/lib/python3.9/dist-packages/batc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14350:113,error,error,113,https://hail.is,https://github.com/hail-is/hail/issues/14350,2,['error'],['error']
Availability,"### What happened?. I installed from PyPI and obtained hail 0.2.132. I made sure I used a completely clean environment with nothing in it (using pixi). . When I did . ```; import hail; ```. I got this error:. ```; >>> import hail; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hail/__init__.py"", line 40, in <module>; from hail.utils import (; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hail/utils/__init__.py"", line 4, in <module>; from .hadoop_utils import (; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hail/utils/hadoop_utils.py"", line 7, in <module>; from hail.fs.hadoop_fs import HadoopFS; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hail/fs/hadoop_fs.py"", line 8, in <module>; from hailtop.fs.fs import FS; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hailtop/fs/__init__.py"", line 1, in <module>; from .fs_utils import (; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hailtop/fs/fs_utils.py"", line 4, in <module>; from hailtop.aiocloud.aiogoogle import GCSRequesterPaysConfiguration; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hailtop/aiocloud/aiogoogle/__init__.py"", line 1, in <module>; from .client import (; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hailtop/aiocloud/aiogoogle/client/__init__.py"", line 8, in <module>; from .storage_client import (; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hailtop/aiocloud/aiogoogle/client/storage_client.py"", line 14, in <module>; from hailtop.aiotools import FeedableAsyncIterable, WriteBuffer; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hailtop/aiotools/__init__.py"", line 1, in <module>; from .fs import (; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14630:201,error,error,201,https://hail.is,https://github.com/hail-is/hail/issues/14630,1,['error'],['error']
Availability,"### What happened?. I've been trying to run VEP on ~3k variants using QoB but keep getting an output: 'ERROR: could not find log file' error (full error attached). I was able to run chr1 and chr2 separately but when I tried, I still got the same error message.; [vep_batch_error.txt](https://hail.zulipchat.com/user_uploads/4771/FwakSVmKTEQI7695UCsdF1fw/vep_batch_error.txt). I've also tried running it on dataproc but it takes hours and won't progress, which is weird for only 3k variants. trying again now on dataproc with high memory machines. The code I'm using is:; ```python3; import hail as hl; hl.init(gcs_requester_pays_configuration='daly-neale-sczmeta', driver_cores=8, driver_memory='highmem'); HT = 'gs://schema_jsealock/de_novo_analysis/schema1_de_novo_variants_grch38.ht'. ht = hl.read_table(HT).key_by(); ht = ht.key_by(ht.locus, ht.alleles).select(); ht_vep = hl.vep(ht, ""gs://hail-us-vep/vep95-GRCh38-loftee-gcloud.json""); ht_vep.write(""gs://schema_jsealock/de_novo_analysis/downsampled_vep95_annotated_de_novo_variants.ht"", overwrite=True); ```. ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13989:103,ERROR,ERROR,103,https://hail.is,https://github.com/hail-is/hail/issues/13989,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"### What happened?. In #14675 I replaced `END` with `LEN` in VDS. In doing so, I made sure that both fields were present so as to not break people's existing pipelines. I added a hidden `_drop_end` flag to `read_vds` in order to be able to (mostly in the combiner) not have the `END` field present. This lead to a strange code pattern:. https://github.com/chrisvittal/hail/blob/f39364c177e0b009589826b2c6b3cd36c3ec359d/hail/python/hail/vds/variant_dataset.py#L44-L46. When running the final VDS+VDS merge in [`test_combiner_run`](https://github.com/chrisvittal/hail/blob/f39364c177e0b009589826b2c6b3cd36c3ec359d/hail/python/test/hail/vds/test_combiner.py#L178-L222) on the local backend, this failed with a memory error (in debug mode):. ```; RuntimeException: invalid memory access: 140a68008/00000001: not in 140a58008/00010000; ```. Applying this patch fixed `test_combiner_run`:; ```patch; diff --git a/hail/python/hail/vds/variant_dataset.py b/hail/python/hail/vds/variant_dataset.py; index 0f851e7364..01be83a982 100644; --- a/hail/python/hail/vds/variant_dataset.py; +++ b/hail/python/hail/vds/variant_dataset.py; @@ -41,9 +41,14 @@ def read_vds(; reference_data = hl.read_matrix_table(VariantDataset._reference_path(path), _intervals=intervals); variant_data = hl.read_matrix_table(VariantDataset._variants_path(path), _intervals=intervals). - reference_data = VariantDataset._add_len_end(reference_data); + # if LEN is missing, add it, _add_len is a no-op if LEN is already present; + reference_data = VariantDataset._add_len(reference_data); if _drop_end:; - reference_data = reference_data.drop('END'); + if 'END' in reference_data.entry:; + reference_data = reference_data.drop('END'); + else: # if END is missing, add it, _add_end is a no-op if END is already present; + reference_data = VariantDataset._add_end(reference_data); +; vds = VariantDataset(reference_data, variant_data); if VariantDataset.ref_block_max_length_field not in vds.reference_data.globals:; fs = hl.current_backend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14705:714,error,error,714,https://hail.is,https://github.com/hail-is/hail/issues/14705,1,['error'],['error']
Availability,"### What happened?. In older versions of hail (tested with 0.2.115), when starting a dataproc cluster with VEP, e.g.; ```{bash}; hailctl dataproc start hail-test --region australia-southeast1 --project my-project --vep GRCh38 --packages gnomad --num-workers 2; ```; the dataproc cluster command would be provided the following environment variable through the `--metadata` flag: `VEP_REPLICATE=aus-sydney`. This variable is used within the script `gs://hail-common/hailctl/dataproc/0.2.115/vep-GRCh38.sh` to determine which bucket to pull the VEP cache data from. In more recent versions (tested with 0.2.130), this `VEP_REPLICATE` variable has been changed to `VEP_REPLICATE=australia-southeast1`, however the Australian bucket containing the VEP cache data is still `aus-sydney`, meaning that the VEP data is not copied into the dataproc cluster, and when trying to run VEP I get the error `No cache found for homo_sapiens, version 95`. ### Version. 0.2.130. ### Relevant log output. ```shell; FatalError: HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:886,error,error,886,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['error'],['error']
Availability,"### What happened?. It seems that the local filesystem can, infrequently, stall when executing `rmtree`. Note that the error about the directory being non-empty is because we have a bug in `rm_dir`: we try to remove the directory even if the children tasks failed. It oddly seems to have happened on both a deploy batch and a PR batch:; - PR: https://ci.hail.is/batches/7706444/jobs/170; - deploy: https://ci.hail.is/batches/7707793/jobs/172. ```; [2023-08-02 05:33:14] test/hail/utils/test_hl_hadoop_and_hail_fs.py::test_hadoop_methods_3[local] PASSED; +++++++++++++++++++++++++++++++++++ Timeout ++++++++++++++++++++++++++++++++++++. ~~~~~~~~~~~~~~ Stack of ThreadPoolExecutor-1_1 (139802083059456) ~~~~~~~~~~~~~~~; File ""/usr/lib/python3.9/threading.py"", line 937, in _bootstrap; self._bootstrap_inner(); File ""/usr/lib/python3.9/threading.py"", line 980, in _bootstrap_inner; self.run(); File ""/usr/lib/python3.9/threading.py"", line 917, in run; self._target(*self._args, **self._kwargs); File ""/usr/lib/python3.9/concurrent/futures/thread.py"", line 81, in _worker; work_item = work_queue.get(block=True). ~~~~~~~~~~~~~~ Stack of ThreadPoolExecutor-1_0 (139802091452160) ~~~~~~~~~~~~~~~; File ""/usr/lib/python3.9/threading.py"", line 937, in _bootstrap; self._bootstrap_inner(); File ""/usr/lib/python3.9/threading.py"", line 980, in _bootstrap_inner; self.run(); File ""/usr/lib/python3.9/threading.py"", line 917, in run; self._target(*self._args, **self._kwargs); File ""/usr/lib/python3.9/concurrent/futures/thread.py"", line 81, in _worker; work_item = work_queue.get(block=True). ~~~~~~~~~~~~~~ Stack of ThreadPoolExecutor-0_0 (139802205742848) ~~~~~~~~~~~~~~~; File ""/usr/lib/python3.9/threading.py"", line 937, in _bootstrap; self._bootstrap_inner(); File ""/usr/lib/python3.9/threading.py"", line 980, in _bootstrap_inner; self.run(); File ""/usr/lib/python3.9/threading.py"", line 917, in run; self._target(*self._args, **self._kwargs); File ""/usr/lib/python3.9/concurrent/futures/thread.py"", line 81",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13361:119,error,error,119,https://hail.is,https://github.com/hail-is/hail/issues/13361,1,['error'],['error']
Availability,"### What happened?. Job cancellation by users or the batch system is a normal operation, yet error logs are emitted when the operation occurs. This will raise false alarms as alerts are sent when error logs are observed. The batch driver, and the system moreover, should not emit ERROR logs for expected operations. ### Version. 0.2.124. ### Relevant log output. ```shell; Example log:. Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1013, in _run_until_done_or_deleted; return await run_until_done_or_deleted(self.deleted_event, f, *args, **kwargs); File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 681, in run_until_done_or_deleted; raise StepInterruptedError; StepInterruptedError. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1888, in run_container; await container.run(on_completion); File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 918, in run; await self.wait(); File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 904, in wait; await self._run_fut; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1015, in _run_until_done_or_deleted; raise ContainerDeletedError from e; ContainerDeletedError; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13803:93,error,error,93,https://hail.is,https://github.com/hail-is/hail/issues/13803,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"### What happened?. Julia Sealock reported this https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/vep.20issue/near/352790173. We also saw it in test_dataproc. Cal also reported it.; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 56 in stage 4.0 failed 20 times, most recent failure: Lost task 56.19 in stage 4.0 (TID 48622) (jsealock-schema-sw-43bq.c.daly-neale-sczmeta.internal executor 3): is.hail.utils.HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 125; VEP Error output:; docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.; See 'docker run --help'. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.methods.VEP$.waitFor(VEP.scala:73); 	at is.hail.methods.VEP.$anonfun$execute$5(VEP.scala:231); 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.utils.richUtils.RichContextRDD$$anon$1.hasNext(RichContextRDD.scala:69); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collectio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:275,failure,failure,275,https://hail.is,https://github.com/hail-is/hail/issues/12936,3,"['Error', 'failure']","['Error', 'failure']"
Availability,"### What happened?. Lindo tried to use JobResourceFiles a second time after updating the original batch, but got `FileNotFoundError`. This is because the default behavior is to delete temporary files with `b.run()`. We should add this use case to our documentation, but it might also be a good idea to eagerly catch these errors if possible and provide a better error message. I don't think we can change the default value at this point. https://hail.zulipchat.com/#narrow/stream/223457-Hail-Batch-support/topic/File.20dependency.20error/near/416647170. ### Version. 0.2.127. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14177:322,error,errors,322,https://hail.is,https://github.com/hail-is/hail/issues/14177,2,['error'],"['error', 'errors']"
Availability,"### What happened?. No hail log file is available. > On 0.2.109: 5k samples and 8 interval lists -- WORKED; > 5k samples and 1 interval list -- WORKED; > On 0.2.120: 2k samples and 1 interval list -- WORKED; > On 0.2.120: 2k samples and 2 interval lists -- WORKED; > On 0.2.120: 2k samples and 4 interval list -- ERROR; > On 0.2.120: 2k samples and 8 interval list -- ERROR (edited); > ; > All of these runs were on driver: 96 CPU/684G RAM; > Workers 4 CPU and 8GB RAM; > Spark configuration allocated 512GB for driver; > ; > I have tried the above in various configurations... Maybe a specific interval list is problematic, but that does not seem to be the case; > ; > The interval lists are the same across runs.; > ; > And lastly, the error is the usual Py4J Error. Usually I address this w/ more driver RAM, but I can't go any higher and this used to work fine in Hail 0.2.109.; > ; > I tried downgrading from 120-->109, but I don't believe that I can in Terra, due to Spark incompatibilities. > filtered_mt is a MatrixTable that has already been split and filtered (to drop irrelevant variants). By the time the [following] code blocks are run, `filtered_mt = hl.read_matrix_table(filtered_mt_url)` has been executed.; > Some more information: The code after this (not shown [in the below code blocks]) does additional filtering. If I skip the step `variant_data.export(f""{variant_stat_file_path_stem}_FULL.tsv"")`, I can complete successfully. The issue is that we need the `*_FULL.tsv` output. So, I believe that this is likely a RAM issue on the driver, but this used to work. ```; variant_mt = generate_variant_stats(filtered_mt, interval_names, interval_table_dict). # Main loop to compute variant stats and save to files. # File path stem to use for saving variant stats over different interval lists; variant_stat_file_path_stem = f""{bucket}/batchE/{workflow_nickname}/variant_stats"". variant_data = variant_mt.cols(); variant_data.describe(); #variant_data.to_pandas().to_csv(f""{variant_st",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:40,avail,available,40,https://hail.is,https://github.com/hail-is/hail/issues/13960,6,"['ERROR', 'Error', 'avail', 'down', 'error']","['ERROR', 'Error', 'available', 'downgrading', 'error']"
Availability,"### What happened?. Note: this is an Azure-specific issue. When submitting a batch/job that requests more storage than is available on the temp disk of any standing worker, but doesn't request a specific number of cores or amount of memory, a NotImplementedError is raised in `batch/cloud/azure/worker/disk.py`. See this Batch record for an example of the issue in action: https://batch.azure.hail.is/batches/4563654/jobs/1. The corresponding base case to reproduce this is:. ```python; import hailtop.batch as hb; backend = hb.ServiceBackend(billing_project=""<YOUR BILLING PROJECT>""); b = hb.Batch(backend=backend, name=""storage_test""); j = b.new_job(); j.image(""ubuntu:20.04""); j.storage(""700GiB""); j.command(""df -h""); b.run(wait=False); ```. On the cluster azure.hail.is this job gets scheduled on a `Standard_D16ds_v4` instance which has a 600 GiB temp disk. On GCP, when requests exceed this amount a data disk is provisioned to service the request. While this is feasible on Azure and could be implemented, it may not be the recommended solution as temp disks are much better suited to ephemeral workloads than data disks. On clusters with a smaller standing worker (i.e. fewer cores) there is a workaround, which also possibly suggests a reasonable partial solution. This workaround is to specify a required number of cores that forces a larger VM of the same family to be provisioned. This makes a larger temp disk available for the job to leverage. The corresponding partial solution would be to take knowledge of the temp disk size for any VM into account when scheduling jobs and provision larger VMs when warranted by the storage requirement of a job. . Based on current limitations for VM core count (16) this suggests a ceiling on storage that can be allocated to any job in Azure of 600 GiB. At that point it would be necessary to allocate a data disk. This issue reproduces on both azure.hail.is and our own Azure cluster.; . ### Version. 0.2.126-cdd2c132bfa2. ### Relevant log output.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14522:122,avail,available,122,https://hail.is,https://github.com/hail-is/hail/issues/14522,1,['avail'],['available']
Availability,"### What happened?. On GNU/Linux, when spawning a process, there are practical limits to the size of the arguments array *and* the environment. These limits are documented in [the `execve` man page](https://man7.org/linux/man-pages/man2/execve.2.html). Bioinformatics tools sometimes work around this limitation by accepting a single file which contains new-line separated arguments. For example: [`bcftools --file-list NAME ...`](https://samtools.github.io/bcftools/bcftools.html). The concrete proposal was to provide an operation like `hb.file_list`:; ```python3; j.command(f'bcftools --file-list {hb.file_list(resources_list)}'); ```. The question is how to construct this file list. We could generate code to create the file but this would still fail if there were so many resources that the environment was too large. A really resilient way to do this would be for the Batch worker to mount a list of filenames into the container as a file. That gives users a robust way to project a very large number of resource filenames into the container. ### Version. 0.2.128. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14356:833,resilien,resilient,833,https://hail.is,https://github.com/hail-is/hail/issues/14356,2,"['resilien', 'robust']","['resilient', 'robust']"
Availability,"### What happened?. On startup, a Batch Worker pre-allocates network namespaces equal to the maximum number of slots on the worker (64 for a 16 core worker). When a job finishes, its network namespace is deleted and a task is created to replenish the namespace. This way, jobs seldom need to wait on the creation of a network namespace and there *should* always be one available or creating. However, sometimes the creation of a new network namespace is disrupted, causing new jobs to hang indefinitely waiting on one. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13402:369,avail,available,369,https://hail.is,https://github.com/hail-is/hail/issues/13402,1,['avail'],['available']
Availability,"### What happened?. On the driver (but this could happen anywhere), a `read` call failed in GoogleStorageFS. In particular line 205:; ```; if (reader != null) {; reader.read(bb); } else {; ```; We don't retry transient errors here or below in the other call to `read`. We only retry on the initial creation of the stream. I think we are concerned that the stream is in a bad state, possible advanced a few bytes. If we were to read from it, we might drop some data. The safe thing to do is to `seek` to the correct position. This will likely initiate a new HTTP request to GCS, which is fine, because we almost certainly lost the old connection due to the transient error. I also think we need to remove `lazyPosition`. I think we can achieve the requester pays nonsense by just relying on the `pos` from the parent class (see FS.scala). ### Version. 0.2.115-71fc978b5c22. ### Relevant log output. ```shell; Traceback (most recent call last):; File ""/usr/local/lib/python3.10/site-packages/reanalysis/summarise_clinvar_entries.py"", line 531, in <module>; main(subs=args.s, date=processed_date, variants=args.v, out=args.o); File ""/usr/local/lib/python3.10/site-packages/reanalysis/summarise_clinvar_entries.py"", line 505, in main; parse_into_table(json_path=temp_output, out_path=out); File ""/usr/local/lib/python3.10/site-packages/reanalysis/summarise_clinvar_entries.py"", line 439, in parse_into_table; ht.write(out_path, overwrite=True); File ""<decorator-gen-1106>"", line 2, in write; File ""/usr/local/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/usr/local/lib/python3.10/site-packages/hail/table.py"", line 1392, in write; Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 490, in execute; return self._cancel_on_ctrl_c(self._async_execute(ir, timed=timed)); File",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:219,error,errors,219,https://hail.is,https://github.com/hail-is/hail/issues/12983,2,['error'],"['error', 'errors']"
Availability,"### What happened?. Removing the FIXME messages in `hailtop.batch_client.aioclient` in favor of a proper issue. This error needs to be fixed for `hailtop.batch_client.aioclient.JobGroup` as well once that code merges with #14282. ```python3; # FIXME Error if this is called while within a job of the same Batch; async def wait(; self,; *,; disable_progress_bar: bool = False,; description: str = '',; progress: Optional[BatchProgressBar] = None,; starting_job: int = 1,; ) -> Dict[str, Any]:; self._raise_if_not_created(); if description:; description += ': '; if progress is not None:; return await self._wait(description, progress, disable_progress_bar, starting_job); with BatchProgressBar(disable=disable_progress_bar) as progress2:; return await self._wait(description, progress2, disable_progress_bar, starting_job); ```. I'm not sure what the best fix is for this. An advanced user who wants to use Batch inside of Batch should really be making separate job groups from the job that job group is in and waiting for the job group that job is not a part of. ### Version. 0.2.128. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14338:117,error,error,117,https://hail.is,https://github.com/hail-is/hail/issues/14338,2,"['Error', 'error']","['Error', 'error']"
Availability,"### What happened?. Reported by Ben Weisburd: https://hail.zulipchat.com/#narrow/stream/223457-Hail-Batch-support/topic/batch.20OOM.20on.20input/near/351698314. <img width=""825"" alt=""image"" src=""https://user-images.githubusercontent.com/106194/234014727-78f535be-26bc-4229-9568-a4bc72bce173.png"">. BAM file is 62.4 GB. Files are available for 60 days from today for our debugging use. ```; ""resources"": {; ""req_cpu"": ""1"",; ""req_memory"": ""standard"",; ""req_storage"": ""75Gi"",; ""preemptible"": true,; ""actual_memory"": ""3.8 GiB"",; ""actual_storage"": ""75.0 GiB"",; ""actual_cpu"": 1.0; },; ""input_files"": [; {; ""from"": ""gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai"",; ""to"": ""/io/batch/9fe5bc/inputs/Mscsi/Homo_sapiens_assembly38.fasta.fai""; },; {; ""from"": ""gs://bw2-delete-after-30-days/CHM1_CHM13_WGS2.downsampled_to_30x.bam"",; ""to"": ""/io/batch/9fe5bc/inputs/1VH03/CHM1_CHM13_WGS2.downsampled_to_30x.bam""; },; {; ""from"": ""gs://bw2-delete-after-30-days/CHM1_CHM13_WGS2.downsampled_to_30x.bam.bai"",; ""to"": ""/io/batch/9fe5bc/inputs/X7RRo/CHM1_CHM13_WGS2.downsampled_to_30x.bam.bai""; },; {; ""from"": ""gs://str-bucket/hg38/variant_catalogs/expansion_hunter/positive_loci.EHv5.006_of_293.json"",; ""to"": ""/io/batch/9fe5bc/inputs/gV89e/positive_loci.EHv5.006_of_293.json""; },; {; ""from"": ""gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta"",; ""to"": ""/io/batch/9fe5bc/inputs/eQZbT/Homo_sapiens_assembly38.fasta""; }; ],; ```. ### Version. batch. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12922:329,avail,available,329,https://hail.is,https://github.com/hail-is/hail/issues/12922,1,['avail'],['available']
Availability,"### What happened?. Reproduction example, passed on spark, fails on batch and local; ```python; import hail as hl. def main():; hl.init(backend='batch'). args = type('Args', (object,), { 'radius': 1e7, 'overwrite': True }). with hl.TemporaryDirectory(ensure_exists=True) as tmp:; mt = hl.balding_nichols_model(3, 100, 100); bm_ldadj = hl.linalg.BlockMatrix.random(100, 100). starts_and_stops = hl.linalg.utils.locus_windows(mt.locus, radius=args.radius, _localize=False); bm_ldadj = bm_ldadj._sparsify_row_intervals_expr(starts_and_stops, blocks_only=False). # sparcify to a triangle matrix; bm_ldadj = bm_ldadj.sparsify_triangle(); bm_ldadj = bm_ldadj.checkpoint(f'{tmp}/ldadj', overwrite=args.overwrite, force_row_major=True). # This is required, as the squaring/multiplication densifies, so this re-sparsifies.; ht = hl.utils.genomic_range_table(100); n = 100. r2 = bm_ldadj ** 2; r2_adj = ((n - 1.0) / (n - 2.0)) * r2 - (1.0 / (n - 2.0)); starts_and_stops = hl.linalg.utils.locus_windows(ht.locus, args.radius, _localize=False); r2_adj = r2_adj._sparsify_row_intervals_expr(starts_and_stops, blocks_only=False); r2_adj = r2_adj.sparsify_triangle(); r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite). if __name__ == '__main__':; main(); ```. ### Version. 0.2.128. ### Relevant log output. ```shell; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.128-17247d8990c6; LOGGING: writing to /home/edmund/.local/src/hail/hail-20240508-1553-0.2.128-17247d8990c6.log; Traceback (most recent call last):; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py"", line 39,",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:653,checkpoint,checkpoint,653,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['checkpoint'],['checkpoint']
Availability,"### What happened?. Searching for experimental.vcf_combiner or experimental.densify or experimental.lgt_to_gt returns links that lead to error 404. They used to work fine.; The pages don't seem to exist at all (eg https://hail.is/docs/0.2/_modules/hail/experimental/vcf_combiner/densify.html), as via a google search it also fails.; Were the pages removed for a reason? I don't see anything in the changelogs. ### Version. 0.2.117. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13377:137,error,error,137,https://hail.is,https://github.com/hail-is/hail/issues/13377,1,['error'],['error']
Availability,"### What happened?. See #13489 for context. We want to use terraform to keep track of artifact registry cleanup policies once it is available in Terraform. Relevant links:; https://github.com/hashicorp/terraform-provider-google-beta/commit/bc4aa512356891f78415d5f309bfe47b0697ac11; https://github.com/hashicorp/terraform-provider-google/issues/13824. It's not in 4.79.0 (see [what was added since then](https://github.com/hashicorp/terraform-provider-google-beta/compare/v4.79.0...main)). Releases appear to happen ~once a week, so we should be able to import into terraform in September. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13504:132,avail,available,132,https://hail.is,https://github.com/hail-is/hail/issues/13504,1,['avail'],['available']
Availability,"### What happened?. Since we guarantee a job will run at least once, there are two issues that can happen:. 1. A user can write a pipeline in which two jobs race to write the same file, e.g.; ```; j = b.new_job(); j.command('echo hello > {j.out}'); j.write_output(j.out, ""gs://bucket/final-output""); ```; 2. Or, a clever user can avoid this race with some randomness:; ```; j = b.new_job(); j.command('echo hello gsutil cp - gs://bucket/final-output-$RANDOM'); ```. The former is a really common pattern and a bit of a footgun! The latter is rare (I don't know anyone who does it) and hard to work with: how would you know the output file of the *successful* attempt?. Hail should provide some mechanism for a user to get the list of successful attempts and their outputs. One simple option is to include some kind of seeded randomness which the user can access and to return either the seed or all the draws of the successful attempt for each job in `/jobs` or for the one job in `/job/{job_id}`. For example, consider:. ```; j = b.new_job(); j.command('echo hello gsutil cp - gs://bucket/final-output-$(/hail-random-str)'); ```. Where `/hail-random-str` is a binary we mount into the container that randomly generates numbers seeded by `(batch id, job id, attempt id)`. Hail should use the same randomness to ensure that `write_output` is reliable. We might also want a way to automatically remove the output files of the non-successful (e.g. preempted) attempts. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13502:225,echo,echo,225,https://hail.is,https://github.com/hail-is/hail/issues/13502,4,"['echo', 'reliab']","['echo', 'reliable']"
Availability,"### What happened?. Sometimes when I push a branch to my fork using the `pre-push` hooks, I get errors that some scala files (which I did not touch) violate the pre-push hooks for `trailing-whitespace` and `end-of-file-fixer`. I suspect that this is because of the following:. 1. These hooks are not tested in CI and not everyone necessarily has them installed; 2. Therefore, changes that violate these hooks can make it into `main`; 3. (theory) When I run the `pre-push` hooks, many commits that I did not author are on the history that is being pushed to my fork. The pre-push hooks run on any changes on that history, and fail on those changes from 2.; 4. I am forced to use `--no-verify` or introduce trailing-whitespace fixes into an irrelevant PR. Note that there are two ways to satisfy the title. The easiest thing might to not run the untested hooks on `pre-push`, but preferably we should just test all the pre-commit hooks in CI. ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13875:96,error,errors,96,https://hail.is,https://github.com/hail-is/hail/issues/13875,1,['error'],['errors']
Availability,"### What happened?. Still a lot of deadlock errors. Largely from MJC https://cloudlogging.app.goo.gl/N8hoXPWYYWLiDPPi9. Looks like workers are leaving tasks running when they shutdown https://cloudlogging.app.goo.gl/JFYoACF9qcDvCaqk8. Looks like we need to set the severity correctly in the worker logs. I'm also seeing a lot of this. ~~WARNING: Published ports are discarded when using host network mode; Also looks like we incorrectly log a ContainerTimeoutError as an error log even though that's a user error: https://cloudlogging.app.goo.gl/TUGWNxnFiBiEdsDo9~~ Moved to https://github.com/hail-is/hail/issues/14262. And we log ImageCannotBePulled as an error even though that's a user error: https://cloudlogging.app.goo.gl/TchqwUKNCrd6qqmh7. Also a few like this: Unknown child process pid 12331, will report returncode 255. ### Version. 0.2.127. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14240:44,error,errors,44,https://hail.is,https://github.com/hail-is/hail/issues/14240,5,['error'],"['error', 'errors']"
Availability,"### What happened?. Struct decoding currently uses `Region.loadBit` which:; 1. Calculates the address of the byte has this bit (e.g. the 65th bit is in the second byte).; 2. Loads the byte out of memory.; 3. Masks the bit out of the byte.; 4. Compares to zero. We don't have concrete data, but we suspect that the JVM can't avoid loading the byte out of memory 8 times. If we can instead load it once per 8 missing fields, there may be a speed up for structs that are frequently decoded (e.g. an entry struct). ### See also. - https://github.com/hail-is/hail/issues/13792#issuecomment-1761652107 . ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13811:208,Mask,Masks,208,https://hail.is,https://github.com/hail-is/hail/issues/13811,1,['Mask'],['Masks']
Availability,"### What happened?. TBD. ### Version. 0.2.172. ### Relevant log output. ```shell; 24/02/05 11:52:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 3.3.2; SparkUI available at http://192.168.1.140:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-d82c34a83360; LOGGING: writing to /private/tmp/varo/avro/hail-20240205-1152-0.2.127-d82c34a83360.log; 2024-02-05 11:53:03.679 Hail: INFO: import_gvs: Importing and writing site filters to temporary storage; Traceback (most recent call last):; File ""/Users/dking/projects/gatk/scripts/variantstore/wdl/extract/hail_gvs_import.py"", line 180, in <module>; create_vds(arguments, vds_path, references_path, temp_path, use_classic_vqsr,; File ""/Users/dking/projects/gatk/scripts/variantstore/wdl/extract/hail_gvs_import.py"", line 35, in create_vds; import_gvs.import_gvs(; File ""<decorator-gen-1896>"", line 2, in import_gvs; File ""/Users/dking/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/projects/gatk/scripts/variantstore/wdl/extract/import_gvs.py"", line 211, in import_gvs; site.write(site_path, overwrite=True); File ""<decorator-gen-1224>"", line 2, in write; File ""/Users/dking/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/miniconda3/lib/python3.10/site-packages/hail/table.py"", line 2002, in write; Env.backend().execute(; File ""/Users/dking/miniconda3/lib/python3.10/site-packages/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/Users/dking/miniconda3/lib/python3.10/site-packages/hail/backend/backend.py"", l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14249:405,avail,available,405,https://hail.is,https://github.com/hail-is/hail/issues/14249,1,['avail'],['available']
Availability,"### What happened?. Tasks that depend on the DB and TaskManager, like the scheduler, need to be properly cancelled upon shutdown before the DB/TaskManager are shutdown. This causes noisy errors in the logs and alerts. ### Version. 0.2.120. ### Relevant log output. ```shell; Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/gear/database.py"", line 190, in async_init; self.conn = await aenter(self.conn_context_manager); File ""/usr/local/lib/python3.8/dist-packages/gear/database.py"", line 79, in aenter; return await acontext_manager.__aenter__() # pylint: disable=unnecessary-dunder-call; File ""/usr/local/lib/python3.8/dist-packages/aiomysql/utils.py"", line 134, in __aenter__; self._conn = await self._coro; File ""/usr/local/lib/python3.8/dist-packages/aiomysql/pool.py"", line 139, in _acquire; raise RuntimeError(""Cannot acquire connection after closing pool""); RuntimeError: Cannot acquire connection after closing pool. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/hailtop/utils/utils.py"", line 895, in retry_long_running; return await f(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/hailtop/utils/utils.py"", line 917, in run_if_changed; should_wait = await f(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/batch/driver/instance_collection/pool.py"", line 591, in schedule_loop_body; user_resources = await self.compute_fair_share(); File ""/usr/local/lib/python3.8/dist-packages/batch/driver/instance_collection/pool.py"", line 499, in compute_fair_share; return await self._compute_fair_share(free_cores_mcpu); File ""/usr/local/lib/python3.8/dist-packages/batch/driver/instance_collection/pool.py"", line 525, in _compute_fair_share; async for record in records:; File ""/usr/local/lib/python3.8/dist-packages/gear/database.py"", line 320, in execute_and_fetchall; async with self.start() as tx:; File ""/usr/local/lib/python3.8/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13324:187,error,errors,187,https://hail.is,https://github.com/hail-is/hail/issues/13324,1,['error'],['errors']
Availability,### What happened?. The GSA keys in Azure can expire without any notification to us developer or automated system to rotate them. This ticket is complete when:; - [ ] Azure auth-driver periodically checks for any expired keys and logs WARN for soon-to-expire (within 1 month) and ERROR for expired.; - [ ] Azure auth-driver automatically rotates keys when they are 1 month from expiration. ### Version. 0.2.126. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14104:280,ERROR,ERROR,280,https://hail.is,https://github.com/hail-is/hail/issues/14104,1,['ERROR'],['ERROR']
Availability,"### What happened?. The NDArrayNumericExpression currently lacks a max method that allows users to compute the maximum value along a specified axis of the NDArray, akin to numpy's max method. Implementing this feature would enhance the functionality and user-friendliness of the Hail library. # Expected Behavior with Examples:. ## Basic Usage:. The max method can be called on an NDArrayNumericExpression object to return the maximum value along a specified axis.; If no axis is specified, it should return the maximum value in the entire NDArray.; Example:. ```python; import hail as hl. # Creating an NDArrayNumericExpression object; nd = hl.nd.array([[1, 2, 3], [4, 5, 6]]). # Getting the maximum value along axis 0; max_along_axis0 = nd.max(axis=0). # Getting the maximum value along axis 1; max_along_axis1 = nd.max(axis=1). # Getting the maximum value in the entire array; overall_max = nd.max(). # Expected outputs; # max_along_axis0: [4, 5, 6]; # max_along_axis1: [3, 6]; # overall_max: 6; ```. ## Handling of NaN Values:; The method should be able to handle NaN values, similar to numpy, where an optional parameter can be provided to ignore NaN values.; Example:. ```python; import hail as hl; import numpy as np. # Creating an NDArrayNumericExpression object with NaN values; nd = hl.nd.array([[1, np.nan, 3], [4, 5, np.nan]]). # Getting the maximum value while ignoring NaN values; max_ignore_nan = nd.max(axis=1, ignore_nan=True). # Expected output: [3, 5] instead of [nan, nan]; ```. ## Errors and Exceptions:; Appropriate errors and exceptions should be raised for invalid inputs, such as non-integer or out-of-bound axis values. ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13781:1502,Error,Errors,1502,https://hail.is,https://github.com/hail-is/hail/issues/13781,2,"['Error', 'error']","['Errors', 'errors']"
Availability,"### What happened?. The `hailtop.batch` client uploads a script file when the command becomes too large. This functionality frees users from thinking about the size of their commands. It's a great abstraction!. The client *does not* provide a mechanism to automatically upload local files or local directories which means that users must messily combine all their code and supporting data into one big file. For example,. ```python; local_in = hb.read_input('/path/to/local/script.sh'); local_data = hb.read_input('/path/to/small/local/reference.dat'). j = b.new_job(); j.command(f'bash {local_in} {local_data} {other_job.out_file} > {j.out_file}'); ```. It need not necessarily be `hb.read_input`, but it does seem like a good way to re-use an extant interface. `hailtop.batch` should upload those files when it uploads large script files and then download them to the appropriate jobs. ### Version. 0.2.128. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14354:849,down,download,849,https://hail.is,https://github.com/hail-is/hail/issues/14354,1,['down'],['download']
Availability,"### What happened?. The error below shows an assertion error in the client code for the GCP activity log. Some aspect of the logging API client code has faulty invariants/assumptions about the logging API. ### Version. 0.2.120. ### Relevant log output. ```shell; Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/hailtop/utils/utils.py"", line 895, in retry_long_running; return await f(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/hailtop/utils/utils.py"", line 941, in loop; await f(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/batch/cloud/gcp/driver/driver.py"", line 170, in process_activity_logs; await process_outstanding_events(self.db, _process_activity_log_events_since); File ""/usr/local/lib/python3.8/dist-packages/batch/driver/driver.py"", line 19, in process_outstanding_events; mark = await process_events_since(mark); File ""/usr/local/lib/python3.8/dist-packages/batch/cloud/gcp/driver/driver.py"", line 160, in _process_activity_log_events_since; return await process_activity_log_events_since(; File ""/usr/local/lib/python3.8/dist-packages/batch/cloud/gcp/driver/activity_logs.py"", line 114, in process_activity_log_events_since; async for event in await activity_logs_client.list_entries(body=body):; File ""/usr/local/lib/python3.8/dist-packages/hailtop/aiocloud/aiogoogle/client/logging_client.py"", line 25, in __anext__; assert self._page; AssertionError; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13332:24,error,error,24,https://hail.is,https://github.com/hail-is/hail/issues/13332,3,"['error', 'fault']","['error', 'faulty']"
Availability,"### What happened?. The following fails:; ```; import hail as hl; hl.init(); ````; with the error:; ```; ImportError: cannot import name 'getargspec' from 'inspect' (/usr/local/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py); ```; when running Python 3.11. The code importing `getargspec` is the Parsimonious library (see stacktrace below). ### Version. 0.2.109. ### Relevant log output. ```shell; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); Cell In[1], line 1; ----> 1 import hail as hl; 2 hl.init(). File /usr/local/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/hail/__init__.py:33; 14 __doc__ = r""""""; 15 __ __ <>__; 16 / /_/ /__ __/ /; (...); 27 To report a bug, please open an issue: https://github.com/hail-is/hail/issues; 28 """"""; 30 # F403 'from .expr import *' used; unable to detect undefined names; 31 # F401 '.expr.*' imported but unused; 32 # E402 module level import not at top of file; ---> 33 from .table import Table, GroupedTable, asc, desc # noqa: E402; 34 from .matrixtable import MatrixTable, GroupedMatrixTable # noqa: E402; 35 from .expr import * # noqa: F401,F403,E402. File /usr/local/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/hail/table.py:8; 5 import pyspark; 6 from typing import Optional, Dict, Callable, Sequence; ----> 8 from hail.expr.expressions import Expression, StructExpression, \; 9 BooleanExpression, expr_struct, expr_any, expr_bool, analyze, Indices, \; 10 construct_reference, to_expr, construct_expr, extract_refs_by_indices, \; 11 ExpressionException, TupleExpression, unify_all, NumericExpression, \; 12 StringExpression, CallExpression, CollectionExpression, DictExpression, \; 13 IntervalExpression, LocusExpression, NDArrayExpression, expr_stream; 14 from hail.expr.types import hail_type, tstruct, types_match, tarray, tset, dtypes_from_pandas; 15 from hail.expr.table_type import ttable. Fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12759:92,error,error,92,https://hail.is,https://github.com/hail-is/hail/issues/12759,1,['error'],['error']
Availability,"### What happened?. The following is a valid `Dockerfile` that does not result in a user entry in `/etc/passwd` in the image. ```; FROM ubuntu:22.04; USER ""1001""; ```. This fails in Batch with the error `ValueError: Container user not found in image's /etc/passwd` because it only supports specifying user and group names instead of also uid/gids that may or may not actually exist in the image. See [here](https://docs.docker.com/engine/reference/builder/#user) for more information on the `USER` directive. This can be be fixed by either properly implementing the `USER` directive in Hail Batch or switching from `crun` to using a higher-level runtime like `podman` that will handle this for us. The latter might be better long-term (podman now supports specifying a user-provided `upperdir` which we must handle ourselves for XFS quota setting as well as user-provided network namespaces). EDIT: See comment, this also requires `hailtop.batch` not to create the tmpdir if there are no input or output files for the job. ### Version. 0.2.123. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13679:197,error,error,197,https://hail.is,https://github.com/hail-is/hail/issues/13679,1,['error'],['error']
Availability,"### What happened?. This is a known issue in our underlying serialization library: https://github.com/uqfoundation/dill/issues/609. I've discovered that if you have dill 0.3.7 (latest) and try to use our image (which has dill 0.3.5.1) you get this error:. Traceback (most recent call last):; File ""<string>"", line 27, in <module>; File ""/usr/local/lib/python3.10/site-packages/dill/_dill.py"", line 373, in load; return Unpickler(file, ignore=ignore, **kwds).load(); File ""/usr/local/lib/python3.10/site-packages/dill/_dill.py"", line 646, in load; obj = StockUnpickler.load(self); File ""/usr/local/lib/python3.10/site-packages/dill/_dill.py"", line 805, in _create_code; return CodeType(args[0], 0, 0, *args[1:]); TypeError: code expected at most 16 arguments, got 19; Switching local dill to the remote version eliminates the error. Fix is to ensure the *de*-serializer is >0.3.5.1. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13535:248,error,error,248,https://hail.is,https://github.com/hail-is/hail/issues/13535,2,['error'],['error']
Availability,"### What happened?. This is really confusing for users. The error is about incompatible number of fields (because the ""locus"" is used for the row_key but the mt has a two-field row key, so Hail tells us we're trying to index the row_key with one field and that does not work. ### Version. 0.2.119. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13280:60,error,error,60,https://hail.is,https://github.com/hail-is/hail/issues/13280,1,['error'],['error']
Availability,"### What happened?. This probably means rethinking our use of rich. We want a little header of things like total cluster size, cores available for us, and cores starting up. Then we want a table of jobs that we've run with the URLs and whatnot. ### Version. 0.2.116. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13063:133,avail,available,133,https://hail.is,https://github.com/hail-is/hail/issues/13063,1,['avail'],['available']
Availability,"### What happened?. This works:. ```; foo = foo.annotate(csq=foo.gene.map(lambda _: 1)); foo.show(); ```. This fails:. ```; foo = foo.annotate(csq=foo.gene.map(lambda _: hl.rand_cat([0.3, 0.2, 0.5], seed=0))); foo.show(); ```. ```; FatalError: ClassCastException: null. Java stack trace:; java.lang.RuntimeException: typ: inference failure:; 	at is.hail.expr.ir.IR.typ(IR.scala:38); 	at is.hail.expr.ir.IR.typ$(IR.scala:33); 	at is.hail.expr.ir.ToStream.typ(IR.scala:300); 	at is.hail.expr.ir.IRParser$.$anonfun$ir_value_expr_1$81(Parser.scala:1111); 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); 	at is.hail.expr.ir.IRParser$.$anonfun$parse_value_ir$1(Parser.scala:2157); 	at is.hail.expr.ir.IRParser$.parse(Parser.scala:2153); 	at is.hail.expr.ir.IRParser$.parse_value_ir(Parser.scala:2157); 	at is.hail.backend.spark.SparkBackend.$anonfun$parse_value_ir$2(SparkBackend.scala:691); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:62); 	at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$1(SparkBackend.scala:345); 	at is.hail.backend.spark.SparkBackend.$anonfun$parse_value_ir$1(SparkBackend.scala:690); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59); 	at is.hail.backend.spark.SparkBackend.parse_value_ir(SparkBackend.scala:689); 	at sun.reflect.GeneratedMethodAccessor193.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13693:332,failure,failure,332,https://hail.is,https://github.com/hail-is/hail/issues/13693,1,['failure'],['failure']
Availability,"### What happened?. Try running a job with `_machine_type: 'n1-highmem-64'`. This is necessary to get enough memory for some larger jobs (> ~200GB). Startup on the batch worker fails because the job is calculating how many theoretical network namespaces it could support (4 per CPU, 64 CPUS, plus some for JVMs), but not considering that the IPv4 schema puts a hard limit of 255 on namespaces if only one subnet value is changing each time. ### Version. Live 7/30/24. ### Relevant log output. _No response_. ### Security considerations:. Low risk of impacting security. High CPU machine types are not materially different from others with respect to security considerations, and the bug is a simple logic error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14644:705,error,error,705,https://hail.is,https://github.com/hail-is/hail/issues/14644,1,['error'],['error']
Availability,"### What happened?. Try writing to a bucket to which your service account has read-only access:; ```; hl.utils.range_table(5,n_partitions=5).write('gs://neale-bge/foo.ht'); ```. https://batch.hail.is/batches/8042383. The client gets an error like this:; ```; Java stack trace:; is.hail.relocated.com.google.cloud.storage.StorageException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/1-day/o/parallelizeAndComputeWithIndex%2FO3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=%2Fresult.0?alt=media; No such object: 1-day/parallelizeAndComputeWithIndex/O3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=/result.0; 	at is.hail.relocated.com.google.cloud.storage.StorageException.translate(StorageException.java:165); 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:298); 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.load(HttpStorageRpc.java:729); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.lambda$readAllBytes$20(StorageImpl.java:610); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:65); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.run(StorageImpl.java:1515); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:610); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:599); 	at is.hail.io.fs.GoogleStorageFS.$anonfun$readNoCompression$1(GoogleStorageFS.scala:280); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.io.fs.GoogleStorageFS.readNoCompression(GoogleStorageFS.scala:278); 	at is.hail.io.fs.RouterFS.readNoCompression(RouterFS.scala:25); 	at is.hail.backend.service.ServiceBac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:236,error,error,236,https://hail.is,https://github.com/hail-is/hail/issues/13697,2,"['down', 'error']","['download', 'error']"
Availability,"### What happened?. Upon worker shutdown, we warn errors if there are any unclosed asyncio Tasks before the process exits. Lately, the worker logs have been noisy with such warnings. See [here](https://console.cloud.google.com/logs/query;query=resource.type%3D%22gce_instance%22%0AlogName:%22workerlog%22%0Aseverity!%3D%22INFO%22%0Alabels.%22compute.googleapis.com%2Fresource_name%22:%22batch-worker-default%22;pinnedLogId=2024-03-27T15:37:03.406989417Z%2F1ye73wf703wad;cursorTimestamp=2024-03-27T15:37:03.458721962Z;duration=P1D?project=hail-vdc) for an example. We should investigate and make sure all tasks are properly closed so that workers can shutdown gracefully. This may also be relevant to #14261, as the running theory is that the nonsensical assertion error is a byproduct of trying to log after the python process is partially torn down. Ideally, we shouldn't have anything left to log once the process tries to exit but this might happen if there are unjoined tasks. ### Version. 0.2.128. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14424:50,error,errors,50,https://hail.is,https://github.com/hail-is/hail/issues/14424,3,"['down', 'error']","['down', 'error', 'errors']"
Availability,### What happened?. Users need a way to control their risk tolerance for preemptions. ### Version. 0.2.120. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13395:59,toler,tolerance,59,https://hail.is,https://github.com/hail-is/hail/issues/13395,1,['toler'],['tolerance']
Availability,### What happened?. We are leaving tasks alive when workers shut down and we do not know which tasks they are. This issue has two parts:. 1. Fix `dump_all_stacktraces` to actually show all the outstanding tasks. Perhaps `log.debug` isn't generating output b/c of our logging configuration.; 2. Figure out why these tasks are running and prevent them from staying running. Several examples [here](https://cloudlogging.app.goo.gl/aMfqzLB4FBa864WJ7). ### Version. 0.2.124. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13908:41,alive,alive,41,https://hail.is,https://github.com/hail-is/hail/issues/13908,2,"['alive', 'down']","['alive', 'down']"
Availability,"### What happened?. We expect the matrix table abstraction to break down at 2M+ samples. Consider that each row now has 2M entries. Even if all the RAM of a highmem machine was made available to row processing, we only have 6.5kB per sample. This is a fair bit of memory! But many reasonable Hail pipelines will generate enough garbage to overflow this. We must develop a block-partitioned matrix table. Instead of each partition containing the entries for every column and a subset of rows, each partition will contain the entries for a subset of rows and columns. While there are many ways to do this partitioning, a simple and workable first try is a ""grid""-like partitioning. Every matrix table has a set of row-key intervals and column-key intervals which define the partitioning. The bounds of the partitions are given by the cross product of these sets of intervals. The visual conception of the partitioning of this matrix table (with its globals, column margin data, row margin data, and entry data) might look like:. ```; +--+ +-----+--+--++---+------+------+; | | | | | || | | |; +--+ +-----+--+--++---+------+------+. ck1 ck2 ...; +--+ rk1 +-----+--+--++---+------+------+; | | | | | || | | |; | | | | | || | | |; +--+ rk2 +-----+--+--++---+------+------+; | | | | | || | | |; +--+ ... +-----+--+--++---+------+------+; | | | | | || | | |; | | | | | || | | |; | | | | | || | | |; +--+ +-----+--+--++---+------+------+; | | | | | || | | |; | | | | | || | | |; +--+ +-----+--+--++---+------+------+; +--+ +-----+--+--++---+------+------+; | | | | | || | | |; | | | | | || | | |; | | | | | || | | |; +--+ +-----+--+--++---+------+------+; ```. The first row-key interval is `[rk1, rk2)`. The first col-key interval is `[ck1, ck2)`. These intervals are define a ""rectangle"" corresponding to the first partition. . All the partitions in the fourth partition column are empty (perhaps these column keys are absent in this dataset). Likewise, all the partitions in the fifth partition row are emp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13800:68,down,down,68,https://hail.is,https://github.com/hail-is/hail/issues/13800,2,"['avail', 'down']","['available', 'down']"
Availability,"### What happened?. We have a dataset with joint call multi-sample VCF files (not from imputation). We converted those multi-sample VCFs to hailmatrix tables with following WDL code in Terra:. ```python; import hail as hl. hl.init(spark_conf={""spark.driver.memory"": ""~{memory_gb}g""}). callset = hl.import_vcf(""~{source_vcf}"",; array_elements_required=False,; force_bgz=True,; reference_genome='~{reference_genome}'). callset.write(""~{target_prefix}"", overwrite=True); ```. After sample filtering, we want to export it to VCF. ```python; import hail as hl. hl.init(spark_conf={; ""spark.driver.memory"": ""~{memory_gb}g"",; ""spark.local.dir"": ""./tmp""; },; tmp_dir=""./tmp"",; local_tmpdir=""./tmp"",; idempotent=True); hl.default_reference(""~{reference_genome}""). mt = hl.read_matrix_table(""~{input_hail_mt_path}""); hl.export_vcf(mt, ""~{hail_vcf}"", tabix = False); ```. It worked on chr1 to chr22, but failed at chrX and chrY with error: VCF spec does not support phased haploid calls. What should we do to export chrX and chrY?. ### Version. 0.2.127-py3.11. ### Relevant log output. ```shell; Traceback (most recent call last):; File ""<stdin>"", line 14, in <module>; File ""<decorator-gen-1448>"", line 2, in export_vcf; File ""/usr/local/lib/python3.10/dist-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/usr/local/lib/python3.10/dist-packages/hail/methods/impex.py"", line 634, in export_vcf; Env.backend().execute(ir.MatrixWrite(dataset._mir, writer)); File ""/usr/local/lib/python3.10/dist-packages/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/usr/local/lib/python3.10/dist-packages/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/usr/local/lib/python3.10/dist-packages/hail/backend/py4j_backend.py"", line 220, in _rpc; raise fatal_error_from_java_error_triplet(; hail.utils.java.FatalError: HailException: VCF spec does not support pha",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14330:922,error,error,922,https://hail.is,https://github.com/hail-is/hail/issues/14330,1,['error'],['error']
Availability,"### What happened?. We have been burned by rare transient errors in Google Cloud Storage three times now. 1. https://github.com/hail-is/hail/pull/14080; 2. https://github.com/hail-is/hail/issues/13721; 3. https://github.com/hail-is/hail/issues/13937. > Fool me once, shame on you, fool me twice shame on me. Before releases, Hail *must* run tests that read on the order of 10 TiB of data so as to ensure that any changes since the last release do not introduce rare transient bugs or at-scale-only memory issues that our users will discover. There are at least four tests in my mind:; 1. Large-scale linear algebra (e.g. PC-Relate & LD-Prune).; 2. gnomAD style frequency calculations on 1M samples grouped 500 ways.; 3. The VDS Combiner.; 4. `show` on 1M samples. ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14082:58,error,errors,58,https://hail.is,https://github.com/hail-is/hail/issues/14082,1,['error'],['errors']
Availability,"### What happened?. We have reported to their GitHub, but we don't have a simple enough repro for them to make progress. https://github.com/Azure/azure-sdk-for-java/issues/35125. Personal correspondence with some MSFT researchers suggested there could be an issue with threading:; > It sort of reminds me of an issue we saw with Cromwell where their old akka pool code caused a bunch of unexpected network behavior that broke their API in certain cases. I've asked if BlobServiceClient is thread-safe or not. We share an object of that class, but none of the things it produces (e.g. blobs). We know that the java.io libraries can improperly drop an HTTP response if it is followed by a TCP RST. In particular, we've seen this happen when a server is load shedding and sends an HTTP ""429 Too Many Requests"" rapidly followed by a TCP RST. This might explain the ""Connection reset"" errors that we sometimes see. We have fewer intuitions about the ""Stream is already closed"". That specific error was reported to Azure in the aforementioned GitHub issue. We treat both stream is closed and connection reset as ""limited retry"" errors. We might retry too quickly. Our initial delay is `100ms * x` where `x` is drawn uniformly from `[0, 1]`. Perhaps we should try an initial delay of at least 1s? . For example, [Azure gives as an example retrying after 2s, 4s, 10s, and 30s](https://learn.microsoft.com/en-us/azure/storage/blobs/storage-performance-checklist#timeout-and-server-busy-errors). Google's [code examples](https://cloud.google.com/storage/docs/retry-strategy#client-libraries_1) suggest an initial delay of 1s with a multiplier of 2. AWS seems to use 500ms as the [default base backoff for ""throttled"" exceptions](https://github.com/aws/aws-sdk-java/blob/master/aws-java-sdk-core/src/main/java/com/amazonaws/retry/PredefinedBackoffStrategies.java#L39). ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13351:880,error,errors,880,https://hail.is,https://github.com/hail-is/hail/issues/13351,4,['error'],"['error', 'errors']"
Availability,"### What happened?. We observed this error log message . ```; deleting disk batch-disk-3d106c666a364d82bec3 from instance that no longer exists; ```. followed by what appears to be an endless stream of the following assertion error in the background task loop that tries to delete orphaned disks:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py"", line 915, in retry_long_running; return await f(*args, **kwargs); File ""/usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py"", line 959, in loop; await f(*args, **kwargs); File ""/usr/local/lib/python3.9/dist-packages/batch/cloud/gcp/driver/driver.py"", line 180, in delete_orphaned_disks; await delete_orphaned_disks(; File ""/usr/local/lib/python3.9/dist-packages/batch/cloud/gcp/driver/disks.py"", line 30, in delete_orphaned_disks; async for disk in await compute_client.list(f'/zones/{zone}/disks', params=params):; File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiocloud/aiogoogle/client/compute_client.py"", line 59, in __anext__; assert 'pageToken' not in self._request_params; AssertionError; ```. This is an invalid state for the `PagedIterator` to be in, and could imply that this garbage disk collection loop just doesn't work. We should track down the broken invariant here and fix it, if possible testing that the async iterator works correctly. ### Version. 0.2.132. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14613:37,error,error,37,https://hail.is,https://github.com/hail-is/hail/issues/14613,3,"['down', 'error']","['down', 'error']"
Availability,### What happened?. We should use a more obvious name like `downsample=False`. ### Version. 0.2.124. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13696:60,down,downsample,60,https://hail.is,https://github.com/hail-is/hail/issues/13696,1,['down'],['downsample']
Availability,"### What happened?. We're dividing by X in two places when it should be Y for computing E10. https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/P.28I.3D1.7CZ.3D0.29.20computation.20in.20IBD/near/403886796. This is a trivial fix, but I want to make sure the value for E11 is also correct. We're using T/2 where as in the paper it's 1. Regardless, we need better tests for IBD that would have caught this error. ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14052:432,error,error,432,https://hail.is,https://github.com/hail-is/hail/issues/14052,1,['error'],['error']
Availability,"### What happened?. When I try select some rows (10) of a large matrixtable and convert it into a pandas dataframe the execution fails with `ClassTooLargeException`. The problem arises after I invoke `make_table()` and try to take some rows. I expected hail to be able to handle data with dimensions 10x3202, which is not too large. Data was downloaded from the 1000 Genomes ftp site: [link](https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20201028_3202_phased/). ```; # load data; vcf_path = "".../1000G_b38_20201028_3202_phased/CCDG_14151_B01_GRM_WGS_2020-08-05_chr*.filtered.shapeit2-duohmm-phased.vcf.gz""; mt = hl.import_vcf(vcf_path, force_bgz=True). # select a few random variants; n_selected_variants = 10; selected_variants = np.random.choice(mt.rsid.collect(), n_selected_variants); selected_variants = hl.array(list(selected_variants)). (; mt.filter_rows(selected_variants.contains(mt.rsid)); .select_rows('rsid'); .select_entries('GT'); ).count(); ```; ```; [Stage 18:=====================================================>(255 + 1) / 256]; (10, 3202); ```. Trying to convert to pandas dataframe `.make_table().to_pandas()`, or even just taking 1 row `.make_table().take(1)` results in the following error:; ```; (; mt.filter_rows(selected_variants.contains(mt.rsid)); .select_rows('rsid'); .select_entries('GT'); ).make_table().take(1); ```; ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); Cell In[10], [line 5](vscode-notebook-cell:?execution_count=10&line=5); [1](vscode-notebook-cell:?execution_count=10&line=1) (; [2](vscode-notebook-cell:?execution_count=10&line=2) mt.filter_rows(selected_variants.contains(mt.rsid)); [3](vscode-notebook-cell:?execution_count=10&line=3) .select_rows('rsid'); [4](vscode-notebook-cell:?execution_count=10&line=4) .select_entries('GT'); ----> [5](vscode-notebook-cell:?execution_count=10&line=5) ).make_table().take(1). File ...",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14362:342,down,downloaded,342,https://hail.is,https://github.com/hail-is/hail/issues/14362,1,['down'],['downloaded']
Availability,"### What happened?. When a job creates a log file in excess of about half a GB, loading the job page can cause the batch front-end pod to crash as it loads the log file into memory and interpolates it directly into the job page. The front-end should instead:. - Fully stream job logs in the log endpoint; - Show a truncated view of the log in the job page, with a pointer to download the full log if it's truncated. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13328:375,down,download,375,https://hail.is,https://github.com/hail-is/hail/issues/13328,1,['down'],['download']
Availability,"### What happened?. With the merger of https://github.com/hail-is/hail/pull/13672 and https://github.com/hail-is/hail/pull/13670, Hail Batch now has an auth and database model that is compatible with Azure-Terra. We also made changes to support SAS Token ABS URLs. Daniel has a diff which makes the final changes here: https://github.com/hail-is/hail/commit/94e5b468b0dcbbe6a1de5a296a2103c193b3c61b#diff-a06605397cc32c70a9d43b97fd2ab400374b5172092c5f6a0e26bf2bf1bd559b. The outstanding issues are:; 1. There is no single API in Terra to delete a VM and all its disks. We need to convince ourselves that we won't leak disks.; 2. Ensure we can mount and format disks on the fly as expected.; 3. A reliable & automated testing system.; 4. Merging the diff mentioned above. ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13941:695,reliab,reliable,695,https://hail.is,https://github.com/hail-is/hail/issues/13941,1,['reliab'],['reliable']
Availability,"### What happened?. [SAIGE](https://github.com/weizhouUMICH/SAIGE) and its competitor [REGENIE](https://rgcgithub.github.io/regenie/) are the standard bearers for modern GWAS. Hail should expose SAIGE within the Hail Query language. The interface should roughly match `hl.linear_regression_rows`. A Batch pipeline would serve the needs of Broadies (and, indeed, such a pipeline already exists) but has two downsides:; 1. There is substantial I/O involved in exporting the data from Hail-native formats to SAIGE-compatible formats.; 2. Non-Broadies cannot use this pipeline. Query language support for SAIGE would transform the accessibility of SAIGE by making it usable at scale by anyone with access to Hail, which is basically anyone with a large dataset (e.g. [DNANexus](https://med.stanford.edu/gbsc/projects/vapahcs.html), [AoU RWB](https://support.researchallofus.org/hc/en-us/articles/6090679838100-How-to-Work-with-All-of-Us-Genomic-Data-Hail-Plink-), [MVP](https://med.stanford.edu/gbsc/projects/vapahcs.html), [FinnGen](https://www.medrxiv.org/content/10.1101/2022.03.03.22271360v1.full)). There are two options:; 1. Determine and implement the linear algebraic primitives necessary for SAIGE.; 2. Compile and link directly against SAIGE. Expose these functions, via JNI, to the Hail Query language. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13442:406,down,downsides,406,https://hail.is,https://github.com/hail-is/hail/issues/13442,1,['down'],['downsides']
Availability,"### What happened?. [reporter's note: IIRC, exit code 137 indicates that the ""container"" in which the worker JVM was executing exceeded memory limits. It seems likely that whole stage codegen has either (1) changed memory management in a way that uses more memory or (2) is newly lowering code that exposes a latent issue in memory management that uses too much (or leaks) memory.]. Reported by Ben Weisburd and Julia Goodrich. [Ben is] running the first step of readviz for gnomAD v4 and we are hitting a 137 error on a partition that includes a site that has 27374 alleles. His code is [here](https://github.com/broadinstitute/gnomad-readviz/blob/step1_optimizations/step1__select_samples.py). I was testing his code out on just that failing partition (just added mt = vds.variant_data._filter_partitions([41229])) and I was able to recreate the error using Hail 0.2.119 (this is what Ben was using when he hit the error on the full dataset). However, the first time I tried to recreate the error I was accidentally using a different version of Hail and it ran with no memory error. It seems that 0.2.117 runs without error, but 0.2.118 and 0.2.119 both hit the 137 error. I am currently rerunning these tests so I can get logs:. Test with Hail 0.2.118:. Cluster:; ```; hailctl dataproc start readviz-118 \; --requester-pays-allow-all \; --packages=""git+https://github.com/broadinstitute/gnomad_methods.git@main"",""git+https://github.com/broadinstitute/gnomad_qc.git@main"" \; --autoscaling-policy=max-20 \; --master-machine-type n1-highmem-16 \; --no-off-heap-memory \; --worker-machine-type n1-highmem-8 \; --max-idle 560m \; --labels gnomad_release=gnomad_v4,gnomad_v4_testing=readviz_test_118; ```; Command:; ```; hailctl dataproc submit readviz-118 /Users/jgoodric/PycharmProjects/gnomad-readviz/step1__select_samples.py --sample-metadata-tsv gs://gnomad-readviz/v4.0/gnomad.exomes.v4.0.metadata.tsv.gz --output-ht-path gs://gnomad-tmp/julia/readviz/gnomad.exomes.v4.0.readviz_crams.part_41229.ha",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13248:510,error,error,510,https://hail.is,https://github.com/hail-is/hail/issues/13248,3,['error'],['error']
Availability,### What happened?. ```; + gcloud artifacts repositories set-cleanup-policies hail --project=hail-vdc --location=us --policy=/io/repo/infra/gcp-broad/gcp-ar-cleanup-policy.txt --no-dry-run; ERROR: (gcloud.artifacts.repositories) Invalid choice: 'set-cleanup-policies'.; ```. I think the release needs an updated version of cloud and then this should work fine. ### Version. 0.2.127. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14154:190,ERROR,ERROR,190,https://hail.is,https://github.com/hail-is/hail/issues/14154,1,['ERROR'],['ERROR']
Availability,"### What happened?. ```; =================================== FAILURES ===================================; _______________ ServiceTests.test_python_job_incorrect_signature _______________. self = <test.hailtop.batch.test_batch.ServiceTests testMethod=test_python_job_incorrect_signature>. def setUp(self):; # https://stackoverflow.com/questions/42332030/pytest-monkeypatch-setattr-inside-of-test-class-method; self.monkeypatch = MonkeyPatch(); ; self.backend = ServiceBackend(); ; remote_tmpdir = get_remote_tmpdir('hailtop_test_batch_service_tests'); if not remote_tmpdir.endswith('/'):; remote_tmpdir += '/'; self.remote_tmpdir = remote_tmpdir + str(uuid.uuid4()) + '/'; ; if remote_tmpdir.startswith('gs://'):; match = re.fullmatch('gs://(?P<bucket_name>[^/]+).*', remote_tmpdir); assert match; self.bucket = match.groupdict()['bucket_name']; else:; assert remote_tmpdir.startswith('hail-az://'); if remote_tmpdir.startswith('hail-az://'):; match = re.fullmatch('hail-az://(?P<storage_account>[^/]+)/(?P<container_name>[^/]+).*', remote_tmpdir); assert match; storage_account, container_name = match.groups(); else:; assert remote_tmpdir.startswith('https://'); match = re.fullmatch('https://(?P<storage_account>[^/]+).blob.core.windows.net/(?P<container_name>[^/]+).*', remote_tmpdir); assert match; storage_account, container_name = match.groups(); self.bucket = f'{storage_account}/{container_name}'; ; self.cloud_input_dir = f'{self.remote_tmpdir}batch-tests/resources'; ; token = uuid.uuid4(); self.cloud_output_path = f'/batch-tests/{token}'; self.cloud_output_dir = f'{self.remote_tmpdir}{self.cloud_output_path}'; ; self.router_fs = RouterAsyncFS(); ; > if not self.sync_exists(f'{self.remote_tmpdir}batch-tests/resources/hello.txt'):. ../test/hailtop/batch/test_batch.py:533: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; ../test/hailtop/batch/test_batch.py:544: in sync_exists; return async_to_blocking(self.router_fs.exists(url)); utils/utils.py:160",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13997:61,FAILURE,FAILURES,61,https://hail.is,https://github.com/hail-is/hail/issues/13997,1,['FAILURE'],['FAILURES']
Availability,"### What happened?. ```; In [9]: import hail as hl; ...: mt = hl.utils.range_matrix_table(2,2); ...: mt = mt.annotate_entries(prod = mt.row_idx * mt.col_idx); ...: hl.logistic_regression_rows(y=mt.row_idx, x=mt.prod, test='wald', covariates=[1.0]).describe(); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[9], line 4; 2 mt = hl.utils.range_matrix_table(2,2); 3 mt = mt.annotate_entries(prod = mt.row_idx * mt.col_idx); ----> 4 hl.logistic_regression_rows(y=mt.row_idx, x=mt.prod, test='wald', covariates=[1.0]).describe(). File <decorator-gen-1708>:2, in logistic_regression_rows(test, y, x, covariates, pass_through, max_iterations, tolerance). File ~/projects/hail/hail/python/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File ~/projects/hail/hail/python/hail/methods/statgen.py:921, in logistic_regression_rows(test, y, x, covariates, pass_through, max_iterations, tolerance); 918 if not y_is_list:; 919 result = result.transmute(**result.logistic_regression[0]); --> 921 return result.persist(). File <decorator-gen-1242>:2, in persist(self, storage_level). File ~/projects/hail/hail/python/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File ~/projects/hail/hail/python/hail/table.py:2112, in Table.persist(self, storage_level); 2076 @typecheck_method(storage_level=storage_level); 2077 def persist(self, storage_level='MEMORY_AND_DISK') -> 'Tab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13788:717,toler,tolerance,717,https://hail.is,https://github.com/hail-is/hail/issues/13788,1,['toler'],['tolerance']
Availability,"### What happened?. ```python3; --- Logging error ---; Traceback (most recent call last):; File ""/usr/lib/python3.9/logging/__init__.py"", line 1083, in emit; msg = self.format(record); File ""/usr/lib/python3.9/logging/__init__.py"", line 927, in format; return fmt.format(record); File ""/usr/local/lib/python3.9/dist-packages/pythonjsonlogger/jsonlogger.py"", line 246, in format; return self.serialize_log_record(log_record); File ""/usr/local/lib/python3.9/dist-packages/pythonjsonlogger/jsonlogger.py"", line 215, in serialize_log_record; return ""%s%s"" % (self.prefix, self.jsonify_log_record(log_record)); File ""/usr/local/lib/python3.9/dist-packages/pythonjsonlogger/jsonlogger.py"", line 207, in jsonify_log_record; return self.json_serializer(log_record,; File ""/usr/local/lib/python3.9/dist-packages/hailtop/hail_logging.py"", line 18, in logger_json_serializer; assert default is None and cls is OrJsonEncoder and indent is None and ensure_ascii is False, (; AssertionError: (None, <class 'hailtop.hail_logging.OrJsonEncoder'>, None, False); Call stack:; File ""/usr/local/lib/python3.9/dist-packages/aiohttp/client.py"", line 367, in __del__; self._loop.call_exception_handler(context); File ""/usr/lib/python3.9/asyncio/base_events.py"", line 1779, in call_exception_handler; self.default_exception_handler(context); File ""/usr/lib/python3.9/asyncio/base_events.py"", line 1753, in default_exception_handler; logger.error('\n'.join(log_lines), exc_info=exc_info); Message: 'Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x7ff9c8559490>'. ```. https://cloudlogging.app.goo.gl/PafWAh6xZEuQFhr78. ### Version. 0.2.127. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14261:44,error,error,44,https://hail.is,https://github.com/hail-is/hail/issues/14261,2,['error'],['error']
Availability,"### What happened?. `add_liftover` fails when provided a local chain file on Dataproc. The error says the file does not exist, even though it does. . ## To reproduce; This is run in my GCP virtual machine following a simple example from [your documentation](https://github.com/hail-is/hail/blob/67801dfc66b504a7d49daa53f7ec6d22c1194585/hail/python/hail/genetics/reference_genome.py#L467):; ```sh; gsutil cp gs://hail-common/references/grch37_to_grch38.over.chain.gz .; ```; ```py; import hail as hl; from pathlib import Path. local_chain_file = 'grch37_to_grch38.over.chain.gz'. if Path(local_chain_file).is_file():; rg37 = hl.get_reference('GRCh37'); rg38 = hl.get_reference('GRCh38'); rg37.add_liftover(local_chain_file, rg38); ```; I've reproduced the bug trying with relative/absolute paths, and also referring to HDFS and the local filesystem. None of them worked on the GCP VM, however reading local chain files works on my computer. ### Version. 0.2.126-ee77707f4fab. ### Relevant log output. ```shell; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-17-ef14f8017832> in <cell line: 3>(); 4 rg37 = hl.get_reference('GRCh37'); 5 rg38 = hl.get_reference('GRCh38'); ----> 6 rg37.add_liftover(local_chain_file, rg38); 7. <decorator-gen-150> in add_liftover(self, chain_file, dest_reference_genome). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/genetics/reference_genome.py in add_liftover(self, chain_file, dest_reference_genome); 507 """"""; 508; --> 509 Env.backend().add_liftover(self.name, chain_file, dest_reference_genome.name);",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13993:91,error,error,91,https://hail.is,https://github.com/hail-is/hail/issues/13993,1,['error'],['error']
Availability,"### What happened?. `hailctl dataproc start` fails with an error message like the one below because [in Dataproc 2.2](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/network#:~:text=Internal%20addresses%20only%20(no%2Daddress)%20is%20set%20by%20default%20when%20creating%20a%20Dataproc%202.2%20image%20version%20cluster.%20You%20can%20use%20the%20gcloud%20dataproc%20clusters%20create%20%2D%2Dpublic%2Dip%2Daddress%20flag%20to%20enable%20public%20IP%20addresses.), clusters are created without public internet access by default. A workaround is to pass the `--public-ip-address` flag to the command. Error message:. ```python; pip packages are ['setuptools', 'mkl<2020', 'lxml<5', 'https://github.com/hail-is/jgscm/archive/v0.1.13+hail.zip', 'ipykernel==6.22.0', 'ipywidgets==8.0.6', 'jupyter-console==6.6.3', 'nbconvert==7.3.1', 'notebook==6.5.6', 'qtconsole==5.4.2', 'aiodns==2.0.0', 'aiohttp==3.9.5', 'aiosignal==1.3.1', 'async-timeout==4.0.3', 'attrs==23.2.0', 'avro==1.11.3', 'azure-common==1.1.28', 'azure-core==1.30.2', 'azure-identity==1.17.1', 'azure-mgmt-core==1.4.0', 'azure-mgmt-storage==20.1.0', 'azure-storage-blob==12.20.0', 'bokeh==3.3.4', 'boto3==1.34.138', 'botocore==1.34.138', 'cachetools==5.3.3', 'certifi==2024.6.2', 'cffi==1.16.0', 'charset-normalizer==3.3.2', 'click==8.1.7', 'commonmark==0.9.1', 'contourpy==1.2.1', 'cryptography==42.0.8', 'decorator==4.4.2', 'deprecated==1.2.14', 'dill==0.3.8', 'frozenlist==1.4.1', 'google-auth==2.31.0', 'google-auth-oauthlib==0.8.0', 'humanize==1.1.0', 'idna==3.7', 'isodate==0.6.1', 'janus==1.0.0', 'jinja2==3.1.4', 'jmespath==1.0.1', 'jproperties==2.1.1', 'markupsafe==2.1.5', 'msal==1.29.0', 'msal-extensions==1.2.0', 'msrest==0.7.1', 'multidict==6.0.5', 'nest-asyncio==1.6.0', 'numpy==1.26.4', 'oauthlib==3.2.2', 'orjson==3.10.6', 'packaging==24.1', 'pandas==2.2.2', 'parsimonious==0.10.0', 'pillow==10.4.0', 'plotly==5.22.0', 'portalocker==2.10.0', 'protobuf==3.20.2', 'py4j==0.10.9.7', 'pyasn1==0.6.0', 'pyasn1-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14652:59,error,error,59,https://hail.is,https://github.com/hail-is/hail/issues/14652,2,"['Error', 'error']","['Error', 'error']"
Availability,"### What happened?. `query_billing_projects_with_cost` runs a `select_and_fetchall` query against the database to load information about certain billing projects. It currently locks the affected rows in share mode, but I don't believe there's any reason to do this and it can lead to deadlock errors in `monitor_billing_limits`. It is also worth noting that in `monitor_billing_limits`, we might not want to reuse this method at all, as it only needs to load rows from the database that have exceeded their billing limit. In practice currently this doesn't much matter as the number of billing projects is fairly small, but it is still not ideal. ### Version. 0.2.128. ### Relevant log output. ```shell; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py"", line 900, in retry_long_running; return await f(*args, **kwargs); File ""/usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py"", line 944, in loop; await f(*args, **kwargs); File ""/usr/local/lib/python3.9/dist-packages/batch/driver/main.py"", line 1288, in monitor_billing_limits; records = await query_billing_projects_with_cost(db); File ""/usr/local/lib/python3.9/dist-packages/batch/utils.py"", line 165, in query_billing_projects_with_cost; async for record in db.select_and_fetchall(sql, tuple(args)):; File ""/usr/local/lib/python3.9/dist-packages/gear/database.py"", line 339, in select_and_fetchall; async for row in tx.execute_and_fetchall(sql, args, query_name):; File ""/usr/local/lib/python3.9/dist-packages/gear/database.py"", line 254, in execute_and_fetchall; await cursor.execute(sql, args); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/cursors.py"", line 239, in execute; await self._query(query); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/cursors.py"", line 457, in _query; await conn.query(q); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 469, in query; await self._read_query_result(unbuffered=unbuffered); File ""/usr/loc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14423:293,error,errors,293,https://hail.is,https://github.com/hail-is/hail/issues/14423,1,['error'],['errors']
Availability,"### What happened?. dev namespace scaling is doing a good job of keeping costs down over the weekend and over night, but if devs don't `k delete deployments -n NAMESPACE` and `k delete statefulsets -n NAMESPACE`, these deployments stick around all day every day. It seems, in practice, our db's get an entire 2 core node to themselves. Let's eliminate the scale-up job. We will keep the cronjob that scales down namespaces at the end of each workday. We will provide a scale-up command to either the make targets or `devbin/functions.sh`. `hailctl dev deploy`, of course, would also force a scale up (while also blowing away whatever was there before). ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14020:79,down,down,79,https://hail.is,https://github.com/hail-is/hail/issues/14020,2,['down'],['down']
Availability,### What happened?. e.g. https://hail.zulipchat.com/#narrow/stream/223457-Hail-Batch-support/topic/Error.20in.20QoB.3A.20unknown.20opcode/near/364895723. We should provide tags like `hailgenetics/hail:0.2.117-py3.8` or something. Maybe look a Tensorflow or PyTorch or pyspark for naming inspiration? I think we should still provide `hailgenetics/hail:0.2.117` with our most well-tested version of Python. ### Version. 0.2.117. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13162:99,Error,Error,99,https://hail.is,https://github.com/hail-is/hail/issues/13162,1,['Error'],['Error']
Availability,"### What happened?. e.g. see an attempt to use build_python_image to execute some Hail code in the cloud: https://hail.zulipchat.com/#narrow/stream/223457-Hail-Batch-support/topic/Error.20in.20QoB.3A.20unknown.20opcode. We should provide users with a simple and straightforward project structure and mechanism for working with a local Python project, its Python dependencies, including, possibly, Hail. It seems to me that a relatively straightforward way to do this would be to recommend the user create a normal, installable python package (and provide instructions on doing so), and then to provide some Hail Batch client functionality that builds an image based on `hailgenetics/hail` (if Hail is required) or `hailgenetics/python-dill` or a user-provided base image (which must have Python, but we'll ensure dill gets installed). The Dockerfile should look something like:. ```; FROM {base_image}; COPY {users_project_dir} /users_project; RUN pip install /users_project; ```. And then that image can be used as the python_default_image (maybe also the default_image?). ### Version. 0.2.117. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13161:180,Error,Error,180,https://hail.is,https://github.com/hail-is/hail/issues/13161,1,['Error'],['Error']
Availability,"### What happened?. gnomAD team asks:. > We would like to get these same sample stats broken down by different variant stratifications, so essentially, this is like what we do for the frequencies, but this is for samples. With Frequencies we can use the hl.agg.filter with hl.agg.call_stats to get what we want, but there isnt really an equivalent for samples since hl.sample_qc and hl.vds.sample_qc take MTs and return HTs rather than taking expressions and returning aggregation expressions. Would the Hail team have the bandwidth in the next couple weeks to put in a modification to the hl.vds.sample_qc to make it function similar to the hl.agg.call_stats ?. My thoughts on it:. It's a reasonable ask. You'll have four parts (first three are aggregators): rmt_sq, vmt_sq, ac_and_atype, and combine. The user must ensure the same filters, groups, etc. are applied to each aggregator. If you group, you'll need to ensure the right grouped AC is passed around. It might look like this on the variant matrix table. The reference stuff looks similar.; ```python3; vmt = vmt.annotate_entries(GT=hl.vds.lgt_to_gt(vmt.LGT, vmt.LA)); vmt = vmt.annotate_rows(ac_atype=hl.agg.group_by(foo, ac_and_atype(vmt.GT, vmt.alleles))); vmt = vmt.annotate_cols(; qc=hl.agg.group_by(; foo,; vmt_sample_qc(; global_gt=vmt.GT,; gq=vmt.GQ,; ac=ac_atype[foo].ac,; atype=ac_atype[foo].atype,; dp=vmt.DP); ); ); ```; The atype needn't really be grouped. That should maybe be its own aggregator and then you can use stats directly to get a valid AC. I sketched this here: https://github.com/hail-is/hail/compare/main...danking:hail:agg-sample-qc but there are probably bugs in that. This issue is complete when we merge a PR that:; 1. Exposes one or more aggregators which compute all the statistics from `hl.vds.sample_qc` on the component matrix tables of a VDS: the variant data and the reference data.; 2. Exposes a combination function which combines reference and variant stats to produce `bases_over_dp_threshold` and ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14264:93,down,down,93,https://hail.is,https://github.com/hail-is/hail/issues/14264,1,['down'],['down']
Availability,"### What happened?. gnomAD went with a custom CUDA-implementation of KING instead of PC-Relate because `hl.pc_relate` was very slow on their gnomAD v4 1M sample dataset. I'm fairly certain the bottleneck is writing out a 1M by 1M dense matrix of 64-bit floating point numbers (aka the relatedness matrix). This matrix is too large. Our users only care about the small subset of entires indicating close relatedness between the samples [1]. Instead of writing a dense BlockMatrix, we should write a Hail Table with the columns `sample1`, `sample2`, and `kinship`. I have some (very old) skeleton code for this [here](https://github.com/hail-is/hail/compare/main...danking:hail:sparse-pc-relate). If I recall correctly, this only calculates the kinship coefficient, not the full set of coefficients. I'm not sure it even works currently, but it demonstrates how we can generate a BlockMatrixIR directly rather than trying to construct it using the Python-level API. ---. #### Footnotes. [1] Consider Figure 2 from [the PC-Relate paper (Conomos, et al. 2016)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4716688/). Beyond 3rd degree relatedness (i.e. avuncular pair), SNP-based relatedness (as opposed to haplotype-based) isn't reliable (see Figures 6 and 7). 3rd degree pair have have kinship 0.0625, in expectation, so only keeping entries >=0.03 is very reasonable. gnomAD is even more aggressive [considering only 2nd degree or higher pairs](https://gnomad.broadinstitute.org/news/2021-09-using-the-gnomad-ancestry-principal-components-analysis-loadings-and-random-forest-classifier-on-your-dataset/), which presumably corresponds to keeping only entries >=0.0625. ---. #### Further reading. - https://en.wikipedia.org/wiki/Coefficient_of_relationship. ### Version. 0.2.124",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13798:1226,reliab,reliable,1226,https://hail.is,https://github.com/hail-is/hail/issues/13798,1,['reliab'],['reliable']
Availability,"### What happened?. https://batch.azure.hail.is/batches/4375769/jobs/126. ```; io/test/test_batch.py::test_always_run_job_private_instance_cancel ; -------------------------------- live log setup --------------------------------; 2023-09-06T21:45:24 INFO test.conftest conftest.py:14:log_before_after starting test; 2023-09-06T21:45:24 INFO hailtop.aiocloud.aioazure.credentials credentials.py:99:default_credentials using credentials file /test-gsa-key/key.json; -------------------------------- live log call ---------------------------------; 2023-09-06T21:45:25 INFO azure.identity.aio._internal.get_token_mixin get_token_mixin.py:93:get_token ClientSecretCredential.get_token succeeded; 2023-09-06T21:45:25 INFO batch_client.aioclient aioclient.py:809:_submit created batch 191; submit job bunches  100% 1/1 0:00:00 0:00:00; 2023-09-06T21:47:17 WARNING hailtop.utils utils.py:842:retry_transient_errors_with_debug_string A transient error occured. We will automatically retry. Do not be alarmed. We have thus far seen 2 transient errors (next delay: 3.794s). The most recent error was <class 'asyncio.exceptions.TimeoutError'> . . +++++++++++++++++++++++++++++++++++ Timeout ++++++++++++++++++++++++++++++++++++. ~~~~~~~~~~~~~~~~~~~~~ Stack of asyncio_0 (140387515627072) ~~~~~~~~~~~~~~~~~~~~~; File ""/usr/lib/python3.9/threading.py"", line 937, in _bootstrap; self._bootstrap_inner(); File ""/usr/lib/python3.9/threading.py"", line 980, in _bootstrap_inner; self.run(); File ""/usr/lib/python3.9/threading.py"", line 917, in run; self._target(*self._args, **self._kwargs); File ""/usr/lib/python3.9/concurrent/futures/thread.py"", line 81, in _worker; work_item = work_queue.get(block=True). +++++++++++++++++++++++++++++++++++ Timeout ++++++++++++++++++++++++++++++++++++; FAILED; _________________ test_always_run_job_private_instance_cancel __________________. client = <hailtop.batch_client.client.BatchClient object at 0x7fae899806a0>. def test_always_run_job_p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13582:974,error,error,974,https://hail.is,https://github.com/hail-is/hail/issues/13582,1,['error'],['error']
Availability,"### What happened?. https://ci.azure.hail.is/batches/3778899/jobs/47; ```; E hail.utils.java.FatalError: NativeIoException: readAddress(..) failed: Connection reset by peer; E ; E Java stack trace:; E io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer; E 	at ; E ; E ; E ; E Hail version: 0.2.115-330031a5d973; E Error summary: NativeIoException: readAddress(..) failed: Connection reset by peer; ```. I'm not sure why we lost the stack trace. ### Version. 330031a5d9734fd33a50e5651e7a2505f352b239. ### Relevant log output. ```shell; ________________________ test_pc_relate_against_R_truth ________________________; [gw2] linux -- Python 3.8.10 /usr/bin/python3. def test_pc_relate_against_R_truth():; mt = hl.import_vcf(resource('pc_relate_bn_input.vcf.bgz')); > hail_kin = hl.pc_relate(mt.GT, 0.00, k=2).checkpoint(utils.new_temp_file(extension='ht')). test/hail/methods/relatedness/test_pc_relate.py:9: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; <decorator-gen-1104>:2: in checkpoint; ???; /usr/local/lib/python3.8/dist-packages/hail/typecheck/check.py:584: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.8/dist-packages/hail/table.py:1347: in checkpoint; self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); <decorator-gen-1106>:2: in write; ???; /usr/local/lib/python3.8/dist-packages/hail/typecheck/check.py:584: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.8/dist-packages/hail/table.py:1393: in write; Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); /usr/local/lib/python3.8/dist-packages/hail/backend/service_backend.py:490: in execute; return self._cancel_on_ctrl_c(self._async_execute(ir, timed=timed)); /usr/local/lib/python3.8/dist-packages/hail/backend/service_backend.py:481: in _cancel_on_ctrl_c; return async_to_bl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12980:223,Error,Errors,223,https://hail.is,https://github.com/hail-is/hail/issues/12980,3,"['Error', 'checkpoint']","['Error', 'Errors', 'checkpoint']"
Availability,### What happened?. https://discuss.hail.is/t/error-summary-classtoolargeexception-class-too-large/3491. Likely due to the large number of fields. We presumably we were able to parse this at some point. It would be good to at least understand why there's been a regression. ### Version. 0.2.108. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13249:46,error,error-summary-classtoolargeexception-class-too-large,46,https://hail.is,https://github.com/hail-is/hail/issues/13249,1,['error'],['error-summary-classtoolargeexception-class-too-large']
Availability,### What happened?. https://discuss.hail.is/t/matrixtable-filter-rows-produces-error-for-data-on-secure-lustre/3344/2. Seems like we drop the file:// scheme at some point when generating code that uses PartitionNativeIntervalReader. ### Version. ????. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13998:79,error,error-for-data-on-secure-lustre,79,https://hail.is,https://github.com/hail-is/hail/issues/13998,1,['error'],['error-for-data-on-secure-lustre']
Availability,### What happened?. https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/setting.20the.20gcloud.20project. An example of a user problem is linked above. It is difficult to discover how to set the GCS requester pays project id for Hail Query-on-Batch and hailtop.fs. We should error or warn on invalid names (error seems best?). We should have a list of valid names and make that documentation available publicly. ### Version. 0.2.118. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13195:293,error,error,293,https://hail.is,https://github.com/hail-is/hail/issues/13195,3,"['avail', 'error']","['available', 'error']"
Availability,"### What happened?. https://hail.zulipchat.com/#narrow/stream/223457-Hail-Batch-support/topic/QoB.20Error.3A.20GoogleJsonResponseException.3A.20404.20Not.20Found/near/398355473. > I was running hl.pca on the wheel you created for me -> 0.2.124-fcaafc533ec1. and there seems to be a transient error going on https://batch.hail.is/batches/8069235?q=state+%3D+failed, not sure whether this is the same as the previous ones. I just cancelled the job before error summary appears. and here is the code I am running:. ```python3; vat_ht = hl.read_table(get_aou_util_path(name=""vat"")); vat_ht = vat_ht.collect_by_key(); meta_ht = hl.read_table(get_sample_meta_path(annotation=True)); meta_ht = meta_ht.filter(~meta_ht.related); pops = args.pops.split("","") if (args.pops is not None) else POPS; for pop in pops:; mt = get_filtered_mt(analysis_type='variant', filter_variants=True, filter_samples=False,; adj_filter=True, pop=pop); variants_to_keep = vat_ht.filter(; (vat_ht.locus.in_autosome()) &; (hl.is_snp(vat_ht.alleles[0], vat_ht.alleles[1])) &; (vat_ht['values'][f'gvs_{pop}_af'][0] >= 0.0001) &; ((vat_ht.values[f""gvs_{pop}_an""][0] >= (N_SAMPLES[pop] * 2 * MIN_CALL_RATE[pop]))); ); print('Filtering Variants...'); mt = mt.filter_rows(hl.is_defined(variants_to_keep[mt.row_key])) # filter to high quality variants; print('Filtering Samples...'); mt = mt.filter_cols(hl.is_defined(meta_ht[mt.col_key])) # filter to unrelated samples -> later to project; print('Running PCA...'); eigenvalues, scores, loadings = hl.pca(; hl.int(hl.is_defined(mt.GT)),; compute_loadings=True,; k=50,; ); print('Writing tables...'); eigenvalues.write(; get_pca_ht_path(pop=pop, name='evals'),; overwrite=args.overwrite,; ); scores.write(; get_pca_ht_path(pop=pop, name='scores'),; overwrite=args.overwrite,; ); loadings.write(; get_pca_ht_path(pop=pop, name='loadings'),; overwrite=args.overwrite,; ); ```. ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13979:292,error,error,292,https://hail.is,https://github.com/hail-is/hail/issues/13979,2,['error'],['error']
Availability,"### What happened?. while trying to run the following code I get the error mention in the title (Invalid maximum heap size: -Xmx0m). import hail as hl; hl.init(default_reference=""GRCh38""). However I tried to resolve the issue with overloading the default setting with new values for spark configuration (command below), unfortunately the error still exists; hl.init(driver_memory='1024m). ### Version. latest version used in allOfUs research workbench platform. ### Relevant log output. ```shell; Invalid maximum heap size: -Xmx0m; Error: Could not create the Java Virtual Machine.; Error: A fatal exception has occurred. Program will exit.; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); Cell In[14], line 2; 1 #hl.init(default_reference=""GRCh38""); ----> 2 hl.init(driver_memory='1024m'). File <decorator-gen-1756>:2, in init(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, backend, driver_cores, driver_memory, worker_cores, worker_memory, gcs_requester_pays_configuration, regions, gcs_bucket_allow_list). File /opt/conda/lib/python3.10/site-packages/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File /opt/conda/lib/python3.10/site-packages/hail/context.py:364, in init(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, backend, driver_cores, driver_memory, worker_cores, worker_memory, gcs_requester_pays_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14489:69,error,error,69,https://hail.is,https://github.com/hail-is/hail/issues/14489,4,"['Error', 'error']","['Error', 'error']"
Availability,"#### Summary. It has happened twice. The failing partition is different in each run. 1. 49340 https://batch.hail.is/batches/8069235/jobs/51280; 2. 25997 https://batch.hail.is/batches/8083195/jobs/27937. The pipeline runs two table collects to get sample information, then converts the matrix table to a table of ndarrays of the value `hl.int(hl.is_defined(mt.GT))`. The entries are getting subsetted, so there is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:673,error,error,673,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623,3,['error'],['error']
Availability,"###Hail version; N/A Kubernetes v1 API, cluster version 1.10.11. ### What you did; Attempted to schedule a pod through app.hail.is. Waited ~20 minutes. ### What went wrong (all error messages here, including the full java stack trace); Simply stuck in Not PodScheduled (status.condition contains an entry of {status: False, type: PodScheduled} ). This status is also verified using kubectl get pods -w. Total number of pods did not seem onerous by quantity alone, so this must be an issue of resource utilization by some of these pods. ```sh; NAME READY STATUS RESTARTS AGE; apiserver-8658d59d48-r8p6w 1/1 Running 0 9d; auth-gateway-deployment-7d7cf8846f-l5m9b 1/1 Running 0 14h; batch-deployment-6448f84d9c-gxn2c 1/1 Running 0 1h; dk-test-58dffcd944-9xkkx 1/1 Running 0 11d; frontend-766c875db4-cmpvx 1/1 Running 0 8d; gateway-deployment-78c4dd64f5-tdnnc 1/1 Running 0 1h; hail-ci-deployment-5744fd6964-s29xb 1/1 Running 0 1h; image-fetcher-bkpcc 1/1 Running 0 23m; image-fetcher-gb9rs 1/1 Running 0 26m; image-fetcher-glj5p 1/1 Running 0 25m; image-fetcher-kjd7z 1/1 Running 0 23m; image-fetcher-vhv74 1/1 Running 0 25m; image-fetcher-zppvc 1/1 Running 0 24m; notebook-api-deployment-7bb85bfd-z6mvp 1/1 Running 0 12h; notebook-deployment-8546dbcb7c-zfc4r 1/1 Running 0 1h; notebook-worker-2lt2l 1/1 Running 0 46m; notebook-worker-77nqq 1/1 Running 0 1h; notebook-worker-fljx6 1/1 Running 0 3h; notebook-worker-gm6lz 1/1 Running 0 36m; notebook-worker-kj7bb 1/1 Running 0 3h; notebook-worker-n8dgv 0/1 Pending 0 4m; notebook-worker-pshdf 1/1 Running 0 35m; scorecard-deployment-654f774444-vwpzr 1/1 Running 0 51m; site-deployment-6789bd6c5b-lxbxk 1/1 Running 0 51m; spark-master-6f7678b449-jcbnp 1/1 Running 0 9d; spark-worker-569866dff7-l452k 1/1 Running 0 9d; spark-worker-569866dff7-xzmx4 1/1 Running 0 9d; upload-658d7f8c7d-gvj4h 1/1 Running 0 51m; web-deployment-bc6497cdb-qfc9g 1/1 Running 0 2h; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5269:177,error,error,177,https://hail.is,https://github.com/hail-is/hail/issues/5269,1,['error'],['error']
Availability,"#10676 correctly points out a documentation error, which I am addressing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10781:44,error,error,44,https://hail.is,https://github.com/hail-is/hail/pull/10781,1,['error'],['error']
Availability,"#12447 Added some assertions to appease mypy checking use of optional types, and these two were too aggressive but aren't necessary to pass the test suite, just noticed the additional error log entries.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12493:184,error,error,184,https://hail.is,https://github.com/hail-is/hail/pull/12493,1,['error'],['error']
Availability,"#133</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/133"">brettcannon/gidgethub#133</a>).</li>; <li>Make the minimum version of PyJWT be v2.0.0.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/brettcannon/gidgethub/blob/main/docs/changelog.rst"">gidgethub's changelog</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <ul>; <li>; <p>Fix cgi and importlib_resources deprecations.; (<code>PR [#185](https://github.com/brettcannon/gidgethub/issues/185) &lt;https://github.com/brettcannon/gidgethub/pull/185&gt;_</code>)</p>; </li>; <li>; <p>Add support for Python 3.11 and drop EOL Python 3.6; (<code>PR [#184](https://github.com/brettcannon/gidgethub/issues/184) &lt;https://github.com/brettcannon/gidgethub/pull/184&gt;_</code>)</p>; </li>; </ul>; <h2>5.2.0</h2>; <ul>; <li>Make the minimum version of PyJWT be v2.4.0.</li>; </ul>; <h2>5.1.0</h2>; <ul>; <li>; <p>Use <code>X-Hub-Signature-256</code> header for webhook validation when available.; (<code>PR [#160](https://github.com/brettcannon/gidgethub/issues/160) &lt;https://github.com/brettcannon/gidgethub/pull/160&gt;</code>_).</p>; </li>; <li>; <p>The documentation is now built using Sphinx v&gt;= 4.0.0.; (<code>Issue [#143](https://github.com/brettcannon/gidgethub/issues/143) &lt;https://github.com/brettcannon/gidgethub/issues/143&gt;</code>_)</p>; </li>; <li>; <p>:meth:<code>gidgethub.abc.GitHubAPI.getiter</code> now accepts <code>iterable_key</code> parameter; in order to support the Checks API.; (<code>Issue [#164](https://github.com/brettcannon/gidgethub/issues/164) &lt;https://github.com/brettcannon/gidgethub/issues/164&gt;</code>_)</p>; </li>; <li>; <p>Accept HTTP 202 ACCEPTED as successful.; (<code>PR [#174](https://github.com/brettcannon/gidgethub/issues/174) &lt;https://github.com/brettcannon/gidgethub/pull/174&gt;</code>_)</p>; </li>; </ul>; <h2>5.0.1</h2>; <ul>; <li>Drop the <code>machine-man-preview</code> ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:4953,avail,available,4953,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['avail'],['available']
Availability,"#13839 is I think the right way to implement this. It passes `test_block_matrix_entries`, which is the only test I could find that exercises this path. Others that should, like `test_to_table`, can't yet be fully lowered. Maybe try rebasing on my branch and see if you still see the indexing errors?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13807#issuecomment-1766713503:292,error,errors,292,https://hail.is,https://github.com/hail-is/hail/pull/13807#issuecomment-1766713503,1,['error'],['errors']
Availability,"#26</a> (<a href=""https://github.com/pre-commit-ci""><code>@pre-commit-ci</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/ipython/comm/graphs/contributors?from=2024-01-02&amp;to=2024-03-12&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Aipython%2Fcomm+involves%3Ablink1073+updated%3A2024-01-02..2024-03-12&amp;type=Issues""><code>@blink1073</code></a> | <a href=""https://github.com/search?q=repo%3Aipython%2Fcomm+involves%3Apre-commit-ci+updated%3A2024-01-02..2024-03-12&amp;type=Issues""><code>@pre-commit-ci</code></a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/ipython/comm/blob/main/CHANGELOG.md"">comm's changelog</a>.</em></p>; <blockquote>; <h2>0.2.2</h2>; <p>(<a href=""https://github.com/ipython/comm/compare/v0.2.1...76149e7ee0f331772c964ae86cdb8bafebe6dfa2"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Update Release Scripts <a href=""https://redirect.github.com/ipython/comm/pull/27"">#27</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; </ul>; <h3>Other merged PRs</h3>; <ul>; <li>chore: update pre-commit hooks <a href=""https://redirect.github.com/ipython/comm/pull/26"">#26</a> (<a href=""https://github.com/pre-commit-ci""><code>@pre-commit-ci</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/ipython/comm/graphs/contributors?from=2024-01-02&amp;to=2024-03-12&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Aipython%2Fcomm+involves%3Ablink1073+updated%3A2024-01-02..2024-03-12&amp;type=Issues""><code>@blink1073</code></a> | <a href=""https://github.com/search?q=repo%3Aipython%2Fcomm+involves%3Apre-commit-ci+updated%3A2024-01-02..2024-03-12&amp;type=Issues""><code>@pre-commit-ci</code></a></p>; <!-- raw HTML omitted -->;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14492:1732,Mainten,Maintenance,1732,https://hail.is,https://github.com/hail-is/hail/pull/14492,1,['Mainten'],['Maintenance']
Availability,#290 - nocompress in vcf wasn't working; #283 - fam export now tab separated; #262 - fatalIf is dead; #246 - add g.fractionReadsAlt; #237 - give tsv annotators a delimiter option. Fixed fatal error in case of old VDS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/294:192,error,error,192,https://hail.is,https://github.com/hail-is/hail/pull/294,1,['error'],['error']
Availability,"#4659 teaches CI to recover from a build job gone missing, but; I neglected to teach CI how to recover from a deploy job gone; missing. This follows the same strategy but for deploy jobs. If a deploy job is not found in the list of refreshed jobs; it is simply removed from the deploy_jobs map. The next heal; stage of CI will kick off a new batch job for whatever the; latest undeployed SHA is.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4683:20,recover,recover,20,https://hail.is,https://github.com/hail-is/hail/pull/4683,2,['recover'],['recover']
Availability,"#5228](https://github.com/aio-libs/aiohttp/issues/5228) &lt;https://github.com/aio-libs/aiohttp/issues/5228&gt;</code>_</li>; </ul>; <h2>Misc</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/master/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.7.4 (2021-02-25)</h1>; <h2>Bugfixes</h2>; <ul>; <li>; <p><strong>(SECURITY BUG)</strong> Started preventing open redirects in the; <code>aiohttp.web.normalize_path_middleware</code> middleware. For; more details, see; <a href=""https://github.com/aio-libs/aiohttp/security/advisories/GHSA-v6wp-4m6f-gcjg"">https://github.com/aio-libs/aiohttp/security/advisories/GHSA-v6wp-4m6f-gcjg</a>.</p>; <p>Thanks to <code>Beast Glatisant &lt;https://github.com/g147&gt;</code>__ for; finding the first instance of this issue and <code>Jelmer Vernoo &lt;https://jelmer.uk/&gt;</code>__ for reporting and tracking it down; in aiohttp.; <code>[#5497](https://github.com/aio-libs/aiohttp/issues/5497) &lt;https://github.com/aio-libs/aiohttp/issues/5497&gt;</code>_</p>; </li>; <li>; <p>Fix interpretation difference of the pure-Python and the Cython-based; HTTP parsers construct a <code>yarl.URL</code> object for HTTP request-target.</p>; <p>Before this fix, the Python parser would turn the URI's absolute-path; for <code>//some-path</code> into <code>/</code> while the Cython code preserved it as; <code>//some-path</code>. Now, both do the latter.; <code>[#5498](https://github.com/aio-libs/aiohttp/issues/5498) &lt;https://github.com/aio-libs/aiohttp/issues/5498&gt;</code>_</p>; </li>; </ul>; <hr />; <h1>3.7.3 (2020-11-18)</h1>; <h2>Features</h2>; <ul>; <li>Use Brotli instead of brotlipy; <code>[#3803](https://github.com/aio-libs/aiohttp/issues/3803) &lt;https://github.com/aio-libs/aiohttp/issues/3803&gt;</code>_</li>; <li>Made exceptions pickleable. Also changed the repr of some exceptions",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10115:4507,down,down,4507,https://hail.is,https://github.com/hail-is/hail/pull/10115,1,['down'],['down']
Availability,#5872 fixes the problem and tests more robustly,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5871#issuecomment-482348287:39,robust,robustly,39,https://hail.is,https://github.com/hail-is/hail/pull/5871#issuecomment-482348287,1,['robust'],['robustly']
Availability,"#9425 fixes the bug that caused us to need to checkpoint twice. This PR removes the second checkpoint. For the `hl.balding_nichols_model(20, 6000, 50000)`, 2 iterations test I've been doing, this gets us down to more like 35 seconds, as opposed to ~40. Current hail PCA takes more like 16 seconds, so we are getting closer (though again, it's not clear that 2 is going to be the right number of iterations in the end).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9434:46,checkpoint,checkpoint,46,https://hail.is,https://github.com/hail-is/hail/pull/9434,3,"['checkpoint', 'down']","['checkpoint', 'down']"
Availability,"#9435 may at long last, finally be a solution to this. We currently keep a static map per jvm that maps general FASTA paths to a local fasta path that we copy the FASTA into. My change serializes the downloading of these files (using a lock), and we never remove keys from the map, so we should finally have 1 FASTA file per executor. There are still circumstances that can blow up on us like restarting executors (like when yarn shuts them down) and then starts them up again. The broadcast changes fixed some of the issues, and I hope that my change can finally fix this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5371#issuecomment-690852316:200,down,downloading,200,https://hail.is,https://github.com/hail-is/hail/issues/5371#issuecomment-690852316,2,['down'],"['down', 'downloading']"
Availability,#9569 Fixes the `HailUserException` error you encountered. `LocalBackend` now correctly handles `HailUserException`s,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9549#issuecomment-704921949:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/pull/9549#issuecomment-704921949,1,['error'],['error']
Availability,$1.run(JVMEntryway.java:107); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:750); Caused by: java.lang.reflect.InvocationTargetException; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at is.hail.JVMEntryway$1.run(JVMEntryway.java:105); ... 7 more; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/rwalters-hail-tmp/o?name=merged_round2_sumstats.fix_lowconf.mt/entries/rows/parts/part-15801-2fde3786-67cb-42ed-8aac-f900cfcc4c00&uploadType=resumable&upload_id=ADPycduMEzX6d_uX4CiP6_XItJKmP8UnUnYBfyPoselMbyLUkxs1wDLPnxWl5gXr5LnBaVntYR_i7jchyxgVsRb_5PknvcCIcfDJ; chunkOffset: 16777216; chunkLength: 0; localOffset: 0; remoteOffset: 16777216; lastChunk: false. at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:267); at java.util.concurrent.Executo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950:2296,recover,recover,2296,https://hail.is,https://github.com/hail-is/hail/issues/12950,1,['recover'],['recover']
Availability,"$100(URLClassLoader.java:71); at java.net.URLClassLoader$1.run(URLClassLoader.java:361); at java.net.URLClassLoader$1.run(URLClassLoader.java:355); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:354); at java.lang.ClassLoader.loadClass(ClassLoader.java:425); at java.lang.ClassLoader.loadClass(ClassLoader.java:358); at org.broadinstitute.hail.driver.ToplevelCommands$.<init>(Command.scala:62); at org.broadinstitute.hail.driver.ToplevelCommands$.<clinit>(Command.scala); at org.broadinstitute.hail.driver.Main$.main(Main.scala:205); at org.broadinstitute.hail.driver.Main.main(Main.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala). I think this may relate to java version, so I re-configured java,but the error still appear, How can I solve it ?. --------------------My java version and path; [root@***-3 opt]# java -version; java version ""1.8.0_91""; Java(TM) SE Runtime Environment (build 1.8.0_91-b14); Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode). [root@***-3 opt]# echo $JAVA_HOME; /opt/BioDir/jdk/jdk1.8.0_91. [root@bio-x-3 opt]# echo $PATH; /opt/BioDir/plink_1.9:/opt/BioDir/jdk/jdk1.8.0_91/bin:/opt/BioDir/gradle/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. My OS is CentOS7; [root@***-3 opt]# uname -a; Linux bio-x-3 3.10.0-229.14.1.el7.x86_64",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/825:2182,error,error,2182,https://hail.is,https://github.com/hail-is/hail/issues/825,3,"['echo', 'error']","['echo', 'error']"
Availability,"$11$adapted(Worker.scala:164) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:637) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:164) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	... 12 more; 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 		at is.hail.relocated.com.google.cloud.storage.StorageException.translate(StorageException.java:165) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:298) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpSt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:17539,error,error,17539,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['error'],['error']
Availability,$anonfun$parse_value_ir$2(SparkBackend.scala:691); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:62); 	at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$1(SparkBackend.scala:345); 	at is.hail.backend.spark.SparkBackend.$anonfun$parse_value_ir$1(SparkBackend.scala:690); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59); 	at is.hail.backend.spark.SparkBackend.parse_value_ir(SparkBackend.scala:689); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182); 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106); 	at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.124-b115f6a6ec23; Error summary: ClassCastException: class is.hail.types.virtual.TStruct cannot be cast to class is.hail.types.virtual.TIterable (is.hail.types.virtual.TStruct and is.hail.types.virtual.TIterable are in unnamed module of loader 'app'); ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13699:8531,Error,Error,8531,https://hail.is,https://github.com/hail-is/hail/issues/13699,1,['Error'],['Error']
Availability,$apply$23.apply(ContextRDD.scala:308); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:923); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:923); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:923); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:347); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:442); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:442); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:469); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:467); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-5d0f74cef4f2; Error summary: MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;); ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790:14031,Error,Error,14031,https://hail.is,https://github.com/hail-is/hail/issues/3790,1,['Error'],['Error']
Availability,$class.isEmpty(Iterator.scala:330); 	at scala.collection.AbstractIterator.isEmpty(Iterator.scala:1336); 	at is.hail.utils.TextTableReader$$anonfun$14.apply(TextTableReader.scala:218); 	at is.hail.utils.TextTableReader$$anonfun$14.apply(TextTableReader.scala:215); 	at is.hail.utils.richUtils.RichHadoopConfiguration$$anonfun$readLines$extension$1.apply(RichHadoopConfiguration.scala:301); 	at is.hail.utils.richUtils.RichHadoopConfiguration$$anonfun$readLines$extension$1.apply(RichHadoopConfiguration.scala:292); 	at is.hail.utils.package$.using(package.scala:587); 	at is.hail.utils.richUtils.RichHadoopConfiguration$.readFile$extension(RichHadoopConfiguration.scala:285); 	at is.hail.utils.richUtils.RichHadoopConfiguration$.readLines$extension(RichHadoopConfiguration.scala:292); 	at is.hail.utils.TextTableReader$.read(TextTableReader.scala:215); 	at is.hail.HailContext$$anonfun$importTables$3.apply(HailContext.scala:516); 	at is.hail.HailContext$$anonfun$importTables$3.apply(HailContext.scala:518); 	at is.hail.HailContext.maybeGZipAsBGZip(HailContext.scala:586); 	at is.hail.HailContext.importTables(HailContext.scala:515); 	at is.hail.HailContext.importTable(HailContext.scala:477); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.2.8-70304a52d33d; Error summary: MalformedInputException: Input length = 1; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5221:4964,Error,Error,4964,https://hail.is,https://github.com/hail-is/hail/issues/5221,1,['Error'],['Error']
Availability,$mcJ$sp(CompileAndEvaluate.scala:26); 	at is.hail.expr.ir.CompileAndEvaluate$$anonfun$apply$1$$anonfun$1.apply(CompileAndEvaluate.scala:26); 	at is.hail.expr.ir.CompileAndEvaluate$$anonfun$apply$1$$anonfun$1.apply(CompileAndEvaluate.scala:26); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); 	at is.hail.expr.ir.CompileAndEvaluate$$anonfun$apply$1.apply(CompileAndEvaluate.scala:26); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:14); 	at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); 	at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); 	at is.hail.utils.package$.using(package.scala:596); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:10); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:9); 	at is.hail.utils.package$.using(package.scala:596); 	at is.hail.annotations.Region$.scoped(Region.scala:18); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:9); 	at is.hail.backend.Backend.execute(Backend.scala:56); 	at is.hail.backend.Backend.executeJSON(Backend.scala:62); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748); Hail version: 0.2.32-e973d7f3c15c; Error summary: ArrayIndexOutOfBoundsException: 3366; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8114:2505,Error,Error,2505,https://hail.is,https://github.com/hail-is/hail/issues/8114,1,['Error'],['Error']
Availability,"&& bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB);  53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB);  97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB);  53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:30140,Down,Downloading,30140,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['Down'],['Downloading']
Availability,"' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: ArrayIndexOutOfBoundsException: 0. Java stack trace:; java.lang.ArrayIndexOutOfBoundsException: 0; 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:173); 	at org.apache.spark.sql.Row$class.apply(Row.scala:163); 	at org.apache.spark.sql.catalyst.expressions.GenericRow.apply(rows.scala:165); 	at is.hail.annotations.Annotation$$anonfun$isSafe$1.apply$mcZI$sp(Annotation.scala:70); 	at is.hail.annotations.Annotation$$anonfun$isSafe$1.apply(Annotation.scala:70); 	at is.hail.annotations.Annotation$$anonfun$isSafe$1.apply(Annotation.scala:70); 	at scala.collection.IndexedSeqOptimized$class.prefixLengthImpl(IndexedSeqOptimized.scala:38); 	at scala.collection.IndexedSeqOptimized$class.forall(IndexedSeqOptimized.scala:43); 	at scala.collection.mutable.ArrayOps$ofInt.forall(ArrayOps.scala:234); 	at is.hail.annotations.Annotation$.isSafe(Annotation.scala:70); 	at is.hail.annotations.BroadcastRow.<init>(BroadcastValue.scala:27); 	at is.hail.variant.MatrixTable$.fromRowsTable(MatrixTable.scala:462); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-1ea0ab823b1f; Error summary: ArrayIndexOutOfBoundsException: 0; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3668:3730,Error,Error,3730,https://hail.is,https://github.com/hail-is/hail/issues/3668,1,['Error'],['Error']
Availability,']'; + echo HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc ']'; + echo HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc ']'; + echo HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc; + for varname in '$arguments'; + '[' -z x ']'; + echo WHEEL_FOR_AZURE=x; WHEEL_FOR_AZURE=x; + for varname in '$arguments'; + '[' -z /path/to/www.tar.gz ']'; + echo WEBSITE_TAR=/path/to/www.tar.gz; WEBSITE_TAR=/path/to/www.tar.gz; + exit 1. ```. ```sh; # WEBSITE_TAR=g WHEEL_FOR_AZURE=f HAIL_GENETICS_VEP_GRCH38_95_IMAGE=e HAIL_GENETICS_VEP_GRCH37_85_IMAGE=d HAIL_GENETICS_HAILTOP_IMAGE=c HAIL_GENETICS_HAIL_IMAGE_PY_3_11=b HAIL_GENETICS_HAIL_IMAGE_PY_3_10=a HAIL_GENETICS_HAIL_IMAGE=abc123 GITHUB_OAUTH_HEADER_FILE=abc123 DEPLOY_REMOTE=origin make -C hail release; HAIL_PIP_VERSION=0.2.128 \; HAIL_VERSION=0.2.128-91d328e7fc84 \; GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a \; REMOTE=origin \; WHEEL=build/deploy/dist/hail-0.2.128-py3-none-any.whl \; GITHUB_OAUTH_HEADER_FILE=abc123 \; HAIL_GENETICS_HAIL_IMAGE=abc123 \; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=a \; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=b \; HAIL_GENETICS_HAILTOP_IMAGE=c \; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=d \; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=e \; WHEEL_FOR_AZURE=f \; WEBSI,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:9931,echo,echo,9931,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['echo'],['echo']
Availability,"'data/1kg.mt',overwrite=True); File ""</Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/decorator.py:decorator-gen-946>"", line 2, in write; File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/typecheck/check.py"", line 561, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/matrixtable.py"", line 2494, in write; Env.backend().execute(MatrixWrite(self._mir, writer)); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/backend/backend.py"", line 106, in execute; result = json.loads(Env.hail().backend.spark.SparkBackend.executeJSON(self._to_java_ir(ir))); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/utils/java.py"", line 240, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: ScalaSigParserError: Unexpected failure. Java stack trace:; org.json4s.scalap.ScalaSigParserError: Unexpected failure; 	at org.json4s.scalap.Rules$$anonfun$expect$1.apply(Rules.scala:73); 	at org.json4s.scalap.scalasig.ClassFileParser$.parse(ClassFileParser.scala:95); 	at org.json4s.reflect.ScalaSigReader$.parseClassFileFromByteCode(ScalaSigReader.scala:178); 	at org.json4s.reflect.ScalaSigReader$.findScalaSig(ScalaSigReader.scala:172); 	at org.json4s.reflect.ScalaSigReader$.findClass(ScalaSigReader.scala:53); 	at org.json4s.reflect.ScalaSigReader$.org$json4s$reflect$ScalaSigReader$$findField(ScalaSigReader.scala:100); 	at org.json4s.reflect.ScalaSigReader$.org$json4s$reflect$ScalaSigReader$$read$1(ScalaSigReader.scala:45); 	at org.json4s.reflect.ScalaSigReader$.readField(ScalaSigReader.scala:49); 	at org.json4s.reflect.Reflector$ClassDescriptorBuilder$$anonfun$3.apply(Reflector.scala:69); 	a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6299:1606,Error,Error,1606,https://hail.is,https://github.com/hail-is/hail/issues/6299,1,['Error'],['Error']
Availability,'may or may not' is redundant phrasing. The word 'may' is sufficient to indicate the optional nature of glob expressions in the `path` argument to `import_vcf`. ## Security Assessment; - This change has no security impact. ### Impact Description; Docs only,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14746:20,redundant,redundant,20,https://hail.is,https://github.com/hail-is/hail/pull/14746,1,['redundant'],['redundant']
Availability,"'s memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: All done; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. Notice:; 1. The total memory available on the machine is less than 52 GiB (= 53,248 MiB), indeed it is a full 1025 MiB below the advertised amount.; 2. Once all the components of the Dataproc cluster have started (but before any Hail Query jobs are submitted) the total memory available is already depleted to 42760 MiB. Recall that Hail allocates 41 GiB (= 41,984 MiB) to its JVM. This leaves the Python process and all other daemons on the system only 776 MiB of excess RAM. For reference `python3 -c 'import hail'` needs 206 MiB. ---. We must address this situation. It seems safe to assume that the system daemons will use a constant 9.5 GiB of RAM. Moreover the advertised RAM amount is at least 1 GiB larger than reality. I propose:; 1. The driver memory calculation in `hailctl dataproc` should take the advertised RAM amount, subtract 10.5 GiB, and then use 90% of the remaining value. For an n1-highmem-8, that reduces our allocation from 41 GiB to 37 GiB yielding an additional 4GiB to Python and deamon memory fluctuations.; 2. AoU RWB needs to review its memory setti",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:2183,avail,available,2183,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790,1,['avail'],['available']
Availability,"'s the only event loop that will exist forever. Pytest (and newer version of IPython, afaict) violate this pretty liberally. ~~pytest_asyncio has [explicit instructions on how to run every test in the same event loop](https://pytest-asyncio.readthedocs.io/en/latest/how-to-guides/run_session_tests_in_same_loop.html). I've implemented those here.~~ [These instructions don't work](https://github.com/pytest-dev/pytest-asyncio/issues/744). It seems that the reliable way to ensure we're using one event loop everywhere is to use pytest-asyncio < 0.23 and to define an event_loop fixture with scope `'session'`. I also switched test_batch.py into pytest-only style. This allows me to use session-scoped fixtures so that they exist exactly once for the entire test suite execution. Also:; - `RouterAsyncFS` methods must either be a static method or an async method. We must not create an FS in a sync method. Both `parse_url` and `copy_part_size` now both do not allocate an FS.; - `httpx.py` now eagerly errors if the running event loop in `request` differs from that at allocation time. Annoying but much better error message than this nonsense about timeout context managers.; - `hail_event_loop` either gets the current thread's event loop (running or not, doesn't matter to us) or creates a fresh event loop and sets it as the current thread's event loop. The previous code didn't guarantee we'd get an event loop b/c `get_event_loop` fails if `set_event_loop` was previously called.; - `conftest.py` is inherited downward, so I lifted fixtures out of test_copy.py and friends and into a common `hailtop/conftest.py`; - I added `make -C hail pytest-inter-cloud` for testing the inter cloud directory. You still need appropriate permissions and authn.; - I removed extraneous pytest.mark.asyncio since we use auto mode everywhere.; - `FailureInjectingClientSession` creates an `aiohttp.ClientSession` and therefore must be used while an event loop is running. Easiest fix was to make the test async.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14097:1186,error,errors,1186,https://hail.is,https://github.com/hail-is/hail/pull/14097,4,"['Failure', 'down', 'error']","['FailureInjectingClientSession', 'downward', 'error', 'errors']"
Availability,"'truth_data'), args.overwrite); File ""<decorator-gen-528>"", line 2, in write; File ""/tmp/88fe16cd-42a9-4d26-ac71-5e6676ff3392/hail-devel-6d6d3d2d7992.zip/hail/typecheck/check.py"", line 479, in _typecheck; File ""/tmp/88fe16cd-42a9-4d26-ac71-5e6676ff3392/hail-devel-6d6d3d2d7992.zip/hail/matrixtable.py"", line 1807, in write; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/88fe16cd-42a9-4d26-ac71-5e6676ff3392/hail-devel-6d6d3d2d7992.zip/hail/utils/java.py"", line 238, in deco; hail.utils.java.FatalError: HailException: found non-left aligned variant: 18:76051965:C:G. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 56 in stage 3.0 failed 20 times, most recent failure: Lost task 56.19 in stage 3.0 (TID 685, exomes2-sw-8mf1.c.broad-mpg-gnomad.internal, executor 55): is.hail.utils.HailException: found non-left aligned variant: 18:76051965:C:G; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.methods.SplitMultiPartitionContext.splitRow(SplitMulti.scala:98); 	at is.hail.methods.SplitMulti$$anonfun$split$1$$anonfun$apply$1.apply(SplitMulti.scala:226); 	at is.hail.methods.SplitMulti$$anonfun$split$1$$anonfun$apply$1.apply(SplitMulti.scala:225); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.hasNext(OrderedRVD.scala:733); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.hasNext(OrderedRVD.scala:733); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.sparkextras.OrderedJoinDistinctIterator.advanceRight1(OrderedJoinDistinctIterator.scala:36); 	at is.hail.sparkextras.OrderedJoinDistinctIterator.advanceRight(OrderedJoinDistinctIterator.scala:42); 	at is.hail.spa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3040:1654,Error,ErrorHandling,1654,https://hail.is,https://github.com/hail-is/hail/issues/3040,1,['Error'],['ErrorHandling']
Availability,"'tsv']}; bgzip {j.counts['tsv']}; gatk IndexFeatureFile --input {j.counts['tsv.gz']}; """"""). b.write_output(j.counts['tsv.gz'], output_path); b.write_output(j.counts['tsv.gz.tbi'], output_index_path); ```. (Trying to use `b.write_output(j.counts, output_base)` to write out the whole ResourceGroup fails because the `/counts.counts.tsv` file no longer exists because it was removed by `bgzip`. In any case, we don't want to write that one to the final bucket anyway. Hence the two separate `write_output` invocations for the two desired output files.). This fails in the second `write_output` with a fairly mysterious exception:. ```; File """", line 92, in test; b.write_output(j.counts['tsv.gz.tbi'], output_index_path); File ""/lib/python/site-packages/hailtop/batch/batch.py"", line 595, in write_output; name = resource._source._resources_inverse[resource]; KeyError: __RESOURCE_FILE__11; ```. Checking that line of _batch.py_, it is failing while trying to print an error message because `_resources_inverse` is not set up for the JobResourceFiles within ResourceGroups. PR #13192 is a suggested fix for this. With that PR applied, this results in a more useful hail error message exception:. ```; hailtop.batch.exceptions.BatchException: undefined resource 'counts[""tsv.gz.tbi""]'; Hint: resources must be defined within the job methods 'command' or 'declare_resource_group'; ```. This can be worked around by mentioning the filename in the commands to be run  in a comment, because none of the commands actually need to specify the `.tbi` output filename:. ```python; ; j.command(f""""""; gatk SubCommand  --output {j.counts['tsv']}; bgzip {j.counts['tsv']}; gatk IndexFeatureFile --input {j.counts['tsv.gz']}; : {j.counts['tsv.gz.tbi']}; """"""); ; ```. This produces the desired two files  compressed data and the associated index  written to the final bucket. Is it kosher to use `write_output` on the individual items within a ResourceGroup like this?. However this resource **was** defined ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13191:1646,error,error,1646,https://hail.is,https://github.com/hail-is/hail/issues/13191,1,['error'],['error']
Availability,"()._jhc.backend().executeJSON(self._to_java_ir(ir))); 109 value = ir.typ._from_json(result['value']); 110 timings = result['timings']. /usr/lib/spark/python/lib/py4j-src.zip/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /usr/local/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 223 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 224 'Hail version: %s\n'; --> 225 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 226 except pyspark.sql.utils.CapturedException as e:; 227 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NoSuchElementException: key not found: GRCh37; ```. ### Traces No.2:; ```java; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 4 times, most recent failure: Lost task 0.3 in stage 19.0 (TID 220, ip-172-31-2-255.ec2.internal, executor 2): org.json4s.package$MappingException: unknown error; 	at org.json4s.Extraction$.extract(Extraction.scala:43); 	at org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21); 	at is.hail.io.index.IndexReader$.readMetadata(IndexReader.scala:65); 	at is.hail.io.index.IndexReader.<init>(IndexReader.scala:90); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:879); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:877); 	at scala.Option.map(Option.scala:146); 	at is.hail.HailContext$$anon$3.compute(HailContext.scala:877); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:30217,failure,failure,30217,https://hail.is,https://github.com/hail-is/hail/issues/7044,1,['failure'],['failure']
Availability,"().write(); ```. ```; Traceback (most recent call last):; File ""/tmp/a913d6ce5b814a63ad7af31060416237/pyscripts_Xr0D99.zip/gnomad_hail/slack_utils.py"", line 77, in try_slack; File ""/tmp/a913d6ce5b814a63ad7af31060416237/generate_qc_annotations.py"", line 247, in main; generate_call_stats(mt).write(annotations_mt_path(data_type, 'call_stats'), args.overwrite); File ""<decorator-gen-556>"", line 2, in write; File ""/tmp/a913d6ce5b814a63ad7af31060416237/hail-devel-a1d6ecc71ce3.zip/hail/typecheck/check.py"", line 481, in _typecheck; File ""/tmp/a913d6ce5b814a63ad7af31060416237/hail-devel-a1d6ecc71ce3.zip/hail/matrixtable.py"", line 2027, in write; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/a913d6ce5b814a63ad7af31060416237/hail-devel-a1d6ecc71ce3.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: IllegalArgumentException: requirement failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 9716 in stage 1.0 failed 20 times, most recent failure: Lost task 9716.19 in stage 1.0 (TID 10060, exomes3-sw-dfpw.c.broad-mpg-gnomad.internal, executor 134): java.lang.IllegalArgumentException: requirement failed; 	at scala.Predef$.require(Predef.scala:212); 	at is.hail.variant.Call$.alleleByIndex(Call.scala:128); 	at is.hail.expr.FunctionRegistry$$anonfun$11.apply$mcIII$sp(FunctionRegistry.scala:685); 	at is.hail.expr.FunctionRegistry$$anonfun$11.apply(FunctionRegistry.scala:685); 	at is.hail.expr.FunctionRegistry$$anonfun$11.apply(FunctionRegistry.scala:685); 	at is.hail.expr.BinaryFun.apply(Fun.scala:122); 	at is.hail.codegen.generated.C9.apply(Unknown Source); 	at is.hail.codegen.generated.C9.apply(Unknown Source); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:84); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:82); 	at is.hail.expr.Parser$$anonfun$is$hail$expr$Parser$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:1627,failure,failure,1627,https://hail.is,https://github.com/hail-is/hail/issues/3465,1,['failure'],['failure']
Availability,"(346 kB); 915 | amazon-ebs:  346.4/346.4 kB 41.0 MB/s eta 0:00:00; 916 | amazon-ebs: Collecting bokeh<2.0,>1.3; 917 | amazon-ebs: Downloading bokeh-1.4.0.tar.gz (32.4 MB); 918 | amazon-ebs:  32.4/32.4 MB 48.4 MB/s eta 0:00:00; 919 | amazon-ebs: Preparing metadata (setup.py): started; 920 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 921 | amazon-ebs: Requirement already satisfied: boto3<2.0,>=1.17 in /usr/local/lib/python3.7/site-packages (1.24.78); 922 | amazon-ebs: Requirement already satisfied: botocore<2.0,>=1.20 in /usr/local/lib/python3.7/site-packages (1.27.78); 923 | amazon-ebs: Collecting decorator<5; 924 | amazon-ebs: Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); 925 | amazon-ebs: Collecting Deprecated<1.3,>=1.2.10; 926 | amazon-ebs: Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB); 927 | amazon-ebs: Collecting dill<0.4,>=0.3.1.1; 928 | amazon-ebs: Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB); 929 | amazon-ebs:  95.8/95.8 kB 15.3 MB/s eta 0:00:00; 930 | amazon-ebs: Collecting google-auth==1.27.0; 931 | amazon-ebs: Downloading google_auth-1.27.0-py2.py3-none-any.whl (135 kB); 932 | amazon-ebs:  135.6/135.6 kB 30.6 MB/s eta 0:00:00; 933 | amazon-ebs: Collecting google-cloud-storage==1.25.*; 934 | amazon-ebs: Downloading google_cloud_storage-1.25.0-py2.py3-none-any.whl (73 kB); 935 | amazon-ebs:  73.4/73.4 kB 22.1 MB/s eta 0:00:00; 936 | amazon-ebs: Collecting humanize==1.0.0; 937 | amazon-ebs: Downloading humanize-1.0.0-py2.py3-none-any.whl (51 kB); 938 | amazon-ebs:  51.9/51.9 kB 14.6 MB/s eta 0:00:00; 939 | amazon-ebs: Collecting hurry.filesize==0.9; 940 | amazon-ebs: Downloading hurry.filesize-0.9.tar.gz (2.8 kB); 941 | amazon-ebs: Preparing metadata (setup.py): s",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:4183,Down,Downloading,4183,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,"(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at org.apache.spark.sql.execution.datasources.FileFormatWriter$SingleDirectoryWriteTask.execute(FileFormatWriter.scala:244); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:190); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:188); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1341); at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:193); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1$$anonfun$3.apply(FileFormatWriter.scala:129); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1$$anonfun$3.apply(FileFormatWriter.scala:128); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-6e815ac; Error summary: HailException: Hail only supports diploid genotypes. Found min ploidy equals `1' and max ploidy equals `2'.; Unhandled exception in thread started by <bound method Thread.__bootstrap of <Thread(Thread-1, stopped daemon 140486823679744)>>; Traceback (most recent call last):; File ""/usr/lib/python2.7/threading.py"", line 783, in __bootstrap; self.__bootstrap_inner(); File ""/usr/lib/python2.7/threading.py"", line 823, in __bootstrap_inner; (self.name, _format_exc()))",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:14989,Error,Error,14989,https://hail.is,https://github.com/hail-is/hail/issues/2407,1,['Error'],['Error']
Availability,"(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745)is.hail.utils.HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; see the Hail log for the full offending line; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:12); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:744); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:413); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:815); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.io.RichContextRDDRegionValue$$anonfun$5$$anonfun$apply$1$$anonfun$apply$2$$anonfun$apply$3$$anonfun$apply$4.apply(RowStore.scala:775); at is.hail.io.RichContextRDDRegionValue$$anonfun$5$$anonfun$apply$1$$anonfun$apply$2$$anonfun$apply$3$$anonfun$apply$4.apply(RowSto",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3379:11550,Error,ErrorHandling,11550,https://hail.is,https://github.com/hail-is/hail/issues/3379,1,['Error'],['ErrorHandling']
Availability,"(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: devel-2e237ca; Error summary: HailException: missing partitioner.json.gz when loading VDS, create with HailContext.write_partitioning.; ```. 2. gs://hail-common/gencode_and_production_intervals.merged.hg19.vds. ```; File ""<decorator-gen-162>"", line 2, in read; File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/java.py"", line 113, in handle_py4j; hail.java.FatalError: HailException: missing partitioner.json.gz when loading VDS, create with HailContext.write_partitioning. Java stack trace:; is.hail.utils.HailException: missing partitioner.json.gz when loading VDS, create with HailContext.write_partitioning.; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:20); 	at is.hail.variant.VariantDataset$.liftedTree1$1(VariantDataset.scala:89); 	at is.hail.variant.VariantDataset$.read(VariantDataset.scala:84); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:414); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:413); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.HailContext.readAll(HailContext.scala:413); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMet",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1683:2869,Error,ErrorHandling,2869,https://hail.is,https://github.com/hail-is/hail/issues/1683,1,['Error'],['ErrorHandling']
Availability,(Table.scala:1003); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)is.hail.utils.HailException: ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf: caught java.util.NoSuchElementException: key not found: GT; offending line: 22	16050075	rs587697622	A	G	100	PASS	AC=1;AF=0.000199681;AN=...; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.utils.Context.wrapException(Context.scala:23); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:761); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); 	at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:413); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:815); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:815); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$11.hasNext(Iterat,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3467:7658,Error,ErrorHandling,7658,https://hail.is,https://github.com/hail-is/hail/issues/3467,1,['Error'],['ErrorHandling']
Availability,(can fix by defining `def __iter__` on MT/Table to throw an error),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3038#issuecomment-369615427:60,error,error,60,https://hail.is,https://github.com/hail-is/hail/issues/3038#issuecomment-369615427,1,['error'],['error']
Availability,"(dup_ht[mt.s]) | (mt.s == 'NA12878') | (mt.s == 'syndip'))); File ""<decorator-gen-510>"", line 2, in filter_cols; File ""/tmp/478e9775e51b49afb6828e4a014c7a7a/hail-devel-d7e032a87341.zip/hail/typecheck/check.py"", line 480, in _typecheck; File ""/tmp/478e9775e51b49afb6828e4a014c7a7a/hail-devel-d7e032a87341.zip/hail/matrixtable.py"", line 1419, in filter_cols; File ""/tmp/478e9775e51b49afb6828e4a014c7a7a/hail-devel-d7e032a87341.zip/hail/matrixtable.py"", line 2241, in _process_joins; File ""/tmp/478e9775e51b49afb6828e4a014c7a7a/hail-devel-d7e032a87341.zip/hail/table.py"", line 1233, in <lambda>; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/478e9775e51b49afb6828e4a014c7a7a/hail-devel-d7e032a87341.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 250 in stage 16.0 failed 20 times, most recent failure: Lost task 250.19 in stage 16.0 (TID 5993, exomes2-sw-znhp.c.broad-mpg-gnomad.internal, executor 1): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:751); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:733); 	at scala.collection.Iterator$$anon$1.next(Iterator.scala:1010); 	at scala.collection.Iterator$$anon$1.head(Iterator.scala:997); 	at is.hail.utils.richUtils.RichIterator$$anon$5.value(RichIterator.scala:18); 	at is.hail.utils.StagingIterator.value(FlipbookIterator.scala:47); 	at is.hail.utils.FlipbookIterator$$anon$5.value(FlipbookIterator.scala:167); 	at is.hail.utils.FlipbookIterator$$anon$5.isValid(FlipbookIterator.scala:168); 	at is.hail.utils.StagingIterator.isValid(FlipbookIterator.scala:46); 	at is.hail.utils.FlipbookIterator.exhaust(FlipbookIterator.scala:110); 	at is.hail.utils.FlipbookIterator$$anon$6.advance(FlipbookIt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3235:1503,failure,failure,1503,https://hail.is,https://github.com/hail-is/hail/issues/3235,1,['failure'],['failure']
Availability,"(note this is coming from a downstream commit where I've written a lowerer for MatrixRead, that's what the `TableZipUnchecked` is for)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5041#issuecomment-449744063:28,down,downstream,28,https://hail.is,https://github.com/hail-is/hail/pull/5041#issuecomment-449744063,1,['down'],['downstream']
Availability,"(self, ir, timed=False):; --> 108 result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); 109 value = ir.typ._from_json(result['value']); 110 timings = result['timings']. /usr/lib/spark/python/lib/py4j-src.zip/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /usr/local/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 223 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 224 'Hail version: %s\n'; --> 225 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 226 except pyspark.sql.utils.CapturedException as e:; 227 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NoSuchElementException: key not found: GRCh37; ```. ### Traces No.2:; ```java; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 4 times, most recent failure: Lost task 0.3 in stage 19.0 (TID 220, ip-172-31-2-255.ec2.internal, executor 2): org.json4s.package$MappingException: unknown error; 	at org.json4s.Extraction$.extract(Extraction.scala:43); 	at org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21); 	at is.hail.io.index.IndexReader$.readMetadata(IndexReader.scala:65); 	at is.hail.io.index.IndexReader.<init>(IndexReader.scala:90); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:879); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:877); 	at scala.Option.map(Option.scala:146); 	at is.hail.HailContext$$anon$3.compute(HailContext.scala:877); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.sp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:30159,failure,failure,30159,https://hail.is,https://github.com/hail-is/hail/issues/7044,1,['failure'],['failure']
Availability,") [""{\""path\"":\""gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht\""}""] ; !191 = MakeStruct(); !192 = WriteMetadata(!191) [""{\""path\"":\""gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht/globals\""}""] ; !193 = MakeStruct(); !194 = WriteMetadata(!193) [""{\""path\"":\""gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht/cols\""}""] ; !195 = MakeStruct(); !196 = WriteMetadata(!195) [""{\""path\"":\""gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht/rows\""}""] ; !197 = MakeStruct(); !198 = WriteMetadata(!197) [""{\""path\"":\""gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht/entries\""}""]; !199 = Begin(!154, !160, !166, !169, !172, !176, !188, !190, !192, !194, !196, !198); Begin(!11, !199); ```. </details>. Notice that, after lowering to CDAIR, the `WriteMetadata` for; `gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht`, `....ht/globals`, `....ht/cols`,; `...ht/rows`, and `...ht/entries` all appear thrice. The error message is clearly coming from; `WriteMetadata` writing into the root of the Hail Table. ```; !1 = MakeStruct(); !2 = WriteMetadata(!1) [""{\""path\"":\""gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht\"",\""overwrite\"":false,\""refs\"":{\""rowType\"":\""Struct{locus:Locus(GRCh38),alleles:Array[String],filters:Set[String],a_index:Int32,was_split:Boolean,variant_qc:Struct{gq_stats:Struct{mean:Float64,stdev:Float64,min:Float64,max:Float64},call_rate:Float64,n_called:Int64,n_not_called:Int64,n_filtered:Int64,n_het:Int64,n_non_ref:Int64,het_freq_hwe:Float64,p_value_hwe:Float64,p_value_excess_het:Float64},info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,homozygote_count:Array[Int32]},`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{GT:Call,GQ:Int32,RGQ:Int32,FT:String,AD:Array[Int32]}]}\"",\""key\"":[\""locus\"",\""alleles\""],\""globalType\"":\""Struct{__cols:Array[Struct{s:String,mt_sample_qc:Struct{gq_stats:Struct{mean:Float64,stdev:Float64,min:Float64,max:Float64},call_rate:Float64,n_called:Int64,n_not_called:Int64",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13809:42429,error,error,42429,https://hail.is,https://github.com/hail-is/hail/issues/13809,1,['error'],['error']
Availability,") and getting the following error with jinja2 (see below).; From the error it seems like this is due to Hail's dependency of bokeh using the latest version of jinja2. Downgrading jinja2 to 3.0.0 solves the problem, and it seems like other people have seen this too with the latest release of jinja2:. https://github.com/holoviz/panel/issues/3260. This may be transient and may be solved by bokeh / jinja2 folks but thought I'd let you know in case you hit this issue. ```; ../conda/envs/glow/lib/python3.7/site-packages/bokeh/core/templates.py:43: in <module>; from jinja2 import Environment, Markup, FileSystemLoader; E ImportError: cannot import name 'Markup' from 'jinja2' (/home/circleci/conda/envs/lib/python3.7/site-packages/jinja2/__init__.py); [error] java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; [error] 	at scala.Predef$.require(Predef.scala:281); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14(build.sbt:288); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14$adapted(build.sbt:278); [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49); [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62); [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67); [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:280); [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19); [error] 	at sbt.Execute.work(Execute.scala:289); [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:280); [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.ThreadPoolExe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705:1044,error,error,1044,https://hail.is,https://github.com/hail-is/hail/issues/11705,1,['error'],['error']
Availability,") from 1.17.54 to 1.21.13.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/boto/boto3/blob/develop/CHANGELOG.rst"">boto3's changelog</a>.</em></p>; <blockquote>; <h1>1.21.13</h1>; <ul>; <li>api-change:<code>synthetics</code>: [<code>botocore</code>] Allow custom handler function.</li>; <li>api-change:<code>transfer</code>: [<code>botocore</code>] Add waiters for server online and offline.</li>; <li>api-change:<code>devops-guru</code>: [<code>botocore</code>] Amazon DevOps Guru now integrates with Amazon CodeGuru Profiler. You can view CodeGuru Profiler recommendations for your AWS Lambda function in DevOps Guru. This feature is enabled by default for new customers as of 3/4/2022. Existing customers can enable this feature with UpdateEventSourcesConfig.</li>; <li>api-change:<code>macie</code>: [<code>botocore</code>] Amazon Macie Classic (macie) has been discontinued and is no longer available. A new Amazon Macie (macie2) is now available with significant design improvements and additional features.</li>; <li>api-change:<code>ec2</code>: [<code>botocore</code>] Documentation updates for Amazon EC2.</li>; <li>api-change:<code>sts</code>: [<code>botocore</code>] Documentation updates for AWS Security Token Service.</li>; <li>api-change:<code>connect</code>: [<code>botocore</code>] This release updates the *InstanceStorageConfig APIs so they support a new ResourceType: REAL_TIME_CONTACT_ANALYSIS_SEGMENTS. Use this resource type to enable streaming for real-time contact analysis and to associate the Kinesis stream where real-time contact analysis segments will be published.</li>; </ul>; <h1>1.21.12</h1>; <ul>; <li>api-change:<code>greengrassv2</code>: [<code>botocore</code>] Doc only update that clarifies Create Deployment section.</li>; <li>api-change:<code>fsx</code>: [<code>botocore</code>] This release adds support for data repository associations to use root (&quot;/&quot;) as the file system path</li>; <li>api-change:<code>ke",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11504:1026,avail,available,1026,https://hail.is,https://github.com/hail-is/hail/pull/11504,1,['avail'],['available']
Availability,") from None; 181 if ir.typ == tvoid:; 182 value = None. File /opt/conda/lib/python3.10/site-packages/hail/backend/backend.py:178, in Backend.execute(self, ir, timed); 176 payload = ExecutePayload(self._render_ir(ir), '{""name"":""StreamBufferSpec""}', timed); 177 try:; --> 178 result, timings = self._rpc(ActionTag.EXECUTE, payload); 179 except FatalError as e:; 180 raise e.maybe_user_error(ir) from None. File /opt/conda/lib/python3.10/site-packages/hail/backend/py4j_backend.py:213, in Py4JBackend._rpc(self, action, payload); 211 if resp.status_code >= 400:; 212 error_json = orjson.loads(resp.content); --> 213 raise fatal_error_from_java_error_triplet(error_json['short'], error_json['expanded'], error_json['error_id']); 214 return resp.content, resp.headers.get('X-Hail-Timings', ''). FatalError: HailException: cannot set missing field for required type +PFloat64. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 6.0 failed 4 times, most recent failure: Lost task 5.3 in stage 6.0 (TID 67) (saturn-machinenumber.c.terra-code.internal executor 4): is.hail.utils.HailException: gs://path/to/bucket/chrY.0002.hard_filtered_with_genotypes.vcf.gz:offset 23933331019603: error while parsing line; chrY	113	.	GG	G,*,AG,CG	596	PASS	AC=2,4,6,1;AF=1.23e-03,5.550e-05,4.44e-05,2.00e-04;AN=265;AS_AltDP=10,0,3,10;AS_BaseQRankSum=0.000,.,0.100,0.500;AS_FS=7.777,.,2.144,8.001;AS_MQ=55.75,.,38.98,40.20;AS_MQRankSum=0.200,.,-1.050,-0.500;AS_QD=0.50,0.00,0.25,0.52;AS_ReadPosRankSum=-0.200,.,0.500,-0.220;AS_SOR=2.300,.,1.600,3.000;BaseQRankSum=0.200;DP=600000;ExcessHet=0.0477;FS=0.900;MQ=55.02;MQRankSum=-0.553;QD=1.00;ReadPosRankSum=-0.162;SOR=0.792;VarDP=650	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0/0:.:21:30	0/0:.:300:20	0/0:.:30:72	0/0:.:31:98	0|1:29,3,0,0,0:33:78:0|1:113_GG_G:78,0,1100,140,1400,1200,172,1600,1200,1000,175,1100,1100,1300,1000:113:19,19,2,1	0/0:.:20:19	0/0:.:19:20	0/0:.:25:50		0|1:90,2,0,0,0:30:40:0|1:113_GG_G:40,0,600,70,650,600,90,640,90",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:6075,failure,failure,6075,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['failure'],['failure']
Availability,")._convert_to_j(index_file_map); 1956; -> 1957 Env.hc()._jhc.indexBgen(jindexed_seq_args(path), index_file_map, joption(rg), contig_recoding, skip_invalid_loci); 1958; 1959. /share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /share/pkg/hail/2018-10-31/install/build/distributions/hail-python.zip/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: OutOfMemoryError: GC overhead limit exceeded. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.immutable.VectorBuilder.<init>(Vector.scala:713); at scala.collection.immutable.Vector$.newBuilder(Vector.scala:22); at scala.collection.immutable.IndexedSeq$.newBuilder(IndexedSeq.scala:46); at scala.collection.IndexedSeq$.newBuilder(IndexedSeq.scala:36); at scala.collection.IndexedSeq$$anon$1.apply(IndexedSeq.scala:34); at com.twitter.chill.TraversableSerializer.read(Traversable.scala:39); at com.twitter.chill.TraversableSerializer.read(Traversable.scala:21); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); at com",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:6973,failure,failure,6973,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['failure'],['failure']
Availability,"); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$8.apply(ContextRDD.scala:192); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.utils.package$.singletonElement(package.scala:603); 	at is.hail.rvd.RVD$$anonfun$aggregateWithPartitionOp$1.apply(RVD.scala:558); 	at is.hail.rvd.RVD$$anonfun$aggregateWithPartitionOp$1.apply(RVD.scala:558); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.12-13681278eb89; Error summary: HailException: found out of bounds index -1; Resulted from trying to merge -0.0; Indices are [0.0, 2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0, 18.0, 20.0, 22.0, 24.0, 26.0, 28.0, 30.0, 32.0, 34.0, 36.0, 38.0, 40.0, 42.0, 44.0, 46.0, 48.0, 50.0, 52.0, 54.0, 56.0, 58.0, 60.0, 62.0, 64.0, 66.0, 68.0, 70.0, 72.0, 74.0, 76.0, 78.0, 80.0, 82.0, 84.0, 86.0, 88.0, 90.0, 92.0, 94.0, 96.0, 98.0, 100.0, 102.0, 104.0, 106.0, 108.0, 110.0, 112.0, 114.0, 116.0, 118.0, 120.0, 122.0, 124.0, 126.0, 128.0, 130.0, 132.0, 134.0, 136.0, 138.0, 140.0, 142.0, 144.0, 146.0, 148.0, 150.0, 152.0, 154.0, 156.0, 158.0, 160.0, 162.0, 164.0, 166.0, 168.0, 170.0, 172.0, 174.0, 176.0, 178.0, 180.0, 182.0, 184.0, 186.0, 188.0, 190.0, 192.0, 194.0, 196.0, 198.0, 200.0]; Binary search index was -1; ```. -----------------------------------------------------------------------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:12727,Error,Error,12727,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['Error'],['Error']
Availability,); 	at is.hail.table.Table.take(Table.scala:637); 	at is.hail.table.Table.showString(Table.scala:673); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)is.hail.utils.HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1012); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.RVD$$anonfun$4$$anon$1.hasNext(RVD.scala:226); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1015); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); 	at is.hail.utils.richUtils.RichIterator$$anon$5.isValid(RichIterator.scala:21); 	at is.hail.utils.StagingIterator.isValid(Fli,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:8600,Error,ErrorHandling,8600,https://hail.is,https://github.com/hail-is/hail/issues/4055,1,['Error'],['ErrorHandling']
Availability,"); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.105-3f053140ad00; Error summary: IllegalArgumentException: requirement failed: Invalid method, methods may have at most 255 arguments, found 1163; Return Type Info: V; Parameter Type Info: JLjava/lang/String;ZJJIZJIJJIJJIJJIJJIJJIJJIJJIJJIJZJIJZJIJZJIJZJIJZJIJZJIJZJIJZJIJZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZJJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZJJJZJZIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZIZIZIZIZIZJIJJIJZJJJZJZJIJZJJIJZZJJIJZZJZJZJZJZJZJZJZJZJIJJIJJZJZJZJZLis/hail/io/OutputBuffer;; ```. Presumably this used to work fine in earlier Hail versions. However, it seems impossible to revert to such a version at the moment, as 0.2.81 is the oldest version that one can still start a Dataproc cluster with -- earlier versions use a Debian image without a fix to the `log4j` vulnerability. 0.2.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12533:12397,Error,Error,12397,https://hail.is,https://github.com/hail-is/hail/issues/12533,1,['Error'],['Error']
Availability,"); File ""</opt/conda/default/lib/python3.6/site-packages/decorator.py:decorator-gen-1226>"", line 2, in export_bgen; File ""/opt/conda/default/lib/python3.6/site-packages/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/conda/default/lib/python3.6/site-packages/hail/methods/impex.py"", line 235, in export_bgen; Env.hail().utils.ExportType.getExportType(parallel)))); File ""/opt/conda/default/lib/python3.6/site-packages/hail/backend/backend.py"", line 109, in execute; result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); File ""/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/opt/conda/default/lib/python3.6/site-packages/hail/utils/java.py"", line 225, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); at is.hail.expr.ir.CompileAndEvaluate$$anonfun$apply$1.apply(CompileAndEvaluate.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:14); at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); at is.hail.utils.package$.using(package.scala:596); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:10); at is.hail.expr.ir.ExecuteCont",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8161:1218,error,error,1218,https://hail.is,https://github.com/hail-is/hail/issues/8161,1,['error'],['error']
Availability,); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Shell output: main : command provided 1; main : run as user is farrell; main : requested yarn user is farrell. Container exited with a non-zero exit code 1. 2019-01-22 13:11:53 BlockManagerMaster: INFO: Removal of executor 2 requested; 2019-01-22 13:11:53 BlockManagerMasterEndpoint: INFO: Trying to remove executor 2 from BlockManagerMaster.; 2019-01-22 13:11:53 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Asked to remove non-existent executor 2; 2019-01-22 13:11:53 BlockManagerMaster: INFO: Removal of executor 4 requested; 2019-01-22 13:11:53 BlockManagerMasterEndpoint: INFO: Trying to remove executor 4 from BlockManagerMaster.; 2019-01-22 13:11:53 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Asked to remove non-existent executor 4; 2019-01-22 13:11:53 YarnScheduler: ERROR: Lost executor 5 on scc-q08.scc.bu.edu: Container marked as failed: container_e2435_1542127286896_0174_01_000006 on host: scc-q08.scc.bu.edu. Exit status: 1. Diagnostics: Exception from container-launch.; Container id: container_e2435_1542127286896_0174_01_000006; Exit code: 1; Stack trace: ExitCodeException exitCode=1:; at org.apache.hadoop.util.Shell.runCommand(Shell.java:576); at org.apache.hadoop.util.Shell.run(Shell.java:487); at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:753); at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:371); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:303); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.u,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:91004,ERROR,ERROR,91004,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['ERROR'],['ERROR']
Availability,); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Shell output: main : command provided 1; main : run as user is farrell; main : requested yarn user is farrell. Container exited with a non-zero exit code 1. 2019-01-22 13:11:53 BlockManagerMasterEndpoint: INFO: Trying to remove executor 6 from BlockManagerMaster.; 2019-01-22 13:11:53 BlockManagerMaster: INFO: Removal of executor 6 requested; 2019-01-22 13:11:53 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Asked to remove non-existent executor 6; 2019-01-22 13:11:53 BlockManagerMaster: INFO: Removal of executor 7 requested; 2019-01-22 13:11:53 BlockManagerMasterEndpoint: INFO: Trying to remove executor 7 from BlockManagerMaster.; 2019-01-22 13:11:53 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Asked to remove non-existent executor 7; 2019-01-22 13:11:53 YarnScheduler: ERROR: Lost executor 4 on scc-q07.scc.bu.edu: Container marked as failed: container_e2435_1542127286896_0174_01_000005 on host: scc-q07.scc.bu.edu. Exit status: 1. Diagnostics: Exception from container-launch.; Container id: container_e2435_1542127286896_0174_01_000005; Exit code: 1; Stack trace: ExitCodeException exitCode=1:; at org.apache.hadoop.util.Shell.runCommand(Shell.java:576); at org.apache.hadoop.util.Shell.run(Shell.java:487); at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:753); at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:371); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:303); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.u,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:83270,ERROR,ERROR,83270,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['ERROR'],['ERROR']
Availability,"* Fix error in TableKeyByAndAggregate caused by field name clobbering; * Fix error in TableLeftJoinRightDistinct with non-strict left tables; * Fix erroneous key preservation in TableStage.mapPartition; * Add Consume to TypeCheck; * Fix error where globals were not exposed in TableAggregate; * Fix error where globals were not exposed in TableAggregate. New local backend success rate:. ```; 271 failed, 496 passed, 75 skipped, 15 warnings in 368.17 seconds; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9202:6,error,error,6,https://hail.is,https://github.com/hail-is/hail/pull/9202,4,['error'],['error']
Availability,* Hailtop wasn't a module.; * The import paths were fucked.; * There was a syntax error in setup.py; * No dirty trees after builds,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6442:82,error,error,82,https://hail.is,https://github.com/hail-is/hail/pull/6442,1,['error'],['error']
Availability,"* Reworked logging to route log output through Python stderr. - Removed SLF4J, everything goes directly through log4j now.; - Removed the explicitly System.err.write calls inside info / warn.; - Separated console logging and log file logging; - Stripped the huge stack traces out of python errors; they are logged; to the screen / cell through log4j. * Fix info for truncatables. * Address comments",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2109:290,error,errors,290,https://hail.is,https://github.com/hail-is/hail/pull/2109,1,['error'],['errors']
Availability,"* add simulated BGEN file based on distributions in real data; * add import, info score, filter benchmarks; * fix bad error message in `export_bgen`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6976:118,error,error,118,https://hail.is,https://github.com/hail-is/hail/pull/6976,1,['error'],['error']
Availability,"* fixed finally. * evict Spark BlockMatrix and friends. * remove old test suite. * a bunch more cleanups. * simplify grid partitioner. * fix test. * remove unneeded try-catches. * organization. * add a test suite for HBM. * help closure serializer. * use correct aggregation method, add test. * test+fix bug grid partitioner. * wip zippartitions. * teach tests to tolerate NaNs. * fix test. * kinda works again. * remove unnecessary trys. * handle transposition in map*. * clean up imports. * standardize langauge. * bunch of comments addressed. * improve error message. * fix python. * rename HailBlockMatrix -> BlockMatrix. * a bunch of comments addressed. * more comments addressed. * make test comment not confusing. * fix rebase error. * fixes. * fix. * fix bug in rirm. * gotta get that transpose right. * test fixes. * dan is a dummy. * commits got lost for sure. * realize transpose when writing. * add indexed tests for map2?WithIndex when transposed. * use Gen.denseMatrix. * use Gen.denseMatrix. * final fixes. * toLocalMatrix returns Spark matrix for backwards compatibility. * avoid an array copy. the BDMs produced by BlockMatrix.toLocalMatrix are in a; ""normal form"", i.e. offset 0, column-major stride, non-; transposed. Given this assumption we can quickly produce a; Spark-style local matrix. * dan is a dummy. * collect-in-order. collect doesn't guarantee order. * do not use BDM.data naively. This was the true root casue: an incorrect test. * fix python interface. * in python, java fields are methods. note the addition of parentheses",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2329:364,toler,tolerate,364,https://hail.is,https://github.com/hail-is/hail/pull/2329,3,"['error', 'toler']","['error', 'tolerate']"
Availability,"* wip: general VSM keys. cleanup. more cleanup. Complete. Addressed comments. Passes JVM tests with generalized row keys. Needs cleanup, work on pythons side. Minor cleanup. Cleanup around OrderedRDD. More minor cleanup. impex cleanup. VSMSubgen cleanup. Formatting. Passing Scala and Python tests. Fixed minor compile error in test. Minor fix. Addressed first round of comments. * Removed generic genotype. Support null genotypes in GenotypeStream. filterGenotypes just sets; filtered cells (genotypes) to null. This is a file-format breaking; change. Bumped the VDS file version, removed backwards compatability; tests. * Nuked generic from python. * More python cleanup, fixed tests. * Fixed tests. * Genotype can be null. All tests pass. * Fixed python tests. * Cleanup. * Fixed docs test. * Another doc test fix. * Fixed doc tests. * Added missing file. * Addressed comments. Added back SampleQC optimizations.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2039:319,error,error,319,https://hail.is,https://github.com/hail-is/hail/pull/2039,1,['error'],['error']
Availability,* works?. * address PR comments. * optimize imports. * use existing interfaces. * fix imports. * fix syntax error. * remove bad import. * add LDMatrix import. * fix tests for ldmatrix. * fix tests. * clean paths before writing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2124:108,error,error,108,https://hail.is,https://github.com/hail-is/hail/pull/2124,1,['error'],['error']
Availability,"** Actually used python stdlib package `difflib`. This PR improves error messages for things like:. ```text; In [3]: ds.INFO; AttributeError: MatrixTable instance has no field, method, or property 'INFO'; Did you mean:; Data field: 'info' [row]; ```; ```text; In [4]: ds['INFO']; LookupError: MatrixTable instance has no field 'INFO'; Did you mean:; 'info' [row field]; Hint: use 'describe()' to show the names of all data fields.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2735:67,error,error,67,https://hail.is,https://github.com/hail-is/hail/pull/2735,1,['error'],['error']
Availability,"**Things still to do:**; 1. Docs for importbgen, importgen, dosage representation, info score in variant qc; 2. Make sure info score is computed properly -- either implement correctly for non-autosomal variants or return None; 3. Add tests for info score (once we finalized how we're computing); 4. Remove null variant in GenotypeBuilder (from import plink block reader code); 5. Decide how to handle fake ref for multiallelics when original genotype call was null (could be because of rounding errors we get same integer value for close doubles such as 0.4035 and 0.4021); 6. Modify variant qc to read parameter about data so info score only calculated for dosage data and likewise for statistics about depth, gq etc.; 7. Handle sex chromosome names in import PLINK properly (do we need to map ""23"" to ""X"", etc.?); 8. Update the readFam function in import plink to utilize functionality Jon wrote already. **Questions:**; 1. I set the default value of --no-compress to true for `importplink`, `importgen`, and `importbgen`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/372:495,error,errors,495,https://hail.is,https://github.com/hail-is/hail/pull/372,1,['error'],['errors']
Availability,"**Work in progress**; _worried the merging and rebasing was done poorly due to the message about merge conflicts at the bottom of this PR - would be useful if someone could let me know or walk me through resolving it_. **Additions:**. - adds method for Blanczos SVD, not yet following the exact interface of the current PCA call; - adds test for Blanczos SVD method; - adds multiple jupyter notebooks where this algorithm was implemented; - adds first version of benchmarking script; - update to requirements.txt regarding gcsfs version should probably be moved to separate PR. **Needs:**; - larger benchmarking; - better test; - hail method for Blanczos PCA to use exact interface and return eigenvalues, scores, and optional loadings as if it were the hail PCA method instead of the current non-centered SVD; - fix the norm(A - QQtA) computation - maybe make it blocked; - possibly block the error bound computation; - possibly replace the numpy library calls to SVD and QR decomposition with distributed hail versions, or at least the SVD call at a minimum since it is easier",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9222:894,error,error,894,https://hail.is,https://github.com/hail-is/hail/pull/9222,1,['error'],['error']
Availability,"*Update*. If it helps, our configuration includes three VMs. This includes a master and two workers with autoscaling enabled. We have tried using n1-himem-8 and n1-himem-64 machines. Both configurations failed with similar errors. The one above is form the n1-himem-64 configuration.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12083#issuecomment-1213381420:223,error,errors,223,https://hail.is,https://github.com/hail-is/hail/issues/12083#issuecomment-1213381420,1,['error'],['errors']
Availability,"*kwargs); 49 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 50 'Hail version: %s\n'; ---> 51 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None; 52 except pyspark.sql.utils.CapturedException as e:; 53 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NullPointerException: null. Java stack trace:; java.lang.NullPointerException: null; 	at scala.collection.mutable.ArrayOps$ofRef$.length$extension(ArrayOps.scala:192); 	at scala.collection.mutable.ArrayOps$ofRef.length(ArrayOps.scala:192); 	at scala.collection.SeqLike$class.size(SeqLike.scala:106); 	at scala.collection.mutable.ArrayOps$ofRef.size(ArrayOps.scala:186); 	at scala.collection.mutable.Builder$class.sizeHint(Builder.scala:69); 	at scala.collection.mutable.ArrayBuilder.sizeHint(ArrayBuilder.scala:22); 	at scala.collection.TraversableLike$class.builder$1(TraversableLike.scala:230); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:233); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.io.fs.HadoopFS.listStatus(HadoopFS.scala:105); 	at is.hail.utils.Py4jUtils$class.ls(Py4jUtils.scala:55); 	at is.hail.utils.package$.ls(package.scala:77); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.58-3f304aae6ce2; Error summary: NullPointerException: null; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9600:2995,Error,Error,2995,https://hail.is,https://github.com/hail-is/hail/issues/9600,1,['Error'],['Error']
Availability,"*kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. ~/bin/anaconda3/lib/python3.6/site-packages/hail/methods/impex.py in import_vcf(path, force, force_bgz, header_file, min_partitions, drop_samples, call_fields, reference_genome, contig_recoding, array_elements_required, skip_invalid_loci); 1893 skip_invalid_loci,; 1894 force_bgz,; -> 1895 force; 1896 ); 1897 return MatrixTable(jmt). ~/bin/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. ~/bin/anaconda3/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:633); 	at is.hail.io.vcf.MatrixVCFReader.<init>(LoadVCF.scala:894); 	at is.hail.io.vcf.LoadVCF$.pyApply(LoadVCF.scala:850); 	at is.hail.io.vcf.LoadVCF.pyApply(LoadVCF.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4775:2110,Error,Error,2110,https://hail.is,https://github.com/hail-is/hail/issues/4775,1,['Error'],['Error']
Availability,+ arguments='HAIL_PIP_VERSION HAIL_VERSION GIT_VERSION REMOTE WHEEL GITHUB_OAUTH_HEADER_FILE HAIL_GENETICS_HAIL_IMAGE HAIL_GENETICS_HAIL_IMAGE_PY_3_10 HAIL_GENETICS_HAIL_IMAGE_PY_3_11 HAIL_GENETICS_HAILTOP_IMAGE HAIL_GENETICS_VEP_GRCH37_85_IMAGE HAIL_GENETICS_VEP_GRCH38_95_IMAGE WHEEL_FOR_AZURE WEBSITE_TAR'; + for varname in '$arguments'; + '[' -z 0.2.123 ']'; + echo HAIL_PIP_VERSION=0.2.123; HAIL_PIP_VERSION=0.2.123; + for varname in '$arguments'; + '[' -z 0.2.123-abcdef123 ']'; + echo HAIL_VERSION=0.2.123-abcdef123; HAIL_VERSION=0.2.123-abcdef123; + for varname in '$arguments'; + '[' -z abcdef123 ']'; + echo GIT_VERSION=abcdef123; GIT_VERSION=abcdef123; + for varname in '$arguments'; + '[' -z origin ']'; + echo REMOTE=origin; REMOTE=origin; + for varname in '$arguments'; + '[' -z /path/to/the.whl ']'; + echo WHEEL=/path/to/the.whl; WHEEL=/path/to/the.whl; + for varname in '$arguments'; + '[' -z /path/to/github/oauth/header/file ']'; + echo GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:2206,echo,echo,2206,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,2,['echo'],['echo']
Availability,", 'b': 2},; {'a': 'bar', 'b': 2}],; hl.tstruct(a=hl.tstr, b=hl.tint32),; key='a'); t2 = hl.Table.parallelize([; {'t': 'foo', 'x': 3.14},; {'t': 'bar', 'x': 2.78},; {'t': 'bar', 'x': -1},; {'t': 'quam', 'x': 0}],; hl.tstruct(t=hl.tstr, x=hl.tfloat64),; key='t'). t1.join(t2, how='outer').show(). # or. t1.join(t2, how='right').show(); ```. ### What went wrong (all error messages here, including the full java stack trace):. FatalError: HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 1 times, most recent failure: Lost task 0.0 in stage 19.0 (TID 24, localhost, executor driver): is.hail.utils.HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1012); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.RVD$$anonfun$4$$anon$1.hasNext(RVD.scala:226); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1015); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); 	at is.hail.utils.richUtils.RichIterator$$anon$5.isValid(RichIterator.scala:21); 	at is.hail.utils.StagingIterator.isValid(FlipbookIterator.scala:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:1116,Error,ErrorHandling,1116,https://hail.is,https://github.com/hail-is/hail/issues/4055,1,['Error'],['ErrorHandling']
Availability,", **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561; 562 return wrapper. /share/pkg/hail/2018-10-31/install/build/distributions/hail-python.zip/hail/matrixtable.py in write(self, output, overwrite, stage_locally, _codec_spec); 2146 """"""; 2147; -> 2148 self._jvds.write(output, overwrite, stage_locally, _codec_spec); 2149; 2150 def globals_table(self) -> Table:. /share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /share/pkg/hail/2018-10-31/install/build/distributions/hail-python.zip/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: OutOfMemoryError: Java heap space. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 76 in stage 1.0 failed 1 times, most recent failure: Lost task 76.0 in stage 1.0 (TID 77, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.nio.HeapCharBuffer.toString(HeapCharBuffer.java:567); at java.nio.CharBuffer.toString(CharBuffer.java:1241); at org.apache.hadoop.io.Text.decode(Text.java:412); at org.apache.hadoop.io.Text.decode(Text.java:389); at org.apache.hadoop.io.Text.toString(Text.java:280); at org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8.apply(SparkContext.scala:833); at o",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635:2196,Error,Error,2196,https://hail.is,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635,1,['Error'],['Error']
Availability,", **kwargs_); 586 ; 587 return wrapper. /usr/local/lib/python3.6/site-packages/hail/table.py in collect(self, _localize); 1825 e = construct_expr(ir, hl.tarray(self.row.dtype)); 1826 if _localize:; -> 1827 return Env.backend().execute(e._ir); 1828 else:; 1829 return e. /usr/local/lib/python3.6/site-packages/hail/backend/backend.py in execute(self, ir, timed); 106 ; 107 def execute(self, ir, timed=False):; --> 108 result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); 109 value = ir.typ._from_json(result['value']); 110 timings = result['timings']. /usr/lib/spark/python/lib/py4j-src.zip/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /usr/local/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 223 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 224 'Hail version: %s\n'; --> 225 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 226 except pyspark.sql.utils.CapturedException as e:; 227 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NoSuchElementException: key not found: GRCh37. ```. ### Traces No. 1: . ```java ; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 16.0 failed 4 times, most recent failure: Lost task 15.3 in stage 16.0 (TID 178, ip-172-31-1-20.ec2.internal, executor 4): org.json4s.package$MappingException: unknown error; 	at org.json4s.Extraction$.extract(Extraction.scala:43); 	at org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21); 	at is.hail.io.index.IndexReader$.readMetadata(IndexReader.scala:65); 	at is.hail.io.index.IndexReader.<init>(IndexReader.scala:90); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.io.index.IndexReaderBuilder$$an",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:4822,Error,Error,4822,https://hail.is,https://github.com/hail-is/hail/issues/7044,1,['Error'],['Error']
Availability,", **kwargs_); 586 ; 587 return wrapper. /usr/local/lib/python3.6/site-packages/hail/table.py in collect(self, _localize); 1825 e = construct_expr(ir, hl.tarray(self.row.dtype)); 1826 if _localize:; -> 1827 return Env.backend().execute(e._ir); 1828 else:; 1829 return e. /usr/local/lib/python3.6/site-packages/hail/backend/backend.py in execute(self, ir, timed); 106 ; 107 def execute(self, ir, timed=False):; --> 108 result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); 109 value = ir.typ._from_json(result['value']); 110 timings = result['timings']. /usr/lib/spark/python/lib/py4j-src.zip/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /usr/local/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 223 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 224 'Hail version: %s\n'; --> 225 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 226 except pyspark.sql.utils.CapturedException as e:; 227 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NoSuchElementException: key not found: GRCh37; ```. ### Traces No.2:; ```java; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 4 times, most recent failure: Lost task 0.3 in stage 19.0 (TID 220, ip-172-31-2-255.ec2.internal, executor 2): org.json4s.package$MappingException: unknown error; 	at org.json4s.Extraction$.extract(Extraction.scala:43); 	at org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21); 	at is.hail.io.index.IndexReader$.readMetadata(IndexReader.scala:65); 	at is.hail.io.index.IndexReader.<init>(IndexReader.scala:90); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.io.index.IndexReaderBuilder$$anonfu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:29807,Error,Error,29807,https://hail.is,https://github.com/hail-is/hail/issues/7044,1,['Error'],['Error']
Availability,", full, error_id = tpl._1(), tpl._2(), tpl._3(); ---> 31 raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; 32 except pyspark.sql.utils.CapturedException as e:; 33 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.4 in stage 1.0 (TID 10) (all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_e01_1690206305672_0001_01_000007 on host: all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal. Exit status: 137. Diagnostics: [2023-07-24 13:52:49.515]Container killed on request. Exit code is 137; [2023-07-24 13:52:49.517]Container exited with a non-zero exit code 137. ; [2023-07-24 13:52:49.518]Killed by external signal; .; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.4 in stage 1.0 (TID 10) (all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_e01_1690206305672_0001_01_000007 on host: all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal. Exit status: 137. Diagnostics: [2023-07-24 13:52:49.515]Container killed on request. Exit code is 137; [2023-07-24 13:52:49.517]Container exited with a non-zero exit code 137. ; [2023-07-24 13:52:49.518]Killed by external signal; .; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287:5740,failure,failure,5740,https://hail.is,https://github.com/hail-is/hail/issues/13287,1,['failure'],['failure']
Availability,", line 2, in write_from_entry_expr; File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/linalg/blockmatrix.py"", line 698, in write_from_entry_expr; mt.select_entries(**{field: entry_expr})._write_block_matrix(path, overwrite, field, block_size); File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/matrixtable.py"", line 4112, in _write_block_matrix; 'blockSize': block_size})); File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/backend/spark_backend.py"", line 296, in execute; result = json.loads(self._jhc.backend().executeJSON(jir)); File ""/share/pkg.7/spark/2.4.3/install/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/backend/spark_backend.py"", line 41, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: FileNotFoundException: /scratch/.writeBlocksRDD-l5om7fTy3akZKCYbLDY4AD.crc (Too many open files). Java stack trace:; java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:28); at is.hail.backend.spark.SparkBackend.is$hail$backend$spark$SparkBackend$$_execute(SparkBackend.scala:317); at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(SparkBackend.scala:304); at ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:7161,Error,Error,7161,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,1,['Error'],['Error']
Availability,", min_block_size, branching_factor, tmp_dir) 60 self._jhc = scala_object(self._hail, 'HailContext').apply( 61 jsc, appName, joption(master), local, log, quiet, append, ---> 62 parquet_compression, min_block_size, branching_factor, tmp_dir) 63 64 self._jsc = self._jhc.sc() /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args) 1131 answer = self.gateway_client.send_command(command) 1132 return_value = get_return_value( -> 1133 answer, self.gateway_client, self.target_id, self.name) 1134 1135 for temp_arg in temp_args: /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/pyspark/sql/utils.py in deco(*a, **kw) 61 def deco(*a, **kw): 62 try: ---> 63 return f(*a, **kw) 64 except py4j.protocol.Py4JJavaError as e: 65 s = e.java_exception.toString() /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name) 317 raise Py4JJavaError( 318 ""An error occurred while calling {0}{1}{2}.\n"". --> 319 format(target_id, ""."", name), value) 320 else: 321 raise Py4JError( Py4JJavaError: An error occurred while calling o68.apply. : org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at: org.apache.spark.SparkContext.<init>(SparkContext.scala:76) is.hail.HailContext$.configureAndCreateSparkContext(HailContext.scala:84) is.hail.HailContext$.apply(HailContext.scala:164) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) java.lang.reflect.Method.invoke(Method.java:498) py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) py4j.reflection.ReflectionEngine.invoke(ReflectionEng",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1525:4585,error,error,4585,https://hail.is,https://github.com/hail-is/hail/issues/1525,1,['error'],['error']
Availability,", not containers. Individual containers write their logs.; - I time all the steps of the Pod container (creating, starting, running, uploading log, etc.) with a timing called ""runtime"" which is how long the docker container itself took to start/run. That's usually 4-6 seconds. However, if you log into a machine and run `docker run --rm ubuntu:18.04 echo hi` it takes 1-2 seconds. It would be good to find out where the extra 3-4 seconds are coming from (I feel like @jigold might have some insight into this. Comparing our container config to the docker command line's might be useful here.); - Stop using (value, err) style exception handling. I think we should be able to design this with very little explicit exception handling, mainly in critical blocks to maintain the program invariants.; - Pods can have error status in 1 of 3 ways: the pod itself failed (e.g. couldn't read k8s secrets), one of the pod containers error out (e.g. pull failed due to invalid image), and the docker container finished but the final container status had an ""Error"" field. Next step is to remove pods and merge the pod and job tables. ```; {; ""name"": ""batch-2-job-1"",; ""batch_id"": 2,; ""job_id"": 1,; ""user"": ""test"",; ""state"": ""succeeded"",; ""container_statuses"": {; ""setup"": {; ""name"": ""setup"",; ""state"": ""succeeded"",; ""timing"": {; ""pulling"": 0.038861751556396484,; ""creating"": 0.7245609760284424,; ""starting"": 4.770207166671753,; ""running"": 1.1384251117706299,; ""runtime"": 5.909235715866089,; ""uploading_log"": 0.3659687042236328,; ""deleting"": 0.013197660446166992; },; ""container_status"": {; ""state"": ""exited"",; ""started_at"": ""2019-10-22T09:25:42.477556224Z"",; ""finished_at"": ""2019-10-22T09:25:42.476019599Z"",; ""exit_code"": 0; }; },; ""main"": {; ""name"": ""main"",; ""state"": ""succeeded"",; ""timing"": {; ""pulling"": 0.031185626983642578,; ""creating"": 0.09947538375854492,; ""starting"": 4.786264657974243,; ""running"": 0.44185924530029297,; ""runtime"": 5.228753566741943,; ""uploading_log"": 0.22835826873779297,; ""deleting"":",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7354:1873,Error,Error,1873,https://hail.is,https://github.com/hail-is/hail/pull/7354,1,['Error'],['Error']
Availability,", output, overwrite, stage_locally, _codec_spec); 2146 """"""; 2147; -> 2148 self._jvds.write(output, overwrite, stage_locally, _codec_spec); 2149; 2150 def globals_table(self) -> Table:. /share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /share/pkg/hail/2018-10-31/install/build/distributions/hail-python.zip/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: OutOfMemoryError: Java heap space. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 76 in stage 1.0 failed 1 times, most recent failure: Lost task 76.0 in stage 1.0 (TID 77, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.nio.HeapCharBuffer.toString(HeapCharBuffer.java:567); at java.nio.CharBuffer.toString(CharBuffer.java:1241); at org.apache.hadoop.io.Text.decode(Text.java:412); at org.apache.hadoop.io.Text.decode(Text.java:389); at org.apache.hadoop.io.Text.toString(Text.java:280); at org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8.apply(SparkContext.scala:833); at org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8.apply(SparkContext.scala:833); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$an",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635:2504,failure,failure,2504,https://hail.is,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635,1,['failure'],['failure']
Availability,", the 8.0.x branch will become a tag marking the end of support for that branch. We encourage everyone to upgrade, and to use a tool such as <a href=""https://pypi.org/project/pip-tools/"">pip-tools</a> to pin all dependencies and control upgrades.</p>; <ul>; <li>Changes: <a href=""https://click.palletsprojects.com/en/8.1.x/changes/#version-8-1-0"">https://click.palletsprojects.com/en/8.1.x/changes/#version-8-1-0</a></li>; <li>Milestone: <a href=""https://github.com/pallets/click/milestone/9?closed=1"">https://github.com/pallets/click/milestone/9?closed=1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/click/blob/main/CHANGES.rst"">click's changelog</a>.</em></p>; <blockquote>; <h2>Version 8.1.3</h2>; <p>Released 2022-04-28</p>; <ul>; <li>Use verbose form of <code>typing.Callable</code> for <code>@command</code> and; <code>@group</code>. :issue:<code>2255</code></li>; <li>Show error when attempting to create an option with; <code>multiple=True, is_flag=True</code>. Use <code>count</code> instead.; :issue:<code>2246</code></li>; </ul>; <h2>Version 8.1.2</h2>; <p>Released 2022-03-31</p>; <ul>; <li>Fix error message for readable path check that was mixed up with the; executable check. :pr:<code>2236</code></li>; <li>Restore parameter order for <code>Path</code>, placing the <code>executable</code>; parameter at the end. It is recommended to use keyword arguments; instead of positional arguments. :issue:<code>2235</code></li>; </ul>; <h2>Version 8.1.1</h2>; <p>Released 2022-03-30</p>; <ul>; <li>Fix an issue with decorator typing that caused type checking to; report that a command was not callable. :issue:<code>2227</code></li>; </ul>; <h2>Version 8.1.0</h2>; <p>Released 2022-03-28</p>; <ul>; <li>; <p>Drop support for Python 3.6. :pr:<code>2129</code></p>; </li>; <li>; <p>Remove previously deprecated code. :pr:<code>2130</code></p>; <ul>; <li><code>Group.resultcallback</code> is renamed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11808:2776,error,error,2776,https://hail.is,https://github.com/hail-is/hail/pull/11808,1,['error'],['error']
Availability,", timed); 77 (result, timings) = (result_tuple._1(), result_tuple._2()); 78 value = ir.typ._from_encoding(result). File ~/miniconda3/lib/python3.10/site-packages/py4j/java_gateway.py:1321, in JavaMember.__call__(self, *args); 1315 command = proto.CALL_COMMAND_NAME +\; 1316 self.command_header +\; 1317 args_command +\; 1318 proto.END_COMMAND_PART; 1320 answer = self.gateway_client.send_command(command); -> 1321 return_value = get_return_value(; 1322 answer, self.gateway_client, self.target_id, self.name); 1324 for temp_arg in temp_args:; 1325 temp_arg._detach(). File ~/miniconda3/lib/python3.10/site-packages/hail/backend/py4j_backend.py:35, in handle_java_exception.<locals>.deco(*args, **kwargs); 33 tpl = Env.jutils().handleForPython(e.java_exception); 34 deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); ---> 35 raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; 36 except pyspark.sql.utils.CapturedException as e:; 37 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 38 'Hail version: %s\n'; 39 'Error summary: %s' % (e.desc, e.stackTrace, hail.__version__, e.desc)) from None. FatalError: ClassCastException: class is.hail.types.physical.stypes.concrete.SIndexablePointer cannot be cast to class is.hail.types.physical.stypes.concrete.SJavaArrayString (is.hail.types.physical.stypes.concrete.SIndexablePointer and is.hail.types.physical.stypes.concrete.SJavaArrayString are in unnamed module of loader 'app'). Java stack trace:; java.lang.ClassCastException: class is.hail.types.physical.stypes.concrete.SIndexablePointer cannot be cast to class is.hail.types.physical.stypes.concrete.SJavaArrayString (is.hail.types.physical.stypes.concrete.SIndexablePointer and is.hail.types.physical.stypes.concrete.SJavaArrayString are in unnamed module of loader 'app'); 	at is.hail.expr.ir.functions.RegistryFunctions.unwrapReturn(Functions.scala:364); 	at is.hail.expr.ir.Emit.$anonfun$emitI$85(Emit.scala:1173); 	at is.hail.expr.ir.IEmitCodeGen.map(Emit.scala:35",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13633:3720,Error,Error,3720,https://hail.is,https://github.com/hail-is/hail/issues/13633,1,['Error'],['Error']
Availability,", tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel...; use 'python setup.py download_pandoc' to download pandoc.; usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]; or: setup.py --help [cmd1 cmd2 ...]; or: setup.py --help-commands; or: setup.py cmd --help; ; error: invalid command 'bdist_wheel'; ----------------------------------------; ERROR: Failed building wheel for pypandoc; ERROR: Failed to build one or more wheels; Traceback (most recent call last):; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/installer.py"", line 128, in fetch_build_egg; subprocess.check_call(cmd); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/subprocess.py"", line 363, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/Users/spascal/.pyenv/versions/3.7.9/bin/python3.7', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/tmpspi2awj3', '--quiet', 'pypandoc']' returned non-zero exit status 1.; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py"", line 224, in <module>; 'Programming Language :: Python :: Implementati",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9742:2229,error,error,2229,https://hail.is,https://github.com/hail-is/hail/issues/9742,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,", two new hypothesis tests, three; new sample statistics, a class for greater control over calculations; involving covariance matrices, and many other enhancements.</li>; </ul>; <h1>New features</h1>; <h1><code>scipy.datasets</code> introduction</h1>; <ul>; <li>A new dedicated <code>datasets</code> submodule has been added. The submodules; is meant for datasets that are relevant to other SciPy submodules ands; content (tutorials, examples, tests), as well as contain a curated; set of datasets that are of wider interest. As of this release, all; the datasets from <code>scipy.misc</code> have been added to <code>scipy.datasets</code>; (and deprecated in <code>scipy.misc</code>).</li>; <li>The submodule is based on <a href=""https://www.fatiando.org/pooch/latest/"">Pooch</a>; (a new optional dependency for SciPy), a Python package to simplify fetching; data files. This move will, in a subsequent release, facilitate SciPy; to trim down the sdist/wheel sizes, by decoupling the data files and; moving them out of the SciPy repository, hosting them externally and</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/scipy/scipy/commit/dde50595862a4f9cede24b5d1c86935c30f1f88a""><code>dde5059</code></a> REL: 1.10.0 final [wheel build]</li>; <li><a href=""https://github.com/scipy/scipy/commit/7856f281b016c585b82d03723c4494bcdbdcd4a5""><code>7856f28</code></a> Merge pull request <a href=""https://redirect.github.com/scipy/scipy/issues/17696"">#17696</a> from tylerjereddy/treddy_110_final_prep</li>; <li><a href=""https://github.com/scipy/scipy/commit/205b6243c6d075d05695e7ac6d007e0f03bfbf42""><code>205b624</code></a> DOC: add missing author</li>; <li><a href=""https://github.com/scipy/scipy/commit/1ab9f1b10145f0a974d5531700e72d1fb4229b76""><code>1ab9f1b</code></a> DOC: update 1.10.0 relnotes</li>; <li><a href=""https://github.com/scipy/scipy/commit/ac2f45fbe1e39a8f52c1ea2e687640",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13227:2688,down,down,2688,https://hail.is,https://github.com/hail-is/hail/pull/13227,1,['down'],['down']
Availability,", we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""BlockingBufferSpec"",""blockSize"":65536,""child"":; {""name"":""ZstdBlockBufferSpec"",""blockSize"":65536,""child"":; {""name"":""StreamBlockBufferSpec""}}}}; ```; Error for run 1.; ```; Caused by: com.github.luben.zstd.ZstdException: Corrupted block detected; 	at com.github.luben.zstd.ZstdDecompressCtx.decompressByteArray(ZstdDecompressCtx.java:157) ~[zstd-jni-1.5.2-1.jar:1.5.2-1]; 	at is.hail.io.ZstdInputBlockBuffer.readBlock(InputBuffers.scala:65",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:1460,failure,failure,1460,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623,1,['failure'],['failure']
Availability,",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""42.0.2""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr);  [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr);  [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14296:11784,avail,available,11784,https://hail.is,https://github.com/hail-is/hail/pull/14296,1,['avail'],['available']
Availability,",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.30.0"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JINJA2-6150717"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PROMPTTOOLKIT-6141120"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,624,531,556,604,589,726,434,589,449,399,696,589,479,519,509,711,701,586,586,384,494,539,589],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr);  [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr);  [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:14354,avail,available,14354,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['avail'],['available']
Availability,",; 489 url=url,; 490 body=request.body,; 491 headers=request.headers,; 492 redirect=False,; 493 assert_same_host=False,; 494 preload_content=False,; 495 decode_content=False,; 496 retries=self.max_retries,; 497 timeout=timeout,; 498 chunked=chunked,; 499 ); 501 except (ProtocolError, OSError) as err:. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:787, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 785 e = ProtocolError(""Connection aborted."", e); --> 787 retries = retries.increment(; 788 method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]; 789 ); 790 retries.sleep(). File /opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py:550, in Retry.increment(self, method, url, response, error, _pool, _stacktrace); 549 if read is False or not self._is_method_retryable(method):; --> 550 raise six.reraise(type(error), error, _stacktrace); 551 elif read is not None:. File /opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py:769, in reraise(tp, value, tb); 768 if value.__traceback__ is not tb:; --> 769 raise value.with_traceback(tb); 770 raise value. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:703, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 702 # Make the request on the httplib connection object.; --> 703 httplib_response = self._make_request(; 704 conn,; 705 method,; 706 url,; 707 timeout=timeout_obj,; 708 body=body,; 709 headers=headers,; 710 chunked=chunked,; 711 ); 713 # If we're going to release the connection in ``finally:``, then; 714 # the response doesn't need to know about the connection. Otherwise; 715 # it will also try to release it and we'll have a double-release; 716 # mess. File /opt/conda/lib/python3.10/site-packages/urllib3/connecti",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:7410,error,error,7410,https://hail.is,https://github.com/hail-is/hail/issues/13960,2,['error'],['error']
Availability,",A]]| 1:11155_C_A|; +--------+-------+--------------------+--------------------+--------------------+; only showing top 10 rows. Struct {; v: Variant,; `va.varid`: String; }; [u'va.varid']; +--------+-------+--------------------+--------------------+--------------------+; |v.contig|v.start| v.ref| v.altAlleles| va.varid|; +--------+-------+--------------------+--------------------+--------------------+; | 01| 10013| A| [[A,C]]| 1:10013_A_C|; | 01| 10179| G| [[G,T]]| 1:10179_G_T|; | 01| 10259| C| [[C,A]]| 1:10259_C_A|; | 01| 10292| C| [[C,T]]| 1:10292_C_T|; | 01| 10402| G| [[G,A]]| 1:10402_G_A|; | 01| 10527| T| [[T,A]]| 1:10527_T_A|; | 01| 10611| G| [[G,A]]| 1:10611_G_A|; | 01| 10754| G| [[G,C]]| 1:10754_G_C|; | 01| 11099| T| [[T,G]]| 1:11099_T_G|; | 01| 11115| C| [[C,A]]| 1:11155_C_A|; +--------+-------+--------------------+--------------------+--------------------+; only showing top 10 rows. Struct {; v: Variant,; `va.varid`: String,; C1: Double,; C2: Double; }; [u'va.varid']; [Stage 6:====================================================>(1640 + 1) / 1641]Traceback (most recent call last):; File ""/tmp/ec5f6e42-0ea7-404d-8311-f97f7ec26ad6/kt_troubleshooting_issue_042617.py"", line 31, in <module>; kt2.to_dataframe().show(10); File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py"", line 287, in show; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o448.showString.; : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 8.0 failed 20 times, most recent failure: Lost task 0.19 in stage 8.0 (TID 3406, cluster-mh-sw-xn3h.c.practice.internal): java.lang.ClassCastException: java.lang.String cannot be cast to is.hail.variant.Variant; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1725:2888,error,error,2888,https://hail.is,https://github.com/hail-is/hail/issues/1725,3,"['error', 'failure']","['error', 'failure']"
Availability,"- **Requires the python modules ** `nbsphinx`, `matplotlib`, `pandas`, `numpy`, and `seaborn`.; - Use property `-Dtutorial.home=/path/to/tutorial/files` with `gradle` to avoid downloading tutorial files with `wget`.; - Added new tgz file with tutorial files (reduced number of samples to 248 from 2535) https://storage.googleapis.com/hail-tutorial/Hail_Tutorial_Data-v2.tgz; - Edited tutorial to reflect smaller input file.; - Added iPython notebook to repository (this should be edited from now on); - Added tutorial to Sphinx docs.; - Changed tutorial location on website.; - Removed old tutorial infrastructure",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1374:176,down,downloading,176,https://hail.is,https://github.com/hail-is/hail/pull/1374,1,['down'],['downloading']
Availability,"- All subprocess calls are async. The UI is much more responsive now.; - Make refresh (rather than heal) non-reentrant. There was a race condition where we could update the Github state of a PR we were actively deploying. This seemed error prone.; - We need to lock the repos until the build is fully deployed. I now protect pr.heal.; - Set `batch_changed = True` whenever heal needs to be rerun becomes some of its inputs (build_state, source or target sha, collection of PRs) changed. Next up: deploy.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5921:234,error,error,234,https://hail.is,https://github.com/hail-is/hail/pull/5921,1,['error'],['error']
Availability,- BPE fix plus ignoring exceeded allocation scheduler errors.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9467:54,error,errors,54,https://hail.is,https://github.com/hail-is/hail/pull/9467,1,['error'],['errors']
Availability,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9928:462,failure,failure,462,https://hail.is,https://github.com/hail-is/hail/pull/9928,2,"['error', 'failure']","['error', 'failure']"
Availability,"- Botocore (AWS) produces its own ConnectionClosedError (:sad:).; - TIMEDOUT is yet another transient socket issue; - I have seen EAI_NONAME as a transient error, even though I would hope to receive EAI_AGAIN.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10924:156,error,error,156,https://hail.is,https://github.com/hail-is/hail/pull/10924,1,['error'],['error']
Availability,"- Expose init_local.; - Fix formatting of some error messages (stray }).; - Fix index paths, they don't have a ""parts"" component, have "".idx"" suffix. This showed up as an issue interopreating between Spark and local modes. FYI @tpoterba rather than just testing them independently, it might be worthwhile to have write/read interop tests between the various backends. Spark to local is partially tested by the pre-existing (matrix)tables tests, but not the other way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9596:47,error,error,47,https://hail.is,https://github.com/hail-is/hail/pull/9596,1,['error'],['error']
Availability,- I don't know why I was recomputing the whole output index instead of just moving forward one. The loops will always just iterate down the new data buffer. Also means I can use the normal array builder abstraction instead.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6029:131,down,down,131,https://hail.is,https://github.com/hail-is/hail/pull/6029,1,['down'],['down']
Availability,"- In the `combOp`, the `TakeByAggregator` was calling the `seqOp` which recomputes the sort-key. Since the evaluation context was not set correctly for the keys, the expression that evaluates the sort-key obviously produced the wrong value for the given key. - `TakeByAggregator.result` used `PriorityQueue.toArray`, which is not guaranteed to produce the elements in sorted order, according to [the PriorityQueue docs](http://www.scala-lang.org/api/current/scala/collection/mutable/PriorityQueue.html). Instead, we must `clone` the `PriorityQueue` and then `dequeueAll` the elements. I'm not certain the `clone` is necessary. @cseed, does the Aggregator interface permit multiple calls to `result`?. > Only the dequeue and dequeueAll methods will return elements in priority order (while removing elements from the heap). Standard collection methods including drop, iterator, and toString will remove or traverse the heap in whichever order seems most convenient. I also added some fairly robust tests that compare `takeBy(f, 10)` to `collect().sortBy(f)`. In particular: ; - the `takeBy` should be a prefix of `sortBy` when lensing by `f`,; - for every sort-key except last one, the elements should be the same as in `sortBy`, and; - for the last sort-key, the elements should be a subset of those in `sortBy`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1761:990,robust,robust,990,https://hail.is,https://github.com/hail-is/hail/pull/1761,1,['robust'],['robust']
Availability,"- Nested arrays appear to be supported in the current code, and I don't think this is intended.; - Why do exportFormat and exportInfo differ?; - Number is accessed from the field attrs without being checked. There could be something silly in there.; - Bad error messages (don't say which field was the problem)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1820:256,error,error,256,https://hail.is,https://github.com/hail-is/hail/issues/1820,1,['error'],['error']
Availability,- Only batch for now -- will add for pipeline and ci later; - This should fail until the kubernetes secret is added; - Requires a password `CLOUD_SQL_PASSWORD` to run the tests locally; (not sure what the best way to distribute this is); - Requires downloading the `cloud_sql_proxy` binary to run the tests locally,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5615:249,down,downloading,249,https://hail.is,https://github.com/hail-is/hail/pull/5615,1,['down'],['downloading']
Availability,"- Removed SLF4J, everything goes directly through log4j now.; - Removed the explicitly System.err.write calls inside info / warn.; - Separated console logging and log file logging; - Stripped the huge stack traces out of python errors; they are logged; to the screen / cell through log4j.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2063:228,error,errors,228,https://hail.is,https://github.com/hail-is/hail/pull/2063,2,['error'],['errors']
Availability,"- Using `-x` prints every line of the script to an error log entry. The main thing we're concerned about here is if it can fetch from notebook, so capture that output in `image-fetch-output.log` and cat that out to `stderr` only if it failed so it shows up as errors in the logs. - Removed old templating from before the `jinja2` times. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9930:51,error,error,51,https://hail.is,https://github.com/hail-is/hail/pull/9930,2,['error'],"['error', 'errors']"
Availability,"- Using the full domain name instead of the shorthand `<service>.<namespace>` isn't strictly necessary but just made me nervous and I opted for the full unambiguous domain for in-cluster services (what if we had a namespace named `com`?? I feel like that would break some things); - I got the configuration wrong on how to tell envoy *not* to worry about certs of internal namespaces (I'd recommend using the `split` view for the diff because otherwise it's pretty hard to read); - For internal namespaces, using the `prefix` parameter for matching a route allowed `/foo/batch` to match a route like `/foo/batch-driver` which is obviously not great. the `path_separated_prefix` parameter actually does what we want; - Fixed the batch tests not to look at the HTTP 1.1 reason phrase and instead look at the response body to determine the error",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12392:837,error,error,837,https://hail.is,https://github.com/hail-is/hail/pull/12392,1,['error'],['error']
Availability,"- Values of types other than `Array` and `Boolean` get output in VCF format (e.g. `.` instead of `NA` for missing values); - `NaN` values are converted to missing (`.`) when exporting VCF since VCF doesn't handle `NaN`; - Changes to handling of filters:; - `.` <=> `NA:Set[String]`; - `PASS` <=> `{}:Set[String]`; - `other` <=> `{""other""}:Set[String]""`; - Removed `va.pass` entirely (redundant with `va.filters` and needs constant synchronization)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1517:384,redundant,redundant,384,https://hail.is,https://github.com/hail-is/hail/pull/1517,1,['redundant'],['redundant']
Availability,"- [ ] (@tpoterba) caf1e1e673 add fails_service_backend; - [ ] (@tpoterba, @cseed) a979dfba58 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) dcf026b01c [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) 807f38c20e [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) 12df8eb456 [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) 03357ee83d [query-service] make user cache thread-safe; - [ ] (@tpoterba) 6c6734bc71 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) a3d2572ce7 [shuffler] log ShuffleCodecSpec anytime it is created; - [ ] (@daniel-goldstein) 8949dfec3c [scala-lsm] bugfix: least key may equal greatest key; - [ ] (@daniel-goldstein) 6067bd8e51 [services] discovered new transient error; - [ ] (@daniel-goldstein) c8356d30bb [shuffler] more assertions in ShuffleClient; - [ ] (@daniel-goldstein) 9991da90f0 [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [ ] (@daniel-goldstein) bc0140ab6f [query-service] move hail.jar earlier in Dockerfile; - [ ] (@daniel-goldstein) f96c28174d [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 6ae26339fe [query-service] simplify socket handling; - [ ] (@jigold) f3db30e23f [batch] teach JVMJob where to find the hail configuration files; - [ ] (@daniel-goldstein) b5c6d85554 [query-service] switch to services team approved logging; - [ ] (@tpoterba) 35a306c066 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 051c89b8e7 [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) ad9ea73d7a [query-service] run tests against query service",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10072:814,error,error,814,https://hail.is,https://github.com/hail-is/hail/pull/10072,1,['error'],['error']
Availability,"- [ ] Signature is wrong for load_references_from_dataset; * abstractMethod returns []. This doesn't do anything (`load_references_from_dataset` still needs to be implemented), and is also not what the concrete implementation of SparkBackend returns (which is a string).; * In general I think we should have type annotations on these methods, to document the expected inputs, outputs. - [ ] ServiceBackend needs to implement load_references_from_dataset. - [ ] ServiceBackend constructor is wrong. states it takes `deploy_config`, but backend.py passes a string (apiserver_url). Error generated is `str has no method base_url`. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7068:579,Error,Error,579,https://hail.is,https://github.com/hail-is/hail/issues/7068,1,['Error'],['Error']
Availability,"- [ ] annotate with mypy; - [ ] add pylint to build; - [x] add basic unit tests; - [x] docs in python; - [x] tutorial in python; - [ ] run tests on dataproc; - [x] delete commands, state, no args4j; - [ ] accumulators/error reporting",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1072:218,error,error,218,https://hail.is,https://github.com/hail-is/hail/issues/1072,1,['error'],['error']
Availability,"- [ ] input pods: exit if the PVC is not empty; - [ ] main pods: use initContainers to delete all content other than /io/inputs; - [ ] exit pods: use pod_name in path and add a _SUCCESS file on completion; - [ ] input pods: use any input directory containing a _SUCCESS file; - [x] if a failure occurs, check the database before mark_unscheduled. e.g. if `read_log` fails because the pod doesn't exist, check if the log is already uploaded. if it is, do nothing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6494:287,failure,failure,287,https://hail.is,https://github.com/hail-is/hail/issues/6494,1,['failure'],['failure']
Availability,"- [ ] use make dry-runs w/ git to ensure that CI executes exactly those tests whose dependencies have changed since the last commit. - [ ] banish `archiveZip`. create `whl` files without spark dependencies, install those on the leader node (do we need to specify the jar separately still?). - [ ] download plink, qctool, and R packages in hail/Makefile and make dependencies for `test`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5199:297,down,download,297,https://hail.is,https://github.com/hail-is/hail/issues/5199,1,['down'],['download']
Availability,"- [x] DANN, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4341060/; - [x] CADD, http://europepmc.org/abstract/med/11384848; - [x] reference genomes 95, GRCh37 & 38., https://useast.ensembl.org/index.html; - [x] low complexity regions 95, GRCh37 & 38, https://useast.ensembl.org/index.html; - [x] Gencode (names and gene metadata) v19 GRCh37, v38 GRCh38, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3431492/, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3431492/; - [x] gnomAD LOF by gene, https://gnomad.broadinstitute.org/; - [x] gnomAD sites exomes & genomes (includes VEP, AF, etc.), https://gnomad.broadinstitute.org/; - [ ] MAF for 1KG, should be in the VCFs which are available via FTP here: http://www.internationalgenome.org/data; - [ ] VEP (?? need more information about what is requested); - [ ] which allele is ancestral (?? Elizabeth has more info?); - [X] clinvar for GRCh37 & 38; - [ ] LCR (?? is gnomAD sufficient?); - [ ] GERP or other sequence conservation score; - [ ] major exome platform capture areas (?? need more information); - [ ] All the missense annotation scores (from dbNSFP, ftp://dbnsfp.softgenetics.com/dbNSFP4.0a.zip)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6715:674,avail,available,674,https://hail.is,https://github.com/hail-is/hail/issues/6715,1,['avail'],['available']
Availability,"- [x] There should be a test in the tests that verify that the account is operational, so if it disabled, we get an informative error message. (see issue #4533). - [x] There should be documentation/a playbook about how to get Github unstuck when this happens. (see [here](; https://github.com/hail-is/hail/issues/4517#issuecomment-429135514)). - [ ] We should mock Github so we don't rely on it during the tests, which makes me sad because yay integration tests, and what do we do when the Github API changes/breaks/doesn't behave the way we expect?. Assigning to @danking since he's been through the first two, but maybe someone else can handle the third.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4517:128,error,error,128,https://hail.is,https://github.com/hail-is/hail/issues/4517,1,['error'],['error']
Availability,"- add PIndexableValue. This represents canonical array, set and dict values.; - use in ArrayRef; - newP{Local, FIeld} now has a `PV <: PValue` type parameter to eliminate some casting. Where I'm going:. There will be a abstract PValue with the interface for each virtual type (container/indexable, base struct, etc.) Each concrete PType will have a corresponding PValue implementation (in this case, PCanonicalArray is implemented by PCanonicalIndexableValue.) I think this will allow us to get rid of PArrayBackedContainer. Only primitive PValues will have a code method (since other types might be compound). The code generator should then dispatch through downcasts of PValues get access to the relevant methods.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8213:659,down,downcasts,659,https://hail.is,https://github.com/hail-is/hail/pull/8213,1,['down'],['downcasts']
Availability,- add priority class infrastructure throughout; - all pod specs have resource requests and limits; - make es tolerate preemptibles; - make monitoring router tolerate preemptibles. Deployed.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7425:109,toler,tolerate,109,https://hail.is,https://github.com/hail-is/hail/pull/7425,2,['toler'],['tolerate']
Availability,"- added `keep_higher_maf` option (`true` by default) to `ld_prune` to prefer to keep higher MAF variants in the global (MIS) stage.; - improved the `ld_prune` flow to reduce duplicated work; - set BlockMatrix.entries to set `i` and `j` as key fields and improved its doc; - corrected references to standard deviation that are actually n times standard deviation, i.e. centered length; - switched `computeCoverByUpperTriangularBlocks` to use the newer`rowIntervalsBlocks` rather than `rectanglesBlocks` directly. I've tested `keep_higher_maf` in notebooks, will add a test of MAF soon and then assign. @danking rather than:; ```; def tie_breaker(l, r):; return hl.cond(l.twice_maf > r.twice_maf,; -1,; hl.cond(l.twice_maf < r.twice_maf,; 1,; 0)); ```; I'd prefer:; ```; def tie_breaker(l, r):; return hl.signum(r.twice_maf - l.twice_maf); ```; I'm having trouble figuring out why the latter throws the error below. Your `tie_breaker` code looks like it should work with Int32Expressions. Any idea what's going on?; ```; FatalError: ClassCastException: java.lang.Long cannot be cast to org.apache.spark.sql.Row. Java stack trace:; java.lang.ClassCastException: java.lang.Long cannot be cast to org.apache.spark.sql.Row; 	at is.hail.codegen.generated.C46.apply(Unknown Source); 	at is.hail.codegen.generated.C46.apply(Unknown Source); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:84); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:82); 	at is.hail.expr.Parser$$anonfun$is$hail$expr$Parser$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail.expr.Parser$$anonfun$parseTypedExpr$1.apply(Parser.scala:102); 	at scala.Function0$class.apply$mcJ$sp(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcJ$sp(AbstractFunction0.scala:12); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:81); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:79); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3704:901,error,error,901,https://hail.is,https://github.com/hail-is/hail/pull/3704,1,['error'],['error']
Availability,- automatically download catch.hpp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5329:16,down,download,16,https://hail.is,https://github.com/hail-is/hail/pull/5329,1,['down'],['download']
Availability,"- automatically download catch.hpp from GitHub if it's missing; - remove builtin rules and suffix based rules to improve performance and ease debugging; - change Makefile variable definitions to match our standard `FOO OP VAL` (note: two spaces); - rely on `clang -MM` (see: [Clang command line reference](https://clang.llvm.org/docs/ClangCommandLineReference.html) and below explanation) to generate precise dependencies for object files (including source and header files); - explicitly specify which files depend on `NUMBER_OF_GENOTYPES_PER_ROW` to be set (namely the dependency file and the object file associated with `ibs.cpp`); - break `TEST_OBJECTS` into two steps so that we can have `_test.cpp` files which do not have corresponding `.cpp` files (consider, for example, a header-only file, which ApproximateQuantiles will be); - eliminate `$(BUILD)/headers` in favor of precise dependency tracking described above; - remove the target `$(BUILD)`, directories don't work the way you think in Make, it's better to have individual rules create the containing directories when necessary; - remove `wget` nonsense, standardize on `curl -sSL` (which produces useful error messages). ---. # clang -MM. This argument to clang allows us to generate ""depfile"" or ""dependency files"" which are valid `Makefile`s describing how object files depend on `c`, `cpp`, `h`, and `hpp` files. `clang -MM foo.cpp` writes to stdout a Makefile that indicates how `foo.o` depends on preprocessor includes of other *user* files. For example,. ```; # cat foo.cpp; #include<stdio.h>; #include ""bar.h""; # clang -MM foo.cpp; foo.o: foo.cpp bar.h; ```. The `-MT target` allows us to specify the target's name:; ```; # clang -MM foo.cpp -MT fiddle; fiddle: foo.cpp bar.h; ```. The `-MQ` argument asks `clang` to quote the variable before make sees it, so (nb, I first quote it for the shell so it doesn't get seen as an env var):; ```; # clang -MM foo.cpp -MQ '$fiddle'; $$fiddle: foo.cpp bar.h; ```. The `-MG` argument tel",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5331:16,down,download,16,https://hail.is,https://github.com/hail-is/hail/pull/5331,2,"['down', 'error']","['download', 'error']"
Availability,- better error message for invalid export type; - don't support nested collections (bugfix),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1821:9,error,error,9,https://hail.is,https://github.com/hail-is/hail/pull/1821,1,['error'],['error']
Availability,"- conda environments are always up to date and enabled (important for developers); - flake8 and pylint are test (and, ergo, CI) dependencies; - use pytest with `--first-failure` so that re-runs run the failing tests first (important for developers)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4924:169,failure,failure,169,https://hail.is,https://github.com/hail-is/hail/pull/4924,1,['failure'],['failure']
Availability,- fix double-counting error in openNoCompression method ; - add tests to read/write more bytes than can be held in the ByteBuffer; - abstract out seek method into FS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11861:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/11861,1,['error'],['error']
Availability,- fixed serialization error with `oneHotGenotype` and `oneHotAlleles`; - Call type is a `java.lang.Integer`; - Missing value is `null`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1532:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/1532,1,['error'],['error']
Availability,"- front_end returns 200 OK if a bunch is already inserted for an open batch; - add a test that inserts failures on every third http request made by a batch builder; - add `MultipleExceptions` which can be raised and have many causes; - set minimum log level of aioclient to WARNING, so users see `log.warn` messages; - increase bunch byte size to 8MiB (was 8MB), increase bunch size to 8 * 1024 (was 1000, which, for typical Konrad jobs (1kB) prevents fully filling the HTTP request); - make the previous two parameters configurable (primarily for testing purposes); - souped up AsyncThrottledGather to bail out after a configurable number of exceptions. For the restartable client we:; 1. create the batch, if that succeeds we never try to create again; 2. create the json-encoded job_spec bunches, this only fails on user error; 3. submit 50-way parallel bunch, with a maximum of (by default) 10 individual request failures; 4. if any request fails, raise an exception, which is caught by outer `submit`, which retries a configurable number of times, logging a configurable number of errors",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7875:103,failure,failures,103,https://hail.is,https://github.com/hail-is/hail/pull/7875,4,"['error', 'failure']","['error', 'errors', 'failures']"
Availability,"- gateway does all the reverse proxy; - site does the polling and serves the website up with nginx; - stop using crontab, just poll in the background; - set up liveness and readiness checks for 0 downtime changes; - ripped out letsencrypt stuff, which I will PR separately; - made certs into a secret. And something that got glommed on:. - put projects into a single file (projects.txt), still a lot to do here but I guess it is an improvement. FYI this is deployed now",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4602:196,downtime,downtime,196,https://hail.is,https://github.com/hail-is/hail/pull/4602,1,['downtime'],['downtime']
Availability,"- gateway does all the reverse proxy; - site does the polling and serves the website up with nginx; - stop using crontab, just poll in the background; - set up liveness and readiness checks for 0 downtime changes; - ripped out letsencrypt stuff, which I will PR separately; - made certs into a secret. And something that got glommed on:. - put projects into a single file (projects.txt), still a lot to do here but I guess it is an improvement. FYI this is deployed now. fixes #4464; fixes #4463",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4601:196,downtime,downtime,196,https://hail.is,https://github.com/hail-is/hail/pull/4601,1,['downtime'],['downtime']
Availability,- generate appropriate error message; - don't test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8637:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/pull/8637,1,['error'],['error']
Availability,- made sure the batch client is closed after a pipeline finishes; - fixed cpu and memory to take ints and floats; - Split AsyncWorkerPool into AsyncWorkerPool and AsyncThrottledGather; - Raise errors in AsyncThrottledGather (errors ignored in AsyncWorkerPool),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7333:193,error,errors,193,https://hail.is,https://github.com/hail-is/hail/pull/7333,2,['error'],['errors']
Availability,"- move environment.yml files out of the packaged directory so they don't get shipped to end users. - add `make test-pip-deploy` which pip deploys to the next available `devN` version (you have to wait a bit before you can `pip install` it, so I didn't include that in the test, but you can do that manually, or a motivated person can write a polling script). - add `build/dev-conda` which ensures that if the dev-environment file changes since you last ran `make build/dev-conda`, your conda environment is updated. - pedantically use the correct conda environment _everywhere_. - use python to determine cpu count instead of fixing it at 2. - add `jq` as an `env-setup.sh` dependency. - add `make build/credentials.json` which `scp`s a new JSON file containing credentials to the local machine, moreover there are two rules for automatically extracting the credentials for PYPI from this JSON file. - use `ENV_VAR`, a make macro, to ensure we rebuild the appropriate targets (but no more) when a relevant environment variable is changed since last build. - added several missing breeze versions, now we can easily test against new spark versions, just run `SPARK_VERSION=4.0.0 make test`. - fold doctests in with regular tests under `test-python` which uses pytest, no more unnecessary copying as well. - fix build-info. - delete two unused python files in hail root. - correct LIBSIMDPP dependency in C makefile. # Not Doing Yet. - incorporate native lib into this Makefile. Instead, if anything changed in src/main/c since we last built, we rebuild. - fix the directory structure to be compliant with pytests recommended structure",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5194:158,avail,available,158,https://hail.is,https://github.com/hail-is/hail/pull/5194,1,['avail'],['available']
Availability,"- moved k8s accounts, roles and bindings to vdc/k8s-config.yaml (applied to current cluster); - created deploy service account with privileges on default (should lock down to minimal set); - added batch service account option, use to launch deploy job with deploy-svc; - give batch-svc default-deploy binding so it can launch the deploy pod with suitable privileges",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4596:167,down,down,167,https://hail.is,https://github.com/hail-is/hail/pull/4596,1,['down'],['down']
Availability,- provide a default session; - made cancel not wait for all jobs to be cancelled before returning; - some log statements; - fix error catching in retry function; - add retry to batch client create jobs; - add cancel if batch is not submitted successfully,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6557:128,error,error,128,https://hail.is,https://github.com/hail-is/hail/pull/6557,1,['error'],['error']
Availability,- remove some redundant project git ignores; - add a few more file types,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8192:14,redundant,redundant,14,https://hail.is,https://github.com/hail-is/hail/pull/8192,1,['redundant'],['redundant']
Availability,"- removed repeated imports in dataset; - fixed typos and clarified docs; - collapsed RegUtils to provide one ingest function each for hardCalls, dosages, and keyedRows. These optionally impute missing and produce sparse, dense, and dense vectors respectively. The first two also optionally take a mask. hardCalls no longer checks for constant vectors.; - killed the two RegUtils mutate matrix functions entirely; - simplified code in regression methods taking Vector[Double] input; - temp added constantHardCalls to RegUtils and in regressions to retrofit changes to preserve 0.1 behavior of missing for constant vectors. In 0.2 constant vectors will be treated the same as others, resulting in lack of convergence, Double.NaN, etc.; - temp added hardCallsAndAC to RegUtils and in linreg to retrofit changes to preserve 0.1 behavior of calculating AC pre-imputation for filtering. In 0.2, AC will be calculated post-imputation for hardCalls and dosages using sum(x); - combined empirical and HWE normalized arrays into one function; - removed various default parameters in tests. About 75 lines are due to retrofit, so for 0.2 it's about 200 added and 420 deleted.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1863:297,mask,mask,297,https://hail.is,https://github.com/hail-is/hail/pull/1863,1,['mask'],['mask']
Availability,"- retry every deadlock in two deadlock prone SQL operations; - add prometheus metrics for cores; - fix prometheus when you're not in the default namespace; - retry every docker 500 error, it's 500, not our fault, just retry, right?; - create a billing account for the dev deploying user; - rewrite a couple queries to harmonize table locking a bit; - add globals to delete tables script; - fix list_batches, which was broken by the query language changes; - include primary services developers' namespaces in prometheus monitoring. Fixes #7756",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7783:181,error,error,181,https://hail.is,https://github.com/hail-is/hail/pull/7783,2,"['error', 'fault']","['error', 'fault']"
Availability,- run cancels in parallel with scheduling; - handle errors asap rather than serially after all jobs have finished,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7852:52,error,errors,52,https://hail.is,https://github.com/hail-is/hail/pull/7852,1,['error'],['errors']
Availability,"- version `devel-6ee2919`; - source: git@github.com/hail-is/hail.git ; compiled with `gradle shadowJar`. Desired behavior:. When reading an old version of a VDS, hail should print a message such as:. ```; The vds ""/users/dking/projects/hail-data/profile225.vds"" cannot be read by this version of hail. It must be regenerated from the VCF source using this version of hail.; ```. Actual behavior:. ```; dking@wmb16-359 # python; >>> from hail import *; >>> hc = HailContext(); hc.reaUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; d9""/projecRunning on Apache Spark version 2.0.2; SparkUI available at http://10.10.99.215:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-6ee2919; WARNING: This is an unstable development build.; >>> hc.read(""/users/dking/projects/hail-data/profile225.vds""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-606>"", line 2, in read; File ""/Users/dking/projects/hail/python/hail/java.py"", line 121, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: MappingException: Did not find value which can be converted into java.lang.String. Java stack trace:; org.json4s.package$MappingException: No usable value for sample_schema; Did not find value which can be converted into java.lang.String; 	at org.json4s.reflect.package$.fail(package.scala:96); 	at org.json4s.Extraction$ClassInstanceBuilder.org$json4s$Extraction$ClassInstanceBuilder$$buildCtorArg(Extraction.scala:462); 	at org.json4s.Extraction$ClassInstanceBuilder$$anonfun$14.apply(Extraction.scala:482); 	at org.json4s.Extraction$ClassInstanceBuilder$$anonfun$14.apply(Extraction.scala:482); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(Traversab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2159:713,avail,available,713,https://hail.is,https://github.com/hail-is/hail/issues/2159,1,['avail'],['available']
Availability,"-- Configuring done; -- Generating done; -- Build files have been written to: /home/rmk/package_sources/hail/hail/src/main/c/libsimdpp-2.0-rc2; mkdir -p lib/linux-x86-64; g++ -fvisibility=hidden -rdynamic -shared -fPIC -ggdb -O3 -march=native -g -std=c++11 -Ilibsimdpp-2.0-rc2 -Wall -Werror ibs.cpp -o lib/linux-x86-64/libibs.so; In file included from ibs.cpp:1:0:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h: In function uint64_t vector_popcnt(uint64vector):; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h:42:1: error: inlining failed in call to always_inline long long int _mm_popcnt_u64(long long unsigned int): target specific option mismatch; _mm_popcnt_u64 (unsigned long long __X); ^; ibs.cpp:14:48: error: called from here; uint64_t count = _mm_popcnt_u64(extract<0>(x));; ^; In file included from ibs.cpp:1:0:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h:42:1: error: inlining failed in call to always_inline long long int _mm_popcnt_u64(long long unsigned int): target specific option mismatch; _mm_popcnt_u64 (unsigned long long __X); ^; ibs.cpp:16:41: error: called from here; count += _mm_popcnt_u64(extract<1>(x));; ^; make: *** [lib/linux-x86-64/libibs.so] Error 1; Makefile:52: recipe for target 'lib/linux-x86-64/libibs.so' failed; :nativeLib FAILED. Tim Poterba suggested defining `CXXFLAGS='-DHAIL_OVERRIDE_ARCH -DSIMDPP_ARCH_X86_SSE2'`, but to no avail. So, he suggested I open this issue. I'm running gcc version 4.9.2. Possibly relevant might be the processor I'm running,; $ lscpu; Architecture: x86_64; CPU op-mode(s): 32-bit, 64-bit; Byte Order: Little Endian; CPU(s): 2; On-line CPU(s) list: 0,1; Thread(s) per core: 1; Core(s) per socket: 2; Socket(s): 1; NUMA node(s): 1; Vendor ID: GenuineIntel; CPU family: 6; Model: 23; Model name: Intel(R) Core(TM)2 CPU P8600 @ 2.40GHz; Stepping: 10; CPU MHz: 800.000; CPU max MHz: 2401.0000; CPU min MHz: 800.0000; BogoMIPS: 4800.16; Virtualization: VT-x; L1d cache: 32K; L1i cache: 32K; L2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1520:1284,error,error,1284,https://hail.is,https://github.com/hail-is/hail/issues/1520,1,['error'],['error']
Availability,"---- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-40-d6d936b012db>"", line 3, in <module>; covariates=[1.0]); File ""<decorator-gen-1697>"", line 2, in linear_regression_rows; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py"", line 370, in linear_regression_rows; return ht_result.persist(); File ""<decorator-gen-1111>"", line 2, in persist; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:1833,Error,Error,1833,https://hail.is,https://github.com/hail-is/hail/issues/9939,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,"--------------------------------------------------------------------. ### Hail version:; devel-6bb4670. ### What you did:; A number of variant QC steps, then a `vds.write`; The error is probably caused by one of the previous steps. If it helps I can comment out earlier parts to narrow down what actually triggers the error. ### What went wrong (all error messages here, including the full java stack trace):; ```; [Stage 6:> (0 + 8) / 5000]; [Stage 6:> (0 + 4) / 5000]; [Stage 6:> (0 + 8) / 5000]Traceback (most recent call last):; File ""/home/hail/hail.zip/hail/utils/java.py"", line 185, in handle_py4j; File ""/home/hail/hail.zip/hail/table.py"", line 1058, in aggregate; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o30335.query.; : org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 6.0 failed 20 times, most recent failure: Lost task 7.19 in stage 6.0 (TID 179, robert1-w-0.c.ccdg-wgs.internal, executor 4): java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.annotations.RegionValueBuilder.endStruct(RegionValueBuilder.scala:109); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2645); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2615); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:1156,error,error,1156,https://hail.is,https://github.com/hail-is/hail/issues/3063,1,['error'],['error']
Availability,"----------------------------------------------------------; Gradle 6.8.3; ------------------------------------------------------------. Build time: 2021-02-22 16:13:28 UTC; Revision: 9e26b4a9ebb910eaa1b8da8ff8575e514bc61c78. Kotlin: 1.4.20; Groovy: 2.5.12; Ant: Apache Ant(TM) version 1.10.9 compiled on September 27 2020; JVM: 1.8.0_362 (Private Build 25.362-b09); OS: Linux 5.4.0-1042-gcp amd64. real	0m3.621s; user	0m4.448s; sys	0m0.623s; + retry make jars wheel HAIL_DEBUG_MODE=1; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.0"" which is different from old value """"; printf ""3.3.0"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=' >> src/main/resources/build-info.properties; echo 'revision=e1d86e1908f0911d45b03ef08a694d07e1c4627b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-03-09T23:23:56Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.0' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.110' >> src/main/resources/build-info.properties; HAIL_DEBUG_MODE is set to ""1"" which is different from old value """"; printf ""1"" > env/HAIL_DEBUG_MODE; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; javac -d build/classes/scala/debug -Xlint:all -Werror -XDenableSunApiLintControl -XDignore.symbol.file src/debug/scala/is/hail/annotations/Memory.java; ./gradlew shadowJar -Dscala.version=2.12.13 -Dspark.version=3.3.0 -Delasticsearch.major-version=7; Starting a Gradle Daemon (subsequent builds will be faster); > Task :compileJava NO-SOURCE; > Task :compileScala; [Error] /io/repo/hail/src/main/scala/is/hail/expr/ir/MatrixWriter.scala:122: value of is not a member of object java.nio.file.Path; [Error] /io/repo/hail/src/main/scala/is/hail/expr/ir/TableWriter.scala:57: value of is not",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12773#issuecomment-1463003450:1022,echo,echo,1022,https://hail.is,https://github.com/hail-is/hail/pull/12773#issuecomment-1463003450,1,['echo'],['echo']
Availability,"--------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-3-ca1bc15ebb3c> in <module>; ----> 1 hl.hadoop_ls(""gs://bw2/bla""). /Library/Python/3.7/site-packages/hail/utils/hadoop_utils.py in hadoop_ls(path); 212 :obj:`list` [:obj:`dict`]; 213 """"""; --> 214 return Env.fs().ls(path); 215; 216. /Library/Python/3.7/site-packages/hail/fs/hadoop_fs.py in ls(self, path); 40; 41 def ls(self, path: str) -> List[Dict]:; ---> 42 return json.loads(self._utils_package_object.ls(self._jfs, path)); 43; 44 def mkdir(self, path: str) -> None:. /Library/Python/3.7/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258; 1259 for temp_arg in temp_args:. /Library/Python/3.7/site-packages/hail/backend/spark_backend.py in deco(*args, **kwargs); 49 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 50 'Hail version: %s\n'; ---> 51 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None; 52 except pyspark.sql.utils.CapturedException as e:; 53 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NullPointerException: null. Java stack trace:; java.lang.NullPointerException: null; 	at scala.collection.mutable.ArrayOps$ofRef$.length$extension(ArrayOps.scala:192); 	at scala.collection.mutable.ArrayOps$ofRef.length(ArrayOps.scala:192); 	at scala.collection.SeqLike$class.size(SeqLike.scala:106); 	at scala.collection.mutable.ArrayOps$ofRef.size(ArrayOps.scala:186); 	at scala.collection.mutable.Builder$class.sizeHint(Builder.scala:69); 	at scala.collection.mutable.ArrayBuilder.sizeHint(ArrayBuilder.scala:22); 	at scala.collection.TraversableLike$class.builder$1(TraversableLike.scala:230); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:233); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.io.fs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9600:1138,Error,Error,1138,https://hail.is,https://github.com/hail-is/hail/issues/9600,1,['Error'],['Error']
Availability,"----------------------------; FatalError Traceback (most recent call last); <ipython-input-4-3a6cee08b392> in <module>; ----> 1 tsvs = hl.hadoop_ls(""gs://my-bucket/*.tsv*""). /Library/Python/3.7/site-packages/hail/utils/hadoop_utils.py in hadoop_ls(path); 212 :obj:`list` [:obj:`dict`]; 213 """"""; --> 214 return Env.fs().ls(path); 215; 216. /Library/Python/3.7/site-packages/hail/fs/hadoop_fs.py in ls(self, path); 40; 41 def ls(self, path: str) -> List[Dict]:; ---> 42 return json.loads(self._utils_package_object.ls(self._jfs, path)); 43; 44 def mkdir(self, path: str) -> None:. /Library/Python/3.7/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258; 1259 for temp_arg in temp_args:. /Library/Python/3.7/site-packages/hail/backend/spark_backend.py in deco(*args, **kwargs); 49 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 50 'Hail version: %s\n'; ---> 51 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None; 52 except pyspark.sql.utils.CapturedException as e:; 53 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz. Java stack trace:; java.io.IOException: java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.concurrentGlobInternal(GoogleHadoopFileSystemBase.java:1284); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1261); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1229); 	at is.hail.io.fs.HadoopFS.listStatus(HadoopFS.scala:104); 	at is.hail.utils.Py4jUtils$class.ls(Py4jUtils.scala:55); 	at is.hail.utils.package$.l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9607:1228,Error,Error,1228,https://hail.is,https://github.com/hail-is/hail/issues/9607,1,['Error'],['Error']
Availability,"---------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **444/1000** <br/> **Why?** Has a fix available, CVSS 4.6 | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **429/1000** <br/> **Why?** Has a fix available, CVSS 4.3 | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https:/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14109:2000,avail,available,2000,https://hail.is,https://github.com/hail-is/hail/pull/14109,1,['avail'],['available']
Availability,"--------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **551/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4MmVlNzU5Ny0wZmFhLTQ1NmUtOTA3Ny0zOTM4ODRjNz",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13370:1843,avail,available,1843,https://hail.is,https://github.com/hail-is/hail/pull/13370,1,['avail'],['available']
Availability,"--------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **551/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5Nzc0NDQwMi1iNzEyLTQ5NjMtYWQ0Zi01YjFhZWZmOT",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13365:1642,avail,available,1642,https://hail.is,https://github.com/hail-is/hail/pull/13365,1,['avail'],['available']
Availability,"--------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **551/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxOGJjNGZiYS05ZTMwLTRmNWItYTE4Yy0wOGNmNDVmZD",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13366:1851,avail,available,1851,https://hail.is,https://github.com/hail-is/hail/pull/13366,1,['avail'],['available']
Availability,"-------. Build time: 2021-02-22 16:13:28 UTC; Revision: 9e26b4a9ebb910eaa1b8da8ff8575e514bc61c78. Kotlin: 1.4.20; Groovy: 2.5.12; Ant: Apache Ant(TM) version 1.10.9 compiled on September 27 2020; JVM: 1.8.0_362 (Private Build 25.362-b09); OS: Linux 5.4.0-1042-gcp amd64. real	0m3.621s; user	0m4.448s; sys	0m0.623s; + retry make jars wheel HAIL_DEBUG_MODE=1; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.0"" which is different from old value """"; printf ""3.3.0"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=' >> src/main/resources/build-info.properties; echo 'revision=e1d86e1908f0911d45b03ef08a694d07e1c4627b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-03-09T23:23:56Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.0' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.110' >> src/main/resources/build-info.properties; HAIL_DEBUG_MODE is set to ""1"" which is different from old value """"; printf ""1"" > env/HAIL_DEBUG_MODE; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; javac -d build/classes/scala/debug -Xlint:all -Werror -XDenableSunApiLintControl -XDignore.symbol.file src/debug/scala/is/hail/annotations/Memory.java; ./gradlew shadowJar -Dscala.version=2.12.13 -Dspark.version=3.3.0 -Delasticsearch.major-version=7; Starting a Gradle Daemon (subsequent builds will be faster); > Task :compileJava NO-SOURCE; > Task :compileScala; [Error] /io/repo/hail/src/main/scala/is/hail/expr/ir/MatrixWriter.scala:122: value of is not a member of object java.nio.file.Path; [Error] /io/repo/hail/src/main/scala/is/hail/expr/ir/TableWriter.scala:57: value of is not a member of object java.nio.file.Path; [Error] /io/repo/hail/src/main/scala/is/hail/expr/ir/TableWriter.scala:674: value of is ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12773#issuecomment-1463003450:1171,echo,echo,1171,https://hail.is,https://github.com/hail-is/hail/pull/12773#issuecomment-1463003450,1,['echo'],['echo']
Availability,"----|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **624/1000** <br/> **Why?** Has a fix available, CVSS 8.2 | Arbitrary Code Execution <br/>[SNYK-PYTHON-IPYTHON-2348630](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-2348630) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **604/1000** <br/> **Why?** Has a fix available, CVSS 7.8 | Improper Privilege Management <br/>[SNYK-PYTHON-JUPYTERCORE-3063766](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERCORE-3063766) | `jupyter-core:` <br> `4.6.3 -> 4.11.2` <br> | No | No Known Exploit ; ![high severity](https://",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:1818,avail,available,1818,https://hail.is,https://github.com/hail-is/hail/pull/13717,2,['avail'],['available']
Availability,"----|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **624/1000** <br/> **Why?** Has a fix available, CVSS 8.2 | Arbitrary Code Execution <br/>[SNYK-PYTHON-IPYTHON-2348630](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-2348630) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `2.11.3 -> 3.1.3` <br> | No | No Known Exploit ; ![high severity](htt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:2136,avail,available,2136,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['avail'],['available']
Availability,"---. ### Hail version:; 0.2; ### What you did:; users = hl.read_table('data/users.ht'); hl.export_elasticsearch(users, 'XX.XXX.XXX.XXX', 32565, 'users', 'movies', 200,config=None, verbose=True ). ### What went wrong (all error messages here, including the full java stack trace):; Gotten this error even though the elasticsearch IP and port number 32565 is correct. The IP mentioned in the error 192.168.185.157:9200 was not found anywhere in our EMR or elasticsearch cluster. ; >>> hl.export_elasticsearch(users, 'XX.XXX.XXX.XXX', 32565, 'users', 'movies', 200,config=None, verbose=True ); Config Map(es.nodes -> XX.XXX.XXX.XXX, es.port -> 32565, es.batch.size.entries -> 200, es.index.auto.create -> true); [Stage 0:> (0 + 32) / 65]Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""</usr/local/lib/python3.6/site-packages/decorator.py:decorator-gen-1122>"", line 2, in export_elasticsearch; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 561, in wrapper; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/methods/impex.py"", line 2106, in export_elasticsearch; File ""/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 227, in deco; hail.utils.java.FatalError: EsHadoopNoNodesLeftException: Connection error (check network and/or proxy settings)- all nodes failed; tried [[192.168.185.157:9200, 192.168.81.209:9200]] . Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 73, ip-172-31-10-234.ap-southeast-1.compute.internal, executor 3): org.elasticsearch.hadoop.rest.EsHadoopNoNodesLeftException: Connection error (check network and/or proxy settings)- all nodes failed; tried [[192.168.185.157:9200, 192.168.81.209:9200]]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5643:1686,error,error,1686,https://hail.is,https://github.com/hail-is/hail/issues/5643,4,"['error', 'failure']","['error', 'failure']"
Availability,"---; Gradle 6.8.3; ------------------------------------------------------------. Build time: 2021-02-22 16:13:28 UTC; Revision: 9e26b4a9ebb910eaa1b8da8ff8575e514bc61c78. Kotlin: 1.4.20; Groovy: 2.5.12; Ant: Apache Ant(TM) version 1.10.9 compiled on September 27 2020; JVM: 1.8.0_362 (Private Build 25.362-b09); OS: Linux 5.4.0-1042-gcp amd64. real	0m3.621s; user	0m4.448s; sys	0m0.623s; + retry make jars wheel HAIL_DEBUG_MODE=1; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.0"" which is different from old value """"; printf ""3.3.0"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=' >> src/main/resources/build-info.properties; echo 'revision=e1d86e1908f0911d45b03ef08a694d07e1c4627b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-03-09T23:23:56Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.0' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.110' >> src/main/resources/build-info.properties; HAIL_DEBUG_MODE is set to ""1"" which is different from old value """"; printf ""1"" > env/HAIL_DEBUG_MODE; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; javac -d build/classes/scala/debug -Xlint:all -Werror -XDenableSunApiLintControl -XDignore.symbol.file src/debug/scala/is/hail/annotations/Memory.java; ./gradlew shadowJar -Dscala.version=2.12.13 -Dspark.version=3.3.0 -Delasticsearch.major-version=7; Starting a Gradle Daemon (subsequent builds will be faster); > Task :compileJava NO-SOURCE; > Task :compileScala; [Error] /io/repo/hail/src/main/scala/is/hail/expr/ir/MatrixWriter.scala:122: value of is not a member of object java.nio.file.Path; [Error] /io/repo/hail/src/main/scala/is/hail/expr/ir/TableWriter.scala:57: value of is not a member of object java.nio.file.Path; [Error] /io/repo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12773#issuecomment-1463003450:1100,echo,echo,1100,https://hail.is,https://github.com/hail-is/hail/pull/12773#issuecomment-1463003450,1,['echo'],['echo']
Availability,"---|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Use of a Broken or Risky Cryptographic Algorithm <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6149518](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6149518) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **451/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.3 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyN2MzNWY4NC0yNDIyLTRmNzUtYWMxYy1mODQxOGJmN",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14234:1940,avail,available,1940,https://hail.is,https://github.com/hail-is/hail/pull/14234,1,['avail'],['available']
Availability,"---|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Use of a Broken or Risky Cryptographic Algorithm <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6149518](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6149518) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **451/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.3 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjMjFkYTE5Ny1lMDgzLTRiNzEtODc1Yi0xZmY0MjNhZ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14236:1674,avail,available,1674,https://hail.is,https://github.com/hail-is/hail/pull/14236,1,['avail'],['available']
Availability,"--; FatalError Traceback (most recent call last); /restricted/projectnb/ukbiobank/ad/analysis/ad.v1/bgen_count.py in <module>; 10 mt=hl.import_bgen(bgen,sample_file=sample,entry_fields=['GT','GP','dosage']); 11 mt.describe(); ---> 12 print(""Count:"",mt.count()); 13 mt.s.show(); 14. /restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/matrixtable.py in count(self); 2129 Number of rows, number of cols.; 2130 """"""; -> 2131 r = self._jmt.count(); 2132 return r._1(), r._2(); 2133. /share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container marked as failed: container_e2435_1542127286896_0109_02_000004 on host: scc-q06.scc.bu.edu. Exit status: 1. Diagnostics: Exception from container-launch.; Container id: container_e2435_1542127286896_0109_02_000004; Exit code: 1; Stack trace: ExitCodeException exitCode=1:; at org.apache.hadoop.util.Shell.runCommand(Shell.java:576); at org.apache.hadoop.util.Shell.run(Shell.java:487); at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:753); at org.apache.hadoop.yarn.server.n",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-446057705:1393,Error,Error,1393,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-446057705,1,['Error'],['Error']
Availability,"-->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tornadoweb/tornado/commit/34f5c1cf2696afec5532ca9e870ba32cbc7fee27""><code>34f5c1c</code></a> Version 6.3.2</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/32ad07c54e607839273b4e1819c347f5c8976b2f""><code>32ad07c</code></a> web: Fix an open redirect in StaticFileHandler</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/e0fa53ee96db720dc7800d0248c39a4ffb8911e9""><code>e0fa53e</code></a> Merge pull request <a href=""https://redirect.github.com/tornadoweb/tornado/issues/3257"">#3257</a> from bdarnell/build-workflow-wstest-warning</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/f5a1d5c7e235ad8860a4c2c5f259a43692bcbaab""><code>f5a1d5c</code></a> ci: Only run pypi actions from the main repo</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/1849ef6c48415ef8f5fecbd47d9f68225588507c""><code>1849ef6</code></a> test: Close a websocket client that causes occasional test failures</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/fcb09eba4bd45c2ebfb6356a38acdb3b4450c0d8""><code>fcb09eb</code></a> Merge pull request <a href=""https://redirect.github.com/tornadoweb/tornado/issues/3256"">#3256</a> from bdarnell/build-workflow-qemu</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/c3d50f41a29cda5f76031c60cf7902b175b79479""><code>c3d50f4</code></a> ci: Update setup-qemu-action version</li>; <li>See full diff in <a href=""https://github.com/tornadoweb/tornado/compare/v6.3.1...v6.3.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tornado&package-manager=pip&previous-version=6.3.1&new-version=6.3.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflic",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13120:2158,failure,failures,2158,https://hail.is,https://github.com/hail-is/hail/pull/13120,2,['failure'],['failures']
Availability,"--impute on the Chromosome from a table imputes it as an Int, not a String, which leads to errors",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/520:91,error,errors,91,https://hail.is,https://github.com/hail-is/hail/issues/520,1,['error'],['errors']
Availability,"-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@25004c63{/api,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@36f9d98a{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@302922c9{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 SparkUI: INFO: Bound SparkUI to 0.0.0.0, and started at http://10.48.225.55:4040; 20",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:13117,AVAIL,AVAILABLE,13117,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability,"-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; [farrell@scc-hadoop ukb.v3]$ cat /restricted/projectnb/ukbiobank/ad/analysis/ukb.v3/hail-20190122-1311-0.2.4-d602a3d7472d.log; 2019-01-22 13:11:20 SparkContext: INFO: Running Spark version 2.2.1; 2019-01-22 13:11:20 NativeCodeLoader: WARN: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 2019-01-22 13:11:21 SparkContext: INFO: Submitted application: Hail; 2019-01-22 13:11:21 SparkContext: INFO: Spark configuration:; spark.ap",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:6325,AVAIL,AVAILABLE,6325,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability,"-01-22 13:12:01 TaskSetManager: INFO: Starting task 38.1 in stage 0.0 (TID 58, scc-q10.scc.bu.edu, executor 19, partition 38, PROCESS_LOCAL, 5147 bytes); 2019-01-22 13:12:01 TaskSetManager: INFO: Starting task 8.1 in stage 0.0 (TID 59, scc-q10.scc.bu.edu, executor 19, partition 8, PROCESS_LOCAL, 5147 bytes); 2019-01-22 13:12:02 BlockManagerMasterEndpoint: INFO: Registering block manager scc-q10.scc.bu.edu:42152 with 21.2 GB RAM, BlockManagerId(19, scc-q10.scc.bu.edu, 42152, None); 2019-01-22 13:12:02 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Disabling executor 13.; 2019-01-22 13:12:02 DAGScheduler: INFO: Executor lost: 13 (epoch 13); 2019-01-22 13:12:02 BlockManagerMasterEndpoint: INFO: Trying to remove executor 13 from BlockManagerMaster.; 2019-01-22 13:12:02 BlockManagerMasterEndpoint: INFO: Removing block manager BlockManagerId(13, scc-q16.scc.bu.edu, 35524, None); 2019-01-22 13:12:02 BlockManagerMaster: INFO: Removed 13 successfully in removeExecutor; 2019-01-22 13:12:02 DAGScheduler: INFO: Shuffle files lost for executor: 13 (epoch 13); 2019-01-22 13:12:02 YarnScheduler: ERROR: Lost executor 15 on scc-q10.scc.bu.edu: Container marked as failed: container_e2435_1542127286896_0174_01_000025 on host: scc-q10.scc.bu.edu. Exit status: 1. Diagnostics: Exception from container-launch.; Container id: container_e2435_1542127286896_0174_01_000025; Exit code: 1; Stack trace: ExitCodeException exitCode=1:; at org.apache.hadoop.util.Shell.runCommand(Shell.java:576); at org.apache.hadoop.util.Shell.run(Shell.java:487); at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:753); at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:371); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:303); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); at java.util.concurrent.Fu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:158806,ERROR,ERROR,158806,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['ERROR'],['ERROR']
Availability,"-13 16:37:36.613 JVMEntryway: INFO: 5: worker; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 6: gs://gnomad-tmp-4day/parallelizeAndComputeWithIndex/s_yyHm37RY7YTSWH29gP5SM0RwKxgs9EXbg9_YMf7ho=; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 7: 38854; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 8: 47960; 2023-09-13 16:37:36.613 JVMEntryway: INFO: Yielding control to the QoB Job.; 2023-09-13 16:37:36.614 Worker$: INFO: is.hail.backend.service.Worker be9d88a80695b04a2a9eb5826361e0897d94c042; 2023-09-13 16:37:36.614 Worker$: INFO: running job 38854/47960 at root gs://gnomad-tmp-4day/parallelizeAndComputeWithIndex/s_yyHm37RY7YTSWH29gP5SM0RwKxgs9EXbg9_YMf7ho= with scratch directory '/batch/1c00c7157d4d41bcbf508f12d75329b1'; 2023-09-13 16:37:36.617 GoogleStorageFS$: INFO: Initializing google storage client from service account key; 2023-09-13 16:37:36.821 services: WARN: A limited retry error has occured. We will automatically retry 4 more times. Do not be alarmed. (next delay: 1938). The most recent error was javax.net.ssl.SSLException: Connection reset.; 2023-09-13 16:37:38.893 WorkerTimer$: INFO: readInputs took 2278.496020 ms.; 2023-09-13 16:37:38.893 : INFO: RegionPool: initialized for thread 9: pool-2-thread-1; 2023-09-13 16:37:38.903 : INFO: TaskReport: stage=0, partition=38854, attempt=0, peakBytes=65536, peakBytesReadable=64.00 KiB, chunks requested=0, cache hits=0; 2023-09-13 16:37:38.903 : INFO: RegionPool: FREE: 64.0K allocated (64.0K blocks / 0 chunks), regions.size = 1, 0 current java objects, thread 9: pool-2-thread-1; 2023-09-13 16:37:38.903 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.GeneratedMethodAccessor48.invoke(Unknown Source) ~[?:?]; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]; 	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119) ~[jvm-entryway.jar:?]; 	at java.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13356#issuecomment-1719508553:1756,error,error,1756,https://hail.is,https://github.com/hail-is/hail/issues/13356#issuecomment-1719508553,1,['error'],['error']
Availability,"-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::int32<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::int32<4>]; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:129:36: required from simdpp::arch_avx2::uint64<2>& simdpp::arch_avx2::uint64<2>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::int32<4, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:272:42: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint64<2> with private member simdpp::arch_avx2::uint64<2>::d_ from an array of const class simdpp::arch_avx2::int32<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:26,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:102:7: note: class simdpp::arch_avx2::uint64<2> declared here; class uint64<2, void> : public any_int64<2, uint64<2,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int32<8>; T = simdpp::arch_avx2::int64<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:74896,error,error,74896,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2063dbf5{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@25004c63{/api,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@36f9d98a{/jobs/job/kill,null,A",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:12864,AVAIL,AVAILABLE,12864,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability,"-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2063dbf5{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; [farrell@scc-hadoop ukb.v3]$ cat /restricted/projectnb/ukbiobank/ad/analysis/ukb.v3/hail-20190122-1311-0.2.4-d602a3d7472d.log; 2019-01-22 13:11:20 SparkContext: INFO: Running Spark version 2.2.1; 2019-01-22 13:11:20 NativeCodeLo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:6072,AVAIL,AVAILABLE,6072,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability,"-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@25004c63{/api,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@36f9d98a{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@302922c9{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 SparkUI: INFO: Bound SparkUI to 0.0.0.0, and started at http://10.48.225.55:4040; 2019-01-22 13:11:23 DomainSocketFactory: WARN: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-22 13:11:23 Client: INFO: Requesting a new application from cluster with 21 NodeManagers; 2019-01-22 13:11:23 Client: INFO: Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-22 13:11:23 Client: INFO: Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-22 13:11:23 Client: INFO: Setting up container launch context for our AM; 2019-01-22 13:11:23 Client: INFO: Setting up the ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:13744,AVAIL,AVAILABLE,13744,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability,"-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cdf8858{/stages/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3418c91b{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6e2585c5{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2063dbf5{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHand",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:5684,AVAIL,AVAILABLE,5684,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['AVAIL'],['AVAILABLE']
Availability,"-42010a8000af; spec:; containers:; - command:; - bash; - -c; - |-; set -e; gcloud -q auth activate-service-account --key-file=/test-gsa-key/privateKeyData; gsutil -m cp -r /test/resources/* gs://hail-test-1c9nm/sj0nb47zqys1/pipeline/input/; env:; - name: POD_IP; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: status.podIP; - name: POD_NAME; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: metadata.name; image: gcr.io/hail-vdc/ci-intermediate:oyyg6y2um4kx; imagePullPolicy: IfNotPresent; name: main; resources:; requests:; cpu: 100m; memory: 500M; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /test-gsa-key; name: test-gsa-key; - mountPath: /gsa-key; name: gsa-key; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: default-token-8h99c; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; nodeName: gke-vdc-preemptible-pool-9c7148b2-1f89; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: default; serviceAccountName: default; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: test-gsa-key; secret:; defaultMode: 420; optional: false; secretName: test-gsa-key; - name: gsa-key; secret:; defaultMode: 420; secretName: ci-gsa-key; - name: default-token-8h99c; secret:; defaultMode: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: ""2019",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6625:4318,toler,tolerations,4318,https://hail.is,https://github.com/hail-is/hail/issues/6625,1,['toler'],['tolerations']
Availability,"-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.620 GoogleStorageFS$: INFO: closed: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.621 : INFO: TaskReport: stage=0, partition=7028, attempt=0, peakBytes=62266032, peakBytesReadable=59.38 MiB, chunks requested=72126, cache hits=72121; 2023-09-27 16:44:22.622 : INFO: RegionPool: FREE: 59.4M allocated (25.2M blocks / 34.2M chunks), regions.size = 11, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:44:22.623 WorkerTimer$: INFO: executeFunction took 71843.446957 ms.; 2023-09-27 16:44:22.623 GoogleStorageFS$: INFO: createNoCompression: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:22.668 GoogleStorageFS$: INFO: close: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:33.788 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_382]; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_382]; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]; 	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(T",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:6333,ERROR,ERROR,6333,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943,1,['ERROR'],['ERROR']
Availability,"-5663682) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **691/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.4 | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5914629](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5914629) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:6783,avail,available,6783,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,"-5663682) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **691/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.4 | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5914629](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5914629) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:6775,avail,available,6775,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['avail'],['available']
Availability,"-CRYPTOGRAPHY-3315324) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **584/1000** <br/> **Why?** Has a fix available, CVSS 7.4 | Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315328](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315328) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Timing Attack <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315331](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315331) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315452](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315452) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315975) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:3788,avail,available,3788,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,"-CRYPTOGRAPHY-3315324) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **584/1000** <br/> **Why?** Has a fix available, CVSS 7.4 | Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315328](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315328) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Timing Attack <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315331](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315331) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315452](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315452) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315975) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:3780,avail,available,3780,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['avail'],['available']
Availability,"-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **454/1000** <br/> **Why?** Has a fix available, CVSS 4.8 | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315324) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **584/1000** <br/> **Why?** Has a fix available, CVSS 7.4 | Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315328](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315328) | `cryptography:` <br> `3.3.2 -> 4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:2257,avail,available,2257,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,"-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **454/1000** <br/> **Why?** Has a fix available, CVSS 4.8 | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315324) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **584/1000** <br/> **Why?** Has a fix available, CVSS 7.4 | Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315328](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315328) | `cryptography:` <br> `3.3.2 -> 4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:2249,avail,available,2249,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['avail'],['available']
Availability,"-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **449/1000** <br/> **Why?** Has a fix available, CVSS 4.7 | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **696/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-PYGMENTS-1088505](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1088505) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-5750273](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-5750273) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium seve",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:4765,avail,available,4765,https://hail.is,https://github.com/hail-is/hail/pull/13717,2,['avail'],['available']
Availability,"-b08) (build 1.8.0_242-8u242-b08-1~deb9u1-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # J 8451 C2 is.hail.annotations.Region$.loadBit(JJ)Z (33 bytes) @ 0x00007fa4b25e18cd [0x00007fa4b25e18a0+0x2d]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /tmp/cac7924b3c14494b9702ac2689c0c52d/hs_err_pid6637.log; ```; with this pipeline:; ```; def normalize_contig(input_contig: hl.expr.StringExpression) -> hl.expr.StringExpression:; return input_contig.replace(""^chr"", """"). def downsample_matrix_table(mt: hl.MatrixTable, n_divisions: int, p_threshold: float) -> hl.Table:;  mt = mt.choose_cols(list(range(10))); ; x = mt.locus.global_position(); y = -hl.log10(mt.Pvalue); ; downsampled = mt.annotate_cols(; binned=hl.agg.filter(; mt.Pvalue > p_threshold,; hl.agg.downsample(; x,; y,; label=[; normalize_contig(mt.locus.contig),; hl.str(mt.locus.position),; hl.str(mt.Pvalue),; ],; n_divisions=n_divisions; ); ),; unbinned=hl.agg.filter(; mt.Pvalue <= p_threshold,; hl.agg.collect(hl.struct(; pval=mt.Pvalue,; chrom=normalize_contig(mt.locus.contig),; pos=mt.locus.position,; ac=mt.AC,; af=mt.AF,; an=mt.N,; alleles=mt.alleles,; beta=mt.BETA,; consequence=hl.if_else(; hl.is_defined(mt.annotation),; mt.annotation,; ""N/A""; ),; gene_name=mt.gene,; is_binned=False; ); ); ); ); ; downsampled = downsampled.select_cols(; binned=downsampled.binned.map(; lambda a_bin: hl.struct(; pval=hl.float64(a_bin[2][2]),; chrom=a_bin[2][0],; pos=hl.int32(a_bin[2][1]),; ac=hl.literal(0.0),; af=hl.literal(0.0),; an=hl.literal(0),; alleles=hl.literal(['N', 'A']),; beta=hl.literal(0.0),; consequence=""N/A"",; gene_name=""N/A"",; is_binned=True,; ; ); ),; unbinned=downsampled.unbinned,; ); ; downsampled = downsampled.select_cols(; data=downsampled.binned.extend(downsampled.unbinned); ); downsampled = do",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8240:1264,down,downsample,1264,https://hail.is,https://github.com/hail-is/hail/issues/8240,1,['down'],['downsample']
Availability,"-beta, --configuration=, --dry-run, --project= and --zone=. These apply to all commands. There is a GcloudRunner object that takes these options, is set to the click context user obj field, and is used by all hailctl dataproc commands to invoke gcloud. Note, not all dataproc subcommands invoke gcloud, but the current design doesn't differentiate. Note, with click, the subcommand options must go on the subcommand, so hailctl dataproc stop --dry-run is an error. Nice. It's great that these are handled at the `hailctl dataproc` level instead of having to remember to account for them in every `hailctl dataproc` subcommand. That's going to resolve a lot of inconsistencies (like #9587). A nitpick though... is there a better name for the click context attribute than ""obj""?. > hailctl no longer takes --region (for gcloud dataproc commands). I compute region in GcloudRunner by checking dataproc/region or falling back to determining the region from the zone. I error if the region and zone are incompatible (gcloud would also do this). If consistency with `gcloud dataproc` is desired, I think the opposite (determining zone from cluster region) would be preferable. `gcloud dataproc` commands take a `--region` argument. [`--zone` is an optional argument for `gcloud dataproc clusters create`](https://cloud.google.com/sdk/gcloud/reference/dataproc/clusters/create#--zone). When a cluster's zone is needed to run `gcloud compute` commands, it can be determined using `gcloud dataproc clusters describe <cluster> --format json`. `hailctl dataproc diagnose` currently does this. I believe the only reason that we currently require a zone be provided either in gcloud configuration or on the command line is to maintain backwards compatibility. `cloudtools` and earlier versions of `hailctl` had a default value for the `--zone` option of `hailctl dataproc start` (I think it was `us-central1-b`). > I stripped all gcloud pass through args from hailctl dataproc modify. There aren't any left. Invoki",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842#issuecomment-767168393:1008,error,error,1008,https://hail.is,https://github.com/hail-is/hail/pull/9842#issuecomment-767168393,1,['error'],['error']
Availability,"-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint64<2>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint64<2>]; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:133:36: required from simdpp::arch_avx2::uint16<8>& simdpp::arch_avx2::uint16<8>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint64<2, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:453:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint16<8> with private member simdpp::arch_avx2::uint16<8>::d_ from an array of const class simdpp::arch_avx2::uint64<2>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:21,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:104:7: note: class simdpp::arch_avx2::uint16<8> declared here; class uint16<8, void> : public any_int16<8, uint16<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint64<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:52991,error,error,52991,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint16<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint16<8>]; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:133:36: required from simdpp::arch_avx2::uint32<4>& simdpp::arch_avx2::uint32<4>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint16<8, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:114:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<4> with private member simdpp::arch_avx2::uint32<4>::d_ from an array of const class simdpp::arch_avx2::uint16<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:104:7: note: class simdpp::arch_avx2::uint32<4> declared here; class uint32<4, void> : public any_int32<4, uint32<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint16<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:36412,error,error,36412,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint64<2>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint64<2>]; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:133:36: required from simdpp::arch_avx2::uint32<4>& simdpp::arch_avx2::uint32<4>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint64<2, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:159:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<4> with private member simdpp::arch_avx2::uint32<4>::d_ from an array of const class simdpp::arch_avx2::uint64<2>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:104:7: note: class simdpp::arch_avx2::uint32<4> declared here; class uint32<4, void> : public any_int32<4, uint32<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint32<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:41924,error,error,41924,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint64<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint64<4>]; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:114:36: required from simdpp::arch_avx2::uint32<8>& simdpp::arch_avx2::uint32<8>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint64<4, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:181:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<8> with private member simdpp::arch_avx2::uint32<8>::d_ from an array of const class simdpp::arch_avx2::uint64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:91:7: note: class simdpp::arch_avx2::uint32<8> declared here; class uint32<8, void> : public any_int32<8, uint32<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::float64<4>; T = simdpp::arch_avx2::float32<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:45595,error,error,45595,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::uint32<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::uint32<4>]; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:129:36: required from simdpp::arch_avx2::uint64<2>& simdpp::arch_avx2::uint64<2>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint32<4, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:157:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint64<2> with private member simdpp::arch_avx2::uint64<2>::d_ from an array of const class simdpp::arch_avx2::uint32<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:26,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:102:7: note: class simdpp::arch_avx2::uint64<2> declared here; class uint64<2, void> : public any_int64<2, uint64<2,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint64<2>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:40088,error,error,40088,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint32<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint32<8>]; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:114:36: required from simdpp::arch_avx2::uint64<4>& simdpp::arch_avx2::uint64<4>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint32<8, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:179:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint64<4> with private member simdpp::arch_avx2::uint64<4>::d_ from an array of const class simdpp::arch_avx2::uint32<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:27,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:91:7: note: class simdpp::arch_avx2::uint64<4> declared here; class uint64<4, void> : public any_int64<4, uint64<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint64<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:43760,error,error,43760,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22887"">#22887</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/5b17097d555d32df51e58b75ee12a48a5b60df88""><code>5b17097</code></a> add validate_authority support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22786"">#22786</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/9acb1882379dab5e910e2a5e3ef6c4a6ac08aadf""><code>9acb188</code></a> fix cspell issues (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22774"">#22774</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/a497e5aba391075ebbbd42c2df4937c2d11185a4""><code>a497e5a</code></a> rename troubleshooting (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22771"">#22771</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/9791fb5bc4cb6001768e6e1fb986b8d8f8326c43""><code>9791fb5</code></a> [core] add error body to HttpResponseError str (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22302"">#22302</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/772054c9cf24e860cf08563ac33caab50e904dd5""><code>772054c</code></a> drop py27 support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22531"">#22531</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-identity_1.6.0...azure-identity_1.8.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-identity&package-manager=pip&previous-version=1.6.0&new-version=1.8.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11493:4303,error,error,4303,https://hail.is,https://github.com/hail-is/hail/pull/11493,2,['error'],['error']
Availability,"-storage/commit/803a90b7747b8972f51d1407616c51084d97c589"">803a90b</a>)</li>; <li>Update dependency net.jqwik:jqwik to v1.7.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1758"">#1758</a>) (<a href=""https://github.com/googleapis/java-storage/commit/140e90911229c876de7b674dd1e61b278e8b07fd"">140e909</a>)</li>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.17 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1759"">#1759</a>) (<a href=""https://github.com/googleapis/java-storage/commit/7e3175a56a06dac0aa0841f221a486bb69b5c9bf"">7e3175a</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.13.1...v2.14.0"">2.14.0</a> (2022-10-26)</h2>; <h3>Google Cloud Storage gRPC API Preview</h3>; <p>The first release of <code>google-cloud-storage</code> with support for a subset of the Google Cloud Storage gRPC API which is in private preview. The most common operations have all been implemented and are available for experimentation.</p>; <p>Given not all public api surface of <code>google-cloud-storage</code> classes are supported for gRPC a new annotation <code>@TransportCompatibility</code> has been added to various classes, methods and fields/enum values to signal where that thing can be expected to work. As we implement more of the operations these annotations will be updated.</p>; <p>All new gRPC related APIs are annotated with <code>@BetaApi</code> to denote they are in preview and the possibility of breaking change is present. At this time, opting to use any of the gRPC transport mode means you are okay with the possibility of a breaking change happening. When the APIs are out of preview, we will remove the <code>@BetaApi</code> annotation to signal they are now considered stable and will not break outside a major version.</p>; <p><strong><em>NOTICE</em></strong>: Using the gRPC transport is exclusive. Any operations which have not yet been implemented for gRPC",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12456:7739,avail,available,7739,https://hail.is,https://github.com/hail-is/hail/pull/12456,2,['avail'],['available']
Availability,-stream 2023-06-09T12:44:22+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/2/31Owgv/main/resource_usage BlockBlob Hot 680 application/octet-stream 2023-06-09T12:44:22+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/2/31Owgv/status.json BlockBlob Hot 4453 application/octet-stream 2023-06-09T12:44:22+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/bunch/dK3o5ZfXmYSkP5TA/specs BlockBlob Hot 1264 application/octet-stream 2023-06-09T12:43:37+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/bunch/dK3o5ZfXmYSkP5TA/specs.idx BlockBlob Hot 16 application/octet-stream 2023-06-09T12:43:37+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/bunch/eOrFpVrN98GBIizi/specs BlockBlob Hot 1264 application/octet-stream 2023-06-09T12:43:34+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/bunch/eOrFpVrN98GBIizi/specs.idx BlockBlob Hot 16 application/octet-stream 2023-06-09T12:43:34+00:00; ```. I looked at the status:. ```; az storage blob download --account-name haildevtest --container test --name batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/2/31Owgv/status.json | jq '.' | less; ```. which contained an error (I un-escaped the string here):. ```; JVMUserError: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at is.hail.JVMEntryway.retrieveException(JVMEntryway.java:253); 	at is.hail.JVMEntryway.finishFutures(JVMEntryway.java:215); 	at is.hail.JVMEntryway.main(JVMEntryway.java:185); Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:122); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.ja,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13160:3496,down,download,3496,https://hail.is,https://github.com/hail-is/hail/pull/13160,1,['down'],['download']
Availability,-vdc/hail/hailgenetics/hailtop:deploy-123abc ']'; + echo HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc ']'; + echo HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc ']'; + echo HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc; + for varname in '$arguments'; + '[' -z '' ']'; + echo. + usage; + cat; ++ basename hail/scripts/release.sh; ++ basename hail/scripts/release.sh; usage: release.sh. All arguments are specified by environment variables. For example:. HAIL_PIP_VERSION=0.2.123; HAIL_VERSION=0.2.123-abcdef123; GIT_VERSION=abcdef123; REMOTE=origin; WHEEL=/path/to/the.whl; GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-dock,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:4456,echo,echo,4456,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['echo'],['echo']
Availability,"-wang-ukps2/pipeline/pipeline-1cac3dd4e66d/__TASK__0/0731f9a3; /io/pipeline/pipeline-1cac3dd4e66d/__TASK__0/0731f9a3\n ""; image: google/cloud-sdk:237.0.0-alpine; imagePullPolicy: IfNotPresent; name: setup; resources:; requests:; cpu: 500m; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /batch-gsa-key; name: batch-gsa-key; - mountPath: /gsa-key; name: gsa-key; - mountPath: /io; name: batch-12728-job-287-742170; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: batch-output-pod-token-8pkmz; readOnly: true; nodeName: gke-vdc-non-preemptible-pool-0106a51b-qz7f; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: batch-output-pod; serviceAccountName: batch-output-pod; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: gsa-key; secret:; defaultMode: 420; secretName: wang-gsa-key; - name: batch-gsa-key; secret:; defaultMode: 420; secretName: batch-gsa-key; - name: batch-12728-job-287-742170; persistentVolumeClaim:; claimName: batch-12728-job-287-742170; - name: batch-output-pod-token-8pkmz; secret:; defaultMode: 420; secretName: batch-output-pod-token-8pkmz; status:; conditions:; - lastProbeTime: null; lastTransitionTime: 2019-09-05T19:15:42Z; message: 'containers with incomplete status: [setup]'; reason: ContainersNotInitialized; status: ""False""; type: Initialized; - lastProbeTime: null; lastTransitionTime: 2019-09-05T19:15:42Z; message: 'containers with unready status: [main cleanup keep-alive]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: 2019-09-05T19:15:42Z; message: 'containers with unready status: [main cleanup",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7016:9756,toler,tolerationSeconds,9756,https://hail.is,https://github.com/hail-is/hail/issues/7016,1,['toler'],['tolerationSeconds']
Availability,"-|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **454/1000** <br/> **Why?** Has a fix available, CVSS 4.8 | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315324) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ; ![high",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:1888,avail,available,1888,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,"-|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **454/1000** <br/> **Why?** Has a fix available, CVSS 4.8 | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315324) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![high",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:1880,avail,available,1880,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['avail'],['available']
Availability,". /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in args_to_expr(func, *args); 176 @decorator; 177 def args_to_expr(func, *args):; --> 178 return func(*(to_expr(a) for a in args)); 179; 180. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in eval_expr_typed(expression); 3612 if len(expression._joins) > 0:; 3613 raise ExpressionException(""'eval_expr' methods do not support joins or broadcasts""); -> 3614 r, t = Env.hc().eval_expr_typed(expression._ast.to_hql()); 3615 return r, t; 3616. <decorator-gen-1049> in eval_expr_typed(self, expr). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/utils/java.py in handle_py4j(func, *args, **kwargs); 153 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 154 'Hail version: %s\n'; --> 155 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); 156 except py4j.protocol.Py4JError as e:; 157 if e.args[0].startswith('An error occurred while calling'):. FatalError: HailException: `(' expected but `i' found; <input>:1:(if (true) ""T"" else ""F"" + if (true) ""T"" else ""F""); ^. Java stack trace:; is.hail.utils.HailException: `(' expected but `i' found; <input>:1:(if (true) ""T"" else ""F"" + if (true) ""T"" else ""F""); ^; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:27); 	at is.hail.expr.ParserUtils$.error(Parser.scala:32); 	at is.hail.expr.RichParser.parse(Parser.scala:16); 	at is.hail.expr.Parser$.parseExpr(Parser.scala:85); 	at is.hail.HailContext.eval(HailContext.scala:613); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.Reflec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2653:2347,error,error,2347,https://hail.is,https://github.com/hail-is/hail/issues/2653,1,['error'],['error']
Availability,". /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in args_to_expr(func, *args); 176 @decorator; 177 def args_to_expr(func, *args):; --> 178 return func(*(to_expr(a) for a in args)); 179; 180. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in eval_expr_typed(expression); 3612 if len(expression._joins) > 0:; 3613 raise ExpressionException(""'eval_expr' methods do not support joins or broadcasts""); -> 3614 r, t = Env.hc().eval_expr_typed(expression._ast.to_hql()); 3615 return r, t; 3616. <decorator-gen-1049> in eval_expr_typed(self, expr). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/utils/java.py in handle_py4j(func, *args, **kwargs); 153 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 154 'Hail version: %s\n'; --> 155 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); 156 except py4j.protocol.Py4JError as e:; 157 if e.args[0].startswith('An error occurred while calling'):. FatalError: HailException: `)' expected but `e' found; <input>:1:(5 * -1.2e-07); ^. Java stack trace:; is.hail.utils.HailException: `)' expected but `e' found; <input>:1:(5 * -1.2e-07); ^; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:27); 	at is.hail.expr.ParserUtils$.error(Parser.scala:32); 	at is.hail.expr.RichParser.parse(Parser.scala:16); 	at is.hail.expr.Parser$.parseExpr(Parser.scala:85); 	at is.hail.HailContext.eval(HailContext.scala:613); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2655:2195,error,error,2195,https://hail.is,https://github.com/hail-is/hail/issues/2655,1,['error'],['error']
Availability,". /opt/conda/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:44: UserWarning:. Reading spark-defaults.conf to determine GCS requester pays configuration. This is deprecated. Please use `hailctl config set gcs_requester_pays/project` and `hailctl config set gcs_requester_pays/buckets`. SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.18.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 3.3.0; SparkUI available at http://saturn-3f2d119c-05e5-496d-97b9-8f40efff98a3-m.c.terra-db12d060.internal:36235/; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.126-ee77707f4fab; LOGGING: writing to /home/jupyter/Ellinor_Lubitz_PHB_Joint_Analyses/edit/hail-20231216-1801-0.2.126-ee77707f4fab.log. SparkContext. [Spark UI](http://saturn-3f2d119c-05e5-496d-97b9-8f40efff98a3-m.c.terra-db12d060.internal:36235/). Version; v3.3.0; Master; yarn; AppName; pyspark-shell. `#### Read vcf; vcfs = [""gs://path/to/bucket/chrY.*.hard_filtered_with_genotypes.vcf.gz""]. #####; ##### Read vcf file; mt = hl.import_vcf(vcfs , force_bgz= True, reference_genome='GRCh38', find_replace=('null', '.')). mt.count(); `. 2023-12-16 18:02:00.897 Hail: INFO: scanning VCF for sortedness... (4 + 3) / 7]; 2023-12-16 18:02:16.278 Hail: INFO: Coerced sorted VCF - no additional import work to do; [Stage 3:===================================================> (10 + 1) / 11]; (15472, 13279). `##### Split the multi-alleleic variant",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:2672,avail,available,2672,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['avail'],['available']
Availability,". ; `vcf = hc.import_vcf('AID61507_SID56895.Improved.gatk.phased.vcf')`. However, I get the following error message:. `FatalError Traceback (most recent call last)`; `<ipython-input-15-90c48751816a> in <module>()`; `----> 1 vcf = hc.import_vcf('AID61507_SID56895.Improved.gatk.phased.vcf')`; `<decorator-gen-605> in import_vcf(self, path, force, force_bgz, header_file, min_partitions, ``drop_samples, store_gq, pp_as_pl, skip_bad_ad, generic, call_fields)`; `/Users/ih/hail/python/hail/java.pyc in handle_py4j(func, *args, **kwargs)`; ` 110 raise FatalError('%s\n\nJava stack trace:\n%s\n'`; ` 111 'Hail version: %s\n'`; `--> 112 'Error summary: %s' % (deepest, full, Env.hc().version, deepest))`; ` 113 except py4j.protocol.Py4JError as e:`; ` 114 if e.args[0].startswith('An error occurred while calling'):`; `FatalError: HailException: arguments refer to no files`; `Java stack trace:`; `is.hail.utils.HailException: arguments refer to no files`; 	`at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6)`; 	`at is.hail.utils.package$.fatal(package.scala:25)`; 	`at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105)`; 	`at is.hail.HailContext.importVCFsGeneric(HailContext.scala:558)`; 	`at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)`; 	`at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)`; 	`at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)`; 	`at java.lang.reflect.Method.invoke(Method.java:498)`; 	`at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)`; 	`at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)`; 	`at py4j.Gateway.invoke(Gateway.java:280)`; 	`at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)`; 	`at py4j.commands.CallCommand.execute(CallCommand.java:79)`; 	`at py4j.GatewayConnection.run(GatewayConnection.java:214)`; 	`at java.lang.Thread.run(Thread.java:745)`. `Hail version: 0.1-4238176`; `Error summary: HailException: ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2070:1078,Error,ErrorHandling,1078,https://hail.is,https://github.com/hail-is/hail/issues/2070,1,['Error'],['ErrorHandling']
Availability,". I had to set --rows-per-partition to 40m to fix a `The requested number of tablets is over the permitted maximum (100)` error. I was able to write a small table. When I tried to write a larger file (~900 exomes) and I got:. ```; hail: writekudu: caught exception: org.kududb.client.NonRecoverableException: Too many attempts: KuduRpc(method=IsCreateTableDone, tablet=null, attempt=6, DeadlineTracker(timeout=10000, elapsed=7721), Deferred@1490962783(state=PENDING, result=null, callback=(continuation of Deferred@813205641 after org.kududb.client.AsyncKuduClient$4@2c0dff53@739114835) -> (continuation of Deferred@1748842457 after org.kududb.client.AsyncKuduClient$5@42031f30@1107500848) -> (continuation of Deferred@919337785 after org.kududb.client.AsyncKuduClient$5@75ff6dd4@1979674068) -> (continuation of Deferred@1962741581 after org.kududb.client.AsyncKuduClient$5@2edd647d@786261117) -> (continuation of Deferred@1202081964 after org.kududb.client.AsyncKuduClient$5@49391441@1228477505), errback=(continuation of Deferred@813205641 after org.kududb.client.AsyncKuduClient$4@2c0dff53@739114835) -> (continuation of Deferred@1748842457 after org.kududb.client.AsyncKuduClient$5@42031f30@1107500848) -> (continuation of Deferred@919337785 after org.kududb.client.AsyncKuduClient$5@75ff6dd4@1979674068) -> (continuation of Deferred@1962741581 after org.kududb.client.AsyncKuduClient$5@2edd647d@786261117) -> (continuation of Deferred@1202081964 after org.kududb.client.AsyncKuduClient$5@49391441@1228477505))); ```. In the Kudu logs, I'm seeing tons of:. ```; W0411 15:20:09.832504 129721 catalog_manager.cc:1880] TS a72be89d736f49a799e1b544197675be: Create Tablet RPC failed for tablet 6652d540f73a4ba5a0b9758a3aeeb1e4: Remote error: Service unavailable: CreateTablet request on kudu.tserver.TabletServerAdminService from 69.173.65.227:42904 dropped due to backpressure. The service queue is full; it has 50 items.; ```. Suggestions on how to proceed? Should I increase the service queue size?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/242#issuecomment-208516279:1778,error,error,1778,https://hail.is,https://github.com/hail-is/hail/pull/242#issuecomment-208516279,1,['error'],['error']
Availability,". ```shell; ----> 1 gwas_weights = hl._linear_regression_rows_nd(y=mt.y,; 2 x=mt.GT.n_alt_alleles(),; 3 covariates=[1.0],; 4 weights=mt.weights). File <decorator-gen-1734>:2, in _linear_regression_rows_nd(y, x, covariates, block_size, weights, pass_through). File ~/hail/hail/python/hail/typecheck/check.py:585, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 582 @decorator; 583 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 584 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 585 return __original_func(*args_, **kwargs_). File ~/hail/hail/python/hail/methods/statgen.py:717, in _linear_regression_rows_nd(y, x, covariates, block_size, weights, pass_through); 714 res = res.select_globals(); 716 temp_file_name = hl.utils.new_temp_file(""_linear_regression_rows_nd"", ""result""); --> 717 res = res.checkpoint(temp_file_name); 719 return res. File <decorator-gen-1234>:2, in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). File ~/hail/hail/python/hail/typecheck/check.py:585, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 582 @decorator; 583 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 584 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 585 return __original_func(*args_, **kwargs_). File ~/hail/hail/python/hail/table.py:1963, in Table.checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1960 hl.current_backend().validate_file(output); 1962 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1963 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1964 _assert_type = self._type; 1965 _load_refs = False. File <decorator-gen-1236>:2, in write(self, output, overwrite, stage_locally, _codec_spec). File ~/hail/hail/python",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14594:1626,checkpoint,checkpoint,1626,https://hail.is,https://github.com/hail-is/hail/issues/14594,1,['checkpoint'],['checkpoint']
Availability,"........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.; ERROR: Create cluster failed!; ERROR: gcloud crashed (AttributeError): 'Operation' object has no attribute 'details'. If you would like to report this issue, please run the following command:; gcloud feedback. To check gcloud for common problems, please run the following command:; gcloud info --run-diagnostics; gcloud command:; gcloud beta dataproc clusters create \; ci-test-6boype3d \; --image-version=1.2-deb9 \; --metadata=MINICONDA_VERSION=4.4.10,JAR=gs://hail-ci-0-1/temp/25aa42b2d6d442615931b2eb65c5f8e012de52a0/96d6daa14989dd0cff08b30ac1f1d53288171a54/hail.jar,ZIP=gs://hail-ci-0-1/temp/25aa42b2d6d442615931b2eb65c5f8e012de52a0/96d6daa14989dd0cff08b30ac1f1d53288171a54/hail.zip \; --properties=spark:spark.driver.memory=3g,spark:spark.driver.maxResultSize=0,spark:spark.task.maxFailures=20,spark:spark.kryoserializer.buffer.max=1g,spark:spark.driver.extraJavaOptions=-Xss4M,spark:spark.executor.extraJavaOptions=-Xss4M,hdfs:dfs.replication=1,dataproc:dataproc.logging.stackdriver.enable=false,dataproc:dataproc.monitoring.stackdriver.enable=false \",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4530#issuecomment-475782518:7806,ERROR,ERROR,7806,https://hail.is,https://github.com/hail-is/hail/issues/4530#issuecomment-475782518,2,['ERROR'],['ERROR']
Availability,"...once KinshipMatrix is in, with RRM going there. The current export to file formats on GRM should be moved to KinshipMatrix too. And then doc on lmmreg should be updated to reflect there are more options than RRM available.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1633:215,avail,available,215,https://hail.is,https://github.com/hail-is/hail/issues/1633,1,['avail'],['available']
Availability,".0.2-bin-hadoop2.7/python/pyspark/sql/utils.pyc in deco(*a, **kw); 61 def deco(*a, **kw):; 62 try:; ---> 63 return f(*a, **kw); 64 except py4j.protocol.Py4JJavaError as e:; 65 s = e.java_exception.toString(). /Users/tpoterba/hail/python/hail/java.py in deco(*a, **kw); 109 # deepest = env.jutils.deepestMessage(e.java_exception); 110 # msg = env.jutils.getMinimalMessage(e.java_exception); --> 111 raise FatalError('%s\n\nJava stack trace:\n%s\n\nERROR SUMMARY: %s' % (deepest, full, deepest)); 112 except py4j.protocol.Py4JError as e:; 113 if e.args[0].startswith('An error occurred while calling'):. FatalError: HailException: malformed.vcf: caught htsjdk.tribble.TribbleException$InternalCodecException: The allele with index 10026357 is not defined in the REF/ALT columns in the record; offending line: 20	10026348	.	A	G	7535.22	PASS	HWP=1.0;AC=2;culprit=Inbreedi... Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3, localhost): is.hail.utils.HailException: malformed.vcf: caught htsjdk.tribble.TribbleException$InternalCodecException: The allele with index 10026357 is not defined in the REF/ALT columns in the record; offending line: 20	10026348	.	A	G	7535.22	PASS	HWP=1.0;AC=2;culprit=Inbreedi...; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:10); 	at is.hail.utils.package$.fatal(package.scala:20); 	at is.hail.utils.TextContext.wrapException(Context.scala:15); 	at is.hail.utils.WithContext.map(Context.scala:27); 	at is.hail.io.vcf.LoadVCF$$anonfun$14$$anonfun$apply$7.apply(LoadVCF.scala:301); 	at is.hail.io.vcf.LoadVCF$$anonfun$14$$anonfun$apply$7.apply(LoadVCF.scala:301); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$7$$anon$2.has",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882:1876,failure,failure,1876,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882,1,['failure'],['failure']
Availability,".0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch-hadoop/releases"">elasticsearch-spark-20_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.6.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/da4f3c3f209aea47d69c4faf90",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:1075,down,downloads,1075,https://hail.is,https://github.com/hail-is/hail/pull/12601,1,['down'],['downloads']
Availability,".1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch-hadoop/releases"">elasticsearch-spark-20_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.6.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.1.html</a></p>; <h2>Elasticsearch Hadoop 8.6.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:1075,down,downloads,1075,https://hail.is,https://github.com/hail-is/hail/pull/12623,1,['down'],['downloads']
Availability,".16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.30.0"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,624,531,604,589,726,434,589,449,696,589,479,519,509,711,701,586,586,384,494,539,589],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr);  [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr);  [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14108:13182,avail,available,13182,https://hail.is,https://github.com/hail-is/hail/pull/14108,1,['avail'],['available']
Availability,".17. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/103692"">kubernetes/kubernetes#103692</a>, <a href=""https://github.com/justaugustus""><code>@justaugustus</code></a>)</li>; <li>Performs strict server side schema validation requests via the <code>fieldValidation=[Strict,Warn,Ignore]</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105916"">kubernetes/kubernetes#105916</a>, <a href=""https://github.com/kevindelgado""><code>@kevindelgado</code></a>)</li>; <li>Promote <code>IPv6DualStack</code> feature to stable.; Controller Manager flags for the node IPAM controller have slightly changed:; <ol>; <li>When configuring a dual-stack cluster, the user must specify both <code>--node-cidr-mask-size-ipv4</code> and <code>--node-cidr-mask-size-ipv6</code> to set the per-node IP mask sizes, instead of the previous <code>--node-cidr-mask-size</code> flag.</li>; <li>The <code>--node-cidr-mask-size</code> flag is mutually exclusive with <code>--node-cidr-mask-size-ipv4</code> and <code>--node-cidr-mask-size-ipv6</code>.</li>; <li>Single-stack clusters do not need to change, but may choose to use the more specific flags. Users can use either the older <code>--node-cidr-mask-size</code> flag or one of the newer <code>--node-cidr-mask-size-ipv4</code> or <code>--node-cidr-mask-size-ipv6</code> flags to configure the per-node IP mask size, provided that the flag's IP family matches the cluster's IP family (--cluster-cidr). (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104691"">kubernetes/kubernetes#104691</a>, <a href=""https://github.com/khenidak""><code>@khenidak</code></a>)</li>; </ol>; </li>; <li>Remove <code>NodeLease</code> feature gate that was graduated and locked to stable in 1.17 release. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105222"">kubernetes/kubernetes#105222</a>, <a href=""https://github.com/cyclinder""><code>@cyclinder</code></a>)</li>; <li>Rem",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:10810,mask,mask-size,10810,https://hail.is,https://github.com/hail-is/hail/pull/11957,3,['mask'],"['mask-size', 'mask-size-']"
Availability,".3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch-hadoop/releases"">elasticsearch-spark-20_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.4.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html</a></p>; <h2>Elasticsearch Hadoop 8.4.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12358:1076,down,downloads,1076,https://hail.is,https://github.com/hail-is/hail/pull/12358,1,['down'],['downloads']
Availability,".3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch-hadoop/releases"">elasticsearch-spark-30_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.4.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html</a></p>; <h2>Elasticsearch Hadoop 8.4.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:1075,down,downloads,1075,https://hail.is,https://github.com/hail-is/hail/pull/12319,1,['down'],['downloads']
Availability,".3.z-SNAPSHOT; 2019-01-22 13:11:22 Server: INFO: Started @12028ms; 2019-01-22 13:11:22 AbstractConnector: INFO: Started ServerConnector@1433e9ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-01-22 13:11:22 Utils: INFO: Successfully started service 'SparkUI' on port 4040.; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1fc6c1cc{/jobs,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@75771d8a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@56931c6{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@7d4d6f14{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@23f9d06d{/stages,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cdf8858{/stages/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3418c91b{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6e2585c5{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2063dbf5{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/j",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:4795,AVAIL,AVAILABLE,4795,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['AVAIL'],['AVAILABLE']
Availability,".6/python/pyspark/rdd.py"", line 1008, in count; return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 999, in sum; return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 873, in fold; vals = self.mapPartitions(func).collect(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 776, in collect; port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd()); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/sql/utils.py"", line 63, in deco; return f(*a, **kw); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; 	at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285); 	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228); 	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313); 	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367:2560,error,error,2560,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367,1,['error'],['error']
Availability,".6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/table.py"", line 1870, in persist; return Env.backend().persist_table(self, storage_level); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/spark_backend.py"", line 285, in persist_table; return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py"", line 16, in deco; return f(*args, **kwargs); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py"", line 336, in get_return_value; format(target_id, ""."", name)); py4j.protocol.Py4JError: An error occurred while calling o1.pyPersistTable. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2044, in showtraceback; stb = value._render_traceback_(); AttributeError: 'Py4JError' object has no attribute '_render_traceback_'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 929, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1067, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ----",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:3723,error,error,3723,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['error'],['error']
Availability,".; It's just one step short of using containers - but since it doesn't require; a containerized OS, I think it works; for laptops etc. I believe the package could have all the stuff we currently manage my; manual install, viz JDK, Spark, Python-3.6,; R, R packages, as well as Hail and a friendly-C++17-capable compiler. All; without perturbing anything else; on the system. See https://bitnami.com. I took a similar approach at PhysicsSpeed, though without using any bitnami; tools because we had less than; zero dollars :-(. I don't know if this adds any value in the containerized/cloud environment,; where custom machine images; are presumably the way to go. But it makes setup easy for standalone use. Regards; Richard. On Thu, Aug 2, 2018 at 10:44 PM Richard Cownie <rcownie@broadinstitute.org>; wrote:. > We have a difference of opinion about the risks involved in using whatever; > compiler happens to show up as $(CXX); > to try to compile arbitrarily large auto-generated C++ files, and maybe; > about what happens when that fails; > and gives an error message about something in the middle of 12000 lines of; > code that bears no obvious relationship; > to what the user is doing. Or when that compiler takes 15 minutes to; > compile it. It's the C++ equivalent of; > the JVM ""no, that's just too much bytecode"". Or worst of all, it compiles; > it but the code gives the wrong answers; > because that particular compiler has a bug, and we never tested the; > combination of our codegen with *that*; > compiler/version.; >; > A couple of years ago I was seeing g++ take 40-60 seconds to compile; > something that clang did in 2 seconds; > (fairly heavily templated code generated for an SQL query, so very much in; > the same ballpark as parts of Hail),; > which contributes to my concern about this, especially on linux where g++; > is the default.; >; > So in the long run I expect we'll ship a compiler, or specify a compiler.; > But that becomes a problem in itself; > if we want the sh",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-410235287:1380,error,error,1380,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410235287,1,['error'],['error']
Availability,".ClientResponseError'> 500, message='Internal Server Error', url=URL('http://batch.hail/api/v1alpha/batches/485962/updates/1/jobs/create') body='500 Internal Server Error\n\nServer got itself in trouble'. ; Traceback (most recent call last):; File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 809, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/aiocloud/common/session.py"", line 117, in _request_with_valid_authn; return await self._http_session.request(method, url, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/httpx.py"", line 148, in request_and_raise_for_status; raise ClientResponseError(; hailtop.httpx.ClientResponseError: 500, message='Internal Server Error', url=URL('http://batch.hail/api/v1alpha/batches/485962/updates/1/jobs/create') body='500 Internal Server Error\n\nServer got itself in trouble'; 2024-09-25 01:54:55,288 - hailtop.utils 835 - WARNING - A transient error occured. We will automatically retry. We have thus far seen 50 transient errors (next delay: 60.0s).; ```. The corresponding server-side error was. ```; pymysql.err.DataError: (1406, \""Data too long for column 'value' at row 106\""); ```. coming from the `INSERT INTO job_attributes ` query in `insert_jobs_into_db()`. We write a list of the samples being processed as a job attribute, and it turned out that for at least some of the jobs of this batch this list had grown to longer than 64K of text. The `job_attributes.value` database field is of type TEXT, which limits each individual attribute to 64KiB bytes. While writing a long list of sample ids as an attribute may or may not be a great idea :smile: it is fair to say that 64K is not a large maximum for user-supplied data here in the 21st century!. It may be worth adding a database migration to change the `job_attributes.value` column type (and perhaps also that of `job_group_attributes.value`) from TEXT to MEDIUMTEXT, ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14702:1589,error,error,1589,https://hail.is,https://github.com/hail-is/hail/issues/14702,1,['error'],['error']
Availability,".ContextRDD.collect(ContextRDD.scala:143); at is.hail.io.RichContextRDDRegionValue$.writeRowsSplit$extension(RowStore.scala:1179); at is.hail.rvd.OrderedRVD.writeRowsSplit(OrderedRVD.scala:454); at is.hail.expr.MatrixValue.write(Relational.scala:122); at is.hail.variant.MatrixTable$$anonfun$write$2.apply(MatrixTable.scala:2301); at is.hail.variant.MatrixTable$$anonfun$write$2.apply(MatrixTable.scala:2301); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:511); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:39); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:15); at is.hail.variant.MatrixTable.write(MatrixTable.scala:2301); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745). Hail version: devel-4f13f27cd28d; Error summary: SparkException: Job 2 cancelled because SparkContext was shut down; [farrell@scc-hadoop ad.v1]$ Exception in thread ""Executor task launch worker for task 766"" java.lang.NullPointerException; at org.apache.spark.scheduler.Task.metrics$lzycompute(Task.scala:66); at org.apache.spark.scheduler.Task.metrics(Task.scala:65); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:473); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755:7437,Error,Error,7437,https://hail.is,https://github.com/hail-is/hail/issues/4755,2,"['Error', 'down']","['Error', 'down']"
Availability,".RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283). Konrad Karczewski @konradjk 16:24; this should work, so i think it's a bug. but in the short run, you could hdfs dfs -cp file:///tmp/clinvar.vcf.gz / and then just load /clinvar.vcf.gz; copy to hdfs; (you shouldn't have to, but \_()_/). bw2 @bw2 16:27; that worked. thanks!. ### What went wrong (all error messages here, including the full java stack trace):. Traceback (most recent call last):; File ""/tmp/7417fcfbbeee44d0b3f4c0b3750121a7/load_clinvar_to_es_pipeline.py"", line 31, in <module>; vds = hc.import_vcf(""file:///tmp/clinvar.vcf.gz"", force=True); File ""<decorator-gen-502>"", line 2, in import_vcf; File ""/tmp/7417fcfbbeee44d0b3f4c0b3750121a7/hail-0.1-es-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; 	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); 	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); 	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(T",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:5099,failure,failure,5099,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['failure'],['failure']
Availability,.SparkBackend.withExecuteContext(SparkBackend.scala:229); 			at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:303); 			at is.hail.backend.spark.SparkBackend.executeJSON(SparkBackend.scala:323); 			at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 			at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 			at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 			at java.lang.reflect.Method.invoke(Method.java:498); 			at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 			at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 			at py4j.Gateway.invoke(Gateway.java:282); 			at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 			at py4j.commands.CallCommand.execute(CallCommand.java:79); 			at py4j.GatewayConnection.run(GatewayConnection.java:238); 			at java.lang.Thread.run(Thread.java:748). 	org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 9 (runJob at RVD.scala:688) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:882) at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:878) at scala.collection.Iterator$class.foreach(Iterator.scala:891) at scala.collection.AbstractIterator.foreach(Iterator.scala:1334) at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:878) at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:691) at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:8439,failure,failure,8439,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['failure'],['failure']
Availability,.SparkBackend.withExecuteContext(SparkBackend.scala:393); at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:631); at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:89); at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:79); at sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:83); at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:82); at sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:822); at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:79); at sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:794); at sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:199); at sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:544); at sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:509); at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.127-bb535cd096c5; Error summary: NegativeArraySizeException: null; tar: chr12: Cannot stat: No such file or directory; tar: Exiting with failure status due to previous errors; 2024/01/17 21:10:34 Starting delocalization.; 2024/01/17 21:10:34 Delocalization script execution started...; 2024/01/17 21:10:34 Delocalizing output /cromwell_root/memory_retry_rc -> gs://fc-5a8938eb-1299-4afc-957f-afb53ef602b9/submissions/e8747e74-47d1-4f52-acfc-1ac7f81d79ba/VUMCBed2HailMatrix/683447d9-9342-4058-bcfc-ba21422d3121/call-Bed2HailMatrix/memory_retry_rc; 2024/01/17 21:10:37 Delocalizing output /cromwell_root/rc -> gs://fc-5a8938eb-1299-4afc-957f-afb53ef602b9/submissions/e8747e74-47d1-4f52-acfc-1ac7f81d79ba/VUMCBed2HailMatrix/683447d9-9342-4058-bcfc-ba21422d3121/call-Bed2HailMatrix/rc; 2024/01/17 21:10:39 Delocalizing output /cromwell_root/stdout -> gs://fc-5a8938eb-1299-4afc-957f-afb53ef602b9/submissions/e8747e74-47d1-4f52-acfc-1ac7f81d79ba/VUMCBed2HailMatrix/683447d9-9342-4058-bcfc-ba21422d3121/call-Bed2HailMatrix/stdout; 2024/01/17 21:10:41 Delocalizing output /cromwell_root/stderr -> gs://fc-5a8938eb-129,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14168:26206,Error,Error,26206,https://hail.is,https://github.com/hail-is/hail/issues/14168,3,"['Error', 'error', 'failure']","['Error', 'errors', 'failure']"
Availability,.Table.take(Table.scala:637); 	at is.hail.table.Table.showString(Table.scala:673); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)is.hail.utils.HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1012); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.RVD$$anonfun$4$$anon$1.hasNext(RVD.scala:226); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1015); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); 	at is.hail.utils.richUtils.RichIterator$$anon$5.isValid(RichIterator.scala:21); 	at is.hail.utils.StagingIterator.isValid(FlipbookIterator.scala:,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:8626,Error,ErrorHandling,8626,https://hail.is,https://github.com/hail-is/hail/issues/4055,1,['Error'],['ErrorHandling']
Availability,".__version__, deepest)) from None; 229 except pyspark.sql.utils.CapturedException as e:; 230 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: HailException: found out of bounds index -1; Resulted from trying to merge -0.0; Indices are [0.0, 2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0, 18.0, 20.0, 22.0, 24.0, 26.0, 28.0, 30.0, 32.0, 34.0, 36.0, 38.0, 40.0, 42.0, 44.0, 46.0, 48.0, 50.0, 52.0, 54.0, 56.0, 58.0, 60.0, 62.0, 64.0, 66.0, 68.0, 70.0, 72.0, 74.0, 76.0, 78.0, 80.0, 82.0, 84.0, 86.0, 88.0, 90.0, 92.0, 94.0, 96.0, 98.0, 100.0, 102.0, 104.0, 106.0, 108.0, 110.0, 112.0, 114.0, 116.0, 118.0, 120.0, 122.0, 124.0, 126.0, 128.0, 130.0, 132.0, 134.0, 136.0, 138.0, 140.0, 142.0, 144.0, 146.0, 148.0, 150.0, 152.0, 154.0, 156.0, 158.0, 160.0, 162.0, 164.0, 166.0, 168.0, 170.0, 172.0, 174.0, 176.0, 178.0, 180.0, 182.0, 184.0, 186.0, 188.0, 190.0, 192.0, 194.0, 196.0, 198.0, 200.0]; Binary search index was -1. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 24.0 failed 20 times, most recent failure: Lost task 0.19 in stage 24.0 (TID 1813, lfrani-sw-hqb8.c.broad-mpg-gnomad.internal, executor 159): is.hail.utils.HailException: found out of bounds index -1; Resulted from trying to merge -0.0; Indices are [0.0, 2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0, 18.0, 20.0, 22.0, 24.0, 26.0, 28.0, 30.0, 32.0, 34.0, 36.0, 38.0, 40.0, 42.0, 44.0, 46.0, 48.0, 50.0, 52.0, 54.0, 56.0, 58.0, 60.0, 62.0, 64.0, 66.0, 68.0, 70.0, 72.0, 74.0, 76.0, 78.0, 80.0, 82.0, 84.0, 86.0, 88.0, 90.0, 92.0, 94.0, 96.0, 98.0, 100.0, 102.0, 104.0, 106.0, 108.0, 110.0, 112.0, 114.0, 116.0, 118.0, 120.0, 122.0, 124.0, 126.0, 128.0, 130.0, 132.0, 134.0, 136.0, 138.0, 140.0, 142.0, 144.0, 146.0, 148.0, 150.0, 152.0, 154.0, 156.0, 158.0, 160.0, 162.0, 164.0, 166.0, 168.0, 170.0, 172.0, 174.0, 176.0, 178.0, 180.0, 182.0, 184.0, 186.0, 188.0, 190.0, 192.0, 194.0, 196.0, 198.0, 200.0]; Binary search index was -1; 	at is.hail.utils.ErrorHandling$class.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:2803,failure,failure,2803,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['failure'],['failure']
Availability,.collect(RDD.scala:935); at is.hail.io.RichRDDRegionValue$.writeRowsSplit$extension(RowStore.scala:806); at is.hail.rvd.OrderedRVD.writeRowsSplit(OrderedRVD.scala:390); at is.hail.variant.MatrixTable.write(MatrixTable.scala:2428); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745)java.io.IOException: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:757); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:756); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:8695,Error,Error,8695,https://hail.is,https://github.com/hail-is/hail/issues/3342,1,['Error'],['Error']
Availability,".com/tox-dev/sphinx-autodoc-typehints/commit/f75d19be9275b25d2f6caa23392a6072f49c3d56""><code>f75d19b</code></a> Add handling of tuples in type subscriptions (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/212"">#212</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/7b8c357be15d7b7b4ec4ad272f554f7ab3e0e197""><code>7b8c357</code></a> ADMIN: Update pepy.tech link in badge (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/213"">#213</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/3492d491fe09701a035715bb1dbaba13734ad69c""><code>3492d49</code></a> Prevents reaching inner blocks that contains <code>if TYPE_CHECKING</code> (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/211"">#211</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/01b3a1abeac063a5530b96b78252aa17a93f040c""><code>01b3a1a</code></a> More robust handling of type guard imports (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/208"">#208</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/d770c69c1e6c7e4a809a145140cfc1033eac57dd""><code>d770c69</code></a> Fix fully_qualified should be typehints_fully_qualified (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/204"">#204</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/compare/1.11.1...1.17.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-autodoc-typehints&package-manager=pip&previous-version=1.11.1&new-version=1.17.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11503:5174,robust,robust,5174,https://hail.is,https://github.com/hail-is/hail/pull/11503,2,['robust'],['robust']
Availability,.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-279ddd2; Error summary: AssertionError: assertion failed; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3235:13021,Error,Error,13021,https://hail.is,https://github.com/hail-is/hail/issues/3235,1,['Error'],['Error']
Availability,.expr.SymRef.typecheckThis(AST.scala:648); at is.hail.expr.AST.typecheck(AST.scala:219); at is.hail.expr.Parser$.is$hail$expr$Parser$$eval(Parser.scala:57); at is.hail.expr.Parser$.parseExpr(Parser.scala:67); at is.hail.stats.RegressionUtils$$anonfun$3.apply(RegressionUtils.scala:36); at is.hail.stats.RegressionUtils$$anonfun$3.apply(RegressionUtils.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); at is.hail.stats.RegressionUtils$.getPhenoCovCompleteSamples(RegressionUtils.scala:36); at is.hail.methods.LinearRegression$.apply(LinearRegression.scala:21); at is.hail.variant.VariantDatasetFunctions$.linreg$extension(VariantDataset.scala:848); at is.hail.variant.VariantDatasetFunctions.linreg(VariantDataset.scala:846); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745). Hail version: devel-07f60b2; Error summary: HailException: symbol `a' not found; Available symbols:; s: String; sa: Struct ; <input>:1:a; ^; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1654:3043,Error,Error,3043,https://hail.is,https://github.com/hail-is/hail/pull/1654,2,"['Avail', 'Error']","['Available', 'Error']"
Availability,.getBytes(ZipCoder.java:80); at java.util.zip.ZipFile.getEntry(ZipFile.java:310); at java.util.jar.JarFile.getEntry(JarFile.java:240); at java.util.jar.JarFile.getJarEntry(JarFile.java:223); at sun.misc.URLClassPath$JarLoader.getResource(URLClassPath.java:1042); at sun.misc.URLClassPath.getResource(URLClassPath.java:239); at java.net.URLClassLoader$1.run(URLClassLoader.java:365); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(I,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2186,Heartbeat,HeartbeatReceiver,2186,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Heartbeat'],['HeartbeatReceiver']
Availability,.hail.io.LEB128InputBuffer.skipInt(InputBuffers.scala:260) ~[gs:__hail-query-ger0g_jars_fcaafc533ec130ae210b152afa81c0b5ac04592b.jar.jar:0.0.1-SNAPSHOT]; 	at __C796collect_distributed_array_table_native_writer.__m872SKIP_o_int32(Unknown Source) ~[?:?]; 	at __C796collect_distributed_array_table_native_writer.__m869INPLACE_DECODE_o_struct_of_o_int32ANDo_int32ANDo_int32ANDo_binaryANDo_array_of_o_int32END_TO_o_struct_of_o_callANDo_int32ANDo_stringANDo_array_of_o_int32END(Unknown Source) ~[?:?]; 	at __C796collect_distributed_array_table_native_writer.__m868INPLACE_DECODE_r_array_of_o_struct_of_o_int32ANDo_int32ANDo_int32ANDo_binaryANDo_array_of_o_int32END_TO_r_array_of_o_struct_of_o_callANDo_int32ANDo_stringANDo_array_of_o_int32END(Unknown Source) ~[?:?]; 	at __C796collect_distributed_array_table_native_writer.__m867DECODE_r_struct_of_r_array_of_o_struct_of_o_int32ANDo_int32ANDo_int32ANDo_binaryANDo_array_of_o_int32ENDEND_TO_SBaseStructPointer(Unknown Source) ~[?:?]; ```. Error for run 2; ```; Caused by: com.github.luben.zstd.ZstdException: Corrupted block detected; 	at com.github.luben.zstd.ZstdDecompressCtx.decompressByteArray(ZstdDecompressCtx.java:157) ~[zstd-jni-1.5.2-1.jar:1.5.2-1]; 	at is.hail.io.ZstdInputBlockBuffer.readBlock(InputBuffers.scala:655) ~[gs:__hail-query-ger0g_jars_ee77707f4fab22b1c253321b082a70aff3f44d1c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.BlockingInputBuffer.readBytes(InputBuffers.scala:444) ~[gs:__hail-query-ger0g_jars_ee77707f4fab22b1c253321b082a70aff3f44d1c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.LEB128InputBuffer.readBytes(InputBuffers.scala:253) ~[gs:__hail-query-ger0g_jars_ee77707f4fab22b1c253321b082a70aff3f44d1c.jar.jar:0.0.1-SNAPSHOT]; 	at __C816collect_distributed_array_table_native_writer.__m893INPLACE_DECODE_o_binary_TO_o_string(Unknown Source) ~[?:?]; 	at __C816collect_distributed_array_table_native_writer.__m889INPLACE_DECODE_o_struct_of_o_int32ANDo_int32ANDo_int32ANDo_binaryANDo_array_of_o_int32END_TO_o_struct_of_o_callANDo_int32A,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:4017,Error,Error,4017,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623,1,['Error'],['Error']
Availability,.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). is.hail.utils.HailException: cannot set missing field for required type +PFloat64; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:207); 	at is.hail.io.vcf.VCFLine.parseAddInfoArrayDouble(LoadVCF.scala:1034); 	at is.hail.io.vcf.VCFLine.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7$adapted(LoadVCF.scala:1909); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:515); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at __C678stream_Let.apply(Emit.scala); 	at is.hail.expr.ir.CompileIterator$$anon$2.step(Compile.scala:302); 	at is.hail.expr.ir.CompileIterator$LongIt,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:18755,Error,ErrorHandling,18755,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['Error'],['ErrorHandling']
Availability,".hail/api/v1alpha/batches/485962/updates/1/jobs/create') body='500 Internal Server Error\n\nServer got itself in trouble'. ; Traceback (most recent call last):; File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 809, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/aiocloud/common/session.py"", line 117, in _request_with_valid_authn; return await self._http_session.request(method, url, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/httpx.py"", line 148, in request_and_raise_for_status; raise ClientResponseError(; hailtop.httpx.ClientResponseError: 500, message='Internal Server Error', url=URL('http://batch.hail/api/v1alpha/batches/485962/updates/1/jobs/create') body='500 Internal Server Error\n\nServer got itself in trouble'; 2024-09-25 01:54:55,288 - hailtop.utils 835 - WARNING - A transient error occured. We will automatically retry. We have thus far seen 50 transient errors (next delay: 60.0s).; ```. The corresponding server-side error was. ```; pymysql.err.DataError: (1406, \""Data too long for column 'value' at row 106\""); ```. coming from the `INSERT INTO job_attributes ` query in `insert_jobs_into_db()`. We write a list of the samples being processed as a job attribute, and it turned out that for at least some of the jobs of this batch this list had grown to longer than 64K of text. The `job_attributes.value` database field is of type TEXT, which limits each individual attribute to 64KiB bytes. While writing a long list of sample ids as an attribute may or may not be a great idea :smile: it is fair to say that 64K is not a large maximum for user-supplied data here in the 21st century!. It may be worth adding a database migration to change the `job_attributes.value` column type (and perhaps also that of `job_group_attributes.value`) from TEXT to MEDIUMTEXT, which would raise the limit to 16 MiB bytes (at, it appears, a cost of 1byte per r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14702:1668,error,errors,1668,https://hail.is,https://github.com/hail-is/hail/issues/14702,1,['error'],['errors']
Availability,".io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **454/1000** <br/> **Why?** Has a fix available, CVSS 4.8 | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315324) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **584/1000** <br/> **Why?** Has a fix available, CVSS 7.4 | Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315328](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315328) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Timing Attack <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315331](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315331) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:2656,avail,available,2656,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,".io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **454/1000** <br/> **Why?** Has a fix available, CVSS 4.8 | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315324) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **584/1000** <br/> **Why?** Has a fix available, CVSS 7.4 | Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315328](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315328) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Timing Attack <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315331](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315331) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:2648,avail,available,2648,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['avail'],['available']
Availability,".iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.21-1d317a44e5fd; Error summary: NoSuchElementException: key not found: GRCh37; ```. ### Error No. 2; ```python; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /usr/local/lib/python3.6/site-packages/IPython/core/formatters.py in __call__(self, obj); 343 method = get_real_method(obj, self.print_method); 344 if method is not None:; --> 345 return method(); 346 return None; 347 else:. /usr/local/lib/python3.6/site-packages/hail/matrixtable.py in _repr_html_(self); 2524 ; 2525 def _repr_html_(self):; -> 2526 s = self.table_show._repr_html_(); 2527 if self.displayed_n_cols != self.actual_n_cols:; 2528 s += '<p style=""background: #fdd; padding: 0.4em;"">'. /usr/local/lib/python3.6/site-packages/hail/table.py in _repr_html_(self); 1256 ; 1257 def _repr_html_(self):; -> 1258 return self._html_str(); 1259 ; 1260 def _ascii_str(self):. /usr/local/lib/python3.6/site-packages/hail/table.py in _html_str(self); 1342 types = self.types; 1343 ; -> 1344 rows, has_more, dtype = self.data(); 1345 fields = list(dtype); 1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:26250,Error,Error,26250,https://hail.is,https://github.com/hail-is/hail/issues/7044,1,['Error'],['Error']
Availability,".java:624); 	at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.115-71fc978b5c22; Error summary: SocketException: Connection reset. -------------------. Some more content from the failing worker job:. ...; 2023-05-04 01:04:35.959 : INFO: executing D-Array [shuffle_initial_write] with 1 tasks; 2023-05-04 01:04:35.960 : INFO: RegionPool: initialized for thread 8: pool-1-thread-1; 2023-05-04 01:04:35.965 GoogleStorageFS$: INFO: createNoCompression: gs://cpg-acute-care-hail/batch-tmp/tmp/hail/pV2Mgy4FVKSGKMwZGafyTh/hail_shuffle_temp_initial-ktRgTs8RfA9fHie5JKHmUy0e020450-e61c-4fa9-9419-2278528f3c86; 2023-05-04 01:04:37.559 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=132096, peakBytesReadable=129.00 KiB, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.560 : INFO: RegionPool: FREE: 129.0K allocated (129.0K blocks / 0 chunks), regions.size = 3, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.561 : ERROR: error while applying lowering 'LowerAndExecuteShuffles'; 2023-05-04 01:04:37.600 : INFO: RegionPool: initialized for thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.S",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:22900,ERROR,ERROR,22900,https://hail.is,https://github.com/hail-is/hail/issues/12983,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,".json.gz when loading VDS, create with HailContext.write_partitioning. Java stack trace:; is.hail.utils.HailException: missing partitioner.json.gz when loading VDS, create with HailContext.write_partitioning.; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:20); 	at is.hail.variant.VariantDataset$.liftedTree1$1(VariantDataset.scala:89); 	at is.hail.variant.VariantDataset$.read(VariantDataset.scala:84); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:414); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:413); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.HailContext.readAll(HailContext.scala:413); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: devel-2e237ca; Error summary: HailException: missing partitioner.json.gz when loading VDS, create with HailContext.write_partitioning.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1683:4491,Error,Error,4491,https://hail.is,https://github.com/hail-is/hail/issues/1683,1,['Error'],['Error']
Availability,.json4s.Extraction$ClassInstanceBuilder$$anonfun$result$6.apply(Extraction.scala:512); 	at org.json4s.Extraction$.org$json4s$Extraction$$customOrElse(Extraction.scala:524); 	at org.json4s.Extraction$ClassInstanceBuilder.result(Extraction.scala:512); 	at org.json4s.Extraction$.extract(Extraction.scala:351); 	at org.json4s.Extraction$ClassInstanceBuilder.org$json4s$Extraction$ClassInstanceBuilder$$mkWithTypeHint(Extraction.scala:507); 	at org.json4s.Extraction$ClassInstanceBuilder$$anonfun$result$6.apply(Extraction.scala:514); 	at org.json4s.Extraction$ClassInstanceBuilder$$anonfun$result$6.apply(Extraction.scala:512); 	at org.json4s.Extraction$.org$json4s$Extraction$$customOrElse(Extraction.scala:524); 	at org.json4s.Extraction$ClassInstanceBuilder.result(Extraction.scala:512); 	at org.json4s.Extraction$.extract(Extraction.scala:351); 	at org.json4s.Extraction$.extract(Extraction.scala:42); 	at org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21); 	at is.hail.variant.RelationalSpec$.read(MatrixTable.scala:69); 	at is.hail.expr.ir.TableIR$.read(TableIR.scala:23); 	at is.hail.table.Table$.read(Table.scala:56); 	at is.hail.HailContext.readTable(HailContext.scala:572); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-51961fa0ef80; Error summary: AssertionError: assertion failed```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4325:7956,Error,Error,7956,https://hail.is,https://github.com/hail-is/hail/issues/4325,1,['Error'],['Error']
Availability,".log</summary>. ```; 2018-10-09 15:04:33 Hail: INFO: SparkUI: http://10.32.119.167:4040; 2018-10-09 15:04:33 Hail: INFO: Running Hail version devel-17a988f2a628; 2018-10-09 15:04:33 SharedState: INFO: loading hive config file: file:/Users/michafla/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml; 2018-10-09 15:04:33 SharedState: INFO: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/').; 2018-10-09 15:04:33 SharedState: INFO: Warehouse path is 'file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/'.; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@16ba3696{/SQL,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2780d0b8{/SQL/json,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@7cea1161{/SQL/execution,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@696b1f0{/SQL/execution/json,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@14d32b0c{/static/sql,null,AVAILABLE,@Spark}; 2018-10-09 15:04:34 StateStoreCoordinatorRef: INFO: Registered StateStoreCoordinator endpoint; 2018-10-09 15:04:34 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 15:04:34 SparkSqlParser: INFO: Parsing command: SHOW TABLES; 2018-10-09 15:04:36 SparkContext: INFO: Starting job: collect at utils.scala:44; 2018-10-09 15:04:36 DAGScheduler: INFO: Got job 0 (collect at utils.scala:44) with 1 output partitions; 2018-10-09 15:04:36 DAGScheduler: INFO: Final stage: ResultStage 0 (collect at utils.scala:44); 2018-10-09 15:04:36 DAGScheduler: INFO: Parents of final stage: List(); 2018-10-09 15:04:36 DAGScheduler: INFO: Missing parents: List(); 2018-10-09 15:04:36 DAGSched",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:14386,AVAIL,AVAILABLE,14386,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['AVAIL'],['AVAILABLE']
Availability,".map(child => boundary(child.asInstanceOf[IR])); val x = if ((node.children, newChildren).zipped.forall(_ eq _)); node; else; node.copy(newChildren). if(x.typ.isInstanceOf[TArray]); ToStream(x); else; x; ```. IRSuite.testDictContains:. Before Lower: ; MakeTuple(ArrayBuffer((0,ApplyIR(contains,ArrayBuffer(GetTupleElement(In(0,PCTuple[0:PCDict[PInt32,PCString]]),0), NA(int32)))))); ...; before: ; ToArray(Ref(__iruid_56,dict<int32, str>)) of typ: array<struct{key: int32, value: str}>; after: Ref(__iruid_56,dict<int32, str>) of typ: dict<int32, str>. java.lang.AssertionError: assertion failed. 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.expr.ir.LowerArrayToStream$.is$hail$expr$ir$LowerArrayToStream$$boundary(LowerArrayToStream.scala:19). #### Fix:; ```scala; private def toStream(node: IR): IR = {; node match {; case _: ToStream => node; case _ => {; if(node.typ.isInstanceOf[TIterable]) {; ToStream(node); } else {; node; }; }; }; }; ```. New issues (many more failures in IRSuite, and surely plenty more in other tests):. First of these:; Before Lower: ; MakeTuple(ArrayBuffer((0,Let(__iruid_302,RunAgg(Begin(ArrayBuffer(Begin(ArrayBuffer(InitOp(0,ArrayBuffer(),AggStateSignature(Map(Sum() -> AggSignature(Sum(),ArrayBuffer(),ArrayBuffer(int64))),Sum(),None),Sum()))), ArrayFor(ArrayMap(ArrayRange(I32(0),I32(4),I32(1)),__iruid_304,Cast(Ref(__iruid_304,int32),int64)),__iruid_303,Begin(ArrayBuffer(SeqOp(0,ArrayBuffer(Ref(__iruid_303,int64)),AggStateSignature(Map(Sum() -> AggSignature(Sum(),ArrayBuffer(),ArrayBuffer(int64))),Sum(),None),Sum())))))),ResultOp(0,WrappedArray(AggStateSignature(Map(Sum() -> AggSignature(Sum(),ArrayBuffer(),ArrayBuffer(int64))),Sum(),None))),WrappedArray(AggStateSignature(Map(Sum() -> AggSignature(Sum(),ArrayBuffer(),ArrayBuffer(int64))),Sum(),None))),GetTupleElement(Ref(__iruid_302,tuple(int64)),0))))). After lower: ; MakeTuple(ArrayBuffer((0,Let(__iruid_302,RunAgg(Begin(ArrayBuffer(Begin(ArrayBuffer(InitOp(0,ArrayBuffer(),AggStateSignature",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-586602113:1711,failure,failures,1711,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-586602113,1,['failure'],['failures']
Availability,".nt2) &; (mt.alleles[1] == mt.ss.nt1)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt2) &; (flip_text(mt.alleles[1]) == mt.ss.nt1)),; mt.ss.ldpred_inf_beta); .or_missing()). # filter bgen matrixtable down to only SNPs with betas; mt = mt.filter_rows(hl.is_defined(mt.beta)). # filter bgen matrixtable to only include people in scoring sample; mt = mt.filter_cols(hl.is_defined(sampleids[mt.s])). # score sample; mt = mt.annotate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # write out table with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rv",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:2799,Failure,Failure,2799,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681,2,"['Failure', 'failure']","['Failure', 'failure']"
Availability,".py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/usr/local/lib/python3.10/dist-packages/hail/backend/py4j_backend.py"", line 220, in _rpc; raise fatal_error_from_java_error_triplet(; hail.utils.java.FatalError: HailException: VCF spec does not support phased haploid calls. Java stack trace:; is.hail.utils.HailException: VCF spec does not support phased haploid calls.; at __C83collect_distributed_array_matrix_vcf_writer.apply_region154_245(Unknown Source); at __C83collect_distributed_array_matrix_vcf_writer.apply_region133_246(Unknown Source); at __C83collect_distributed_array_matrix_vcf_writer.apply_region1_250(Unknown Source); at __C83collect_distributed_array_matrix_vcf_writer.apply(Unknown Source); at __C83collect_distributed_array_matrix_vcf_writer.apply(Unknown Source); at is.hail.backend.BackendUtils.$anonfun$collectDArray$19(BackendUtils.scala:142); at is.hail.utils.package$.using(package.scala:665); at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:170); at is.hail.backend.BackendUtils.$anonfun$collectDArray$18(BackendUtils.scala:141); at is.hail.backend.spark.SparkBackend$$anon$5.compute(SparkBackend.scala:474); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365); at org.apache.spark.rdd.RDD.iterator(RDD.scala:329); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:136); at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.127-bb535cd096c5; Error summary: HailException: VCF spec does not support phased haploid calls.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14330:3622,Error,Error,3622,https://hail.is,https://github.com/hail-is/hail/issues/14330,1,['Error'],['Error']
Availability,".py"", line 87, in docker_call_retry; return await f(*args, **kwargs); File ""/usr/local/lib/python3.6/site-packages/aiodocker/containers.py"", line 188, in start; data=kwargs; File ""/usr/local/lib/python3.6/site-packages/aiodocker/docker.py"", line 166, in _query; json.loads(what.decode('utf8'))); aiodocker.exceptions.DockerError: DockerError(500, 'OCI runtime start failed: container process is already dead: unknown'); ```. Unfortunately the batch worker had already died by this point. ```; {; ""batch_id"": 1,; ""job_id"": 19,; ""name"": ""18"",; ""state"": ""Error"",; ""exit_code"": null,; ""duration"": 10408,; ""msec_mcpu"": 1040800,; ""cost"": ""$0.0000"",; ""status"": {; ""worker"": ""batch-worker-dking-16py5"",; ""batch_id"": 1,; ""job_id"": 19,; ""attempt_id"": ""5cs0mg"",; ""user"": ""dking"",; ""state"": ""error"",; ""format_version"": 2,; ""container_statuses"": {; ""main"": {; ""name"": ""main"",; ""state"": ""error"",; ""timing"": {; ""pulling"": {; ""start_time"": 1580760856472,; ""finish_time"": 1580760856486,; ""duration"": 14; },; ""creating"": {; ""start_time"": 1580760856486,; ""finish_time"": 1580760856629,; ""duration"": 143; },; ""runtime"": {; ""start_time"": 1580760856630,; ""finish_time"": 1580760867038,; ""duration"": 10408; },; ""starting"": {; ""start_time"": 1580760856630,; ""finish_time"": 1580760867038,; ""duration"": 10408; }; },; ""error"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/site-packages/batch/worker.py\"", line 281, in run\n await docker_call_retry(self.container.start)\n File \""/usr/local/lib/python3.6/site-packages/batch/worker.py\"", line 87, in docker_call_retry\n return await f(*args, **kwargs)\n File \""/usr/local/lib/python3.6/site-packages/aiodocker/containers.py\"", line 188, in start\n data=kwargs\n File \""/usr/local/lib/python3.6/site-packages/aiodocker/docker.py\"", line 166, in _query\n json.loads(what.decode('utf8')))\naiodocker.exceptions.DockerError: DockerError(500, 'OCI runtime start failed: container process is already dead: unknown')\n""; }; },; ""start_time"": 1580760856630,; ""end_t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8029:1186,error,error,1186,https://hail.is,https://github.com/hail-is/hail/issues/8029,3,['error'],['error']
Availability,".rdd.RDD.treeReduce(RDD.scala:1037); at is.hail.methods.SampleQC$.results(SampleQC.scala:206); at is.hail.methods.SampleQC$.apply(SampleQC.scala:221); at is.hail.methods.SampleQC.apply(SampleQC.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745)is.hail.utils.HailException: invalid allele ""<DEL>""; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:29); at is.hail.methods.SampleQCCombiner$.alleleIndices(SampleQC.scala:44); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:178); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:175); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:175); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:170); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:7473,Error,ErrorHandling,7473,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['Error'],['ErrorHandling']
Availability,.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.load(HttpStorageRpc.java:726); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.lambda$readAllBytes$24(StorageImpl.java:574); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:60); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.run(StorageImpl.java:1476); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:574); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:563); 	at is.hail.io.fs.GoogleStorageFS.$anonfun$readNoCompression$1(GoogleStorageFS.scala:288); 	at is.hail.services.package$.retryTransientErrors(package.scala:163); 	at is.hail.io.fs.GoogleStorageFS.readNoCompression(GoogleStorageFS.scala:286); 	at is.hail.io.fs.RouterFS.readNoCompression(RouterFS.scala:26); 	at is.hail.backend.service.ServiceBackend$$anon$4.call(ServiceBackend.scala:239); 	at is.hail.backend.service.ServiceBackend$$anon$4.call(ServiceBackend.scala:235); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.120-f00f916faf78; Error summary: GoogleJsonResponseException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/wes-bipolar-tmp-4day/o/bge-wave-1-VQSR%2FparallelizeAndComputeWithIndex%2FgCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=%2Fresult.2706?alt=media; No such object: wes-bipolar-tmp-4day/bge-wave-1-VQSR/parallelizeAndComputeWithIndex/gCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=/result.2706; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13409:10009,Error,Error,10009,https://hail.is,https://github.com/hail-is/hail/issues/13409,2,"['Error', 'down']","['Error', 'download']"
Availability,.scala:139); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Hail version: devel-bfea6715901c; Error summary: HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4096:11336,Error,Error,11336,https://hail.is,https://github.com/hail-is/hail/issues/4096,2,"['Error', 'error']","['Error', 'error']"
Availability,.scala:303); 			at is.hail.backend.spark.SparkBackend.executeJSON(SparkBackend.scala:323); 			at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 			at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 			at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 			at java.lang.reflect.Method.invoke(Method.java:498); 			at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 			at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 			at py4j.Gateway.invoke(Gateway.java:282); 			at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 			at py4j.commands.CallCommand.execute(CallCommand.java:79); 			at py4j.GatewayConnection.run(GatewayConnection.java:238); 			at java.lang.Thread.run(Thread.java:748). 	org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 9 (runJob at RVD.scala:688) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:882) at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:878) at scala.collection.Iterator$class.foreach(Iterator.scala:891) at scala.collection.AbstractIterator.foreach(Iterator.scala:1334) at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:878) at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:691) at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:8553,failure,failure,8553,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['failure'],['failure']
Availability,".scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198); 	at is.hail.asm4s.ClassesBytes.load(ClassBuilder.scala:62); 	at is.hail.expr.ir.EmitClassBuilder$$anon$1.apply(EmitClassBuilder.scala:715); 	at is.hail.expr.ir.EmitClassBuilder$$anon$1.apply(EmitClassBuilder.scala:708); 	at is.hail.expr.ir.CompileIterator$.$anonfun$forTableStageToRVD$1(Compile.scala:311); 	at is.hail.expr.ir.CompileIterator$.$anonfun$forTableStageToRVD$1$adapted(Compile.scala:310); 	at is.hail.expr.ir.lowering.TableStageToRVD$.$anonfun$apply$9(RVDToTableStage.scala:106); 	at is.hail.sparkextras.ContextRDD.$anonfun$cflatMap$2(ContextRDD.scala:211); 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1234); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1233); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:131); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:498); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:501); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.105-3f053140ad00; Error summary: ClassFormatError: Too many arguments in method signature in class file __C2866stream; ```. This used to work fine in earlier Hail versions, e.g. 0.2.85.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:13805,Error,Error,13805,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['Error'],['Error']
Availability,".scala:618); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:50); 	at is.hail.table.Table.aggregate(Table.scala:373); 	at is.hail.table.Table.aggregate(Table.scala:369); 	at is.hail.table.Table.aggregateJSON(Table.scala:364); 	at sun.reflect.GeneratedMethodAccessor45.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-414f3f183bd5; Error summary: RuntimeException: Class file too large!; ```; Code was:; ```; cutoff = 10. agg_expr = {; 'downsampling': hl.agg.collect(ht.downsamplings)[0]; }; locations = list(zip(('syn', 'mis', 'lof'), ('', '', '_classic_hc'))); agg_expr.update({; f'median_expected_{var}_{pop}': [hl.median(hl.agg.collect(ht[f'exp_{var}_{pop}{var_loc}'][i])) for i in range(length)]; for length, pop in pop_lengths; for var, var_loc in locations; }); agg_expr.update({; f'median_observed_{var}_{pop}': [hl.median(hl.agg.collect(ht[f'obs_{var}_{pop}{var_loc}'][i])) for i in range(length)]; for length, pop in pop_lengths; for var, var_loc in locations; }); agg_expr.update({; f'mean_expected_{var}_{pop}': [hl.agg.mean(ht[f'exp_{var}_{pop}{var_loc}'][i]) for i in range(length)]; for length, pop in pop_lengths; for var, var_loc in locations; }); agg_expr.update({; f'mean_observed_{var}_{pop}': [hl.agg.mean(ht[f'obs_{var}_{pop}{var_loc}'][i]) for i in range(length)]; for length, pop in pop_lengths; for var, var_loc in locations; }); agg_expr.update({; f'fraction_expected_{var}_{pop}': [hl.agg.fraction(ht[f'exp_{var",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4516:1931,down,downsampling,1931,https://hail.is,https://github.com/hail-is/hail/issues/4516,1,['down'],['downsampling']
Availability,".serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:185); at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32); at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37); at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:199); at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:103); at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38). Hail version: 0.2-721af83bc30a; Error summary: OutOfMemoryError: GC overhead limit exceeded; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1035, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 883, in send_command; response = connection.send_command(command); File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1040, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:15075,Error,Error,15075,https://hail.is,https://github.com/hail-is/hail/issues/4780,4,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,.service.ServiceBackendSocketAPI2$.$anonfun$main$6$adapted(ServiceBackend.scala:460); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$5(ServiceBackend.scala:460); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:124); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4(ServiceBackend.scala:460); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4$adapted(ServiceBackend.scala:458); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$3(ServiceBackend.scala:458); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:124); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.main(ServiceBackend.scala:458); 	at is.hail.backend.service.Main$.main(Main.scala:33); 	at is.hail.backend.service.Main.main(Main.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:105); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.113-0b5bc2eb0c95; Error summary: SocketException: Connection reset; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:25994,Error,Error,25994,https://hail.is,https://github.com/hail-is/hail/issues/12982,1,['Error'],['Error']
Availability,".sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:4032,echo,echo,4032,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['echo'],['echo']
Availability,.spark.SparkBackend.executeJSON(SparkBackend.scala:323); 			at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 			at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 			at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 			at java.lang.reflect.Method.invoke(Method.java:498); 			at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 			at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 			at py4j.Gateway.invoke(Gateway.java:282); 			at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 			at py4j.commands.CallCommand.execute(CallCommand.java:79); 			at py4j.GatewayConnection.run(GatewayConnection.java:238); 			at java.lang.Thread.run(Thread.java:748). 	Hail version: 0.2.44-6cfa355a1954; 	Error summary: SparkException: Job aborted due to stage failure: ResultStage 9 (runJob at RVD.scala:688) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:882) at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:878) at scala.collection.Iterator$class.foreach(Iterator.scala:891) at scala.collection.AbstractIterator.foreach(Iterator.scala:1334) at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:878) at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:691) at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:15808,failure,failure,15808,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['failure'],['failure']
Availability,".spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-e6de08e; Error summary: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [3c5f402fed564ccd85257c0919d4bffb] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 128, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 109, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, output=output); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/gnomad_qc/hail/sample_qc/assign_subpops.py', '--cluster', 'gt1', '--files=gs://hail-common/builds/devel/jars/hail-devel-38dbf156b630-Spark-2.2.0.jar', '--py-files=gs://hail-common/builds/devel/python/hail-devel-38dbf156b630.zip,/var/folders/rn/t2xcx1ps4h96txll46qkkfsj2q8bnl/T/pyscripts_fYVAte.zip', '--properties=spark.executor.extraClassPath=./hail-devel-38dbf156b630-Spark-2.2.0.jar,spark.driver.extraClassPath=./hail-devel-38dbf156b630-Spark-2.2.0.jar,spark.files=./hail-devel-38dbf156b630-S",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:7675,ERROR,ERROR,7675,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627,1,['ERROR'],['ERROR']
Availability,"//]: # (snyk:metadata:{""prId"":""648a0aea-922c-46c9-b851-66c7e282d2e5"",""prPublicId"":""648a0aea-922c-46c9-b851-66c7e282d2e5"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.6""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr);  [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr);  [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14196:10739,avail,available,10739,https://hail.is,https://github.com/hail-is/hail/pull/14196,1,['avail'],['available']
Availability,"//github.com/michel-kraemer/gradle-download-task/commit/0f43ce67de72bd511d849c07bd7728c0d6f2e6dd""><code>0f43ce6</code></a> Document path and relativePath properties</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a8504f9d60d0264808894e4bb80d4a73b8086a3e""><code>a8504f9</code></a> Bump up version number to 5.3.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/708067cd11c4a013da7a8c15d91f7f946967cf94""><code>708067c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0fdebf3c7ad43ed4739d0400c333a72b32f5d514""><code>0fdebf3</code></a> Improve verify example</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/019089b9554692674d6baee7df7d4d884f310cc9""><code>019089b</code></a> Correctly create list of output files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/fa2739ded05333ba46d8f50bb3b2a3721cf0ca86""><code>fa2739d</code></a> Create target directories at a central place</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/02b8e1a79d9e00acd61f9ac42e5555619fe2247a""><code>02b8e1a</code></a> Prevent duplicate destination files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0b65ca2f17c8890a3ec34cf80cde52ee5413cbec""><code>0b65ca2</code></a> Call eachFile action only once per source</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/717877121299cea8f216d3a595eaa56731a6acd3""><code>7178771</code></a> Support changing a target file's relative path in an eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e5af1bd7f9daa8a9222aee0dd1b703727cb5e94e""><code>e5af1bd</code></a> Bump version number to 5.3.0-SNAPSHOT</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.3.0"">compare view</a></li>; </ul>; </d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:4111,down,download-task,4111,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download-task']
Availability,"//snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **444/1000** <br/> **Why?** Has a fix available, CVSS 4.6 | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **429/1000** <br/> **Why?** Has a fix available, CVSS 4.3 | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **501/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.3 | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14109:2731,avail,available,2731,https://hail.is,https://github.com/hail-is/hail/pull/14109,1,['avail'],['available']
Availability,"//snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **696/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-PYGMENTS-1088505](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1088505) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-5750273](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-5750273) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![medium severit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:5496,avail,available,5496,https://hail.is,https://github.com/hail-is/hail/pull/13717,2,['avail'],['available']
Availability,"/3717"">#3717</a>)</li>; <li>Updating content-type header for application/json to not contain charset field, according do RFC 8259 (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2154"">#2154</a>)</li>; <li>Fixing tests by bumping karma-sauce-launcher version (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3813"">#3813</a>)</li>; <li>Changing testing process from Travis CI to GitHub Actions (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3938"">#3938</a>)</li>; </ul>; <p>Documentation:</p>; <ul>; <li>Updating documentation around the use of <code>AUTH_TOKEN</code> with multiple domain endpoints (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3539"">#3539</a>)</li>; <li>Remove duplication of item in changelog (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3523"">#3523</a>)</li>; <li>Fixing gramatical errors (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2642"">#2642</a>)</li>; <li>Fixing spelling error (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3567"">#3567</a>)</li>; <li>Moving gitpod metion (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2637"">#2637</a>)</li>; <li>Adding new axios documentation website link (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3681"">#3681</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3707"">#3707</a>)</li>; <li>Updating documentation around dispatching requests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3772"">#3772</a>)</li>; <li>Adding documentation for the type guard isAxiosError (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3767"">#3767</a>)</li>; <li>Adding explanation of cancel token (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3803"">#3803</a>)</li>; <li>Updating CI status badge (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3953"">#3953</a>)</li>; <li>Fixing errors with J",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:3430,error,error,3430,https://hail.is,https://github.com/hail-is/hail/pull/11080,4,['error'],['error']
Availability,"/>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/v3.8.5/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.8.5 (2023-07-19)</h1>; <h2>Security bugfixes</h2>; <ul>; <li>; <p>Upgraded the vendored copy of llhttp_ to v8.1.1 -- by :user:<code>webknjaz</code>; and :user:<code>Dreamsorcerer</code>.</p>; <p>Thanks to :user:<code>sethmlarson</code> for reporting this and providing us with; comprehensive reproducer, workarounds and fixing details! For more; information, see; <a href=""https://github.com/aio-libs/aiohttp/security/advisories/GHSA-45c4-8wx5-qw6w"">https://github.com/aio-libs/aiohttp/security/advisories/GHSA-45c4-8wx5-qw6w</a>.</p>; <p>.. _llhttp: <a href=""https://llhttp.org"">https://llhttp.org</a></p>; <p><code>[#7346](https://github.com/aio-libs/aiohttp/issues/7346) &lt;https://github.com/aio-libs/aiohttp/issues/7346&gt;</code>_</p>; </li>; </ul>; <h2>Features</h2>; <ul>; <li>; <p>Added information to C parser exceptions to show which character caused the error. -- by :user:<code>Dreamsorcerer</code></p>; <p><code>[#7366](https://github.com/aio-libs/aiohttp/issues/7366) &lt;https://github.com/aio-libs/aiohttp/issues/7366&gt;</code>_</p>; </li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>; <p>Fixed a transport is :data:<code>None</code> error -- by :user:<code>Dreamsorcerer</code>.</p>; <p><code>[#3355](https://github.com/aio-libs/aiohttp/issues/3355) &lt;https://github.com/aio-libs/aiohttp/issues/3355&gt;</code>_</p>; </li>; </ul>; <hr />; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/9c13a52c21c23dfdb49ed89418d28a5b116d0681""><code>9c13a52</code></a> Bump aiohttp to v3.8.5 a security release</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/7c02129567bc4ec59be467b70fc937c82920948c""><code>7c02129</code></a>  Bump pypa/cibuildwheel to v2.14.1</li>; <li><a href=""https://",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13270:2526,error,error,2526,https://hail.is,https://github.com/hail-is/hail/pull/13270,5,['error'],['error']
Availability,"/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:111; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all_from_cache /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:115; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:91; STACK Bio::EnsEMBL::VEP::BaseRunner::get_all_AnnotationSources /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/BaseRunner.pm:175; STACK Bio::EnsEMBL::VEP::Runner::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/Runner.pm:123; STACK Bio::EnsEMBL::VEP::Runner::run /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/Runner.pm:194; STACK toplevel /opt/vep/src/ensembl-vep/vep:225; Date (localtime) = Mon Apr 29 23:53:34 2024; Ensembl API version = 95; ---------------------------------------------------. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 1.0 failed 20 times, most recent failure: Lost task 8.19 in stage 1.0 (TID 2899) (hail-test-w-1.australia-southeast1-a.c.pb-dev-312200.internal executor 3): is.hail.utils.HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:3430,failure,failure,3430,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['failure'],['failure']
Availability,"/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiocloud/common/base_client.py"", line 21, in request; async with await self._session.request(method, url, **kwargs) as resp:; File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiocloud/common/session.py"", line 103, in request; return await retry_transient_errors(self._request_with_valid_authn, method, url, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/utils/utils.py"", line 769, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/utils/utils.py"", line 785, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiocloud/common/session.py"", line 115, in _request_with_valid_authn; return await self._http_session.request(method, url, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/httpx.py"", line 138, in request_and_raise_for_status; raise ClientResponseError(; hailtop.httpx.ClientResponseError: 403, message='Forbidden', url=URL('https://storage.googleapis.com/storage/v1/b/hail-common?userProject=finngen-xavier') body='{\n ""error"": {\n ""code"": 403,\n ""message"": ""mkanai@broadinstitute.org does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission \'storage.buckets.get\' denied on resource (or it may not exist)."",\n ""errors"": [\n {\n ""message"": ""mkanai@broadinstitute.org does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission \'storage.buckets.get\' denied on resource (or it may not exist)."",\n ""domain"": ""global"",\n ""reason"": ""forbidden""\n }\n ]\n }\n}\n'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14291:5146,error,error,5146,https://hail.is,https://github.com/hail-is/hail/issues/14291,2,['error'],"['error', 'errors']"
Availability,"/api/v1alpha/batches/485962/updates/1/jobs/create') body='500 Internal Server Error\n\nServer got itself in trouble'. ; Traceback (most recent call last):; File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 809, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/aiocloud/common/session.py"", line 117, in _request_with_valid_authn; return await self._http_session.request(method, url, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/httpx.py"", line 148, in request_and_raise_for_status; raise ClientResponseError(; hailtop.httpx.ClientResponseError: 500, message='Internal Server Error', url=URL('http://batch.hail/api/v1alpha/batches/485962/updates/1/jobs/create') body='500 Internal Server Error\n\nServer got itself in trouble'; 2024-09-25 01:54:55,288 - hailtop.utils 835 - WARNING - A transient error occured. We will automatically retry. We have thus far seen 50 transient errors (next delay: 60.0s).; ```. The corresponding server-side error was. ```; pymysql.err.DataError: (1406, \""Data too long for column 'value' at row 106\""); ```. coming from the `INSERT INTO job_attributes ` query in `insert_jobs_into_db()`. We write a list of the samples being processed as a job attribute, and it turned out that for at least some of the jobs of this batch this list had grown to longer than 64K of text. The `job_attributes.value` database field is of type TEXT, which limits each individual attribute to 64KiB bytes. While writing a long list of sample ids as an attribute may or may not be a great idea :smile: it is fair to say that 64K is not a large maximum for user-supplied data here in the 21st century!. It may be worth adding a database migration to change the `job_attributes.value` column type (and perhaps also that of `job_group_attributes.value`) from TEXT to MEDIUMTEXT, which would raise the limit to 16 MiB bytes (at, it appears, a cost of 1byte per row).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14702:1732,error,error,1732,https://hail.is,https://github.com/hail-is/hail/issues/14702,1,['error'],['error']
Availability,"/astroid/issues/1282"">#1282</a>; Ref <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1103"">#1103</a></p>; </li>; <li>; <p>Fixed crash with recursion error for inference of class attributes that referenced; the class itself.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5408"">PyCQA/pylint#5408</a></p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/astroid/commit/07c0f60ffc1017d0a9a2bb605a5c645781a8c088""><code>07c0f60</code></a> Bump astroid to 2.10.0, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/e6dc5ef0f8c2d28bc9d2ffa226fbb5e4e58d88f3""><code>e6dc5ef</code></a> Fix some typoes in the Changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/b6d17107f2e02df4ce5080536bb783a25273b33f""><code>b6d1710</code></a> Changed NodeNG.tolineno to use end_lineno when it is available (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1351"">#1351</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/0acb961d7375131c3d1e7a3580f974b6e8c5ef94""><code>0acb961</code></a> Refactor: Stop adding arbitrary attributes to module obj when building (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1215"">#1215</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/62aa3bb63c3ca0cda19a1bb294a6b052c2346189""><code>62aa3bb</code></a> Restore custom distutils handling for resolving paths to submodules. (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1386"">#1386</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/8f7f07898720b875cfbf447a7106875db4a904b3""><code>8f7f078</code></a> Limit expensive decorator function (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1407"">#1407</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/98280b57b5ed3db8a4d431cb60e21f136",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11463:3724,avail,available,3724,https://hail.is,https://github.com/hail-is/hail/pull/11463,2,['avail'],['available']
Availability,"/build/distributions/hail-python.zip/hail/matrixtable.py in count(self); 2129 Number of rows, number of cols.; 2130 """"""; -> 2131 r = self._jmt.count(); 2132 return r._1(), r._2(); 2133. /share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container marked as failed: container_e2435_1542127286896_0109_02_000004 on host: scc-q06.scc.bu.edu. Exit status: 1. Diagnostics: Exception from container-launch.; Container id: container_e2435_1542127286896_0109_02_000004; Exit code: 1; Stack trace: ExitCodeException exitCode=1:; at org.apache.hadoop.util.Shell.runCommand(Shell.java:576); at org.apache.hadoop.util.Shell.run(Shell.java:487); at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:753); at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:371); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:303); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); at java",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-446057705:1687,failure,failure,1687,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-446057705,1,['failure'],['failure']
Availability,"/code> and <code>category_orders</code> now available in <code>px.pie()</code> <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3775"">#3775</a></li>; </ul>; <h3>Performance</h3>; <ul>; <li><code>px</code> methods no longer call <code>groupby</code> on the input dataframe when the result would be a single group, and no longer groups by a lambda, for significant speedups <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3765"">#3765</a> with thanks to <a href=""https://github.com/jvdd""><code>@jvdd</code></a></li>; </ul>; <h3>Updated</h3>; <ul>; <li>Allow non-string extras in <code>flaglist</code> attributes, to support upcoming changes to <code>ax.automargin</code> in plotly.js <a href=""https://github-redirect.dependabot.com/plotly/plotly.js/pull/6193"">plotly.js#6193</a>, <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3749"">#3749</a></li>; </ul>; <h2>[5.8.2] - 2022-06-10</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed a syntax error that caused rendering issues in Databricks notebooks and likely elsewhere. <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3763"">#3763</a> with thanks to <a href=""https://github.com/fwetdb""><code>@fwetdb</code></a></li>; </ul>; <h2>[5.8.1] - 2022-06-08</h2>; <p>(no changes, due to a mixup with the build process!)</p>; <h2>[5.8.0] - 2022-05-09</h2>; <h3>Fixed</h3>; <ul>; <li>Improve support for type checking and IDE auto-completion by bypassing lazy-loading when type checking. <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3425"">#3425</a> with thanks to <a href=""https://github.com/JP-Ellis""><code>@JP-Ellis</code></a></li>; <li>line dash-style validators are now correctly used everywhere so that values like <code>10px 2px</code> are accepted <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3722"">#3722</a></li>; <li>Resolved various deprecation warning messages and compatibility issues with upstream dependencies and Python 3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12113:3193,error,error,3193,https://hail.is,https://github.com/hail-is/hail/pull/12113,1,['error'],['error']
Availability,"/code></a> Release v3.9.4 (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8201"">#8201</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/a7e240a9f625a0b9559bdf5f0049c71565352400""><code>a7e240a</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8320"">#8320</a>/9ba9a4e5 backport][3.9] Fix Python parser to mark responses without...</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/28335525d1eac015a7e7584137678cbb6ff19397""><code>2833552</code></a> Escape filenames and paths in HTML when generating index pages (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8317"">#8317</a>) (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8319"">#8319</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/ed43040613988fc4666109aca82a5180ff165df5""><code>ed43040</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8309"">#8309</a>/c29945a1 backport][3.9] Improve reliability of run_app test (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8315"">#8315</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/ec2be0500e2674eea019c0966a7a905e9b3d6608""><code>ec2be05</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8299"">#8299</a>/28d026eb backport][3.9] Create marker for internal tests (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8307"">#8307</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/292d961f4ee2829a1b13fad92444a4fd693fbc87""><code>292d961</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8304"">#8304</a>/88c80c14 backport][3.9] Check for backports in CI (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8305"">#8305</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/cebe526b9c34dc3a3da9140409db63014bc4cf19""><code>cebe526</code></a> Fix handling of multipart/form-data (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/828",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14477:4899,reliab,reliability,4899,https://hail.is,https://github.com/hail-is/hail/pull/14477,6,['reliab'],['reliability']
Availability,"/commit/019089b9554692674d6baee7df7d4d884f310cc9""><code>019089b</code></a> Correctly create list of output files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/fa2739ded05333ba46d8f50bb3b2a3721cf0ca86""><code>fa2739d</code></a> Create target directories at a central place</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/02b8e1a79d9e00acd61f9ac42e5555619fe2247a""><code>02b8e1a</code></a> Prevent duplicate destination files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0b65ca2f17c8890a3ec34cf80cde52ee5413cbec""><code>0b65ca2</code></a> Call eachFile action only once per source</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/717877121299cea8f216d3a595eaa56731a6acd3""><code>7178771</code></a> Support changing a target file's relative path in an eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e5af1bd7f9daa8a9222aee0dd1b703727cb5e94e""><code>e5af1bd</code></a> Bump version number to 5.3.0-SNAPSHOT</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=3.2.0&new-version=5.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:4895,down,download-task,4895,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download-task']
Availability,"/compare/4.0.0...4.0.1"">https://github.com/samtools/htsjdk/compare/4.0.0...4.0.1</a></p>; <h2>4.0.0</h2>; <h2>Moving forward</h2>; <p>This is the first release to be built exclusively for java 17. Java 17 features are now allowed in our source code and we will no longer support older versions of java. We've also updated dependencies to fix security issues. There are several small bug fixes as well.</p>; <h3>JSON dependency:</h3>; <p>We've dropped the MJSON library which was no longer being updated and replaced it with a similarly small json library from org.json</p>; <h2>What's Changed</h2>; <ul>; <li>Migrate to Java 17 by <a href=""https://github.com/lbergelson""><code>@lbergelson</code></a> in <a href=""https://redirect.github.com/samtools/htsjdk/pull/1649"">samtools/htsjdk#1649</a></li>; <li>Remove low-value progress logging message by <a href=""https://github.com/nh13""><code>@nh13</code></a> in <a href=""https://redirect.github.com/samtools/htsjdk/pull/1659"">samtools/htsjdk#1659</a></li>; <li>removed redundant code by <a href=""https://github.com/KleinSamuel""><code>@KleinSamuel</code></a> in <a href=""https://redirect.github.com/samtools/htsjdk/pull/1664"">samtools/htsjdk#1664</a></li>; <li>Update snappy-java and migrate mjson to org.json to address CVEs by <a href=""https://github.com/bbimber""><code>@bbimber</code></a> in <a href=""https://redirect.github.com/samtools/htsjdk/pull/1670"">samtools/htsjdk#1670</a></li>; <li>Remove incorrect zero-length-B-array checks <a href=""https://github.com/gileshall""><code>@gileshall</code></a> and <a href=""https://github.com/jmarshall""><code>@jmarshall</code></a> in <a href=""https://redirect.github.com/samtools/htsjdk/pull/1674"">samtools/htsjdk#1674</a></li>; <li>add SINGULAR platform to read group by <a href=""https://github.com/omicsorama""><code>@omicsorama</code></a> in <a href=""https://redirect.github.com/samtools/htsjdk/pull/1635"">samtools/htsjdk#1635</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://gith",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13576:2222,redundant,redundant,2222,https://hail.is,https://github.com/hail-is/hail/pull/13576,1,['redundant'],['redundant']
Availability,"/dataset""},; ""version"": ""one_version""},; {""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""another_version""}]}; ```. The `annotation_db.json` file is now used by the `load_dataset()` function in `datasets.py` as well, any dataset in the JSON file should now be able to be loaded this way. Made changes to the following:; - `DB` class now requires a `region` parameter.; - `Dataset.from_name_and_json()` has had a `custom_config` parameter added that indicates whether or not the user has supplied their own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9496:1619,avail,available,1619,https://hail.is,https://github.com/hail-is/hail/pull/9496,1,['avail'],['available']
Availability,"/dking/miniconda3/lib/python3.10/site-packages/pyspark/conf/spark-defaults.conf) and either an explicit argument or through `hailctl config`. For GCS requester pays configuration, Hail first checks explicit arguments, then `hailctl config`, then spark-defaults.conf.; warnings.warn(; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 3.3.3; SparkUI available at http://192.168.1.142:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.125-c4e2880b3279; LOGGING: writing to /Users/dking/projects/hail/hail/hail-20231026-0957-0.2.125-c4e2880b3279.log; --------------------------------------------------------------------------- / 1]; FatalError Traceback (most recent call last); Cell In[1], line 2; 1 import hail as hl; ----> 2 hl.import_vcf('gs://danking/chr*.vcf').count(). File ~/miniconda3/lib/python3.10/site-packages/hail/matrixtable.py:2631, in MatrixTable.count(self); 2618 """"""Count the number of rows and columns in the matrix.; 2619 ; 2620 Examples; (...); 2628 Number of rows, number of cols.; 2629 """"""; 2630 count_ir = ir.MatrixCount(self._mir); -> 2631 return Env.backend().execute(count_ir). File ~/miniconda3/lib/python3.10/site-packages/hail/backend/backend.py:180, in Backend.execute(self, ir, timed); 178 result, timings = self._rpc(ActionTag.EXECUTE, payload); 179 except FatalError as e:; --> 180",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13915:2345,avail,available,2345,https://hail.is,https://github.com/hail-is/hail/issues/13915,1,['avail'],['available']
Availability,"/driver/main.py"", line 1288, in monitor_billing_limits; records = await query_billing_projects_with_cost(db); File ""/usr/local/lib/python3.9/dist-packages/batch/utils.py"", line 165, in query_billing_projects_with_cost; async for record in db.select_and_fetchall(sql, tuple(args)):; File ""/usr/local/lib/python3.9/dist-packages/gear/database.py"", line 339, in select_and_fetchall; async for row in tx.execute_and_fetchall(sql, args, query_name):; File ""/usr/local/lib/python3.9/dist-packages/gear/database.py"", line 254, in execute_and_fetchall; await cursor.execute(sql, args); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/cursors.py"", line 239, in execute; await self._query(query); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/cursors.py"", line 457, in _query; await conn.query(q); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 469, in query; await self._read_query_result(unbuffered=unbuffered); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 683, in _read_query_result; await result.read(); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 1172, in read; await self._read_result_packet(first_packet); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 1232, in _read_result_packet; await self._read_rowdata_packet(); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 1282, in _read_rowdata_packet; packet = await self.connection._read_packet(); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 652, in _read_packet; packet.raise_for_error(); File ""/usr/local/lib/python3.9/dist-packages/pymysql/protocol.py"", line 221, in raise_for_error; err.raise_mysql_exception(self._data); File ""/usr/local/lib/python3.9/dist-packages/pymysql/err.py"", line 143, in raise_mysql_exception; raise errorclass(errno, errval); pymysql.err.OperationalError: (1213, 'Deadlock found when trying to get lock; try restarting transaction'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14423:2903,error,errorclass,2903,https://hail.is,https://github.com/hail-is/hail/issues/14423,1,['error'],['errorclass']
Availability,"/elastic/elasticsearch-hadoop) from 7.17.1 to 8.4.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch-hadoop/releases"">elasticsearch-spark-20_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.4.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html</a></p>; <h2>Elasticsearch Hadoop 8.4.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12358:1039,down,downloads,1039,https://hail.is,https://github.com/hail-is/hail/pull/12358,1,['down'],['downloads']
Availability,"/expr/expression.py in eval_expr_typed(expression); 3612 if len(expression._joins) > 0:; 3613 raise ExpressionException(""'eval_expr' methods do not support joins or broadcasts""); -> 3614 r, t = Env.hc().eval_expr_typed(expression._ast.to_hql()); 3615 return r, t; 3616. <decorator-gen-1049> in eval_expr_typed(self, expr). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/utils/java.py in handle_py4j(func, *args, **kwargs); 153 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 154 'Hail version: %s\n'; --> 155 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); 156 except py4j.protocol.Py4JError as e:; 157 if e.args[0].startswith('An error occurred while calling'):. FatalError: HailException: `(' expected but `i' found; <input>:1:(if (true) ""T"" else ""F"" + if (true) ""T"" else ""F""); ^. Java stack trace:; is.hail.utils.HailException: `(' expected but `i' found; <input>:1:(if (true) ""T"" else ""F"" + if (true) ""T"" else ""F""); ^; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:27); 	at is.hail.expr.ParserUtils$.error(Parser.scala:32); 	at is.hail.expr.RichParser.parse(Parser.scala:16); 	at is.hail.expr.Parser$.parseExpr(Parser.scala:85); 	at is.hail.HailContext.eval(HailContext.scala:613); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2653:2657,Error,ErrorHandling,2657,https://hail.is,https://github.com/hail-is/hail/issues/2653,1,['Error'],['ErrorHandling']
Availability,"/fonttools/issues/3020"">#3020</a>).</li>; <li>[cython] Prevent <code>cython.compiled</code> raise AttributeError if cython not installed properly (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3017"">#3017</a>).</li>; <li>[OS/2] Guard against ZeroDivisionError when calculating xAvgCharWidth in the unlikely scenario no glyph has non-zero advance (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3015"">#3015</a>).</li>; <li>[subset] Recompute xAvgCharWidth independently of --no-prune-unicode-ranges, previously the two options were involuntarily bundled together (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3012"">#3012</a>).</li>; <li>[fontBuilder] Add <code>debug</code> parameter to addOpenTypeFeatures method to add source debugging information to the font in the <code>Debg</code> private table (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3008"">#3008</a>).</li>; <li>[name] Make NameRecord <code>__lt__</code> comparison not fail on Unicode encoding errors (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3006"">#3006</a>).</li>; <li>[featureVars] Fixed bug in <code>overlayBox</code> (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3003"">#3003</a>, <a href=""https://redirect.github.com/fonttools/fonttools/issues/3005"">#3005</a>).</li>; <li>[glyf] Added experimental support for cubic bezier curves in TrueType glyf table, as outlined in glyf v1 proposal (<a href=""https://redirect.github.com/fonttools/fonttools/issues/2988"">#2988</a>):<br />; <a href=""https://github.com/harfbuzz/boring-expansion-spec/blob/main/glyf1-cubicOutlines.md"">https://github.com/harfbuzz/boring-expansion-spec/blob/main/glyf1-cubicOutlines.md</a></li>; <li>Added new qu2cu module and related qu2cuPen, the reverse of cu2qu for converting TrueType quadratic splines to cubic bezier curves (<a href=""https://redirect.github.com/fonttools/fonttools/issues/2993"">#2993</a>).</li>; <li>[glyf] Added experimental s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12910:5174,error,errors,5174,https://hail.is,https://github.com/hail-is/hail/pull/12910,1,['error'],['errors']
Availability,"/hail/typecheck/check.py in _typecheck(__orig_func__, *args, **kwargs); 479 def _typecheck(__orig_func__, *args, **kwargs):; 480 args_, kwargs_ = check_all(__orig_func__, args, kwargs, checkers, is_method=True); --> 481 return __orig_func__(*args_, **kwargs_); 482; 483 return decorator(_typecheck). ~/tools/hail/python/hail/table.py in _select(self, caller, s); 377 base, cleanup = self._process_joins(s); 378 analyze(caller, s, self._row_indices); --> 379 return cleanup(Table(base._jt.select(s._ast.to_hql()))); 380; 381 @typecheck_method(caller=str, s=expr_struct()). ~/tools/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. ~/tools/hail/python/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: ClassCastException: java.lang.Integer cannot be cast to java.lang.Double. Java stack trace:; java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.Double; 	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114); 	at is.hail.expr.ir.Literal$.apply(IR.scala:31); 	at is.hail.expr.ir.functions.UtilFunctions$$anonfun$registerAll$2.apply(UtilFunctions.scala:22); 	at is.hail.expr.ir.functions.UtilFunctions$$anonfun$registerAll$2.apply(UtilFunctions.scala:18); 	at is.hail.expr.ir.functions.RegistryFunctions$$anonfun$registerIR$2.apply(Functions.scala:165); 	at is.hail.expr.ir.functions.RegistryFunctions$$anonfun$registerIR$2.apply(Functions.scala:165); 	at is.hail.expr.ApplyMethod$$anonfun$toIR$12$$anonfun$apply$58.apply(AST.scala",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3436:4006,Error,Error,4006,https://hail.is,https://github.com/hail-is/hail/issues/3436,1,['Error'],['Error']
Availability,"/issues/458"">#458</a>)</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Changed DockerNetwork.delete() to return True if successful (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/464"">#464</a>)</li>; </ul>; <h1>0.18.9 (2020-07-07)</h1>; <p>Bugfixes</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiodocker/commit/234522e191d208bab11175e2684b02ed9caedc43""><code>234522e</code></a> Bump to 0.21.0</li>; <li><a href=""https://github.com/aio-libs/aiodocker/commit/9b459934c3b1fde2fb9f0fa4e692be2403994cda""><code>9b45993</code></a> Fix <a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/536"">#536</a>: ssl_context not used (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/607"">#607</a>)</li>; <li><a href=""https://github.com/aio-libs/aiodocker/commit/72c157378490cfd4ef463759169c8be2bdfbfd19""><code>72c1573</code></a> Fix error when Stream is closed after container stopped (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/608"">#608</a>)</li>; <li><a href=""https://github.com/aio-libs/aiodocker/commit/e35e9698c93d5e9df59e81267a65ff355109af5c""><code>e35e969</code></a> Bump to 0.20.0</li>; <li><a href=""https://github.com/aio-libs/aiodocker/commit/d85e607f2c3d100b6415273665e75bc1fd75657c""><code>d85e607</code></a> Fix <a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/295"">#295</a>: allow passing credentials into run() call to pulling absent image f...</li>; <li><a href=""https://github.com/aio-libs/aiodocker/commit/2ad735b17d4ee7c1b1617373d2858ae776672ef3""><code>2ad735b</code></a> Fix <a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/295"">#295</a>: allow passing credentials into run() call to pulling absent image f...</li>; <li><a href=""https://github.com/aio-libs/aiodocker/commit/50421c40815af68e066cad81eaf57e899ec42415""><code>504",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11537:3705,error,error,3705,https://hail.is,https://github.com/hail-is/hail/pull/11537,1,['error'],['error']
Availability,"/li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.24 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2158"">#2158</a>) (<a href=""https://github.com/googleapis/java-storage/commit/4f5682a4f6d6d5372a2d382ae3e47dace490ca0d"">4f5682a</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.25.0...v2.26.0"">2.26.0</a> (2023-08-03)</h2>; <h3>Features</h3>; <ul>; <li>Implement BufferToDiskThenUpload BlobWriteSessionConfig (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2139"">#2139</a>) (<a href=""https://github.com/googleapis/java-storage/commit/4dad2d5c3a81eda7190ad4f95316471e7fa30f66"">4dad2d5</a>)</li>; <li>Introduce new BlobWriteSession (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2123"">#2123</a>) (<a href=""https://github.com/googleapis/java-storage/commit/e0191b518e50a49fae0691894b50f0c5f33fc6af"">e0191b5</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li><strong>grpc:</strong> Return error if credentials are detected to be null (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2142"">#2142</a>) (<a href=""https://github.com/googleapis/java-storage/commit/b61a9764a9d953d2b214edb2b543b8df42fbfa06"">b61a976</a>)</li>; <li>Possible NPE when HttpStorageOptions deserialized (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2153"">#2153</a>) (<a href=""https://github.com/googleapis/java-storage/commit/68ad8e7357097e3dd161c2ab5f7a42a060a3702c"">68ad8e7</a>)</li>; <li>Update grpc default metadata projection to include acl same as json (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2150"">#2150</a>) (<a href=""https://github.com/googleapis/java-storage/commit/330e795040592e5df22d44fb5216ad7cf2448e81"">330e795</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.14.0 (<a href=""https://redirect.github.com/google",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13605:6544,error,error,6544,https://hail.is,https://github.com/hail-is/hail/pull/13605,1,['error'],['error']
Availability,"/li>; <li>Fix TXT CHAOS test</li>; <li>Add support for CAA queries</li>; <li>Support Python &gt;= 3.6</li>; <li>Bump pycares dependency</li>; <li>Drop tasks.py</li>; <li>Allow specifying dnsclass for queries</li>; <li>Set URL to https</li>; <li>Add license args in setup.py</li>; <li>Converted Type Annotations to Py3 syntax Closes</li>; <li>Only run mypy on cpython versions</li>; <li>Also fix all type errors with latest mypy - pycares seems to have no typing / stubs so lets ignore it via <code>mypy.ini</code></li>; <li>setup: typing exists since Python 3.5</li>; <li>Fix type annotation of gethostbyname()</li>; <li>Updated README</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/saghul/aiodns/blob/master/ChangeLog"">aiodns's changelog</a>.</em></p>; <blockquote>; <h1>3.0.0</h1>; <ul>; <li>Release wheels and source to PyPI with GH actions</li>; <li>Try to make tests more resilient</li>; <li>Don't build universal wheels</li>; <li>Migrate CI to GH Actions</li>; <li>Fix TXT CHAOS test</li>; <li>Add support for CAA queries</li>; <li>Support Python &gt;= 3.6</li>; <li>Bump pycares dependency</li>; <li>Drop tasks.py</li>; <li>Allow specifying dnsclass for queries</li>; <li>Set URL to https</li>; <li>Add license args in setup.py</li>; <li>Converted Type Annotations to Py3 syntax Closes</li>; <li>Only run mypy on cpython versions</li>; <li>Also fix all type errors with latest mypy - pycares seems to have no typing / stubs so lets ignore it via <code>mypy.ini</code></li>; <li>setup: typing exists since Python 3.5</li>; <li>Fix type annotation of gethostbyname()</li>; <li>Updated README</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/saghul/aiodns/commit/cdb33385f46be1e18bc525ccb153c8abc8ac92d4""><code>cdb3338</code></a> Updated changelog</li>; <li><a href=""https://github.com/saghul/aiodns/commit/a57968007a0e6f826e1a8a2160eade23c254bc42",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11570:1387,resilien,resilient,1387,https://hail.is,https://github.com/hail-is/hail/pull/11570,1,['resilien'],['resilient']
Availability,"/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py"", line 418, in start; resp = await task; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 458, in _handle; resp = await handler(request); File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_urldispatcher.py"", line 157, in handler_wrapper; result = await result; File ""/usr/local/lib/python3.6/dist-packages/batch/batch.py"", line 914, in create_jobs; success = await jobs_builder.commit(); File ""/usr/local/lib/python3.6/dist-packages/batch/database.py"", line 161, in commit; await cursor.executemany(self._jobs_sql, self._jobs); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py"", line 283, in executemany; self._get_db().encoding)); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py"", line 318, in _do_execute_many; r = await self.execute(sql + postfix); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py"", line 239, in execute; await self._query(query); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py"", line 457, in _query; await conn.query(q); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py"", line 428, in query; await self._read_query_result(unbuffered=unbuffered); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py"", line 622, in _read_query_result; await result.read(); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py"", line 1105, in read; first_packet = await self.connection._read_packet(); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py"", line 593, in _read_packet; packet.check_error(); File ""/usr/local/lib/python3.6/dist-packages/pymysql/protocol.py"", line 220, in check_error; err.raise_mysql_exception(self._data); File ""/usr/local/lib/python3.6/dist-packages/pymysql/err.py"", line 109, in raise_mysql_exception; raise errorclass(errno, errval); pymysql.err.OperationalError: (1213, 'Deadlock found when trying to get lock; try restarting transaction'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6543:4795,error,errorclass,4795,https://hail.is,https://github.com/hail-is/hail/issues/6543,1,['error'],['errorclass']
Availability,"/python/hail/typecheck/check.py"", line 481, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/restricted/projectnb/genpro/github/hail/python/hail/matrixtable.py"", line 1935, in write; self._jvds.write(output, overwrite, _codec_spec); File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; see the Hail log for the full offending line. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 2.0 failed 4 times, most recent failure: Lost task 20.3 in stage 2.0 (TID 485, scc-q08.scc.bu.edu, executor 2): is.hail.utils.HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; see the Hail log for the full offending line; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:12); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:744); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:413); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:815); at scala.collection.Iterator$$anon$12.hasN",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3379:3007,failure,failure,3007,https://hail.is,https://github.com/hail-is/hail/issues/3379,1,['failure'],['failure']
Availability,"/snyk.io/vuln/SNYK-PYTHON-IPYTHON-2348630) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `2.11.3 -> 3.1.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **604/1000** <br/> **Why?** Has a fix available, CVSS 7.8 | Improper Privilege Management <br/>[SNYK-PYTHON-JUPYTERCORE-3063766](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERCORE-3063766) | `jupyter-core:` <br> `4.6.3 -> 4.11.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-MISTUNE-2940625](https://snyk.io/vuln/SNYK-PYTHON-MISTUNE-2940625) | `mistune:` <br> `0.8.4 -> 2.0.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **726/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 8.1 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:3247,avail,available,3247,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['avail'],['available']
Availability,/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:111; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all_from_cache /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:115; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:91; STACK Bio::EnsEMBL::VEP::BaseRunner::get_all_AnnotationSources /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/BaseRunner.pm:175; STACK Bio::EnsEMBL::VEP::Runner::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/Runner.pm:123; STACK Bio::EnsEMBL::VEP::Runner::run /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/Runner.pm:194; STACK toplevel /opt/vep/src/ensembl-vep/vep:225; Date (localtime) = Mon Apr 29 23:53:34 2024; Ensembl API version = 95; ---------------------------------------------------. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:19); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:19); 	at is.hail.utils.package$.fatal(package.scala:89); 	at is.hail.methods.VEP$.waitFor(VEP.scala:73); 	at is.hail.methods.VEP.$anonfun$execute$5(VEP.scala:244); 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.utils.richUtils.RichContextRDD$$anon$1.hasNext(RichContextRDD.scala:77); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at __C1310collect_distributed_array_table_native_writer.apply_region1_87(Unknown Source); 	at __C1310collect_distributed_array_table_native_writer.apply(Unknown Source); 	at __C1310collect_distr,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:6009,Error,ErrorHandling,6009,https://hail.is,https://github.com/hail-is/hail/issues/14513,2,['Error'],['ErrorHandling']
Availability,"/summary>. ```; pytest-html 1.22.1 requires pytest-metadata, which is not installed.; jupyter 1.0.0 requires qtconsole, which is not installed.; jupyter 1.0.0 requires notebook, which is not installed.; curlylint 0.13.1 requires pathspec, which is not installed.; beautifulsoup4 4.12.3 requires soupsieve, which is not installed.; astroid 2.15.8 requires lazy-object-proxy, which is not installed.; argon2-cffi-bindings 21.2.0 requires cffi, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14365:1453,avail,available,1453,https://hail.is,https://github.com/hail-is/hail/pull/14365,1,['avail'],['available']
Availability,"/ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1b5d69760d19cb7f88cbc837ee46456c494c0696""><code>1b5d697</code></a> Bump up version number to 5.2.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/7d6de83037ca41cd2f2f31830b43e43720e45b3a""><code>7d6de83</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1da8f078e22412475b694ce07b890148b8a5e4fc""><code>1da8f07</code></a> Add comment</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/9703f764df56c52626f7d6f44bca8b1d51312389""><code>9703f76</code></a> Use pooling connection manager instead of basic one</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/306172e4c6532e185c8a6a9998bca7d22d2d0c63""><code>306172e</code></a> Bump up version number to 5.2.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b9df0c0daa080450772c365f16a9406fe0ca607a""><code>b9df0c0</code></a> Document eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/05a4433770f7020ff845add9348bdc12c82793dd""><code>05a4433</code></a> Add eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/09d1eca91afbf21ace3672be24c68d9028ee1e33""><code>09d1eca</code></a> Document runAsync method</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/800e3df1647c5ce65bffdd25c3240dfa5244e6c5""><code>800e3df</code></a> Add runAsync method to download extension</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/80f04c6a46fe7df053ac55bcfc6f90ff74c4b873""><code>80f04c6</code></a> Bump up version number to 5.1.3</li>; <li>Additional commits viewable in ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:3756,down,download-task,3756,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['down'],['download-task']
Availability,/us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc \; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc \; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc \; WHEEL_FOR_AZURE= \; WEBSITE_TAR=/path/to/www.tar.gz \; hail/scripts/release.sh. +++ dirname -- hail/scripts/release.sh; ++ cd -- hail/scripts; ++ pwd; + SCRIPT_DIR=/Users/dking/projects/hail/hail/scripts; + arguments='HAIL_PIP_VERSION HAIL_VERSION GIT_VERSION REMOTE WHEEL GITHUB_OAUTH_HEADER_FILE HAIL_GENETICS_HAIL_IMAGE HAIL_GENETICS_HAIL_IMAGE_PY_3_10 HAIL_GENETICS_HAIL_IMAGE_PY_3_11 HAIL_GENETICS_HAILTOP_IMAGE HAIL_GENETICS_VEP_GRCH37_85_IMAGE HAIL_GENETICS_VEP_GRCH38_95_IMAGE WHEEL_FOR_AZURE WEBSITE_TAR'; + for varname in '$arguments'; + '[' -z 0.2.123 ']'; + echo HAIL_PIP_VERSION=0.2.123; HAIL_PIP_VERSION=0.2.123; + for varname in '$arguments'; + '[' -z 0.2.123-abcdef123 ']'; + echo HAIL_VERSION=0.2.123-abcdef123; HAIL_VERSION=0.2.123-abcdef123; + for varname in '$arguments'; + '[' -z abcdef123 ']'; + echo GIT_VERSION=abcdef123; GIT_VERSION=abcdef123; + for varname in '$arguments'; + '[' -z origin ']'; + echo REMOTE=origin; REMOTE=origin; + for varname in '$arguments'; + '[' -z /path/to/the.whl ']'; + echo WHEEL=/path/to/the.whl; WHEEL=/path/to/the.whl; + for varname in '$arguments'; + '[' -z /path/to/github/oauth/header/file ']'; + echo GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgen,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:1742,echo,echo,1742,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['echo'],['echo']
Availability,"/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 821, in unpack_url; hashes=hashes; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 659, in unpack_http_url; hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 882, in _download_http_url; _download_url(resp, link, content_file, hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 603, in _download_url; hashes.check_against_chunks(downloaded_chunks); File ""/usr/lib/python3/dist-packages/pip/utils/hashes.py"", line 46, in check_against_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 571, in written_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/utils/ui.py"", line 139, in iter; for x in it:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 560, in resp_read; decode_content=False):; File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 436, in stream; data = self.read(amt=amt, decode_content=decode_content); File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 401, in read; raise IncompleteRead(self._fp_bytes_read, self.length_remaining); File ""/usr/lib/python3.6/contextlib.py"", line 99, in __exit__; self.gen.throw(type, value, traceback); File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 307, in _error_catcher; raise ReadTimeoutError(self._pool, None, 'Read timed out.'); urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.; The command '/bin/sh -c python3 -m pip install --no-cache-dir -r requirements.txt -r dev-requirements.txt' returned a non-zero code: 2; [0m; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8390:2283,down,download,2283,https://hail.is,https://github.com/hail-is/hail/issues/8390,1,['down'],['download']
Availability,"/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,435	job.py	schedule_job:473	error while scheduling job (101, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:15920,error,error,15920,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['error'],['error']
Availability,"/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,447	job.py	schedule_job:473	error while scheduling job (102, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:17926,error,error,17926,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['error'],['error']
Availability,"/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:39,204	job.py	schedule_job:473	error while scheduling job (100, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:24080,error,error,24080,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['error'],['error']
Availability,"/v1561977819/icon/m.png ""medium severity"") | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNA",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14074:2640,Error,Error,2640,https://hail.is,https://github.com/hail-is/hail/pull/14074,1,['Error'],['Error']
Availability,"/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **444/1000** <br/> **Why?** Has a fix available, CVSS 4.6 | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **429/1000** <br/> **Why?** Has a fix available, CVSS 4.3 | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **501/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.3 | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14109:2359,avail,available,2359,https://hail.is,https://github.com/hail-is/hail/pull/14109,1,['avail'],['available']
Availability,"/vuln/SNYK-PYTHON-JUPYTERCORE-3063766) | `jupyter-core:` <br> `4.6.3 -> 4.11.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-MISTUNE-2940625](https://snyk.io/vuln/SNYK-PYTHON-MISTUNE-2940625) | `mistune:` <br> `0.8.4 -> 2.0.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **726/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 8.1 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **434/1000** <br/> **Why?** Has a fix available, CVSS 4.4 | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **449/1000** <br/> **Why?** Has a fix available, CVSS 4.7 | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v15",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:3684,avail,available,3684,https://hail.is,https://github.com/hail-is/hail/pull/13717,2,['avail'],['available']
Availability,"/vuln/SNYK-PYTHON-JUPYTERCORE-3063766) | `jupyter-core:` <br> `4.6.3 -> 4.11.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-MISTUNE-2940625](https://snyk.io/vuln/SNYK-PYTHON-MISTUNE-2940625) | `mistune:` <br> `0.8.4 -> 2.0.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **726/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 8.1 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **434/1000** <br/> **Why?** Has a fix available, CVSS 4.4 | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **449/1000** <br/> **Why?** Has a fix available, CVSS 4.7 | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v156",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:4376,avail,available,4376,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['avail'],['available']
Availability,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44428,avail,available,44428,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,2,['avail'],['available']
Availability,"0""><code>34e2dd4</code></a> Downgrade slf4j to fix warning on console about missing slf4j provider</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b3fa29f9ffb4d4544e13ef84601e371fb2778ddf""><code>b3fa29f</code></a> Revert &quot;Update Apache HttpClient to 5.2.1&quot;</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/01f05e046be0dca18f506723c79e88f208336e71""><code>01f05e0</code></a> Add integration tests for Gradle 6.9.3 and 7.6</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a998a544908a8b39f713f4526f717fcb328c06eb""><code>a998a54</code></a> Upgrade Gradle to 7.6</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.0...5.3.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.0&new-version=5.3.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:3402,down,download,3402,https://hail.is,https://github.com/hail-is/hail/pull/12707,1,['down'],['download']
Availability,"0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB);  53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' p",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:30772,avail,available,30772,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['avail'],['available']
Availability,"0.8.3|slackclient==2.0.0|websocket-client|sklearn|tabulate|statsmodels|scikit-learn|hdbscan|matplotlib \; --master-machine-type=n1-highmem-8 \; --master-boot-disk-size=100GB \; --num-master-local-ssds=0 \; --num-preemptible-workers=0 \; --num-worker-local-ssds=0 \; --num-workers=2 \; --preemptible-worker-boot-disk-size=40GB \; --worker-boot-disk-size=40 \; --worker-machine-type=n1-standard-8 \; --zone=us-central1-b \; --initialization-action-timeout=20m \; --labels=creator=weisburd_broadinstitute_org \; --max-idle=12h; Starting cluster 'bw2'...; Waiting on operation [projects/seqr-project/regions/global/operations/46f1d37d-798a-3fc0-8f70-eac304448a08].; Waiting for cluster creation operation...; WARNING: For PD-Standard without local SSDs, we strongly recommend provisioning 1TB or larger to ensure consistently high I/O performance. See https://cloud.google.com/compute/docs/disks/performance for information on disk I/O performance.; Waiting for cluster creation operation...done.; ERROR: (gcloud.beta.dataproc.clusters.create) Operation [projects/seqr-project/regions/global/operations/46f1d37d-798a-3fc0-8f70-eac304448a08] failed: Initialization action failed. Failed action 'gs://hail-common/hailctl/dataproc/0.2.18/init_notebook.py', see output in: gs://dataproc-d919bddb-bde3-4138-bbe1-e068dfa1e550-us/google-cloud-dataproc-metainfo/3ec45dcc-d901-4777-930c-23046e64a97d/bw2-m/dataproc-initialization-script-0_output.; Traceback (most recent call last):; File ""/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/bin/hailctl"", line 10, in <module>; sys.exit(main()); File ""/usr/local/lib/python3.7/site-packages/hailtop/hailctl/__main__.py"", line 91, in main; cli.main(args); File ""/usr/local/lib/python3.7/site-packages/hailtop/hailctl/dataproc/cli.py"", line 99, in main; jmp[args.module].main(args, pass_through_args); File ""/usr/local/lib/python3.7/site-packages/hailtop/hailctl/dataproc/start.py"", line 195, in main; sp.check_call(cmd); File ""/usr/local/Cellar/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6634:2146,ERROR,ERROR,2146,https://hail.is,https://github.com/hail-is/hail/issues/6634,1,['ERROR'],['ERROR']
Availability,"00 on error. We could return a BadRequest error code with the message 'invalid spec' and then handle the MJC database call on the driver. I chose instead to have the worker to post job complete so we get the error message with the stack trace showing up in the UI as having the normal job flow seemed cleaner to me last week then special casing `schedule_job` on the driver. `post job complete` needs a job object to get the status to send back to the driver. However, a `Job` has two concrete implementations and we don't know which the bad job is because we can't get the spec. Furthermore, the `Job` class does a lot of work based on the spec right now. So I thought it was clearer to just create a new class that had the status, but nothing else. After writing this out, it's probably better to have the driver MJC upon error rather than from the worker. The code below would be more complicated. We'd have to get the traceback / error message from the response from the worker. ```python3; try:; await client_session.post(; f'http://{instance.ip_address}:5000/api/v1alpha/batches/jobs/create',; json=body,; timeout=aiohttp.ClientTimeout(total=2),; ); await instance.mark_healthy(); except aiohttp.ClientResponseError as e:; await instance.mark_healthy(); if e.status == 403:; log.info(f'attempt already exists for job {id} on {instance}, aborting'); if e.status == 503:; log.info(f'job {id} cannot be scheduled because {instance} is shutting down, aborting'); raise e; except Exception:; await instance.incr_failed_request_count(); raise; ```. And the error handling would look something like this:. ```python3; try:; body = await job_config(app, record, attempt_id); except Exception:; log.exception('while making job config'); status = {; 'version': STATUS_FORMAT_VERSION,; 'worker': None,; 'batch_id': batch_id,; 'job_id': job_id,; 'attempt_id': attempt_id,; 'user': record['user'],; 'state': 'error',; 'error': traceback.format_exc(),; 'container_statuses': {k: None for k in tasks},; }. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11391#issuecomment-1048213078:1491,down,down,1491,https://hail.is,https://github.com/hail-is/hail/pull/11391#issuecomment-1048213078,4,"['down', 'error']","['down', 'error']"
Availability,"00; 936 | amazon-ebs: Collecting humanize==1.0.0; 937 | amazon-ebs: Downloading humanize-1.0.0-py2.py3-none-any.whl (51 kB); 938 | amazon-ebs:  51.9/51.9 kB 14.6 MB/s eta 0:00:00; 939 | amazon-ebs: Collecting hurry.filesize==0.9; 940 | amazon-ebs: Downloading hurry.filesize-0.9.tar.gz (2.8 kB); 941 | amazon-ebs: Preparing metadata (setup.py): started; 942 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 943 | amazon-ebs: Collecting janus<1.1,>=0.6; 944 | amazon-ebs: Downloading janus-1.0.0-py3-none-any.whl (6.9 kB); 945 | amazon-ebs: Requirement already satisfied: Jinja2==3.0.3 in /usr/local/lib/python3.7/site-packages (3.0.3); 946 | amazon-ebs: Collecting nest_asyncio==1.5.4; 947 | amazon-ebs: Downloading nest_asyncio-1.5.4-py3-none-any.whl (5.1 kB); 948 | amazon-ebs: Requirement already satisfied: numpy<2 in /usr/local/lib64/python3.7/site-packages (1.21.6); 949 | amazon-ebs: Collecting orjson==3.6.4; 950 | amazon-ebs: Downloading orjson-3.6.4-cp37-cp37m-manylinux_2_24_x86_64.whl (249 kB); 951 | amazon-ebs:  249.9/249.9 kB 45.1 MB/s eta 0:00:00; 952 | amazon-ebs: Requirement already satisfied: pandas<1.5.0,>=1.3.0 in /usr/local/lib64/python3.7/site-packages (1.3.5); 953 | amazon-ebs: Collecting parsimonious<0.9; 954 | amazon-ebs: Downloading parsimonious-0.8.1.tar.gz (45 kB); 955 | amazon-ebs:  45.1/45.1 kB 10.2 MB/s eta 0:00:00; 956 | amazon-ebs: Preparing metadata (setup.py): started; 957 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 958 | amazon-ebs: Collecting plotly<5.11,>=5.5.0; 959 | amazon-ebs: Downloading plotly-5.10.0-py2.py3-none-any.whl (15.2 MB); 960 | amazon-ebs:  15.2/15.2 MB 57.8 MB/s eta 0:00:00; 961 | amazon-ebs: Collecting PyJWT; 962 | amazon-ebs: Downloading PyJWT-2.5.0-py3-none-any.whl (20 kB); 963 | amazon-ebs: Collecting python-json-l",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:5796,Down,Downloading,5796,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,"011 for rg_config in Env.backend().load_references_from_dataset(path):; 2012 hl.ReferenceGenome._from_config(rg_config); 2013 . ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/backend/spark_backend.py in load_references_from_dataset(self, path); 321 ; 322 def load_references_from_dataset(self, path):; --> 323 return json.loads(Env.hail().variant.ReferenceGenome.fromHailDataset(self.fs._jfs, path)); 324 ; 325 def from_fasta_file(self, name, fasta_file, index_file, x_contigs, y_contigs, mt_contigs, par):. ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/py4j/java_gateway.py in __call__(self, *args); 1302 ; 1303 answer = self.gateway_client.send_command(command); -> 1304 return_value = get_return_value(; 1305 answer, self.gateway_client, self.target_id, self.name); 1306 . ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 28 raise FatalError('Error summary: %s' % (deepest,), error_id) from None; 29 else:; ---> 30 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 31 'Hail version: %s\n'; 32 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None. FatalError: UnsupportedFileSystemException: No FileSystem for scheme ""gs"". Java stack trace:; org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme ""gs""; 	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3281); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3301); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3352); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3320); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:479); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361); 	at is.hail.io.fs.HadoopFS.fileStatus(HadoopFS.scala:164); 	at is.hail.io.fs.FS.isDir(FS.scala:175); 	at is.hail.io.fs.FS.isDir$(FS.scala:173); 	at is.hail.io.fs.Hado",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10530:2956,Error,Error,2956,https://hail.is,https://github.com/hail-is/hail/issues/10530,2,['Error'],['Error']
Availability,"019-02-22 11:48:48,210 	| _internal.py 	| _log:87 | 127.0.0.1 - - [22/Feb/2019 11:48:48] ""POST /pod_changed HTTP/1.1"" 204 -; INFO	| 2019-02-22 11:48:48,833 	| server.py 	| mark_complete:190 | wrote log for job 61, main task to logs/job-61-main.log; INFO	| 2019-02-22 11:48:48,845 	| server.py 	| set_state:272 | job 61 changed state: Created -> Complete; INFO	| 2019-02-22 11:48:48,851 	| server.py 	| parent_new_state:287 | parent 61 successfully complete for 63; INFO	| 2019-02-22 11:48:48,857 	| server.py 	| parent_new_state:292 | all parents successfully complete for 63, creating pod; INFO	| 2019-02-22 11:48:48,918 	| server.py 	| create_pod:135 | created pod name: job-63-main-qqwb2 for job 63, main task; INFO	| 2019-02-22 11:48:48,929 	| server.py 	| mark_complete:330 | job 61 complete, exit_code 0; INFO	| 2019-02-22 11:48:48,995 	| _internal.py 	| _log:87 | 127.0.0.1 - - [22/Feb/2019 11:48:48] ""POST /pod_changed HTTP/1.1"" 204 -; [2019-02-22 11:48:49,043] ERROR in app: Exception on /test [POST]; Traceback (most recent call last):; File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1982, in wsgi_app; response = self.full_dispatch_request(); File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1615, in full_dispatch_request; return self.finalize_request(rv); File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1630, in finalize_request; response = self.make_response(rv); File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1740, in make_response; rv = self.response_class.force_type(rv, request.environ); File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/werkzeug/wrappers.py"", line 885, in force_type; response = BaseResponse(*_run_wsgi_app(response, environ)); File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/werkzeug/test.py"", line 884, in run_wsgi_app; app_rv = app(environ, start_response); TypeError: 'int' object is not callable; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5418:1530,ERROR,ERROR,1530,https://hail.is,https://github.com/hail-is/hail/pull/5418,1,['ERROR'],['ERROR']
Availability,"05c4bf85/pyscripts_rlCXpu.zip/gnomad_hail/slack_utils.py"", line 77, in try_slack; func(*args); File ""/tmp/aa0cd79aaa1a4f1ba652555c05c4bf85/assign_subpops.py"", line 16, in main; pop_table = exome_pop_table.union(genome_pop_table); File ""<decorator-gen-484>"", line 2, in union; File ""/tmp/aa0cd79aaa1a4f1ba652555c05c4bf85/hail-devel-3da0e7424af0.zip/hail/typecheck/check.py"", line 481, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/tmp/aa0cd79aaa1a4f1ba652555c05c4bf85/hail-devel-3da0e7424af0.zip/hail/table.py"", line 1496, in union; return Table(self._jt.union([table._jt for table in tables])); File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/tmp/aa0cd79aaa1a4f1ba652555c05c4bf85/hail-devel-3da0e7424af0.zip/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.table.Table.union(Table.scala:931); at is.hail.table.Table.union(Table.scala:928); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748). Hail version: devel-5f23872; Error summary: AssertionError: assertion failed; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3404:2024,Error,Error,2024,https://hail.is,https://github.com/hail-is/hail/issues/3404,1,['Error'],['Error']
Availability,"088108948b2b76bb607f61d7b3f] submitted.; Waiting for job output...; Initializing Spark and Hail with default parameters...; using hail jar at /opt/conda/default/lib/python3.6/site-packages/hail/hail-all-spark.jar; Running on Apache Spark version 2.4.3; SparkUI available at http://dk-m.c.broad-ctsa.internal:4041; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.16-277ccc7aec45; LOGGING: writing to /tmp/66c1d088108948b2b76bb607f61d7b3f/hail-20190703-2330-0.2.16-277ccc7aec45.log; yo dawg. [Stage 0:> (0 + 1) / 1]OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x00007f2e73b00000, 1035468800, 0) failed; error='Cannot allocate memory' (errno=12); #; # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 1035468800 bytes for committing reserved memory.; # An error report file with more information is saved as:; # /tmp/66c1d088108948b2b76bb607f61d7b3f/hs_err_pid10896.log; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [66c1d088108948b2b76bb607f61d7b3f] failed with error:; Google Cloud Dataproc Agent reports job failure. If logs are available, they can be found in 'gs://dataproc-7f9e9d5e-03bd-4e95-bea1-fe0321239b35-us/google-cloud-dataproc-metainfo/f03fbc39-c07f-4e3e-8f21-47ffa986058e/jobs/66c1d088108948b2b76bb607f61d7b3f/driveroutput'.; Traceback (most recent call last):; File ""/usr/local/bin/hailctl"", line 10, in <module>; sys.exit(main()); File ""/usr/local/lib/python3.7/site-packages/hailtop/hailctl/__main__.py"", line 91, in main; cli.main(args); File ""/usr/local/lib/python3.7/site-packages/hailtop/hailctl/dataproc/cli.py"", line 99, in main; jmp[args.module].main(args, pass_through_args); File ""/usr/local/lib/python3.7/site-packages/hailtop/hailctl/dataproc/submit.py"", line 72, in main; check_call(cmd); File ""/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py"", line 347, in check_call; raise CalledProcessE",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6565#issuecomment-508289815:1310,ERROR,ERROR,1310,https://hail.is,https://github.com/hail-is/hail/issues/6565#issuecomment-508289815,1,['ERROR'],['ERROR']
Availability,"1 else:; 1922 return e. /opt/conda/miniconda3/lib/python3.8/site-packages/hail/backend/py4j_backend.py in execute(self, ir, timed); 96 raise HailUserError(message_and_trace) from None; 97; ---> 98 raise e. /opt/conda/miniconda3/lib/python3.8/site-packages/hail/backend/py4j_backend.py in execute(self, ir, timed); 72 # print(self._hail_package.expr.ir.Pretty.apply(jir, True, -1)); 73 try:; ---> 74 result = json.loads(self._jhc.backend().executeJSON(jir)); 75 value = ir.typ._from_json(result['value']); 76 timings = result['timings']. /usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py in __call__(self, *args); 1302; 1303 answer = self.gateway_client.send_command(command); -> 1304 return_value = get_return_value(; 1305 answer, self.gateway_client, self.target_id, self.name); 1306. /opt/conda/miniconda3/lib/python3.8/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 28 raise FatalError('Error summary: %s' % (deepest,), error_id) from None; 29 else:; ---> 30 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 31 'Hail version: %s\n'; 32 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None. FatalError: NoClassDefFoundError: Could not initialize class __C147RGContainer_GRCh38. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19) (my-first-hail-cluster-w-0.c.open-targets-eu-dev.internal executor 1): java.lang.NoClassDefFoundError: Could not initialize class __C147RGContainer_GRCh38; 	at __C144Compiled.applyregion0_8(Emit.scala); 	at __C144Compiled.apply(Emit.scala); 	at is.hail.expr.ir.TableMapRows.$anonfun$execute$43(TableIR.scala:1938); 	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23); 	at scala.collection.Iterator$$anon$10.next(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:496); 	at is.hail.utils.richUtils.RichContextRDD$$",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:5585,Error,Error,5585,https://hail.is,https://github.com/hail-is/hail/issues/10682,2,['Error'],['Error']
Availability,"1 if ir.typ == tvoid:; 192 value = None. File ~/projects/hail/hail/python/hail/backend/backend.py:188, in Backend.execute(self, ir, timed); 186 payload = ExecutePayload(self._render_ir(ir), '{""name"":""StreamBufferSpec""}', timed); 187 try:; --> 188 result, timings = self._rpc(ActionTag.EXECUTE, payload); 189 except FatalError as e:; 190 raise e.maybe_user_error(ir) from None. File ~/projects/hail/hail/python/hail/backend/py4j_backend.py:223, in Py4JBackend._rpc(self, action, payload); 221 if resp.status_code >= 400:; 222 error_json = orjson.loads(resp.content); --> 223 raise fatal_error_from_java_error_triplet(; 224 error_json['short'], error_json['expanded'], error_json['error_id']; 225 ); 226 return resp.content, resp.headers.get('X-Hail-Timings', ''). FatalError: NoSuchElementException: Ref with name __iruid_1834 could not be resolved in env BindingEnv((__iruid_1832 -> struct{},__iruid_2157 -> struct{}),None,None,()). Java stack trace:; is.hail.utils.HailException: error after applying LowerToDistributedArray; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:23); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:23); 	at is.hail.utils.package$.fatal(package.scala:89); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:32); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:205); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.sc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14245:3339,error,error,3339,https://hail.is,https://github.com/hail-is/hail/issues/14245,1,['error'],['error']
Availability,1(LocalBackend.scala:272); E 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:271); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); E 	at is.hail.utils.package$.using(package.scala:673); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); E 	at is.hail.utils.package$.using(package.scala:673); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); E 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:120); E 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); E 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); E 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:105); E 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:271); E 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); E 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); E 	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82); E 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:80); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:848); E 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:817); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:201); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:560); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:526); E 	at java.base/java.lang.Thread.run(Thread.java:829); E; E; E; E Hail version: 0.2.132-f39364c177e0; E Error summary: RuntimeException: invalid memory access: 140a68008/00000001: not in 140a58008/00010000; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14705:8571,Error,Error,8571,https://hail.is,https://github.com/hail-is/hail/issues/14705,1,['Error'],['Error']
Availability,"1-13 18:12:20,160 	| _internal.py 	| _log:88 | 127.0.0.1 - - [13/Nov/2018 18:12:20] ""POST /refresh_k8s_state HTTP/1.1"" 204 -; INFO	| 2018-11-13 18:12:55,902 	| _internal.py 	| _log:88 | 127.0.0.1 - - [13/Nov/2018 18:12:55] ""GET /jobs HTTP/1.1"" 200 -; INFO	| 2018-11-13 18:17:20,174 	| server.py 	| refresh_k8s_state:360 | started k8s state refresh; INFO	| 2018-11-13 18:17:20,179 	| server.py 	| refresh_k8s_state:379 | k8s state refresh complete; INFO	| 2018-11-13 18:17:20,179 	| _internal.py 	| _log:88 | 127.0.0.1 - - [13/Nov/2018 18:17:20] ""POST /refresh_k8s_state HTTP/1.1"" 204 -; INFO	| 2018-11-13 18:19:31,732 	| _internal.py 	| _log:88 | 127.0.0.1 - - [13/Nov/2018 18:19:31] ""POST /jobs/create HTTP/1.1"" 200 -; INFO	| 2018-11-13 18:19:31,745 	| _internal.py 	| _log:88 | 127.0.0.1 - - [13/Nov/2018 18:19:31] ""POST /pod_changed HTTP/1.1"" 204 -; INFO	| 2018-11-13 18:19:31,764 	| _internal.py 	| _log:88 | 127.0.0.1 - - [13/Nov/2018 18:19:31] ""POST /pod_changed HTTP/1.1"" 204 -; ERROR	| 2018-11-13 18:19:31,779 	| app.py 	| log_exception:1761 | Exception on /pod_changed [POST]; Traceback (most recent call last):; File ""/Users/bking/miniconda3/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 2292, in wsgi_app; response = self.full_dispatch_request(); File ""/Users/bking/miniconda3/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1815, in full_dispatch_request; rv = self.handle_user_exception(e); File ""/Users/bking/miniconda3/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1718, in handle_user_exception; reraise(exc_type, exc_value, tb); File ""/Users/bking/miniconda3/envs/hail-batch/lib/python3.6/site-packages/flask/_compat.py"", line 35, in reraise; raise value; File ""/Users/bking/miniconda3/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1813, in full_dispatch_request; rv = self.dispatch_request(); File ""/Users/bking/miniconda3/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1799, in dispatch_request;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4773:2600,ERROR,ERROR,2600,https://hail.is,https://github.com/hail-is/hail/issues/4773,1,['ERROR'],['ERROR']
Availability,"1-22 13:11:21 DiskBlockManager: INFO: Created local directory at /tmp/blockmgr-8d910f25-2ae8-439c-8577-377758342d28; 2019-01-22 13:11:21 MemoryStore: INFO: MemoryStore started with capacity 2.5 GB; 2019-01-22 13:11:22 SparkEnv: INFO: Registering OutputCommitCoordinator; 2019-01-22 13:11:22 log: INFO: Logging initialized @11836ms; 2019-01-22 13:11:22 Server: INFO: jetty-9.3.z-SNAPSHOT; 2019-01-22 13:11:22 Server: INFO: Started @12028ms; 2019-01-22 13:11:22 AbstractConnector: INFO: Started ServerConnector@1433e9ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-01-22 13:11:22 Utils: INFO: Successfully started service 'SparkUI' on port 4040.; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1fc6c1cc{/jobs,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@75771d8a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@56931c6{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@7d4d6f14{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@23f9d06d{/stages,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cdf8858{/stages/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3418c91b{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6e2585c5{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2063dbf5{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,A",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:4420,AVAIL,AVAILABLE,4420,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['AVAIL'],['AVAILABLE']
Availability,"1-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@25004c63{/api,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@36f9d98a{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@302922c9{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 SparkUI: INFO: Bound SparkUI to 0.0.0.0, and started at http://10.48.225.55:4040; 2019-01-22 13:11:23 DomainSocketFactory: WARN: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-22 13:11:23 Client: INFO: Requesting a new application from cluster with 21 NodeManagers; 2019-01-22 13:11:23 Client: INFO: Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-22 13:11:23 Client: INFO: Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-22 13:11:23 Client: INFO: Setting up container launch context for our AM; 2019-01-22 13:11:23 Client: INFO: Setting up the launch environment for our AM container; 2019-01-22 13:11:24 Client: INFO: Preparing resources for our AM container; 2019-01-22 13:11:24 HadoopFSCredentialProvider: INFO: getting token for: hdfs://scc/user/farrell; 2019-01-22 13:11:24 DFSClient: INFO: Cr",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:14004,AVAIL,AVAILABLE,14004,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability,"1-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@7d4d6f14{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@23f9d06d{/stages,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cdf8858{/stages/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3418c91b{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6e2585c5{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2063dbf5{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/th",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:5432,AVAIL,AVAILABLE,5432,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['AVAIL'],['AVAILABLE']
Availability,1. Don't ignore parse errors by default. These shouldn't be happening; with modern VEP versions anyway (they were caused by genes named NaN; or something in older versions); 2. Don't silently drop variants that don't have a match in VEP. All keys; coming in will have a row coming out with a VEP annotation (maybe NA); and a partition/block index.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9973:22,error,errors,22,https://hail.is,https://github.com/hail-is/hail/pull/9973,1,['error'],['errors']
Availability,"1. For runImage steps, you can only copy out-of or copy into `/io` (the reasoning is a bit complicated and somewhat historical).; 2. For buildImage steps, you can copy out-of or copy into `/`; 3. the `to` of an `output` specifies a file path in a ""filesystem"" that another step can access if it `dependsOn` the outputting step; 4. the `from` of an `input` specifies a file path in the aforementioned ""filesystem""; the filesystem contains all `outputs` from steps in the inputting step's `dependsOn` clause. We also have a `docker/Makefile` which is an emergency manual build system. I update that so that `hail_version` appears in the root of the docker context. The `service-base` uses the entire repository as its docker context, so I place hail_version at the root of the repository. I moved the `version` function from `hailtop.hailctl` into `hailtop`. It seems broadly useful and isn't specific to hailctl in anyway. Your concern about loading from pkg_resources repeated seems well-founded, so I went ahead and loaded the hail_version at package import time. This seems likely to ensure we learn about a missing hail_version file as early as possible (presumably at service start-time). This also means all hailtop installs need a hail_version file. I only found two other places that use hailtop. One of them was a completely unused Dockerfile. I deleted that (`Dockerfile.hailtop`). The other was Dockerfile.ci-test, which I updated to copy the hail_version file just like service-base. https://github.com/hail-is/hail/compare/main...danking:add-version-endpoint. Do you want to cherry-pick that change onto your add-version-endpoint branch?. One more change request: can we remove the try-catch? I don't expect any errors in that call and I tend to avoid revealing anything about errors to our users. Aiohttp will log the error and the stack trace if you let it rise all the way. Sorry for all the complication! Our build system is the second service we built and is clearly showing its age.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10085#issuecomment-789279401:2528,error,errors,2528,https://hail.is,https://github.com/hail-is/hail/pull/10085#issuecomment-789279401,3,['error'],"['error', 'errors']"
Availability,"1. Functionally, it's already possible -- should be able to do `vds.annotate_variants_db('va.dann')` and get the `va.dann.score` annotation in your VDS. Taking a step further, you can even do `vds.annotate_variants_db('va')` and get all of the annotations. It's just a matter of designing the query builder to encourage people using the function in whatever way we think is optimal, I suppose. What are the downsides to carrying around a lot of annotations in a VDS? I worry that if we supplied a select-all `va` option, everybody would just use that -- but if there aren't any major drawbacks, maybe that's the way to go and we don't even really need a query builder. Or maybe just allowing top-level selections like `va.dann`, `va.chromHMM`, etc. would be a good intermediate solution. 2. Yes! I'd definitely be interested in working on a Scala implementation, if one of you would be willing to work with a newbie :). Though I think if we can get this Python version working & usable first, that may be best. 3. I'll look into this. I don't have a solution yet. That's why in the method documentation, I used ; `.. code-block:: python` statements to add example code snippets. With the `>>> ...` syntax, the build was trying to run those examples and throwing weird errors like you anticipated.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1914#issuecomment-308780378:407,down,downsides,407,https://hail.is,https://github.com/hail-is/hail/pull/1914#issuecomment-308780378,2,"['down', 'error']","['downsides', 'errors']"
Availability,"1. HailException now causes job failure; 2. ServiceBackend doesn't short-circuit on batch failure, but instead finds the first bad job (either success with exception or failed with no output) and throws a contextual exception from that.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12318:32,failure,failure,32,https://hail.is,https://github.com/hail-is/hail/pull/12318,2,['failure'],['failure']
Availability,"1. I ended up removing the test with the VCF from 1000 genomes; 2. I couldn't figure out a good way to get the number of variants used in the computation. It's either in the annotations as ""sa.imputegender.T"" or we'd have to do RDD.count() ; 3. I'm open to naming suggestions if you think something else is better. I didn't want to use ""sex check"" because that implies comparing to the reported gender and reporting errors -- not what I have implemented here.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/386:416,error,errors,416,https://hail.is,https://github.com/hail-is/hail/pull/386,1,['error'],['errors']
Availability,"1. I really don't understand what this code is trying to do. Can you give me a short explanation in English?. 2. I think you just need single-use Let forwarding to optimize this. It looks like:. Push down the TableCount. (TableCount (Paralellelize ...)) should turn into (ArrayLen (GetField rows ...)). Push the ArrayLen/GetField into the Let. (Is this what your ""MaximizeLets"" is doing? I think that would traditionally be called let lifting.). Now you have (Let __cols_and_globals (ArrayLen (GetField __cols (Ref __cols_and_globals))). Then you forward the single-use Let, and the rest of the code simplifies into (ArrayLen (TableCollect (TableRead ""cols""))), and that should have the static number of rows and be able to be simplified. 3. So how should single-use Let forwarding work? You need two things: to determine there is only one use, and that the single use isn't in a more expensive context, e.g. you don't want to forward a single-use Let into a loop: (Let expensive X (ArrayMap a x <use expensive once>)). Since our control flow is structured, there is a static notion of ""loop nesting depth"", e.g. in the above code, the Let has nesting depth 0, and the use in the ArrayMap body has nesting depth 1. You can only forward into the same nesting depth. 4. Final question is, do you want the let forwarding pass to also delete unused Lets? If you delete a let, that might delete references that make other lets single (or zero) use. In this case, it might be nice to build a ""use-def chain"" data structure, that keeps, for each let, its list of uses (and vice versa). Then, when you delete a Let, you can dynamically delete the references for the right hand side, possibly creating additional optimization opportunities.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5041#issuecomment-452863737:200,down,down,200,https://hail.is,https://github.com/hail-is/hail/pull/5041#issuecomment-452863737,1,['down'],['down']
Availability,"1. I'm not sure why we don't throw an error. My bash isn't good enough to run both commands and then detect if either failed if the exit code is indeed not equal to 0. My only thought is that maybe the exit code isn't 0 if there are no VMs or disks to delete. 2. Yes, I'll see if I can PR the fix.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13554#issuecomment-1737459046:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1737459046,1,['error'],['error']
Availability,"1. If a job errors rather than fails, we still want to see its logs in the debug info. 2. The backend from before `hl_stop_for_test` is broken. In particular, it does not have an open ClientSession, so it cannot make HTTP requests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13872:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/pull/13872,1,['error'],['errors']
Availability,"1. If we receive an error other than 404 from Google when asking about an instance, we should raise. This is unexpected. (The later lines will fail anyway because spec is `None`); 2. (the main issue) if the instance is not active, do not bother contacting it and, crucially, continue `check_on_instance` eventually learning the instance does not exist.; 3. Drop timeout to 5s to talk to a batch agent. Fixes the zombie instance issue.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8023:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/pull/8023,1,['error'],['error']
Availability,"1. It's feasible to build and ship the compiler + libraries for a limited number of known platforms; (at Physics Speed I did this for Ubuntu-16.04 and one particular version of CentOS). It gets nuts if; you have many different OS'es each of which needs its own compiler build (and it then becomes; another build-system/packaging issue to get all those compilers built correctly for each OS).; Possibly a good thing to do in the long run. Probably not something I could do in the limited time; available. 2. If you build your own compiler + library, then you risk becoming incompatible with other ; libraries on the target system which were built against that system's ""standard"" compiler; and library and header files. e.g. BLAS. [Though this only applies to libraries compiled from C++,; not libraries in C, which might conatin the damage]. So it seemed like the least disruptive path in the short term was to excise the few uses of; std::string and std::stringstream, so that we can build a libhail.so which should work across; a wide variety of Linux systems.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4422#issuecomment-424744733:493,avail,available,493,https://hail.is,https://github.com/hail-is/hail/pull/4422#issuecomment-424744733,1,['avail'],['available']
Availability,"1. Lazily load the tokens on the end user machine because the first time someone logs in to the default namespace, they will have no tokens. 2. Teach `get_tokens_file` to default to the default end-user location. 3. Add a bunch of types which would have caught this error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11054:266,error,error,266,https://hail.is,https://github.com/hail-is/hail/pull/11054,1,['error'],['error']
Availability,"1. Makefile is a bit more resilient to changes in the `dk-test` instance that is used to route traffic from GitHub to a local laptop test. It now looks up the ip. The zone is still hardcoded and it's moved to zone `us-central1-a`. The name is also hardcoded to `dk-test`.; 2. I renamed `is_running` to `is_building`; 3. When a job refresh happens, it is now `PRS` responsibility to determine what to do. It starts the same as it always does, updating existing PRs with new job information. The difference is that it tracks which (believed to be) currently building jobs are not seen in the job list. All such jobs are re-built, under the assumption that the job must have failed. cc: @cseed . This should allow CI to recover from the loss of batch. Fixes #4654.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4659:26,resilien,resilient,26,https://hail.is,https://github.com/hail-is/hail/pull/4659,2,"['recover', 'resilien']","['recover', 'resilient']"
Availability,"1. Move `hail/www` to `site/www` and associated build commands into `site/Makefile` and a new `build.yaml` step.; 2. Prepare for a simpler docs deployment by supporting both the current 0.2 structure (top-level `www` containing `docs/0.2` and `docs/0.1`) and a future, simpler structure (top-level `docs` containing `0.2` and `0.1`).; 3. Fix `site/Makefile` which had bit-rotted. `test` doesn't really work anymore so I removed it. We could restore `make test` by figuring out a local SSL story. I went down this route but couldn't get NGINX to respond to my HTTPS requests. `make deploy` is rather fast now anyway. Currently deployed at https://internal.hail.is/dking/site/index.html. There are two known issues with dev deploy, those are resolved at https://github.com/hail-is/hail/pull/8922.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8923:503,down,down,503,https://hail.is,https://github.com/hail-is/hail/pull/8923,1,['down'],['down']
Availability,"1. NativeModule manages the lifecycle of Scala-generated C++ functions. Generate the C++; source code as a Scala String, then construct ; NativeModule(compileOptions, sourceString, forceBuild); From that object you can do getKey(): String and getBinary(): Array[Byte] to get the compiled ; code in a serializable form which can be passed to other nodes in a cluster, and then used to; construct a local NativeModule(key, binary). 2. NativeCode.java now does a two-stage bootstrap on Linux to make sure that libhail.so is; loaded with the RTLD_GLOBAL flag so that dynamic-generated C++ can use functions; defined in libhail.so. On Mac, this works ok without the bootstrap. [We needed this for the; RowStore with generated-C++ decoders]. 3. Added a NativeStatus* parameter to all NativeLongFunc's, to encourage consistent handling; of errors.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973:833,error,errors,833,https://hail.is,https://github.com/hail-is/hail/pull/3973,1,['error'],['errors']
Availability,"1. The default log path includes the version and a; timestamp. This will help people avoid overwriting; log files, which will help us.; 2. Echo the full path to the log after the hail logo; 3. Add a function `hl.copy_log` which can be used to; copy the session log to a hadoop-api-compliant; location.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4421:139,Echo,Echo,139,https://hail.is,https://github.com/hail-is/hail/pull/4421,1,['Echo'],['Echo']
Availability,"1. Treat any 500 from Docker as a retryable error.; 2. Move DockerError transiency to is_transient_errors and use retry_transient_errors instead of a hand rolled transient wrapper. The first change also makes us robust to changes in error messages on the GCR side. In particular, we started seeing this error message:. ```; Head https://gcr.io/v2/hail-vdc/ubuntu/manifests/18.04: Get https://gcr.io/v2/token?account=_json_key&scope=repository%3Ahail-vdc%2Fubuntu%3Apull&service=gcr.io: net/http: request canceled (Client.Timeout exceeded while awaiting headers); ```. which is slightly different from the extant messages we check for.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11943:44,error,error,44,https://hail.is,https://github.com/hail-is/hail/pull/11943,4,"['error', 'robust']","['error', 'robust']"
Availability,"1. `hl.plot.cdf`, `hl.plot.histogram`: `values` is a method on `hl.Struct`s (because they are `Mapping`), use `[""values""]` to get the `values` field of a struct.; 2. `hl.plot.pdf`: Do not error if there are no compactions, just set error to zero.; 3. *: Add return type annotations to improve IDE hints.; 4. `hl.plot.joint_plot`: I think a bokeh upgrade completely broke this; the first argument is the grid of figures.; 5. `hl.plot.qq`: Kill unnecessary persists with fire.; 6. `hl.plot.visualize_missingness`: Informative error message when row key is not ""windowable"".; 7. `hl.plot.visualize_missingness`: When row key is a one-field struct, use the one field instead of the struct as the windowable value.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12739:188,error,error,188,https://hail.is,https://github.com/hail-is/hail/pull/12739,3,['error'],['error']
Availability,"1.00m, 42.46MB read; Socket errors: connect 0, read 2079, write 0, timeout 12; Requests/sec: 4642.59; Transfer/sec: 723.58KB. Sanic Run 3 (very large background task spike in last 1-2s of run):; alexkotlar:~/projects/aiohttp-vs-sanic-vs-japronto:$ wrk -d 60 -c 2000 -t 12 --timeout 8 http://localhost:8000/db; Running 1m test @ http://localhost:8000/db; 12 threads and 2000 connections; Thread Stats Avg Stdev Max +/- Stdev; Latency 543.65ms 839.00ms 7.93s 87.81%; Req/Sec 392.47 118.69 1.42k 73.81%; 279206 requests in 1.00m, 42.54MB read; Socket errors: connect 0, read 2101, write 0, timeout 35; Requests/sec: 4646.20; Transfer/sec: 724.97KB. Aiohttp Run 1:; alexkotlar:~/projects/aiohttp-vs-sanic-vs-japronto:$ wrk -d 60 -c 2000 -t 12 --timeout 8 http://localhost:8000/db; Running 1m test @ http://localhost:8000/db; 12 threads and 2000 connections; Thread Stats Avg Stdev Max +/- Stdev; Latency 747.49ms 1.00s 7.88s 86.77%; Req/Sec 280.95 103.65 1.60k 79.52%; 199147 requests in 1.00m, 36.47MB read; Socket errors: connect 0, read 2058, write 1, timeout 45; Requests/sec: 3313.70; Transfer/sec: 621.36KB. Aiohttp Run 2:; Running 1m test @ http://localhost:8000/db; 12 threads and 2000 connections; Thread Stats Avg Stdev Max +/- Stdev; Latency 696.00ms 967.04ms 7.93s 86.48%; Req/Sec 289.87 115.90 1.90k 83.92%; 205188 requests in 1.00m, 37.54MB read; Socket errors: connect 0, read 2041, write 0, timeout 38; Requests/sec: 3414.95; Transfer/sec: 639.84KB. Aiohttp Run 3:; Running 1m test @ http://localhost:8000/db; 12 threads and 2000 connections; Thread Stats Avg Stdev Max +/- Stdev; Latency 670.88ms 898.81ms 7.89s 86.58%; Req/Sec 318.17 108.06 1.47k 74.96%; 226300 requests in 1.00m, 41.34MB read; Socket errors: connect 0, read 2053, write 0, timeout 19; Requests/sec: 3765.55; Transfer/sec: 704.34KB. Runs were interleaved two reduce chance that the programs would benefit from caching across runs. First run for each had somewhat more background tasks open. Starlette will be run later.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5242#issuecomment-461259030:5532,error,errors,5532,https://hail.is,https://github.com/hail-is/hail/pull/5242#issuecomment-461259030,3,['error'],['errors']
Availability,"1/lib/python3.7/site-packages/hail/typecheck/check.py"", line 561, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/matrixtable.py"", line 2494, in write; Env.backend().execute(MatrixWrite(self._mir, writer)); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/backend/backend.py"", line 106, in execute; result = json.loads(Env.hail().backend.spark.SparkBackend.executeJSON(self._to_java_ir(ir))); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/utils/java.py"", line 240, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: ScalaSigParserError: Unexpected failure. Java stack trace:; org.json4s.scalap.ScalaSigParserError: Unexpected failure; 	at org.json4s.scalap.Rules$$anonfun$expect$1.apply(Rules.scala:73); 	at org.json4s.scalap.scalasig.ClassFileParser$.parse(ClassFileParser.scala:95); 	at org.json4s.reflect.ScalaSigReader$.parseClassFileFromByteCode(ScalaSigReader.scala:178); 	at org.json4s.reflect.ScalaSigReader$.findScalaSig(ScalaSigReader.scala:172); 	at org.json4s.reflect.ScalaSigReader$.findClass(ScalaSigReader.scala:53); 	at org.json4s.reflect.ScalaSigReader$.org$json4s$reflect$ScalaSigReader$$findField(ScalaSigReader.scala:100); 	at org.json4s.reflect.ScalaSigReader$.org$json4s$reflect$ScalaSigReader$$read$1(ScalaSigReader.scala:45); 	at org.json4s.reflect.ScalaSigReader$.readField(ScalaSigReader.scala:49); 	at org.json4s.reflect.Reflector$ClassDescriptorBuilder$$anonfun$3.apply(Reflector.scala:69); 	at org.json4s.reflect.Reflector$ClassDescriptorBuilder$$anonfun$3.apply(Reflector.scala:68); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6299:1820,failure,failure,1820,https://hail.is,https://github.com/hail-is/hail/issues/6299,1,['failure'],['failure']
Availability,"1095>"", line 2, in take; File ""/Users/konradk/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/konradk/hail/hail/python/hail/table.py"", line 2087, in take; return self.head(n).collect(_localize); File ""<decorator-gen-1089>"", line 2, in collect; File ""/Users/konradk/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/konradk/hail/hail/python/hail/table.py"", line 1886, in collect; return Env.backend().execute(e._ir); File ""/Users/konradk/hail/hail/python/hail/backend/spark_backend.py"", line 296, in execute; result = json.loads(self._jhc.backend().executeJSON(jir)); File ""/Users/konradk/programs/spark-2.4.1-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/konradk/hail/hail/python/hail/backend/spark_backend.py"", line 41, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: NoSuchElementException: key not found: 1; [...]; java.util.NoSuchElementException: key not found: 1; at scala.collection.MapLike$class.default(MapLike.scala:228); at scala.collection.AbstractMap.default(Map.scala:59); at scala.collection.MapLike$class.apply(MapLike.scala:141); at scala.collection.AbstractMap.apply(Map.scala:59); at is.hail.types.encoded.EBaseStruct.fieldType(EBaseStruct.scala:34); at is.hail.types.encoded.EBaseStruct$$anonfun$8.apply(EBaseStruct.scala:84); at is.hail.types.encoded.EBaseStruct$$anonfun$8.apply(EBaseStruct.scala:83); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at scala.collection.Traver",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9016:4530,Error,Error,4530,https://hail.is,https://github.com/hail-is/hail/issues/9016,1,['Error'],['Error']
Availability,"1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/cseed/hail/python/hail/utils/java.py"", line 200, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 2.0 failed 1 times, most recent failure: Lost task 7.0 in stage 2.0 (TID 23, localhost, executor driver): is.hail.utils.HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1011); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.io.RichContextRDDRegionValue$.writeRowsPartition(RowStore.scala:1071); 	at is.hail.io.RichContextRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:1096); 	at is.hail.io.RichContextRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:1096); 	at is.hail.utils.richUtils.RichContextRDD$$anonfun$1.apply(RichContextRDD.scala:42); 	at is.hail.utils.richUtils.RichContextRDD$$anonfun$1.apply(RichContextRDD.scala:27); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$22.app",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4096:1644,Error,ErrorHandling,1644,https://hail.is,https://github.com/hail-is/hail/issues/4096,1,['Error'],['ErrorHandling']
Availability,11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc \; HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc \; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc \; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc \; WHEEL_FOR_AZURE= \; WEBSITE_TAR=/path/to/www.tar.gz \; hail/scripts/release.sh. +++ dirname -- hail/scripts/release.sh; ++ cd -- hail/scripts; ++ pwd; + SCRIPT_DIR=/Users/dking/projects/hail/hail/scripts; + arguments='HAIL_PIP_VERSION HAIL_VERSION GIT_VERSION REMOTE WHEEL GITHUB_OAUTH_HEADER_FILE HAIL_GENETICS_HAIL_IMAGE HAIL_GENETICS_HAIL_IMAGE_PY_3_10 HAIL_GENETICS_HAIL_IMAGE_PY_3_11 HAIL_GENETICS_HAILTOP_IMAGE HAIL_GENETICS_VEP_GRCH37_85_IMAGE HAIL_GENETICS_VEP_GRCH38_95_IMAGE WHEEL_FOR_AZURE WEBSITE_TAR'; + for varname in '$arguments'; + '[' -z 0.2.123 ']'; + echo HAIL_PIP_VERSION=0.2.123; HAIL_PIP_VERSION=0.2.123; + for varname in '$arguments'; + '[' -z 0.2.123-abcdef123 ']'; + echo HAIL_VERSION=0.2.123-abcdef123; HAIL_VERSION=0.2.123-abcdef123; + for varname in '$arguments'; + '[' -z abcdef123 ']'; + echo GIT_VERSION=abcdef123; GIT_VERSION=abcdef123; + for varname in '$arguments'; + '[' -z origin ']'; + echo REMOTE=origin; REMOTE=origin; + for varname in '$arguments'; + '[' -z /path/to/the.whl ']'; + echo WHEEL=/path/to/the.whl; WHEEL=/path/to/the.whl; + for varname in '$arguments'; + '[' -z /path/to/github/oauth/header/file ']'; + echo GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailge,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:1620,echo,echo,1620,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['echo'],['echo']
Availability,123; HAIL_VERSION=0.2.123-abcdef123; + for varname in '$arguments'; + '[' -z abcdef123 ']'; + echo GIT_VERSION=abcdef123; GIT_VERSION=abcdef123; + for varname in '$arguments'; + '[' -z origin ']'; + echo REMOTE=origin; REMOTE=origin; + for varname in '$arguments'; + '[' -z /path/to/the.whl ']'; + echo WHEEL=/path/to/the.whl; WHEEL=/path/to/the.whl; + for varname in '$arguments'; + '[' -z /path/to/github/oauth/header/file ']'; + echo GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc ']'; + echo HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:2774,echo,echo,2774,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,2,['echo'],['echo']
Availability,"1289); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:241); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:227); at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:893); at io.netty.channel.AbstractChannel$AbstractUnsafe$7.run(AbstractChannel.java:691); at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:367); at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:671); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:456); at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144); at java.lang.Thread.run(Thread.java:745); 2019-01-22 13:12:06 SparkContext: INFO: Successfully stopped SparkContext; 2019-01-22 13:12:06 NettyRpcEnv: WARN: Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@115b6ba4 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@3f21bf73[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]; 2019-01-22 13:12:06 YarnSchedulerBackend$YarnSchedulerEndpoint: ERROR: Error requesting driver to remove executor 14 after disconnection.; org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.; at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:155); at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:132); at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:228); at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:515); at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:63); at org.apache.spark.scheduler.cluster.YarnSchedulerBackend",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:213882,failure,failure,213882,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['failure'],['failure']
Availability,"13-py2.py3-none-any.whl (9.6 kB); 927 | amazon-ebs: Collecting dill<0.4,>=0.3.1.1; 928 | amazon-ebs: Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB); 929 | amazon-ebs:  95.8/95.8 kB 15.3 MB/s eta 0:00:00; 930 | amazon-ebs: Collecting google-auth==1.27.0; 931 | amazon-ebs: Downloading google_auth-1.27.0-py2.py3-none-any.whl (135 kB); 932 | amazon-ebs:  135.6/135.6 kB 30.6 MB/s eta 0:00:00; 933 | amazon-ebs: Collecting google-cloud-storage==1.25.*; 934 | amazon-ebs: Downloading google_cloud_storage-1.25.0-py2.py3-none-any.whl (73 kB); 935 | amazon-ebs:  73.4/73.4 kB 22.1 MB/s eta 0:00:00; 936 | amazon-ebs: Collecting humanize==1.0.0; 937 | amazon-ebs: Downloading humanize-1.0.0-py2.py3-none-any.whl (51 kB); 938 | amazon-ebs:  51.9/51.9 kB 14.6 MB/s eta 0:00:00; 939 | amazon-ebs: Collecting hurry.filesize==0.9; 940 | amazon-ebs: Downloading hurry.filesize-0.9.tar.gz (2.8 kB); 941 | amazon-ebs: Preparing metadata (setup.py): started; 942 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 943 | amazon-ebs: Collecting janus<1.1,>=0.6; 944 | amazon-ebs: Downloading janus-1.0.0-py3-none-any.whl (6.9 kB); 945 | amazon-ebs: Requirement already satisfied: Jinja2==3.0.3 in /usr/local/lib/python3.7/site-packages (3.0.3); 946 | amazon-ebs: Collecting nest_asyncio==1.5.4; 947 | amazon-ebs: Downloading nest_asyncio-1.5.4-py3-none-any.whl (5.1 kB); 948 | amazon-ebs: Requirement already satisfied: numpy<2 in /usr/local/lib64/python3.7/site-packages (1.21.6); 949 | amazon-ebs: Collecting orjson==3.6.4; 950 | amazon-ebs: Downloading orjson-3.6.4-cp37-cp37m-manylinux_2_24_x86_64.whl (249 kB); 951 | amazon-ebs:  249.9/249.9 kB 45.1 MB/s eta 0:00:00; 952 | amazon-ebs: Requirement already satisfied: pandas<1.5.0,>=1.3.0 in /usr/local/lib64/python3.7/site-packages (1.3.5",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:5084,Down,Downloading,5084,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,"131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.expr.TableMapGlobals.execute(Relational.scala:2158); 	at is.hail.table.Table.value$lzycompute(Table.scala:243); 	at is.hail.table.Table.value(Table.scala:238); 	at is.hail.table.Table.x$5$lzycompute(Table.scala:246); 	at is.hail.table.Table.x$5(Table.scala:246); 	at is.hail.table.Table.globals$lzycompute(Table.scala:246); 	at is.hail.table.Table.globals(Table.scala:246); 	at is.hail.utils.Py4jUtils$class.joinGlobals(Py4jUtils.scala:137); 	at is.hail.utils.package$.joinGlobals(package.scala:26); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-5b299ddae758; Error summary: AssertionError: assertion failed; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3728:6143,Error,Error,6143,https://hail.is,https://github.com/hail-is/hail/issues/3728,1,['Error'],['Error']
Availability,"13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6e2585c5{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2063dbf5{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@25004c63{/api,null,",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:12733,AVAIL,AVAILABLE,12733,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability,"13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6e2585c5{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2063dbf5{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; [farrell@scc-hadoop ukb.v3]$ cat /restricted/projectnb/ukbiobank/ad/analysis/ukb.v3/hail-20190122-1",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:5941,AVAIL,AVAILABLE,5941,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability,"147; -> 2148 self._jvds.write(output, overwrite, stage_locally, _codec_spec); 2149; 2150 def globals_table(self) -> Table:. /share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /share/pkg/hail/2018-10-31/install/build/distributions/hail-python.zip/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: OutOfMemoryError: Java heap space. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 76 in stage 1.0 failed 1 times, most recent failure: Lost task 76.0 in stage 1.0 (TID 77, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.nio.HeapCharBuffer.toString(HeapCharBuffer.java:567); at java.nio.CharBuffer.toString(CharBuffer.java:1241); at org.apache.hadoop.io.Text.decode(Text.java:412); at org.apache.hadoop.io.Text.decode(Text.java:389); at org.apache.hadoop.io.Text.toString(Text.java:280); at org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8.apply(SparkContext.scala:833); at org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8.apply(SparkContext.scala:833); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:788); at scala.collection.Iterato",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635:2562,failure,failure,2562,https://hail.is,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635,1,['failure'],['failure']
Availability,"149 return self._jbackend.parse_value_ir(; 150 code,; 151 {k: t._parsable_string() for k, t in ref_map.items()},; 152 ir_map). File ~/miniconda3/lib/python3.10/site-packages/py4j/java_gateway.py:1321, in JavaMember.__call__(self, *args); 1315 command = proto.CALL_COMMAND_NAME +\; 1316 self.command_header +\; 1317 args_command +\; 1318 proto.END_COMMAND_PART; 1320 answer = self.gateway_client.send_command(command); -> 1321 return_value = get_return_value(; 1322 answer, self.gateway_client, self.target_id, self.name); 1324 for temp_arg in temp_args:; 1325 temp_arg._detach(). File /private/tmp/hail/hail/python/hail/backend/py4j_backend.py:35, in handle_java_exception.<locals>.deco(*args, **kwargs); 33 tpl = Env.jutils().handleForPython(e.java_exception); 34 deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); ---> 35 raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; 36 except pyspark.sql.utils.CapturedException as e:; 37 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 38 'Hail version: %s\n'; 39 'Error summary: %s' % (e.desc, e.stackTrace, hail.__version__, e.desc)) from None. FatalError: ClassCastException: class is.hail.types.virtual.TStruct cannot be cast to class is.hail.types.virtual.TIterable (is.hail.types.virtual.TStruct and is.hail.types.virtual.TIterable are in unnamed module of loader 'app'). Java stack trace:; java.lang.RuntimeException: typ: inference failure:; 	at is.hail.expr.ir.IR.typ(IR.scala:38); 	at is.hail.expr.ir.IR.typ$(IR.scala:33); 	at is.hail.expr.ir.ToStream.typ(IR.scala:300); 	at is.hail.expr.ir.IRParser$.$anonfun$ir_value_expr_1$81(Parser.scala:1111); 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); 	at is.hail.expr.ir.IRParser$.$anonfun$parse_value_ir$1(Parser.scala:2157); 	at is.hail.expr.ir.IRParser$.parse(Parser.scala:2153); 	at is.hail.expr.ir.IRParser$.parse_value_ir(Parser.s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13699:3118,Error,Error,3118,https://hail.is,https://github.com/hail-is/hail/issues/13699,1,['Error'],['Error']
Availability,"151"">#8151</a>) (<a href=""https://github.com/vitejs/vite/commit/9fdd0a3"">9fdd0a3</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8151"">#8151</a></li>; <li>feat: new hook <code>configurePreviewServer</code> (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7658"">#7658</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8437"">#8437</a>) (<a href=""https://github.com/vitejs/vite/commit/7b972bc"">7b972bc</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7658"">#7658</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8437"">#8437</a></li>; <li>fix: remove empty chunk css imports when using esnext (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8345"">#8345</a>) (<a href=""https://github.com/vitejs/vite/commit/9fbc1a9"">9fbc1a9</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8345"">#8345</a></li>; <li>fix: EPERM error on Windows when processing dependencies (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8235"">#8235</a>) (<a href=""https://github.com/vitejs/vite/commit/dfe4307"">dfe4307</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8235"">#8235</a></li>; <li>fix(css): remove <code>?used</code> hack (fixes <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/6421"">#6421</a>, <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8245"">#8245</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8278"">#8278</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8471"">#8471</a>) (<a href=""https://github.com/vitejs/vite/commit/8d7bac4"">8d7bac4</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/6421"">#6421</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8245"">#8245</a> <a href=""https://github-redirect.dependabot.com/vitejs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12142:4742,error,error,4742,https://hail.is,https://github.com/hail-is/hail/pull/12142,2,['error'],['error']
Availability,"19-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@23f9d06d{/stages,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cdf8858{/stages/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3418c91b{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6e2585c5{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2063dbf5{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:5558,AVAIL,AVAILABLE,5558,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['AVAIL'],['AVAILABLE']
Availability,"19-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@56931c6{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@7d4d6f14{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@23f9d06d{/stages,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cdf8858{/stages/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3418c91b{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6e2585c5{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2063dbf5{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:5311,AVAIL,AVAILABLE,5311,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['AVAIL'],['AVAILABLE']
Availability,"19603: error while parsing line; chrY	113	.	GG	G,*,AG,CG	596	PASS	AC=2,4,6,1;AF=1.23e-03,5.550e-05,4.44e-05,2.00e-04;AN=265;AS_AltDP=10,0,3,10;AS_BaseQRankSum=0.000,.,0.100,0.500;AS_FS=7.777,.,2.144,8.001;AS_MQ=55.75,.,38.98,40.20;AS_MQRankSum=0.200,.,-1.050,-0.500;AS_QD=0.50,0.00,0.25,0.52;AS_ReadPosRankSum=-0.200,.,0.500,-0.220;AS_SOR=2.300,.,1.600,3.000;BaseQRankSum=0.200;DP=600000;ExcessHet=0.0477;FS=0.900;MQ=55.02;MQRankSum=-0.553;QD=1.00;ReadPosRankSum=-0.162;SOR=0.792;VarDP=650	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0/0:.:21:30	0/0:.:300:20	0/0:.:30:72	0/0:.:31:98	0|1:29,3,0,0,0:33:78:0|1:113_GG_G:78,0,1100,140,1400,1200,172,1600,1200,1000,175,1100,1100,1300,1000:113:19,19,2,1	0/0:.:20:19	0/0:.:19:20	0/0:.:25:50		0|1:90,2,0,0,0:30:40:0|1:113_GG_G:40,0,600,70,650,600,90,640,900,300,60,800,400,900,900:113:2,14,2,0	0/0:.:20:10	0/0:.:9:20	0/0:.:30:40	0/0:.:37:38		0/4:5,0,0,0,1:5:33:.:.:30,40,400,50,220,220,38,270,270,270,0,200,200,200,202:.:5,0,0,1	. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:22); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:22); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1921); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7$adapted(LoadVCF.scala:1909); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:515); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at __C678stream_Let.apply(Emit.scala); 	at is.hail.expr.ir.CompileIterator$$anon$2.step(Compile.scala:302); 	at is.hail.expr.ir.CompileIterator$LongIteratorWrapper.hasNext(Compile.scala:155); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:7284,Error,ErrorHandling,7284,https://hail.is,https://github.com/hail-is/hail/issues/14102,2,['Error'],['ErrorHandling']
Availability,"1977819/icon/m.png ""medium severity"") | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TOR",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14259:3296,Error,Error,3296,https://hail.is,https://github.com/hail-is/hail/pull/14259,1,['Error'],['Error']
Availability,"19fe2247a""><code>02b8e1a</code></a> Prevent duplicate destination files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0b65ca2f17c8890a3ec34cf80cde52ee5413cbec""><code>0b65ca2</code></a> Call eachFile action only once per source</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/717877121299cea8f216d3a595eaa56731a6acd3""><code>7178771</code></a> Support changing a target file's relative path in an eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e5af1bd7f9daa8a9222aee0dd1b703727cb5e94e""><code>e5af1bd</code></a> Bump version number to 5.3.0-SNAPSHOT</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=3.2.0&new-version=5.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:5331,down,download,5331,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download']
Availability,"1:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@25004c63{/api,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@36f9d98a{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@302922c9{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 SparkUI: INFO: Bound SparkUI to 0.0.0.0, and started at http://10.48.225.55:4040; 2019-01-22 13:11:23 DomainSocketFactory: WARN: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:13252,AVAIL,AVAILABLE,13252,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability,"1:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; [farrell@scc-hadoop ukb.v3]$ cat /restricted/projectnb/ukbiobank/ad/analysis/ukb.v3/hail-20190122-1311-0.2.4-d602a3d7472d.log; 2019-01-22 13:11:20 SparkContext: INFO: Running Spark version 2.2.1; 2019-01-22 13:11:20 NativeCodeLoader: WARN: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 2019-01-22 13:11:21 SparkContext: INFO: Submitted application: Hail; 2019-01-22 13:11:21 SparkContext: INFO: Spark configuration:; spark.app.name=Hail; spark.driver.extraClassPath=""/restricted/projectnb/genpro/github/hail/hail/build/libs/hail-all-spark.jar""; spark.driver",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:6460,AVAIL,AVAILABLE,6460,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability,1=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc \; HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc \; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc \; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc \; WHEEL_FOR_AZURE=x \; WEBSITE_TAR=/path/to/www.tar.gz \; hail/scripts/release.sh. +++ dirname -- hail/scripts/release.sh; ++ cd -- hail/scripts; ++ pwd; + SCRIPT_DIR=/Users/dking/projects/hail/hail/scripts; + arguments='HAIL_PIP_VERSION HAIL_VERSION GIT_VERSION REMOTE WHEEL GITHUB_OAUTH_HEADER_FILE HAIL_GENETICS_HAIL_IMAGE HAIL_GENETICS_HAIL_IMAGE_PY_3_10 HAIL_GENETICS_HAIL_IMAGE_PY_3_11 HAIL_GENETICS_HAILTOP_IMAGE HAIL_GENETICS_VEP_GRCH37_85_IMAGE HAIL_GENETICS_VEP_GRCH38_95_IMAGE WHEEL_FOR_AZURE WEBSITE_TAR'; + for varname in '$arguments'; + '[' -z 0.2.123 ']'; + echo HAIL_PIP_VERSION=0.2.123; HAIL_PIP_VERSION=0.2.123; + for varname in '$arguments'; + '[' -z 0.2.123-abcdef123 ']'; + echo HAIL_VERSION=0.2.123-abcdef123; HAIL_VERSION=0.2.123-abcdef123; + for varname in '$arguments'; + '[' -z abcdef123 ']'; + echo GIT_VERSION=abcdef123; GIT_VERSION=abcdef123; + for varname in '$arguments'; + '[' -z origin ']'; + echo REMOTE=origin; REMOTE=origin; + for varname in '$arguments'; + '[' -z /path/to/the.whl ']'; + echo WHEEL=/path/to/the.whl; WHEEL=/path/to/the.whl; + for varname in '$arguments'; + '[' -z /path/to/github/oauth/header/file ']'; + echo GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailge,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:7096,echo,echo,7096,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['echo'],['echo']
Availability,"1_70_65,GAAGTCTCATCCCATC-1_45;AACGTCAGTGTTTCAG-1_74:1:19:255	0/1:2,4:6:60:101,0,60:.:.:.:.; chr1	12198	rs62635282	G	C	69.6	.	BaseQRankSum=0;ClippingRankSum=0;DB;ExcessHet=3.0103;FS=4.771;MQ=42;MQRankSum=-0.967;QD=23.2;ReadPosRankSum=0.967;SOR=2.225;CSQ=C|non_coding_transcript_exon_variant|MODIFIER|DDX11L1|ENSG00000223972|Transcript|ENST00000450305|transcribed_unprocessed_pseudogene|2/6||||68|||||||1||HGNC|HGNC:37102|||||||||||||||||||||||||||,C|non_coding_transcript_exon_variant|MODIFIER|DDX11L1|ENSG00000223972|Transcript|ENST00000456328|processed_transcript|1/3||||330|||||||1||HGNC|HGNC:37102|||||||||||||||||||||||||||,C|downstream_gene_variant|MODIFIER|WASH7P|ENSG00000227232|Transcript|ENST00000488147|unprocessed_pseudogene|||||||||||2206|-1||HGNC|HGNC:38034|||||||||||||||||||||||||||;DP=3;AF=0.5;MLEAC=1;MLEAF=0.5;AN=2;AC=1	GT:AD:DP:GQ:PL	./.:.:.:.:.	0/1:1,2:3:37:77,0,37; ```. Getting this error message:; ```; INFO: [pid 11941] Worker Worker(salt=943636132, workers=1, host=seqr-loading-cluster-m, username=root, pid=11941) running SeqrVCFToMTTask(source_paths=gs://seqr-bw/merged_phased_3P5CH.split.vcf.gz, dest_path=gs://seqr-bw/merged_phased_3P5CH.mt, genome_version=38, vep_runner=VEP, reference_ht_path=gs://seqr-reference-data/GRCh38/all_reference_data/combined_reference_data_grch38.ht, clinvar_ht_path=gs://seqr-reference-data/GRCh38/clinvar/clinvar.GRCh38.2020-03-29.ht, hgmd_ht_path=None, sample_type=WGS, validate=False, dataset_type=VARIANTS, remap_path=, subset_path=, vep_config_json_path=); Initializing Spark and Hail with default parameters...; Running on Apache Spark version 2.4.5; SparkUI available at http://seqr-loading-cluster-m.c.seqr-project.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.34-914bd8a10ca2; LOGGING: writing to /tmp/c7e0443c47b54e91b295e2bff7b554b9/hail-20200405-1408-0.2.34-914bd8a10ca2.log; {'_Task__hash': -3818947167740532127,; 'clinvar_ht_path': 'gs://seqr-reference-data/GRCh38/clinva",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:36022,error,error,36022,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['error'],['error']
Availability,"1bc1497"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""42.0.2""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,509,454,616,584,479,509,509,509,509,589,509,691,399,479,399,539,479,479,616,616,561,519],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr);  [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr);  [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:13458,avail,available,13458,https://hail.is,https://github.com/hail-is/hail/pull/14327,1,['avail'],['available']
Availability,"2 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3418c91b{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6e2585c5{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2063dbf5{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@8587",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:5815,AVAIL,AVAILABLE,5815,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['AVAIL'],['AVAILABLE']
Availability,"2 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@25004c63{/api,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@36f9d98a{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@302922c9{/stages/stage/kill,n",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:12988,AVAIL,AVAILABLE,12988,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability,"2 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; [farrell@scc-hadoop ukb.v3]$ cat /restricted/projectnb/ukbiobank/ad/analysis/ukb.v3/hail-20190122-1311-0.2.4-d602a3d7472d.log; 2019-01-22 13:11:20 SparkContext: INFO: Running Spark version 2.2.1; 2019-01-22 13:11:20 NativeCodeLoader: WARN: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 2019-01-22 1",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:6196,AVAIL,AVAILABLE,6196,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability,"2 19:11:13.126 : INFO: RegionPool: initialized for thread 10: pool-2-thread-2; 2023-09-22 19:11:13.126 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-09-22 19:11:13.126 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-22 19:11:13.127 : INFO: RegionPool: initialized for thread 10: pool-2-thread-2; 2023-09-22 19:11:13.127 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-09-22 19:11:13.127 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-22 19:11:13.127 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-22 19:11:13.138 : ERROR: GoogleJsonResponseException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/1-day/o/parallelizeAndComputeWithIndex%2FO3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=%2Fresult.0?alt=media; No such object: 1-day/parallelizeAndComputeWithIndex/O3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=/result.0; From is.hail.relocated.com.google.cloud.storage.StorageException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/1-day/o/parallelizeAndComputeWithIndex%2FO3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=%2Fresult.0?alt=media; No such object: 1-day/parallelizeAndComputeWithIndex/O3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=/result.0; 	at is.hail.relocated.com.google.cloud.storage.StorageException.translate(StorageException.java:165); 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:298); 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.load(HttpStorageRpc.java:729); 	at is.hail.relocated.com.google.cloud.storage.S",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:3947,ERROR,ERROR,3947,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['ERROR'],['ERROR']
Availability,"2 6d 65 64 69 61 74 65 73 2f 2d 50 74 33 |termediates/-Pt3|; 00000050 67 4e 74 51 57 35 57 6f 42 64 43 54 44 50 51 69 |gNtQW5WoBdCTDPQi|; 00000060 77 48 64 61 39 63 32 36 35 66 32 2d 66 62 64 38 |wHda9c265f2-fbd8|; 00000070 2d 34 66 31 62 2d 62 63 64 65 2d 66 62 66 32 39 |-4f1b-bcde-fbf29|; 00000080 31 38 30 63 33 34 37 00 00 00 00 |180c347....|; 0000008b; ```. code:; ```ipython3; In [1]: import hail as hl; ...: import gnomad.utils.sparse_mt; ...: ; ...: ; ...: tmp_dir = 'gs://danking/tmp/'; ...: vds_file = 'gs://neale-bge/bge-wave-1.vds'; ...: out = 'gs://danking/foo.vcf.bgz'; ...: ; ...: vds = hl.vds.read_vds(vds_file); ...: mt = hl.vds.to_dense_mt(vds); ...: t = gnomad.utils.sparse_mt.default_compute_info(mt); ...: t = t.annotate(info=t.info.drop('AS_SB_TABLE')); ...: t = t.annotate(info = t.info.drop(; ...: 'AS_QUALapprox', 'AS_VarDP', 'AS_SOR', 'AC_raw', 'AC', 'AS_SB'; ...: )); ...: t = t.drop('AS_lowqual'); ...: ; ...: hl.methods.export_vcf(dataset = t, output = out, tabix = True); ```; worker failure:; ```; 2023-09-27 16:43:10.389 JVMEntryway: INFO: is.hail.JVMEntryway received arguments:; 2023-09-27 16:43:10.389 JVMEntryway: INFO: 0: /hail-jars/gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar; 2023-09-27 16:43:10.389 JVMEntryway: INFO: 1: is.hail.backend.service.Main; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 2: /batch/83e7aee9e9244f6884b8a84ea81b4c7a; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 3: /batch/83e7aee9e9244f6884b8a84ea81b4c7a/log; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 4: gs://hail-test-ezlis/dking/jars/ch4g3zvqceyo/09526a168d57dac1a26f8caa4ab49593931ed2ef.jar; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 5: worker; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 6: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 7: 7028; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 8: 9060; 2023-09-27 16:43:10.390 JVMEntryway: INFO: Yielding",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:1936,failure,failure,1936,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943,1,['failure'],['failure']
Availability,"2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::int8<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::int8<16>]; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:133:36: required from simdpp::arch_avx2::uint8<16>& simdpp::arch_avx2::uint8<16>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::int8<16, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_avg_trunc.h:64:25: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<16> with private member simdpp::arch_avx2::uint8<16>::d_ from an array of const class simdpp::arch_avx2::int8<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:19,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:104:7: note: class simdpp::arch_avx2::uint8<16> declared here; class uint8<16, void> : public any_int8<16, uint8<16,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::int16<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:84016,error,error,84016,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint16<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint16<16>]; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:114:36: required from simdpp::arch_avx2::uint32<8>& simdpp::arch_avx2::uint32<8>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:136:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<8> with private member simdpp::arch_avx2::uint32<8>::d_ from an array of const class simdpp::arch_avx2::uint16<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:91:7: note: class simdpp::arch_avx2::uint32<8> declared here; class uint32<8, void> : public any_int32<8, uint32<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::uint32<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:38252,error,error,38252,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"2019-01-22 13:11:58 DAGScheduler: INFO: Executor lost: 18 (epoch 10); 2019-01-22 13:11:58 BlockManagerMasterEndpoint: INFO: Trying to remove executor 18 from BlockManagerMaster.; 2019-01-22 13:11:58 BlockManagerMasterEndpoint: INFO: Removing block manager BlockManagerId(18, scc-q02.scc.bu.edu, 37258, None); 2019-01-22 13:11:58 BlockManagerMaster: INFO: Removed 18 successfully in removeExecutor; 2019-01-22 13:11:58 DAGScheduler: INFO: Shuffle files lost for executor: 18 (epoch 10); 2019-01-22 13:11:58 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Disabling executor 11.; 2019-01-22 13:11:58 DAGScheduler: INFO: Executor lost: 11 (epoch 11); 2019-01-22 13:11:58 BlockManagerMasterEndpoint: INFO: Trying to remove executor 11 from BlockManagerMaster.; 2019-01-22 13:11:58 BlockManagerMasterEndpoint: INFO: Removing block manager BlockManagerId(11, scc-q17.scc.bu.edu, 37841, None); 2019-01-22 13:11:58 BlockManagerMaster: INFO: Removed 11 successfully in removeExecutor; 2019-01-22 13:11:58 DAGScheduler: INFO: Shuffle files lost for executor: 11 (epoch 11); 2019-01-22 13:11:59 YarnScheduler: ERROR: Lost executor 11 on scc-q17.scc.bu.edu: Container marked as failed: container_e2435_1542127286896_0174_01_000021 on host: scc-q17.scc.bu.edu. Exit status: 1. Diagnostics: Exception from container-launch.; Container id: container_e2435_1542127286896_0174_01_000021; Exit code: 1; Stack trace: ExitCodeException exitCode=1:; at org.apache.hadoop.util.Shell.runCommand(Shell.java:576); at org.apache.hadoop.util.Shell.run(Shell.java:487); at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:753); at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:371); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:303); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); at java.util.concurrent.Fu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:136897,ERROR,ERROR,136897,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['ERROR'],['ERROR']
Availability,"2019-01-22 13:12:04 DAGScheduler: INFO: Executor lost: 21 (epoch 14); 2019-01-22 13:12:04 BlockManagerMasterEndpoint: INFO: Trying to remove executor 21 from BlockManagerMaster.; 2019-01-22 13:12:04 BlockManagerMasterEndpoint: INFO: Removing block manager BlockManagerId(21, scc-q12.scc.bu.edu, 45213, None); 2019-01-22 13:12:04 BlockManagerMaster: INFO: Removed 21 successfully in removeExecutor; 2019-01-22 13:12:04 DAGScheduler: INFO: Shuffle files lost for executor: 21 (epoch 14); 2019-01-22 13:12:05 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Disabling executor 12.; 2019-01-22 13:12:05 DAGScheduler: INFO: Executor lost: 12 (epoch 15); 2019-01-22 13:12:05 BlockManagerMasterEndpoint: INFO: Trying to remove executor 12 from BlockManagerMaster.; 2019-01-22 13:12:05 BlockManagerMasterEndpoint: INFO: Removing block manager BlockManagerId(12, scc-q03.scc.bu.edu, 36955, None); 2019-01-22 13:12:05 BlockManagerMaster: INFO: Removed 12 successfully in removeExecutor; 2019-01-22 13:12:05 DAGScheduler: INFO: Shuffle files lost for executor: 12 (epoch 15); 2019-01-22 13:12:05 YarnScheduler: ERROR: Lost executor 21 on scc-q12.scc.bu.edu: Container marked as failed: container_e2435_1542127286896_0174_01_000036 on host: scc-q12.scc.bu.edu. Exit status: 1. Diagnostics: Exception from container-launch.; Container id: container_e2435_1542127286896_0174_01_000036; Exit code: 1; Stack trace: ExitCodeException exitCode=1:; at org.apache.hadoop.util.Shell.runCommand(Shell.java:576); at org.apache.hadoop.util.Shell.run(Shell.java:487); at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:753); at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:371); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:303); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); at java.util.concurrent.Fu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:180854,ERROR,ERROR,180854,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['ERROR'],['ERROR']
Availability,"205 for j in list(e._joins)[::-1]:; 2206 if j.uid not in used_uids:; -> 2207 left = j.join_function(left); 2208 all_uids.extend(j.temp_vars); 2209 used_uids.add(j.uid). /home/hail/hail.zip/hail/matrixtable.py in <lambda>(left); 2157 prefix = 'va'; 2158 joiner = lambda left: (; -> 2159 MatrixTable(left._jvds.annotateRowsVDS(right._jvds, uid))); 2160 else:; 2161 return self.rows().index(*exprs). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 236 # this is a hack to suppress the original error's stack trace; 237 if _exception:; --> 238 raise _exception; 239; 240 return deco. FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.variant.MatrixTable.orderedRVDLeftJoinDistinctAndInsert(MatrixTable.scala:982); 	at is.hail.variant.MatrixTable.annotateRowsVDS(MatrixTable.scala:1449); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-14287a4; Error summary: AssertionError: assertion failed; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3119:3366,Error,Error,3366,https://hail.is,https://github.com/hail-is/hail/issues/3119,1,['Error'],['Error']
Availability,"2079a85bce (41 minutes):. I could try to make the tests even more fine-grained and split up even more long-running tests. Seems like some of the bottlenecks I'm hitting now are:; 1. Introducing an image with the wheel already installed isn't worthwhile, it adds 2.5 min latency.; 2. The large number of splits often requires default Hail to scale up adding a 2min delay (It would be great to get that down). I'm gonna revert the change that added images and maybe try to reduce service backend parallelism a bit. 36 minutes is an improvement. We should probably focus on making Hail faster rather than trying to squeeze lower latency out of parallelism. <img width=""2032"" alt=""Screen Shot 2023-05-22 at 12 30 47"" src=""https://github.com/hail-is/hail/assets/106194/aaa3fbb7-176d-4487-b65e-586c235e2089"">; <img width=""541"" alt=""Screen Shot 2023-05-22 at 12 31 23"" src=""https://github.com/hail-is/hail/assets/106194/016f1089-d08d-4555-ae86-c01353f39c78"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13076#issuecomment-1557548015:401,down,down,401,https://hail.is,https://github.com/hail-is/hail/pull/13076#issuecomment-1557548015,1,['down'],['down']
Availability,"22 13:11:21 MemoryStore: INFO: MemoryStore started with capacity 2.5 GB; 2019-01-22 13:11:22 SparkEnv: INFO: Registering OutputCommitCoordinator; 2019-01-22 13:11:22 log: INFO: Logging initialized @11836ms; 2019-01-22 13:11:22 Server: INFO: jetty-9.3.z-SNAPSHOT; 2019-01-22 13:11:22 Server: INFO: Started @12028ms; 2019-01-22 13:11:22 AbstractConnector: INFO: Started ServerConnector@1433e9ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-01-22 13:11:22 Utils: INFO: Successfully started service 'SparkUI' on port 4040.; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1fc6c1cc{/jobs,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@75771d8a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@56931c6{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@7d4d6f14{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@23f9d06d{/stages,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cdf8858{/stages/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3418c91b{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6e2585c5{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2063dbf5{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:4548,AVAIL,AVAILABLE,4548,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['AVAIL'],['AVAILABLE']
Availability,"22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@25004c63{/api,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@36f9d98a{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@302922c9{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 SparkUI: INFO: Bound SparkUI to 0.0.0.0, and started at http://10.48.225.55:4040; 2019-01-22 13:11:23 DomainSocketFactory: WARN: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-22 13:11:23 Client: INFO: Requesting a new application from cluster with 21 NodeManagers; 2019-01-22 13:11:23 Client: INFO: Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-22 13:11:23 Client: INFO: Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-22 13:11",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:13626,AVAIL,AVAILABLE,13626,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability,"23 | amazon-ebs: Collecting decorator<5; 924 | amazon-ebs: Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); 925 | amazon-ebs: Collecting Deprecated<1.3,>=1.2.10; 926 | amazon-ebs: Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB); 927 | amazon-ebs: Collecting dill<0.4,>=0.3.1.1; 928 | amazon-ebs: Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB); 929 | amazon-ebs:  95.8/95.8 kB 15.3 MB/s eta 0:00:00; 930 | amazon-ebs: Collecting google-auth==1.27.0; 931 | amazon-ebs: Downloading google_auth-1.27.0-py2.py3-none-any.whl (135 kB); 932 | amazon-ebs:  135.6/135.6 kB 30.6 MB/s eta 0:00:00; 933 | amazon-ebs: Collecting google-cloud-storage==1.25.*; 934 | amazon-ebs: Downloading google_cloud_storage-1.25.0-py2.py3-none-any.whl (73 kB); 935 | amazon-ebs:  73.4/73.4 kB 22.1 MB/s eta 0:00:00; 936 | amazon-ebs: Collecting humanize==1.0.0; 937 | amazon-ebs: Downloading humanize-1.0.0-py2.py3-none-any.whl (51 kB); 938 | amazon-ebs:  51.9/51.9 kB 14.6 MB/s eta 0:00:00; 939 | amazon-ebs: Collecting hurry.filesize==0.9; 940 | amazon-ebs: Downloading hurry.filesize-0.9.tar.gz (2.8 kB); 941 | amazon-ebs: Preparing metadata (setup.py): started; 942 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 943 | amazon-ebs: Collecting janus<1.1,>=0.6; 944 | amazon-ebs: Downloading janus-1.0.0-py3-none-any.whl (6.9 kB); 945 | amazon-ebs: Requirement already satisfied: Jinja2==3.0.3 in /usr/local/lib/python3.7/site-packages (3.0.3); 946 | amazon-ebs: Collecting nest_asyncio==1.5.4; 947 | amazon-ebs: Downloading nest_asyncio-1.5.4-py3-none-any.whl (5.1 kB); 948 | amazon-ebs: Requirement already satisfied: numpy<2 in /usr/local/lib64/python3.7/site-packages (1.21.6); 949 | amazon-ebs: Collecting orjson==3.6.4; 950 | amazon-ebs: Downloading orjson-3.6.4-cp37-cp37m-manylinux_2_24_x86_64.whl (249 kB",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:4864,Down,Downloading,4864,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,"23-09-13 16:37:36.613 JVMEntryway: INFO: 4: gs://hail-query-ger0g/jars/be9d88a80695b04a2a9eb5826361e0897d94c042.jar; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 5: worker; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 6: gs://gnomad-tmp-4day/parallelizeAndComputeWithIndex/s_yyHm37RY7YTSWH29gP5SM0RwKxgs9EXbg9_YMf7ho=; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 7: 38854; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 8: 47960; 2023-09-13 16:37:36.613 JVMEntryway: INFO: Yielding control to the QoB Job.; 2023-09-13 16:37:36.614 Worker$: INFO: is.hail.backend.service.Worker be9d88a80695b04a2a9eb5826361e0897d94c042; 2023-09-13 16:37:36.614 Worker$: INFO: running job 38854/47960 at root gs://gnomad-tmp-4day/parallelizeAndComputeWithIndex/s_yyHm37RY7YTSWH29gP5SM0RwKxgs9EXbg9_YMf7ho= with scratch directory '/batch/1c00c7157d4d41bcbf508f12d75329b1'; 2023-09-13 16:37:36.617 GoogleStorageFS$: INFO: Initializing google storage client from service account key; 2023-09-13 16:37:36.821 services: WARN: A limited retry error has occured. We will automatically retry 4 more times. Do not be alarmed. (next delay: 1938). The most recent error was javax.net.ssl.SSLException: Connection reset.; 2023-09-13 16:37:38.893 WorkerTimer$: INFO: readInputs took 2278.496020 ms.; 2023-09-13 16:37:38.893 : INFO: RegionPool: initialized for thread 9: pool-2-thread-1; 2023-09-13 16:37:38.903 : INFO: TaskReport: stage=0, partition=38854, attempt=0, peakBytes=65536, peakBytesReadable=64.00 KiB, chunks requested=0, cache hits=0; 2023-09-13 16:37:38.903 : INFO: RegionPool: FREE: 64.0K allocated (64.0K blocks / 0 chunks), regions.size = 1, 0 current java objects, thread 9: pool-2-thread-1; 2023-09-13 16:37:38.903 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.GeneratedMethodAccessor48.invoke(Unknown Source) ~[?:?]; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]; 	at java.lang.reflect.Method",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13356#issuecomment-1719508553:1640,error,error,1640,https://hail.is,https://github.com/hail-is/hail/issues/13356#issuecomment-1719508553,1,['error'],['error']
Availability,"24, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/test.py"", line 10, in <module>; expr = hl.any(lambda x:; File ""/home/edmund/.local/src/hail/hail/python/hail/expr/functions.py"", line 3530, in any; collection = arg_check(args[1], 'any', 'collection', collection_type); File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 586, in arg_check; raise TypeError(""{fname}: parameter '{argname}': ""; TypeError: any: parameter 'collection': expected expression of type set<any> or array<any>, found list: [['10', 123, 'G', 'C'], ['10', 456, 'T', 'A']]; ```; So, hail doesn't support heterogeneous arrays. Converting to a homogeneous array:. ```python; variants = [(""10"", 123, [""G"", ""C""]), (""10"", 456, [""T"", ""A""])]. expr = hl.any(; lambda x:; (mt.locus.contig == hl.literal(x[0])) & \; (mt.locus.position == hl.literal(int(x[1]))) & \; (mt.alleles == hl.literal(x[2])),; variants; ). hl.eval(expr). ```; Leads to the following error (which looks like the bug!):; ```; Traceback (most recent call last):; File ""test.py"", line 10, in <module>; expr = hl.any(lambda x:; File ""/home/edmund/.local/src/hail/hail/python/hail/expr/functions.py"", line 3531, in any; return collection.any(f); File ""<decorator-gen-510>"", line 2, in any; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 68, in any; return hl.array(self).fold(lambda accum, elt: accum | f(elt), False); File ""<decorator-gen-518>"", line 2, in fold; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 221, in fold; return collection._to_stream().fold(lambda x, y: f(x, y), zero); File ""<decorator-gen-650>"", line 2, in fold; File ""/h",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13046#issuecomment-1624278982:5135,error,error,5135,https://hail.is,https://github.com/hail-is/hail/issues/13046#issuecomment-1624278982,1,['error'],['error']
Availability,"24-04-08&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab_server+involves%3AAshokChoudhary11+updated%3A2024-03-11..2024-04-08&amp;type=Issues""><code>@AshokChoudhary11</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab_server+involves%3Aholzman+updated%3A2024-03-11..2024-04-08&amp;type=Issues""><code>@holzman</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab_server+involves%3Amanics+updated%3A2024-03-11..2024-04-08&amp;type=Issues""><code>@manics</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab_server+involves%3Awelcome+updated%3A2024-03-11..2024-04-08&amp;type=Issues""><code>@welcome</code></a></p>; <!-- raw HTML omitted -->; <h2>2.25.4</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab_server/compare/v2.25.3...15e796699f04e06db9ed23a689d454feae36ffbd"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Use updated releaser workflows <a href=""https://redirect.github.com/jupyterlab/jupyterlab_server/pull/442"">#442</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Use json5 typings <a href=""https://redirect.github.com/jupyterlab/jupyterlab_server/pull/441"">#441</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Enforce pytest 7 <a href=""https://redirect.github.com/jupyterlab/jupyterlab_server/pull/439"">#439</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Fix test util typings <a href=""https://redirect.github.com/jupyterlab/jupyterlab_server/pull/437"">#437</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab_server/graphs/contributors?from=2024-02-14&amp;to=2024-03-11&amp;type=c"">GitHub contributors page for this release</a>)</p>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14483:5312,Mainten,Maintenance,5312,https://hail.is,https://github.com/hail-is/hail/pull/14483,1,['Mainten'],['Maintenance']
Availability,"24.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB);  53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB);  97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB);  53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; +",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:29985,Down,Downloading,29985,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['Down'],['Downloading']
Availability,"245227,; ""duration"": 10461; },; ""starting"": {; ""start_time"": 1586188234767,; ""finish_time"": 1586188236190,; ""duration"": 1423; },; ""running"": {; ""start_time"": 1586188236190,; ""finish_time"": 1586188245227,; ""duration"": 9037; },; ""uploading_log"": {; ""start_time"": 1586188245231,; ""finish_time"": 1586188245276,; ""duration"": 45; },; ""deleting"": {; ""start_time"": 1586188245276,; ""finish_time"": 1586188245305,; ""duration"": 29; }; },; ""container_status"": {; ""state"": ""exited"",; ""started_at"": ""2020-04-06T15:50:36.182009912Z"",; ""finished_at"": ""2020-04-06T15:50:44.884808909Z"",; ""out_of_memory"": false,; ""exit_code"": 0; }; },; ""main"": {; ""name"": ""main"",; ""state"": ""error"",; ""timing"": {; ""pulling"": {; ""start_time"": 1586188245305,; ""finish_time"": 1586188245404,; ""duration"": 99; },; ""creating"": {; ""start_time"": 1586188245404,; ""finish_time"": 1586188245457,; ""duration"": 53; },; ""runtime"": {; ""start_time"": 1586188245458,; ""finish_time"": 1586189446263,; ""duration"": 1200805; },; ""starting"": {; ""start_time"": 1586188245458,; ""finish_time"": 1586188246261,; ""duration"": 803; },; ""running"": {; ""start_time"": 1586188246262,; ""finish_time"": 1586189446263,; ""duration"": 1200001; },; ""uploading_log"": {; ""start_time"": 1586189446266,; ""finish_time"": 1586189446350,; ""duration"": 84; },; ""deleting"": {; ""start_time"": 1586189446351,; ""finish_time"": 1586189456802,; ""duration"": 10451; }; },; ""error"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/site-packages/batch/worker.py\"", line 387, in run\n raise JobTimeoutError(f'timed out after {self.timeout}s')\nJobTimeoutError: timed out after 1200s\n"",; ""container_status"": {; ""state"": ""running"",; ""started_at"": ""2020-04-06T15:50:46.250931386Z"",; ""finished_at"": ""0001-01-01T00:00:00Z"",; ""out_of_memory"": false,; ""exit_code"": 0; }; }; },; ""start_time"": 1586188245458,; ""end_time"": 1586189446263; },; ""spec"": {; ""command"": [; ""bash"",; ""-c"",; ""export HAIL_DEPLOY_CONFIG_FILE=/deploy-config/deploy-config.json\nexport SCRATCH=gs://hail-test-dmk9z/o1111h6zx",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8473:1381,error,error,1381,https://hail.is,https://github.com/hail-is/hail/issues/8473,2,['error'],['error']
Availability,"2466143828b9b69494c6cb6f2b""><code>15cf7ee</code></a> Bump up version number to 5.3.1-SNAPSHOT</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e3c65ffcb49b9c5a33fde5f31fb63043dbf21134""><code>e3c65ff</code></a> Allow extensions to be created from tasks</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/34e2dd41477f18b1ae3d6d5a71dca5449d6cd1e0""><code>34e2dd4</code></a> Downgrade slf4j to fix warning on console about missing slf4j provider</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b3fa29f9ffb4d4544e13ef84601e371fb2778ddf""><code>b3fa29f</code></a> Revert &quot;Update Apache HttpClient to 5.2.1&quot;</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/01f05e046be0dca18f506723c79e88f208336e71""><code>01f05e0</code></a> Add integration tests for Gradle 6.9.3 and 7.6</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a998a544908a8b39f713f4526f717fcb328c06eb""><code>a998a54</code></a> Upgrade Gradle to 7.6</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.0...5.3.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.0&new-version=5.3.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:2982,down,download-task,2982,https://hail.is,https://github.com/hail-is/hail/pull/12707,1,['down'],['download-task']
Availability,"24d070c815e02f6f5b), and gnomad_qc (0c52cf47e48fa5b503d874e96482ea4286474c71). I cloned the repo in question; ```bash; pip3 uninstall hail gnomad gnomad_qc. pip3 install -U \; hail \; git+https://github.com/broadinstitute/gnomad_methods.git \; git+https://github.com/broadinstitute/gnomad_qc.git. git clone git@github.com:broadinstitute/gnomad-readviz.git; ```. I applied this patch:; ```diff; diff --git a/step1__select_samples.py b/step1__select_samples.py; index c159207..9ba1812 100644; --- a/step1__select_samples.py; +++ b/step1__select_samples.py; @@ -38,14 +38,7 @@ def hemi_expr(mt):; ; def main(args):; ; - hl.init(log=""/select_samples"", default_reference=""GRCh38"", idempotent=True, tmp_dir=args.temp_bucket); - meta_ht = hl.import_table(args.sample_metadata_tsv, force_bgz=True); - meta_ht = meta_ht.key_by(""s""); - meta_ht = meta_ht.filter(hl.is_defined(meta_ht.cram_path) & hl.is_defined(meta_ht.crai_path), keep=True); - meta_ht = meta_ht.repartition(1000); - meta_ht = meta_ht.checkpoint(; - re.sub("".tsv(.b?gz)?"", """", args.sample_metadata_tsv) + "".ht"", overwrite=True, _read_if_exists=True); -; + hl.init(log=""/tmp/select_samples"", default_reference=""GRCh38"", idempotent=True, tmp_dir=args.temp_bucket); vds = gnomad_v4_genotypes.vds(); ; # see https://github.com/broadinstitute/ukbb_qc/pull/227/files; @@ -55,19 +48,8 @@ def main(args):; ; v4_qc_meta_ht = meta.ht(); ; - mt = vds.variant_data; - #mt = vds.variant_data._filter_partitions([41229]); -; - mt = mt.filter_cols(v4_qc_meta_ht[mt.s].release); -; - meta_join = meta_ht[mt.s]; - mt = mt.annotate_cols(; - meta=hl.struct(; - sex_karyotype=meta_join.sex_karyotype,; - cram=meta_join.cram_path,; - crai=meta_join.crai_path,; - ); - ); + #mt = vds.variant_data; + mt = vds.variant_data._filter_partitions([41229]); ; logger.info(""Adjusting samples' sex ploidy""); lgt_expr = hl.if_else(; @@ -88,9 +70,9 @@ def main(args):; logger.info(""Filter variants with at least one non-ref GT""); mt = mt.filter_rows(hl.agg.any(mt.GT.is_non_ref",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13248#issuecomment-1703383664:1069,checkpoint,checkpoint,1069,https://hail.is,https://github.com/hail-is/hail/issues/13248#issuecomment-1703383664,1,['checkpoint'],['checkpoint']
Availability,"280; 2. 25997 https://batch.hail.is/batches/8083195/jobs/27937. The pipeline runs two table collects to get sample information, then converts the matrix table to a table of ndarrays of the value `hl.int(hl.is_defined(mt.GT))`. The entries are getting subsetted, so there is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""BlockingBufferSpec"",""blockSize"":65536,""child"":; {""name"":""ZstdBlockBufferSpec"",""blockSize"":65536,""child"":; {""name"":""StreamBlockBuff",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:1120,error,error,1120,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623,1,['error'],['error']
Availability,"2814; 2815 return cleanup(MatrixTable(base._jvds.selectRows(row._ast.to_hql(),; -> 2816 new_key))); 2817; 2818 @typecheck_method(caller=str,. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-c8ca698c6ed5.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NegativeArraySizeException: null. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 24 in stage 9.0 failed 20 times, most recent failure: Lost task 24.19 in stage 9.0 (TID 2874, berylc-sw-68wx.c.broad-mpg-gnomad.internal, executor 39): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:140); 	at is.hail.annotations.Region.allocate(Region.scala:153); 	at is.hail.annotations.Region.allocate(Region.scala:160); 	at is.hail.codegen.generated.C11.apply(Unknown Source); 	at is.hail.codegen.generated.C11.apply(Unknown Source); 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:650); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:245); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:218); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$czip$1$$anon$1.next(ContextRDD.scala:333); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:915); 	at is.hail.rvd.Ordered",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3583:3706,failure,failure,3706,https://hail.is,https://github.com/hail-is/hail/issues/3583,1,['failure'],['failure']
Availability,28e7fc84686936ffd4f370c8c104b2d78b2a ']'; + echo GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a; GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a; + for varname in '$arguments'; + '[' -z origin ']'; + echo REMOTE=origin; REMOTE=origin; + for varname in '$arguments'; + '[' -z build/deploy/dist/hail-0.2.128-py3-none-any.whl ']'; + echo WHEEL=build/deploy/dist/hail-0.2.128-py3-none-any.whl; WHEEL=build/deploy/dist/hail-0.2.128-py3-none-any.whl; + for varname in '$arguments'; + '[' -z abc123 ']'; + echo GITHUB_OAUTH_HEADER_FILE=abc123; GITHUB_OAUTH_HEADER_FILE=abc123; + for varname in '$arguments'; + '[' -z abc123 ']'; + echo HAIL_GENETICS_HAIL_IMAGE=abc123; HAIL_GENETICS_HAIL_IMAGE=abc123; + for varname in '$arguments'; + '[' -z a ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_10=a; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=a; + for varname in '$arguments'; + '[' -z b ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_11=b; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=b; + for varname in '$arguments'; + '[' -z c ']'; + echo HAIL_GENETICS_HAILTOP_IMAGE=c; HAIL_GENETICS_HAILTOP_IMAGE=c; + for varname in '$arguments'; + '[' -z d ']'; + echo HAIL_GENETICS_VEP_GRCH37_85_IMAGE=d; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=d; + for varname in '$arguments'; + '[' -z e ']'; + echo HAIL_GENETICS_VEP_GRCH38_95_IMAGE=e; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=e; + for varname in '$arguments'; + '[' -z f ']'; + echo WHEEL_FOR_AZURE=f; WHEEL_FOR_AZURE=f; + for varname in '$arguments'; + '[' -z g ']'; + echo WEBSITE_TAR=g; WEBSITE_TAR=g; + exit 1; make: *** [release] Error 1; ```. ```sh; # WEBSITE_TAR=g WHEEL_FOR_AZURE=f HAIL_GENETICS_VEP_GRCH38_95_IMAGE=e HAIL_GENETICS_VEP_GRCH37_85_IMAGE=d HAIL_GENETICS_HAILTOP_IMAGE=c HAIL_GENETICS_HAIL_IMAGE_PY_3_11=b HAIL_GENETICS_HAIL_IMAGE_PY_3_10=a HAIL_GENETICS_HAIL_IMAGE=abc123 GITHUB_OAUTH_HEADER_FILE=abc123 DEPLOY_REMOTE= make -C hail release; HAIL_PIP_VERSION=0.2.128 \; HAIL_VERSION=0.2.128-91d328e7fc84 \; GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a \; REMOTE= \; WHEE,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:12196,echo,echo,12196,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,10,"['Error', 'echo']","['Error', 'echo']"
Availability,"2::uint32<16>]; libsimdpp-2.0-rc2/simdpp/types/int32.h:50:35: required from simdpp::arch_avx2::int32<N>& simdpp::arch_avx2::int32<N>::operator=(const simdpp::arch_avx2::any_vec<(N * 4), V>&) [with V = simdpp::arch_avx2::uint32<16>; unsigned int N = 16]; libsimdpp-2.0-rc2/simdpp/types/int32.h:43:73: required from simdpp::arch_avx2::int32<N>::int32(const simdpp::arch_avx2::uint32<N, E>&) [with E = void; unsigned int N = 16]; libsimdpp-2.0-rc2/simdpp/core/combine.h:73:69: required from simdpp::arch_avx2::int32<(N * 2)> simdpp::arch_avx2::combine(const simdpp::arch_avx2::int32<N, E>&, const simdpp::arch_avx2::int32<N, E2>&) [with unsigned int N = 8; E1 = void; E2 = void]; libsimdpp-2.0-rc2/simdpp/detail/insn/to_int32.h:74:26: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int32<16> with private member simdpp::arch_avx2::int32<16>::d_ from an array of const class simdpp::arch_avx2::uint32<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:37,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32.h:31:7: note: class simdpp::arch_avx2::int32<16> declared here; class int32<N, void> : public any_int32<N, int32<N,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int32<8>; T = simdpp::arch_avx2::uint32<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:129600,error,error,129600,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.1-0320a61; Error summary: HailException: arguments refer to no",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:2467,Error,ErrorHandling,2467,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071,1,['Error'],['ErrorHandling']
Availability,"2](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **444/1000** <br/> **Why?** Has a fix available, CVSS 4.6 | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **429/1000** <br/> **Why?** Has a fix available, CVSS 4.3 | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **501/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.3 | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14109:3115,avail,available,3115,https://hail.is,https://github.com/hail-is/hail/pull/14109,1,['avail'],['available']
Availability,"2a9-4d26-ac71-5e6676ff3392/pyscripts_F47nn5.zip/gnomad_hail/slack_utils.py"", line 77, in try_slack; File ""/tmp/88fe16cd-42a9-4d26-ac71-5e6676ff3392/generate_qc_annotations.py"", line 203, in main; vds.write(annotations_vds_path(data_type, 'truth_data'), args.overwrite); File ""<decorator-gen-528>"", line 2, in write; File ""/tmp/88fe16cd-42a9-4d26-ac71-5e6676ff3392/hail-devel-6d6d3d2d7992.zip/hail/typecheck/check.py"", line 479, in _typecheck; File ""/tmp/88fe16cd-42a9-4d26-ac71-5e6676ff3392/hail-devel-6d6d3d2d7992.zip/hail/matrixtable.py"", line 1807, in write; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/88fe16cd-42a9-4d26-ac71-5e6676ff3392/hail-devel-6d6d3d2d7992.zip/hail/utils/java.py"", line 238, in deco; hail.utils.java.FatalError: HailException: found non-left aligned variant: 18:76051965:C:G. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 56 in stage 3.0 failed 20 times, most recent failure: Lost task 56.19 in stage 3.0 (TID 685, exomes2-sw-8mf1.c.broad-mpg-gnomad.internal, executor 55): is.hail.utils.HailException: found non-left aligned variant: 18:76051965:C:G; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.methods.SplitMultiPartitionContext.splitRow(SplitMulti.scala:98); 	at is.hail.methods.SplitMulti$$anonfun$split$1$$anonfun$apply$1.apply(SplitMulti.scala:226); 	at is.hail.methods.SplitMulti$$anonfun$split$1$$anonfun$apply$1.apply(SplitMulti.scala:225); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.hasNext(OrderedRVD.scala:733); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.hasNext(OrderedRVD.scala:733); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3040:1425,failure,failure,1425,https://hail.is,https://github.com/hail-is/hail/issues/3040,1,['failure'],['failure']
Availability,2pfXIoSO&uploadType=resumable&upload_id=ADPycdvZ5HhnGfOKt5TE1qXWiHpqIpZnXVTYWuWUCXNPRF9HqyCB-4LvRsxNX6SUWRgk13pYrzYaa9-wXlvNZt1oct0ptaEz0bS3; chunkOffset: 16777216; chunkLength: 0; localOffset: 268435456; remoteOffset: 285212672; lastChunk: false. 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:267); 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 		at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); 		at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 		at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:189); 		at is.hail.relocated.com.google.cloud.BaseWriteChannel.flush(BaseWriteChannel.java:112); 		at is.hail.relocated.com.google.cloud.BaseWriteChannel.write(BaseWriteChannel.java:139); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$flush$1(GoogleStorageFS.scala:317); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:299); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.flush(GoogleStorageFS.scala:317); 		at is.hail.io.fs.FSPositionedOutputStream.write(FS.scala:227); 		at java.io.DataOutputStream.write(DataOutputStream.java:107); 		at is.hail.fs.FSSuite.$anonfun$testSeekMoreThanMaxInt$1(FSSuite.scala:347); 		at is.hail.fs.FSSuite.$anonfun$testSeekMoreThanMaxInt$1$adapted(FSSuite.scala:341); 		at is.hail.utils.package$.using(package.scala:635); 		... 26 more. test is.hail.fs.gs.GoogleStorageFSSuite.testSeekMoreThanMaxInt FAILURE; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911:9368,FAILURE,FAILURE,9368,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911,1,['FAILURE'],['FAILURE']
Availability,"3 try:; ---> 74 result = json.loads(self._jhc.backend().executeJSON(jir)); 75 value = ir.typ._from_json(result['value']); 76 timings = result['timings']. /usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py in __call__(self, *args); 1302; 1303 answer = self.gateway_client.send_command(command); -> 1304 return_value = get_return_value(; 1305 answer, self.gateway_client, self.target_id, self.name); 1306. /opt/conda/miniconda3/lib/python3.8/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 28 raise FatalError('Error summary: %s' % (deepest,), error_id) from None; 29 else:; ---> 30 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 31 'Hail version: %s\n'; 32 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None. FatalError: NoClassDefFoundError: Could not initialize class __C147RGContainer_GRCh38. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19) (my-first-hail-cluster-w-0.c.open-targets-eu-dev.internal executor 1): java.lang.NoClassDefFoundError: Could not initialize class __C147RGContainer_GRCh38; 	at __C144Compiled.applyregion0_8(Emit.scala); 	at __C144Compiled.apply(Emit.scala); 	at is.hail.expr.ir.TableMapRows.$anonfun$execute$43(TableIR.scala:1938); 	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23); 	at scala.collection.Iterator$$anon$10.next(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:496); 	at is.hail.utils.richUtils.RichContextRDD$$anon$1.next(RichContextRDD.scala:79); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:496); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:415); 	at is.hail.rvd.RVD.$anonfun$head$2(RVD.scala:526); 	at is.hail.rvd.RVD.$anonfun$head$2$adapted(RVD.scala:526); 	at is.hail.sparkextras.ContextRDD.$anonfun$runJob$2(ContextRDD.scala:366); 	at is.hail.sparkext",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:6044,failure,failure,6044,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['failure'],['failure']
Availability,"3""><code>@blink1073</code></a>)</li>; <li>Clean up 7.x workflows <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/865"">#865</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2022-10-25&amp;to=2022-11-10&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2022-10-25..2022-11-10&amp;type=Issues""><code>@blink1073</code></a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_client/blob/v7.4.5/CHANGELOG.md"">jupyter-client's changelog</a>.</em></p>; <blockquote>; <h2>7.4.5</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.4.4...d27c8a497c6cbb1a232fbbe75cb1fd0f53faa9b0"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>[7.x] Handle Jupyter Core Warning <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/875"">#875</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Clean up 7.x workflows <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/865"">#865</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2022-10-25&amp;to=2022-11-10&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2022-10-25..2022-11-10&amp;type=Issues""><code>@blink1073</code></a></p>; <!-- raw HTML omitted -->; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jupyter/jupyter_clie",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12459:1666,Mainten,Maintenance,1666,https://hail.is,https://github.com/hail-is/hail/pull/12459,1,['Mainten'],['Maintenance']
Availability,"3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 225 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 226 'Hail version: %s\n'; --> 227 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 228 except pyspark.sql.utils.CapturedException as e:; 229 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: AssertionError: assertion failed: type mismatch:; name: global; actual: Struct{bn:Struct{n_populations:Int32,n_samples:Int32,n_variants:Int32,n_partitions:Int32,pop_dist:Array[Int32],fst:Array[Float64],mixture:Boolean},__uid_882:Array[Struct{sample_idx:Int32,pop:Int32,s:String}]}; expect: Struct{bn:Struct{n_populations:Int32,n_samples:Int32,n_variants:Int32,n_partitions:Int32,pop_dist:Array[Int32],fst:Array[Float64],mixture:Boolean},__cols:Array[Struct{sample_idx:Int32,pop:Int32,s:String}]}. Java stack trace:; is.hail.utils.HailException: Error while typechecking IR:; (MakeStruct; (bn; (GetField bn; (Ref global)))); 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:16); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:45); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:32); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:77); 	at is.hail.expr.ir.TableMapGlobals$$anonfun$38.apply(TableIR.scala:856); 	at is.hail.expr.ir.TableMapGlobals$$anonfun$38.apply(TableIR.scala:846); 	at is.hail.utils.package$.using(package.scala:587); 	at is.hail.annotations.Region$.scoped(Region.scala:13); 	at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:846); 	at is.hail.expr.ir.TableKeyBy.execute(TableIR.scala:237); 	at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:696); 	at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:838); 	at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:696); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:42); 	at is.hail.table.Table.x$3$lzycompute(Table.scala:211); 	at i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5212:3253,Error,ErrorHandling,3253,https://hail.is,https://github.com/hail-is/hail/issues/5212,1,['Error'],['ErrorHandling']
Availability,"30/hail-1e2e8c7e8.zip/hail/typecheck/check.py"", line 547, in wrapper; File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/hail-1e2e8c7e8.zip/hail/matrixtable.py"", line 2893, in _select_rows; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/hail-1e2e8c7e8.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: RuntimeException: Method code too large!. Java stack trace:; java.lang.RuntimeException: Method code too large!; 	at is.hail.relocated.org.objectweb.asm.MethodWriter.a(Unknown Source); 	at is.hail.relocated.org.objectweb.asm.ClassWriter.toByteArray(Unknown Source); 	at is.hail.asm4s.FunctionBuilder.classAsBytes(FunctionBuilder.scala:306); 	at is.hail.asm4s.FunctionBuilder.result(FunctionBuilder.scala:340); 	at is.hail.expr.CM.runWithDelayedValues(CM.scala:80); 	at is.hail.expr.Parser$.is$hail$expr$Parser$$evalNoTypeCheck(Parser.scala:60); 	at is.hail.expr.Parser$.eval(Parser.scala:73); 	at is.hail.expr.Parser$.parseExpr(Parser.scala:88); 	at is.hail.variant.MatrixTable.selectRows(MatrixTable.scala:1232); 	at is.hail.variant.MatrixTable.selectRows(MatrixTable.scala:1205); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-1e2e8c7e86f3; Error summary: RuntimeException: Method code too large!; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3746:2993,Error,Error,2993,https://hail.is,https://github.com/hail-is/hail/issues/3746,1,['Error'],['Error']
Availability,"31 raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; 32 except pyspark.sql.utils.CapturedException as e:; 33 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: SparkException: Job aborted due to stage failure: Task 0 in stage 23.0 failed 4 times, most recent failure: Lost task 0.3 in stage 23.0 (TID 26) (all-of-us-56-w-0.c.terra-vpc-sc-8f5cdfd2.internal executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1691092255852_0001_01_000005 on host: all-of-us-56-w-0.c.terra-vpc-sc-8f5cdfd2.internal. Exit status: 137. Diagnostics: [2023-08-03 20:14:25.441]Container killed on request. Exit code is 137; [2023-08-03 20:14:25.442]Container exited with a non-zero exit code 137. ; [2023-08-03 20:14:25.442]Killed by external signal; .; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 23.0 failed 4 times, most recent failure: Lost task 0.3 in stage 23.0 (TID 26) (all-of-us-56-w-0.c.terra-vpc-sc-8f5cdfd2.internal executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1691092255852_0001_01_000005 on host: all-of-us-56-w-0.c.terra-vpc-sc-8f5cdfd2.internal. Exit status: 137. Diagnostics: [2023-08-03 20:14:25.441]Container killed on request. Exit code is 137; [2023-08-03 20:14:25.442]Container exited with a non-zero exit code 137. ; [2023-08-03 20:14:25.442]Killed by external signal; .; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(Res",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619:4509,failure,failure,4509,https://hail.is,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619,1,['failure'],['failure']
Availability,"32""><code>ab633b6</code></a> Build x86_64 musllinux wheels (<a href=""https://github-redirect.dependabot.com/ijl/orjson/issues/242"">#242</a>)</li>; <li><a href=""https://github.com/ijl/orjson/commit/8bf078b27e7479f2cfbea1bac7155d4449ce7e30""><code>8bf078b</code></a> Cross compile wheels for armv7l on GitHub Actions (<a href=""https://github-redirect.dependabot.com/ijl/orjson/issues/241"">#241</a>)</li>; <li><a href=""https://github.com/ijl/orjson/commit/c196f0e55bd51d3693d381ccc06f2fd4b5443d86""><code>c196f0e</code></a> 3.6.6</li>; <li><a href=""https://github.com/ijl/orjson/commit/81890b097f7a479d1c1e697d21467952e0be24a9""><code>81890b0</code></a> Fix 53-bit error on value between isize and usize</li>; <li><a href=""https://github.com/ijl/orjson/commit/8fc1e8989d6a72581aa71533384cb1ef9a260ebc""><code>8fc1e89</code></a> Fast conditional for zoneinfo.ZoneInfo</li>; <li><a href=""https://github.com/ijl/orjson/commit/853ffbdf8dc5f34792765c22aa835e1b67d90a76""><code>853ffbd</code></a> fix(errors): adjust column offset if not at char boundary</li>; <li>Additional commits viewable in <a href=""https://github.com/ijl/orjson/compare/3.6.4...3.6.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=orjson&package-manager=pip&previous-version=3.6.4&new-version=3.6.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11572:4114,error,errors,4114,https://hail.is,https://github.com/hail-is/hail/pull/11572,1,['error'],['errors']
Availability,"3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `2.11.3 -> 3.1.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **604/1000** <br/> **Why?** Has a fix available, CVSS 7.8 | Improper Privilege Management <br/>[SNYK-PYTHON-JUPYTERCORE-3063766](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERCORE-3063766) | `jupyter-core:` <br> `4.6.3 -> 4.11.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-MISTUNE-2940625](https://snyk.io/vuln/SNYK-PYTHON-MISTUNE-2940625) | `mistune:` <br> `0.8.4 -> 2.0.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **726/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 8.1 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **434/1000** <br/> **Why?** Has a fix available, CVSS 4.4 | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://re",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:3616,avail,available,3616,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['avail'],['available']
Availability,35); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:234); 	at scala.Function1$$anonfun$andThen$1.apply(Function1.scala:52); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; ```. _All_ of my workers had this error:; ```; java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:6595,error,error,6595,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681,1,['error'],['error']
Availability,36 --gvcf-gq-bands 37 --gvcf-gq-bands 38 --gvcf-gq-bands 39 --gvcf-gq-bands 40 --gvcf-gq-bands 41 --gvcf-gq-bands 42 --gvcf-gq-bands 43 --gvcf-gq-bands 44 --gvcf-gq-bands 45 --gvcf-gq-bands 46 --gvcf-gq-bands 47 --gvcf-gq-bands 48 --gvcf-gq-bands 49 --gvcf-gq-bands 50 --gvcf-gq-bands 51 --gvcf-gq-bands 52 --gvcf-gq-bands 53 --gvcf-gq-bands 54 --gvcf-gq-bands 55 --gvcf-gq-bands 56 --gvcf-gq-bands 57 --gvcf-gq-bands 58 --gvcf-gq-bands 59 --gvcf-gq-bands 60 --gvcf-gq-bands 70 --gvcf-gq-bands 80 --gvcf-gq-bands 90 --gvcf-gq-bands 99 --indel-size-to-eliminate-in-ref-model 10 --use-alleles-trigger false --disable-optimizations false --just-determine-active-regions false --dont-genotype false --max-mnp-distance 0 --dont-trim-active-regions false --max-disc-ar-extension 25 --max-gga-ar-extension 300 --padding-around-indels 150 --padding-around-snps 20 --kmer-size 10 --kmer-size 25 --dont-increase-kmer-sizes-for-cycles false --allow-non-unique-kmers-in-ref false --num-pruning-samples 1 --recover-dangling-heads false --do-not-recover-dangling-branches false --min-dangling-branch-length 4 --consensus false --max-num-haplotypes-in-population 128 --error-correct-kmers false --min-pruning 2 --debug-graph-transformations false --kmer-length-for-read-error-correction 25 --min-observations-for-kmer-to-be-solid 20 --likelihood-calculation-engine PairHMM --base-quality-score-threshold 18 --pair-hmm-gap-continuation-penalty 10 --pair-hmm-implementation FASTEST_AVAILABLE --pcr-indel-model CONSERVATIVE --phred-scaled-global-read-mismapping-rate 45 --native-pair-hmm-threads 4 --native-pair-hmm-use-double-precision false --debug false --use-filtered-reads-for-annotations false --bam-writer-type CALLED_HAPLOTYPES --dont-use-soft-clipped-bases false --capture-assembly-failure-bam false --error-correct-reads false --do-not-run-physical-phasing false --min-base-quality-score 10 --smith-waterman JAVA --use-new-qual-calculator false --annotate-with-num-discovered-alleles false --heterozygosity 0.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:2605,recover,recover-dangling-heads,2605,https://hail.is,https://github.com/hail-is/hail/issues/8469,6,"['error', 'failure', 'recover']","['error-correct-kmers', 'error-correct-reads', 'error-correction', 'failure-bam', 'recover-dangling-branches', 'recover-dangling-heads']"
Availability,"37.559 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=132096, peakBytesReadable=129.00 KiB, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.560 : INFO: RegionPool: FREE: 129.0K allocated (129.0K blocks / 0 chunks), regions.size = 3, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.561 : ERROR: error while applying lowering 'LowerAndExecuteShuffles'; 2023-05-04 01:04:37.600 : INFO: RegionPool: initialized for thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:23545,ERROR,ERROR,23545,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['ERROR'],['ERROR']
Availability,"37</a></li>; <li>Fix typing errors with recent versions of mypy <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/769"">#769</a></li>; <li>Prevent DeprecationWarning about internal use of <code>asyncio.get_event_loop()</code> from affecting test cases <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/757"">#757</a></li>; </ul>; <h2>Known issues</h2>; <p>As of v0.23, pytest-asyncio attaches an asyncio event loop to each item of the test suite (i.e. session, packages, modules, classes, functions) and allows tests to be run in those loops when marked accordingly. Pytest-asyncio currently assumes that async fixture scope is correlated with the new event loop scope. This prevents fixtures from being evaluated independently from the event loop scope and breaks some existing test suites (see <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/706"">#706</a>). For example, a test suite may require all fixtures and tests to run in the same event loop, but have async fixtures that are set up and torn down for each module. If you're affected by this issue, please continue using the v0.21 release, until it is resolved.</p>; <h2>pytest-asyncio 0.23.5</h2>; <h1>0.23.5 (2024-02-09)</h1>; <ul>; <li>Declare compatibility with pytest 8 <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/737"">#737</a></li>; <li>Fix typing errors with recent versions of mypy <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/769"">#769</a></li>; <li>Prevent DeprecationWarning about internal use of <code>asyncio.get_event_loop()</code> from affecting test cases <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/757"">#757</a></li>; </ul>; <h2>Known issues</h2>; <p>As of v0.23, pytest-asyncio attaches an asyncio event loop to each item of the test suite (i.e. session, packages, modules, classes, functions) and allows tests to be run in those loops when marked accordingly. Pytest-asyncio currently a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14507:2547,down,down,2547,https://hail.is,https://github.com/hail-is/hail/pull/14507,1,['down'],['down']
Availability,"37</a></li>; <li>Fix typing errors with recent versions of mypy <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/769"">#769</a></li>; <li>Prevent DeprecationWarning about internal use of <code>asyncio.get_event_loop()</code> from affecting test cases <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/757"">#757</a></li>; </ul>; <h2>Known issues</h2>; <p>As of v0.23, pytest-asyncio attaches an asyncio event loop to each item of the test suite (i.e. session, packages, modules, classes, functions) and allows tests to be run in those loops when marked accordingly. Pytest-asyncio currently assumes that async fixture scope is correlated with the new event loop scope. This prevents fixtures from being evaluated independently from the event loop scope and breaks some existing test suites (see <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/706"">#706</a>). For example, a test suite may require all fixtures and tests to run in the same event loop, but have async fixtures that are set up and torn down for each module. If you're affected by this issue, please continue using the v0.21 release, until it is resolved.</p>; <h2>pytest-asyncio 0.23.5a0</h2>; <h1>0.23.5 (UNRELEASED)</h1>; <ul>; <li>Declare compatibility with pytest 8 <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/737"">#737</a></li>; <li>Fix typing errors with recent versions of mypy <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/769"">#769</a></li>; </ul>; <h2>Known issues</h2>; <p>As of v0.23, pytest-asyncio attaches an asyncio event loop to each item of the test suite (i.e. session, packages, modules, classes, functions) and allows tests to be run in those loops when marked accordingly. Pytest-asyncio currently assumes that async fixture scope is correlated with the new event loop scope. This prevents fixtures from being evaluated independently from the event loop scope and breaks some existing test suites (see <a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14507:3917,down,down,3917,https://hail.is,https://github.com/hail-is/hail/pull/14507,1,['down'],['down']
Availability,"3:4041; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.11-cf54f08305d1; LOGGING: writing to /Users/dking/hail-20190327-1827-0.2.11-cf54f08305d1.log; Traceback (most recent call last):; File ""<stdin>"", line 4, in <module>; File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/matrixtable.py"", line 2371, in count; return (self.count_rows(), self.count_cols()); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/matrixtable.py"", line 2331, in count_rows; TableCount(MatrixRowsTable(self._mir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/backend/backend.py"", line 94, in execute; self._to_java_ir(ir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/utils/java.py"", line 227, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): is.hail.utils.HailException: foo: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; offending line: 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.utils.Context.wrapException(Context.scala:19); 	at is.hail.utils.WithContext.wrap(Context.scala:43); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:2203,Error,Error,2203,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['Error'],['Error']
Availability,"3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed.; argon2-cffi-bindings 21.2.0 requires cffi, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3OWQ3MTdiYy05MThjLTRlMjctOGQ2OC0xNTNhNWI",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13850:1127,avail,available,1127,https://hail.is,https://github.com/hail-is/hail/pull/13850,1,['avail'],['available']
Availability,"3a90b7747b8972f51d1407616c51084d97c589"">803a90b</a>)</li>; <li>Update dependency net.jqwik:jqwik to v1.7.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1758"">#1758</a>) (<a href=""https://github.com/googleapis/java-storage/commit/140e90911229c876de7b674dd1e61b278e8b07fd"">140e909</a>)</li>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.17 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1759"">#1759</a>) (<a href=""https://github.com/googleapis/java-storage/commit/7e3175a56a06dac0aa0841f221a486bb69b5c9bf"">7e3175a</a>)</li>; </ul>; <h2>v2.14.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.13.1...v2.14.0"">2.14.0</a> (2022-10-26)</h2>; <h3>Google Cloud Storage gRPC API Preview</h3>; <p>The first release of <code>google-cloud-storage</code> with support for a subset of the Google Cloud Storage gRPC API which is in private preview. The most common operations have all been implemented and are available for experimentation.</p>; <p>Given not all public api surface of <code>google-cloud-storage</code> classes are supported for gRPC a new annotation <code>@TransportCompatibility</code> has been added to various classes, methods and fields/enum values to signal where that thing can be expected to work. As we implement more of the operations these annotations will be updated.</p>; <p>All new gRPC related APIs are annotated with <code>@BetaApi</code> to denote they are in preview and the possibility of breaking change is present. At this time, opting to use any of the gRPC transport mode means you are okay with the possibility of a breaking change happening. When the APIs are out of preview, we will remove the <code>@BetaApi</code> annotation to signal they are now considered stable and will not break outside a major version.</p>; <p><strong><em>NOTICE</em></strong>: Using the gRPC transport is exclusive. Any operations which have not yet been implemented for gRPC",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12456:2245,avail,available,2245,https://hail.is,https://github.com/hail-is/hail/pull/12456,2,['avail'],['available']
Availability,"4 (Krishnan Mahadevan); 7.6.0; Fixed: GITHUB-2741: Show fully qualified name of the test instead of just the function name for better readability of test output.(Krishnan Mahadevan); Fixed: GITHUB-2725: Honour custom attribute values in TestNG default reports (Krishnan Mahadevan); Fixed: GITHUB-2726: <a href=""https://github.com/AfterClass""><code>@AfterClass</code></a> config method is executed for EACH <a href=""https://github.com/Test""><code>@Test</code></a> method when parallel == methods (Krishnan Mahadevan); Fixed: GITHUB-2752: TestListener is being lost when implenting both IClassListener and ITestListener (Krishnan Mahadevan); New: GITHUB-2724: DataProvider: possibility to unload dataprovider class, when done with it (Dzmitry Sankouski); Fixed: GITHUB-217: Configure TestNG to fail when there's a failure in data provider (Krishnan Mahadevan); Fixed: GITHUB-2743: SuiteRunner could not be initial by default Configuration (Nan Liang); Fixed: GITHUB-2729: beforeConfiguration() listener method should be invoked for skipped configurations as well(Nan Liang); Fixed: assertEqualsNoOrder for Collection and Iterators size check was missing (Adam Kaczmarek); Fixed: GITHUB-2709: Testnames not working together with suites in suite (Martin Aldrin); Fixed: GITHUB-2704: IHookable and IConfigurable callback discrepancy (Krishnan Mahadevan); Fixed: GITHUB-2637: Upgrade to JDK11 as the minimum JDK requirements (Krishnan Mahadevan); Fixed: GITHUB-2734: Keep the initial order of listeners (Andrei Solntsev); Fixed: GITHUB-2359: Testng <a href=""https://github.com/BeforeGroups""><code>@BeforeGroups</code></a> is running in parallel with testcases in the group (Anton Velma); Fixed: Possible StringIndexOutOfBoundsException in XmlReporter (Anton Velma); Fixed: GITHUB-2754: <a href=""https://github.com/AfterGroups""><code>@AfterGroups</code></a> is executed for each &quot;finished&quot; group when it has multiple groups defined (Anton Velma)</p>; <p>7.5; Fixed: GITHUB-2701: Bump gradle ve",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:13257,failure,failure,13257,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['failure'],['failure']
Availability,"4.2</li>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0f43ce67de72bd511d849c07bd7728c0d6f2e6dd""><code>0f43ce6</code></a> Document path and relativePath properties</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a8504f9d60d0264808894e4bb80d4a73b8086a3e""><code>a8504f9</code></a> Bump up version number to 5.3.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/708067cd11c4a013da7a8c15d91f7f946967cf94""><code>708067c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0fdebf3c7ad43ed4739d0400c333a72b32f5d514""><code>0fdebf3</code></a> Improve verify example</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/019089b9554692674d6baee7df7d4d884f310cc9""><code>019089b</code></a> Correctly create list of output files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/fa2739ded05333ba46d8f50bb3b2a3721cf0ca86""><code>fa2739d</code></a> Create target directories at a central place</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/02b8e1a79d9e00acd61f9ac42e5555619fe2247a""><code>02b8e1a</code></a> Prevent duplicate destination files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0b65ca2f17c8890a3ec34cf80cde52ee5413cbec""><code>0b65ca2</code></a> Call eachFile action only once per source</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/717877121299cea8f216d3a595eaa56731a6acd3""><code>7178771</code></a> Support changing a target file's relative path in an eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e5af1bd7f9daa8a9222aee0dd1b703727cb5e94e""><code>e5af1bd</code></a> Bump vers",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:3925,down,download-task,3925,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download-task']
Availability,"4.7 to download on laptop, 1.5 to download on k8s. About 1.2 seconds to untar in either setting. That yields the ~7s on my laptop and 3s in k8s.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7626#issuecomment-560450115:7,down,download,7,https://hail.is,https://github.com/hail-is/hail/pull/7626#issuecomment-560450115,2,['down'],['download']
Availability,"4.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/vep_data//human_ancestor.fa.gz,conservation_file:/vep_data//loftee.sql', '--dir_plugins', '/vep/ensembl-vep/Plugins/', '--dir_cache', '/vep_data/', '-o', 'STDOUT'] failed with non-zero exit status -9; VEP error output:; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:2226,error,error,2226,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224,1,['error'],['error']
Availability,"404s occur in `hail-ci-build.sh` because batch is already bound to port 5000 when CI tries to start. https://storage.googleapis.com/hail-ci-0-1/ci/7aa524504b8bafe0a4af859e73bc4f9efdaa052c/39a94649482a2512a7a514e6084c5b84f48b8205/index.html. The error from `ci.py`:; ```; Traceback (most recent call last):; File ""ci/ci.py"", line 372, in <module>; app.run(host='0.0.0.0', threaded=False); File ""/home/hail/.conda/envs/hail-ci/lib/python3.7/site-packages/flask/app.py"", line 943, in run; run_simple(host, port, self, **options); File ""/home/hail/.conda/envs/hail-ci/lib/python3.7/site-packages/werkzeug/serving.py"", line 814, in run_simple; inner(); File ""/home/hail/.conda/envs/hail-ci/lib/python3.7/site-packages/werkzeug/serving.py"", line 774, in inner; fd=fd); File ""/home/hail/.conda/envs/hail-ci/lib/python3.7/site-packages/werkzeug/serving.py"", line 666, in make_server; passthrough_errors, ssl_context, fd=fd); File ""/home/hail/.conda/envs/hail-ci/lib/python3.7/site-packages/werkzeug/serving.py"", line 577, in __init__; self.address_family), handler); File ""/home/hail/.conda/envs/hail-ci/lib/python3.7/socketserver.py"", line 449, in __init__; self.server_bind(); File ""/home/hail/.conda/envs/hail-ci/lib/python3.7/http/server.py"", line 137, in server_bind; socketserver.TCPServer.server_bind(self); File ""/home/hail/.conda/envs/hail-ci/lib/python3.7/socketserver.py"", line 463, in server_bind; self.socket.bind(self.server_address); OSError: [Errno 98] Address already in use; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4531:245,error,error,245,https://hail.is,https://github.com/hail-is/hail/issues/4531,1,['error'],['error']
Availability,"416]Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail/delly_vcf2vdf.py"", line 3, in <module>; hl.import_vcf('/project/casa/vcf.5k/delly/gcad.sv.delly.5k.vcf.bgz').write('/project/casa/vdf.5k/delly'); File ""<decorator-gen-546>"", line 2, in write; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 481, in _typecheck; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 1956, in write; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: NumberFormatException: For input string: ""-66.2667,0,-25.4754"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 48 in stage 2.0 failed 4 times, most recent failure: Lost task 48.3 in stage 2.0 (TID 536, scc-q14.scc.bu.edu, executor 1): is.hail.utils.HailExcput string: ""-66.2667,0,-25.4754""; offending line: chr2 130824417 DEL00068296 AGAACAGGACATCCCAGGCAGCTACAGCCCATC...; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.utils.Context.wrapException(Context.scala:23); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:741); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:412); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:750); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3361:2074,failure,failure,2074,https://hail.is,https://github.com/hail-is/hail/issues/3361,1,['failure'],['failure']
Availability,"458); 	at is.hail.backend.service.Main$.main(Main.scala:33); 	at is.hail.backend.service.Main.main(Main.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:105); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.115-71fc978b5c22; Error summary: SocketException: Connection reset. -------------------. Some more content from the failing worker job:. ...; 2023-05-04 01:04:35.959 : INFO: executing D-Array [shuffle_initial_write] with 1 tasks; 2023-05-04 01:04:35.960 : INFO: RegionPool: initialized for thread 8: pool-1-thread-1; 2023-05-04 01:04:35.965 GoogleStorageFS$: INFO: createNoCompression: gs://cpg-acute-care-hail/batch-tmp/tmp/hail/pV2Mgy4FVKSGKMwZGafyTh/hail_shuffle_temp_initial-ktRgTs8RfA9fHie5JKHmUy0e020450-e61c-4fa9-9419-2278528f3c86; 2023-05-04 01:04:37.559 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=132096, peakBytesReadable=129.00 KiB, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.560 : INFO: RegionPool: FREE: 129.0K allocated (129.0K blocks / 0 chunks), regions.size = 3, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.561 : ERROR: error while applying lowering 'LowerAndExecuteShuffles'; 2023-05-04 01:04:37.600 : INFO: RegionPool: initialized for thread 8: pool-1-threa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:22030,Error,Error,22030,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['Error'],['Error']
Availability,460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). is.hail.utils.HailException: cannot set missing field for required type +PFloat64; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:207); 	at is.hail.io.vcf.VCFLine.parseAddInfoArrayDouble(LoadVCF.scala:1034); 	at is.hail.io.vcf.VCFLine.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7$adapted(LoadVCF.scala:1909); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:515); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at __C678stream_Let.apply(Emit.scala); 	at is.hail.expr.ir.CompileIte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:18671,Error,ErrorHandling,18671,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['Error'],['ErrorHandling']
Availability,"46924854015744 also had an error]; [thread 46924847699712 also had an error]. 	#. 	# A fatal error has been detected by the Java Runtime Environment:. 	[thread 46926905038592 also had an error]#; 	# ; 	[thread 46926895564544 also had an error][thread 46926900827904 also had an error]. 	SIGSEGV (0xb) at pc=0x00002aaab5115c88, pid=34051, tid=0x00002aae05d1a700; 	#; 	# JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-b08); 	# Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); 	# Problematic frame:; 	[thread 46926929250048 also had an error]# ; 	[thread 46926881888000 also had an error]; 	J 5583 C2 __C111CompiledWithAggs.__m131wrapped(Lis/hail/annotations/Region;J)V (280 bytes) @ 0x00002aaab5115c88 [0x00002aaab5115ae0+0x1a8]; 	#; 	# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; 	#; 	[thread 46924863489792 also had an error]; 	[thread 46924861384448 also had an error]; 	# An error report file with more information is saved as:; 	# /local/scratch/app-20200610100916-0000/0/hs_err_pid34051.log; 	[thread 46926913459968 also had an error]; 	[thread 46924843489024 also had an error][thread 46926917670656 also had an error]. 	#; 	# If you would like to submit a bug report, please visit:; 	# http://bugreport.java.com/bugreport/crash.jsp; 	#. To summarize our observations:; * The issue does not occur when hail is initialized without an existing spark master; * The issue does not occur in HAIL versions prior to 0.2.43 (tested: 0.2.42, 0.2.40, 0.2.38, 0.2.34, 0.2.33 all passed and 0.2.43, 0.2.44 both failed); * The issue occurs consistently when the number of partitions is >= 354 (tested: 500, 450, 400, 360, 354, 1000) and does not occur with lower numbers of partitions (tested: 5, 10, 20, 50, 100, 200, 300, 350, 351, 352, 353); * Changing the number of variants and/or subjects does not appear to change the issue (but we haven't tested ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:19650,error,error,19650,https://hail.is,https://github.com/hail-is/hail/issues/8944,3,['error'],['error']
Availability,"49f5514afe58e884d487d7c57dae47759d""><code>53af104</code></a> Bump http-cache-semantics from 4.1.0 to 4.1.1 in /screencast</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/398c14c05c6448b380ac35c6095598299c5e23c5""><code>398c14c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/15cf7eecfbc17d2466143828b9b69494c6cb6f2b""><code>15cf7ee</code></a> Bump up version number to 5.3.1-SNAPSHOT</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e3c65ffcb49b9c5a33fde5f31fb63043dbf21134""><code>e3c65ff</code></a> Allow extensions to be created from tasks</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/34e2dd41477f18b1ae3d6d5a71dca5449d6cd1e0""><code>34e2dd4</code></a> Downgrade slf4j to fix warning on console about missing slf4j provider</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b3fa29f9ffb4d4544e13ef84601e371fb2778ddf""><code>b3fa29f</code></a> Revert &quot;Update Apache HttpClient to 5.2.1&quot;</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/01f05e046be0dca18f506723c79e88f208336e71""><code>01f05e0</code></a> Add integration tests for Gradle 6.9.3 and 7.6</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a998a544908a8b39f713f4526f717fcb328c06eb""><code>a998a54</code></a> Upgrade Gradle to 7.6</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.0...5.3.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.0&new-version=5.3.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any con",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:2586,down,download-task,2586,https://hail.is,https://github.com/hail-is/hail/pull/12707,1,['down'],['download-task']
Availability,"4; 1135 for temp_arg in temp_args:. /Users/tpoterba/spark-2.0.2-bin-hadoop2.7/python/pyspark/sql/utils.pyc in deco(*a, **kw); 61 def deco(*a, **kw):; 62 try:; ---> 63 return f(*a, **kw); 64 except py4j.protocol.Py4JJavaError as e:; 65 s = e.java_exception.toString(). /Users/tpoterba/hail/python/hail/java.py in deco(*a, **kw); 109 # deepest = env.jutils.deepestMessage(e.java_exception); 110 # msg = env.jutils.getMinimalMessage(e.java_exception); --> 111 raise FatalError('%s\n\nJava stack trace:\n%s\n\nERROR SUMMARY: %s' % (deepest, full, deepest)); 112 except py4j.protocol.Py4JError as e:; 113 if e.args[0].startswith('An error occurred while calling'):. FatalError: HailException: malformed.vcf: caught htsjdk.tribble.TribbleException$InternalCodecException: The allele with index 10026357 is not defined in the REF/ALT columns in the record; offending line: 20	10026348	.	A	G	7535.22	PASS	HWP=1.0;AC=2;culprit=Inbreedi... Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3, localhost): is.hail.utils.HailException: malformed.vcf: caught htsjdk.tribble.TribbleException$InternalCodecException: The allele with index 10026357 is not defined in the REF/ALT columns in the record; offending line: 20	10026348	.	A	G	7535.22	PASS	HWP=1.0;AC=2;culprit=Inbreedi...; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:10); 	at is.hail.utils.package$.fatal(package.scala:20); 	at is.hail.utils.TextContext.wrapException(Context.scala:15); 	at is.hail.utils.WithContext.map(Context.scala:27); 	at is.hail.io.vcf.LoadVCF$$anonfun$14$$anonfun$apply$7.apply(LoadVCF.scala:301); 	at is.hail.io.vcf.LoadVCF$$anonfun$14$$anonfun$apply$7.apply(LoadVCF.scala:301); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882:1819,failure,failure,1819,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882,1,['failure'],['failure']
Availability,"4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:2233,avail,available,2233,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949,1,['avail'],['available']
Availability,"4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 199 'Hail version: %s\n'; --> 200 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 201 except pyspark.sql.utils.CapturedException as e:; 202 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: RuntimeException: Cannot find row in Map(). Java stack trace:; is.hail.utils.HailException: Error while typechecking IR:; (MakeStruct; (titv; (ApplyBinaryPrimOp FloatingPointDivide; (GetField n_ti; (Ref Struct{rank_id:String,snv:Boolean,bi_allelic:Boolean,singleton:Boolean,bin:Int32,min_score:Float64,max_score:Float64,n_ti:Int64,n_tv:Int64,model:String} row)); (GetField n_tv; (Ref Struct{rank_id:String,snv:Boolean,bi_allelic:Boolean,singleton:Boolean,bin:Int32,min_score:Float64,max_score:Float64,n_ti:Int64,n_tv:Int64,model:String} row)))); (min_score; (GetField `0`; (In Struct{`0`:Float64,`1`:Float64} 0))); (max_score; (GetField `1`; (In Struct{`0`:Float64,`1`:Float64} 0)))); 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:11); 	at is.hail.expr.ir.Emit$.emit(Emit.scala:42); 	at is.hail.expr.ir.Emit$.apply(Emit.scala:28); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:51); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:31); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:74); 	at is.hail.expr.ir.TableKeyByAndAggregate.execute(TableIR.scala:843); 	at is.hail.table.Table.value$lzycompute(Table.scala:215); 	at is.hail.table.Table.value(Table.scala:213); 	at is.hail.table.Table.x$5$lzycompute(Table.scala:218); 	at is.hail.table.Table.x$5(T",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4110:2657,Error,Error,2657,https://hail.is,https://github.com/hail-is/hail/issues/4110,1,['Error'],['Error']
Availability,"4p.zip/gnomad_hail/utils/slack.py"", line 95, in try_slack; func(*args); File ""/tmp/d30041623ee542dca820faecd29538a9/generate_frequency_data.py"", line 155, in main; write_temp_gcs(ht, annotations_ht_path(data_type, location), args.overwrite); File ""/tmp/d30041623ee542dca820faecd29538a9/pyscripts_tyqA4p.zip/gnomad_hail/utils/generic.py"", line 36, in write_temp_gcs; t.write(temp_path, overwrite=True); File ""/tmp/d30041623ee542dca820faecd29538a9/hail-devel-cb98819b64ad.zip/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/tmp/d30041623ee542dca820faecd29538a9/hail-devel-cb98819b64ad.zip/hail/table.py"", line 1183, in write; self._jt.write(output, overwrite, stage_locally, _codec_spec); File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/tmp/d30041623ee542dca820faecd29538a9/hail-devel-cb98819b64ad.zip/hail/utils/java.py"", line 200, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: AssertionError: assertion failed: type mismatch:; name: global; actual: +Struct{}; expect: Struct{}. Java stack trace:; java.lang.AssertionError: assertion failed: type mismatch:; name: global; actual: +Struct{}; expect: Struct{}; at scala.Predef$.assert(Predef.scala:170); at is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:55); at is.hail.expr.ir.TypeCheck$.is$hail$expr$ir$TypeCheck$$check$1(TypeCheck.scala:17); at is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:186); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:39); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1636); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapRows.execute(MatrixIR.scala:1147); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapCols.execute(Matri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4127:1196,Error,Error,1196,https://hail.is,https://github.com/hail-is/hail/issues/4127,1,['Error'],['Error']
Availability,"50294) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6092044](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6092044) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **489/1000** <br/> **Why?** Has a fix available, CVSS 5.5 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14329:9413,avail,available,9413,https://hail.is,https://github.com/hail-is/hail/pull/14329,1,['avail'],['available']
Availability,"51cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/typecheck/check.py"", line 560, in wrapper; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/table.py"", line 1133, in aggregate; File ""</opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-436>"", line 2, in analyze; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/typecheck/check.py"", line 560, in wrapper; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/expr/expressions/expression_utils.py"", line 94, in analyze; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/expr/expressions/expression_utils.py"", line 237, in get_refs; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/expr/expressions/expression_utils.py"", line 212, in _get_refs; AttributeError: 'NoneType' object has no attribute '_indices_from_ref'; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [251cbf7beb5f4503ba74e4d69bd09ec3] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""/Users/laurent/tools/gnomad_hail/pyhail.py"", line 132, in <module>; main(args, pass_through_args); File ""/Users/laurent/tools/gnomad_hail/pyhail.py"", line 113, in main; subprocess.check_output(job); File ""/anaconda3/lib/python3.6/subprocess.py"", line 336, in check_output; **kwargs).stdout; File ""/anaconda3/lib/python3.6/subprocess.py"", line 418, in run; output=stdout, stderr=stderr); ```. Note that first filtering the table, then running agg.group_by it works, if I just run agg_filter without agg.group_by (just agg.count()), it also works. For ref, this is `pops_ht` schema:; ```; ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 's': str ; 'known_pop': str ; 'known_subpop': str ; '_kgp': bool ; 'pop': str ; 'prob_afr': float64 ; 'prob_amr': float64 ; 'prob_eas': float64 ; 'prob_eur': float64 ; 'prob_sas': float64 ; -------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5296:1936,ERROR,ERROR,1936,https://hail.is,https://github.com/hail-is/hail/issues/5296,1,['ERROR'],['ERROR']
Availability,"5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **624/1000** <br/> **Why?** Has a fix available, CVSS 8.2 | Arbitrary Code Execution <br/>[SNYK-PYTHON-IPYTHON-2348630](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-2348630) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **604/1000** <br/> **Why?** Has a fix available, CVSS 7.8 | Improper Privilege Management <br/>[SNYK-PYTHON-JUPYTERCORE-3063766](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERCORE-3063766) | `jupyter-core:` <br> `4.6.3 -> 4.11.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-MISTUNE-2940625](https://snyk.io/vuln/SNYK-PYTHON-MISTUNE-2940625) | `mistune:` <br> `0.8.4 -> 2.0.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **726/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 8.1 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:2555,avail,available,2555,https://hail.is,https://github.com/hail-is/hail/pull/13717,2,['avail'],['available']
Availability,"59"">#1559</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/1449dec45b4e95293db14595ec0d11a3839bac23""><code>1449dec</code></a> Support loading of CSI from URLs/streams. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1507"">#1507</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1595"">#1595</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/22aec6782b33f8d169a5d1cf63e952126a3f09e0""><code>22aec67</code></a> Fix decoding of CRAM Scores read feature during normalization. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1592"">#1592</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/70e42597ee8e2db6241f7b147f1356a1f8a846bc""><code>70e4259</code></a> Remove unnecessary println in test (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1602"">#1602</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/6507249a4422d021b984e710e8f031816f6d8da2""><code>6507249</code></a> Make the CRAM MD5 failure message more user friendly. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1607"">#1607</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/samtools/htsjdk/compare/2.24.1...3.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.samtools:htsjdk&package-manager=gradle&previous-version=2.24.1&new-version=3.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dep",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:8643,failure,failure,8643,https://hail.is,https://github.com/hail-is/hail/pull/12229,1,['failure'],['failure']
Availability,"5975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315975) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **691/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.4 | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No |",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:5629,avail,available,5629,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,"5975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315975) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **691/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.4 | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No |",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:5621,avail,available,5621,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['avail'],['available']
Availability,"5:51.994Z caller=web.go:417 component=web msg=""Start listening for connections"" address=0.0.0.0:9090; level=info ts=2019-07-31T15:45:51.996Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563105600000 maxt=1563170400000 ulid=01DFTDRJHCX1S9B0KPJTG8CRGW; level=info ts=2019-07-31T15:45:51.997Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563170400000 maxt=1563235200000 ulid=01DFWBK0336Z71ZCRRKS79T18P; level=info ts=2019-07-31T15:45:51.997Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563235200000 maxt=1563300000000 ulid=01DFY9C92NRA1S7FDVHFRFMFPF; level=info ts=2019-07-31T15:45:51.998Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563300000000 maxt=1563364800000 ulid=01DG075GN2MME91GM1DA5G3H07; level=info ts=2019-07-31T15:45:51.999Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563364800000 maxt=1563429600000 ulid=01DG24Z1SDJ7VXW96YYSY1FC8Y; level=info ts=2019-07-31T15:45:51.999Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563429600000 maxt=1563494400000 ulid=01DG42SDMFEK1AJPRJ5YWKZFJ8; level=info ts=2019-07-31T15:45:52.000Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563494400000 maxt=1563559200000 ulid=01DG60K1ADH2GGZ6ZHYVRQA7PQ; level=info ts=2019-07-31T15:45:52.001Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563559200000 maxt=1563624000000 ulid=01DG7YBCA5FFBKYXX7EADE91TP; level=info ts=2019-07-31T15:45:52.001Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563624000000 maxt=1563688800000 ulid=01DG9W4WYEDBQ32Q112S7EPMEP; level=info ts=2019-07-31T15:45:52.002Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563688800000 maxt=1563753600000 ulid=01DGBSYJDGQ8NY58106XGFT7CS; level=info ts=2019-07-31T15:45:52.002Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563753600000 maxt=1563818400000 ulid=01DGDQRCZ949B46BNYWP2S5F02; level=info ts=2019",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6773:4256,repair,repair,4256,https://hail.is,https://github.com/hail-is/hail/issues/6773,1,['repair'],['repair']
Availability,"5]	[:makeHailDocs] compileflags, 1) in test.globs; [13:46:55]	[:makeHailDocs] File ""<doctest default[0]>"", line 7, in <module>; [13:46:55]	[:makeHailDocs] covariates=['sa.burden.cov1', 'sa.burden.cov2'])); [13:46:55]	[:makeHailDocs] File ""<decorator-gen-233>"", line 2, in linreg_burden; [13:46:55]	[:makeHailDocs] File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/java.py"", line 119, in handle_py4j; [13:46:55]	[:makeHailDocs] 'Error summary: %s' % (msg, e.message, Env.hc().version, msg)); [13:46:55]	[:makeHailDocs] FatalError: An error occurred while calling into JVM, probably due to invalid parameter types.; [13:46:55]	[:makeHailDocs] ; [13:46:55]	[:makeHailDocs] Java stack trace:; [13:46:55]	[:makeHailDocs] An error occurred while calling o3918.linregBurden. Trace:; [13:46:55]	[:makeHailDocs] py4j.Py4JException: Method linregBurden([class java.lang.String, class java.lang.String, class java.lang.String, class java.lang.String, class java.lang.String, class [Ljava.lang.String;]) does not exist; [13:46:55]	[:makeHailDocs] 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); [13:46:55]	[:makeHailDocs] 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326); [13:46:55]	[:makeHailDocs] 	at py4j.Gateway.invoke(Gateway.java:272); [13:46:55]	[:makeHailDocs] 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); [13:46:55]	[:makeHailDocs] 	at py4j.commands.CallCommand.execute(CallCommand.java:79); [13:46:55]	[:makeHailDocs] 	at py4j.GatewayConnection.run(GatewayConnection.java:214); [13:46:55]	[:makeHailDocs] 	at java.lang.Thread.run(Thread.java:745); [13:46:55]	[:makeHailDocs] ; [13:46:55]	[:makeHailDocs] ; [13:46:55]	[:makeHailDocs] Hail version: devel-b94d386; [13:46:55]	[:makeHailDocs] Error summary: An error occurred while calling into JVM, probably due to invalid parameter types.; [13:46:55]	[:makeHailDocs] ; [13:46:55]	[:makeHailDocs] ; [13:46:55]	[:makeHailDocs] make: *** [doctest] Error 1; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1708#issuecomment-297039203:2741,Error,Error,2741,https://hail.is,https://github.com/hail-is/hail/pull/1708#issuecomment-297039203,3,"['Error', 'error']","['Error', 'error']"
Availability,"6 2017, 17:29:19); [GCC 7.2.0] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/02/22 20:29:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/02/22 20:29:10 WARN Utils: Your hostname, CompyWompy resolves to a loopback address: 127.0.1.1; using 192.168.1.122 instead (on interface eth0); 18/02/22 20:29:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.14 (default, Oct 16 2017 17:29:19); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(spark.sparkContext); Running on Apache Spark version 2.0.2; SparkUI available at http://192.168.1.122:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-20613ed; >>> table = hc.import_table('data/1kg_annotations.txt', impute=True).key_by('Sample'); 2018-02-22 20:29:45 Hail: INFO: Reading table to impute column types; 2018-02-22 20:29:45 Hail: INFO: Finished type imputation; Loading column `Sample' as type String (imputed); Loading column `Population' as type String (imputed); Loading column `SuperPopulation' as type String (imputed); Loading column `isFemale' as type Boolean (imputed); Loading column `PurpleHair' as type Boolean (imputed); Loading column `CaffeineConsumption' as type Int (imputed); >>> common_vds = hc.read('/mnt/d/metistream/hail/data/1kg.vds'); >>> common_vds = common_vds.annotate_samples_table(table, root='sa'); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2966:2183,avail,available,2183,https://hail.is,https://github.com/hail-is/hail/issues/2966,1,['avail'],['available']
Availability,"6"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.30.0"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494,539,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr);  [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr);  [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14024:11524,avail,available,11524,https://hail.is,https://github.com/hail-is/hail/pull/14024,1,['avail'],['available']
Availability,"6' in ZooKeeper; I0824 16:42:27.072525 8706 detector.cpp:481] A new leading master (UPID=master@192.168.0.9:5050) is detected; I0824 16:42:27.072593 8736 sched.cpp:262] New master detected at master@192.168.0.9:5050; I0824 16:42:27.072742 8736 sched.cpp:272] No credentials provided. Attempting to register without authentication; I0824 16:42:27.074246 8746 sched.cpp:641] Framework registered with 0233fcf9-88ce-407f-8ed5-b015adf9b59c-1932; hail: info: running: importvcf file:///mnt/lustre/schoi/projects/TOPMed/BROAD/Chr22/TopMed_8k.853.vcf.bgz; [Stage 0:=====================================================> (53 + 3) / 56]hail: info: Ordering unsorted dataset with network shuffle; hail: info: running: splitmulti; hail: info: running: annotatevariants expr -c 'va.info.AC = va.info.AC[va.aIndex]'; hail: info: running: count; [Stage 3:> (0 + 56) / 56]hail: count: caught exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 50 in stage 3.0 failed 4 times, most recent failure: Lost task 50.3 in stage 3.0 (TID 296, nid00004.urika.com): java.lang.ClassCastException: java.lang.Integer cannot be cast to scala.collection.IndexedSeq; at org.broadinstitute.hail.expr.IndexOp$$anonfun$eval$224.apply(AST.scala:1894); at org.broadinstitute.hail.expr.AST$$anonfun$evalCompose$2.apply(AST.scala:129); at org.broadinstitute.hail.expr.Parser$$anonfun$5$$anonfun$apply$7.apply(Parser.scala:168); at org.broadinstitute.hail.expr.Parser$$anonfun$5$$anonfun$apply$7.apply(Parser.scala:168); at org.broadinstitute.hail.driver.AnnotateVariantsExpr$$anonfun$2$$anonfun$apply$2.apply(AnnotateVariantsExpr.scala:71); at org.broadinstitute.hail.driver.AnnotateVariantsExpr$$anonfun$2$$anonfun$apply$2.apply(AnnotateVariantsExpr.scala:70); at scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:51); at scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:60); at scala.collection.mutable.ArrayOps$ofRef.foldLeft(ArrayOps.scala:108); at ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/660#issuecomment-242218633:3387,failure,failure,3387,https://hail.is,https://github.com/hail-is/hail/issues/660#issuecomment-242218633,1,['failure'],['failure']
Availability,"6); at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.fold(RDD.scala:1083); at is.hail.rvd.RVD.count(RVD.scala:603); at is.hail.expr.ir.Interpret$$anonfun$apply$1.apply$mcJ$sp(Interpret.scala:725); at is.hail.expr.ir.Interpret$$anonfun$apply$1.apply(Interpret.scala:725); at is.hail.expr.ir.Interpret$$anonfun$apply$1.apply(Interpret.scala:725); at scala.Option.getOrElse(Option.scala:121); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:725); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:107); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:77); at is.hail.variant.MatrixTable.countRows(MatrixTable.scala:552); at is.hail.variant.MatrixTable.count(MatrixTable.scala:550); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745). Hail version: 0.2.4-d602a3d7472d; Error summary: SparkException: Job aborted due to stage failure: Task 7 in stage 0.0 failed 4 times, most recent failure: Lost task 7.3 in stage 0.0 (TID 86, scc-q16.scc.bu.edu, executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Slave lost; Driver stacktrace:. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572:11412,Error,Error,11412,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572,3,"['Error', 'failure']","['Error', 'failure']"
Availability,"64 prometheus-0 (none))""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:325 fd_limits=""(soft=1048576, hard=1048576)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:326 vm_limits=""(soft=unlimited, hard=unlimited)""; level=info ts=2019-07-31T15:45:51.993Z caller=main.go:645 msg=""Starting TSDB ...""; level=info ts=2019-07-31T15:45:51.994Z caller=web.go:417 component=web msg=""Start listening for connections"" address=0.0.0.0:9090; level=info ts=2019-07-31T15:45:51.996Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563105600000 maxt=1563170400000 ulid=01DFTDRJHCX1S9B0KPJTG8CRGW; level=info ts=2019-07-31T15:45:51.997Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563170400000 maxt=1563235200000 ulid=01DFWBK0336Z71ZCRRKS79T18P; level=info ts=2019-07-31T15:45:51.997Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563235200000 maxt=1563300000000 ulid=01DFY9C92NRA1S7FDVHFRFMFPF; level=info ts=2019-07-31T15:45:51.998Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563300000000 maxt=1563364800000 ulid=01DG075GN2MME91GM1DA5G3H07; level=info ts=2019-07-31T15:45:51.999Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563364800000 maxt=1563429600000 ulid=01DG24Z1SDJ7VXW96YYSY1FC8Y; level=info ts=2019-07-31T15:45:51.999Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563429600000 maxt=1563494400000 ulid=01DG42SDMFEK1AJPRJ5YWKZFJ8; level=info ts=2019-07-31T15:45:52.000Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563494400000 maxt=1563559200000 ulid=01DG60K1ADH2GGZ6ZHYVRQA7PQ; level=info ts=2019-07-31T15:45:52.001Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563559200000 maxt=1563624000000 ulid=01DG7YBCA5FFBKYXX7EADE91TP; level=info ts=2019-07-31T15:45:52.001Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563624000000 maxt=1563688800000 ulid=01DG9W4WYEDBQ32Q112S7EPMEP; level=info ts=2019",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6773:3914,repair,repair,3914,https://hail.is,https://github.com/hail-is/hail/issues/6773,1,['repair'],['repair']
Availability,"6926895564544 also had an error][thread 46926900827904 also had an error]. 	SIGSEGV (0xb) at pc=0x00002aaab5115c88, pid=34051, tid=0x00002aae05d1a700; 	#; 	# JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-b08); 	# Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); 	# Problematic frame:; 	[thread 46926929250048 also had an error]# ; 	[thread 46926881888000 also had an error]; 	J 5583 C2 __C111CompiledWithAggs.__m131wrapped(Lis/hail/annotations/Region;J)V (280 bytes) @ 0x00002aaab5115c88 [0x00002aaab5115ae0+0x1a8]; 	#; 	# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; 	#; 	[thread 46924863489792 also had an error]; 	[thread 46924861384448 also had an error]; 	# An error report file with more information is saved as:; 	# /local/scratch/app-20200610100916-0000/0/hs_err_pid34051.log; 	[thread 46926913459968 also had an error]; 	[thread 46924843489024 also had an error][thread 46926917670656 also had an error]. 	#; 	# If you would like to submit a bug report, please visit:; 	# http://bugreport.java.com/bugreport/crash.jsp; 	#. To summarize our observations:; * The issue does not occur when hail is initialized without an existing spark master; * The issue does not occur in HAIL versions prior to 0.2.43 (tested: 0.2.42, 0.2.40, 0.2.38, 0.2.34, 0.2.33 all passed and 0.2.43, 0.2.44 both failed); * The issue occurs consistently when the number of partitions is >= 354 (tested: 500, 450, 400, 360, 354, 1000) and does not occur with lower numbers of partitions (tested: 5, 10, 20, 50, 100, 200, 300, 350, 351, 352, 353); * Changing the number of variants and/or subjects does not appear to change the issue (but we haven't tested that rigorously; increased/decreased by an order of magnitude and observed the same behavior at the same number of partitions); * The issue also occurs on real datasets (large datasets imported from VCF files).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:19863,error,error,19863,https://hail.is,https://github.com/hail-is/hail/issues/8944,3,['error'],['error']
Availability,"7-0.2-721af83bc30a.log; Exception in thread ""dispatcher-event-loop-8"" Exception in thread ""refresh progress"" java.lang.OutOfMemoryError: GC overhead limit exceeded; at java.util.zip.ZipCoder.getBytes(ZipCoder.java:80); at java.util.zip.ZipFile.getEntry(ZipFile.java:310); at java.util.jar.JarFile.getEntry(JarFile.java:240); at java.util.jar.JarFile.getJarEntry(JarFile.java:223); at sun.misc.URLClassPath$JarLoader.getResource(URLClassPath.java:1042); at sun.misc.URLClassPath.getResource(URLClassPath.java:239); at java.net.URLClassLoader$1.run(URLClassLoader.java:365); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:1962,Heartbeat,HeartbeatReceiver,1962,https://hail.is,https://github.com/hail-is/hail/issues/4780,2,['Heartbeat'],['HeartbeatReceiver']
Availability,"7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args) 1131 answer = self.gateway_client.send_command(command) 1132 return_value = get_return_value( -> 1133 answer, self.gateway_client, self.target_id, self.name) 1134 1135 for temp_arg in temp_args: /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/pyspark/sql/utils.py in deco(*a, **kw) 61 def deco(*a, **kw): 62 try: ---> 63 return f(*a, **kw) 64 except py4j.protocol.Py4JJavaError as e: 65 s = e.java_exception.toString() /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name) 317 raise Py4JJavaError( 318 ""An error occurred while calling {0}{1}{2}.\n"". --> 319 format(target_id, ""."", name), value) 320 else: 321 raise Py4JError( Py4JJavaError: An error occurred while calling o68.apply. : org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at: org.apache.spark.SparkContext.<init>(SparkContext.scala:76) is.hail.HailContext$.configureAndCreateSparkContext(HailContext.scala:84) is.hail.HailContext$.apply(HailContext.scala:164) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) java.lang.reflect.Method.invoke(Method.java:498) py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357) py4j.Gateway.invoke(Gateway.java:280) py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) py4j.commands.CallCommand.execute(CallCommand.java:79) py4j.GatewayConnection.run(GatewayConnection.java:214) java.lang.Thread.run(Thread.java:745) at org.apache.spark.SparkContext$$anonfun$assertNoOtherC",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1525:4880,error,error,4880,https://hail.is,https://github.com/hail-is/hail/issues/1525,1,['error'],['error']
Availability,"71, in count; return (self.count_rows(), self.count_cols()); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/matrixtable.py"", line 2331, in count_rows; TableCount(MatrixRowsTable(self._mir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/backend/backend.py"", line 94, in execute; self._to_java_ir(ir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/utils/java.py"", line 227, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): is.hail.utils.HailException: foo: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; offending line: 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.utils.Context.wrapException(Context.scala:19); 	at is.hail.utils.WithContext.wrap(Context.scala:43); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:575); 	at ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:2574,failure,failure,2574,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['failure'],['failure']
Availability,72); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:590); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:38); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:15); 	at is.hail.table.Table.write(Table.scala:618); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)is.hail.utils.HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1011); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.io.RichContextRDDRegionValue$.writeRowsPartition(RowStore.scala:1071); 	at is.hail.io.RichContextRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:1096); 	at is.hail.io.RichContextRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:1096); 	at is.hail.utils.richUtils.RichCon,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4096:8030,error,error,8030,https://hail.is,https://github.com/hail-is/hail/issues/4096,1,['error'],['error']
Availability,"7366"">#7366</a>) (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7380"">#7380</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/9337fb3f2ab2b5f38d7e98a194bde6f7e3d16c40""><code>9337fb3</code></a> Fix bump llhttp to v8.1.1 (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7367"">#7367</a>) (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7377"">#7377</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/f07e9b44b5cb909054a697c8dd447b30dbf8073e""><code>f07e9b4</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7373"">#7373</a>/66e261a5 backport][3.8] Drop azure mention (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7374"">#7374</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/01d9b70e5477cd746561b52225992d8a2ebde953""><code>01d9b70</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7370"">#7370</a>/22c264ce backport][3.8] fix: Spelling error fixed (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7371"">#7371</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/3577b1e3719d4648fa973dbdec927f78f9df34dd""><code>3577b1e</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7359"">#7359</a>/7911f1e9 backport][3.8]  Set up secretless publishing to PyPI (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7360"">#7360</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/8d45f9c99511cd80140d6658bd9c11002c697f1c""><code>8d45f9c</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7333"">#7333</a>/3a54d378 backport][3.8] Fix TLS transport is <code>None</code> error (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7357"">#7357</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/dd8e24e77351df9c0f029be49d3c6d7862706e79""><code>dd8e24e</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7343"">#7343</a>/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13270:4632,error,error,4632,https://hail.is,https://github.com/hail-is/hail/pull/13270,5,['error'],['error']
Availability,78b2a \; REMOTE= \; WHEEL=build/deploy/dist/hail-0.2.128-py3-none-any.whl \; GITHUB_OAUTH_HEADER_FILE=abc123 \; HAIL_GENETICS_HAIL_IMAGE=abc123 \; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=a \; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=b \; HAIL_GENETICS_HAILTOP_IMAGE=c \; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=d \; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=e \; WHEEL_FOR_AZURE=f \; WEBSITE_TAR=g \; bash scripts/release.sh; +++ dirname -- scripts/release.sh; ++ cd -- scripts; ++ pwd; + SCRIPT_DIR=/Users/dking/projects/hail/hail/scripts; + arguments='HAIL_PIP_VERSION HAIL_VERSION GIT_VERSION REMOTE WHEEL GITHUB_OAUTH_HEADER_FILE HAIL_GENETICS_HAIL_IMAGE HAIL_GENETICS_HAIL_IMAGE_PY_3_10 HAIL_GENETICS_HAIL_IMAGE_PY_3_11 HAIL_GENETICS_HAILTOP_IMAGE HAIL_GENETICS_VEP_GRCH37_85_IMAGE HAIL_GENETICS_VEP_GRCH38_95_IMAGE WHEEL_FOR_AZURE WEBSITE_TAR'; + for varname in '$arguments'; + '[' -z 0.2.128 ']'; + echo HAIL_PIP_VERSION=0.2.128; HAIL_PIP_VERSION=0.2.128; + for varname in '$arguments'; + '[' -z 0.2.128-91d328e7fc84 ']'; + echo HAIL_VERSION=0.2.128-91d328e7fc84; HAIL_VERSION=0.2.128-91d328e7fc84; + for varname in '$arguments'; + '[' -z 91d328e7fc84686936ffd4f370c8c104b2d78b2a ']'; + echo GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a; GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a; + for varname in '$arguments'; + '[' -z '' ']'; + echo. + usage; + cat; ++ basename scripts/release.sh; ++ basename scripts/release.sh; usage: release.sh. All arguments are specified by environment variables. For example:. HAIL_PIP_VERSION=0.2.123; HAIL_VERSION=0.2.123-abcdef123; GIT_VERSION=abcdef123; REMOTE=origin; WHEEL=/path/to/the.whl; GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_G,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:14664,echo,echo,14664,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['echo'],['echo']
Availability,"7</code></a> Negative timeouts are actually not allowed</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4ff0ff0e63e0dd45f231990d0dcebffde6e6b709""><code>4ff0ff0</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a1858b494b5f3a51ccef7580c243c6dfdf520731""><code>a1858b4</code></a> Merge pull request <a href=""https://redirect.github.com/michel-kraemer/gradle-download-task/issues/295"">#295</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/c1e212c0fb41b3ea9185a9ea463fb1ea7142f748""><code>c1e212c</code></a> Add integration tests for Gradle 8.0 and 8.0.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/304f68e25f53633a92a4d2d6ce003a4986929503""><code>304f68e</code></a> Fix type inference issue</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.1...5.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.1&new-version=5.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:2709,down,download-task,2709,https://hail.is,https://github.com/hail-is/hail/pull/12893,1,['down'],['download-task']
Availability,"7](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `2.11.3 -> 3.1.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **604/1000** <br/> **Why?** Has a fix available, CVSS 7.8 | Improper Privilege Management <br/>[SNYK-PYTHON-JUPYTERCORE-3063766](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERCORE-3063766) | `jupyter-core:` <br> `4.6.3 -> 4.11.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-MISTUNE-2940625](https://snyk.io/vuln/SNYK-PYTHON-MISTUNE-2940625) | `mistune:` <br> `0.8.4 -> 2.0.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **726/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 8.1 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **434/1000** <br/> **Why?** Has a fix available, CVSS 4.4 | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/up",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:4012,avail,available,4012,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['avail'],['available']
Availability,"7e18f61222c6c8c5fb04a8]"" ""__cols""; (MatrixMapRows; (MatrixRead Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String]},entry:Struct{}} False False ""{\""name\"":\""MatrixBGENReader\"",\""files\"":[\""/Users/dking/projects/hail-data/caitlin/ukb_imp_chr22_v3.bgen\""],\""indexFileMap\"":{},\""blockSizeInMB\"":128}""); (MakeStruct; (locus; (GetField locus; (Ref va))); (alleles; (GetField alleles; (Ref va)))))); (InsertFields; (Ref row); (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`; (ArrayMap i; (ArrayRange; (I32 0); (ArrayLen; (GetField __cols; (Ref global))); (I32 1)); (Let g; (ArrayRef; (Ref global))); (SelectFields (locus alleles); (Ref row)))); 2019-01-08 18:19:48 root: INFO: optimize: after:; (TableCount; (CastMatrixToTable ""the entries! [877f12a8827e18f61222c6c8c5fb04a8]"" ""__cols""; (MatrixMapRows; (CastTableToMatrix `the entries! [877f12a8827e18f61222c6c8c5fb04a8]` __cols (s); (TableMapRows; (CastMatrixToTable ""the entries! [877f12a8827e18f61222c6c8c5fb04a8]"" ""__cols""; (MatrixMapRows; (MatrixRead Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String]},entry:Struct{}} False False ""{\""name\"":\""MatrixBGENReader\"",\""files\"":[\""/Users/dking/projects/hail-data/caitlin/ukb_imp_chr22_v3.bgen\""],\""indexFileMap\"":{},\""blockSizeInMB\"":128}""); (MakeStruct; (locus; (GetField locus; (Ref va))); (alleles; (GetField alleles; (Ref va)))))); (InsertFields; (Ref row); (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`; (ArrayMap i; (ArrayRange; (I32 0); (ArrayLen; (GetField __cols; (Ref global))); (I32 1)); (ArrayRef; (GetField `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`; (Ref row)); (Ref i))))))); (MakeStruct; (locus; (GetField locus; (Ref va))); (alleles; (GetField alleles; (Ref va))))))); ```; ### What went wrong (all error messages here, including the full java stack trace):; This wasn't optimized to a read of the metadata.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5100:2470,error,error,2470,https://hail.is,https://github.com/hail-is/hail/issues/5100,1,['error'],['error']
Availability,"8); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # J 8451 C2 is.hail.annotations.Region$.loadBit(JJ)Z (33 bytes) @ 0x00007fa4b25e18cd [0x00007fa4b25e18a0+0x2d]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /tmp/cac7924b3c14494b9702ac2689c0c52d/hs_err_pid6637.log; ```; with this pipeline:; ```; def normalize_contig(input_contig: hl.expr.StringExpression) -> hl.expr.StringExpression:; return input_contig.replace(""^chr"", """"). def downsample_matrix_table(mt: hl.MatrixTable, n_divisions: int, p_threshold: float) -> hl.Table:;  mt = mt.choose_cols(list(range(10))); ; x = mt.locus.global_position(); y = -hl.log10(mt.Pvalue); ; downsampled = mt.annotate_cols(; binned=hl.agg.filter(; mt.Pvalue > p_threshold,; hl.agg.downsample(; x,; y,; label=[; normalize_contig(mt.locus.contig),; hl.str(mt.locus.position),; hl.str(mt.Pvalue),; ],; n_divisions=n_divisions; ); ),; unbinned=hl.agg.filter(; mt.Pvalue <= p_threshold,; hl.agg.collect(hl.struct(; pval=mt.Pvalue,; chrom=normalize_contig(mt.locus.contig),; pos=mt.locus.position,; ac=mt.AC,; af=mt.AF,; an=mt.N,; alleles=mt.alleles,; beta=mt.BETA,; consequence=hl.if_else(; hl.is_defined(mt.annotation),; mt.annotation,; ""N/A""; ),; gene_name=mt.gene,; is_binned=False; ); ); ); ); ; downsampled = downsampled.select_cols(; binned=downsampled.binned.map(; lambda a_bin: hl.struct(; pval=hl.float64(a_bin[2][2]),; chrom=a_bin[2][0],; pos=hl.int32(a_bin[2][1]),; ac=hl.literal(0.0),; af=hl.literal(0.0),; an=hl.literal(0),; alleles=hl.literal(['N', 'A']),; beta=hl.literal(0.0),; consequence=""N/A"",; gene_name=""N/A"",; is_binned=True,; ; ); ),; unbinned=downsampled.unbinned,; ); ; downsampled = downsampled.select_cols(; data=downsampled.binned.extend(downsampled.unbinned); ); downsampled = downsampled.cols(); ; return downsampled; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8240:1779,down,downsampled,1779,https://hail.is,https://github.com/hail-is/hail/issues/8240,11,['down'],['downsampled']
Availability,"8*hl.median(hl.abs(hl.agg.collect(ht[metric])-hl.median(hl.agg.collect(ht[metric]))))); medmad = ht.aggregate(hl.struct(**medmad_dict)); print(medmad); print(hl.eval_expr(hl.json(medmad))); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; [Stage 0:==================================================>(9853 + 93) / 10000]#; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fbeaec3ca22, pid=6662, tid=0x00007fbe3dd81700; #; # JRE version: OpenJDK Runtime Environment (8.0_181-b13) (build 1.8.0_181-8u181-b13-1~deb9u1-b13); # Java VM: OpenJDK 64-Bit Server VM (25.181-b13 mixed mode linux-amd64 compressed oops); # Problematic frame:; # J 14270 C1 is.hail.annotations.Region.storeInt(JI)V (6 bytes) @ 0x00007fbeaec3ca22 [0x00007fbeaec3c980+0xa2]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /tmp/828e66d5a71741d7ab2c8d6580997da3/hs_err_pid6662.log; Compiled method (c1) 88328 14270 3 is.hail.annotations.Region::storeInt (6 bytes); total in heap [0x00007fbeaec3c810,0x00007fbeaec3cbc0] = 944; relocation [0x00007fbeaec3c938,0x00007fbeaec3c968] = 48; main code [0x00007fbeaec3c980,0x00007fbeaec3caa0] = 288; stub code [0x00007fbeaec3caa0,0x00007fbeaec3cb30] = 144; oops [0x00007fbeaec3cb30,0x00007fbeaec3cb38] = 8; metadata [0x00007fbeaec3cb38,0x00007fbeaec3cb48] = 16; scopes data [0x00007fbeaec3cb48,0x00007fbeaec3cb78] = 48; scopes pcs [0x00007fbeaec3cb78,0x00007fbeaec3cbb8] = 64; dependencies [0x00007fbeaec3cbb8,0x00007fbeaec3cbc0] = 8; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #; FATAL: caught signal 6 SIGABRT; /tmp/libhail7224206977949339430.so(+0x1788c)[0x7fbdea5db88c]; /lib/x86_64-linux-gnu/libc.so.6(+0x33060)[0x7fbec2eae060]; /lib/x86_64-linux-gnu/libc.so.6(gsign",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4418:2402,error,error,2402,https://hail.is,https://github.com/hail-is/hail/issues/4418,1,['error'],['error']
Availability,"8/1kg/ALL.GRCh38_sites.20170504.vcf.gz""; vds = hc.import_vcf(input_vcf, npartitions=1000, force=True); ```. causes. ```; FatalErrorTraceback (most recent call last); <ipython-input-4-5e86630fbae5> in <module>(); ----> 1 vds = hc.import_vcf(input_vcf, npartitions=1000, force=True). <decorator-gen-291> in import_vcf(self, path, force, force_bgz, header_file, npartitions, sites_only, store_gq, pp_as_pl, skip_bad_ad, generic, call_fields). /home/hail/pyhail-hail-is-master-ebabd77.zip/hail/java.pyc in handle_py4j(func, *args, **kwargs); 111 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 112 'Hail version: %s\n'; --> 113 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); 114 except py4j.protocol.Py4JError as e:; 115 if e.args[0].startswith('An error occurred while calling'):. FatalError: IllegalArgumentException: Size exceeds Integer.MAX_VALUE. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, seqr-pipeline-cluster-grch38-w-0.c.seqr-project.internal): java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE; 	at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:869); 	at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:103); 	at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:91); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1310); 	at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:105); 	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:438); 	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:606); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:663); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1806:1098,failure,failure,1098,https://hail.is,https://github.com/hail-is/hail/issues/1806,1,['failure'],['failure']
Availability,"813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5914629](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5914629) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Missing Cryptographic Step <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6036192](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6036192) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6092044](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6092044) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:7515,avail,available,7515,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,"813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5914629](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5914629) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Missing Cryptographic Step <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6036192](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6036192) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6050294](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6050294) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:7507,avail,available,7507,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['avail'],['available']
Availability,"813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5914629](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5914629) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Missing Cryptographic Step <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6036192](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6036192) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6092044](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6092044) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:7884,avail,available,7884,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,"813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5914629](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5914629) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Missing Cryptographic Step <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6036192](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6036192) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6050294](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6050294) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6092044](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6092044) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:7876,avail,available,7876,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['avail'],['available']
Availability,"869: in _run_once; event_list = self._selector.select(timeout); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <selectors.EpollSelector object at 0x7fae890f2d30>; timeout = 15.402000000000001. def select(self, timeout=None):; if timeout is None:; timeout = -1; elif timeout <= 0:; timeout = 0; else:; # epoll_wait() has a resolution of 1 millisecond, round away; # from zero to wait *at least* timeout seconds.; timeout = math.ceil(timeout * 1e3) * 1e-3; ; # epoll_wait() expects `maxevents` to be greater than zero;; # we want to make sure that `select()` can be called when no; # FD is registered.; max_ev = max(len(self._fd_to_key), 1); ; ready = []; try:; > fd_event_list = self._selector.poll(timeout, max_ev); E Failed: Timeout >360.0s. usr/lib/python3.9/selectors.py:469: Failed; ------------------------------ Captured log setup ------------------------------; 2023-09-06T21:45:24 INFO test.conftest conftest.py:14:log_before_after starting test; 2023-09-06T21:45:24 INFO hailtop.aiocloud.aioazure.credentials credentials.py:99:default_credentials using credentials file /test-gsa-key/key.json; ------------------------------ Captured log call -------------------------------; 2023-09-06T21:45:25 INFO azure.identity.aio._internal.get_token_mixin get_token_mixin.py:93:get_token ClientSecretCredential.get_token succeeded; 2023-09-06T21:45:25 INFO batch_client.aioclient aioclient.py:809:_submit created batch 191; 2023-09-06T21:47:17 WARNING hailtop.utils utils.py:842:retry_transient_errors_with_debug_string A transient error occured. We will automatically retry. Do not be alarmed. We have thus far seen 2 transient errors (next delay: 3.794s). The most recent error was <class 'asyncio.exceptions.TimeoutError'> . ------------------------------ live log teardown -------------------------------; 2023-09-06T21:51:25 INFO test.conftest conftest.py:16:log_before_after ending test. ```. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13582:4412,error,error,4412,https://hail.is,https://github.com/hail-is/hail/issues/13582,3,['error'],"['error', 'errors']"
Availability,"8746 group.cpp:674] Trying to get '/mesos/json.info_0000000066' in ZooKeeper; I0824 16:42:27.072525 8706 detector.cpp:481] A new leading master (UPID=master@192.168.0.9:5050) is detected; I0824 16:42:27.072593 8736 sched.cpp:262] New master detected at master@192.168.0.9:5050; I0824 16:42:27.072742 8736 sched.cpp:272] No credentials provided. Attempting to register without authentication; I0824 16:42:27.074246 8746 sched.cpp:641] Framework registered with 0233fcf9-88ce-407f-8ed5-b015adf9b59c-1932; hail: info: running: importvcf file:///mnt/lustre/schoi/projects/TOPMed/BROAD/Chr22/TopMed_8k.853.vcf.bgz; [Stage 0:=====================================================> (53 + 3) / 56]hail: info: Ordering unsorted dataset with network shuffle; hail: info: running: splitmulti; hail: info: running: annotatevariants expr -c 'va.info.AC = va.info.AC[va.aIndex]'; hail: info: running: count; [Stage 3:> (0 + 56) / 56]hail: count: caught exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 50 in stage 3.0 failed 4 times, most recent failure: Lost task 50.3 in stage 3.0 (TID 296, nid00004.urika.com): java.lang.ClassCastException: java.lang.Integer cannot be cast to scala.collection.IndexedSeq; at org.broadinstitute.hail.expr.IndexOp$$anonfun$eval$224.apply(AST.scala:1894); at org.broadinstitute.hail.expr.AST$$anonfun$evalCompose$2.apply(AST.scala:129); at org.broadinstitute.hail.expr.Parser$$anonfun$5$$anonfun$apply$7.apply(Parser.scala:168); at org.broadinstitute.hail.expr.Parser$$anonfun$5$$anonfun$apply$7.apply(Parser.scala:168); at org.broadinstitute.hail.driver.AnnotateVariantsExpr$$anonfun$2$$anonfun$apply$2.apply(AnnotateVariantsExpr.scala:71); at org.broadinstitute.hail.driver.AnnotateVariantsExpr$$anonfun$2$$anonfun$apply$2.apply(AnnotateVariantsExpr.scala:70); at scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:51); at scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:60); at scala.collect",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/660#issuecomment-242218633:3329,failure,failure,3329,https://hail.is,https://github.com/hail-is/hail/issues/660#issuecomment-242218633,1,['failure'],['failure']
Availability,"87bf0c19bL101-R101; ):; ```diff; -orjson==3.9.10; +orjson==3.9.12; ```. orjson [reduced the frequency of this segfault in 3.9.13](https://github.com/ijl/orjson/commit/58a8bd3e31aa3b5fd3d962fb5b03479fa0014ee9) by eliding some of the code that caused buffer overheads; however, [the problem persists](https://github.com/ijl/orjson/issues/452#issuecomment-1943053799). I complete fix is currently awaiting [pull request review](https://github.com/ijl/orjson/pull/457). Reports:; - https://hail.zulipchat.com/#narrow/stream/127527-team/topic/seg.20faults.20in.20tests; - https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/segfault.20in.20ci.20tests. Batches:; - https://batch.hail.is/batches/8123269/jobs/86; - https://batch.hail.is/batches/8127894/jobs/53. ### Version. 0.2.127. ### Relevant log output. ```shell; [2024-02-08 22:36:47] test/hail/matrixtable/test_file_formats.py::test_backward_compatability_ht[/io/resources/backward_compatability/1.6.0/table/6.ht/] Fatal Python error: Segmentation fault. Thread 0x00007fa51d817640 (most recent call first):; File ""/usr/lib/python3.9/selectors.py"", line 416 in select; File ""/usr/lib/python3.9/socketserver.py"", line 232 in serve_forever; File ""/usr/lib/python3.9/threading.py"", line 917 in run; File ""/usr/lib/python3.9/threading.py"", line 980 in _bootstrap_inner; File ""/usr/lib/python3.9/threading.py"", line 937 in _bootstrap. Thread 0x00007fa5273ff640 (most recent call first):; File ""/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py"", line 58 in run; File ""/usr/lib/python3.9/threading.py"", line 980 in _bootstrap_inner; File ""/usr/lib/python3.9/threading.py"", line 937 in _bootstrap. Current thread 0x00007fa52bd6b000 (most recent call first):; File ""/usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py"", line 217 in _rpc; File ""/usr/local/lib/python3.9/dist-packages/hail/backend/backend.py"", line 212 in table_type; File ""/usr/local/lib/python3.9/dist-packages/hail/ir/table_ir.py"", line 438 in _co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14299:3188,error,error,3188,https://hail.is,https://github.com/hail-is/hail/issues/14299,2,"['error', 'fault']","['error', 'fault']"
Availability,"88> in repartition(self, n_partitions, shuffle); /home/hail/hail.zip/hail/typecheck/check.py in _typecheck(__orig_func__, *args, **kwargs); 484 def _typecheck(__orig_func__, *args, **kwargs):; 485 args_, kwargs_ = check_all(__orig_func__, args, kwargs, checkers, is_method=True); --> 486 return __orig_func__(*args_, **kwargs_); 487 ; 488 return decorator(_typecheck); /home/hail/hail.zip/hail/matrixtable.py in repartition(self, n_partitions, shuffle); 2505 Repartitioned dataset.; 2506 """"""; -> 2507 jvds = self._jvds.coalesce(n_partitions, shuffle); 2508 return MatrixTable(jvds); 2509 ; /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:; /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'; FatalError: AssertionError: assertion failed; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 7.0 failed 20 times, most recent failure: Lost task 4.19 in stage 7.0 (TID 601, mycluster-w-0.c.ukbb-all-phenos.internal, executor 2): java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.annotations.Region.loadAddress(Region.scala:63); at is.hail.expr.types.TBaseStruct.loadField(TBaseStruct.scala:215); at is.hail.annotations.RegionValueBuilder.addField(RegionValueBuilder.scala:335); at is.hail.annotations.RegionValueBuilder.addField(RegionValueBuilder.scala:341); at is.hail.annotations.WritableRegionValue.setSelect(WritableRegionValue.scala:38); at is.hail.rvd.OrderedRVD$$anonf",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3507:1889,Error,Error,1889,https://hail.is,https://github.com/hail-is/hail/issues/3507,1,['Error'],['Error']
Availability,"8928e9468335d8efab963f""><code>a9825c2</code></a> Bump py-actions/py-dependency-install from 2.1.0 to 3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1239"">#1239</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/7f65c4ccb0e954c17f2a3e1ecc665c62e4a1aaeb""><code>7f65c4c</code></a> Remove <strong>del</strong> from Redis (Fixes <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1115"">#1115</a>) (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1227"">#1227</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/5062740974e493c390fb8db33982f97d6e08df2d""><code>5062740</code></a> Fix typing on blpop (etc) timeout argument (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1224"">#1224</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/dbdd0add63f986f2ed2d56c9736303d133add23c""><code>dbdd0ad</code></a> fix socket.error raises (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1129"">#1129</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/2ba15fb6947fa2347d401ba436e362ad62ed38ff""><code>2ba15fb</code></a> Fix buffer is closed error when using PythonParser class (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1213"">#1213</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/0aa06df10b9531f4ba734ec7567f8621c00e65e9""><code>0aa06df</code></a> Fix typing on evalsha keys_and_args argument (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1215"">#1215</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/33b2dbd0a40ac148e6a36ba2fc7ab5d438a9a71d""><code>33b2dbd</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1201"">#1201</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/a708bd14b1a8bec0a1f3d469bf5384",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11569:5001,error,error,5001,https://hail.is,https://github.com/hail-is/hail/pull/11569,1,['error'],['error']
Availability,"8h99c; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; nodeName: gke-vdc-preemptible-pool-9c7148b2-4gq2; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: default; serviceAccountName: default; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: gsa-key; secret:; defaultMode: 420; secretName: konradk-gsa-key; - name: batch-2554-job-4-8vvgl; persistentVolumeClaim:; claimName: batch-2554-job-4-8vvgl; - name: default-token-8h99c; secret:; defaultMode: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: ContainersReady; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; status: ""True""; type: PodScheduled; containerStatuses:; - image: konradjk/saige:0.35.8.2.2; imageID: """"; lastState: {}; name: main; ready: false; restartCount: 0; state:; waiting:; reason: ContainerCreating; hostIP: 10.128.0.8; phase: Pending; qosClass: Burstable; startTime: ""2019-06-25T03:09:04Z""; ```; PVC in question; ```; # k describe pvc batch-2554-job-4-8vvgl -n batch-pods; Name: batch-2554-job-4-8vvgl; Namespace: batch-pods; StorageClass: batch; Status: Bound; Volume: pvc-32804669-96f6-11e9-8aa3-42010a80015f; Labels: app=batch-job; hail.is/batch-instance=cd50b95a89914efb897965a5e982a29d; Ann",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466:6590,toler,tolerationSeconds,6590,https://hail.is,https://github.com/hail-is/hail/issues/6466,1,['toler'],['tolerationSeconds']
Availability,"8h99c; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; nodeName: gke-vdc-preemptible-pool-9c7148b2-4gq2; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: default; serviceAccountName: default; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: gsa-key; secret:; defaultMode: 420; secretName: konradk-gsa-key; - name: batch-2554-job-4-8vvgl; persistentVolumeClaim:; claimName: batch-2554-job-4-8vvgl; - name: default-token-8h99c; secret:; defaultMode: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T12:37:07Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T12:37:07Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T12:37:07Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: ContainersReady; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T12:37:07Z""; status: ""True""; type: PodScheduled; containerStatuses:; - image: konradjk/saige:0.35.8.2.2; imageID: """"; lastState: {}; name: main; ready: false; restartCount: 0; state:; waiting:; reason: ContainerCreating; hostIP: 10.128.0.8; phase: Pending; qosClass: Burstable; startTime: ""2019-06-25T12:37:07Z""; + kubectl describe pod batch-2554-job-4-main-vsk7h -n batch-pods; Name: batch-2554-job-4-main-vsk7h; Namespace: batch-pods; Priority: 500000; PriorityClassName: user; Node: gke-vdc-preemptible-pool-9c7148b2-4gq2/10.128.0.8; Start Time: Tue, 25 Jun 2019 08:37:07 -0400; Labels: app=batch-job; hail.is/batc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649:14865,toler,tolerationSeconds,14865,https://hail.is,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649,1,['toler'],['tolerationSeconds']
Availability,"9 for temp_arg in temp_args:. ~/bin/anaconda3/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:633); 	at is.hail.io.vcf.MatrixVCFReader.<init>(LoadVCF.scala:894); 	at is.hail.io.vcf.LoadVCF$.pyApply(LoadVCF.scala:850); 	at is.hail.io.vcf.LoadVCF.pyApply(LoadVCF.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2-a2eaf89baa0c; Error summary: HailException: arguments refer to no files; ```. Basically, the ; ```; hl.utils.get_1kg('data/'); ```; ![image](https://user-images.githubusercontent.com/10011161/48459558-9f645c80-e798-11e8-94db-0faa2e44e985.png). directly provides 1kg.mt so the conversion step ; ```python; hl.import_vcf('data/1kg.vcf.bgz').write('data/1kg.mt', overwrite=True); ```; is unnecessary:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4775:3519,Error,Error,3519,https://hail.is,https://github.com/hail-is/hail/issues/4775,1,['Error'],['Error']
Availability,"9% /etc/hosts; shm 64.0M 0 64.0M 0% /dev/shm; tmpfs 14.7G 12.0K 14.7G 0% /var/run/secrets/kubernetes.io/serviceaccount; tmpfs 14.7G 0 14.7G 0% /proc/acpi; tmpfs 64.0M 0 64.0M 0% /proc/kcore; tmpfs 64.0M 0 64.0M 0% /proc/keys; tmpfs 64.0M 0 64.0M 0% /proc/timer_list; tmpfs 14.7G 0 14.7G 0% /proc/scsi; tmpfs 14.7G 0 14.7G 0% /sys/firmware; ```. Which isn't much larger than it was before the scaling tests. It appears to slowly increase the amount of memory it needs:; ```; 1 0 nobody S 30.9g103.7 1 11.5 /bin/prometheus --config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/prometheus --web.console.libraries=/usr/share/prometheus/console_libraries --web.console.templates=/usr/share/prometheus/consoles --web.external; ```. caping out at 31.5 GB (the disk is 31.2 GB). Now, it is presumably trying to recover. It's been up for about 7 minutes. Still unavailable:; ```; /prometheus $ wget localhost:9090/monitoring/prometheus; Connecting to localhost:9090 (127.0.0.1:9090); wget: server returned error: HTTP/1.1 503 Service Unavailable; /prometheus $ ; ```. https://github.com/prometheus/prometheus/issues/5727#issuecomment-510818825; https://github.com/prometheus/prometheus/issues/4324#issuecomment-460243182. ```; # k logs -n monitoring prometheus-0 ; level=info ts=2019-07-31T15:45:51.990Z caller=main.go:286 msg=""no time or size retention was set so using the default time retention"" duration=15d; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:322 msg=""Starting Prometheus"" version=""(version=2.10.0, branch=HEAD, revision=d20e84d0fb64aff2f62a977adc8cfb656da4e286)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:323 build_context=""(go=go1.12.5, user=root@a49185acd9b0, date=20190525-12:28:13)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:324 host_details=""(Linux 4.14.127+ #1 SMP Tue Jun 18 18:32:10 PDT 2019 x86_64 prometheus-0 (none))""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:325 fd_limits=""(soft=1048576, hard=1048576)""; level=info ts=201",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6773:2062,error,error,2062,https://hail.is,https://github.com/hail-is/hail/issues/6773,1,['error'],['error']
Availability,"9); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-e6de08e; Error summary: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [3c5f402fed564ccd85257c0919d4bffb] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 128, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 109, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, output=output); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/gnomad_qc/hail/sample_qc/assign_subpops.py', '--cluster', 'gt1', '--files=gs://hail-common/builds/devel/jars/hail-devel-38dbf156b630-Spark-2.2.0.jar', '--py-files=gs://hail-common/builds/devel/python/hail-devel-38dbf156b630.zip,/var/folders/rn/t2xcx1ps4h96txll46qkkfsj2q8bnl/T/pyscripts_fYVAte.zip', '--properties=spark.executor.extraClassPath=./hail-devel-38dbf156b630-Spark-2.2.0.jar,spark.driver.extraClassPat",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:7576,ERROR,ERROR,7576,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627,1,['ERROR'],['ERROR']
Availability,"9-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cae8477{/executors/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3f5a136b{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1c36c598{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@35dfb92d{/static,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@85877e{/,null,AVAILABLE,@Spark}; [farrell@scc-hadoop ukb.v3]$ cat /restricted/projectnb/ukbiobank/ad/analysis/ukb.v3/hail-20190122-1311-0.2.4-d602a3d7472d.log; 2019-01-22 13:11:20 SparkContext: INFO: Running Spark version 2.2.1; 2019-01-22 13:11:20 NativeCodeLoader: WARN: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 2019-01-22 13:11:21 SparkContext: INFO: Submitted application: Hail; 2019-01-22 13:11:21 SparkContext: INFO: Spark configuration:; spark.app.name=Hail; spark.driver.extraClassPath=""/restricted/projectnb/genpro/github/hail/hail/build/libs/hail-all-spark.jar""; spark.driver.memory=5G; spark.executor.cores=4; spark.executor.extraClassPath=./hail-all-spark.jar; spark.executor.instances=10; spark.executor.memory=40G; spark.hadoop.io.compression.codecs=org.apache.hadoop.io.compress.DefaultCodec,is.hail.io.compress.BGzipCodec,is.hail.io.compress.BGzipCodecTbi,org.apache.hadoop.io.compress.GzipCodec; spark.hadoop.mapreduce.input.fileinputforma",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:6834,AVAIL,AVAILABLE,6834,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['AVAIL'],['AVAILABLE']
Availability,"910eaa1b8da8ff8575e514bc61c78. Kotlin: 1.4.20; Groovy: 2.5.12; Ant: Apache Ant(TM) version 1.10.9 compiled on September 27 2020; JVM: 1.8.0_362 (Private Build 25.362-b09); OS: Linux 5.4.0-1042-gcp amd64. real	0m3.621s; user	0m4.448s; sys	0m0.623s; + retry make jars wheel HAIL_DEBUG_MODE=1; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.0"" which is different from old value """"; printf ""3.3.0"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=' >> src/main/resources/build-info.properties; echo 'revision=e1d86e1908f0911d45b03ef08a694d07e1c4627b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-03-09T23:23:56Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.0' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.110' >> src/main/resources/build-info.properties; HAIL_DEBUG_MODE is set to ""1"" which is different from old value """"; printf ""1"" > env/HAIL_DEBUG_MODE; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; javac -d build/classes/scala/debug -Xlint:all -Werror -XDenableSunApiLintControl -XDignore.symbol.file src/debug/scala/is/hail/annotations/Memory.java; ./gradlew shadowJar -Dscala.version=2.12.13 -Dspark.version=3.3.0 -Delasticsearch.major-version=7; Starting a Gradle Daemon (subsequent builds will be faster); > Task :compileJava NO-SOURCE; > Task :compileScala; [Error] /io/repo/hail/src/main/scala/is/hail/expr/ir/MatrixWriter.scala:122: value of is not a member of object java.nio.file.Path; [Error] /io/repo/hail/src/main/scala/is/hail/expr/ir/TableWriter.scala:57: value of is not a member of object java.nio.file.Path; [Error] /io/repo/hail/src/main/scala/is/hail/expr/ir/TableWriter.scala:674: value of is not a member of object java.nio.file.Path; three errors found; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12773#issuecomment-1463003450:1828,Error,Error,1828,https://hail.is,https://github.com/hail-is/hail/pull/12773#issuecomment-1463003450,4,"['Error', 'error']","['Error', 'errors']"
Availability,"946 | amazon-ebs: Collecting nest_asyncio==1.5.4; 947 | amazon-ebs: Downloading nest_asyncio-1.5.4-py3-none-any.whl (5.1 kB); 948 | amazon-ebs: Requirement already satisfied: numpy<2 in /usr/local/lib64/python3.7/site-packages (1.21.6); 949 | amazon-ebs: Collecting orjson==3.6.4; 950 | amazon-ebs: Downloading orjson-3.6.4-cp37-cp37m-manylinux_2_24_x86_64.whl (249 kB); 951 | amazon-ebs:  249.9/249.9 kB 45.1 MB/s eta 0:00:00; 952 | amazon-ebs: Requirement already satisfied: pandas<1.5.0,>=1.3.0 in /usr/local/lib64/python3.7/site-packages (1.3.5); 953 | amazon-ebs: Collecting parsimonious<0.9; 954 | amazon-ebs: Downloading parsimonious-0.8.1.tar.gz (45 kB); 955 | amazon-ebs:  45.1/45.1 kB 10.2 MB/s eta 0:00:00; 956 | amazon-ebs: Preparing metadata (setup.py): started; 957 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 958 | amazon-ebs: Collecting plotly<5.11,>=5.5.0; 959 | amazon-ebs: Downloading plotly-5.10.0-py2.py3-none-any.whl (15.2 MB); 960 | amazon-ebs:  15.2/15.2 MB 57.8 MB/s eta 0:00:00; 961 | amazon-ebs: Collecting PyJWT; 962 | amazon-ebs: Downloading PyJWT-2.5.0-py3-none-any.whl (20 kB); 963 | amazon-ebs: Collecting python-json-logger==2.0.2; 964 | amazon-ebs: Downloading python_json_logger-2.0.2-py3-none-any.whl (7.4 kB); 965 | amazon-ebs: Collecting requests==2.25.1; 966 | amazon-ebs: Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB); 967 | amazon-ebs:  61.2/61.2 kB 15.6 MB/s eta 0:00:00; 968 | amazon-ebs: Requirement already satisfied: scipy<1.8,>1.2 in /usr/local/lib64/python3.7/site-packages (1.7.3); 969 | amazon-ebs: Requirement already satisfied: sortedcontainers==2.4.0 in /usr/local/lib/python3.7/site-packages (2.4.0); 970 | amazon-ebs: Collecting tabulate==0.8.9; 971 | amazon-ebs: Downloading tabulate-0.8.9-py3-none-any.whl (25 kB); 972 | amazon-ebs: Requirement",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:6497,Down,Downloading,6497,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,"972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315975) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **691/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.4 | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:5260,avail,available,5260,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,"972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315975) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **691/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.4 | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:5252,avail,available,5252,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['avail'],['available']
Availability,"9</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Fix search coming back in notebook and editor <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15443"">#15443</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Fix <code>jupyter labextension watch --help</code> <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15542"">#15542</a> (<a href=""https://github.com/akx""><code>@akx</code></a>)</li>; <li>Fix <code>FormComponent</code> showing error indicators in all fields when using a <code>customValidate</code> function <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15464"">#15464</a> (<a href=""https://github.com/mmichilot""><code>@mmichilot</code></a>)</li>; <li>Fix Shift + L not working in stdin <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15440"">#15440</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15499"">#15499</a>: Adopt ruff format <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15564"">#15564</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Pin <code>actions/labeler</code> to v4 to fix failing CI action <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15496"">#15496</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Fix URLs in debugger-extension <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15462"">#15462</a> (<a href=""https://github.com/fcollonval""><code>@fcollonval</code></a>)</li>; <li>More robust galata/UI tests <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15355"">#15355</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; </ul>; <h3>Documentation improvements</h3>; <ul>; <li>Backport PR <a hr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14184:4720,Mainten,Maintenance,4720,https://hail.is,https://github.com/hail-is/hail/pull/14184,2,['Mainten'],['Maintenance']
Availability,": 10}. # Group by the array directly (gives an expected error); > mt.aggregate_rows(hl.agg.counter(mt.alleles)); TypeError: unhashable type: 'list'. # Aggregate sorted arrays (works but gives wrong result); > mt.aggregate_rows(hl.agg.counter(hl.delimit(hl.sorted(mt.alleles), '|'))); {'A|A|A|C|\x0b\x00\x00': 2, 'A|A|A|C|C|C': 8}. # Aggregate the sorted arrays directly (segfault); # *This should probably throw ""unhashable type list"" like it does without the sort*; mt.aggregate_rows(hl.agg.counter(hl.sorted(mt.alleles))); ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/opt/conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty; ...; Py4JError: An error occurred while calling o59.executeJSON; ```. Here is the full [stack trace](https://github.com/hail-is/hail/files/4187400/stacktrace.txt) and [core dump](https://github.com/hail-is/hail/files/4187399/coredump.txt). I think some related questions that arise from this are:. 1. What's the best way to group by an array to avoid the conversion to a delimited string? In this case I could do something like ```mt.aggregate_rows(hl.agg.counter(hl.tuple([mt.alleles[0], mt.alleles[1]])))``` but I can't find a solution for getting a tuple from an array without knowing the length of it beforehand for every row. Is there a more fundamental reason why the API doesn't allow aggregation by arrays even if Spark does?; 2. When the Py4J server crashes, it's no longer reachable from the python clients so I have to restart my process and re-initialize Hail. Is there already functionality implemented for bringing that server up if it's down? I'd imagine segfaults aren't the only reason it could down, so it would be nice if there was a way to bring it back up either automatically or manually. Hail version: 0.2.30-2ae07d872f43; Spark version: 2.4.4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8076:2142,down,down,2142,https://hail.is,https://github.com/hail-is/hail/issues/8076,2,['down'],['down']
Availability,": ; 2.49.0; Measurement time: ; 2023-06-05 03:25:16 PM ; Running on GCE: ; True; GCE Instance:; 	; Bucket location: ; US-CENTRAL1; Bucket storage class: ; REGIONAL; Google Server: ; ; Google Server IP Addresses: ; 142.250.128.128; 142.251.6.128; 108.177.112.128; 74.125.124.128; 172.217.212.128; 172.217.214.128; 172.253.119.128; 108.177.111.128; 142.250.1.128; 108.177.121.128; 142.250.103.128; 108.177.120.128; 142.250.159.128; 142.251.120.128; 142.251.161.128; 74.125.126.128; Google Server Hostnames: ; ib-in-f128.1e100.net; ic-in-f128.1e100.net; jo-in-f128.1e100.net; jp-in-f128.1e100.net; jq-in-f128.1e100.net; jr-in-f128.1e100.net; jt-in-f128.1e100.net; jv-in-f128.1e100.net; jw-in-f128.1e100.net; jx-in-f128.1e100.net; jy-in-f128.1e100.net; jz-in-f128.1e100.net; ie-in-f128.1e100.net; if-in-f128.1e100.net; ig-in-f128.1e100.net; ik-in-f128.1e100.net; Google DNS thinks your IP is: ; ; CPU Count: ; 16; CPU Load Average: ; [32.39, 33.2, 19.0]; Total Memory: ; 57.5 GiB; Free Memory: ; 38.41 GiB; TCP segment counts not available because ""netstat"" was not found during test runs; Disk Counter Deltas:; disk reads writes rbytes wbytes rtime wtime ; loop0 0 0 0 0 0 0 ; loop1 0 0 0 0 0 0 ; loop3 0 0 0 0 0 0 ; loop4 0 0 0 0 0 0 ; loop5 0 0 0 0 0 0 ; nvme0n1 4385 4694 581857280 1743810560 6453 527129 ; sda1 0 544 0 3731456 0 429 ; sda14 0 0 0 0 0 0 ; sda15 0 0 0 0 0 0 ; TCP /proc values:; tcp_timestamps = 1; tcp_sack = 1; tcp_window_scaling = 1; Boto HTTPS Enabled: ; True; Requests routed through proxy: ; False; Latency of the DNS lookup for Google Storage server (ms): ; 1.5; Latencies connecting to Google Storage server IPs (ms):; 74.125.126.128 = 1.1. ------------------------------------------------------------------------------; In-Process HTTP Statistics ; ------------------------------------------------------------------------------; Total HTTP requests made: 149; HTTP 5xx errors: 0; HTTP connections broken: 0; Availability: 100%. Output file written to '/tmp/output.json'.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12923#issuecomment-1577071597:3689,avail,available,3689,https://hail.is,https://github.com/hail-is/hail/issues/12923#issuecomment-1577071597,3,"['Avail', 'avail', 'error']","['Availability', 'available', 'errors']"
Availability,: AssertionError: assertion failed; Java stack trace:; java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:78); at is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:7); at is.hail.expr.ir.Emit$.emit(Emit.scala:42); at is.hail.expr.ir.Emit$.apply(Emit.scala:28); at is.hail.expr.ir.Compile$.apply(Compile.scala:49); at is.hail.expr.ir.Compile$.apply(Compile.scala:31); at is.hail.expr.ir.Compile$.apply(Compile.scala:62); at is.hail.expr.TableExplode.execute(Relational.scala:2201); at is.hail.expr.TableUnkey.execute(Relational.scala:1883); at is.hail.expr.TableMapRows.execute(Relational.scala:2090); at is.hail.expr.TableKeyBy.execute(Relational.scala:1846); at is.hail.expr.TableMapRows.execute(Relational.scala:2090); at is.hail.table.Table.value$lzycompute(Table.scala:243); at is.hail.table.Table.value(Table.scala:238); at is.hail.table.Table.x$5$lzycompute(Table.scala:246); at is.hail.table.Table.x$5(Table.scala:246); at is.hail.table.Table.rvd$lzycompute(Table.scala:246); at is.hail.table.Table.rvd(Table.scala:246); at is.hail.table.Table.take(Table.scala:961); at is.hail.table.Table.showString(Table.scala:1002); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745); Hail version: devel-10a75bb57a6f; Error summary: AssertionError: assertion failed; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3744:4559,Error,Error,4559,https://hail.is,https://github.com/hail-is/hail/issues/3744,1,['Error'],['Error']
Availability,": Downloading asyncinit-0.2.4-py3-none-any.whl (2.8 kB); 901 | amazon-ebs: Collecting avro<1.12,>=1.10; 902 | amazon-ebs: Downloading avro-1.11.1.tar.gz (84 kB); 903 | amazon-ebs:  84.2/84.2 kB 22.0 MB/s eta 0:00:00; 904 | amazon-ebs: Installing build dependencies: started; 905 | amazon-ebs: Installing build dependencies: finished with status 'done'; 906 | amazon-ebs: Getting requirements to build wheel: started; 907 | amazon-ebs: Getting requirements to build wheel: finished with status 'done'; 908 | amazon-ebs: Preparing metadata (pyproject.toml): started; 909 | amazon-ebs: Preparing metadata (pyproject.toml): finished with status 'done'; 910 | amazon-ebs: Collecting azure-identity==1.6.0; 911 | amazon-ebs: Downloading azure_identity-1.6.0-py2.py3-none-any.whl (108 kB); 912 | amazon-ebs:  108.5/108.5 kB 28.5 MB/s eta 0:00:00; 913 | amazon-ebs: Collecting azure-storage-blob==12.11.0; 914 | amazon-ebs: Downloading azure_storage_blob-12.11.0-py3-none-any.whl (346 kB); 915 | amazon-ebs:  346.4/346.4 kB 41.0 MB/s eta 0:00:00; 916 | amazon-ebs: Collecting bokeh<2.0,>1.3; 917 | amazon-ebs: Downloading bokeh-1.4.0.tar.gz (32.4 MB); 918 | amazon-ebs:  32.4/32.4 MB 48.4 MB/s eta 0:00:00; 919 | amazon-ebs: Preparing metadata (setup.py): started; 920 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 921 | amazon-ebs: Requirement already satisfied: boto3<2.0,>=1.17 in /usr/local/lib/python3.7/site-packages (1.24.78); 922 | amazon-ebs: Requirement already satisfied: botocore<2.0,>=1.20 in /usr/local/lib/python3.7/site-packages (1.27.78); 923 | amazon-ebs: Collecting decorator<5; 924 | amazon-ebs: Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); 925 | amazon-ebs: Collecting Deprecated<1.3,>=1.2.10; 926 | amazon-ebs: Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB); 927 | amazon-ebs:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:3126,Down,Downloading,3126,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,": INFO: Coerced almost-sorted dataset; [Stage 2:> (0 + 36) / 416]Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail/delly_vcf2vdf.py"", line 3, in <module>; hl.import_vcf('/project/casa/vcf.5k/delly/gcad.sv.delly.5k.vcf.bgz').write('/project/casa/vdf.5k/delly'); File ""<decorator-gen-546>"", line 2, in write; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 481, in _typecheck; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 1956, in write; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: NumberFormatException: For input string: ""-66.2667,0,-25.4754"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 48 in stage 2.0 failed 4 times, most recent failure: Lost task 48.3 in stage 2.0 (TID 536, scc-q14.scc.bu.edu, executor 1): is.hail.utils.HailExcput string: ""-66.2667,0,-25.4754""; offending line: chr2 130824417 DEL00068296 AGAACAGGACATCCCAGGCAGCTACAGCCCATC...; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.utils.Context.wrapException(Context.scala:23); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:741); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:412); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:750); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$class.foreach",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3361:2016,failure,failure,2016,https://hail.is,https://github.com/hail-is/hail/issues/3361,1,['failure'],['failure']
Availability,": i686; Version : 3.10.1; Release : 10.el7; Size : 1.5 M; Repo : base/7/x86_64; Summary : Development libraries for ATLAS; URL : http://math-atlas.sourceforge.net/; License : BSD; Description : This package contains the libraries and headers for development; : with ATLAS (Automatically Tuned Linear Algebra Software). Name : atlas-devel; Arch : x86_64; Version : 3.10.1; Release : 10.el7; Size : 1.5 M; Repo : base/7/x86_64; Summary : Development libraries for ATLAS; URL : http://math-atlas.sourceforge.net/; License : BSD; Description : This package contains the libraries and headers for development; : with ATLAS (Automatically Tuned Linear Algebra Software). ## 2I installed the atlas-devel , . root yum.repos.d $ yum install atlas-devel; Loaded plugins: fastestmirror, langpacks; Loading mirror speeds from cached hostfile; - base: mirror.bit.edu.cn; - epel: mirrors.neusoft.edu.cn; - extras: mirror.bit.edu.cn; - updates: mirror.bit.edu.cn; Resolving Dependencies; --> Running transaction check; ---> Package atlas-devel.x86_64 0:3.10.1-10.el7 will be installed; --> Processing Dependency: atlas = 3.10.1-10.el7 for package: atlas-devel-3.10.1-10.el7.x86_64; ............. Installed:; atlas-devel.x86_64 0:3.10.1-10.el7 . Dependency Installed:; atlas.x86_64 0:3.10.1-10.el7 . ## Complete!. ## ######**but when I excute the ""gradle check --info"" the error still appeared.**. /opt/BioDir/jdk/jdk1.8.0_91/bin/java: symbol lookup error: /tmp/jniloader7277009897699512423netlib-native_system-linux-x86_64.so: undefined symbol: cblas_dgemv. FAILURE: Build failed with an exception.; - What went wrong:; Execution failed for task ':test'.; ; > Process 'Gradle Test Executor 1' finished with non-zero exit value 127; - Try:; ; ## Run with --stacktrace option to get the stack trace. Run with --debug option to get more log output.; ; #######The output info was collected in the file as follow:; [gradle_check_info1.txt](https://github.com/broadinstitute/hail/files/417544/gradle_check_info1.txt)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/565#issuecomment-239729893:1990,error,error,1990,https://hail.is,https://github.com/hail-is/hail/issues/565#issuecomment-239729893,3,"['FAILURE', 'error']","['FAILURE', 'error']"
Availability,"://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105916"">kubernetes/kubernetes#105916</a>, <a href=""https://github.com/kevindelgado""><code>@kevindelgado</code></a>)</li>; <li>Promote <code>IPv6DualStack</code> feature to stable.; Controller Manager flags for the node IPAM controller have slightly changed:; <ol>; <li>When configuring a dual-stack cluster, the user must specify both <code>--node-cidr-mask-size-ipv4</code> and <code>--node-cidr-mask-size-ipv6</code> to set the per-node IP mask sizes, instead of the previous <code>--node-cidr-mask-size</code> flag.</li>; <li>The <code>--node-cidr-mask-size</code> flag is mutually exclusive with <code>--node-cidr-mask-size-ipv4</code> and <code>--node-cidr-mask-size-ipv6</code>.</li>; <li>Single-stack clusters do not need to change, but may choose to use the more specific flags. Users can use either the older <code>--node-cidr-mask-size</code> flag or one of the newer <code>--node-cidr-mask-size-ipv4</code> or <code>--node-cidr-mask-size-ipv6</code> flags to configure the per-node IP mask size, provided that the flag's IP family matches the cluster's IP family (--cluster-cidr). (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104691"">kubernetes/kubernetes#104691</a>, <a href=""https://github.com/khenidak""><code>@khenidak</code></a>)</li>; </ol>; </li>; <li>Remove <code>NodeLease</code> feature gate that was graduated and locked to stable in 1.17 release. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105222"">kubernetes/kubernetes#105222</a>, <a href=""https://github.com/cyclinder""><code>@cyclinder</code></a>)</li>; <li>Removed deprecated <code>--seccomp-profile-root</code>/<code>seccompProfileRoot</code> config. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/103941"">kubernetes/kubernetes#103941</a>, <a href=""https://github.com/saschagrunert""><code>@saschagrunert</code></a>)</li>; <li>Since golang 1.17 both net.ParseIP and ne",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:11095,mask,mask-size,11095,https://hail.is,https://github.com/hail-is/hail/pull/11957,4,['mask'],"['mask', 'mask-size', 'mask-size-']"
Availability,"://github.com/michel-kraemer/gradle-download-task/commit/612f57a382b8640cc730dc5e75d1c809e3e772bd""><code>612f57a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/291"">#291</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/53af1049f5514afe58e884d487d7c57dae47759d""><code>53af104</code></a> Bump http-cache-semantics from 4.1.0 to 4.1.1 in /screencast</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/398c14c05c6448b380ac35c6095598299c5e23c5""><code>398c14c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/15cf7eecfbc17d2466143828b9b69494c6cb6f2b""><code>15cf7ee</code></a> Bump up version number to 5.3.1-SNAPSHOT</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e3c65ffcb49b9c5a33fde5f31fb63043dbf21134""><code>e3c65ff</code></a> Allow extensions to be created from tasks</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/34e2dd41477f18b1ae3d6d5a71dca5449d6cd1e0""><code>34e2dd4</code></a> Downgrade slf4j to fix warning on console about missing slf4j provider</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b3fa29f9ffb4d4544e13ef84601e371fb2778ddf""><code>b3fa29f</code></a> Revert &quot;Update Apache HttpClient to 5.2.1&quot;</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/01f05e046be0dca18f506723c79e88f208336e71""><code>01f05e0</code></a> Add integration tests for Gradle 6.9.3 and 7.6</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a998a544908a8b39f713f4526f717fcb328c06eb""><code>a998a54</code></a> Upgrade Gradle to 7.6</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.0...5.3.1"">compare view</a></li>; </u",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:2177,down,download-task,2177,https://hail.is,https://github.com/hail-is/hail/pull/12707,1,['down'],['download-task']
Availability,"://github.com/michel-kraemer/gradle-download-task/commit/a8504f9d60d0264808894e4bb80d4a73b8086a3e""><code>a8504f9</code></a> Bump up version number to 5.3.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/708067cd11c4a013da7a8c15d91f7f946967cf94""><code>708067c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0fdebf3c7ad43ed4739d0400c333a72b32f5d514""><code>0fdebf3</code></a> Improve verify example</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/019089b9554692674d6baee7df7d4d884f310cc9""><code>019089b</code></a> Correctly create list of output files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/fa2739ded05333ba46d8f50bb3b2a3721cf0ca86""><code>fa2739d</code></a> Create target directories at a central place</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/02b8e1a79d9e00acd61f9ac42e5555619fe2247a""><code>02b8e1a</code></a> Prevent duplicate destination files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0b65ca2f17c8890a3ec34cf80cde52ee5413cbec""><code>0b65ca2</code></a> Call eachFile action only once per source</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/717877121299cea8f216d3a595eaa56731a6acd3""><code>7178771</code></a> Support changing a target file's relative path in an eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e5af1bd7f9daa8a9222aee0dd1b703727cb5e94e""><code>e5af1bd</code></a> Bump version number to 5.3.0-SNAPSHOT</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previou",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:4304,down,download-task,4304,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download-task']
Availability,":0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:164) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	... 12 more; 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 		at is.hail.relocated.com.google.cloud.storage.StorageException.translate(StorageException.java:165) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:298) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1029) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.ResumableMedia.lambda$startUploadForBlobInfo$0(ResumableMedia.java:40) ~[gs:__hail-query-ger",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:17783,error,errors,17783,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['error'],['errors']
Availability,":00:00; 961 | amazon-ebs: Collecting PyJWT; 962 | amazon-ebs: Downloading PyJWT-2.5.0-py3-none-any.whl (20 kB); 963 | amazon-ebs: Collecting python-json-logger==2.0.2; 964 | amazon-ebs: Downloading python_json_logger-2.0.2-py3-none-any.whl (7.4 kB); 965 | amazon-ebs: Collecting requests==2.25.1; 966 | amazon-ebs: Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB); 967 | amazon-ebs:  61.2/61.2 kB 15.6 MB/s eta 0:00:00; 968 | amazon-ebs: Requirement already satisfied: scipy<1.8,>1.2 in /usr/local/lib64/python3.7/site-packages (1.7.3); 969 | amazon-ebs: Requirement already satisfied: sortedcontainers==2.4.0 in /usr/local/lib/python3.7/site-packages (2.4.0); 970 | amazon-ebs: Collecting tabulate==0.8.9; 971 | amazon-ebs: Downloading tabulate-0.8.9-py3-none-any.whl (25 kB); 972 | amazon-ebs: Requirement already satisfied: tqdm==4.* in /usr/local/lib/python3.7/site-packages (4.64.1); 973 | amazon-ebs: Collecting uvloop==0.16.0; 974 | amazon-ebs: Downloading uvloop-0.16.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.8 MB); 975 | amazon-ebs:  3.8/3.8 MB 113.0 MB/s eta 0:00:00; 976 | ==> amazon-ebs: ERROR: Ignored the following versions that require a different python version: 1.22.0 Requires-Python >=3.8; 1.22.0rc1 Requires-Python >=3.8; 1.22.0rc2 Requires-Python >=3.8; 1.22.0rc3 Requires-Python >=3.8; 1.22.1 Requires-Python >=3.8; 1.22.2 Requires-Python >=3.8; 1.22.3 Requires-Python >=3.8; 1.22.4 Requires-Python >=3.8; 1.23.0 Requires-Python >=3.8; 1.23.0rc1 Requires-Python >=3.8; 1.23.0rc2 Requires-Python >=3.8; 1.23.0rc3 Requires-Python >=3.8; 1.23.1 Requires-Python >=3.8; 1.23.2 Requires-Python >=3.8; 1.23.3 Requires-Python >=3.8; 1.4.0 Requires-Python >=3.8; 1.4.0rc0 Requires-Python >=3.8; 1.4.1 Requires-Python >=3.8; 1.4.2 Requires-Python >=3.8; 1.4.3 Requires-Python >=3.8; 1.4.4 Requires-Python >=3.8; 1.5.0 Requires-Python >=3.8; 1.5.0rc0 Requires-Python >=3.8; 1.8.0",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:7642,Down,Downloading,7642,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,":00; 952 | amazon-ebs: Requirement already satisfied: pandas<1.5.0,>=1.3.0 in /usr/local/lib64/python3.7/site-packages (1.3.5); 953 | amazon-ebs: Collecting parsimonious<0.9; 954 | amazon-ebs: Downloading parsimonious-0.8.1.tar.gz (45 kB); 955 | amazon-ebs:  45.1/45.1 kB 10.2 MB/s eta 0:00:00; 956 | amazon-ebs: Preparing metadata (setup.py): started; 957 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 958 | amazon-ebs: Collecting plotly<5.11,>=5.5.0; 959 | amazon-ebs: Downloading plotly-5.10.0-py2.py3-none-any.whl (15.2 MB); 960 | amazon-ebs:  15.2/15.2 MB 57.8 MB/s eta 0:00:00; 961 | amazon-ebs: Collecting PyJWT; 962 | amazon-ebs: Downloading PyJWT-2.5.0-py3-none-any.whl (20 kB); 963 | amazon-ebs: Collecting python-json-logger==2.0.2; 964 | amazon-ebs: Downloading python_json_logger-2.0.2-py3-none-any.whl (7.4 kB); 965 | amazon-ebs: Collecting requests==2.25.1; 966 | amazon-ebs: Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB); 967 | amazon-ebs:  61.2/61.2 kB 15.6 MB/s eta 0:00:00; 968 | amazon-ebs: Requirement already satisfied: scipy<1.8,>1.2 in /usr/local/lib64/python3.7/site-packages (1.7.3); 969 | amazon-ebs: Requirement already satisfied: sortedcontainers==2.4.0 in /usr/local/lib/python3.7/site-packages (2.4.0); 970 | amazon-ebs: Collecting tabulate==0.8.9; 971 | amazon-ebs: Downloading tabulate-0.8.9-py3-none-any.whl (25 kB); 972 | amazon-ebs: Requirement already satisfied: tqdm==4.* in /usr/local/lib/python3.7/site-packages (4.64.1); 973 | amazon-ebs: Collecting uvloop==0.16.0; 974 | amazon-ebs: Downloading uvloop-0.16.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.8 MB); 975 | amazon-ebs:  3.8/3.8 MB 113.0 MB/s eta 0:00:00; 976 | ==> amazon-ebs: ERROR: Ignored the following versions that require a different python version: 1.22.0 Requires-Python >=3.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:6957,Down,Downloading,6957,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,:212); 	at scala.collection.AbstractIterator.fold(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1$$anonfun$20.apply(RDD.scala:1095); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1$$anonfun$20.apply(RDD.scala:1095); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). is.hail.utils.HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.io.LoadMatrixParser.parseLine(LoadMatrix.scala:33); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:383); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:377); 	at is.hail.utils.WithContext.wrap(Context.scala:41); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:575); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:573); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:12849,Error,ErrorHandling,12849,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['Error'],['ErrorHandling']
Availability,":46:55]	[:makeHailDocs] single_key='false',; [13:46:55]	[:makeHailDocs] agg_expr='gs.map(g => g.gt).max()',; [13:46:55]	[:makeHailDocs] y='sa.burden.pheno',; [13:46:55]	[:makeHailDocs] covariates=['sa.burden.cov1', 'sa.burden.cov2'])); [13:46:55]	[:makeHailDocs] Exception raised:; [13:46:55]	[:makeHailDocs] Traceback (most recent call last):; [13:46:55]	[:makeHailDocs] File ""/usr/lib64/python2.7/doctest.py"", line 1315, in __run; [13:46:55]	[:makeHailDocs] compileflags, 1) in test.globs; [13:46:55]	[:makeHailDocs] File ""<doctest default[0]>"", line 7, in <module>; [13:46:55]	[:makeHailDocs] covariates=['sa.burden.cov1', 'sa.burden.cov2'])); [13:46:55]	[:makeHailDocs] File ""<decorator-gen-233>"", line 2, in linreg_burden; [13:46:55]	[:makeHailDocs] File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/java.py"", line 119, in handle_py4j; [13:46:55]	[:makeHailDocs] 'Error summary: %s' % (msg, e.message, Env.hc().version, msg)); [13:46:55]	[:makeHailDocs] FatalError: An error occurred while calling into JVM, probably due to invalid parameter types.; [13:46:55]	[:makeHailDocs] ; [13:46:55]	[:makeHailDocs] Java stack trace:; [13:46:55]	[:makeHailDocs] An error occurred while calling o3918.linregBurden. Trace:; [13:46:55]	[:makeHailDocs] py4j.Py4JException: Method linregBurden([class java.lang.String, class java.lang.String, class java.lang.String, class java.lang.String, class java.lang.String, class [Ljava.lang.String;]) does not exist; [13:46:55]	[:makeHailDocs] 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); [13:46:55]	[:makeHailDocs] 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326); [13:46:55]	[:makeHailDocs] 	at py4j.Gateway.invoke(Gateway.java:272); [13:46:55]	[:makeHailDocs] 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); [13:46:55]	[:makeHailDocs] 	at py4j.commands.CallCommand.execute(CallCommand.java:79); [13:46:55]	[:makeHailDocs] 	at py4j.GatewayConnection.run(GatewayConnectio",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1708#issuecomment-297039203:1506,error,error,1506,https://hail.is,https://github.com/hail-is/hail/pull/1708#issuecomment-297039203,1,['error'],['error']
Availability,"::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::float32<4>; T = simdpp::arch_avx2::float64<2, simdpp::arch_avx2::expr_empty>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::float32<4>; T = simdpp::arch_avx2::float64<2, simdpp::arch_avx2::expr_empty>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::float32<4>; T = simdpp::arch_avx2::float64<2, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:255:45: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::float32<4> with private member simdpp::arch_avx2::float32<4>::d_ from an array of const class simdpp::arch_avx2::float64<2, simdpp::arch_avx2::expr_empty>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:29,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/float32x4.h:32:7: note: class simdpp::arch_avx2::float32<4> declared here; class float32<4, void> : public any_float32<4, float32<4,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint16<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(con",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:3800,error,error,3800,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:253:45: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::float64<2> with private member simdpp::arch_avx2::float64<2>::d_ from an array of const class simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:32,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/float64x2.h:32:7: note: class simdpp::arch_avx2::float64<2> declared here; class float64<2, void> : public any_float64<2, float64<2,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::float32<4>; T = simdpp::arch_avx2::float64<2, simdpp::arch_avx2::expr_empty>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:2073,error,error,2073,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,":; Name: hail; Version: 0.2.93; Summary: Scalable library for exploring and analyzing genomic data.; Home-page: https://hail.is; Author: Hail Team; Author-email: hail@broadinstitute.org; License: UNKNOWN; Location: /Users/jacobbayer/opt/anaconda3/lib/python3.8/site-packages; Requires: dill, bokeh, scipy, azure-storage-blob, janus, parsimonious, botocore, google-cloud-storage, tabulate, Jinja2, python-json-logger, plotly, avro, azure-identity, PyJWT, orjson, tqdm, aiohttp-session, google-auth, nest-asyncio, uvloop, humanize, hurry.filesize, decorator, requests, Deprecated, aiohttp, asyncinit, numpy, pyspark, sortedcontainers, boto3, pandas. -----------------------------------------------------------------------------. Importing hail via the IPython console in Spyder causes the following error:. Python 3.8.12 (default, Oct 12 2021, 06:23:56) ; IPython 8.2.0 -- An enhanced Interactive Python. In [1]: `import hail`. > [SpyderKernelApp] ERROR | Exception in message handler:; > Traceback (most recent call last):; > File ""/Users/jacobbayer/opt/anaconda3/lib/python3.8/site-packages/spyder_kernels/comms/frontendcomm.py"", line 164, in poll_one; > asyncio.run(handler(out_stream, ident, msg)); > File ""/Users/jacobbayer/opt/anaconda3/lib/python3.8/site-packages/nest_asyncio.py"", line 36, in run; > task = asyncio.ensure_future(main); > File ""/Users/jacobbayer/opt/anaconda3/lib/python3.8/asyncio/tasks.py"", line 684, in ensure_future; > raise TypeError('An asyncio.Future, a coroutine or an awaitable is '; > TypeError: An asyncio.Future, a coroutine or an awaitable is required; > [SpyderKernelApp] ERROR | Exception in message handler:; > Traceback (most recent call last):; > File ""/Users/jacobbayer/opt/anaconda3/lib/python3.8/site-packages/spyder_kernels/comms/frontendcomm.py"", line 164, in poll_one; > asyncio.run(handler(out_stream, ident, msg)); > File ""/Users/jacobbayer/opt/anaconda3/lib/python3.8/site-packages/nest_asyncio.py"", line 36, in run; > task = asyncio.ensure_future(mai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11758:1251,ERROR,ERROR,1251,https://hail.is,https://github.com/hail-is/hail/issues/11758,1,['ERROR'],['ERROR']
Availability,":; java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.methods.Nirvana$.annotate(Nirvana.scala:361); at is.hail.methods.Nirvana$.apply(Nirvana.scala:487); at is.hail.methods.Nirvana.apply(Nirvana.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.10-ceb85fc87544; Error summary: AssertionError: assertion failed. We also check the key of input file:; ; >>> vcfVds.describe(); ----------------------------------------; Global fields:; None; ----------------------------------------; Column fields:; 's': str; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'rsid': str; 'qual': float64; 'filters': set<str>; 'info': struct {; AC: array<int32>,; AF: array<float64>,; AN: int32,; BaseQRankSum: float64,; ClippingRankSum: float64,; DP: int32,; DS: bool,; FS: float64,; HaplotypeScore: float64,; InbreedingCoeff: float64,; MLEAC: array<int32>,; MLEAF: array<float64>,; MQ: float64,; MQ0: int32,; MQRankSum: float64,; QD: float64,; ReadPosRankSum: float64,; set: str; }; ----------------------------------------; Entry fields:; 'GT': call; 'AD': array<int32>; 'DP': int32; 'GQ': int32; 'PL': array<int32>; ----------------------------------------; Column key: ['s']; Row key: ['locus', 'alleles']; ----------------------------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5657:2008,Error,Error,2008,https://hail.is,https://github.com/hail-is/hail/issues/5657,1,['Error'],['Error']
Availability,":</p>; <ul>; <li>Downgrade slf4j to fix warning on console about missing slf4j provider</li>; <li>Allow <code>download</code> and <code>verify</code> extensions to be created on demand in custom tasks, so these tasks can be made compatible with Gradle's configuration cache (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/284"">#284</a>). Thanks to <a href=""https://github.com/liblit""><code>@liblit</code></a> for testing!</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; <li>Improve documentation</li>; <li>Add integration tests for Gradle 6.9.3 and 7.6</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a0374fc7c895ae53309ea351e989571204e0ea5f""><code>a0374fc</code></a> Bump up version number to 5.3.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/612f57a382b8640cc730dc5e75d1c809e3e772bd""><code>612f57a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/291"">#291</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/53af1049f5514afe58e884d487d7c57dae47759d""><code>53af104</code></a> Bump http-cache-semantics from 4.1.0 to 4.1.1 in /screencast</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/398c14c05c6448b380ac35c6095598299c5e23c5""><code>398c14c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/15cf7eecfbc17d2466143828b9b69494c6cb6f2b""><code>15cf7ee</code></a> Bump up version number to 5.3.1-SNAPSHOT</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e3c65ffcb49b9c5a33fde5f31fb63043dbf21134""><code>e3c65ff</code></a> Allow extensions to be created from tasks</li>; <li><a href=""https://githu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:1282,down,download-task,1282,https://hail.is,https://github.com/hail-is/hail/pull/12707,1,['down'],['download-task']
Availability,":[\""A\"",\""<NON_REF>\""]},\""includeStart\"":true,\""includeEnd\"":true},{\""start\"":{\""locus\"":{\""contig\"":\""chr20\"",\""position\"":17994753},\""alleles\"":[\""A\"",\""<NON_REF>\""]},\""end\"":{\""locus\"":{\""cont...""] ; !s20 = ToStream(%29) [False]; !s21 = StreamMap(!s20) { (%elt10) =>; SelectFields(%elt10) [; (partitionCounts distinctlyKeyed firstKey; lastKey)]; }; !37 = ToArray(!s21); !38 = WriteMetadata(!37) [""{\""name\"":\""TableSpecWriter\"",\""path\"":\""/tmp/foo.ht\"",\""typ\"":{\""rowType\"":\""Struct{locus:Locus(GRCh38),alleles:Array[String],data:Array[Struct{}]}\"",\""key\"":[\""locus\"",\""alleles\""],\""globalType\"":\""Struct{new_globals:Array[Struct{}]}\""},\""rowRelPath\"":\""rows\"",\""globalRelPath\"":\""globals\"",\""refRelPath\"":\""references\"",\""log\"":true}""]; !39 = Begin(!34, !36, !38); WriteMetadata(!39) [""{\""name\"":\""RelationalWriter\"",\""path\"":\""/tmp/foo.ht\"",\""overwrite\"":true,\""maybeRefs\"":{\""references\"":[\""GRCh38\""]}}""]. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:23); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:23); 	at is.hail.utils.package$.fatal(package.scala:89); 	at is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:17); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:29); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:205); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14245:15644,Error,ErrorHandling,15644,https://hail.is,https://github.com/hail-is/hail/issues/14245,1,['Error'],['ErrorHandling']
Availability,":arch_avx2::uint64<4>; T = simdpp::arch_avx2::int64<4>]; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:114:36: required from simdpp::arch_avx2::uint64<4>& simdpp::arch_avx2::uint64<4>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int64<4>]; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:107:73: required from simdpp::arch_avx2::uint64<4>::uint64(const simdpp::arch_avx2::int64<4, E>&) [with E = void]; libsimdpp-2.0-rc2/simdpp/core/combine.h:79:49: required from simdpp::arch_avx2::int64<(N * 2)> simdpp::arch_avx2::combine(const simdpp::arch_avx2::int64<N, E>&, const simdpp::arch_avx2::int64<N, E2>&) [with unsigned int N = 4; E1 = void; E2 = void]; libsimdpp-2.0-rc2/simdpp/detail/insn/to_int64.h:70:26: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint64<4> with private member simdpp::arch_avx2::uint64<4>::d_ from an array of const class simdpp::arch_avx2::int64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:27,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:91:7: note: class simdpp::arch_avx2::uint64<4> declared here; class uint64<4, void> : public any_int64<4, uint64<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int64<8>; T = simdpp::arch_avx2::uint64<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:134003,error,error,134003,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,":offset 23933331019603: error while parsing line; chrY	113	.	GG	G,*,AG,CG	596	PASS	AC=2,4,6,1;AF=1.23e-03,5.550e-05,4.44e-05,2.00e-04;AN=265;AS_AltDP=10,0,3,10;AS_BaseQRankSum=0.000,.,0.100,0.500;AS_FS=7.777,.,2.144,8.001;AS_MQ=55.75,.,38.98,40.20;AS_MQRankSum=0.200,.,-1.050,-0.500;AS_QD=0.50,0.00,0.25,0.52;AS_ReadPosRankSum=-0.200,.,0.500,-0.220;AS_SOR=2.300,.,1.600,3.000;BaseQRankSum=0.200;DP=600000;ExcessHet=0.0477;FS=0.900;MQ=55.02;MQRankSum=-0.553;QD=1.00;ReadPosRankSum=-0.162;SOR=0.792;VarDP=650	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0/0:.:21:30	0/0:.:300:20	0/0:.:30:72	0/0:.:31:98	0|1:29,3,0,0,0:33:78:0|1:113_GG_G:78,0,1100,140,1400,1200,172,1600,1200,1000,175,1100,1100,1300,1000:113:19,19,2,1	0/0:.:20:19	0/0:.:19:20	0/0:.:25:50		0|1:90,2,0,0,0:30:40:0|1:113_GG_G:40,0,600,70,650,600,90,640,900,300,60,800,400,900,900:113:2,14,2,0	0/0:.:20:10	0/0:.:9:20	0/0:.:30:40	0/0:.:37:38		0/4:5,0,0,0,1:5:33:.:.:30,40,400,50,220,220,38,270,270,270,0,200,200,200,202:.:5,0,0,1	. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:22); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:22); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1921); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7$adapted(LoadVCF.scala:1909); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:515); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at __C678stream_Let.apply(Emit.scala); 	at is.hail.expr.ir.CompileIterator$$anon$2.step(Compile.scala:302); 	at is.hail.expr.ir.CompileIterator$LongIteratorWrapper.hasNext(Compile.scala:155); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:7264,Error,ErrorHandling,7264,https://hail.is,https://github.com/hail-is/hail/issues/14102,2,['Error'],['ErrorHandling']
Availability,":run(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint32<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint32<8>]; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:115:37: required from simdpp::arch_avx2::uint16<16>& simdpp::arch_avx2::uint16<16>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint32<8, simdpp::arch_avx2::expr_bit_and<simdpp::arch_avx2::uint32<8, simdpp::arch_avx2::uint16<16> >, simdpp::arch_avx2::uint32<8, simdpp::arch_avx2::uint32<8> > > >]; libsimdpp-2.0-rc2/simdpp/detail/insn/unzip_lo.h:107:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint16<16> with private member simdpp::arch_avx2::uint16<16>::d_ from an array of const class simdpp::arch_avx2::uint32<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:22,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:92:7: note: class simdpp::arch_avx2::uint16<16> declared here; class uint16<16, void> : public any_int16<16, uint16<16,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint16<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:34569,error,error,34569,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,":uint16<32>]; libsimdpp-2.0-rc2/simdpp/types/int16.h:50:35: required from simdpp::arch_avx2::int16<N>& simdpp::arch_avx2::int16<N>::operator=(const simdpp::arch_avx2::any_vec<(N * 2), V>&) [with V = simdpp::arch_avx2::uint16<32>; unsigned int N = 32]; libsimdpp-2.0-rc2/simdpp/types/int16.h:43:73: required from simdpp::arch_avx2::int16<N>::int16(const simdpp::arch_avx2::uint16<N, E>&) [with E = void; unsigned int N = 32]; libsimdpp-2.0-rc2/simdpp/core/combine.h:66:69: required from simdpp::arch_avx2::int16<(N * 2)> simdpp::arch_avx2::combine(const simdpp::arch_avx2::int16<N, E>&, const simdpp::arch_avx2::int16<N, E2>&) [with unsigned int N = 16; E1 = void; E2 = void]; libsimdpp-2.0-rc2/simdpp/detail/insn/to_int16.h:125:26: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int16<32> with private member simdpp::arch_avx2::int16<32>::d_ from an array of const class simdpp::arch_avx2::uint16<32>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:36,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16.h:31:7: note: class simdpp::arch_avx2::int16<32> declared here; class int16<N, void> : public any_int16<N, int16<N,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::uint16<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:138495,error,error,138495,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,; 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$2$adapted(SparkBackend.scala:612); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:657); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:657); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:62); 	at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$1(SparkBackend.scala:347); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$1(SparkBackend.scala:612); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$1$adapted(SparkBackend.scala:611); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59); 	at is.hail.backend.spark.SparkBackend.pyAddLiftover(SparkBackend.scala:611); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182); 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106); 	at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.126-ee77707f4fab; Error summary: HailException: Chain file 'grch37_to_grch38.over.chain.gz' does not exist.; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13993:5648,Error,Error,5648,https://hail.is,https://github.com/hail-is/hail/issues/13993,1,['Error'],['Error']
Availability,; 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:332); 	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:330); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-74bf1eb; Error summary: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:14543,Error,Error,14543,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['Error'],['Error']
Availability,"; 'locus': locus<GRCh37>; 'alleles': array<str>; 'rsid': str; 'varid': str; ----------------------------------------; Entry fields:; 'GT': call; 'GP': array<float64>; 'dosage': float64; ----------------------------------------; Column key: ['s']; Row key: ['locus', 'alleles']; ----------------------------------------; [Stage 0:> (0 + 16) / 292]Traceback (most recent call last):; File ""/restricted/projectnb/ukbiobank/ad/analysis/ukb.v3/bgen_count.py"", line 13, in <module>; print(""Count:"",mt.count()); File ""/restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 2131, in count; File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 210, in deco; hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: Task 7 in stage 0.0 failed 4 times, most recent failure: Lost task 7.3 in stage 0.0 (TID 86, scc-q16.scc.bu.edu, executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Slave lost; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 0.0 failed 4 times, most recent failure: Lost task 7.3 in stage 0.0 (TID 86, scc-q16.scc.bu.edu, executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Slave lost; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuff",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572:7734,failure,failure,7734,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572,1,['failure'],['failure']
Availability,"; 's': str; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'rsid': str; 'varid': str; ----------------------------------------; Entry fields:; 'GT': call; 'GP': array<float64>; 'dosage': float64; ----------------------------------------; Column key: ['s']; Row key: ['locus', 'alleles']; ----------------------------------------; [Stage 0:> (0 + 16) / 292]Traceback (most recent call last):; File ""/restricted/projectnb/ukbiobank/ad/analysis/ukb.v3/bgen_count.py"", line 13, in <module>; print(""Count:"",mt.count()); File ""/restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 2131, in count; File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 210, in deco; hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: Task 7 in stage 0.0 failed 4 times, most recent failure: Lost task 7.3 in stage 0.0 (TID 86, scc-q16.scc.bu.edu, executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Slave lost; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 0.0 failed 4 times, most recent failure: Lost task 7.3 in stage 0.0 (TID 86, scc-q16.scc.bu.edu, executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Slave lost; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.sc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572:7677,failure,failure,7677,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572,1,['failure'],['failure']
Availability,"; - hail/python/dev/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed.; jupyter 1.0.0 requires qtconsole, which is not installed.; curlylint 0.13.1 requires pathspec, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed.; astroid 2.15.8 requires lazy-object-proxy, which is not installed.; argon2-cffi-bindings 21.2.0 requires cffi, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **624/1000** <br/> **Why?** Has a fix available, CVSS 8.2 | Arbitrary Code Execution <br/>[SNYK-PYTHON-IPYTHON-2348630](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-2348630) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | No Known Exploit ;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:1357,avail,available,1357,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['avail'],['available']
Availability,"; 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:8038,error,error,8038,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['error'],['error']
Availability,"; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 199 'Hail version: %s\n'; --> 200 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 201 except pyspark.sql.utils.CapturedException as e:; 202 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: RuntimeException: Cannot find row in Map(). Java stack trace:; is.hail.utils.HailException: Error while typechecking IR:; (MakeStruct; (titv; (ApplyBinaryPrimOp FloatingPointDivide; (GetField n_ti; (Ref Struct{rank_id:String,snv:Boolean,bi_allelic:Boolean,singleton:Boolean,bin:Int32,min_score:Float64,max_score:Float64,n_ti:Int64,n_tv:Int64,model:String} row)); (GetField n_tv; (Ref Struct{rank_id:String,snv:Boolean,bi_allelic:Boolean,singleton:Boolean,bin:Int32,min_score:Float64,max_score:Float64,n_ti:Int64,n_tv:Int64,model:String} row)))); (min_score; (GetField `0`; (In Struct{`0`:Float64,`1`:Float64} 0))); (max_score; (GetField `1`; (In Struct{`0`:Float64,`1`:Float64} 0)))); 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:11); 	at is.hail.expr.ir.Emit$.emit(Emit.scala:42); 	at is.hail.expr.ir.Emit$.apply(Emit.scala:28); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:51); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:31); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:74); 	at is.hail.expr.ir.TableKeyByAndAggregate.execute(TableIR.scala:843); 	at is.hail.table.Table.value$lzycompute(Table.scala:215); 	at is.hail.table.Table.value(Table.scala:213); 	at is.hail.table.Table.x$5$lzycompute(Table.scala:218); 	at is.hail.table.Table.x$5(Table.scala:218); 	at is.hail.table.Table.rvd$lzycompute(Table.scala:218); 	at is.hail.table.Table.rvd(Table.scala:218); 	at is.hail.table.Table.take(Table.scala:649); 	at is.hail.table.Table.showString(Table.scala:685); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.in",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4110:3268,Error,ErrorHandling,3268,https://hail.is,https://github.com/hail-is/hail/issues/4110,1,['Error'],['ErrorHandling']
Availability,"; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@75771d8a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@56931c6{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@7d4d6f14{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@23f9d06d{/stages,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cdf8858{/stages/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3418c91b{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6e2585c5{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2063dbf5{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environment,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@57318cba{/environment/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5c9c4006{/executors,",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:5180,AVAIL,AVAILABLE,5180,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['AVAIL'],['AVAILABLE']
Availability,"; 930 | amazon-ebs: Collecting google-auth==1.27.0; 931 | amazon-ebs: Downloading google_auth-1.27.0-py2.py3-none-any.whl (135 kB); 932 | amazon-ebs:  135.6/135.6 kB 30.6 MB/s eta 0:00:00; 933 | amazon-ebs: Collecting google-cloud-storage==1.25.*; 934 | amazon-ebs: Downloading google_cloud_storage-1.25.0-py2.py3-none-any.whl (73 kB); 935 | amazon-ebs:  73.4/73.4 kB 22.1 MB/s eta 0:00:00; 936 | amazon-ebs: Collecting humanize==1.0.0; 937 | amazon-ebs: Downloading humanize-1.0.0-py2.py3-none-any.whl (51 kB); 938 | amazon-ebs:  51.9/51.9 kB 14.6 MB/s eta 0:00:00; 939 | amazon-ebs: Collecting hurry.filesize==0.9; 940 | amazon-ebs: Downloading hurry.filesize-0.9.tar.gz (2.8 kB); 941 | amazon-ebs: Preparing metadata (setup.py): started; 942 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 943 | amazon-ebs: Collecting janus<1.1,>=0.6; 944 | amazon-ebs: Downloading janus-1.0.0-py3-none-any.whl (6.9 kB); 945 | amazon-ebs: Requirement already satisfied: Jinja2==3.0.3 in /usr/local/lib/python3.7/site-packages (3.0.3); 946 | amazon-ebs: Collecting nest_asyncio==1.5.4; 947 | amazon-ebs: Downloading nest_asyncio-1.5.4-py3-none-any.whl (5.1 kB); 948 | amazon-ebs: Requirement already satisfied: numpy<2 in /usr/local/lib64/python3.7/site-packages (1.21.6); 949 | amazon-ebs: Collecting orjson==3.6.4; 950 | amazon-ebs: Downloading orjson-3.6.4-cp37-cp37m-manylinux_2_24_x86_64.whl (249 kB); 951 | amazon-ebs:  249.9/249.9 kB 45.1 MB/s eta 0:00:00; 952 | amazon-ebs: Requirement already satisfied: pandas<1.5.0,>=1.3.0 in /usr/local/lib64/python3.7/site-packages (1.3.5); 953 | amazon-ebs: Collecting parsimonious<0.9; 954 | amazon-ebs: Downloading parsimonious-0.8.1.tar.gz (45 kB); 955 | amazon-ebs:  45.1/45.1 kB 10.2 MB/s eta 0:00:00; 956 | amazon-ebs: Preparing metadata (s",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:5332,Down,Downloading,5332,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,"; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/async-timeout/blob/master/CHANGES.rst"">async-timeout's changelog</a>.</em></p>; <blockquote>; <h1>4.0.2 (2021-12-20)</h1>; <h2>Misc</h2>; <ul>; <li><code>[#259](https://github.com/aio-libs/async-timeout/issues/259) &lt;https://github.com/aio-libs/async-timeout/issues/259&gt;</code><em>, <code>[#274](https://github.com/aio-libs/async-timeout/issues/274) &lt;https://github.com/aio-libs/async-timeout/issues/274&gt;</code></em></li>; </ul>; <h1>4.0.1 (2121-11-10)</h1>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h1>4.0.0 (2021-11-01)</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Dropped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:2959,avail,available,2959,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['avail'],['available']
Availability,"; </ul>; <h2>5.0.4</h2>; <p>Bug fixes:</p>; <ul>; <li>Fix deadlock in <code>DownloadExtension</code> if <code>max-workers</code> equals 1 (thanks to <a href=""https://github.com/beatbrot""><code>@beatbrot</code></a> for spotting this, see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/205"">#205</a>)</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1b5d69760d19cb7f88cbc837ee46456c494c0696""><code>1b5d697</code></a> Bump up version number to 5.2.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/7d6de83037ca41cd2f2f31830b43e43720e45b3a""><code>7d6de83</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1da8f078e22412475b694ce07b890148b8a5e4fc""><code>1da8f07</code></a> Add comment</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/9703f764df56c52626f7d6f44bca8b1d51312389""><code>9703f76</code></a> Use pooling connection manager instead of basic one</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/306172e4c6532e185c8a6a9998bca7d22d2d0c63""><code>306172e</code></a> Bump up version number to 5.2.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b9df0c0daa080450772c365f16a9406fe0ca607a""><code>b9df0c0</code></a> Document eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/05a4433770f7020ff845add9348bdc12c82793dd""><code>05a4433</code></a> Add eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/09d1eca91afbf21ace3672be24c68d9028ee1e33""><code>09d1eca</code></a> Document runAsync method</li>; <li><a href=""https://github.com/michel-kraemer/gradle-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:3396,down,download-task,3396,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['down'],['download-task']
Availability,"; <ipython-input-17-671d2e9c22c8> in <module>(); 1 #ht = hl.import_table('gs://gnomad/annotations/hail-0.2/ht/genomes/score_rankings/gnomad.sites.RF.newStats24.txt.bgz', types={'chrom': hl.tstr}, impute=True, min_partitions=100).cache(); ----> 2 ht.export('gs://gnomad-tmp/genomes_rf.txt.bgz', parallel=True). /home/hail/hail.zip/hail/table.py in export(self, output, types_file, header, parallel); 994 """"""; 995 ; --> 996 self._jt.export(output, types_file, header, Env.hail().utils.ExportType.getExportType(parallel)); 997 ; 998 def group_by(self, *exprs, **named_exprs) -> 'GroupedTable':. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 186 import pyspark; 187 try:; --> 188 return f(*args, **kwargs); 189 except py4j.protocol.Py4JJavaError as e:; 190 s = e.java_exception.toString(). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 321 raise Py4JError(; 322 ""An error occurred while calling {0}{1}{2}. Trace:\n{3}\n"".; --> 323 format(target_id, ""."", name, value)); 324 else:; 325 raise Py4JError(. Py4JError: An error occurred while calling z:is.hail.utils.ExportType.getExportType. Trace:; py4j.Py4JException: Method getExportType([class java.lang.Boolean]) does not exist; 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:339); 	at py4j.Gateway.invoke(Gateway.java:274); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4033:2016,error,error,2016,https://hail.is,https://github.com/hail-is/hail/issues/4033,2,['error'],['error']
Availability,"; <li>Improve documentation</li>; <li>Add integration tests for Gradle 6.9.3 and 7.6</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a0374fc7c895ae53309ea351e989571204e0ea5f""><code>a0374fc</code></a> Bump up version number to 5.3.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/612f57a382b8640cc730dc5e75d1c809e3e772bd""><code>612f57a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/291"">#291</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/53af1049f5514afe58e884d487d7c57dae47759d""><code>53af104</code></a> Bump http-cache-semantics from 4.1.0 to 4.1.1 in /screencast</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/398c14c05c6448b380ac35c6095598299c5e23c5""><code>398c14c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/15cf7eecfbc17d2466143828b9b69494c6cb6f2b""><code>15cf7ee</code></a> Bump up version number to 5.3.1-SNAPSHOT</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e3c65ffcb49b9c5a33fde5f31fb63043dbf21134""><code>e3c65ff</code></a> Allow extensions to be created from tasks</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/34e2dd41477f18b1ae3d6d5a71dca5449d6cd1e0""><code>34e2dd4</code></a> Downgrade slf4j to fix warning on console about missing slf4j provider</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b3fa29f9ffb4d4544e13ef84601e371fb2778ddf""><code>b3fa29f</code></a> Revert &quot;Update Apache HttpClient to 5.2.1&quot;</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/01f05e046be0dca18f506723c79e88f208336e71""><code>01f05e0</code></a> Add",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:1820,down,download-task,1820,https://hail.is,https://github.com/hail-is/hail/pull/12707,1,['down'],['download-task']
Availability,"; <li>winbuild: Refactor dependency versions into constants <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7843"">#7843</a> [<a href=""https://github.com/hugovk""><code>@hugovk</code></a>]</li>; <li>Build macOS arm64 wheels natively <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7852"">#7852</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Fixed typo <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7855"">#7855</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Open 16-bit grayscale PNGs as I;16 <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7849"">#7849</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Handle truncated chunks at the end of PNG images <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7709"">#7709</a> [<a href=""https://github.com/lajiyuan""><code>@lajiyuan</code></a>]</li>; <li>Match mask size to pasted image size in GifImagePlugin <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7779"">#7779</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Changed SupportsGetMesh protocol to be public <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7841"">#7841</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Release GIL while calling <code>WebPAnimDecoderGetNext</code> <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7782"">#7782</a> [<a href=""https://github.com/evanmiller""><code>@evanmiller</code></a>]</li>; <li>Fixed reading FLI/FLC images with a prefix chunk <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7804"">#7804</a> [<a href=""https://github.com/twolife""><code>@twolife</code></a>]</li>; <li>Updated package name for Tidelift <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7810"">#7810</a> [<a href=""https://github.com/radarhere""><code",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14439:8626,mask,mask,8626,https://hail.is,https://github.com/hail-is/hail/pull/14439,3,['mask'],['mask']
Availability,"; <ul>; <li>Use pooling connection manager of Apache HttpClient instead of basic one. The basic one is not meant to be used by multiple threads. This fixes an issue that could cause an <code>IllegalStateException</code> with the message <code>Connection is still allocated</code>. Thanks to <a href=""https://github.com/dmarks2""><code>@dmarks2</code></a> for spotting this.</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>eachFile</code> method that adds an action to be applied to each source URL before it is downloaded. The action can be used to modify the filename of the target file.</li>; <li>Add <code>runAsync</code> method to download extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted --",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:2076,down,download,2076,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download']
Availability,"; <ul>; <li>Use pooling connection manager of Apache HttpClient instead of basic one. The basic one is not meant to be used by multiple threads. This fixes an issue that could cause an <code>IllegalStateException</code> with the message <code>Connection is still allocated</code>. Thanks to <a href=""https://github.com/dmarks2""><code>@dmarks2</code></a> for spotting this.</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>eachFile</code> method that adds an action to be applied to each source URL before it is downloaded. The action can be used to modify the filename of the target file.</li>; <li>Add <code>runAsync</code> method to download extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.5</h2>; <p>Maint",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:1357,down,download,1357,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['down'],['download']
Availability,"; File ""/restricted/projectnb/genpro/github/hail/python/hail/typecheck/check.py"", line 490, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/restricted/projectnb/genpro/github/hail/python/hail/methods/qc.py"", line 91, in sample_qc; return MatrixTable(Env.hail().methods.SampleQC.apply(require_biallelic(dataset, 'sample_qc')._jvds, name)); File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: invalid allele ""<DEL>"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 3.0 failed 4 times, most recent failure: Lost task 2.3 in stage 3.0 (TID 160, scc-q01.scc.bu.edu, executor 4): is.hail.utils.HailException: invalid allele ""<DEL>""; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:29); at is.hail.methods.SampleQCCombiner$.alleleIndices(SampleQC.scala:44); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:178); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:175); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:175); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:170); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsR",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:1718,Error,ErrorHandling,1718,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['Error'],['ErrorHandling']
Availability,; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc \; WHEEL_FOR_AZURE=x \; WEBSITE_TAR=/path/to/www.tar.gz \; hail/scripts/release.sh. +++ dirname -- hail/scripts/release.sh; ++ cd -- hail/scripts; ++ pwd; + SCRIPT_DIR=/Users/dking/projects/hail/hail/scripts; + arguments='HAIL_PIP_VERSION HAIL_VERSION GIT_VERSION REMOTE WHEEL GITHUB_OAUTH_HEADER_FILE HAIL_GENETICS_HAIL_IMAGE HAIL_GENETICS_HAIL_IMAGE_PY_3_10 HAIL_GENETICS_HAIL_IMAGE_PY_3_11 HAIL_GENETICS_HAILTOP_IMAGE HAIL_GENETICS_VEP_GRCH37_85_IMAGE HAIL_GENETICS_VEP_GRCH38_95_IMAGE WHEEL_FOR_AZURE WEBSITE_TAR'; + for varname in '$arguments'; + '[' -z 0.2.123 ']'; + echo HAIL_PIP_VERSION=0.2.123; HAIL_PIP_VERSION=0.2.123; + for varname in '$arguments'; + '[' -z 0.2.123-abcdef123 ']'; + echo HAIL_VERSION=0.2.123-abcdef123; HAIL_VERSION=0.2.123-abcdef123; + for varname in '$arguments'; + '[' -z abcdef123 ']'; + echo GIT_VERSION=abcdef123; GIT_VERSION=abcdef123; + for varname in '$arguments'; + '[' -z origin ']'; + echo REMOTE=origin; REMOTE=origin; + for varname in '$arguments'; + '[' -z /path/to/the.whl ']'; + echo WHEEL=/path/to/the.whl; WHEEL=/path/to/the.whl; + for varname in '$arguments'; + '[' -z /path/to/github/oauth/header/file ']'; + echo GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://u,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:7344,echo,echo,7344,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,2,['echo'],['echo']
Availability,"; May 16 14:17:07 mw116-m python[8309]: File ""/opt/conda/miniconda3/lib/python3.10/site-packages/nbconvert/exporters/__init__.py"", line 3, in <module>; May 16 14:17:07 mw116-m python[8309]: from .html import HTMLExporter; May 16 14:17:07 mw116-m python[8309]: File ""/opt/conda/miniconda3/lib/python3.10/site-packages/nbconvert/exporters/html.py"", line 12, in <module>; May 16 14:17:07 mw116-m python[8309]: from jinja2 import contextfilter; May 16 14:17:07 mw116-m python[8309]: ImportError: cannot import name 'contextfilter' from 'jinja2' (/opt/conda/miniconda3/lib/python3.10/site-packages/jinja2/__init__.py); May 16 14:17:07 mw116-m python[8309]: [D 14:17:07.045 NotebookApp] Using contents: services/contents; May 16 14:17:07 mw116-m python[8309]: [D 14:17:07.045 NotebookApp] Using contents: services/contents; May 16 14:17:07 mw116-m python[8309]: [E 14:17:07.046 NotebookApp] {; May 16 14:17:07 mw116-m python[8309]: ""Host"": ""localhost:8123"",; May 16 14:17:07 mw116-m python[8309]: ""Connection"": ""keep-alive"",; May 16 14:17:07 mw116-m python[8309]: ""Sec-Ch-Ua"": ""\""Google Chrome\"";v=\""113\"", \""Chromium\"";v=\""113\"", \""Not-A.Brand\"";v=\""24\"""",; May 16 14:17:07 mw116-m python[8309]: ""Sec-Ch-Ua-Mobile"": ""?0"",; May 16 14:17:07 mw116-m python[8309]: ""Sec-Ch-Ua-Platform"": ""\""macOS\"""",; May 16 14:17:07 mw116-m python[8309]: ""Upgrade-Insecure-Requests"": ""1"",; May 16 14:17:07 mw116-m python[8309]: ""User-Agent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36"",; May 16 14:17:07 mw116-m python[8309]: ""Accept"": ""text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7"",; May 16 14:17:07 mw116-m python[8309]: ""Sec-Fetch-Site"": ""same-origin"",; May 16 14:17:07 mw116-m python[8309]: ""Sec-Fetch-Mode"": ""navigate"",; May 16 14:17:07 mw116-m python[8309]: ""Sec-Fetch-User"": ""?1"",; May 16 14:17:07 mw116-m python[8309]: ""Sec-Fetch-Dest"": ""document"",; M",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13059:4456,alive,alive,4456,https://hail.is,https://github.com/hail-is/hail/issues/13059,1,['alive'],['alive']
Availability,"; Resource: ""rbac.authorization.k8s.io/v1, Resource=rolebindings"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=RoleBinding""; Name: ""batch-pods-admin-binding"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""RoleBinding"" ""metadata"":map[""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""] ""name"":""batch-pods-admin-binding"" ""namespace"":""batch-pods""] ""roleRef"":map[""apiGroup"":"""" ""kind"":""Role"" ""name"":""batch-pods-admin""] ""subjects"":[map[""kind"":""ServiceAccount"" ""name"":""batch-svc"" ""namespace"":""default""]]]}; from server for: ""deployment.yaml"": rolebindings.rbac.authorization.k8s.io ""batch-pods-admin-binding"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get rolebindings.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""apps/v1beta2, Resource=deployments"", GroupVersionKind: ""apps/v1beta2, Kind=Deployment""; Name: ""batch-deployment"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""apps/v1beta2"" ""kind"":""Deployment"" ""metadata"":map[""labels"":map[""hail.is/sha"":""1c6dbf20333a"" ""app"":""batch""] ""name"":""batch-deployment"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""spec"":map[""replicas"":'\x01' ""selector"":map[""matchLabels"":map[""app"":""batch""]] ""template"":map[""metadata"":map[""labels"":map[""app"":""batch"" ""hail.is/sha"":""1c6dbf20333a""]] ""spec"":map[""containers"":[map[""image"":""gcr.io/broad-ctsa/batch:4b4139c73fe9be3bee6c2895aa74059e157eb861d2bdac7d2304ba44b5421f88"" ""name"":""batch"" ""ports"":[map[""containerPort"":'\u1388']]]] ""serviceAccountName"":""batch-svc""]]]]}; from server for: ""deployment.yaml"": deployments.apps ""batch-deployment"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get deployments.apps in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609:3196,Error,Error,3196,https://hail.is,https://github.com/hail-is/hail/issues/4609,2,"['Error', 'error']","['Error', 'error']"
Availability,"; ```sh; $ pyspark; Python 3.9.18 (main, Oct 25 2023, 05:26:35) ; [GCC 7.3.1 20180712 (Red Hat 7.3.1-17)] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populati",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:2053,avail,available,2053,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949,1,['avail'],['available']
Availability,"; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services-and-pods; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services #this was causing the error, and of course the create-services role is superseded by the the create-services-and-pods role; apiGroup: """"; ---; ```. After:; ```yaml; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: create-services-and-pods; rules:; - apiGroups: [""""]; resources: [""services""]; verbs: [""*""]; - apiGroups: [""""]; resources: [""pods""]; verbs: [""*""]; ---; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services-and-pods; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services-and-pods; apiGroup: """"; ---; ```. ### Results of test runs. Before:. ```sh; kubectl apply -f k8s-config.yaml; ERROR: (gcloud.compute.addresses.describe) Could not fetch resource:; - Required 'compute.addresses.get' permission for 'projects/hail-vdc-staging/regions/us-central1/addresses/site'. namespace/batch-pods unchanged; ...; The RoleBinding ""notebook-create-services-and-pods"" is invalid: roleRef: Invalid value: rbac.RoleRef{APIGroup:""rbac.authorization.k8s.io"", Kind:""Role"", Name:""create-services""}: cannot change roleRef; make: *** [k8s-config] Error 1; ```. After:; ```sh; ERROR: (gcloud.compute.addresses.describe) Could not fetch resource:; - Required 'compute.addresses.get' permission for 'projects/hail-vdc-staging/regions/us-central1/addresses/site'. ...; role.rbac.authorization.k8s.io/create-services-and-pods unchanged; rolebinding.rbac.authorization.k8s.io/notebook-create-services-and-pods configured; role.rbac.authorization.k8s.io/read-get-user-secret unchanged; rolebinding.rbac.authorization.k8s.io/notebook-read-get-users-secret configured; ```. I think the error just reflects my not havi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5746:2409,ERROR,ERROR,2409,https://hail.is,https://github.com/hail-is/hail/pull/5746,1,['ERROR'],['ERROR']
Availability,"; apiVersion: v1; kind: Pod; metadata:; creationTimestamp: ""2019-04-02T19:50:21Z""; generateName: notebook2-worker-; labels:; app: notebook2-worker; hail.is/notebook2-instance: f4dc8213468f4799a3c7f94cb6969309; jupyter_token: 484b71e2c12d42c79b169b1991602d45; name: a_notebook; user_id: e7e7b9c420f0b0ff503ab6711355f27748522a8a37d9d22b2c8e0af4; uuid: 84873cf540014e128cce18f5481fb682; name: notebook2-worker-d4snh; namespace: default; resourceVersion: ""41241284""; selfLink: /api/v1/namespaces/default/pods/notebook2-worker-d4snh; uid: 8cb3c1c2-5580-11e9-bcd4-42010a8000c9; spec:; containers:; - command:; - jupyter; - notebook; - --NotebookApp.token=484b71e2c12d42c79b169b1991602d45; - --NotebookApp.base_url=/instance/84873cf540014e128cce18f5481fb682/; - --ip; - 0.0.0.0; - --no-browser; image: gcr.io/hail-vdc/hail-jupyter:2c2281012d0b2171837e99fe50c8656395c7adafd93b3821af6c0a605ffaea1e; imagePullPolicy: IfNotPresent; name: default; ports:; - containerPort: 8888; protocol: TCP; readinessProbe:; failureThreshold: 3; httpGet:; path: /instance/84873cf540014e128cce18f5481fb682/login; port: 8888; scheme: HTTP; periodSeconds: 5; successThreshold: 1; timeoutSeconds: 1; resources:; requests:; cpu: ""1.601""; memory: 1.601G; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /gsa-key-secret-name; name: gsa-key-secret-name; readOnly: true; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: user-kmpnh-token-hbdd4; readOnly: true; dnsPolicy: ClusterFirst; nodeName: gke-vdc-non-preemptible-pool-0106a51b-l48l; restartPolicy: Always; schedulerName: default-scheduler; securityContext: {}; serviceAccount: user-kmpnh; serviceAccountName: user-kmpnh; terminationGracePeriodSeconds: 30; tolerations:; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: gsa-key-secret-nam",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5753#issuecomment-479174611:2326,failure,failureThreshold,2326,https://hail.is,https://github.com/hail-is/hail/pull/5753#issuecomment-479174611,1,['failure'],['failureThreshold']
Availability,"; at is.hail.annotations.Region$.scoped(Region.scala:18); at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:7); at is.hail.backend.Backend.execute(Backend.scala:86); at is.hail.backend.Backend.executeJSON(Backend.scala:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:282); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:238); at java.lang.Thread.run(Thread.java:745). org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 2 (runJob at SparkHadoopWriter.scala:78) has failed the maximum alloreamId=830947795015, chunkIndex=0}: java.nio.file.NoSuchFileException: /data03/hadoop/yarn/local/usercache/farrell/appcache/application_15657888296Exception.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) at sun.nio.fs.UnixException.rethrowAsIOExcee.Files.newByteChannel(Files.java:361) at java.nio.file.Files.newByteChannel(Files.java:407) at org.apache.spark.shuffle.IndexShuffleBlockResolvt org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61) at org.apache.spark.network.netty.NettyBloction.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamMt org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:101) at org.apache.spark.network.server.TransportractChannelHandlerContext.java:362) at io.netty.channel.Abst",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:16207,failure,failure,16207,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['failure'],['failure']
Availability,"; drwxr-xr-x 8 teamcity www-data 4096 Sep 7 18:55 ./; drwxr-xr-x 4 root root 4096 Sep 7 18:16 ../; drwxrwxr-x 6 teamcity teamcity 4096 Sep 7 18:33 .BuildServer/; drwxr-xr-x 5 teamcity www-data 4096 Sep 7 18:55 .gradle/; drwxr-xr-x 13 teamcity teamcity 4096 Aug 22 19:22 TeamCity/; drwxrwxr-x 13 teamcity teamcity 4096 Sep 7 18:54 TeamCityAgent1/; drwxrwxr-x 13 teamcity teamcity 4096 Sep 7 18:54 TeamCityAgent2/; drwxrwxr-x 13 teamcity teamcity 4096 Sep 7 18:54 TeamCityAgent3/; ```. ### Update the `init.d` scripts. #### `/etc/init.d/teamcity`. ```; #!/bin/sh; ### BEGIN INIT INFO; # Provides: teamcity ; # Required-Start: $local_fs $network; # Required-Stop: $local_fs; # Default-Start: 2 3 4 5; # Default-Stop: 0 1 6; # Short-Description: teamcity ; # Description: teamcity build server; ### END INIT INFO; # /etc/init.d/teamcity - startup script for teamcity; export TEAMCITY_DATA_PATH=""/home/teamcity/.BuildServer""; export TEAMCITY_SERVER_OPTS=-Djava.awt.headless=true # Configure TeamCity for use on a headless OS. case $1 in; start); start-stop-daemon --start -c teamcity --exec /home/teamcity/TeamCity/bin/teamcity-server.sh start; ;;. stop); start-stop-daemon --start -c teamcity --exec /home/teamcity/TeamCity/bin/teamcity-server.sh stop; ;;. esac. exit 0; ```. #### `/etc/init.d/teamcityAgents`. ```; #!/bin/bash; ### BEGIN INIT INFO; # Provides: teamcityAgents ; # Required-Start: $local_fs $network; # Required-Stop: $local_fs; # Default-Start: 2 3 4 5; # Default-Stop: 0 1 6; # Short-Description: teamcityAgents ; # Description: TeamCity build agents ; ### END INIT INFO. USER=""teamcity""; AGENTS=(TeamCityAgent1 TeamCityAgent2 TeamCityAgent3). case ""$1"" in; start); for agent in ${AGENTS[@]}; do; start-stop-daemon --start -c teamcity --exec /home/teamcity/$agent/bin/agent.sh start; done; ;;; stop); for agent in ${AGENTS[@]}; do; start-stop-daemon --start -c teamcity --exec /home/teamcity/$agent/bin/agent.sh stop; done; ;;; *); echo ""usage start/stop""; exit 1; ;;. esac. exit 0; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/675#issuecomment-245383790:2307,echo,echo,2307,https://hail.is,https://github.com/hail-is/hail/issues/675#issuecomment-245383790,1,['echo'],['echo']
Availability,"; }; ```; * Scripts are thing that can be run by typing, in shell `npm run`. Ex: `npm run dev`. ### Async, Await, Promises and callback (WIP); Javascript is async-first. This is most obvious in Node.js, which is the most popular library for server-side JS.; * [How event loop works](https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/); <img width=""765"" alt=""screen shot 2019-01-18 at 11 20 51 am"" src=""https://user-images.githubusercontent.com/5543229/51399094-1f999c00-1b13-11e9-8dfb-da8aa20807b0.png"">. * The event loop call stack: https://www.youtube.com/watch?v=8aGhZQkoFbQ. At a high level, a function that defines a callback will return immediately. The callback is pushed on to the event-loop stack, and on each tick, is checked to determine whether it has returned or not. Blocking operations within the callbacks will block the event loop. This is how CPU viruses, like blockchain manage to slow down web pages that are hijacked to include some mining script: hashing something 30 million times, takes a long time, and JS cannot do anything besides waiting for those operations to finish in a synchronous fashion. Luckily, asynchronous functions are the norm in the JS ecosystem, such that both in the browser, and nodejs, IO functions are (mostly?) asynchronous.; * For NodeJS: Transparently to the user, blocking operations (IO) are executed from kernel threads that Node maintains in the background, effectively making these operations non-blocking (until the thread pool is exhausted). Browsers and NodeJS use different event loops:. NodeJS: libuv event loop; * Node maintains a hidden worker thread pool (kernel threads) through which it issues sys calls, to avoid blocking the event loop. Web: depends on the underlying Javascript Engine; * Chromium: V8: libevent: https://stackoverflow.com/questions/25750884/are-there-significant-differences-between-the-chrome-browser-event-loop-versus-t; * Firefox: Spidermonkey: ?; * https://developer.mozilla.org/en-US/docs/Web/Jav",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:3814,down,down,3814,https://hail.is,https://github.com/hail-is/hail/pull/5162,1,['down'],['down']
Availability,"</a> Webgl problem in stream app with multiple glyphs</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/6669"">#6669</a> [component: bokehjs] BoxAnnotation does not appear to handle formal NumberSpec</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/8168"">#8168</a> [component: bokehjs] Strange behavior with BoxSelectTool when click+dragging on toolbar</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/8332"">#8332</a> [component: bokehjs] Autohide toolbar quirks</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/8346"">#8346</a> [component: bokehjs] update datasource cause error with webgl backend</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/8469"">#8469</a> Modifying a child element in a tab causes the whole tab to rerender</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/8531"">#8531</a> [component: bokehjs] Save tool in gridplot initiates multiple downloads</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/8684"">#8684</a> Allow at least partial alignment of fixed sized frames</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/9113"">#9113</a> [component: bokehjs] Empty group widgets don't size properly once populated</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/9133"">#9133</a> [BUG] Tabs ignore explicitly set dimensions</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/9208"">#9208</a> [component: bokehjs] [BUG] sizing_mode='stretch_width' makes plot too wide if scrollbar is showing</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/9320"">#9320</a> [BUG] Bokeh rendering performance</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/9448"">#9448</a> [component: bokehjs] [BUG] Google Fonts not loading on Glyph on standalone HTML until interacting wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12454:2641,down,downloads,2641,https://hail.is,https://github.com/hail-is/hail/pull/12454,1,['down'],['downloads']
Availability,"</b></summary>. ```; aiodocker 0.21.0 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;) <br/>[SNYK-PYTHON-AIOHTTP-6209406](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209406) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **718/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-6209407](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209407) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMzQ0ZjYzNy00MjQwLTQxNmEtYjE2Yi1kODhmYjc2YTUwZm",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14226:1441,avail,available,1441,https://hail.is,https://github.com/hail-is/hail/pull/14226,1,['avail'],['available']
Availability,"</details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/plotly/plotly.py/blob/master/CHANGELOG.md"">plotly's changelog</a>.</em></p>; <blockquote>; <h2>[5.10.0] - 2022-08-11</h2>; <h3>Updated</h3>; <ul>; <li>Updated Plotly.js to from version 2.12.1 to version 2.14.0. See the <a href=""https://github.com/plotly/plotly.js/blob/master/CHANGELOG.md#2140----2022-08-10"">plotly.js CHANGELOG</a> for more information. Notable changes include:; <ul>; <li>Add support for <code>sankey</code> links with arrows</li>; <li>Add <code>selections</code>, <code>newselection</code> and <code>activeselection</code> layout attributes to have persistent and editable selections over cartesian subplots</li>; <li>Add <code>unselected.line.color</code> and <code>unselected.line.opacity</code> options to <code>parcoords</code> trace</li>; <li>Display Plotly's new logo in the modebar</li>; </ul>; </li>; </ul>; <h2>[5.9.0] - 2022-06-23</h2>; <h3>Added</h3>; <ul>; <li><code>pattern_shape</code> options now available in <code>px.timeline()</code> <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3774"">#3774</a></li>; <li><code>facet_*</code> and <code>category_orders</code> now available in <code>px.pie()</code> <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3775"">#3775</a></li>; </ul>; <h3>Performance</h3>; <ul>; <li><code>px</code> methods no longer call <code>groupby</code> on the input dataframe when the result would be a single group, and no longer groups by a lambda, for significant speedups <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3765"">#3765</a> with thanks to <a href=""https://github.com/jvdd""><code>@jvdd</code></a></li>; </ul>; <h3>Updated</h3>; <ul>; <li>Allow non-string extras in <code>flaglist</code> attributes, to support upcoming changes to <code>ax.automargin</code> in plotly.js <a href=""https://github-redirect.dependabot.com/plotly/plotly.js/pull/6193"">plotly.js#6193</a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12113:2051,avail,available,2051,https://hail.is,https://github.com/hail-is/hail/pull/12113,1,['avail'],['available']
Availability,"</em></p>; <blockquote>; <h2>7.4.6</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.4.5...3394591f161be4a19f9e61c66ba510d7e29afd59"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Reconcile connection information <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/879"">#879</a> (<a href=""https://github.com/kevin-bates""><code>@kevin-bates</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2022-11-10&amp;to=2022-11-15&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ameeseeksmachine+updated%3A2022-11-10..2022-11-15&amp;type=Issues""><code>@meeseeksmachine</code></a></p>; <!-- raw HTML omitted -->; <h2>7.4.5</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.4.4...d27c8a497c6cbb1a232fbbe75cb1fd0f53faa9b0"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>[7.x] Handle Jupyter Core Warning <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/875"">#875</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Clean up 7.x workflows <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/865"">#865</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2022-10-25&amp;to=2022-11-10&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2022-10-25..2022-11-10&amp;type=Issues""><code>@blink1073</code></a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/f71daff259071f307",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12467:3304,Mainten,Maintenance,3304,https://hail.is,https://github.com/hail-is/hail/pull/12467,1,['Mainten'],['Maintenance']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html</a></p>; <h2>Elasticsearch Hadoop 8.1.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/a7873eb46985d849286ab89fa0a51f8b5374e02e""><code>a7873eb</code></a> Update index.adoc (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2000"">#2000</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2002"">#2002</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/9f44fe66d0ff82f18a13a38cae6abf3f72183a94""><code>9f44fe6</code></a> Bump to version 8.4.3</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/c9e3b114b98bb0e340555311c82e2d9f32c880b6""><code>c9e3b11</code></a> [DOCS] Add 8.4.2 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1998"">#1998",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:4259,Down,Downloads,4259,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['Down'],['Downloads']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html</a></p>; <h2>Elasticsearch Hadoop 8.1.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/a7873eb46985d849286ab89fa0a51f8b5374e02e""><code>a7873eb</code></a> Update index.adoc (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2000"">#2000</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2002"">#2002</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/9f44fe66d0ff82f18a13a38cae6abf3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:3933,Down,Downloads,3933,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['Down'],['Downloads']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html</a></p>; <h2>Elasticsearch Hadoop 8.1.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/a7873eb46985d849286ab89fa0a51f8b5374e02e""><code>a7873eb</code></a> U",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:3607,Down,Downloads,3607,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['Down'],['Downloads']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html</a></p>; <h2>Elasticsearch Hadoop 8.1.3</h2>; <p>Downloads: <a href=""https://elastic",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:3281,Down,Downloads,3281,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['Down'],['Downloads']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:2955,Down,Downloads,2955,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['Down'],['Downloads']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:2629,Down,Downloads,2629,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['Down'],['Downloads']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:2303,Down,Downloads,2303,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['Down'],['Downloads']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:1977,Down,Downloads,1977,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['Down'],['Downloads']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:1651,Down,Downloads,1651,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['Down'],['Downloads']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html</a></p>; <h2>Elasticsearch Hadoop 8.4.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:1325,Down,Downloads,1325,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['Down'],['Downloads']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/da4f3c3f209aea47d69c4faf90029a6933bd3a60""><code>da4f3c3</code></a> [DOCS] Add 8.5.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2045"">#2045</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2050"">#2050</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/79d592abdce1cd90845d153afab8b66069e2a172""><code>79d592a</code></a> [DOCS] Add 8.5.2 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2042"">#2042</a>) (<a href=""h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:1651,Down,Downloads,1651,https://hail.is,https://github.com/hail-is/hail/pull/12601,1,['Down'],['Downloads']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/e665cd918aa8d0ba7806b92e16881edb96180d48""><code>e665cd9</code></a> Update Spark to 3.2.3 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2056"">#2056</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2057"">#2057</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/07380b0e17c7d908d50d59fc69ac2953adfa5a0d""><code>07380b0</code></a> Use DRA repository for build-tools dependencies</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/77bce30bfefb39c39bd34a6f147b17f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:1977,Down,Downloads,1977,https://hail.is,https://github.com/hail-is/hail/pull/12623,1,['Down'],['Downloads']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/da4f3c3f209aea47d69c4faf90029a6933bd3a60""><code>da4f3c3</code></a> [DOCS] Add 8.5.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2045"">#2045</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elas",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:1325,Down,Downloads,1325,https://hail.is,https://github.com/hail-is/hail/pull/12601,1,['Down'],['Downloads']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/e665cd918aa8d0ba7806b92e16881edb96180d48""><code>e665cd9</code></a> Update Spark to 3.2.3 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2056"">#2056</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:1651,Down,Downloads,1651,https://hail.is,https://github.com/hail-is/hail/pull/12623,1,['Down'],['Downloads']
Availability,"</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.1.html</a></p>; <h2>Elasticsearch Hadoop 8.6.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:1325,Down,Downloads,1325,https://hail.is,https://github.com/hail-is/hail/pull/12623,1,['Down'],['Downloads']
Availability,"</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; sphinx 5.3.0 has requirement docutils<0.20,>=0.14, but you have docutils 0.20.1.; sphinx-rtd-theme 1.3.0 has requirement docutils<0.19, but you have docutils 0.20.1.; notebook 6.5.6 has requirement pyzmq<25,>=17, but you have pyzmq 25.1.2.; aiohttp-devtools 1.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14109:1238,avail,available,1238,https://hail.is,https://github.com/hail-is/hail/pull/14109,1,['avail'],['available']
Availability,"</li>; <li>1996_, [BSD]: add support for MidnightBSD. (patch by Saeed Rasooli)</li>; <li>1999_, [Linux]: <code>disk_partitions()</code>_: convert <code>/dev/root</code> device (an alias; used on some Linux distros) to real root device path.</li>; <li>2005_: <code>PSUTIL_DEBUG</code> mode now prints file name and line number of the debug; messages coming from C extension modules.</li>; <li>2042_: rewrite HISTORY.rst to use hyperlinks pointing to psutil API doc.</li>; </ul>; <p><strong>Bug fixes</strong></p>; <ul>; <li>1456_, [macOS], <strong>[critical]</strong>: <code>cpu_freq()</code>_ <code>min</code> and <code>max</code> are set to; 0 if can't be determined (instead of crashing).</li>; <li>1512_, [macOS]: sometimes <code>Process.connections()</code>_ will crash with; <code>EOPNOTSUPP</code> for one connection; this is now ignored.</li>; <li>1598_, [Windows]: <code>disk_partitions()</code>_ only returns mountpoints on drives; where it first finds one.</li>; <li>1874_, [SunOS]: swap output error due to incorrect range.</li>; <li>1892_, [macOS]: <code>cpu_freq()</code>_ broken on Apple M1.</li>; <li>1901_, [macOS]: different functions, especially <code>Process.open_files()</code>_ and; <code>Process.connections()</code><em>, could randomly raise <code>AccessDenied</code></em> because the; internal buffer of <code>proc_pidinfo(PROC_PIDLISTFDS)</code> syscall was not big enough.; We now dynamically increase the buffer size until it's big enough instead of; giving up and raising <code>AccessDenied</code>_, which was a fallback to avoid crashing.</li>; <li>1904_, [Windows]: <code>OpenProcess</code> fails with <code>ERROR_SUCCESS</code> due to; <code>GetLastError()</code> called after <code>sprintf()</code>. (patch by alxchk)</li>; <li>1913_, [Linux]: <code>wait_procs()</code>_ should catch <code>subprocess.TimeoutExpired</code>; exception.</li>; <li>1919_, [Linux]: <code>sensors_battery()</code>_ can raise <code>TypeError</code> on PureOS.</li>; <li>1921_, [Windows]: <co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:1870,error,error,1870,https://hail.is,https://github.com/hail-is/hail/pull/11459,1,['error'],['error']
Availability,"</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/ca4cb2d6a4b95a6925de85a47b323d2235032c74""><code>ca4cb2d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/804"">#804</a> from blink1073/fix-docs-build</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/2c545599e1da419c096abffcd81f922fb709e239""><code>2c54559</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/803"">#803</a> from ccordoba12/fix-threaded-client</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/30ce7539778e2a25ff5e6eba4ccb6c08b8a0fe20""><code>30ce753</code></a> fix sphinx 5.0 support</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/a2e90574645052320de861bb84ba1752e25ef2dd""><code>a2e9057</code></a> ignore type error</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/3c6fc38e8dda754aba4a1217733eb1a0146b4c57""><code>3c6fc38</code></a> Run qtconsole test suite as a another downstream project</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/dcb45960b337fb089e04b0c3dde880e8f0f10ae5""><code>dcb4596</code></a> Revert changes related to _handle_recv in ThreadedZMQSocketChannel</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/01bfdd18c2eb8ea34cbb9915cb2bc7d9806f81a4""><code>01bfdd1</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/799"">#799</a> from jupyter/pre-commit-ci-update-config</li>; <li>Additional commits viewable in <a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.1...v7.3.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyter-client&package-manager=pip&previous-version=7.3.1&new-version=7.3.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12110:9188,down,downstream,9188,https://hail.is,https://github.com/hail-is/hail/pull/12110,1,['down'],['downstream']
Availability,"</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/7d6de83037ca41cd2f2f31830b43e43720e45b3a""><code>7d6de83</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1da8f078e22412475b694ce07b890148b8a5e4fc""><code>1da8f07</code></a> Add comment</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/9703f764df56c52626f7d6f44bca8b1d51312389""><code>9703f76</code></a> Use pooling connection manager instead of basic one</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/306172e4c6532e185c8a6a9998bca7d22d2d0c63""><code>306172e</code></a> Bump up version number to 5.2.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b9df0c0daa080450772c365f16a9406fe0ca607a""><code>b9df0c0</code></a> Document eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/05a4433770f7020ff845add9348bdc12c82793dd""><code>05a4433</code></a> Add eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/09d1eca91afbf21ace3672be24c68d9028ee1e33""><code>09d1eca</code></a> Document runAsync method</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/800e3df1647c5ce65bffdd25c3240dfa5244e6c5""><code>800e3df</code></a> Add runAsync method to download extension</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/80f04c6a46fe7df053ac55bcfc6f90ff74c4b873""><code>80f04c6</code></a> Bump up version number to 5.1.3</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=3.2.0&new-version=5.2.1)](https://docs.github.co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:4109,down,download-task,4109,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['down'],['download-task']
Availability,"</li>; <li>Added support for blob names containing invalid XML characters.; Previously \uFFFE and \uFFFF would fail if present in blob name.</li>; <li>Added support for listing system containers with get_blob_containers().</li>; <li>Added support for <code>find_blobs_by_tags()</code> on a container.</li>; <li>Added support for <code>Find (f)</code> container SAS permission.</li>; </ul>; <h3>Bugs Fixed</h3>; <ul>; <li>Added all missing Service SAS permissions.</li>; <li>Fixed a bug that prevented <code>upload_blob()</code> from working with an OS pipe; reader stream on Linux. (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23131"">#23131</a>)</li>; </ul>; <h2>azure-storage-blob_12.10.0b4</h2>; <h2>12.10.0b4 (2022-02-24)</h2>; <h3>Features Added</h3>; <ul>; <li>Updated clients to support both SAS and OAuth together.</li>; <li>Updated OAuth implementation to use the AAD scope returned in a Bearer challenge.</li>; </ul>; <h3>Bugs Fixed</h3>; <ul>; <li>Addressed a few <code>mypy</code> typing hint errors.</li>; </ul>; <h2>azure-storage-blob_12.10.0b3</h2>; <h2>12.10.0b3 (2022-02-08)</h2>; <p>This version and all future versions will require Python 3.6+. Python 2.7 is no longer supported.</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/4c24f4f2d09d3e00668cb273f5257dd2b19c115a""><code>4c24f4f</code></a> [Storage][Hotfix] Fix <code>BlobSasPermission</code> default value for Tag (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23651"">#23651</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/699acfe143cc0ca570de2d040c8ffcf7cb2a3c55""><code>699acfe</code></a> [Storage] Fix <code>detination_lease</code> type hint (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23417"">#23417</a>)</li>; <li><a href=""https://gith",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11703:2742,error,errors,2742,https://hail.is,https://github.com/hail-is/hail/pull/11703,1,['error'],['errors']
Availability,"</li>; <li>Added support for blob names containing invalid XML characters.; Previously \uFFFE and \uFFFF would fail if present in blob name.</li>; <li>Added support for listing system containers with get_blob_containers().</li>; <li>Added support for <code>find_blobs_by_tags()</code> on a container.</li>; <li>Added support for <code>Find (f)</code> container SAS permission.</li>; </ul>; <h3>Bugs Fixed</h3>; <ul>; <li>Added all missing Service SAS permissions.</li>; <li>Fixed a bug that prevented <code>upload_blob()</code> from working with an OS pipe; reader stream on Linux. (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23131"">#23131</a>)</li>; </ul>; <h2>azure-storage-blob_12.10.0b4</h2>; <h2>12.10.0b4 (2022-02-24)</h2>; <h3>Features Added</h3>; <ul>; <li>Updated clients to support both SAS and OAuth together.</li>; <li>Updated OAuth implementation to use the AAD scope returned in a Bearer challenge.</li>; </ul>; <h3>Bugs Fixed</h3>; <ul>; <li>Addressed a few <code>mypy</code> typing hint errors.</li>; </ul>; <h2>azure-storage-blob_12.10.0b3</h2>; <h2>12.10.0b3 (2022-02-08)</h2>; <p>This version and all future versions will require Python 3.6+. Python 2.7 is no longer supported.</p>; <h3>Features Added</h3>; <ul>; <li>Added support for service version 2021-04-10.</li>; <li>Added support for <code>find_blobs_by_tags()</code> on a container.</li>; <li>Added support for <code>Find (f)</code> container SAS permission.</li>; </ul>; <h3>Bugs Fixed</h3>; <ul>; <li>Update <code>azure-core</code> dependency to avoid inconsistent dependencies from being installed.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/699acfe143cc0ca570de2d040c8ffcf7cb2a3c55""><code>699acfe</code></a> [Storage] Fix <code>detination_lease</code> type hint (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23417"">#23417</a>)</li>; <",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11610:1947,error,errors,1947,https://hail.is,https://github.com/hail-is/hail/pull/11610,1,['error'],['errors']
Availability,"</p>; <ul>; <li>Binary wheels provided on PyPi for <code>aarch64</code> Linux systems and macOS; native silicon where supported by Python when using <code>pypa/cibuildwheel</code>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/f2f1a680113d500f525de78da91ae19235efef16""><code>f2f1a68</code></a> Merge branch 'release/1.14.1'</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/97b72d49a8cda771c6006571486530ca84f3a834""><code>97b72d4</code></a> Update version of cibuildwheel for recent Python versions.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/337072730beddd653f19c8b1a1157ecbb9d62790""><code>3370727</code></a> Only test Python 3.10 on aarch64 linux due to unreliability of GitHub runners...</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/982ddecf52013ce9bbdf8b48b76ae054844ba31b""><code>982ddec</code></a> Python 3.6 no longer available on aarch64 linux for testing.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/240fea86df0357f3642db040f912031e4ecdfcb1""><code>240fea8</code></a> Update copyright notice year.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/9668bbd7c7314d81b7cf8ce4293d04212ae1edee""><code>9668bbd</code></a> Update version in preparation for 1.14.1 release.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/c86a4d37fa61494957153f76b1d6bbdacfd83205""><code>c86a4d3</code></a> Add classifier for Python 3.11.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/07239ac21a68ced86860cf3bb52ee0c60faf0915""><code>07239ac</code></a> Document fix for module importers using deprecated APIs.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/df0e62c2740143cceb6cafea4c306dae1c559ef8""><code>df0e62c</code></a> Deal with module importers that don't implement newer API.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/726275923",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12102:2909,avail,available,2909,https://hail.is,https://github.com/hail-is/hail/pull/12102,1,['avail'],['available']
Availability,"</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6050294](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6050294) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure the",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14203:1105,avail,available,1105,https://hail.is,https://github.com/hail-is/hail/pull/14203,1,['avail'],['available']
Availability,"</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | N",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:1105,avail,available,1105,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,"</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; msal-extensions 1.1.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | N",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14329:1105,avail,available,1105,https://hail.is,https://github.com/hail-is/hail/pull/14329,1,['avail'],['available']
Availability,"</summary>. ```; aiohttp-jinja2 1.5.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;) <br/>[SNYK-PYTHON-AIOHTTP-6209406](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209406) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **718/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-6209407](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209407) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5ZWNjYjQ0YS1jYWZiLTQ0OTgtYjU1NS02NDdmZjUwY2ExOT",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14225:1450,avail,available,1450,https://hail.is,https://github.com/hail-is/hail/pull/14225,1,['avail'],['available']
Availability,"<2 in /usr/local/lib64/python3.7/site-packages (1.21.6); 949 | amazon-ebs: Collecting orjson==3.6.4; 950 | amazon-ebs: Downloading orjson-3.6.4-cp37-cp37m-manylinux_2_24_x86_64.whl (249 kB); 951 | amazon-ebs:  249.9/249.9 kB 45.1 MB/s eta 0:00:00; 952 | amazon-ebs: Requirement already satisfied: pandas<1.5.0,>=1.3.0 in /usr/local/lib64/python3.7/site-packages (1.3.5); 953 | amazon-ebs: Collecting parsimonious<0.9; 954 | amazon-ebs: Downloading parsimonious-0.8.1.tar.gz (45 kB); 955 | amazon-ebs:  45.1/45.1 kB 10.2 MB/s eta 0:00:00; 956 | amazon-ebs: Preparing metadata (setup.py): started; 957 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 958 | amazon-ebs: Collecting plotly<5.11,>=5.5.0; 959 | amazon-ebs: Downloading plotly-5.10.0-py2.py3-none-any.whl (15.2 MB); 960 | amazon-ebs:  15.2/15.2 MB 57.8 MB/s eta 0:00:00; 961 | amazon-ebs: Collecting PyJWT; 962 | amazon-ebs: Downloading PyJWT-2.5.0-py3-none-any.whl (20 kB); 963 | amazon-ebs: Collecting python-json-logger==2.0.2; 964 | amazon-ebs: Downloading python_json_logger-2.0.2-py3-none-any.whl (7.4 kB); 965 | amazon-ebs: Collecting requests==2.25.1; 966 | amazon-ebs: Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB); 967 | amazon-ebs:  61.2/61.2 kB 15.6 MB/s eta 0:00:00; 968 | amazon-ebs: Requirement already satisfied: scipy<1.8,>1.2 in /usr/local/lib64/python3.7/site-packages (1.7.3); 969 | amazon-ebs: Requirement already satisfied: sortedcontainers==2.4.0 in /usr/local/lib/python3.7/site-packages (2.4.0); 970 | amazon-ebs: Collecting tabulate==0.8.9; 971 | amazon-ebs: Downloading tabulate-0.8.9-py3-none-any.whl (25 kB); 972 | amazon-ebs: Requirement already satisfied: tqdm==4.* in /usr/local/lib/python3.7/site-packages (4.64.1); 973 | amazon-ebs: Collecting uvloop==0.16.0; 974 | amazon-ebs: Downloading uvloop-0.16.0-cp37-cp37",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:6704,Down,Downloading,6704,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,"<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49806"">#49806</a> on branch 1.5.x (DOC: Update what's new notes for 1.5.2 re...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/98c6139ff12107b9aa34441d25ef1593b6a0adca""><code>98c6139</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49579"">#49579</a> on Branch 1.5.x (BUG: Behaviour change in 1.5.0 when using...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/9196f8d545d1118f1233c1b45e7b740cb95c370c""><code>9196f8d</code></a> Backport PR STYLE enable pylint: method-cache-max-size-none (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49784"">#49784</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/8c4b559c87561ca68ccdc3e81ff3c5218c7b4db7""><code>8c4b559</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49776"">#49776</a> on branch 1.5.x (REGR: arithmetic ops recursion error with...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/1616fb3d2c00905a5f3af510db893206ae00ea09""><code>1616fb3</code></a> Backport PR Revert &quot;Add color and size to arguments (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/44856"">#44856</a>)&quot; (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49752"">#49752</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/6f8e1745472c9d107367da1e38494425c3938234""><code>6f8e174</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49720"">#49720</a> on branch 1.5.x (Suppress spurious warning) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49726"">#49726</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/63a91d0992b5f2837dc028d1bab34e659535b6b4""><code>63a91d0</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49676"">#496",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12564:3884,error,error,3884,https://hail.is,https://github.com/hail-is/hail/pull/12564,1,['error'],['error']
Availability,"<a href=""https://github-redirect.dependabot.com/psf/requests/issues/6028"">#6028</a>)</li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/psf/requests/blob/v2.27.1/HISTORY.md#2271-2022-01-05"">https://github.com/psf/requests/blob/v2.27.1/HISTORY.md#2271-2022-01-05</a></p>; <h2>v2.27.0</h2>; <h2>2.27.0 (2022-01-03)</h2>; <p><strong>Improvements</strong></p>; <ul>; <li>; <p>Officially added support for Python 3.10. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5928"">#5928</a>)</p>; </li>; <li>; <p>Added a <code>requests.exceptions.JSONDecodeError</code> to unify JSON exceptions between; Python 2 and 3. This gets raised in the <code>response.json()</code> method, and is; backwards compatible as it inherits from previously thrown exceptions.; Can be caught from <code>requests.exceptions.RequestException</code> as well. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5856"">#5856</a>)</p>; </li>; <li>; <p>Improved error text for misnamed <code>InvalidSchema</code> and <code>MissingSchema</code>; exceptions. This is a temporary fix until exceptions can be renamed; (Schema-&gt;Scheme). (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/6017"">#6017</a>)</p>; </li>; <li>; <p>Improved proxy parsing for proxy URLs missing a scheme. This will address; recent changes to <code>urlparse</code> in Python 3.9+. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5917"">#5917</a>)</p>; </li>; </ul>; <p><strong>Bugfixes</strong></p>; <ul>; <li>; <p>Fixed defect in <code>extract_zipped_paths</code> which could result in an infinite loop; for some paths. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5851"">#5851</a>)</p>; </li>; <li>; <p>Fixed handling for <code>AttributeError</code> when calculating length of files obtained; by <code>Tarfile.extractfile()</code>. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5239"">#5239</a>)</p>; </li>; <li>; <",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11528:1422,error,error,1422,https://hail.is,https://github.com/hail-is/hail/pull/11528,2,['error'],['error']
Availability,"<a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1144"">PyMySQL/PyMySQL#1144</a></li>; <li>chore(deps): update dependency sphinx-rtd-theme to v2 by <a href=""https://github.com/renovate""><code>@renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1147"">PyMySQL/PyMySQL#1147</a></li>; <li>chore(deps): update actions/setup-python action to v5 by <a href=""https://github.com/renovate""><code>@renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1152"">PyMySQL/PyMySQL#1152</a></li>; <li>chore(deps): update github/codeql-action action to v3 by <a href=""https://github.com/renovate""><code>@renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1154"">PyMySQL/PyMySQL#1154</a></li>; <li>chore(deps): update codecov/codecov-action action to v4 by <a href=""https://github.com/renovate""><code>@renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1158"">PyMySQL/PyMySQL#1158</a></li>; <li>Support error packet without sqlstate by <a href=""https://github.com/methane""><code>@methane</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1160"">PyMySQL/PyMySQL#1160</a></li>; <li>test json - mariadb without JSON type by <a href=""https://github.com/grooverdan""><code>@grooverdan</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1165"">PyMySQL/PyMySQL#1165</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/hugovk""><code>@hugovk</code></a> made their first contribution in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1134"">PyMySQL/PyMySQL#1134</a></li>; <li><a href=""https://github.com/svaskov""><code>@svaskov</code></a> made their first contribution in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1145"">PyMySQL/PyMySQL#1145</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/PyMySQL/PyMySQL/compare/v1.1.0...v1.1.1"">https://github.com/PyMySQL/PyMySQL/compare",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14556:3325,error,error,3325,https://hail.is,https://github.com/hail-is/hail/pull/14556,1,['error'],['error']
Availability,"<b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed.; jupyter 1.0.0 requires qtconsole, which is not installed.; curlylint 0.13.1 requires pathspec, which is not installed.; black 22.12.0 requires pathspec, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed.; astroid 2.15.8 requires lazy-object-proxy, which is not installed.; argon2-cffi-bindings 21.2.0 requires cffi, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `3.1.2 -> 3.1.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlOTc1OTMyYy1kNmNhLTQ0NTUtYmU4ZC04NzY1ZGY0MTZjMWMiLCJldmVudC",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14141:1435,avail,available,1435,https://hail.is,https://github.com/hail-is/hail/pull/14141,1,['avail'],['available']
Availability,"<blockquote>; <h2>v1.22.0</h2>; <h1>NumPy 1.22.0 Release Notes</h1>; <p>NumPy 1.22.0 is a big release featuring the work of 153 contributors; spread over 609 pull requests. There have been many improvements,; highlights are:</p>; <ul>; <li>Annotations of the main namespace are essentially complete. Upstream; is a moving target, so there will likely be further improvements,; but the major work is done. This is probably the most user visible; enhancement in this release.</li>; <li>A preliminary version of the proposed Array-API is provided. This is; a step in creating a standard collection of functions that can be; used across application such as CuPy and JAX.</li>; <li>NumPy now has a DLPack backend. DLPack provides a common interchange; format for array (tensor) data.</li>; <li>New methods for <code>quantile</code>, <code>percentile</code>, and related functions. The; new methods provide a complete set of the methods commonly found in; the literature.</li>; <li>A new configurable allocator for use by downstream projects.</li>; </ul>; <p>These are in addition to the ongoing work to provide SIMD support for; commonly used functions, improvements to F2PY, and better documentation.</p>; <p>The Python versions supported in this release are 3.8-3.10, Python 3.7; has been dropped. Note that 32 bit wheels are only provided for Python; 3.8 and 3.9 on Windows, all other wheels are 64 bits on account of; Ubuntu, Fedora, and other Linux distributions dropping 32 bit support.; All 64 bit wheels are also linked with 64 bit integer OpenBLAS, which should fix; the occasional problems encountered by folks using truly huge arrays.</p>; <h2>Expired deprecations</h2>; <h3>Deprecated numeric style dtype strings have been removed</h3>; <p>Using the strings <code>&quot;Bytes0&quot;</code>, <code>&quot;Datetime64&quot;</code>, <code>&quot;Str0&quot;</code>, <code>&quot;Uint32&quot;</code>,; and <code>&quot;Uint64&quot;</code> as a dtype will now raise a <code>TypeError</code>.</p>; <p>(<a h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11939:1233,down,downstream,1233,https://hail.is,https://github.com/hail-is/hail/pull/11939,4,['down'],['downstream']
Availability,"<br/>[SNYK-PYTHON-NUMPY-2321970](https://snyk.io/vuln/SNYK-PYTHON-NUMPY-2321970) | `numpy:` <br> `1.21.3 -> 1.22.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4ZjJmN2FlNC0wY2VjLTQ3ZTYtODIyZi1lODFiMTA2N2RhMjIiLCJldmVudCI6IlBSIHZpZXd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13871:3961,avail,available,3961,https://hail.is,https://github.com/hail-is/hail/pull/13871,1,['avail'],['available']
Availability,"<br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **501/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.3 | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14109:3905,avail,available,3905,https://hail.is,https://github.com/hail-is/hail/pull/14109,1,['avail'],['available']
Availability,"<code>[#3008](https://github.com/urllib3/urllib3/issues/3008) &lt;https://github.com/urllib3/urllib3/issues/3008&gt;</code>__)</li>; <li>Fixed <code>assert_hostname=False</code> to correctly skip hostname check. (<code>[#3051](https://github.com/urllib3/urllib3/issues/3051) &lt;https://github.com/urllib3/urllib3/issues/3051&gt;</code>__)</li>; </ul>; <h1>2.0.2 (2023-05-03)</h1>; <ul>; <li>Fixed <code>HTTPResponse.stream()</code> to continue yielding bytes if buffered decompressed data; was still available to be read even if the underlying socket is closed. This prevents; a compressed response from being truncated. (<code>[#3009](https://github.com/urllib3/urllib3/issues/3009) &lt;https://github.com/urllib3/urllib3/issues/3009&gt;</code>__)</li>; </ul>; <h1>2.0.1 (2023-04-30)</h1>; <ul>; <li>Fixed a socket leak when fingerprint or hostname verifications fail. (<code>[#2991](https://github.com/urllib3/urllib3/issues/2991) &lt;https://github.com/urllib3/urllib3/issues/2991&gt;</code>__)</li>; <li>Fixed an error when <code>HTTPResponse.read(0)</code> was the first <code>read</code> call or when the internal response body buffer was otherwise empty. (<code>[#2998](https://github.com/urllib3/urllib3/issues/2998) &lt;https://github.com/urllib3/urllib3/issues/2998&gt;</code>__)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/urllib3/urllib3/commit/56f01e088dc006c03d4ee6ea9da4ab810f1ed700""><code>56f01e0</code></a> Release 2.0.7</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/4e50fbc5db74e32cabd5ccc1ab81fc103adfe0b3""><code>4e50fbc</code></a> Merge pull request from GHSA-g4mx-q9vg-27p4</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/80808b04bfa68fbd099828848c96ee25df185f1d""><code>80808b0</code></a> Fix docs build on Python 3.12 (<a href=""https://redirect.github.com/urllib3/urllib3/issues/3144"">#3144</a>)</li>; <li><a href=""https://git",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13852:11560,error,error,11560,https://hail.is,https://github.com/hail-is/hail/pull/13852,1,['error'],['error']
Availability,"<code>[#3008](https://github.com/urllib3/urllib3/issues/3008) &lt;https://github.com/urllib3/urllib3/issues/3008&gt;</code>__)</li>; <li>Fixed <code>assert_hostname=False</code> to correctly skip hostname check. (<code>[#3051](https://github.com/urllib3/urllib3/issues/3051) &lt;https://github.com/urllib3/urllib3/issues/3051&gt;</code>__)</li>; </ul>; <h1>2.0.2 (2023-05-03)</h1>; <ul>; <li>Fixed <code>HTTPResponse.stream()</code> to continue yielding bytes if buffered decompressed data; was still available to be read even if the underlying socket is closed. This prevents; a compressed response from being truncated. (<code>[#3009](https://github.com/urllib3/urllib3/issues/3009) &lt;https://github.com/urllib3/urllib3/issues/3009&gt;</code>__)</li>; </ul>; <h1>2.0.1 (2023-04-30)</h1>; <ul>; <li>Fixed a socket leak when fingerprint or hostname verifications fail. (<code>[#2991](https://github.com/urllib3/urllib3/issues/2991) &lt;https://github.com/urllib3/urllib3/issues/2991&gt;</code>__)</li>; <li>Fixed an error when <code>HTTPResponse.read(0)</code> was the first <code>read</code> call or when the internal response body buffer was otherwise empty. (<code>[#2998](https://github.com/urllib3/urllib3/issues/2998) &lt;https://github.com/urllib3/urllib3/issues/2998&gt;</code>__)</li>; </ul>; <h1>2.0.0 (2023-04-26)</h1>; <p>Read the <code>v2.0 migration guide &lt;https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html&gt;</code>__ for help upgrading to the latest version of urllib3.</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/urllib3/urllib3/commit/262e3e332209ee93ff70e2b13502c8f20c105ac8""><code>262e3e3</code></a> Release 2.0.6</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/644124ecd0b6e417c527191f866daa05a5a2056d""><code>644124e</code></a> Merge pull request from GHSA-v845-jxx5-vc9f</li>; <li><a href=""https://github.com/urllib3/urllib3/comm",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13768:11208,error,error,11208,https://hail.is,https://github.com/hail-is/hail/pull/13768,2,['error'],['error']
Availability,"<code>numpy.float16</code> (<code>numpy.half</code>).</li>; <li>sdist uses metadata 2.3 instead of 2.1.</li>; <li>Improve Windows PyPI builds.</li>; </ul>; <h2>3.9.15</h2>; <h3>Fixed</h3>; <ul>; <li>Implement recursion limit of 1024 on <code>orjson.loads()</code>.</li>; <li>Use byte-exact read on <code>str</code> formatting SIMD path to avoid crash.</li>; </ul>; <h2>3.9.14</h2>; <h3>Fixed</h3>; <ul>; <li>Fix crash serializing <code>str</code> introduced in 3.9.11.</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Build now depends on Rust 1.72 or later.</li>; </ul>; <h2>3.9.13</h2>; <h3>Fixed</h3>; <ul>; <li>Serialization <code>str</code> escape uses only 128-bit SIMD.</li>; <li>Fix compatibility with CPython 3.13 alpha 3.</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Publish <code>musllinux_1_2</code> instead of <code>musllinux_1_1</code> wheels.</li>; <li>Serialization uses small integer optimization in CPython 3.12 or later.</li>; </ul>; <h2>3.9.12</h2>; <h3>Fixed</h3>; <ul>; <li>Minimal <code>musllinux_1_1</code> build due to sporadic CI failure.</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Update benchmarks in README.</li>; </ul>; <h2>3.9.11</h2>; <h3>Changed</h3>; <ul>; <li>Improve performance of serializing. <code>str</code> is significantly faster. Documents; using <code>dict</code>, <code>list</code>, and <code>tuple</code> are somewhat faster.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/ijl/orjson/blob/master/CHANGELOG.md"">orjson's changelog</a>.</em></p>; <blockquote>; <h2>3.10.0 - 2024-03-27</h2>; <h3>Changed</h3>; <ul>; <li>Support serializing <code>numpy.float16</code> (<code>numpy.half</code>).</li>; <li>sdist uses metadata 2.3 instead of 2.1.</li>; <li>Improve Windows PyPI builds.</li>; </ul>; <h2>3.9.15 - 2024-02-23</h2>; <h3>Fixed</h3>; <ul>; <li>Implement recursion limit of 1024 on <code>orjson.loads()</code>.</li>; <li>Use byte-exact read on <code>str</code> formatting SIMD path to",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14427:1340,failure,failure,1340,https://hail.is,https://github.com/hail-is/hail/pull/14427,1,['failure'],['failure']
Availability,"<details>; <summary> <b>Warning</b></summary>. ```; aiohttp-jinja2 1.5.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlNDEzMjhlZS0zNDg5LTQ3NDItYTc3YS01ZDZhNTQ1ZWE",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14037:1413,avail,available,1413,https://hail.is,https://github.com/hail-is/hail/pull/14037,1,['avail'],['available']
Availability,"<h2>[5.10.0] - 2022-08-11</h2>; <h3>Updated</h3>; <ul>; <li>Updated Plotly.js to from version 2.12.1 to version 2.14.0. See the <a href=""https://github.com/plotly/plotly.js/blob/master/CHANGELOG.md#2140----2022-08-10"">plotly.js CHANGELOG</a> for more information. Notable changes include:; <ul>; <li>Add support for <code>sankey</code> links with arrows</li>; <li>Add <code>selections</code>, <code>newselection</code> and <code>activeselection</code> layout attributes to have persistent and editable selections over cartesian subplots</li>; <li>Add <code>unselected.line.color</code> and <code>unselected.line.opacity</code> options to <code>parcoords</code> trace</li>; <li>Display Plotly's new logo in the modebar</li>; </ul>; </li>; </ul>; <h2>[5.9.0] - 2022-06-23</h2>; <h3>Added</h3>; <ul>; <li><code>pattern_shape</code> options now available in <code>px.timeline()</code> <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3774"">#3774</a></li>; <li><code>facet_*</code> and <code>category_orders</code> now available in <code>px.pie()</code> <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3775"">#3775</a></li>; </ul>; <h3>Performance</h3>; <ul>; <li><code>px</code> methods no longer call <code>groupby</code> on the input dataframe when the result would be a single group, and no longer groups by a lambda, for significant speedups <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3765"">#3765</a> with thanks to <a href=""https://github.com/jvdd""><code>@jvdd</code></a></li>; </ul>; <h3>Updated</h3>; <ul>; <li>Allow non-string extras in <code>flaglist</code> attributes, to support upcoming changes to <code>ax.automargin</code> in plotly.js <a href=""https://github-redirect.dependabot.com/plotly/plotly.js/pull/6193"">plotly.js#6193</a>, <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3749"">#3749</a></li>; </ul>; <h2>[5.8.2] - 2022-06-10</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed a syntax error that caused",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12113:2245,avail,available,2245,https://hail.is,https://github.com/hail-is/hail/pull/12113,1,['avail'],['available']
Availability,"<h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzM2VkMzM4Ny0zZTVmLTRkZDgtYjIxYy1iYzIyNzk4ODViZjMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjMzZWQzMzg3LTNlNWYtNGRkOC1iMjFjLWJjMjI3OTg4NWJmMyJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_med",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13107:761,avail,available,761,https://hail.is,https://github.com/hail-is/hail/pull/13107,1,['avail'],['available']
Availability,"<h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlNTZiOGU3Ni1mMTk3LTQ0MmMtOGVlMC04MjFhMDk5YzM3YTAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU1NmI4ZTc2LWYxOTctNDQyYy04ZWUwLTgyMWEwOTljMzdhMCJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13072:772,avail,available,772,https://hail.is,https://github.com/hail-is/hail/pull/13072,1,['avail'],['available']
Availability,"<h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; sphinx 5.3.0 has requirement docutils<0.20,>=0.14, but you have docutils 0.20.; sphinx-rtd-theme 1.2.0 has requirement docutils<0.19, but you have docutils 0.20. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyOTUzNDFmZi1lMjQ4LTRiOTItYTY1Yy1kYjJiZWQ3ZDQxMGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6I",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13066:998,avail,available,998,https://hail.is,https://github.com/hail-is/hail/pull/13066,1,['avail'],['available']
Availability,"<h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `40.0.2 -> 41.0.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmZWM3ZmQ2Ny0xZmE0LTRlNzEtODQ4Ni1hMDk5YThmYWM3NzgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZlYzdmZDY3LTFmYTQtNGU3MS04NDg2LWEwOTlhOGZhYzc3OCJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13138:776,avail,available,776,https://hail.is,https://github.com/hail-is/hail/pull/13138,1,['avail'],['available']
Availability,"<h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2YzU3NmY1Yi1lNGM5LTQ4ZjctYmYxNy04YjEzOTIxODlmZDQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjZjNTc2ZjViLWU0YzktNDhmNy1iZjE3LThiMTM5MjE4OWZkNCJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;git",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13097:776,avail,available,776,https://hail.is,https://github.com/hail-is/hail/pull/13097,1,['avail'],['available']
Availability,"<h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Use of a Broken or Risky Cryptographic Algorithm <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6149518](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6149518) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affecte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14230:1125,avail,available,1125,https://hail.is,https://github.com/hail-is/hail/pull/14230,1,['avail'],['available']
Availability,"<h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; msal-extensions 1.1.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6261585](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6261585) | `cryptography:` <br> `42.0.2 -> 42.0.4` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1MzAxOWZkZC04YjQwLTQ5NmUtYjRmYS0wMzA5MTAx",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14344:1125,avail,available,1125,https://hail.is,https://github.com/hail-is/hail/pull/14344,1,['avail'],['available']
Availability,"<h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiNzM2NzI0Yi1hY2RiLTRiOTUtYWQwMy1hYWI3MjkyZGNlYzQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI3MzY3MjRiLWFjZGItNGI5NS1hZDAzLWFhYjcyOTJkY2VjNCJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13116:768,avail,available,768,https://hail.is,https://github.com/hail-is/hail/pull/13116,1,['avail'],['available']
Availability,"<li>Fixing spelling error (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3567"">#3567</a>)</li>; <li>Moving gitpod metion (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2637"">#2637</a>)</li>; <li>Adding new axios documentation website link (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3681"">#3681</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3707"">#3707</a>)</li>; <li>Updating documentation around dispatching requests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3772"">#3772</a>)</li>; <li>Adding documentation for the type guard isAxiosError (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3767"">#3767</a>)</li>; <li>Adding explanation of cancel token (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3803"">#3803</a>)</li>; <li>Updating CI status badge (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3953"">#3953</a>)</li>; <li>Fixing errors with JSON documentation (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3936"">#3936</a>)</li>; <li>Fixing README typo under Request Config (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3825"">#3825</a>)</li>; <li>Adding axios-multi-api to the ecosystem file (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3817"">#3817</a>)</li>; <li>Adding SECURITY.md to properly disclose security vulnerabilities (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3981"">#3981</a>)</li>; </ul>; <p>Huge thanks to everyone who contributed to this release via code (authors listed below) or via reviews and triaging on GitHub:</p>; <ul>; <li><a href=""https://github.com/SashaKoro"">Sasha Korotkov</a></li>; <li><a href=""https://github.com/timemachine3030"">Daniel Lopretto</a></li>; <li><a href=""https://github.com/MikeBishop"">Mike Bishop</a></li>; <li><a href=""https://github.com/DigitalBrainJS"">Dmitriy Mozgovoy</a></li>; <li><a href=""https://git",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:4405,error,errors,4405,https://hail.is,https://github.com/hail-is/hail/pull/11080,2,['error'],['errors']
Availability,"<li>Fixing spelling error (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3567"">#3567</a>)</li>; <li>Moving gitpod metion (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2637"">#2637</a>)</li>; <li>Adding new axios documentation website link (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3681"">#3681</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3707"">#3707</a>)</li>; <li>Updating documentation around dispatching requests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3772"">#3772</a>)</li>; <li>Adding documentation for the type guard isAxiosError (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3767"">#3767</a>)</li>; <li>Adding explanation of cancel token (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3803"">#3803</a>)</li>; <li>Updating CI status badge (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3953"">#3953</a>)</li>; <li>Fixing errors with JSON documentation (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3936"">#3936</a>)</li>; <li>Fixing README typo under Request Config (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3825"">#3825</a>)</li>; <li>Adding axios-multi-api to the ecosystem file (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3817"">#3817</a>)</li>; <li>Adding SECURITY.md to properly disclose security vulnerabilities (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3981"">#3981</a>)</li>; </ul>; <p>Huge thanks to everyone who contributed to this release via code (authors listed below) or via reviews and triaging on GitHub:</p>; <ul>; <li><a href=""https://github.com/axios/axios/blob/master/mailto:jasonsaayman@gmail.com"">Jay</a></li>; <li><a href=""https://github.com/SashaKoro"">Sasha Korotkov</a></li>; <li><a href=""https://github.com/timemachine3030"">Daniel Lopretto</a></li>; <li><a href=""https://github.com/MikeBishop"">Mike Bishop</a></li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:9930,error,errors,9930,https://hail.is,https://github.com/hail-is/hail/pull/11080,2,['error'],['errors']
Availability,"<module>; from jinja2 import Environment, Markup, FileSystemLoader; E ImportError: cannot import name 'Markup' from 'jinja2' (/home/circleci/conda/envs/lib/python3.7/site-packages/jinja2/__init__.py); [error] java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; [error] 	at scala.Predef$.require(Predef.scala:281); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14(build.sbt:288); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14$adapted(build.sbt:278); [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49); [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62); [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67); [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:280); [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19); [error] 	at sbt.Execute.work(Execute.scala:289); [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:280); [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); [error] 	at java.lang.Thread.run(Thread.java:748); [error] (hail / hailtest) java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; ```. To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705:1605,error,error,1605,https://hail.is,https://github.com/hail-is/hail/issues/11705,1,['error'],['error']
Availability,"<p><em>Sourced from <a href=""https://github.com/michel-kraemer/gradle-download-task/releases"">de.undercouch.download's releases</a>.</em></p>; <blockquote>; <h2>5.4.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to set request <code>method</code> and <code>body</code></li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; <li>Improve documentation</li>; <li>Add integration tests for Gradle 8.0.1</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4c983ed5cd229fa64912294737c858c2ba8486d6""><code>4c983ed</code></a> Bump up version number to 5.4.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/cc20442ab67bf37687c08e67af7e7de3a21c8fbe""><code>cc20442</code></a> Add integration tests for Gradle 8.0.2</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/472920e572e4cf45d321868874ced50ad8d1e2d5""><code>472920e</code></a> Add possibility to set request method and body</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/82e70cae2a8d48b4f5165a9b543d4e65bb793d88""><code>82e70ca</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86a15f1c16eb729dc71b6caf30237d07b8e0bb01""><code>86a15f1</code></a> Fix compiler warnings and deprecations</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86363072c8239330b28976109a622bdd073507b6""><code>8636307</code></a> Negative timeouts are actually not allowed</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4ff0ff0e63e0dd45f231990d0dcebffde6e6b709""><code>4ff0ff0</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a1858b494b5f3a51ccef7580c243c6dfdf520731""><code>a1858b4</code></a> Merge pull request <a href=""https://redirect.github.com/michel-kraemer/grad",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:1083,down,download-task,1083,https://hail.is,https://github.com/hail-is/hail/pull/12893,1,['down'],['download-task']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - auth/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjMDQ5NzlhMC1iYWM3LTRiMjEtYmE0ZS02OWU5YjAzMTE5ZjAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImMwNDk3OWEwLWJhYzctNGIyMS1iYTRlLTY5ZTliMDMxMTlmMCJ9fQ=="" width=""0"" height=""0""/>;  [View latest pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13309:847,avail,available,847,https://hail.is,https://github.com/hail-is/hail/pull/13309,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - auth/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1ZDhmZDhmZC1mZGUxLTRiYmMtYWMzMi0xOTE1NmY0ZDFjZjIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjVkOGZkOGZkLWZkZTEtNGJiYy1hYzMyLTE5MTU2ZjRkMWNmMiJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](https://app.snyk.io",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13112:853,avail,available,853,https://hail.is,https://github.com/hail-is/hail/pull/13112,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - batch/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmZmEwNjUyZi1hMzc2LTQ0NmQtYWJjNC04NmJhMzUwNmY3MzMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZmYTA2NTJmLWEzNzYtNDQ2ZC1hYmM0LTg2YmEzNTA2ZjczMyJ9fQ=="" width=""0"" height=""0""/>;  [View latest project rep",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13285:880,avail,available,880,https://hail.is,https://github.com/hail-is/hail/pull/13285,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - batch/requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; aiodocker 0.21.0 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;) <br/>[SNYK-PYTHON-AIOHTTP-6209406](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209406) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **718/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-6209407](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209407) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ens",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14226:977,avail,available,977,https://hail.is,https://github.com/hail-is/hail/pull/14226,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - batch/requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; aiodocker 0.21.0 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with y",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14044:1003,avail,available,1003,https://hail.is,https://github.com/hail-is/hail/pull/14044,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3Mzc3ZjFlZS1kMjJjLTQ0MDAtYmE1Yy04NGNkYWZmZWJmYzgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjczNzdmMWVlLWQyMmMtNDQwMC1iYTVjLTg0Y2RhZmZlYmZjOCJ9fQ=="" width=""0"" height=""0""/>;  [View latest proj",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13305:845,avail,available,845,https://hail.is,https://github.com/hail-is/hail/pull/13305,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **551/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13365:845,avail,available,845,https://hail.is,https://github.com/hail-is/hail/pull/13365,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6050294](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6050294) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14200:831,avail,available,831,https://hail.is,https://github.com/hail-is/hail/pull/14200,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyNWE2ZGYzMi1kYmEzLTQzOTctYmIyNC0zNjdlMzhmZWQ3ZmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjI1YTZkZjMyLWRiYTMtNDM5Ny1iYjI0LTM2N2UzOGZlZDdmZSJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13848:851,avail,available,851,https://hail.is,https://github.com/hail-is/hail/pull/13848,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Use of a Broken or Risky Cryptographic Algorithm <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6149518](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6149518) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **451/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.3 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14236:831,avail,available,831,https://hail.is,https://github.com/hail-is/hail/pull/14236,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `40.0.2 -> 41.0.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjOTM3MTIxYy1lZTM3LTQ2ZmMtYTcxMC04MWY4YzdhZmUyN2IiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImM5MzcxMjFjLWVlMzctNDZmYy1hNzEwLTgxZjhjN2FmZTI3YiJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](https:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13136:851,avail,available,851,https://hail.is,https://github.com/hail-is/hail/pull/13136,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3ZGVlZGFlMy1mZmE3LTQxYmUtOGY4MS1lNmYwZTA5YTczOTMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdkZWVkYWUzLWZmYTctNDFiZS04ZjgxLWU2ZjBlMDlhNzM5MyJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13770:851,avail,available,851,https://hail.is,https://github.com/hail-is/hail/pull/13770,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6261585](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6261585) | `cryptography:` <br> `42.0.2 -> 42.0.4` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiYWUwMDM5My05NGUzLTRhNjYtYTE5Ni0xMjUwZDg0ZGZiZDgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImJhZTAwMzkzLTk0ZTMtNGE2Ni1hMTk2LTEyNTBkODRkZmJkOCJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](https",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14343:851,avail,available,851,https://hail.is,https://github.com/hail-is/hail/pull/14343,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlZjQxMWYxOC1hM2JiLTQ1YzgtODFjOS1hNmNhNjI4MWI1ZjMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImVmNDExZjE4LWEzYmItNDVjOC04MWM5LWE2Y2E2MjgxYjVmMyJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](https://app.snyk.io/o",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13108:851,avail,available,851,https://hail.is,https://github.com/hail-is/hail/pull/13108,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **611/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5914629](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5914629) | `cryptography:` <br> `41.0.3 -> 41.0.4` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiN2QwMTZlZS0zODA0LTQwMjItOWE0Yi01MzExNjZhNjBjMWQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI3ZDAxNmVlLTM4MDQtNDAyMi05YTRiLTUzMTE2NmE2MGMxZCJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](https:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13698:851,avail,available,851,https://hail.is,https://github.com/hail-is/hail/pull/13698,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmYWJiOGYzZi1mMDFjLTQxMjktODJjNC1kZjQzMjRmZTU4YTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZhYmI4ZjNmLWYwMWMtNDEyOS04MmM0LWRmNDMyNGZlNThhMiJ9fQ=="" width=""0"" height=""0""/>;  [View latest pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13296:847,avail,available,847,https://hail.is,https://github.com/hail-is/hail/pull/13296,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2ZWQ3MzlmOS1mZjc4LTQzYzgtYWQwOC05MThjNmRhMWNlOTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjZlZDczOWY5LWZmNzgtNDNjOC1hZDA4LTkxOGM2ZGExY2U5NiJ9fQ=="" width=""0"" height=""0""/>;  [View latest project repo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13284:879,avail,available,879,https://hail.is,https://github.com/hail-is/hail/pull/13284,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; prometheus-async 19.2.0 requires prometheus-client, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;) <br/>[SNYK-PYTHON-AIOHTTP-6209406](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209406) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **718/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-6209407](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209407) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the ch",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14228:1000,avail,available,1000,https://hail.is,https://github.com/hail-is/hail/pull/14228,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; prometheus-async 19.2.0 requires prometheus-client, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they wo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14034:1026,avail,available,1026,https://hail.is,https://github.com/hail-is/hail/pull/14034,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMjNiYjk0OC04YjdmLTQ5MzUtYTRkMi05ZWJmNjg4NjZlMmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUyM2JiOTQ4LThiN2YtNDkzNS1hNGQyLTllYmY2ODg2NmUyZSJ9fQ=="" width=""0"" height=""0""/>;  [Vie",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13316:858,avail,available,858,https://hail.is,https://github.com/hail-is/hail/pull/13316,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzYWEwNDk2OC02NDIxLTRmODktYTBjYy03MjE4MzExNDNiZGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjNhYTA0OTY4LTY0MjEtNGY4OS1hMGNjLTcyMTgzMTE0M2JkZCJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](https://",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13100:864,avail,available,864,https://hail.is,https://github.com/hail-is/hail/pull/13100,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1ZTRkMTU3Zi04YTdjLTRhNzctYTZlNC00YTdmNGU4Y2I0YzkiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjVlNGQxNTdmLThhN2MtNGE3Ny1hNmU0L",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13323:966,avail,available,966,https://hail.is,https://github.com/hail-is/hail/pull/13323,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **566/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzYWE2MzZiYi00NmJmLTQ3MjgtOGVjMC0yMDg0OWE4NzgyZGMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZC",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13444:992,avail,available,992,https://hail.is,https://github.com/hail-is/hail/pull/13444,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; matplotlib 3.5.3 requires numpy, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5NmE4NGVhMS1hYzgxLTQxYmEtOGYzNC02MGU1ZTdhYzNjZTMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnR",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12896:972,avail,available,972,https://hail.is,https://github.com/hail-is/hail/pull/12896,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1NDMwZTFmMi0wNDZjLTQwNDctYmI3Mi1hZmJkZmM1MDViNGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjU0MzBlMWYyLTA0NmMtNDA0Ny1iYjcyLWFmYmRmYzUwNWI0YSJ9fQ=="" width=""0"" height=""0""/>;  ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13304:862,avail,available,862,https://hail.is,https://github.com/hail-is/hail/pull/13304,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwMzdiOGRmZS1hZDA4LTRmZjUtYTFkOC1hNGM4Nzg2N2NkYjAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjAzN2I4ZGZlLWFkMDgtNGZmNS1hMWQ4LWE0Yzg3ODY3Y2RiMCJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13159:868,avail,available,868,https://hail.is,https://github.com/hail-is/hail/pull/13159,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4YTljZTU5Zi0yOTY3LTQ2MTQtOGE5YS1iY2M5YjU1ZWZkZGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjhhOWNlNTlmLTI5NjctNDYxNC04YTlhLWJjYzliNTVlZmRkZCJ9fQ=="" width=""0"" height=""0""/>;  [View late",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13282:894,avail,available,894,https://hail.is,https://github.com/hail-is/hail/pull/13282,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **661/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 7.5 | Relative Path Traversal <br/>[SNYK-PYTHON-ORJSON-6276643](https://snyk.io/vuln/SNYK-PYTHON-ORJSON-6276643) | `orjson:` <br> `3.9.7 -> 3.9.15` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3YTljMjVmNy0wMTBmLTQxNmItYjc0OS1jNzFkY2I4YjY5YjgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdhOWMyNWY3LTAxMGYtNDE2Yi1iNzQ5LWM3MWRjYjhiNjliOCJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](https://app.snyk.io",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14361:857,avail,available,857,https://hail.is,https://github.com/hail-is/hail/pull/14361,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14045:887,avail,available,887,https://hail.is,https://github.com/hail-is/hail/pull/14045,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **763/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 7.4 | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `41.0.1 -> 41.0.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwMjJhZDMzNS1kYzBkLTQxZWYtYmRjYi03ZTFkODQwNWJhYTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjAyMmFkMzM1LWRjMGQtNDFlZi1iZGNiLTdlMWQ4NDA1YmFhNiJ9fQ=="" width=""0"" height=""0""/>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13247:882,avail,available,882,https://hail.is,https://github.com/hail-is/hail/pull/13247,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkY2E2ZDI1ZC1hZGM3LTRiNTctYWU3Zi0yNjExOTYzNTY5MmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImRjYTZkMjVkLWFkYzctNGI1Ny1hZTdmLTI2MTE5NjM1NjkyZSJ9fQ=="" width=""0"" height=""0""/>;  [View la",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13294:854,avail,available,854,https://hail.is,https://github.com/hail-is/hail/pull/13294,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `40.0.2 -> 41.0.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhYmU2OWI5ZC1kMzViLTQ1Y2ItYWY2NS04ZDEwN2YxZWMzZmMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFiZTY5YjlkLWQzNWItNDVjYi1hZjY1LThkMTA3ZjFlYzNmYyJ9fQ=="" width=""0"" height=""0""/>;  [View latest project repor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13139:860,avail,available,860,https://hail.is,https://github.com/hail-is/hail/pull/13139,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlNDQxZTBmNS1jZDQ4LTQzZDUtYTdkMy1kMTM4YzQ2ZTc2NTgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU0NDFlMGY1LWNkNDgtNDNkNS1hN2QzLWQxMzhjNDZlNzY1OCJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](https://app.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13158:860,avail,available,860,https://hail.is,https://github.com/hail-is/hail/pull/13158,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMjk5ZmU1Ni0wNGI1LTQ3MzEtYmUzYS03M2ZmYzgxZTZjYjgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUyOTlmZTU2LTA0YjUtNDczMS1iZTNhLTczZmZjODFlNmNiOCJ9fQ=="" width=""0"" height=""0""/>;  [View latest proje",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13283:886,avail,available,886,https://hail.is,https://github.com/hail-is/hail/pull/13283,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - web_common/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjZmU2NDEwYi1jYjQ3LTQ2YzgtOTYwYy1kOWRlY2UxMjI5ZTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImNmZTY0MTBiLWNiNDctNDZjOC05NjBjLWQ5ZGVjZTEyMjllMiJ9fQ=="" width=""0"" height=""0""/>;  [View latest projec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13286:885,avail,available,885,https://hail.is,https://github.com/hail-is/hail/pull/13286,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - web_common/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14036:885,avail,available,885,https://hail.is,https://github.com/hail-is/hail/pull/14036,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - web_common/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; aiosignal 1.3.1 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `3.1.2 -> 3.1.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlYTQ5ODFkZC02M2FmLTQ4YzYtYTIwMC05NjkyZjg2ZTlhNjIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14140:991,avail,available,991,https://hail.is,https://github.com/hail-is/hail/pull/14140,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - web_common/requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; aiohttp-jinja2 1.5.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;) <br/>[SNYK-PYTHON-AIOHTTP-6209406](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209406) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **718/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-6209407](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209407) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14225:986,avail,available,986,https://hail.is,https://github.com/hail-is/hail/pull/14225,1,['avail'],['available']
Availability,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - web_common/requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; aiohttp-jinja2 1.5.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14037:1012,avail,available,1012,https://hail.is,https://github.com/hail-is/hail/pull/14037,1,['avail'],['available']
Availability,"= self.gateway_client.send_command(command); -> 1304 return_value = get_return_value(; 1305 answer, self.gateway_client, self.target_id, self.name); 1306 . /databricks/spark/python/pyspark/sql/utils.py in deco(*a, **kw); 115 def deco(*a, **kw):; 116 try:; --> 117 return f(*a, **kw); 118 except py4j.protocol.Py4JJavaError as e:; 119 converted = convert_exception(e.java_exception). /databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 324 value = OUTPUT_CONVERTER[type](answer[2:], gateway_client); 325 if answer[1] == REFERENCE_TYPE:; --> 326 raise Py4JJavaError(; 327 ""An error occurred while calling {0}{1}{2}.\n"".; 328 format(target_id, ""."", name), value). Py4JJavaError: An error occurred while calling o504.pyPersistTable.; : is.hail.utils.HailException: 1 samples and 12 covariates (including x) implies -11 degrees of freedom.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:11); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:11); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.methods.LinearRegressionRowsSingle.execute(LinearRegression.scala:51); 	at is.hail.expr.ir.functions.WrappedMatrixToTableFunction.execute(RelationalFunctions.scala:51); 	at is.hail.expr.ir.TableToTableApply.execute(TableIR.scala:2936); 	at is.hail.expr.ir.TableIR.analyzeAndExecute(TableIR.scala:57); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:27); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyPersistTable$2(SparkBackend.scala:502); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:46); 	at is.hail.backend.spark.SparkBackend.withExecu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11413:3851,Error,ErrorHandling,3851,https://hail.is,https://github.com/hail-is/hail/issues/11413,1,['Error'],['ErrorHandling']
Availability,"=""https://redirect.github.com/python-pillow/Pillow/issues/7497"">#7497</a> [<a href=""https://github.com/ZachNagengast""><code>@ZachNagengast</code></a>]</li>; <li>Add .git-blame-ignore-revs file <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7528"">#7528</a> [<a href=""https://github.com/akx""><code>@akx</code></a>]</li>; <li>Attempt memory mapping when tile args is a string <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7565"">#7565</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Fill identical pixels with transparency in subsequent frames when saving GIF <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7568"">#7568</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Removed unnecessary string length check <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7560"">#7560</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Determine mask mode in Python instead of C <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7548"">#7548</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Corrected duration when combining multiple GIF frames into single frame <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7521"">#7521</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Handle disposing GIF background from outside palette <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7515"">#7515</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Seek past the data when skipping a PSD layer <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7483"">#7483</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>ImageMath: Inline <code>isinstance</code> check <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7623"">#7623</a> [<a href=""https://git",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14191:5093,mask,mask,5093,https://hail.is,https://github.com/hail-is/hail/pull/14191,3,['mask'],['mask']
Availability,"=======================> (222 + 80) / 353]; 	[PASS] with 353 partitions: (50000, 973); 	2020-06-10 10:30:15 Hail: INFO: balding_nichols_model: generating genotypes for 1 populations, 1000 samples, and 50000 variants...; 	[Stage 9:> (0 + 18) / 18]; 	[FAIL] with 354 partitions; 	Traceback (most recent call last):; 	 File ""test_11_cluster_sampleqc.py"", line 20, in <module>; 		print(""\n[PASS] with"", N, ""partitions:"", Y.count()); 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/matrixtable.py"", line 2426, in count; 		return Env.backend().execute(count_ir); 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/backend/spark_backend.py"", line 296, in execute; 		result = json.loads(self._jhc.backend().executeJSON(jir)); 	 File ""/bmrn/apps/spark/2.4.5/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/backend/spark_backend.py"", line 41, in deco; 		'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 	hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: ResultStage 9 (runJob at RVD.scala:688) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:882) at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:878) at scala.collection.Iterator$class.foreach(Iterator.scala:891) at scala.collection.AbstractIterator.foreach(Iterator.scala:1334) at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:878) at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:691) at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) at org.apache.spark.rdd.ShuffledRD",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:3628,Error,Error,3628,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['Error'],['Error']
Availability,"=main.go:326 vm_limits=""(soft=unlimited, hard=unlimited)""; level=info ts=2019-07-31T15:45:51.993Z caller=main.go:645 msg=""Starting TSDB ...""; level=info ts=2019-07-31T15:45:51.994Z caller=web.go:417 component=web msg=""Start listening for connections"" address=0.0.0.0:9090; level=info ts=2019-07-31T15:45:51.996Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563105600000 maxt=1563170400000 ulid=01DFTDRJHCX1S9B0KPJTG8CRGW; level=info ts=2019-07-31T15:45:51.997Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563170400000 maxt=1563235200000 ulid=01DFWBK0336Z71ZCRRKS79T18P; level=info ts=2019-07-31T15:45:51.997Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563235200000 maxt=1563300000000 ulid=01DFY9C92NRA1S7FDVHFRFMFPF; level=info ts=2019-07-31T15:45:51.998Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563300000000 maxt=1563364800000 ulid=01DG075GN2MME91GM1DA5G3H07; level=info ts=2019-07-31T15:45:51.999Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563364800000 maxt=1563429600000 ulid=01DG24Z1SDJ7VXW96YYSY1FC8Y; level=info ts=2019-07-31T15:45:51.999Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563429600000 maxt=1563494400000 ulid=01DG42SDMFEK1AJPRJ5YWKZFJ8; level=info ts=2019-07-31T15:45:52.000Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563494400000 maxt=1563559200000 ulid=01DG60K1ADH2GGZ6ZHYVRQA7PQ; level=info ts=2019-07-31T15:45:52.001Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563559200000 maxt=1563624000000 ulid=01DG7YBCA5FFBKYXX7EADE91TP; level=info ts=2019-07-31T15:45:52.001Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563624000000 maxt=1563688800000 ulid=01DG9W4WYEDBQ32Q112S7EPMEP; level=info ts=2019-07-31T15:45:52.002Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563688800000 maxt=1563753600000 ulid=01DGBSYJDGQ8NY58106XGFT7CS; level=info ts=2019",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6773:4085,repair,repair,4085,https://hail.is,https://github.com/hail-is/hail/issues/6773,1,['repair'],['repair']
Availability,"> (0 + 16) / 292]Traceback (most recent call last):; File ""/restricted/projectnb/ukbiobank/ad/analysis/ukb.v3/bgen_count.py"", line 13, in <module>; print(""Count:"",mt.count()); File ""/restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 2131, in count; File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 210, in deco; hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: Task 7 in stage 0.0 failed 4 times, most recent failure: Lost task 7.3 in stage 0.0 (TID 86, scc-q16.scc.bu.edu, executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Slave lost; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 0.0 failed 4 times, most recent failure: Lost task 7.3 in stage 0.0 (TID 86, scc-q16.scc.bu.edu, executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Slave lost; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(O",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572:8063,failure,failure,8063,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572,1,['failure'],['failure']
Availability,"> **Why?** | Buffer Overflow <br/>[SNYK-PYTHON-NUMPY-2321966](https://snyk.io/vuln/SNYK-PYTHON-NUMPY-2321966) | `numpy:` <br> `1.21.3 -> 1.22.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **/1000** <br/> **Why?** | Denial of Service (DoS) <br/>[SNYK-PYTHON-NUMPY-2321970](https://snyk.io/vuln/SNYK-PYTHON-NUMPY-2321970) | `numpy:` <br> `1.21.3 -> 1.22.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13871:3620,avail,available,3620,https://hail.is,https://github.com/hail-is/hail/pull/13871,1,['avail'],['available']
Availability,"> +1,738 -2,452. Sorry :-(. High level summary changes:; - batch and batch2: Removed /batch endpoint limit and offset options, added include_jobs. Limit was ever only 0 or None. Going forward, /batch should never return jobs, and /jobs endpoint should always paginate.; - Got rid of pods. There is no pod_status options on the client, but they are left in for legacy reasons (batch).; - Simplified worker startup and cleaned up logging paths. The old code could restart the worker after a failure after it had activated. I don't think we're equipped for that case. I do explicitly pull the worker image (with one retry) before trying to run it.; - Batch and Job are gone. database.py is effectively gone. Almost everywhere interacts directly with the database using the simple gear.Database interface, and drops down to aiomysql directly when that is insufficient (e.g. transaction with multiple executemany for /jobs/create). When we pass around data representing a job or batch, it's normally a data record (a dict).; - Added the running log test from your PR.; - The job status is no longer written to a file, just in the database jobs.status.; - I moved the INSTANCE_ID to the database. There is now a table called tokens. It has the instance id and a token for securing communication between the front end and the driver (currently unused).; - Operations that need to be atomic in the database are now implemented as stored procedures which can be called with the check_call_procedure helper in database.py. They return a row with a field rc (return code) that is 0 on success and non-zero on failure.; - Renamed Driver => Scheduler. Scheduler has two threads, one that schedules jobs that are in the Ready state, and one that cancels cancelled jobs in the Running state. There is a new job state Ready. A job is Ready if its parents are complete and it is not scheduled (instance_id is null). A job is Running if it is scheduled (instance_id is not null).; - The full set of instances are mirror",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7420:489,failure,failure,489,https://hail.is,https://github.com/hail-is/hail/pull/7420,2,"['down', 'failure']","['down', 'failure']"
Availability,"> 500 is meaningless, docker returns 500 for everything. I'm quite concerned about infinite retry loops here, and I'd rather have documentation on the errors we're getting from docker if possible. OK, I can add the two other failures I found, but it's infuriating to get most of the way through 100k jobs and then have one fail for some new 500. It feels like there's a long tail of rare docker errors.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7783#issuecomment-568581120:151,error,errors,151,https://hail.is,https://github.com/hail-is/hail/pull/7783#issuecomment-568581120,3,"['error', 'failure']","['errors', 'failures']"
Availability,"> > I should fix it!; > ; > That'd be awesome!; > ; > Yes, the steps are steps from build.yaml. Some background on the current setup, there are two classes of deployed stuff: normal, and ""infrastructure"". Infrastructure is stuff that can't be virtualized (or we've chosen not to) within the k8s cluster and can't be tested with the current CI setup. An example is gateway, that binds the live IP address for hail.is. Infrastructure will need a ""meta"" testing setup that will spin up another k8s cluster or testing in a separate staging cluster, where taking down the test cluster isn't an issue. Obviously, we haven't built this yet. Thank you for the background. Makes sense",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7015#issuecomment-540035311:558,down,down,558,https://hail.is,https://github.com/hail-is/hail/pull/7015#issuecomment-540035311,1,['down'],['down']
Availability,"> > I think I'm seeing more where this approach is coming from, specifically we put batches as they exist today in a special category of having no updates and avoid the new code path in that case. An alternative which pairs with my above suggestion of not adding new staging tables is that all batches have at least 1 update. I feel like if we can force all batches down the new code path we'll be incentivized to make it really low overhead for batches that only submit jobs once, and that will benefit all batches, as well as simplifying the mental model. I may be wrong that we can do this with minimal performance tradeoff, but I'd like to try it first.; > ; > Can you elaborate more? I'm not sure which code paths you are referring to. Mainly that the commit procedure branches on whether the start id is 1 and that we sometimes grab the update id from the batch token and sometimes from the update table. Not very different code paths but slightly different, which could lead to some confusion.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12010#issuecomment-1220825403:366,down,down,366,https://hail.is,https://github.com/hail-is/hail/pull/12010#issuecomment-1220825403,1,['down'],['down']
Availability,"> @lgruen are y'all running with this change now? I was vaguely concerned that with ~32 JVMs alive that would negatively impact the machine. Do you find that the JVM's RAM gets swapped out and the machines are generally stable?. Yes, we haven't seen any issues with this so far, but also have only been running with this change for a few days.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12248#issuecomment-1267773430:93,alive,alive,93,https://hail.is,https://github.com/hail-is/hail/pull/12248#issuecomment-1267773430,1,['alive'],['alive']
Availability,> @tpoterba do we think this is the actual cause of the 2.4.2 incompatibility?. Didn't you see things fail on initialization? That's not related to serialization. > how do we verify this fixes the issues our users are seeing?. The people seeing those errors are using jars not compiled for the version of Spark (and json4s) they have installed. I don't think we need to test for this case.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5958#issuecomment-486844526:251,error,errors,251,https://hail.is,https://github.com/hail-is/hail/pull/5958#issuecomment-486844526,1,['error'],['errors']
Availability,"> A user reported this error concurrent.futures._base.TimeoutError with no stack trace while copying files in a batch job. . This. No stack trace. If you look at this output, the previous stack trace is part of the WARNING message. ```; INFO:deploy_config:deploy config file not found: None; INFO:hailtop.aiocloud.aiogoogle.credentials:using credentials file /gsa-key/key.json: GoogleServiceAccountCredentials for XXXXX@PROJECT.iam.gserviceaccount.com; WARNING:hailtop.utils:Encountered 2 errors (current delay: 0.2). My stack trace is File ""/usr/lib/python3.7/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/usr/lib/python3.7/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/usr/local/lib/python3.7/dist-packages/hailtop/aiotools/copy.py"", line 128, in <module>; asyncio.run(main()); File ""/usr/lib/python3.7/asyncio/runners.py"", line 43, in run; return loop.run_until_complete(main); File ""/usr/local/lib/python3.7/dist-packages/hailtop/utils/utils.py"", line 735, in retry_transient_errors; st = ''.join(traceback.format_stack()); . Most recent error was; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/dist-packages/hailtop/utils/utils.py"", line 729, in retry_transient_errors; return await f(*args, **kwargs); File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 134, in request_and_raise_for_status; resp = await self.client_session._request(method, url, **kwargs); File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 634, in _request; break; File ""/usr/local/lib/python3.7/dist-packages/aiohttp/helpers.py"", line 721, in __exit__; raise asyncio.TimeoutError from None; concurrent.futures._base.TimeoutError; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11817#issuecomment-1117642330:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/pull/11817#issuecomment-1117642330,3,['error'],"['error', 'errors']"
Availability,"> Ah sorry, I forgot to update the original commit message as that's not actually correct. The optimization is that we don't need to iterate through all blobs until we find the exact blob matching our path name. The list operation returns all blobs that start with the prefix of that path. If we see a blob with a different name that is a child of our path f'{path}/foo, then we know it's a directory and don't need to iterate anymore (although it could be a file as well, but in Scala we don't currently throw errors on paths that are both files and directories, so we just choose the first we see). If we see a blob that matches the path exactly, then we know it's a file and stop iterating. The only reason we need to iterate through more than one blob is if there's blobs that are like '{path}zzzzz/foo or '{path}szzzzz. We need to ignore these as they don't provide any information on whether {path} is a file or directory. This is where isChildOf is needed because we need to make sure the blob is actually a child of the path such as '{path}/file and not {path}zzzzz/file. Ah thanks, this makes more sense to me now. > The other option is to do 2 queries. One to check if it's a file and the next to check if there are any child blobs. This does sound simpler conceptually. I'm not sure off the top of my head what is better performance-wise: the two network requests for a directory or loading a whole page of results in a single request when we only need max 2 results. What do you prefer?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13390#issuecomment-1677489464:511,error,errors,511,https://hail.is,https://github.com/hail-is/hail/pull/13390#issuecomment-1677489464,1,['error'],['errors']
Availability,"> Almost by definition I'd suspect that adding a system administrator is a high security impact (that's not a judgement on you, just a statement about the security boundary getting wider).; > ; > This is obviously fine in this case because we want you to be a system administrator, but we should let appsec know regardless. They'll also probably want to send you some standard trainings (and maybe background check forms?). I'll ping them. Ah right that's an extremely fair point. Should I put ""high"" back in this PR description, or just sit tight until I hear from appsec?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14717#issuecomment-2400720230:429,ping,ping,429,https://hail.is,https://github.com/hail-is/hail/pull/14717#issuecomment-2400720230,1,['ping'],['ping']
Availability,"> Also all the tests need to be fixed. Yep, working on it. Serialization failures.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083#issuecomment-491423599:73,failure,failures,73,https://hail.is,https://github.com/hail-is/hail/pull/6083#issuecomment-491423599,1,['failure'],['failures']
Availability,"> Also, it looks like we didn't define the operator syntax. Sounds like an easy PR to farm out to someone else!. @danking I intentionally didn't add this yet - there is a case I am worried about:. ```; mt.filter_rows(mt.pass & mt.variant_qc.AF[1] > 0.01); ```. Right now this is a type error. With bit operators, this is the same as:. ```; mt.filter_rows((hl.bit_and(hl.int(mt.pass), mt.variant_qc.AF[1]) > 0.01); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5149#issuecomment-454835409:286,error,error,286,https://hail.is,https://github.com/hail-is/hail/pull/5149#issuecomment-454835409,1,['error'],['error']
Availability,"> Are there any CSS conventions within Hail? I assume I need to migrate the ad-hoc ""style"" tags into CSS?. See the PR #14562 where Daniel introduced the new UI. He decided to use [tailwind](https://tailwindcss.com), which apparently (I don't know much about frontend stuff) prefers to keep styling in the html. > I've moved the status indicator to the front of the line. Is that ok?. I like it. > I'm not really sure I like the change to Pending. Curious for others' thoughts. In the template do we have the number of running jobs available? If so maybe we split ""Pending"" into ""Pending"" and ""Running"". Otherwise I think this is fine.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14640#issuecomment-2274259369:531,avail,available,531,https://hail.is,https://github.com/hail-is/hail/pull/14640#issuecomment-2274259369,1,['avail'],['available']
Availability,"> Banning versions completely is a little tricky because the user can specify a JAR url directly instead of a version. JARs don't currently have a simple way to report pip version to the worker, though we could cook something up. We could also just delete the old JARs. I feel like we should make a (cached) request to ensure that the JAR exists in the front-end upon job submission and return a 400 if it doesn't exist instead of waiting for the worker to error. It would:. - Allow us to remove support by deleting old jars; - Fail fast (I know I have accidentally messed up deploying a dev jar and had to wait until a worker came online to find out); - Avoid alerts from workers that can't find dev jars due to mistakes like I mention above",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12941#issuecomment-1529754664:457,error,error,457,https://hail.is,https://github.com/hail-is/hail/pull/12941#issuecomment-1529754664,1,['error'],['error']
Availability,"> But I'm confused because I thought that was the same as my initial implementation. Sorry, don't read too much into my first few comments, I was trying to understand the constraints. I think my last comment is very close to your original proposal, but also includes Running -> Error and Running -> Ready as possible transitions.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6268#issuecomment-499651541:278,Error,Error,278,https://hail.is,https://github.com/hail-is/hail/pull/6268#issuecomment-499651541,1,['Error'],['Error']
Availability,"> Can we dummy proof this a bit more to have a nice error message if this is not the case?. Happy to, but I'm not exactly sure what you mean by ""if this is not the case"". What would you like to add?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13180#issuecomment-1593184582:52,error,error,52,https://hail.is,https://github.com/hail-is/hail/pull/13180#issuecomment-1593184582,1,['error'],['error']
Availability,"> Can you lock down this behaviour with a test?. As I said in the description, I tried hard to write a test, but I couldn't manage to find a way to exercise this with a targeted test. And this bug is currently blocking a user, so I want to get it released asap. I can try again, but I suspect it would end up being a day or two of extra work, and would likely still end up brittle and unsatisfactory. I'd rather spend my effort getting back into the line of work that would eventually make it much easier to target specific compiler code paths.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14673#issuecomment-2338662541:15,down,down,15,https://hail.is,https://github.com/hail-is/hail/pull/14673#issuecomment-2338662541,1,['down'],['down']
Availability,"> Could you explain why you think the boundary is invalid?. Boundary can only be used by consumers who generate an iterator with a new context. Here we were just inserting a clear before each next(), no matter who was consuming the iterator. The particular pipeline that triggered this error was a TableMapPartitions with a ToArray(Ref rows) after an IR with a repartitionedOrderedRDD2",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9425#issuecomment-689597263:286,error,error,286,https://hail.is,https://github.com/hail-is/hail/pull/9425#issuecomment-689597263,1,['error'],['error']
Availability,"> Dan's OOO this week. It's a Python lint failure:. Thanks very much, @tpoterba! Should hopefully be better now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10647#issuecomment-876805713:42,failure,failure,42,https://hail.is,https://github.com/hail-is/hail/pull/10647#issuecomment-876805713,1,['failure'],['failure']
Availability,"> Did you copy the the oath2 key to your namespace? You need to do that for the auth service to boot. This is probably a cascaded failure because auth is down. I think I have what I need. I have a ~/.hail/token and ~/.hail/tokens.json. The token file looks like a jwt, decodes to ""email"": ""ako"" followed by some low-ascii characters. . Before I ran this I logged in using hailctl auth login.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7064#issuecomment-532256223:130,failure,failure,130,https://hail.is,https://github.com/hail-is/hail/pull/7064#issuecomment-532256223,2,"['down', 'failure']","['down', 'failure']"
Availability,"> Did you ssh to CI, start a python session, start a batch client, and delete it in that manner?. Yes. And the CI status (https://ci.hail.is/watched_branches/0/pr/6561) continued to error out with 500s (caused by batch lookup 404s in the logs) even after a heal loop.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6582#issuecomment-509627134:182,error,error,182,https://hail.is,https://github.com/hail-is/hail/issues/6582#issuecomment-509627134,1,['error'],['error']
Availability,"> Do we insert finally blocks and clean up our open streams when an exception bubbles through generated code?. Nope. We can add this pretty easily now, I added infrastructure to HailTaskContexts for task-owned resources. Maybe I misunderstand Google write channels -- how would a stale writer to a different object cause this failure? I'm interpreting ""session"" here as a specific object destination, is that wrong?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1531672420:326,failure,failure,326,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1531672420,1,['failure'],['failure']
Availability,"> Done, however this is a bit awkward, and I suspect a source of future error, because in order to pStringInstance.allocate you need to know the byte length, not the string/code point length. So I thought to make allocate take a string instead of length. However, if you have the string at the time of allocation, and pass it to allocate, you probably intend to store it, in which case you pay the cost of 2x the number of calls to getBytes. Therefore I made an allocateAndStoreString method, which takes care of both steps, potentially more efficiently, but also more ergonomically. PString.allocate probably shouldn't exist, then! The public interfaces to PString probably need to include the ability to copy value=>value (address) and to put a string in a region.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7904#issuecomment-576358719:72,error,error,72,https://hail.is,https://github.com/hail-is/hail/pull/7904#issuecomment-576358719,1,['error'],['error']
Availability,"> Drive by comment here as I review PRs, but this is The Python Way, for better or worse. People call it ""easer to ask forgiveness than permission"". I don't personally have strong feelings one way or the other but we do this in many places in our codebase. Be that as it may, throwing if something does not exist is clearer and more robust that catching an error because some operation failed for what is arguably unexceptional, and just hoping that the `KeyError` that that operation threw is because the item did not exist, rather than another `KeyError` risen in any subsequent work.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12864#issuecomment-1516489544:333,robust,robust,333,https://hail.is,https://github.com/hail-is/hail/pull/12864#issuecomment-1516489544,2,"['error', 'robust']","['error', 'robust']"
Availability,"> First, I'm seeing transient (but common, maybe 10% of the time?! Have you seen this before, Jackie?) gsutil errors in the setup/cleanup containers that look like: [Errno 2] No such file or directory. Nope. But I didn't run many tests with setup/cleanup containers actually doing anything.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7445#issuecomment-549184176:110,error,errors,110,https://hail.is,https://github.com/hail-is/hail/pull/7445#issuecomment-549184176,1,['error'],['errors']
Availability,"> Having the Auth service ping the Batch API with it to verify the token is valid. I believe the way our CRSF is implemented, we don't actually ever ""validate"" the tokens, we only check that the token in the formdata matches the token in the cookie. > Or perhaps we could just make this UI a single page application instead of a bunch of pages on different subdomains that resemble one. . This would be wonderful! Sort of similar-but-better to my thought of hosting the ""top menu bar"" as a separate iframe that always comes from auth. For the same reason (in particular, the apparently lack of regular usage of the logout button), that kind of change is probably larger than the scope of getting this bug fixed... but would cool to look into some day!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14639#issuecomment-2269645369:26,ping,ping,26,https://hail.is,https://github.com/hail-is/hail/pull/14639#issuecomment-2269645369,1,['ping'],['ping']
Availability,"> Hi @daniel-goldstein. I've taken a look at a few of the records in this table in prod. Do you know what it means to have negative values for `n_running_cancellable_jobs` and/or `running_cancellable_cores_mcpu`? Here's an example:; > ; > ; > ; > ```sql; > ; > select * from job_group_inst_coll_cancellable_resources where batch_id = X;; > ; > +----------+-------+--------------------------+------------------------------+----------------------------+--------------------------------+-----------+-----------------------------+-----------+--------------+; > ; > | batch_id | token | n_ready_cancellable_jobs | ready_cancellable_cores_mcpu | n_running_cancellable_jobs | running_cancellable_cores_mcpu | inst_coll | n_creating_cancellable_jobs | update_id | job_group_id |; > ; > +----------+-------+--------------------------+------------------------------+----------------------------+--------------------------------+-----------+-----------------------------+-----------+--------------+; > ; > | X | 0 | 0 | 0 | 0 | 0 | standard | 0 | 1 | 0 |; > ; > | X | 18 | 0 | 0 | -1 | -2000 | standard | 0 | 1 | 0 |; > ; > | X | 59 | 0 | 0 | 0 | 0 | standard | 0 | 1 | 0 |; > ; > | X | 60 | 0 | 0 | -1 | -2000 | standard | 0 | 1 | 0 |; > ; > | X | 74 | 0 | 0 | 0 | 0 | standard | 0 | 1 | 0 |; > ; > | X | 172 | 0 | 0 | 0 | 0 | standard | 0 | 1 | 0 |; > ; > | X | 185 | 0 | 0 | -1 | -1000 | standard | 0 | 1 | 0 |; > ; > +----------+-------+--------------------------+------------------------------+----------------------------+--------------------------------+-----------+-----------------------------+-----------+--------------+; > ; > ```; > ; > . Good question, looks like a bug to me as these records should eventually settle to sum to 0. Are these from recent batches? Hopefully this is some bug that has already been fixed but these rows were never cleaned up. I'd also check the code around `schedule_job` to see if any additions to this table aren't fault tolerant.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14623#issuecomment-2254138069:1948,fault,fault,1948,https://hail.is,https://github.com/hail-is/hail/issues/14623#issuecomment-2254138069,2,"['fault', 'toler']","['fault', 'tolerant']"
Availability,"> Hi Ivan! Thanks so much for picking this up :) I haven't much experience on the batch system but I'll try my best to give accurate feedback. I have a few questions/observations up front:; > ; > 1. Your changes to stored procedures under `batch/sql` make me a little nervous.; > ; > Most of these are migrations applied in the order defined in the build step mentioned in [NOTE 1] except `estimated-current.sql` [NOTE 2].; > ; > I don't think changing these will have the desired effect and may make it impossible for someone to reproduce the database. The only changes to _existing_ sql you'll need to make are in the sql strings in python code.; > ; > 2. This needs to be written as a migration and maybe could be simplified?; > ; > I think this needs to be done as a database migration. We'll have no need for a stored procedure once complete. You can assume current columns and constraints exist, dispense with the error checking and simplify. Can you convert this to a sql script and add it to the end of the list of migrations in `build.yaml`? You'll probably want `online: false` too. I fear you'll have to take inspiration from `rename-job-groups-tables.sql` by applying one `ALTER TABLE` command then drop and recreate EVERYTHING that references that name (constraints, triggers, procedures etc). This will likely involve copy+paste and rename. Alternatively, create, execute then drop the procedure within `rename-job-groups-cancelled`.; > ; > [NOTE 1] migration applied in `build.yaml`; > ; > The relevant build step in `build.yaml` can be found by searching for the entry starting with the yaml below. This controls which migrations are applied and in what order.; > ; > ```yaml; > kind: createDatabase2; > name: batch_database; > databaseName: batch; > ```; > ; > [NOTE 2] estimated-current.yaml; > ; > I don't agree with why we have this. It would be nice to generate this automatically. Anyway, please keep your changes to this file as it's meant for documentation purposes only. None ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14672#issuecomment-2334778045:920,error,error,920,https://hail.is,https://github.com/hail-is/hail/pull/14672#issuecomment-2334778045,1,['error'],['error']
Availability,"> High level question: is the state stored in MySQL the same as the k8s notebook pod state? If so, should we just query k8s rather than duplicating the notebook state in MySQL?. Not entirely the same I think, but I also prefer tools that are well-designed for the purpose, and have limited k8 / etcd experience / survivor bias. One interesting fact (spoke with Dan), is that we don't have direct access to etcd, so are limited to k8 client operations. * We had talked about, in batch context, of having our own master state, against which k8 is reconciled, to protect against k8 operational errors. Obviously that means our record of state is a point of failure, but db failure modes and uptime solutions are well defined across cloud/db provider vendors (we can minimize lock-in as well). The idea seemed to be that we don't particularly care how k8 works, or how much state it persists; the contract is with our users, and we should satisfy . * K8 does not store all state indefinitely. It's more like a rotating log: https://stackoverflow.com/questions/40636021/how-to-list-kubernetes-recently-deleted-pods . For users, and for investors, we want to have a permanent record of all user interactions. * Some kinds of data may be awkward to store and query within pod labels. For instance, how much user state do we want to store in labels? How do we store operation graphs / history?; ; * aggregation operations across users or resources; * a given, or all users' history: so the user can manage, see, so we can track (some, gross) metrics for billing; * various sorting operations (by date/time, etc); * full log of state for a given set of related resources (I think k8 stores last 5 events, this is probably configurable) ; ability to retry in a user-controlled way, even if pod is deleted from etcd. * Operations across N k8 resources seems like it may take up to N queries (i.e k8s.list_namespaced_service, k8s.list_namespaced_pod). There may be more efficient ways of handling this (there eith",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-459054290:591,error,errors,591,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-459054290,3,"['error', 'failure']","['errors', 'failure']"
Availability,"> How about underlining it?. Nice suggestion. I hadn't done this because placing the underline on the li increased the height of the element, again requiring negative margin. But, on display: inline elements, border doesn't affect height, so the solution is just to place it there. CSS. I've also improved the javascript function to be more robust; before it would have considered /docs/0.2/index.html as home. It now matches the `pathname` of the anchor tag and location. This is just the right way to do it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8455#issuecomment-609911680:341,robust,robust,341,https://hail.is,https://github.com/hail-is/hail/pull/8455#issuecomment-609911680,1,['robust'],['robust']
Availability,"> I agree this is the most compelling critique. I think the Pythonistas would make two points: a) KeyError is the one specific error you get in this case and b) it should be written like this:; > ; > ```python; > try:; > persisted_bm = self._persisted_locations[bm]; > except KeyError as err:; > raise ValueError(f'{bm} is not persisted') from err; > persisted_bm.__exit__(None, None, None); > ```. Updated my comment - I think my argument still holds with `KeyError`. Furthermore, you're still leaving around state in that dict, opening yourself up to calling `__exit__` twice.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12864#issuecomment-1516535470:127,error,error,127,https://hail.is,https://github.com/hail-is/hail/pull/12864#issuecomment-1516535470,1,['error'],['error']
Availability,"> I agree users should have `storage.buckets.get` only to their own folder, and not `storage.buckets.get`. However, it looks like it is trying to create a bucket with the new folder name, and failing against that (non-existent) bucket:; > ; > > exceptions.from_http_response(response) google.api_core.exceptions.Forbidden: 403 GET https://www.googleapis.com/storage/v1/b/untitled-folder?projection=noAcl: [user-nrru16jaxrwmnzkv5f35xfibg@hail-vdc.iam.gserviceaccount.com](mailto:user-nrru16jaxrwmnzkv5f35xfibg@hail-vdc.iam.gserviceaccount.com) does not have storage.buckets.get access to untitled-folder.; > ; > That's untitled-folder. Maybe the error is not permissions at all, but it is using the wrong base directory to create the folder?. Right, I mentioned this above. It appears to be trying to create, or trying to read, untitled_folder as a bucket. If you trick it into using /your_bucket_name as the cwd, folder creation works.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5788#issuecomment-480381353:645,error,error,645,https://hail.is,https://github.com/hail-is/hail/pull/5788#issuecomment-480381353,1,['error'],['error']
Availability,"> I almost went down this route. It would save a couple lines of tar/untar in runImage steps. I felt the savings wasn't worth the effort of implementing it. In the buildImage case (what this PR addressed), I think it's worth it to keep images small. The point isn't to save the few untars, the point is to make the general facilities performant for everyone. Basically, I think directory outputs are untenable in the current design unless they are very small, which is why you're doing all this for your use case, and the tar is still probably as good (if not better) in that case. Fix it for everyone's use case so nobody has to go through this in the future.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7626#issuecomment-560459474:16,down,down,16,https://hail.is,https://github.com/hail-is/hail/pull/7626#issuecomment-560459474,1,['down'],['down']
Availability,"> I can't make create idempotent, it returns a fresh batch id. I'm saying we can (and should, for all such requests) make /batches/create idempotent by having the client generate a random token that it includes in the POST request to create a batch. The create batch code then first checks a batch exists with the random string and returns that id if it exists before deciding to create a fresh batch. > I did make jobs/create idempotent, but if you have 10M jobs, I don't want the client to regenerate a 10M job DAG (which takes longer than the submits do). I'm not sure I understand the alternative you're considering in the second half of this statement. > A missing internet connection is apparently considered ""transient"". Yes. Transient just means the expectation is that the error will eventually go away. Most computers usually get hooked up to the internet again. My mental model for transient errors is like this: there are two types of transient errors, short and long. Short transient errors occur sporadically with some very low probability p (so that two such such transient errors will almost occur twice in a row). The other is a long transient error like a service going down and waiting for a liveness check to notice and restart, internet connection going down, or laptop being losing wifi connection, being moved, etc. For the first type, you want to retry immediately. For the second, you want to retry with exponential backoff. I think the PR that introduced logging for retry went in when I was gone. I think it should follow the same strategy: I would log always on the second failure, and then with exponential backoff. Same with the batch client. > I allow the user to say they don't want that. Fine. I'm saying I want the default to be infinite. I doubt anyone will ever change it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7875#issuecomment-574400367:782,error,error,782,https://hail.is,https://github.com/hail-is/hail/pull/7875#issuecomment-574400367,9,"['down', 'error', 'failure']","['down', 'error', 'errors', 'failure']"
Availability,"> I confirmed that, with this change, #13915 is resolved. In the interest of fixing that for 0.2.125, I'm gonna approve and get it into this release.; > ; > However, I left a comment inline. It seems that the meaning of pathsUsed was always a bit buggy and I think we should kill that tech debt now before it trips us again.; > ; > I'm also still concerned that `test_glob` didn't catch this bug; we should nail down why. We don't catch this in `test_glob` because the matrixread is nested within a `TableKeyByAndAggregate`, which semhash can't handle yet:; ```; 2023-10-26 12:54:40.576 : WARN: Failed to compute SemanticHash: SemanticHash unknown: is.hail.expr.ir.TableKeyByAndAggregate; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13919#issuecomment-1781498654:412,down,down,412,https://hail.is,https://github.com/hail-is/hail/pull/13919#issuecomment-1781498654,1,['down'],['down']
Availability,"> I do not know why the retries setting in pip.conf did not catch https://ci.hail.is/batches/167314/jobs/27, but more retries never hurt anyone. Is the whole pip process crashing because of the exception? Perhaps a different kind of crash that pip can't recover from and retry. > Another CI-related PR. This one changes the base image of everything else: hail-ubuntu. It's an ubuntu image with two scripts that make pip and apt more resilient. Take a look at docker/hail-ubuntu. Should we do this for `apt` too?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9906#issuecomment-767033129:254,recover,recover,254,https://hail.is,https://github.com/hail-is/hail/pull/9906#issuecomment-767033129,2,"['recover', 'resilien']","['recover', 'resilient']"
Availability,"> I do not understand why, but, by default, no messages are printed. Hmm, it looks to me like the default is to print (for WARN and above) the message with no further format:. ```; $ cat foo.py; import logging. log = logging.getLogger('test'). log.info('info'); log.warning('warning'); log.error('error'); $ python3 foo.py; warning; error; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7990#issuecomment-579976077:290,error,error,290,https://hail.is,https://github.com/hail-is/hail/pull/7990#issuecomment-579976077,3,['error'],['error']
Availability,> I feel like rebinding an argument should be a syntax error in scala. It certainly should warrant some big red intellij squiggles.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6984#issuecomment-527605644:55,error,error,55,https://hail.is,https://github.com/hail-is/hail/pull/6984#issuecomment-527605644,1,['error'],['error']
Availability,"> I should fix it!. That'd be awesome!. Yes, the steps are steps from build.yaml. Some background on the current setup, there are two classes of deployed stuff: normal, and ""infrastructure"". Infrastructure is stuff that can't be virtualized (or we've chosen not to) within the k8s cluster and can't be tested with the current CI setup. An example is gateway, that binds the live IP address for hail.is. Infrastructure will need a ""meta"" testing setup that will spin up another k8s cluster or testing in a separate staging cluster, where taking down the test cluster isn't an issue. Obviously, we haven't built this yet.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7015#issuecomment-540031541:544,down,down,544,https://hail.is,https://github.com/hail-is/hail/pull/7015#issuecomment-540031541,1,['down'],['down']
Availability,"> I think I'm seeing more where this approach is coming from, specifically we put batches as they exist today in a special category of having no updates and avoid the new code path in that case. An alternative which pairs with my above suggestion of not adding new staging tables is that all batches have at least 1 update. I feel like if we can force all batches down the new code path we'll be incentivized to make it really low overhead for batches that only submit jobs once, and that will benefit all batches, as well as simplifying the mental model. I may be wrong that we can do this with minimal performance tradeoff, but I'd like to try it first. Can you elaborate more? I'm not sure which code paths you are referring to.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12010#issuecomment-1219867494:364,down,down,364,https://hail.is,https://github.com/hail-is/hail/pull/12010#issuecomment-1219867494,1,['down'],['down']
Availability,"> I think pretty strongly that if nPreservedFields==0, you've done something very wrong. I don't disagree, but if you're concerned about this, I think an assert here is both in the wrong place and the wrong solution. I think for the design the IR, we should focus on (1) simple operations (this is already more complicated than I'd like), (2) that are composable, and (3) minimize special cases. By composability, I mean each IR should have a (local) contract, and each program composed from that local contract should be valid. Breaking this introduces a lot of potential bugs that can't be reasoned about locally, which is not good. The IR nodes do what they do. If you don't like what they do, we should probably find different ones. > so how could you possibly join this with another table? You'd have to create a single partition, and we'd never want to do that. Yeah, create a single partition. Or reshuffle if the partitioner has too little information. How much is too little? What if nPreservedFields==1 and we're down to 1 partition? Should that be an error? 2 partitions? How many partitions is too few? Any time nPreservedFields is less than the requested keys, you could get down to 1 partition. This is a continuous issue and rejecting the extreme case doesn't actually solve the problem. I guess isSorted isn't user exposed, but this seems dangerously close to reporting a user error with an assertion. When the service comes up, hopefully not too long, we're going to want to document the IR and make it public. So if we want to reject this case, we should do it early on: when the IR is parsed and/or constructed. (In general I think to give a nice experience we're going to have to do more up-front validation.) This is what I mean when I say ""find another IR"". In summary:; - If we're going to have this assertion, it needs to be in TableKeyBy constructor, and; - This is a complex and serious issue that isn't actually solved by your assertion.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8649#issuecomment-622415940:1023,down,down,1023,https://hail.is,https://github.com/hail-is/hail/pull/8649#issuecomment-622415940,4,"['down', 'error']","['down', 'error']"
Availability,"> I think we should change the taints on the node pools before we merge this PR. The GCP UI has changed and I don't see where we can change the taints. I think that's backwards. This PR shouldn't change the scheduling (it just adds tolerations to non-existent taints), so it should go in first, then we should add the taint and let the preemptible workload on non-preemptible nodes get rescheduled to preemptible nodes. However, I think what we should do is create a new tainted non-preemptible pool, merge this PR, and then delete the old pool. Yeah, looks like you can't edit labels or taints from the UI. Maybe you can from the command line? ; Anyway, with the above strategy which seems upgrade safe, it doesn't matter.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7636#issuecomment-565690039:232,toler,tolerations,232,https://hail.is,https://github.com/hail-is/hail/pull/7636#issuecomment-565690039,1,['toler'],['tolerations']
Availability,"> I think you'll still have the doctest failure. It just returns list of lists now ,right?. I'm not sure I follow. What returns a list of lists?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8265#issuecomment-601452175:40,failure,failure,40,https://hail.is,https://github.com/hail-is/hail/pull/8265#issuecomment-601452175,1,['failure'],['failure']
Availability,"> I tried making a plot with only shape, not color. It should behave the same as color (in the discrete case), only using shapes instead of colors, but right now the legend uses ""trace 0"" etc. instead of the data values. I was able to get the category names showing properly in the legend with just shapes by adding a `shape_legend -> name` mapping to `GeomPoint.trace_args`, but this caused the shape names to override the color names when using both; I added logic to `Geom._add_aesthetics_to_trace_args` to concatenate the names with one legend entry per pair of color and shape, which causes the shapes to stop working and a separate color to be assigned to each legend entry. ```python; import hail as hl; from hail.ggplot import ggplot, aes, geom_point; ht = hl.utils.range_table(10); ht = ht.annotate(squared=ht.idx ** 2); ht = ht.annotate(even=hl.if_else(ht.idx % 2 == 0, ""yes"", ""no"")); ht = ht.annotate(threeven=hl.if_else(ht.idx % 3 == 0, ""good"", ""bad"")); fig = (; ggplot(ht); + aes(x=ht.idx, y=ht.squared, color=ht.even, shape=ht.threeven); + geom_point(); ); fig.show(); ```. ![newplot(1)](https://user-images.githubusercontent.com/84595986/191850065-fa9cf15a-44b5-48cc-ad95-47af67d76ec1.png). I'm having trouble tracking down why this is happening, so I'll ask for some help with that tomorrow.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12207#issuecomment-1255544008:1234,down,down,1234,https://hail.is,https://github.com/hail-is/hail/pull/12207#issuecomment-1255544008,1,['down'],['down']
Availability,"> I'd rather read a short one-line description of what is being done followed by the example. I agree with this. See, for example, filter_alleles in my PR: https://ci.hail.is/repository/download/HailSourceCode_HailCi/3269:id/www/pyhail/index.html. I'm allowing from some short clarifying remarks after the example.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1216#issuecomment-270983676:186,down,download,186,https://hail.is,https://github.com/hail-is/hail/pull/1216#issuecomment-270983676,1,['down'],['download']
Availability,"> I'm confused. What do you mean by this? Are you planning on using Dan's version of notebook (the rainbow gradient notebook.hail.is), or mine? If Dan's, he and I spoke about it, and he specifically stated that his version of Notebook is no longer needed, which is why I deleted the existing notebook. My apologies, @danking was wrong. I'm currently planning to use Dan's version because yours isn't ready. If yours is ready, I will use it. What does ready mean? From our recent email:. - it needs to get in master,; - and and integrated with our CI/CD (we can't be fixing issues and doing manual deployments leading up to or during a tutorial),; - it need to be beaten on by the team to look for issues (including scale issues), and; - it needs to be scale tested (@danking has a script for the old one that fires up N notebooks and reports any failures and summarizes the latency to notebook available),; - @tpoterba and I need to be comfortable enough with it we have confidence we can fix issues that arise during the tutorial. I probably also need time to review the workshop auth flow since I think that changed. If we're requiring login, we'll need to support more social login providers and/or email/password.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-464229358:846,failure,failures,846,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-464229358,2,"['avail', 'failure']","['available', 'failures']"
Availability,"> I'm not sure how this is unsafe. Could you explain?. Partitioner just says what elements are in what partitions. OrderedRDD also guarantees those elements are in a specific order. It is not safe to take an RDD partitioned with an OrderedPartitioner and just ""make"" it an OrderedRDD. Case where it fails: in read, union, which creates a partition-aware RDD that unions corresponding partition from a set of identically partitioned RDDs. > i think the better solution is to check that the ordered key inside the partitioner is the same as the implicit ordered key supplied. this also could have caught the errors. The error was making it into an OrderedRDD without sorting. It is perfectly valid to have an OrderedPartitioner-partitioned RDD that is sorted. (Above read case.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1864#issuecomment-303237349:606,error,errors,606,https://hail.is,https://github.com/hail-is/hail/pull/1864#issuecomment-303237349,2,['error'],"['error', 'errors']"
Availability,"> I'm seeing issues creating notebooks (500). I can't reproduce this. Can you give me more details? Where are you running it? Note, my namespace is running a different branch that I'm working on (e.g. the menu stuff which doesn't include these changes.). > reaching CI and Batch (502). Is this in my namespace? I don't have CI or Batch deployed. Let me know if you want to test it there and I'll spin up this branch. Is it not working in your namespace?. > Notebook2 link should be changed to redirect to notebook 1. There should be no notebook2 links. I just grepped through the entire codebase, I didn't find anything. We're not asking for notebook2 certs anymore. Notebook2 is dead, long live notebook. Nobody is using it besides us, so I don't see any need for maintaining backward compatibility. In particular, if/when we make this more widely available, there shouldn't be anything2.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7145#issuecomment-536150091:849,avail,available,849,https://hail.is,https://github.com/hail-is/hail/pull/7145#issuecomment-536150091,1,['avail'],['available']
Availability,"> I'm worried this PR will break all dev deploys. The migration will bring down the service (batch, etc.) inside the dev namespace, but the dev deploy itself is running in the production batch, so there should be no issue. The deploys will still happen as normal after the migrations, e.g. deploy_batch will run after batch_database.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7855#issuecomment-573731718:75,down,down,75,https://hail.is,https://github.com/hail-is/hail/pull/7855#issuecomment-573731718,1,['down'],['down']
Availability,"> I've been working on an R interface to Hail through the sparklyr package. this also sounds awesome. To the issue -- this usually means something really bad happened on an executor, like a segfault. Spark usually is reluctant to provide the real error message, but in this case I think it's our fault. . Did you already do our job of bisecting to that commit for us? I'm not sure where exactly the generated C++ is being used (just the decoder, right, team?)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513#issuecomment-428377258:247,error,error,247,https://hail.is,https://github.com/hail-is/hail/issues/4513#issuecomment-428377258,2,"['error', 'fault']","['error', 'fault']"
Availability,"> Ideally, I'd release the references to the regions of my producer once I finished constructing the new RegionValue. I think references from a region to other regions should be treated the same as data directly contained in the region. In particular, in the current model it all gets freed at the same time. If we move to a stacked/checkpointed model like Cotton suggested, a checkpoint would remember both where in the region to move back to, and where in the list of region dependencies to move back to, releasing those regions to the right of that point.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7952#issuecomment-577853956:333,checkpoint,checkpointed,333,https://hail.is,https://github.com/hail-is/hail/pull/7952#issuecomment-577853956,2,['checkpoint'],"['checkpoint', 'checkpointed']"
Availability,"> If there's no requester pays, is it just impossible to have ""public"" data in Azure storage safely? Like anything in there could be downloaded infinity times to drive up a bill?. That's correct.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11187#issuecomment-1004244889:133,down,downloaded,133,https://hail.is,https://github.com/hail-is/hail/pull/11187#issuecomment-1004244889,1,['down'],['downloaded']
Availability,"> If we ever ban old versions of Hail from the cluster, then we can also eliminate the log4j2 reconfiguration. New versions of Hail work fine without any runtime log configuration (thanks to QoBAppender). We might want to do this if we get rid of GSA keys. We can't have any more jars that presume the existence of some key file. It would also be a good time to fully delete the `memory` service, even though old jars should be able to tolerate that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12941#issuecomment-1527963692:436,toler,tolerate,436,https://hail.is,https://github.com/hail-is/hail/pull/12941#issuecomment-1527963692,1,['toler'],['tolerate']
Availability,"> In particular, the matrixtable available in doc examples as `ds` lives at `hail/hail/python/hail/docs/data/example.mt`. Thanks, this is exactly what I was looking for. I am having trouble testing my new example locally though. When I run `make -C hail doctest-query`, the tests fail with a checksum error. I tried running `make -C hail clean` and retrying, but I still get the same error. ```; E hail.utils.java.FatalError: ChecksumException: Checksum error: file:/Users/willtyler/Desktop/hail/hail/python/hail/docs/data/example.8bits.bgen.idx2/metadata.json.gz at 0 exp: 982431825 got: -2031629660; E; E Java stack trace:; E org.apache.hadoop.fs.ChecksumException: Checksum error: file:/Users/willtyler/Desktop/hail/hail/python/hail/docs/data/example.8bits.bgen.idx2/metadata.json.gz at 0 exp: 982431825 got: -2031629660; E 	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347); E 	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303); E 	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252); E 	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197); E 	at java.base/java.io.DataInputStream.read(DataInputStream.java:149); E 	at is.hail.io.fs.HadoopFS$$anon$2.read(HadoopFS.scala:58); E 	at java.base/java.io.DataInputStream.read(DataInputStream.java:149); E 	at org.apache.commons.compress.utils.CountingInputStream.read(CountingInputStream.java:56); E 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252); E 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271); E 	at org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream.init(GzipCompressorInputStream.java:185); E 	at org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream.<init>(GzipCompressorInputStream.java:168); E 	at is.hail.io.fs.GZipCompressionCodec$.makeInputStream(FS.scala:125); E 	at is.hail.io.fs.FS.open(FS.scala:563); E 	at is.hail.io.fs.FS.open$(FS.scala:560); E 	",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14255#issuecomment-1933346001:33,avail,available,33,https://hail.is,https://github.com/hail-is/hail/pull/14255#issuecomment-1933346001,5,"['avail', 'error']","['available', 'error']"
Availability,"> In trying to test this (from your branch, ran pip install on /hail/python just in case). You're running this locally, or with `hailctl dev deploy`? I assume the latter because the former is essentially impossible. ~/.hail/token is no longer used and you can delete it. You'll need a valid tokens.json to run the dev deploy. Once the dev deploy runs, your local configuration is irrelevant. It sounds like your dev deploy was successful. You're getting failures in your deployed services. You need to look into your namespace to debug them. In particular, for auth to run, you're going to need a copy of auth-oauth2-client-secret from the production namespace. To log in inside the dev namespace, you'll have to add the callback to the list of registered callbacks at Google. You can copy mine as an example.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7064#issuecomment-532260285:454,failure,failures,454,https://hail.is,https://github.com/hail-is/hail/pull/7064#issuecomment-532260285,1,['failure'],['failures']
Availability,"> Introducing an image with the wheel already installed isn't worthwhile, it adds 2.5 min latency. Agreed. I think our best path for speed is keeping these images totally cacheable so basically dependencies (nothing that will have to change on every commit, e.g. the wheel). Installing the wheels in the image is just adding more latency and work of localization. > The large number of splits often requires default Hail to scale up adding a 2min delay (It would be great to get that down).; I'm gonna revert the change that added images and maybe try to reduce service backend parallelism a bit. 36 minutes is an improvement. We should probably focus on making Hail faster rather than trying to squeeze lower latency out of parallelism. Totally agree.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13076#issuecomment-1561101182:484,down,down,484,https://hail.is,https://github.com/hail-is/hail/pull/13076#issuecomment-1561101182,1,['down'],['down']
Availability,"> It's a little concerning that this is necessary. Are there typecheck cases that don't make assertions about some of their children?. This check would have to go in a LOT of places otherwise. Reading down from the top: CastRename, NA, IsNA, Coalesce, AggLet, TailLoop, MakeArray, ...",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9974#issuecomment-772079087:201,down,down,201,https://hail.is,https://github.com/hail-is/hail/pull/9974#issuecomment-772079087,1,['down'],['down']
Availability,"> Just so I understand correctly (and sorry if this is obvious), the current job logs interface is still the same. But if you want a container's logs, then you'll get bytes which the user will have to decode themselves. How does that affect the file download button in the UI and the hailctl batch logs functionality you have? Will you see text or a random byte string?. Good question. For the download button, the file you download is still a normal text file and I've confirmed that I can download and view a log file as I would expect. For the `hailctl batch logs` functionality, I added logic to the CLI in this PR where I download the bytes of the log and if I can decode it as UTF-8 I do, so it prints exactly as before, and if I can't I just print the bytes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12666#issuecomment-1426373373:250,down,download,250,https://hail.is,https://github.com/hail-is/hail/pull/12666#issuecomment-1426373373,5,['down'],['download']
Availability,"> Looks like we need to set the severity correctly in the worker logs. I'm also seeing a lot of this; WARNING: Published ports are discarded when using host network mode; Also looks like we incorrectly log a ContainerTimeoutError as an error log even though that's a user error: https://cloudlogging.app.goo.gl/TUGWNxnFiBiEdsDo9. For what it's worth, this was showing up as an info log because this is a docker log message not from our code, so it's not going through our logging filters. The reason this showed up in the Google Logging query was because the query included this line; ```; severity=ERROR OR WARNING; ```; which means ""logs whose severity is ERROR or whose log entry contains ""WARNING"""", it is *not* equivalent to `severity=ERROR OR severity=WARNING` which does not show that log entry. Either way, #14252 gets rid of that log message entirely.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14240#issuecomment-1930672702:236,error,error,236,https://hail.is,https://github.com/hail-is/hail/issues/14240#issuecomment-1930672702,5,"['ERROR', 'error']","['ERROR', 'error']"
Availability,> Looks like you need to [update the Google Artifact Registry cleanup policies](https://batch.hail.is/batches/8076011/jobs/210) to account for your new image. Instructions to do so are in the error message. Thanks!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13936#issuecomment-1785779141:192,error,error,192,https://hail.is,https://github.com/hail-is/hail/pull/13936#issuecomment-1785779141,1,['error'],['error']
Availability,> Maybe that's the error when no orphaned disks are found with any labels. Ya I interpret this as the query just returned no results.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13719#issuecomment-1737810077:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/13719#issuecomment-1737810077,1,['error'],['error']
Availability,> Merging in #14233 causes the failure in `test_union_rows1`. Some strangeness with these new dependencies - running without this commit and everything works fine. Doesn't seem to be an issue anymore...,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14231#issuecomment-1934834223:31,failure,failure,31,https://hail.is,https://github.com/hail-is/hail/pull/14231#issuecomment-1934834223,1,['failure'],['failure']
Availability,"> My experiments show that clone+merge is ~20 seconds but download from GCS is ~3s. Where are you running clone+merge here? We time the clone and pull in the build:. > + git clone https://github.com/hail-is/hail.git .; > real	0m12.030s. > + git fetch -q akotlar/hail; > real	0m2.878s. We don't time the merge, so that should be fast. I spot-checked the base_image step from half a dozen builds and the spread was ~11-18s. How was the 3s measured?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7626#issuecomment-560436226:58,down,download,58,https://hail.is,https://github.com/hail-is/hail/pull/7626#issuecomment-560436226,1,['down'],['download']
Availability,"> Not sure what to do about wait for and ghost. rather silly of ghost to refuse connections on http when the base url is set to https. > The test failure that I'm running into currently has to do with the fact that the wait command there queries the endpoint without going through either the router or the gateway, (since it's e.g. hitting http://blog.wang/wang/blog/ directly), so it's getting the 301 redirect to https because the X-Forwarded-Proto header isn't set. I'm not sure what the right fix is in this case. I still don't quite understand why the wait command doesn't hit gateway. Isn't it just issuing an http request to `f'{base_url}/{endpoint)`? Why doesn't that hit gateway?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7381#issuecomment-548104962:146,failure,failure,146,https://hail.is,https://github.com/hail-is/hail/pull/7381#issuecomment-548104962,1,['failure'],['failure']
Availability,"> Noteworthy as well. Although I can't reproduce it consistently, sometimes conda may not like `-f environment.yml`, but will work perfectly well with `conda env create`. While I prefer `-f environment.yml` because it is more obvious, dropping that argument may be less fragile.; > ; > [conda/conda#3847](https://github.com/conda/conda/issues/3847); > ; > Edit: This was actually a typo in the documentation. Fixed in [3135dc1](https://github.com/hail-is/hail/commit/3135dc124c37ec6987d96f5de0b7dbb634487b7d). I find `conda`'s terminal UI supremely frustrating. That `conda env create -f does-not-exist` doesn't error with ""file not found"" blows my mind.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5022#issuecomment-449439317:612,error,error,612,https://hail.is,https://github.com/hail-is/hail/pull/5022#issuecomment-449439317,1,['error'],['error']
Availability,"> OK, but I'm not sure it's the right change to make. Now some jobs will fail silently. I don't think this lets anything fail silently -- the failure from run() is still tracked. Agree that the right solution is to additionally track information about dead JVMs to try to provide a better error message, but that juice isn't worth the squeeze at the moment.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12838#issuecomment-1527612619:142,failure,failure,142,https://hail.is,https://github.com/hail-is/hail/pull/12838#issuecomment-1527612619,2,"['error', 'failure']","['error', 'failure']"
Availability,"> Oh, I misunderstood, I thought you were suggesting changing our FROM to stretch/9.6.; > ; > I think that should be fine, but can we do it as a separate PR since it seems orthogonal to this change which we're trying to get in for the demo tomorrow? (And in general orthogonal changes should be separate PRs so discussion on one part doesn't hold up the other parts.). Yes, although the gzip settings issued in this pr will be different between the two version. 1.10.3 doesn't have gzip on by default. I understand the value of conservative updates before public demonstrations, so will do what you ask. Btw, the full config if relying on nginx:10.15.8 goes from:. ```; FROM debian:9.5. RUN apt-get update -y && \; apt-get install -y nginx && \; rm -rf /var/lib/apt/lists/*. RUN rm -f /etc/nginx/sites-enabled/default; ADD @nginx_conf@ /etc/nginx/conf.d/hail.conf; ADD gzip.conf /etc/nginx/conf.d/gzip.conf. RUN ln -sf /dev/stdout /var/log/nginx/access.log; RUN ln -sf /dev/stderr /var/log/nginx/error.log. CMD [""nginx"", ""-g"", ""daemon off;""]; ```. to . ```; FROM nginx:1.15.8. RUN rm -f /etc/nginx/sites-enabled/default; ADD @nginx_conf@ /etc/nginx/conf.d/hail.conf; ADD gzip.conf /etc/nginx/conf.d/gzip.conf; ```. kind of neat.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5244#issuecomment-460378467:996,error,error,996,https://hail.is,https://github.com/hail-is/hail/pull/5244#issuecomment-460378467,1,['error'],['error']
Availability,"> Options: 1) Fix this rule, 2) (Seems not as good) In Emit have ArrayAgg needs to pass its child through Emit.emit a second time to match on ToArray, 3) make unstreamify more specific, such that ArrayAgg is allowed to take streams directly. ToArray definitely needs to wrap StreamRange in some cases (for instance MakeTuple(ToArray(StreamRange)), else get issues with the stream passed to SRVB. it would be helpful to have the intended (but currently applicable) design of stream/array semantics written down for all nodes (maybe it exists, I'll dig through design docs). Besides this 2 more failures. Option 4: rebase on master, where ArrayAgg is not an emittable node (only RunAgg / RunAggScan) :)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-583803556:505,down,down,505,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-583803556,2,"['down', 'failure']","['down', 'failures']"
Availability,"> Pending -> Ready -> (Error, Running -> (Failed, Success)) . Does Running mean the pod has been created, or it is verified to be running? In the former case, is it Pending -> Ready -> Running -> (Error, Failed, Success)?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6268#issuecomment-499306521:23,Error,Error,23,https://hail.is,https://github.com/hail-is/hail/pull/6268#issuecomment-499306521,2,['Error'],['Error']
Availability,"> So error propagation from CI back to hailctl isn't great right now. (Something worth fixing!) If it an error in what you're trying to deploy (e.g. branch not found, syntax error in build.yaml, etc.) you can find it in the CI log. I should fix it!. edit: Yeah, I could see it in the logs, I just didn't understand some of the syntax, so dug around CI and deploy codebase, figured it out. Monitoring wasn't expected, thanks.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7015#issuecomment-540028930:5,error,error,5,https://hail.is,https://github.com/hail-is/hail/pull/7015#issuecomment-540028930,3,['error'],['error']
Availability,"> Still seeing this error in the deploy_batch job:; > ; > ```python; > utils.py	retry_long_running:923	in delete_prev_cancelled_job_group_cancellable_resources_records	; > Traceback (most recent call last):; > File ""/usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py"", line 915, in retry_long_running; > return await f(*args, **kwargs)\n File ""/usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py"", line 959, in loop; > await f(*args, **kwargs)\n File ""/usr/local/lib/python3.9/dist-packages/batch/driver/main.py"", line 1485, in delete_prev_cancelled_job_group_cancellable_resources_records; > async for target in targets:\n File ""/usr/local/lib/python3.9/dist-packages/gear/database.py"", line 334, in execute_and_fetchall; > async for row in tx.execute_and_fetchall(sql, args, query_name):\n File ""/usr/local/lib/python3.9/dist-packages/gear/database.py"", line 257, in execute_and_fetchall; > await cursor.execute(sql, args)\n File ""/usr/local/lib/python3.9/dist-packages/aiomysql/cursors.py"", line 239, in execute; > await self._query(query)\n File ""/usr/local/lib/python3.9/dist-packages/aiomysql/cursors.py"", line 457, in _query; > await conn.query(q)\n File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 469, in query; > await self._read_query_result(unbuffered=unbuffered)\n File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 683, in _read_query_result; > await result.read()\n File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 1164, in read; > first_packet = await self.connection._read_packet()\n File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 652, in _read_packet; > packet.raise_for_error()\n File ""/usr/local/lib/python3.9/dist-packages/pymysql/protocol.py"", line 219, in raise_for_error; > err.raise_mysql_exception(self._data)\n File ""/usr/local/lib/python3.9/dist-packages/pymysql/err.py"", line 150, in raise_mysql_exception; > raise errorclass(errno, errval); > pym",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14672#issuecomment-2353226053:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/pull/14672#issuecomment-2353226053,1,['error'],['error']
Availability,"> Supporting `file://` seems to suggest that we would support URIs in general (e.g. `--files gs://foo/bar:/baz`); AFAICT we don't support the latter, right? What's the motivation to support `file://`?. I didn't know what we currently support with regards to file paths, so I just made it that we're resilient to someone adding file://",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13812#issuecomment-1836784494:299,resilien,resilient,299,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1836784494,1,['resilien'],['resilient']
Availability,> TMPDIR; > This variable shall represent a pathname of a directory made; > available for programs that need a place to create temporary; > files. http://pubs.opengroup.org/onlinepubs/9699919799/. Requested by the discuss user rca:. http://discuss.hail.is/t/hailcontext-tmp-dir/323,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2327:76,avail,available,76,https://hail.is,https://github.com/hail-is/hail/pull/2327,1,['avail'],['available']
Availability,"> That should be a simple fix, though perhaps at this point not worth it as this is not a fruitful optimization for this query. Agreed, although depending on the time line for a good optimization for this query I may circle back on this, as there is currently a bug in this deduplication so if the actual optimizaion won;t be available for a while it might be worth fixing in the meantime",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13882#issuecomment-1839244525:326,avail,available,326,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1839244525,1,['avail'],['available']
Availability,"> The 9 is about stopping the exponential backoff. At i=9, (0.1 * 2^9 is roughly half a second) we stop backing off and keep polling with delays uniformly chosen between 0 and half second.; > ; > We might actually want a hard limit on the number of backoffs, as written this test could trigger an infinite loop. I'll add a max number of iterations. What does a failure indicate? The only concern I have is that we have a stochastic process, but I dont know whether 14 indicates a 99.99% success target, or something else. Also, if this test fails for a future batch PR, should we pass the contribution under some circumstances.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5503#issuecomment-470262025:361,failure,failure,361,https://hail.is,https://github.com/hail-is/hail/pull/5503#issuecomment-470262025,1,['failure'],['failure']
Availability,"> The 9 is about stopping the exponential backoff. At i=9, (0.1 * 2^9 is roughly half a second) we stop backing off and keep polling with delays uniformly chosen between 0 and half second.; > ; > We might actually want a hard limit on the number of backoffs, as written this test could trigger an infinite loop. I'll add a max number of iterations. What does a failure indicate? The only concern I have is that we have a stochastic process, but I dont know whether 14 indicates a 99.99% success target, or something else. Also, if this test fails for a future batch PR, should we pass the contribution under some circumstances. > Ok, what do you think of this?; > ; > ```; > i = 0; > while len(output) != 4:; > time.sleep(0.100 * (3/2) ** i); > i = i + 1; > if i > 14:; > break; > assert len(output) != 4; > ```; > We exponentially back off with base 3/2. We break as soon as the condition is satisfied. If we wait more than a minute (`0.1 * (3/2)^14` is roughly 30s, so we've waited about a minute in total), we bail (and the assert will fail). Seems completely reasonable to prevent infinite loops in CI. I dont really understand under which circumstances this should fail, and whether 30s is enough to ensure that we get rare false positive test failures. I trust your judgment on this, so if you say 30s is good enough, I think we should start there and adjust if test failures on batch PRs pile up.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5503#issuecomment-470263694:361,failure,failure,361,https://hail.is,https://github.com/hail-is/hail/pull/5503#issuecomment-470263694,3,['failure'],"['failure', 'failures']"
Availability,"> The approach in this PR doubles down on the functional Code[T] structure. I don't see anything in the design that prevents us from moving away from `Code[T]`, but it does have to support it for now. > I think if I could choose an interface for injecting line numbers from IR in emit it would look something like:. This is also the interface I would like to see for CodeBuilder. And you're right, making that change would allow methods taking a `CodeBuilder` to not need a line number argument. I agree that's better. I may have gotten a bit of tunnel vision in the middle of the giant mechanical refactoring :) I will make this change. > I think part of my concern is that Im not entirely sold by the need to have a whole stack of IR printouts and associated line numbers  right now, the option to get debug information by LIR line number or IR (fully lowered, compile-ready) seems plenty sufficient. I think most of this PR is necessary for debug information with the fully lowered IR line numbers. It doesn't do anything to propagate line numbers through IR lowerings, which is what would be needed to support line numbers at earlier compiler stages. > Part of my pushback is that I'm hesitant to use Scala implicits pervasively without a careful cost/benefit consideration. My main reason for that approach was to manage the number of changes required in this PR. We could follow up on this with making line number arguments explicit in manageable chunks. But personally this seems like the ideal use case for implicit arguments. And as `Code` goes away, the number of places with implicit line number arguments should go down significantly.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9770#issuecomment-742042975:34,down,down,34,https://hail.is,https://github.com/hail-is/hail/pull/9770#issuecomment-742042975,2,['down'],['down']
Availability,> The error is here:; > `Invalid value for field \'resource.scheduling.instanceTerminationAction\': \'DELETE\'. You cannot specify a termination action for a VM instance that has the standard provisioning model (default).`. Thanks very much for finding that and sorry for not seeing this issue earlier! This is fixed now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11878#issuecomment-1144803938:6,error,error,6,https://hail.is,https://github.com/hail-is/hail/pull/11878#issuecomment-1144803938,1,['error'],['error']
Availability,"> The failure isn't the dataproc delete, that's just what you get when you try to delete a cluster that wasn't created. You had an import error:; > ; > ```; > File ""/hail/repo/hail/python/hail/fs/google_fs.py"", line 3, in <module>; > import gcsfs; > ModuleNotFoundError: No module named 'gcsfs'; > ```. I see. gcsfs is already dynamically imported. If the apiserver tests are being run by CI, it needs to have the gcsfs module, unless we want to make fs lazy.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5878#issuecomment-485522267:6,failure,failure,6,https://hail.is,https://github.com/hail-is/hail/pull/5878#issuecomment-485522267,2,"['error', 'failure']","['error', 'failure']"
Availability,"> The hailctl dataproc subcommand now has --beta, --configuration=, --dry-run, --project= and --zone=. These apply to all commands. There is a GcloudRunner object that takes these options, is set to the click context user obj field, and is used by all hailctl dataproc commands to invoke gcloud. Note, not all dataproc subcommands invoke gcloud, but the current design doesn't differentiate. Note, with click, the subcommand options must go on the subcommand, so hailctl dataproc stop --dry-run is an error. Nice. It's great that these are handled at the `hailctl dataproc` level instead of having to remember to account for them in every `hailctl dataproc` subcommand. That's going to resolve a lot of inconsistencies (like #9587). A nitpick though... is there a better name for the click context attribute than ""obj""?. > hailctl no longer takes --region (for gcloud dataproc commands). I compute region in GcloudRunner by checking dataproc/region or falling back to determining the region from the zone. I error if the region and zone are incompatible (gcloud would also do this). If consistency with `gcloud dataproc` is desired, I think the opposite (determining zone from cluster region) would be preferable. `gcloud dataproc` commands take a `--region` argument. [`--zone` is an optional argument for `gcloud dataproc clusters create`](https://cloud.google.com/sdk/gcloud/reference/dataproc/clusters/create#--zone). When a cluster's zone is needed to run `gcloud compute` commands, it can be determined using `gcloud dataproc clusters describe <cluster> --format json`. `hailctl dataproc diagnose` currently does this. I believe the only reason that we currently require a zone be provided either in gcloud configuration or on the command line is to maintain backwards compatibility. `cloudtools` and earlier versions of `hailctl` had a default value for the `--zone` option of `hailctl dataproc start` (I think it was `us-central1-b`). > I stripped all gcloud pass through args from hailctl dat",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842#issuecomment-767168393:501,error,error,501,https://hail.is,https://github.com/hail-is/hail/pull/9842#issuecomment-767168393,1,['error'],['error']
Availability,"> The missing permission is `storage.buckets.get` though? It seems reasonable for a user to [be able to read metadata](https://cloud.google.com/storage/docs/access-control/iam-permissions) about their own bucket. I'd wager that jgscm was designed for use with the `roles/storage.legacyBucketWriter` role granted on their bucket. What role are we currently granting?. The problem I believe is that they would need project-wide read/list permissions. The blob (folder) is not being created in their bucket, but as a new bucket in the project. edit: You can clearly see the difference if you click on the checkpoint folder, back up to the folder /bucket_name and try to create a folder. No additional permissions needed (it's being made in their bucket)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5788#issuecomment-480375549:602,checkpoint,checkpoint,602,https://hail.is,https://github.com/hail-is/hail/pull/5788#issuecomment-480375549,1,['checkpoint'],['checkpoint']
Availability,"> The reason we didn't expose the other parameters was what if we had 16 core jobs waiting to be scheduled and then we changed the worker pool size to 4 cores. Yep. Let's call that admin operator error and let's not do that. The other reason was we had hardcoded the billing computation in the code, but that's fixed now. But it is hardcoded in the documentation, so we still shouldn't really be changing any of these settings (I see this mainly for the second instance at this point). Separately, we should decouple the billing from the details of the implementation so we get a bit more flexibility on the backend in the main instance, as we've discussed. I'm OK with this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9285#issuecomment-674998109:196,error,error,196,https://hail.is,https://github.com/hail-is/hail/pull/9285#issuecomment-674998109,1,['error'],['error']
Availability,"> The thinking behind this is that there's a huge amount of re-use of code for an individual from one Hail analysis to the next. So I'm not sure I buy this. Hail is a exploratory data analysis platform, it isn't a SQL engine running nightly billing reports. In particular, as we do whole stage optimization and code generation. It isn't clear to me how you do code-reuse when we're specializing each operation into the global context (happy to hear the plan). For example, tables that have many fields, you will need to load different ones for different queries and in general it is infeasible (exponential) to generate them all. Also, to get sharing you need to break the code up and now you're running the compiler multiple times which also seems bad. Given our focus on large-scale analysis, introducing optimization boundaries for code reuse seems like a bad trade off to me. A significant amount of analysis happens in the cloud where $HOME is ephemeral so you won't get savings between sessions. Finally, there are pipelines that are more standardized but it is my impression they are run on extremely large datasets (hours, overnight) in which case compilation speed isn't important. Finally, there's the complexity around locking that isn't easy and have real technical risk. A compiler cache potentially becomes more appealing in the context of an always-on service. There's no locking issue, and you can start to do things like speculative compilation (e.g. immediately start compiling the decoder (the full decoder? Hmm.) when a user opens the dataset.). I would say getting in a 3x decoder improvement is way more important than this. I would have punted it down the road and instrumented to estimate cache hit rates before building this out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-410358596:1670,down,down,1670,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410358596,1,['down'],['down']
Availability,> Then I will PR a change that raises errors if we try to start a service with plaintext connections or unverified connections. You should also modify the CloudSQL instance to only accept TLS connections. That's an option.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8433#issuecomment-607558384:38,error,errors,38,https://hail.is,https://github.com/hail-is/hail/pull/8433#issuecomment-607558384,1,['error'],['errors']
Availability,> Then we just need to decide if we want to throw an error on file:// for a non-existent Transfer.TARGET_DIR. I say no. I agree. I think the user is being explicit what they intend to have happen.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9822#issuecomment-764956189:53,error,error,53,https://hail.is,https://github.com/hail-is/hail/pull/9822#issuecomment-764956189,1,['error'],['error']
Availability,"> There should be no notebook2 links. I just grepped through the entire codebase, I didn't find anything. We're not asking for notebook2 certs anymore. Notebook2 is dead, long live notebook. Nobody is using it besides us, so I don't see any need for maintaining backward compatibility. In particular, if/when we make this more widely available, there shouldn't be anything2. I just mean we should have a gateway/router redirect, or have 404's issued. Right now some kind of routing happens, resulting in a certificate error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7145#issuecomment-536197945:334,avail,available,334,https://hail.is,https://github.com/hail-is/hail/pull/7145#issuecomment-536197945,2,"['avail', 'error']","['available', 'error']"
Availability,"> Tim Poterba: I think we need to kick up the local disk size requested when running VEP. > Tim Poterba: we were talking about this here https://discuss.hail.is/t/dataproc-workers-lost-after-intensive-task/1014/34. > Kyle Satterstrom: Interesting, thanks for pointing that out. Yeah, I had been using workers with 40GB boot disks (and no attached SSDs). I had looked in the log and seen the errors that said ""no space left on device"", but I guess I didn't really believe it would fill up all that space at once. I can try increasing the 40 to 100 and see if it helps. > Tim Poterba: that unblocked Kevin on VEP!. > Tim Poterba: and don't try to repartition, I think. > Kyle Satterstrom: Just an update -- I tried the same thing again with 100GB worker boot disks intead of 40GB, and it made more progress but ultimately failed again hail-20190726-1716-0.2.16-6da0d3571629.log. > Kyle Satterstrom: One more update -- I tried the same thing again but with a local SSD attached to each machine instead of increasing the boot disk size (so worker boot disks were 40 GB), and that worked!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6756:391,error,errors,391,https://hail.is,https://github.com/hail-is/hail/issues/6756,1,['error'],['errors']
Availability,"> Well yes. What I mean is in an automated fashion. We haven't deployed any builds in around a day because of this error, the deploy job keeps restarting and it was very difficult for me to interrogate what was going on. yeah, sorry, that's on me. I didn't notice because the pod's log didn't change between the first PR, which didn't have libsass, and the next, which did; assumed CI hadn't deployed it because it was backed up.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5489#issuecomment-468435191:115,error,error,115,https://hail.is,https://github.com/hail-is/hail/pull/5489#issuecomment-468435191,1,['error'],['error']
Availability,"> What do you mean by ""a maintenance error is generated in Ghost""? I kind of assumed that the website wasn't working right now because the tests finished and `cleanup_deploy_blog` shut down the blog in the PR namespace.; > ; > The ""endpoint"" that I'm passing in to the `wait` command for the blog in build.yaml is `/`, which _should_ do the right thing interally because the URL that's actually being constructed in `wait-for.py` becomes `http://{service}.{namespace}/{namespace}/{service}{endpoint}`, which gives you the right thing.; > ; > The test failure that I'm running into currently has to do with the fact that the wait command there queries the endpoint without going through either the router or the gateway, (since it's e.g. hitting http://blog.wang/wang/blog/ directly), so it's getting the 301 redirect to https because the `X-Forwarded-Proto` header isn't set. I'm not sure what the right fix is in this case.; ```; [2019-10-30 20:03:15] [36mINFO[39m Ghost boot 5.169s; [2019-10-30 20:03:16] [31mERROR[39m ""GET /pr-7381-default-sx9ail9zkm77/blog/"" [31m503[39m 40ms; [31m; [31mSite is starting up, please wait a moment then retry.[39m. [1m[37mError ID:[39m[22m; [90m4f8b8590-fb50-11e9-ab7c-9dd7e9eff310[39m. [90m----------------------------------------[39m. [90mMaintenanceError: Site is starting up, please wait a moment then retry.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7381#issuecomment-548102772:25,mainten,maintenance,25,https://hail.is,https://github.com/hail-is/hail/pull/7381#issuecomment-548102772,4,"['down', 'error', 'failure', 'mainten']","['down', 'error', 'failure', 'maintenance']"
Availability,"> What were the errors? It should be OK to hold the job object around and e.g. use it to ask for logs even if the job is deleted. We were setting the Job id attribute to None on deletion. ci then queried various properties of the job, passing None as the job id in the URL. That caused batch to 500 converting the id to an integer (this is itself a bug). Leaving the id in the Job might also fix it, but it seems wrong in the REST setting to delete an object, but still be able to query it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5655#issuecomment-476227436:16,error,errors,16,https://hail.is,https://github.com/hail-is/hail/pull/5655#issuecomment-476227436,1,['error'],['errors']
Availability,"> When will it be available to use?. 0.2.129. Should be released soon,",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14375#issuecomment-2025929109:18,avail,available,18,https://hail.is,https://github.com/hail-is/hail/pull/14375#issuecomment-2025929109,1,['avail'],['available']
Availability,"> Whoops, sorry this got dropped!. No problem. This wasn't important, just a potential ""nice to have"". > how changes like this could unintentionally affect things. This shouldn't change anything unless a user intentionally opts into using it to encode JSON. It was intended as a convenience: it's easy enough for a user to implement this themselves, but it might take a few rounds of trial and error to catch all the classes that need to be handled.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11307#issuecomment-1050104675:394,error,error,394,https://hail.is,https://github.com/hail-is/hail/pull/11307#issuecomment-1050104675,1,['error'],['error']
Availability,"> Why is writing the hail table first more efficient than just directly exporting from the grouped matrixtable?. We take special care to ensure our system is as efficient as possible when reading or writing to this native format. So, it's partly a sociological thing. On the practical end of things, Hail's native formats (for Tables and Matrix Tables) are a partitioned binary format. The partitioned part means Hail can use many cores in parallel to process and write the dataset. The binary part means that Hail need not use unnecessarily large (in terms of bytes) representations of values. These three things together make writing the native formats use less time, use less memory, and be more reliable. ---. > One thing I noticed is the mt_hwe_vals variable in my code below is a MatrixTable and not a GroupedMatrixTable. Is this correct?. Yes, after you aggregate you get back an MT with a different column key. ---. The `entries` method converts your matrix table from a compact and efficient matrix into a ""long"" and inefficient table. I generally recommend avoiding it if you can. However, if you only have a handful of ancestries, I wouldn't expect this to be *that* bad. You can just write the MT itself:. ```python3; ancestry_table = hl.Table.from_pandas(ancestry.astype({""person_id"":str}), key='person_id'); mt = mt.annotate_cols(ancestry = ancestry_table[mt.s].ancestry); mt_hwe_vals = mt.group_cols_by(mt.ancestry).aggregate(hwe = hl.agg.hardy_weinberg_test(mt.GT)); mt_hwe_vals = mt_hwe_vals.select_rows().select_cols() # drop irrelevant row and column fields; mt_hwe_vals.write(bucket + '/hwe.ht'); ```. ---. > I tried modifying the code to what is shown below but I'm still having the same issue. Just to be clear it's the exact same error ""Container exited with a non-zero exit code 137. ""? This makes me think we have an issue with `entries`, because, even though it's not great, it shouldn't be blowing RAM here. Can you share the log file from your previous or next attempt?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287#issuecomment-1679755636:699,reliab,reliable,699,https://hail.is,https://github.com/hail-is/hail/issues/13287#issuecomment-1679755636,2,"['error', 'reliab']","['error', 'reliable']"
Availability,"> Would it just be index which is the correct path relative to the metadata file?. Yes. So you should take the index path in the metadata interpreted with respect to the base of the index file (directory) rather than hardcoding it. This might seem like overkill but this flexibility has proved useful for the Matrix/Table format and I'd like to copy the idiom here. > I don't use the firstKeyOffset in the internal nodes anywhere. What were you envisioning it would be used for? Otherwise, I think we should delete it. So having indices like this effectively make a Matrix/Table arbitrarily repartitionable. For example, we can double the partitioning for free by splitting one partition into two by splitting at the roughly the midpoint row which I want to get from the root block. That's what I was thinking firstKeyOffset would be used for. This would be for a rough split. For a split accurate to the row-level, we'd have to read down to the leaf node blocks. Maybe this isn't really worth it. I'm on the fence. Delete it if you want. I thought of one more thing we should support in the file: store arbitrary user annotations of the keys. If the annotation is `+struct {}` it would have no overhead. This will give us some future flexibility and I can imagine the following use case: When we go to a sparse VCF, we'll want to store ""checkpoint"" rows to avoid having to search backward arbitrarily far to find ref blocks that might overlap with our variant of interest. The alternative is to make the first row of each partition a checkpoint block, but in that case, we can no longer seek into the middle of the partition if we want to track overlapping ref blocks. So we want to search for the first checkpoint row before our row of interest. Can we add this to the format but not use it?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4049#issuecomment-412184897:934,down,down,934,https://hail.is,https://github.com/hail-is/hail/pull/4049#issuecomment-412184897,4,"['checkpoint', 'down']","['checkpoint', 'down']"
Availability,"> Your tool should also examine the first word of the MAKEFLAGS variable and look for the character n. If this character is present then make was invoked with the -n option and your tool should stop without performing any operations. Added. > Your tool should be sure to write back the tokens it read, even under error conditions. This includes not only errors in your tool but also outside influences such as interrupts (SIGINT), etc. You may want to install signal handlers to manage this write-back. I mean, I doubt anyone is sending signals other than SIGKILL to our build system, but I added some signal handlers that just `sys.exit(0)` which triggers the finally (I checked). > We also get a lot of warning: jobserver unavailable: using -j1. Add +' to parent make rule.warnings when runningmake jvm-test`. This is because our C++ backend uses make to drive compilation (wtf). I strip MAKEFLAGS before calling gradle now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6923#issuecomment-524446104:315,error,error,315,https://hail.is,https://github.com/hail-is/hail/pull/6923#issuecomment-524446104,2,['error'],"['error', 'errors']"
Availability,"> [!WARNING]; > <b>This pull request is not mergeable via GitHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14533?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14533** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14533?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> ; * **#14509** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14509?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14514** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14514?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14554](https://github.com/hail-is/hail/pull/14554) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14554?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14517** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14517?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14533#issuecomment-2098889324:75,down,downstack,75,https://hail.is,https://github.com/hail-is/hail/pull/14533#issuecomment-2098889324,2,['down'],"['downstack', 'downstack-mergeability-warning']"
Availability,"> [!WARNING]; > <b>This pull request is not mergeable via GitHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14663?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14663** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14663?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> ; * **#14662** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14662?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14663#issuecomment-2302524299:75,down,downstack,75,https://hail.is,https://github.com/hail-is/hail/pull/14663#issuecomment-2302524299,2,['down'],"['downstack', 'downstack-mergeability-warning']"
Availability,"> [!WARNING]; > <b>This pull request is not mergeable via GitHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14686?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14731** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14731?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14732](https://github.com/hail-is/hail/pull/14732) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14732?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14748](https://github.com/hail-is/hail/pull/14748) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14748?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14698** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14698?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14696** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14696?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14693** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14693?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14692** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14692?utm_source=stack-comment-icon"" targ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14686#issuecomment-2354274670:75,down,downstack,75,https://hail.is,https://github.com/hail-is/hail/pull/14686#issuecomment-2354274670,2,['down'],"['downstack', 'downstack-mergeability-warning']"
Availability,"> [!WARNING]; > <b>This pull request is not mergeable via GitHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14690?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14731** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14731?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14732](https://github.com/hail-is/hail/pull/14732) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14732?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14748](https://github.com/hail-is/hail/pull/14748) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14748?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14698** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14698?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14696** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14696?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14693** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14693?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14692** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14692?utm_source=stack-comment-icon"" targ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14690#issuecomment-2356990835:75,down,downstack,75,https://hail.is,https://github.com/hail-is/hail/pull/14690#issuecomment-2356990835,2,['down'],"['downstack', 'downstack-mergeability-warning']"
Availability,"> [!WARNING]; > <b>This pull request is not mergeable via GitHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14691?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14731** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14731?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14732](https://github.com/hail-is/hail/pull/14732) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14732?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14748](https://github.com/hail-is/hail/pull/14748) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14748?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14698** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14698?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14696** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14696?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14693** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14693?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14692** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14692?utm_source=stack-comment-icon"" targ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14691#issuecomment-2357221524:75,down,downstack,75,https://hail.is,https://github.com/hail-is/hail/pull/14691#issuecomment-2357221524,2,['down'],"['downstack', 'downstack-mergeability-warning']"
Availability,"> [!WARNING]; > <b>This pull request is not mergeable via GitHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14692?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14731** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14731?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14732](https://github.com/hail-is/hail/pull/14732) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14732?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14748](https://github.com/hail-is/hail/pull/14748) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14748?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14698** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14698?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14696** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14696?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14693** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14693?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14692** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14692?utm_source=stack-comment-icon"" targ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14692#issuecomment-2358958754:75,down,downstack,75,https://hail.is,https://github.com/hail-is/hail/pull/14692#issuecomment-2358958754,2,['down'],"['downstack', 'downstack-mergeability-warning']"
Availability,"> [!WARNING]; > <b>This pull request is not mergeable via GitHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14693?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14731** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14731?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14732](https://github.com/hail-is/hail/pull/14732) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14732?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14748](https://github.com/hail-is/hail/pull/14748) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14748?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14698** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14698?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14696** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14696?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14693** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14693?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> ; * **#14692** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14692?utm_source=stack-comment-icon"" ta",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14693#issuecomment-2362149504:75,down,downstack,75,https://hail.is,https://github.com/hail-is/hail/pull/14693#issuecomment-2362149504,2,['down'],"['downstack', 'downstack-mergeability-warning']"
Availability,"> [!WARNING]; > <b>This pull request is not mergeable via GitHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14696?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14731** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14731?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14732](https://github.com/hail-is/hail/pull/14732) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14732?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14748](https://github.com/hail-is/hail/pull/14748) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14748?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14698** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14698?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14696** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14696?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> ; * **#14693** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14693?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14692** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14692?utm_source=stack-comment-icon"" ta",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14696#issuecomment-2362438406:75,down,downstack,75,https://hail.is,https://github.com/hail-is/hail/pull/14696#issuecomment-2362438406,2,['down'],"['downstack', 'downstack-mergeability-warning']"
Availability,"> [!WARNING]; > <b>This pull request is not mergeable via GitHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14698?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14731** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14731?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14732](https://github.com/hail-is/hail/pull/14732) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14732?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14748](https://github.com/hail-is/hail/pull/14748) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14748?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14698** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14698?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> ; * **#14696** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14696?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14693** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14693?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14692** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14692?utm_source=stack-comment-icon"" ta",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14698#issuecomment-2364681873:75,down,downstack,75,https://hail.is,https://github.com/hail-is/hail/pull/14698#issuecomment-2364681873,2,['down'],"['downstack', 'downstack-mergeability-warning']"
Availability,"> [!WARNING]; > <b>This pull request is not mergeable via GitHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14731?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14731** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14731?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14732](https://github.com/hail-is/hail/pull/14732) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14732?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14748](https://github.com/hail-is/hail/pull/14748) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14748?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>) ; * **#14698** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14698?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14696** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14696?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14693** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14693?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14692** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14692?utm_source=stack-comment-icon"" ta",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417750658:75,down,downstack,75,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417750658,2,['down'],"['downstack', 'downstack-mergeability-warning']"
Availability,"> [!WARNING]; > <b>This pull request is not mergeable via GitHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14732?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14732** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14732?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> ; * **#14731** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14731?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14748](https://github.com/hail-is/hail/pull/14748) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14748?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14698** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14698?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14696** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14696?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14693** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14693?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14692** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14692?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://sta",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14732#issuecomment-2419668108:75,down,downstack,75,https://hail.is,https://github.com/hail-is/hail/pull/14732#issuecomment-2419668108,2,['down'],"['downstack', 'downstack-mergeability-warning']"
Availability,"> [!WARNING]; > <b>This pull request is not mergeable via GitHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14747?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14751** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14751?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14747** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14747?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> ; * **#14684** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14684?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14686](https://github.com/hail-is/hail/pull/14686) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14686?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14683** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14683?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @grohli and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Grap",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14747#issuecomment-2438734907:75,down,downstack,75,https://hail.is,https://github.com/hail-is/hail/pull/14747#issuecomment-2438734907,2,['down'],"['downstack', 'downstack-mergeability-warning']"
Availability,"> [!WARNING]; > <b>This pull request is not mergeable via GitHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14748?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14748** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14748?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> ; * **#14731** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14731?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14732](https://github.com/hail-is/hail/pull/14732) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14732?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14698** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14698?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14696** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14696?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14693** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14693?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14692** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14692?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://sta",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14748#issuecomment-2444958196:75,down,downstack,75,https://hail.is,https://github.com/hail-is/hail/pull/14748#issuecomment-2444958196,2,['down'],"['downstack', 'downstack-mergeability-warning']"
Availability,"> [!WARNING]; > <b>This pull request is not mergeable via GitHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14751?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14751** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14751?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> ; * **#14747** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14747?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14684** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14684?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14686](https://github.com/hail-is/hail/pull/14686) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14686?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14683** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14683?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @grohli and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Grap",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14751#issuecomment-2457987492:75,down,downstack,75,https://hail.is,https://github.com/hail-is/hail/pull/14751#issuecomment-2457987492,2,['down'],"['downstack', 'downstack-mergeability-warning']"
Availability,"> agree: api is in GH, ergo public, so only point of contention is:. It's public to people who read GitHub and hail docs. It isn't really public to someone who is probing around for endpoints to exploit. > Yes, because I know I will make mistakes (and users will make config mistakes) and I want an easily debuggable system. Sure. > The risk is that an attacker may learn /jobs exists. If that knowledge substantially improves an attacker's ability to infiltrate batch, then we've made a severe error in securing batch. I agree in general, except I think of the problem seemingly inversely. If providing 401/403 responses to the end user substantially improves their experience, then we should do it. If not we shouldn't, because the degree to which an attacker is ""substantially"" enabled, is in my mind anything other than 0. Battles can be lost by small degrees. The choices should be user driven. . I think you told me that your system benefits, so let's do it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5844#issuecomment-483797170:495,error,error,495,https://hail.is,https://github.com/hail-is/hail/pull/5844#issuecomment-483797170,1,['error'],['error']
Availability,"> all options that are also gcloud options (such as --project)? [That] could be difficult. Yes, this is what I was thinking. `hailctl` could parse (as much as is needed) the `gcloud` options to find options (like `--project`) and modify others (like `--initialization-actions`). The latter is somewhat surprising since one expects everything after the `--` to pass through unchanged. OK, summarizing our options so far:. - hailctl has no options that are also gcloud options. gcloud options go after the `--`, and get modified as needed by hailctl (with a message).; - hailctl has no gcloud options that are simply pass through. gcloud options that are needed by hailctl commands are hailctl options (like `--project`). When a gcloud option is needed by some hailctl command, all hailctl commands take that option (when it makes sense), even if in some cases that makes them simply pass through. This fixes the inconsistency issues, but the user still needs to keep track of which gcloud options needs to be passed to hailctl and which are passed to gcloud directly. If you specify an option twice, once to hailctl and once to gcloud, we invoke gcloud with the option duplicated. Pros and cons:; - The first option has the most consistent interface.; - The first option modifies options after the --, which is surprising.; - The first option involves replication (some of) the gcloud option parsing semantics, which is annoying.; - The second option requires the user to know which gcloud options need to be passed to hailctl instead (but globally, not per-command).; - With the second option, if we want to warn (or error) on duplicate options, we're back to duplicating the gcloud option parsing logic. I think I'm coming around to the second option. > so that hailctl dataproc submit cluster -- --script-options would work. I see, so if there is only one `--` it refers to script options, and if there are two, the first one corresponds to gcloud options? I think that should be doable.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842#issuecomment-758128554:1617,error,error,1617,https://hail.is,https://github.com/hail-is/hail/pull/9842#issuecomment-758128554,1,['error'],['error']
Availability,"> can pass down an allocator that returns regions backed by a single fixed RegionMemory, with no-op freeing. Even this may be expensive when we're doing something like ToArray(StreamRange). Let's start by benchmarking and seeing where we're at with the current benchmarks?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9106#issuecomment-661888188:11,down,down,11,https://hail.is,https://github.com/hail-is/hail/pull/9106#issuecomment-661888188,1,['down'],['down']
Availability,> how it's impossible to use timings currently inside cleanup blocks because it could accidentally re-raise a deleted error. Can you explain this to me? I saw Dan had a comment as well in the JVMJob that stated this. Our code seems to be always this:. ```; try:; with self.step('running'):; self.run_until_deleted or completed(); finally:; with self.step('uploading log'):; self.upload_log(); ```. The upload log step should propagate the deletion error from above.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11429#issuecomment-1054581169:118,error,error,118,https://hail.is,https://github.com/hail-is/hail/pull/11429#issuecomment-1054581169,2,['error'],['error']
Availability,"> if there's a problem with the expression, I don't want to get a crash from a requirementError from the Variant constructor without any context. You need to do validation in the expr code. User could isn't allowed to fail with a requirement error. I'd solve the error message problem by carrying it along with the annotation. Line can be generalized to carry line information about any type. > My CNV work involves parallelizing file parsing, and this interface wouldn't be compatible with that use case. I don't understand, can you elaborate on this?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/462#issuecomment-233005833:242,error,error,242,https://hail.is,https://github.com/hail-is/hail/pull/462#issuecomment-233005833,2,['error'],['error']
Availability,> infinitely retry transient errors with exponential backoff and no retry of non-transient errors. In other words: Do or do not. There is no try.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7875#issuecomment-574380438:29,error,errors,29,https://hail.is,https://github.com/hail-is/hail/pull/7875#issuecomment-574380438,2,['error'],['errors']
Availability,"> it seems to provide visibility into what happened during the last run of lets encrypt?. Yes. As far as I know, certbot needs the previous config to do a renew (which I'm not doing yet). > I think the ""sidecar"" approach is simpler than this one (no extra nginx instance, no secrets, no service, no k8s secret creation privileges). We beef up the nginx pod to have a second container sharing a letsencrypt volume (which we've already defined in this PR). You can't mount volumes to multiple pods. You can't even mount volumes to the SAME pod if you want to do rolling updates (because the new instance can't launch because the old one is mounting the volume). I think this means volumes for certs and web root are out. volumes only work for replicated StatefulSets where you can take down one instance at a time for updates.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4624#issuecomment-432724868:784,down,down,784,https://hail.is,https://github.com/hail-is/hail/pull/4624#issuecomment-432724868,1,['down'],['down']
Availability,"> looks like a compile error in TestUtils.scala.; > ; > The rest looks good, will approve when tests pass. I fixed `TestUtils.scala`; the issue was a missing parameter in a call to the (changed) `MatrixVCFReader`. Should I rebase and squash all of my commits into a single commit, or are you OK with merging my branch with the discrete feature commits (i.e., non-""Merge remote-tracking branch"" commits)?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5077#issuecomment-453215900:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/pull/5077#issuecomment-453215900,1,['error'],['error']
Availability,> need it to be offline unless we're willing to tolerate up to 5-10 mins of not being able to cancel a batch and some alerts. I want as much as possible for alerts to mean something unexpected is going wrong. If we can I think this should just be done offline.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13810#issuecomment-1812859285:48,toler,tolerate,48,https://hail.is,https://github.com/hail-is/hail/pull/13810#issuecomment-1812859285,1,['toler'],['tolerate']
Availability,> one approach is to build a Bitnami package. I'll ping them to get a sense on pricing.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-410367637:51,ping,ping,51,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410367637,1,['ping'],['ping']
Availability,"> printing an error. Error sounds like you're going to exit and not do anything. But you mean print out a message and don't label but still create the cluster? That seems fine, although munging seems more informational, that is, it's an error to us/Sam, not the user, esp. since they can't do anything about it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6276#issuecomment-499694220:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/pull/6276#issuecomment-499694220,3,"['Error', 'error']","['Error', 'error']"
Availability,> pytest-instafail is a plugin for py.test that shows failures and errors instantly instead of waiting until the end of test session. https://github.com/pytest-dev/pytest-instafail/,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6854:54,failure,failures,54,https://hail.is,https://github.com/hail-is/hail/pull/6854,2,"['error', 'failure']","['errors', 'failures']"
Availability,"> retry every deadlock in two deadlock prone SQL operations. I prefer @jigold's change which is almost ready: https://github.com/hail-is/hail/pull/7782. > retry every docker 500 error, it's 500, not our fault, just retry, right?. 500 is meaningless, docker returns 500 for everything. I'm quite concerned about infinite retry loops here, and I'd rather have documentation on the errors we're getting from docker if possible. Looking over the other changes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7783#issuecomment-568580624:178,error,error,178,https://hail.is,https://github.com/hail-is/hail/pull/7783#issuecomment-568580624,3,"['error', 'fault']","['error', 'errors', 'fault']"
Availability,"> slight nitpick---can we call this ""error"" or ""raise_error"" or something less dire sounding than ""die""?. or some version of `except` for parallelism with python?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8865#issuecomment-634380327:37,error,error,37,https://hail.is,https://github.com/hail-is/hail/pull/8865#issuecomment-634380327,1,['error'],['error']
Availability,"> submit 50-way parallel bunch, with a maximum of (by default) 10 individual request failures; > if any request fails, raise an exception, which is caught by outer submit, which retries a configurable number of times, logging a configurable number of errors. I haven't dug into the PR yet, but will just remark I'm going to argue pretty strenuously to maintain our current model here: infinitely retry transient errors with exponential backoff and no retry of non-transient errors.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7875#issuecomment-574377227:85,failure,failures,85,https://hail.is,https://github.com/hail-is/hail/pull/7875#issuecomment-574377227,4,"['error', 'failure']","['errors', 'failures']"
Availability,"> the above has plenty of errors, surrounding attempts to cast PCanonicalArray to PStream. where do these errors appear?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-586598443:26,error,errors,26,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-586598443,2,['error'],['errors']
Availability,"> the failure from run() is still tracked. Is that true? When we get out-of-memory errors, doesn't `run` just return?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12838#issuecomment-1527648997:6,failure,failure,6,https://hail.is,https://github.com/hail-is/hail/pull/12838#issuecomment-1527648997,2,"['error', 'failure']","['errors', 'failure']"
Availability,"> validation. Checking the arguments to the `Variant` constructor and generating nice error messages. For CNV work, you want to parallelize over files and not lines within files? You need to process the each file serially?. I'm not against having an additional interface like ParseContext that you can use both for the RDD interface and for the CNV stuff. Another option might be to make `TableReader[C[_]](...): (TStruct, C[Annotation])` but you'll have to do some work to define a `C` that knows how to load itself from a file, for example. It would be useful to be able to write code that can be used with either RDDs or local collections. > For the 'annotation line' are you suggesting a general error-catching wrapper?. Yep! I'll look over your proposed interface. Letting my mind wander a little here. One of the challenges with Spark error handling is propagating errors from the workers back to the master. RDDs are naturally used functionally, so functional error handling might be a better approach. The `Try` monad is the normal way to do functional error handling in Scala. Since we have concurrency, we have multiple errors and we want to preserve them all. In addition, it would be nice if the new generalized `Try` monad tracked warnings (like VCFReport). The main thing it isn't clear how to handle is writing RDDs. You basically want a write to write out the values and return an RDD, but just with the errors and warnings, which you could transfer to the driver at the end with collect.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/462#issuecomment-233041581:86,error,error,86,https://hail.is,https://github.com/hail-is/hail/pull/462#issuecomment-233041581,8,['error'],"['error', 'error-catching', 'errors']"
Availability,"> we don't wait for all JVMs to be intitialized before accepting JVM jobs and the queue is FIFO so we reuse the same JVMs that are warm already?. No. We have no way to accept only JVM jobs or only Batch jobs, so we either accept all jobs or no jobs. In main, we accept jobs before the JVMs have initialized. We wait for all JVMs to initialize before giving JVMs to any JVM Job. So, concretely, in main and in this PR we *accept* jobs before JVMs are ready; however, in this PR we don't wait for all JVMs to initialize before *running* jobs. There are two improvements in this PR:; 1. If a JVM with the requested number of cores is available, allow the requesting JVMJob to start before the remaining JVMs are initialized.; 2. Rather than starting all the JVMs in parallel, start JVMs serially *and also* start them in the order that they are requested. If we have three waiting JVM Jobs two requesting 1 core and one requesting 4 cores, prefer to start JVMs with 1 and 4 cores to JVMs with 2 or 8 cores. (2) might sound slower (why start serially when we can stat in parallel?) but it appears that 30 JVMs competing for CPU time dramatically slows down average start up time. In both main and this PR it takes about ~25s for all JVMs to be ready; however, in this PR, some jobs can start much sooner than 25s b/c their JVMs are started first.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13870#issuecomment-1775517156:631,avail,available,631,https://hail.is,https://github.com/hail-is/hail/pull/13870#issuecomment-1775517156,2,"['avail', 'down']","['available', 'down']"
Availability,"> what ends up in /home/cotton/hail-20200407-1502-0.2.36-75a0f869d72d.log? What happens to the usual Spark/Hail master logs?. The client and the server are now separated by a machine boundary, so just the Python client logs end up in the client log. That's basically nothing and can probably be removed when using the client with the service. There are no Spark logs, the service is 100% Spark-free. The Hail master logs end up in the query service logs. Obviously a lot of this needs to be rethough and improved. The error checking and reporting needs to get improved at the service boundary, errors should be relative to the input, and clients probably shouldn't get a server-side stack trace. We're going to need additional tools for debugging pipelines on the master, and probably want an admin UI where you get the logs for each query, the IR getting executed, how it was transformed with lowering/optimization, statistics on timing of its execution, etc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8485#issuecomment-610628050:518,error,error,518,https://hail.is,https://github.com/hail-is/hail/pull/8485#issuecomment-610628050,2,['error'],"['error', 'errors']"
Availability,">#15690</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Add scroll margin to headings for better alignment <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15703"">#15703</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Fix shortcut UI failing on filtering when empty command is given <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15695"">#15695</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Fix connection loop issue with standalone foreign document in LSP <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15262"">#15262</a> (<a href=""https://github.com/trungleduc""><code>@trungleduc</code></a>)</li>; <li>Fix outputarea package from not detecting updates <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15642"">#15642</a> (<a href=""https://github.com/MFA-X-AI""><code>@MFA-X-AI</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15524"">#15524</a>: Fix visual tests <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15578"">#15578</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; </ul>; <h3>Documentation improvements</h3>; <ul>; <li>Remove Python 3.0, Notebook 5 mentions from contributor docs <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15710"">#15710</a> (<a href=""https://github.com/JasonWeill""><code>@JasonWeill</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/graphs/contributors?from=2024-01-19&amp;to=2024-01-30&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3AFoSuCloud+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@FoSuCloud</code></a> | <a href=""https://github",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:1791,Mainten,Maintenance,1791,https://hail.is,https://github.com/hail-is/hail/pull/14218,2,['Mainten'],['Maintenance']
Availability,">::run(const T&) [with R = simdpp::arch_avx2::int16<16>; T = simdpp::arch_avx2::uint16<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int16<16>; T = simdpp::arch_avx2::uint16<16>]; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:56:36: required from simdpp::arch_avx2::int16<16>& simdpp::arch_avx2::int16<16>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint16<16>]; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:49:75: required from simdpp::arch_avx2::int16<16>::int16(const simdpp::arch_avx2::uint16<16, E>&) [with E = void]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:64:29: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int16<16> with private member simdpp::arch_avx2::int16<16>::d_ from an array of const class simdpp::arch_avx2::uint16<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:22,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:33:7: note: class simdpp::arch_avx2::int16<16> declared here; class int16<16, void> : public any_int16<16, int16<16,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int64<2>; T = simdpp::arch_avx2::uint64<2>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:106947,error,error,106947,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,">::run(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint16<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint16<16>]; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:114:36: required from simdpp::arch_avx2::uint8<32>& simdpp::arch_avx2::uint8<32>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::expr_bit_and<simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::uint8<32> >, simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::uint16<16> > > >]; libsimdpp-2.0-rc2/simdpp/detail/insn/unzip_lo.h:56:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<32> with private member simdpp::arch_avx2::uint8<32>::d_ from an array of const class simdpp::arch_avx2::uint16<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: class simdpp::arch_avx2::uint8<32> declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint32<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:30641,error,error,30641,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,">; <h3>Features</h3>; <ul>; <li>Add support for Python 3.10 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/143"">#143</a>) (<a href=""https://github.com/googleapis/python-api-common-protos/commit/63ca888512be84508fcf95e4d5d40df036a85e18"">63ca888</a>)</li>; <li>Add support for Python 3.11 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/145"">#145</a>) (<a href=""https://github.com/googleapis/python-api-common-protos/commit/b9dbb219ea46abd9851af1fc41ea37f9d5631c0b"">b9dbb21</a>)</li>; <li>added google.api.JwtLocation.cookie (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; <li>added google.api.Service.publishing and client libraries settings (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; <li>new fields in enum google.api.ErrorReason (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li>deprecate google.api.BackendRule.min_deadline (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; <li><strong>deps:</strong> Require protobuf &gt;=3.19.5 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/141"">#141</a>) (<a href=""https://github.com/googleapis/python-api-common-protos/commit/9ea3530b459269e964fcc98db1c5025e05d6495f"">9ea3530</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>minor updates to comments (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-api-common-protos/blo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12514:1439,Error,ErrorReason,1439,https://hail.is,https://github.com/hail-is/hail/pull/12514,1,['Error'],['ErrorReason']
Availability,">; <h3>Features</h3>; <ul>; <li>Add support for Python 3.10 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/143"">#143</a>) (<a href=""https://github.com/googleapis/python-api-common-protos/commit/63ca888512be84508fcf95e4d5d40df036a85e18"">63ca888</a>)</li>; <li>Add support for Python 3.11 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/145"">#145</a>) (<a href=""https://github.com/googleapis/python-api-common-protos/commit/b9dbb219ea46abd9851af1fc41ea37f9d5631c0b"">b9dbb21</a>)</li>; <li>added google.api.JwtLocation.cookie (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; <li>added google.api.Service.publishing and client libraries settings (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; <li>new fields in enum google.api.ErrorReason (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li>deprecate google.api.BackendRule.min_deadline (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; <li><strong>deps:</strong> Require protobuf &gt;=3.19.5 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/141"">#141</a>) (<a href=""https://github.com/googleapis/python-api-common-protos/commit/9ea3530b459269e964fcc98db1c5025e05d6495f"">9ea3530</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>minor updates to comments (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/0ee8d805",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12514:3649,Error,ErrorReason,3649,https://hail.is,https://github.com/hail-is/hail/pull/12514,1,['Error'],['ErrorReason']
Availability,">; <li>Correctly create list of output files (even if the destination is the project's build directory)</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Use pooling connection manager of Apache HttpClient instead of basic one. The basic one is not meant to be used by multiple threads. This fixes an issue that could cause an <code>IllegalStateException</code> with the message <code>Connection is still allocated</code>. Thanks to <a href=""https://github.com/dmarks2""><code>@dmarks2</code></a> for spotting this.</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>eachFile</code> method that adds an action to be applied to each source URL before it is downloaded. The action can be used to modify the filename of the target file.</li>; <li>Add <code>runAsync</code> method to download extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:1838,down,downloaded,1838,https://hail.is,https://github.com/hail-is/hail/pull/12345,2,['down'],"['download', 'downloaded']"
Availability,">; <li>Optimize ImageStat.Stat.extrema <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7593"">#7593</a> [<a href=""https://github.com/florath""><code>@florath</code></a>]</li>; <li>Handle pathlib.Path in FreeTypeFont <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7578"">#7578</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Use list comprehensions to create transformed lists <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7597"">#7597</a> [<a href=""https://github.com/hugovk""><code>@hugovk</code></a>]</li>; <li>Added support for reading DX10 BC4 DDS images <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7603"">#7603</a> [<a href=""https://github.com/sambvfx""><code>@sambvfx</code></a>]</li>; <li>Optimized ImageStat.Stat.count <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7599"">#7599</a> [<a href=""https://github.com/florath""><code>@florath</code></a>]</li>; <li>Moved error from truetype() to FreeTypeFont <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7587"">#7587</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Correct PDF palette size when saving <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7555"">#7555</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Fixed closing file pointer with olefile 0.47 <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7594"">#7594</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>ruff: Minor optimizations of list comprehensions, x in set, etc. <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7524"">#7524</a> [<a href=""https://github.com/cclauss""><code>@cclauss</code></a>]</li>; <li>Build Windows wheels using cibuildwheel <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7580"">#7580</a> [<a href=""https://github.com/nulano""><code>@nulano</code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14191:8198,error,error,8198,https://hail.is,https://github.com/hail-is/hail/pull/14191,3,['error'],['error']
Availability,>; <li>api-change:<code>timestream-query</code>: [<code>botocore</code>] Documentation only update for SDK and CLI</li>; </ul>; <h1>1.21.11</h1>; <ul>; <li>api-change:<code>gamelift</code>: [<code>botocore</code>] Minor updates to address errors.</li>; <li>api-change:<code>cloudtrail</code>: [<code>botocore</code>] Add bytesScanned field into responses of DescribeQuery and GetQueryResults.</li>; <li>api-change:<code>athena</code>: [<code>botocore</code>] This release adds support for S3 Object Ownership by allowing the S3 bucket owner full control canned ACL to be set when Athena writes query results to S3 buckets.</li>; <li>api-change:<code>keyspaces</code>: [<code>botocore</code>] This release adds support for data definition language (DDL) operations</li>; <li>api-change:<code>ecr</code>: [<code>botocore</code>] This release adds support for tracking images lastRecordedPullTime.</li>; </ul>; <h1>1.21.10</h1>; <ul>; <li>api-change:<code>mediapackage</code>: [<code>botocore</code>] This release adds Hybridcast as an available profile option for Dash Origin Endpoints.</li>; <li>api-change:<code>rds</code>: [<code>botocore</code>] Documentation updates for Multi-AZ DB clusters.</li>; <li>api-change:<code>mgn</code>: [<code>botocore</code>] Add support for GP3 and IO2 volume types. Add bootMode to LaunchConfiguration object (and as a parameter to UpdateLaunchConfigurationRequest).</li>; <li>api-change:<code>kafkaconnect</code>: [<code>botocore</code>] Adds operation for custom plugin deletion (DeleteCustomPlugin) and adds new StateDescription field to DescribeCustomPlugin and DescribeConnector responses to return errors from asynchronous resource creation.</li>; </ul>; <h1>1.21.9</h1>; <ul>; <li>api-change:<code>finspace-data</code>: [<code>botocore</code>] Add new APIs for managing Users and Permission Groups.</li>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Add repositoryCloneMethod field for hosting an Amplify app. This field shows what authorizati,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11486:2036,avail,available,2036,https://hail.is,https://github.com/hail-is/hail/pull/11486,2,['avail'],['available']
Availability,">; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>eachFile</code> method that adds an action to be applied to each source URL before it is downloaded. The action can be used to modify the filename of the target file.</li>; <li>Add <code>runAsync</code> method to download extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0f43ce67de72bd511d849c07bd7728c0d6f2e6dd""><code>0f43ce6</code></a> Document path and relativePath properties</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a8504f9d60d0264808894e4bb80d4a73b8086a3e""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:2479,Mainten,Maintenance,2479,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['Mainten'],['Maintenance']
Availability,">; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>eachFile</code> method that adds an action to be applied to each source URL before it is downloaded. The action can be used to modify the filename of the target file.</li>; <li>Add <code>runAsync</code> method to download extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.5</h2>; <p>Maintenance:</p>; <ul>; <li>Publish signed artifacts to Gradle plugin portal</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.4</h2>; <p>Bug fixes:</p>; <ul>; <li>Fix deadlock in <code>DownloadExtension</code> if <code>max-workers</code> equals 1 (thanks to <a href=""https://github.com/beatbrot""><code>@beatbrot</code></a> for spotting this, see <a href=""https://github-redirect.dependabot.com/michel-kraeme",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:1760,Mainten,Maintenance,1760,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['Mainten'],['Maintenance']
Availability,"></li>; </ul>; <h2>pytest-asyncio 0.23.4a2</h2>; <h1>0.23.4 (UNRELEASED)</h1>; <ul>; <li>pytest-asyncio no longer imports additional, unrelated packages during test collection <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/729"">#729</a></li>; <li>Addresses further issues that caused an internal pytest error during test collection</li>; </ul>; <h2>Known issues</h2>; <p>As of v0.23, pytest-asyncio attaches an asyncio event loop to each item of the test suite (i.e. session, packages, modules, classes, functions) and allows tests to be run in those loops when marked accordingly. Pytest-asyncio currently assumes that async fixture scope is correlated with the new event loop scope. This prevents fixtures from being evaluated independently from the event loop scope and breaks some existing test suites (see <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/706"">#706</a>). For example, a test suite may require all fixtures and tests to run in the same event loop, but have async fixtures that are set up and torn down for each module. If you're affected by this issue, please continue using the v0.21 release, until it is resolved.</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/c34da04b82153ce052109bad31ccdbc0be7938e1""><code>c34da04</code></a> [docs] Mentioned pytest 8.2 compatibility fix in changelog.</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/143f745d279afc070cf5cf6144fbf34d960fae72""><code>143f745</code></a> Fix compatibility with pytest 8.2 FixtureDef.unittest removal</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/13d4b79f7ff0d9d0ea70880b3276f85dea7f1f15""><code>13d4b79</code></a> Remove unused function <code>_removesuffix</code></li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/cdd2c4906835b6f627d681fbee5d487554884e5f"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14507:6736,down,down,6736,https://hail.is,https://github.com/hail-is/hail/pull/14507,1,['down'],['down']
Availability,"><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **661/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 7.5 | Improper Neutralization of Special Elements in Data Query Logic <br/>[SNYK-PYTHON-MSAL-5904284](https://snyk.io/vuln/SNYK-PYTHON-MSAL-5904284) | `msal:` <br> `1.24.0 -> 1.24.1` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhYjlhNGM2ZS0xOTg1LTRmYTctYj",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13753:1117,avail,available,1117,https://hail.is,https://github.com/hail-is/hail/pull/13753,1,['avail'],['available']
Availability,">> the store methods on PString should take a Code[String], not a Code[Array[Byte]], I think. Done, however this is a bit awkward, and I suspect a source of future error, because in order to pStringInstance.allocate you need to know the byte length, not the string/code point length. So I thought to make allocate take a string instead of length. However, if you have the string at the time of allocation, and pass it to allocate, you probably intend to store it, in which case you pay the cost of 2x the number of calls to getBytes. Therefore I made an `allocateAndStoreString` method, which takes care of both steps, potentially more efficiently, but also more ergonomically. I left the allocate(region: Region, length: Int) and store(addr: Long, str: String) methods, though we have no current use for them so I worry will wind up as bloat.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7904#issuecomment-576358168:164,error,error,164,https://hail.is,https://github.com/hail-is/hail/pull/7904#issuecomment-576358168,1,['error'],['error']
Availability,">@ahg-g</code></a>)</li>; <li>Promote IdentifyPodOS feature to beta. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107859"">kubernetes/kubernetes#107859</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@ravisantoshgudimetla</code></a>)</li>; <li>Remove a v1alpha1 networking API for ClusterCIDRConfig (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/109436"">kubernetes/kubernetes#109436</a>, <a href=""https://github.com/JamesLaverack""><code>@JamesLaverack</code></a>)</li>; <li>Renamed metrics <code>evictions_number</code> to <code>evictions_total</code> and mark it as stable. The original <code>evictions_number</code> metrics name is marked as &quot;Deprecated&quot; and has been removed in kubernetes 1.23 . (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106366"">kubernetes/kubernetes#106366</a>, <a href=""https://github.com/cyclinder""><code>@cyclinder</code></a>)</li>; <li>Skip x-kubernetes-validations rules if having fundamental error against the OpenAPIv3 schema. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108859"">kubernetes/kubernetes#108859</a>, <a href=""https://github.com/cici37""><code>@cici37</code></a>)</li>; <li>Support for gRPC probes is now in beta. GRPCContainerProbe feature gate is enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108522"">kubernetes/kubernetes#108522</a>, <a href=""https://github.com/SergeyKanzhelev""><code>@SergeyKanzhelev</code></a>)</li>; <li>Suspend job to GA. The feature gate <code>SuspendJob</code> is locked and will be removed in 1.26. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108129"">kubernetes/kubernetes#108129</a>, <a href=""https://github.com/ahg-g""><code>@ahg-g</code></a>)</li>; <li>The AnyVolumeDataSource feature is now beta, and the feature gate is enabled by default. In order to provide user feedback on PVCs with data s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:12664,error,error,12664,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['error'],['error']
Availability,">Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0f43ce67de72bd511d849c07bd7728c0d6f2e6dd""><code>0f43ce6</code></a> Document path and relativePath properties</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a8504f9d60d0264808894e4bb80d4a73b8086a3e""><code>a8504f9</code></a> Bump up version number to 5.3.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/708067cd11c4a013da7a8c15d91f7f946967cf94""><code>708067c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0fdebf3c7ad43ed4739d0400c333a72b32f5d514""><code>0fdebf3</code></a> Improve verify example</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/019089b9554692674d6baee7df7d4d884f310cc9""><code>019089b</code></a> Correctly create list of output files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/fa2739ded05333ba46d8f50bb3b2a3721cf0ca86""><code>fa2739d</code></a> Create target directories at a central place</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/02b8e1a79d9e00acd61f9ac42e5555619fe2247a""><code>02b8e1a</code></a> Prevent duplicate destination files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0b65ca2f17c8890a3ec34cf80cde52ee5413cbec""><code>0b65ca2</code></a> Call eachFile action only once per source</li>; <li><a href=""https:/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:3586,down,download-task,3586,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download-task']
Availability,">As of v0.23, pytest-asyncio attaches an asyncio event loop to each item of the test suite (i.e. session, packages, modules, classes, functions) and allows tests to be run in those loops when marked accordingly. Pytest-asyncio currently assumes that async fixture scope is correlated with the new event loop scope. This prevents fixtures from being evaluated independently from the event loop scope and breaks some existing test suites (see <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/706"">#706</a>). For example, a test suite may require all fixtures and tests to run in the same event loop, but have async fixtures that are set up and torn down for each module. If you're affected by this issue, please continue using the v0.21 release, until it is resolved.</p>; <h2>pytest-asyncio 0.23.5</h2>; <h1>0.23.5 (2024-02-09)</h1>; <ul>; <li>Declare compatibility with pytest 8 <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/737"">#737</a></li>; <li>Fix typing errors with recent versions of mypy <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/769"">#769</a></li>; <li>Prevent DeprecationWarning about internal use of <code>asyncio.get_event_loop()</code> from affecting test cases <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/757"">#757</a></li>; </ul>; <h2>Known issues</h2>; <p>As of v0.23, pytest-asyncio attaches an asyncio event loop to each item of the test suite (i.e. session, packages, modules, classes, functions) and allows tests to be run in those loops when marked accordingly. Pytest-asyncio currently assumes that async fixture scope is correlated with the new event loop scope. This prevents fixtures from being evaluated independently from the event loop scope and breaks some existing test suites (see <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/706"">#706</a>). For example, a test suite may require all fixtures and tests to run in the same event loop, but have as",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14507:2884,error,errors,2884,https://hail.is,https://github.com/hail-is/hail/pull/14507,1,['error'],['errors']
Availability,">Read more in the v2.0 Roadmap</a></p>; <p>:warning: <strong>This release will be the last release supporting Python 3.5. Please upgrade to a non-EOL Python version.</strong></p>; <ul>; <li>Added extra message to<code>urllib3.exceptions.ProxyError</code> when urllib3 detects that a proxy is configured to use HTTPS but the proxy itself appears to only use HTTP.</li>; <li>Added a mention of the size of the connection pool when discarding a connection due to the pool being full.</li>; <li>Added explicit support for Python 3.11.</li>; <li>Deprecated the <code>Retry.MAX_BACKOFF</code> class property in favor of <code>Retry.DEFAULT_MAX_BACKOFF</code> to better match the rest of the default parameter names. <code>Retry.MAX_BACKOFF</code> is removed in v2.0.</li>; <li>Changed location of the vendored <code>ssl.match_hostname</code> function from <code>urllib3.packages.ssl_match_hostname</code> to <code>urllib3.util.ssl_match_hostname</code> to ensure Python 3.10+ compatibility after being repackaged by downstream distributors.</li>; <li>Fixed absolute imports, all imports are now relative.</li>; </ul>; <h2>1.26.7</h2>; <p>:warning: <strong>IMPORTANT: urllib3 v2.0 will drop support for Python 2</strong>: <a href=""https://urllib3.readthedocs.io/en/latest/v2-roadmap.html"">Read more in the v2.0 Roadmap</a></p>; <ul>; <li>Fixed a bug with HTTPS hostname verification involving IP addresses and lack of SNI</li>; <li>Fixed a bug where IPv6 braces weren't stripped during certificate hostname matching</li>; </ul>; <p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=""https://github.com/sponsors/urllib3"">GitHub Sponsors</a></strong></p>; <h2>1.26.6</h2>; <p>:warning: <strong>IMPORTANT: urllib3 v2.0 will drop support for Python 2</strong>: <a href=""https://urllib3.readthedocs.io/en/latest/v2-roadmap.html"">Read more in the v2.0 Roadmap</a></p>; <ul>; <li>Deprecated the <code>urllib3.contrib.ntlmpool</code> module. urllib3 is not able to support it pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11532:1574,down,downstream,1574,https://hail.is,https://github.com/hail-is/hail/pull/11532,1,['down'],['downstream']
Availability,">See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.5/whatsnew/v1.5.0.html"">whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on conda-forge and PyPI.</p>; <p>The release can be installed from PyPI</p>; <pre><code>python -m pip install --upgrade --pre pandas==1.5.0rc0; </code></pre>; <p>Or from conda-forge</p>; <pre><code>conda install -c conda-forge/label/pandas_rc pandas==1.5.0rc0; </code></pre>; <p>Please report any issues with the release candidate on the pandas issue tracker.</p>; <h2>Pandas 1.4.4</h2>; <p>This is a patch release in the 1.4.x series and includes some regression and bug fixes. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4.4/whatsnew/v1.4.4.html"">full whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <p>Thanks to all the contributors who made this release possible.</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pandas-dev/pandas/commit/87cfe4e38bafe7300a6003a1d18bd80f3f77c763""><code>87cfe4e</code></a> RLS: 1.5.0</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/ecc700c8be8e4af2799dc18ce5f7e6328c80e976""><code>ecc700c</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48627"">#48627</a> on branch 1.5.x (DOC: Last changes to release notes for 1....</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/e726483d70938f3bff67e95358841a1f6271b149""><code>e726483</code></a> Backport PR <a href=""https://github-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12292:2004,avail,available,2004,https://hail.is,https://github.com/hail-is/hail/pull/12292,1,['avail'],['available']
Availability,">Update dependencies</li>; </ul>; <h2>5.0.5</h2>; <p>Maintenance:</p>; <ul>; <li>Publish signed artifacts to Gradle plugin portal</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.4</h2>; <p>Bug fixes:</p>; <ul>; <li>Fix deadlock in <code>DownloadExtension</code> if <code>max-workers</code> equals 1 (thanks to <a href=""https://github.com/beatbrot""><code>@beatbrot</code></a> for spotting this, see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/205"">#205</a>)</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1b5d69760d19cb7f88cbc837ee46456c494c0696""><code>1b5d697</code></a> Bump up version number to 5.2.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/7d6de83037ca41cd2f2f31830b43e43720e45b3a""><code>7d6de83</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1da8f078e22412475b694ce07b890148b8a5e4fc""><code>1da8f07</code></a> Add comment</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/9703f764df56c52626f7d6f44bca8b1d51312389""><code>9703f76</code></a> Use pooling connection manager instead of basic one</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/306172e4c6532e185c8a6a9998bca7d22d2d0c63""><code>306172e</code></a> Bump up version number to 5.2.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b9df0c0daa080450772c365f16a9406fe0ca607a""><code>b9df0c0</code></a> Document eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/05a4433770f7020ff845add9348bdc12c82793dd""><code>05a4433</code></a> Add eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:3228,down,download-task,3228,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['down'],['download-task']
Availability,"@JLama75 We don't support Spark 3.5.0 yet, please downgrade to Spark 3.3.x. You can track progress on 3.5.0 support here: https://github.com/hail-is/hail/issues/13971",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14235#issuecomment-1921923818:50,down,downgrade,50,https://hail.is,https://github.com/hail-is/hail/issues/14235#issuecomment-1921923818,1,['down'],['downgrade']
Availability,"@Sun-shan According to the error message you posted, Spark itself cannot find `/hail/test/BRCA1.raw_indel.vcf`:; ```; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; ```. Looking at that error message, it looks like Spark is interpreting your path as a local file system path, _not_ a hadoop path. Moreover, earlier in your posted output this line:; ```; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; ```; suggests that you're not actually connecting to a Spark cluster with a properly configured Hadoop installation. ---. Your Spark cluster appears improperly configured. I'm not sure if `pyspark` is even connecting to your cluster. You might try looking at [this StackOverflow post](https://stackoverflow.com/questions/34642292/cant-connect-pyspark-to-master) about connecting `pyspark` to a Spark cluster. I strongly recommend running `pyspark` again and executing:; ```; spark.sparkContext.master; ```; This should print the URL of your Spark master node. If this prints a String starting with `local`, then you're definitely not connecting to a Spark cluster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-322539635:27,error,error,27,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322539635,3,['error'],['error']
Availability,"@asvetlov thanks for your reply, and for your work on the Sanic project! I was really curious about the Techempower issue. Do you know why Sanic, on past rounds failed to complete test subsets without error? I havent had much of a chance to look into that yet, but https://github.com/huge-success/sanic/issues/53 doesnt divulge much, and my own attempts to give Sanic problems havent yielded anything worrisome (i.e asyncpg works great under 2000 simultaneous connection load, request standard deviation is about as tight as aiohttp, and number of extremes / timeouts is smaller than aiohttp). Techwmpower benchmark was on version 0.7, if not earlier (the linked file in the Techempower issue is 0.7), and that version may have been affected by the issue described here: https://github.com/huge-success/sanic/issues/1176 which seems to have been largely addressed. . Edit: furthermore, other recent tests showed no significant issues with Sanic https://fgimian.github.io/blog/2018/06/05/python-api-framework-benchmarks/. Still the addressing the Techempower issues may help people feel more confident.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5242#issuecomment-461425481:201,error,error,201,https://hail.is,https://github.com/hail-is/hail/pull/5242#issuecomment-461425481,1,['error'],['error']
Availability,"@bw2 Hey looks like there's some weird version issues. Can you set up the gradle to use a Spark 2.1 compatible version of elastic search if spark version is set to a 2.1.x version and use a Spark 2.0 compatible version of elastic search?. I don't fully understand the error, but it definitely looks like there's a spark version mismatch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2049#issuecomment-319098074:268,error,error,268,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-319098074,1,['error'],['error']
Availability,"@catoverdrive Assigned you since it will be good to get you acclimated to the services team code. We have a function called `is_transient_error` which checks if an error is a known-to-be-transient error. An error is transient if perpetually retrying the error-raising-operation will eventually lead to success. We consider most things transient, even 500 Internal Server Error, because we expect our systems work but sometimes fail under heavy load. Eventually load should drop.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9213#issuecomment-668750434:164,error,error,164,https://hail.is,https://github.com/hail-is/hail/pull/9213#issuecomment-668750434,5,"['Error', 'error']","['Error', 'error', 'error-raising-operation']"
Availability,"@catoverdrive I did a bad, pip.conf needs to come from `docker/hail-ubuntu/pip.conf`, you also need the download-gcs-connector.py file I added to that branch",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9935#issuecomment-773428416:104,down,download-gcs-connector,104,https://hail.is,https://github.com/hail-is/hail/pull/9935#issuecomment-773428416,1,['down'],['download-gcs-connector']
Availability,"@catoverdrive can you rebase and ping me when done? This isn't stacked anymore, right?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6765#issuecomment-530559600:33,ping,ping,33,https://hail.is,https://github.com/hail-is/hail/pull/6765#issuecomment-530559600,1,['ping'],['ping']
Availability,"@catoverdrive this came up while Konrad and I were trying to understand a discrepancy with PCA in python sklearn, which automatically mean centers. This simplest solution would be to add a map that mean centers between irm and computeSVD here:; `val svd = irm.computeSVD(k, computeLoadings)`; But this is redundant when the data is already mean-centered, as in pca_of_normalized_genotypes. Let's discuss when you're back and I can make the changes and update the docs which need some work anyhow.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2734#issuecomment-358096966:305,redundant,redundant,305,https://hail.is,https://github.com/hail-is/hail/issues/2734#issuecomment-358096966,1,['redundant'],['redundant']
Availability,"@chrisvittal I can't figure out how to comment on unedited code, but here:. https://github.com/hail-is/hail/pull/9604/files#diff-689808a42e9fe9329e347edede9bc12419e29a1634afc5d8c899a41c9d550659R211. you probably want to switch to passing in an EmitCode as well. Not sure if that's the source of the code verification errors, but I think the order I was originally passing in the tuples (m, v) is swapped from how emitCodeParams represent them (v, m), so that might help.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9604#issuecomment-713805849:317,error,errors,317,https://hail.is,https://github.com/hail-is/hail/pull/9604#issuecomment-713805849,1,['error'],['errors']
Availability,"@chrisvittal I took the plunge and also created a `MatrixHybridReader`. Changes (including above):. - FunctionBuilder now accepts `Code[Unit]` to be added to the `init` method of the function object; - SRVB now has an `init` method that should be called in the `init` method of a function object if many methods will share the SRVB; - `CodeChar` now exists; - `TextMatrixReader` exists which mimics `TextTableReader`; these should get unified at some point; - minor documentation fixes to `import_matrix_table`; - better error messages wrt using the name `row_id`, which is reserved for use by `import_matrix_table` when there are no keys specified; - several new tests, including:; - extensive testing of the product space of `header`, `delimiter`, `header`, and `entry_type` (including such weird things as using `9` as the missing value); - a pathological file: `9`-separated values with `8` representing the missing value; - several tests that trigger the pruner; - rename `LoadMatrix.scala` to `TextMatrixReader.scala`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6987#issuecomment-529001365:521,error,error,521,https://hail.is,https://github.com/hail-is/hail/pull/6987#issuecomment-529001365,1,['error'],['error']
Availability,"@chrisvittal This is all garbage, the failure makes little sense. I've started back from scratch with master, and have re-implemented all of the functionality, from this branch, needed to have the Dataproc test run (which relies on LoadVCF). . It works fine. Something else is amiss. I'm going to finish reimplementing everything in that clean slate, and when everything is running close this PR and reissue. The diff between them will show the problem area, which is in some kind of global state affecting sparkContext or RDD",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083#issuecomment-498334543:38,failure,failure,38,https://hail.is,https://github.com/hail-is/hail/pull/6083#issuecomment-498334543,1,['failure'],['failure']
Availability,"@chrisvittal not sure what this error is. Doesnt happen on local (on local all tests pass, besides the one that also fails on master, `is.hail.methods.IBDSuite.ibdPlinkSameOnRealVCF`, because I don't have Plink installed). Will try to investigate tomorrow, first step is accessing the log, but if you have suggestions Im interested!. 2019-05-16 00:23:41 Hail: INFO: test is.hail.expr.ir.ForwardLetsSuite.testAggregators SUCCESS; 2019-05-16 00:23:41 Hail: INFO: starting test is.hail.expr.ir.ForwardLetsSuite.testForwardingOps...; dlopen: /tmp/hail_dJAhNQ/hm_fd419e9b11e18f87ceb4.so: undefined symbol: _ZN4hail2FSC1EP8_jobject",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083#issuecomment-492892219:32,error,error,32,https://hail.is,https://github.com/hail-is/hail/pull/6083#issuecomment-492892219,1,['error'],['error']
Availability,"@chrisvittal, these tests actually pass the local backend. I changed the tests to reflect this, but wanted to ping you to make sure that seems reasonable.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11345#issuecomment-1059604289:110,ping,ping,110,https://hail.is,https://github.com/hail-is/hail/pull/11345#issuecomment-1059604289,1,['ping'],['ping']
Availability,"@cseed - this PR has a bad interaction with the changes made to [optimize inside ArrayAgg emit](https://github.com/hail-is/hail/pull/5765/files). . I've added a [test that catches the problem](https://github.com/hail-is/hail/pull/5710/files#diff-3273df362c814023cfa64428acf395cfR1122). The root of the issue is that we **cannot run NormalizeNames again** inside of that optimization pass -- it generates references that collide/overwrite existing bindings available when ArrayAgg is emitted. We should be creating globally-unique names inside ForwardLets, not normalized names.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5710#issuecomment-483001172:456,avail,available,456,https://hail.is,https://github.com/hail-is/hail/pull/5710#issuecomment-483001172,1,['avail'],['available']
Availability,"@cseed ; I added a secret to default named `ssl-config-hail-root` containing `hail-root-key.pem`, and `hail-root-cert.pem`. Every principal trusts this root. This root trusts every principal. This PR originally prevented clients from speaking to servers with certs they didn't trust. Now everyone trusts everyone. As long as the root key is not leaked this is OK. Only `create_certs` mounts this secret. The key is used to sign every certificate and the cert is included in each principal's incoming and outgoing trust lists. The root certificate and key are never re-created, so our deploys have no downtime and we avoid addressing the rotation problem. I removed all the trust specifications. A later PR will resolve rotation and mTLS. That PR will restore the trust specifications. I didn't change the structure of the secrets (they still have an incoming and outgoing trust list which only contains the root cert) because I need this structure for mTLS anyway. I've updated the PR description with this text so it ends up in the squashed commit.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561#issuecomment-617911061:600,downtime,downtime,600,https://hail.is,https://github.com/hail-is/hail/pull/8561#issuecomment-617911061,1,['downtime'],['downtime']
Availability,"@cseed @danking . Hi, I tried the following command , and configured the log path , but it still not worked, are there any suggestions?. spark-submit --executor-memory 16g --executor-cores 4 --class org.broadinstitute.hail.driver.Main ******/hail-all-spark.jar --master yarn-client importvcf --log-file /user/hail/hail.log /user/hail/split_test.vcf splitmulti write -o /user/hail/split_test_1_1.vds exportvcf -o /user/hail/split_test_1_1.vcf. **ERROR:**; WARNING: Running spark-class from user-defined location.; hail: info: running: importvcf /user/hail/sample.vcf; hail: info: Coerced sorted dataset; hail: info: running: splitmulti; hail: info: running: write -o /user/hail/sample_1008.vds; hail: write: caught exception: org.apache.spark.SparkException: Job aborted.; .........; at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 5, bio-x-3): java.io.IOException: The file being written is in an invalid state. Probably caused by an error thrown previously. Current state: COLUMN; ...........; at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)java.io.IOException: The file being written is in an invalid state. Probably caused by an error thrown previously. Current state: COLUMN. [splitmulti_1_1.txt](https://github.com/hail-is/hail/files/521087/splitmulti_1_1.txt)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/825#issuecomment-252825829:445,ERROR,ERROR,445,https://hail.is,https://github.com/hail-is/hail/issues/825#issuecomment-252825829,5,"['ERROR', 'error', 'failure']","['ERROR', 'error', 'failure']"
Availability,"@cseed @danking it's a lot of lines of code, but I couldn't really figure out how to cut down on the boilerplate. Suggestions welcome.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3426:89,down,down,89,https://hail.is,https://github.com/hail-is/hail/pull/3426,1,['down'],['down']
Availability,"@cseed @jbloom22 I don't really like how the examples sections are looking. I'd rather read a short one-line description of what is being done followed by the example. Right now, it's example code with detailed explanation. See https://ci.hail.is/repository/download/HailSourceCode_HailCi/3257:id/www/pyhail/index.html#pyhail.VariantDataset.annotate_variants_bed for an example. Cotton -- I'll defer to you on the variantqc table. Did we come to a consensus what the return type should be for export commands?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1216#issuecomment-270982982:258,down,download,258,https://hail.is,https://github.com/hail-is/hail/pull/1216#issuecomment-270982982,1,['down'],['download']
Availability,@cseed @jigold I think this resolves our PVC issues modulo batch failure. We still need to add the batch refresh loop.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6166:65,failure,failure,65,https://hail.is,https://github.com/hail-is/hail/pull/6166,1,['failure'],['failure']
Availability,"@cseed Added the redirect logic. It feels much slower (although there may be some small optimizations available). What do you think about using popup as the default, and then catch on error and send to redirect method? https://github.com/auth0/auth0.js/issues/868. This could work well as long as blocking happened rarely. So far, I haven't been able to trigger the block in any browser (Safari, Chrome, Firefox, all latest v), with content blockers enabled (which definitely block popups on other sites).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162#issuecomment-456667812:102,avail,available,102,https://hail.is,https://github.com/hail-is/hail/pull/5162#issuecomment-456667812,2,"['avail', 'error']","['available', 'error']"
Availability,"@cseed As I briefly mentioned in an email on Saturday, I moved notebook loading to a prefetched model. Data and page loading are decoupled: When one clicks on the Notebook link, routing to the page happens without waiting for data to come in from notebook-api.hail.is. If data is available, it is shown, else a loading indicator. To avoid loading screens, I call notebook-api.hail.is asynchronously immediately after a user hits app.hail.is, whether they're on the Notebook page or not. Therefore, typically a user will never see a Notebook page loading indicator, when they click from one page to Notebook (say they land on the home page: by the time they click on Notebook, the data is fetched, so no loading screen). Furthermore, web sockets keep that Notebook data up to date, again regardless of whether a user is on the Notebook page. So in all instances except when a user lands on Notebook directly, the time it takes to reach the Notebook page is << 16ms (seemingly ~3ms). A similar approach is now used for scorecard, except Scorecard will render data in the SSR phase (because I consider scorecard less important, and because most users of the web app won't need it), and will not prefetch data when on another page. However, clicking on ""Scorecard"" from another page will not cause routing to block while waiting for the https://scorecard.hail.is/json response; instead a loading indicator will be shown. In practice I find this preferable, because the GUI feels more responsive, and users get more feedback. This demonstrates the core benefit of universal rendering approaches, and how they can improve page loading times over even the leanest server-side rendered application.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162#issuecomment-462221996:280,avail,available,280,https://hail.is,https://github.com/hail-is/hail/pull/5162#issuecomment-462221996,1,['avail'],['available']
Availability,"@cseed Can you look over this for structure before I assign it randomly? There's three things I am not happy about or want double checked:. 1. I had to replicate the parsing code for `quoted_literal` etc. between the two parser classes. I couldn't figure out how to have the function in one place and be able to call it. 2. I debated back and forth what the `repsepUntil` and `repUntil` interface should look like. I decided to make it take the desired tokens instead of comparing to a string or any value because that seems more error proof and explicit. However, the users of the function have something like this now `repsepUntil(it, f, PunctuationToken("",""), PunctuationToken(""}""))`, which is quite verbose. I thought about making a second function that took string arguments and converted it to PunctuationToken and then called the functions that took tokens, but decided it was better to be explicit. 3. Can you double check the regex for `float_literal` is still correct? This was to fix the empty string match I had during our check-in last week.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4711:530,error,error,530,https://hail.is,https://github.com/hail-is/hail/pull/4711,1,['error'],['error']
Availability,"@cseed I had to make the CloudSQL instance have a public IP in order for testing locally (not in the cluster) to work. Should I get rid of that option? Or can we have a separate test database? As for permissions for the databases, I couldn't find a way to say a specific user could not create a database. I think we can lock down a database with SQL commands after the database has been created. This will be good to discuss on Monday. See #5615",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5618#issuecomment-473591074:325,down,down,325,https://hail.is,https://github.com/hail-is/hail/pull/5618#issuecomment-473591074,1,['down'],['down']
Availability,@cseed I shrunk the PR down to the minimal code change and it's still failing the `LDPruneSuite.testNoPrune` test. Do I misunderstand how to use the Encoder/Decorder stuff?. The failure isn't an assertion error. I've somehow changed the number of records that result from an LDPrune.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3391#issuecomment-382377269:23,down,down,23,https://hail.is,https://github.com/hail-is/hail/pull/3391#issuecomment-382377269,3,"['down', 'error', 'failure']","['down', 'error', 'failure']"
Availability,@cseed I think this is a better organization. The pod specs in the database are static and can be inserted into the database upon job creation. So we now assert the job tasks are never null in the database. This doesn't change the problem of how to handle a pvc/pod creation error in the database. Should we delete the record upon failure? Poll and wait for creation to succeed up to N times?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6075:275,error,error,275,https://hail.is,https://github.com/hail-is/hail/pull/6075,2,"['error', 'failure']","['error', 'failure']"
Availability,@cseed I think we need to bump the Batch test time limit to 360. The tests passed in 328 seconds but wait-for.py marked it as a failure as it was over 300 seconds.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6015#issuecomment-489803786:128,failure,failure,128,https://hail.is,https://github.com/hail-is/hail/pull/6015#issuecomment-489803786,1,['failure'],['failure']
Availability,"@cseed I'd like to turn on the key checking again for the time being because we were relying on it for some split_multi stuff that's going to take some amount of new infrastructure to fix properly, and in the meantime it's causing some pretty bad/nonsense errors downstream because things are can be out of order (see #6223). Is that going cause any problems?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5424#issuecomment-499240905:256,error,errors,256,https://hail.is,https://github.com/hail-is/hail/pull/5424#issuecomment-499240905,2,"['down', 'error']","['downstream', 'errors']"
Availability,"@cseed Should the behavior of the logs be to not have a link if the job is ready or pending or to report None? Right now, we report None for `status` if it's ready or pending and have a web.HTTPNotFound error for logs when it's pending or ready. I think we should have it be consistent between logs and status and I think having no links in the ready and pending case is clearer.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7449#issuecomment-549440769:203,error,error,203,https://hail.is,https://github.com/hail-is/hail/pull/7449#issuecomment-549440769,1,['error'],['error']
Availability,@cseed This is ready for review. Please check the logic for _create_pod. I added a Try/Except that sets the pod to failure if pod_creation fails.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6075#issuecomment-491011207:115,failure,failure,115,https://hail.is,https://github.com/hail-is/hail/pull/6075#issuecomment-491011207,1,['failure'],['failure']
Availability,@cseed is this how it should work? seems odd to put `null` as position. I also notice that `filterSamplesMask` does some custom stuff. Will this change slow things down unnecessarily if `drop_samples` is not used immediately after a read?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2285#issuecomment-335862234:164,down,down,164,https://hail.is,https://github.com/hail-is/hail/pull/2285#issuecomment-335862234,1,['down'],['down']
Availability,@cseed ping,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1946#issuecomment-313167921:7,ping,ping,7,https://hail.is,https://github.com/hail-is/hail/pull/1946#issuecomment-313167921,3,['ping'],['ping']
Availability,"@cseed ping, stacked PRs have proven unsuccessful in the past, so I'm keeping the rest of my work gated, but I'd like to start moving things into master. Can you take a look at the latest changes and confirm if you're cool punting on points 1-5 until later?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3186#issuecomment-375368023:7,ping,ping,7,https://hail.is,https://github.com/hail-is/hail/pull/3186#issuecomment-375368023,1,['ping'],['ping']
Availability,@cseed surely now it will pass; set --ignore fs/google_fs.py in the doctest run. Previous error was caused by the testing of this file (since CI doesn't yet have gcsfs). https://storage.googleapis.com/hail-ci-0-1/ci/4d17fb5a7df0bb9d766eb80f4a2926b3ed7bbb70/564ab40014a5aa349a517a8353d09eac4a5273f7/index.html,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5878#issuecomment-485139453:90,error,error,90,https://hail.is,https://github.com/hail-is/hail/pull/5878#issuecomment-485139453,1,['error'],['error']
Availability,"@cseed, details below, exec summary: a series of confusions and confusing interfaces lead to cloud tools deployment issues. The resolution is to fix the deploy script to always deploy `cloudtools` for python 2 and 3 (because *it* works with both). Users will need `python2` somewhere on their PATH, but `gsutil` will guide them through that, i.e. not our problem. There is no problem except that I cannot approve my own PR. I noticed @catoverdrive wasn't actually assigned, so it wasn't in her scorecard queue. ---. There was a bit of confusion around this recently that @catoverdrive figured out. So, `gsutil` only supports `python2`, but it's happy to search through your path for a variety of binaries with suggestive names until it finds a valid python 2.x binary. `cloudtools` itself works with any version of python (there was a recent breaking change in the release of python 3.7, which broke cloud tools [but that's been resolved in an open PR](https://github.com/Nealelab/cloudtools/pull/91/files#diff-7decff7c08c5270a32982ea34483b8cbR11)). Now, wrt PYPI, @catoverdrive discovered that the version of python you use to run `setup.py bdist_wheel` determines which version of python is deployed. This is rather confusing and, since none (or many?) of us did not know this, we accidentally uploaded a variety of [cloud tools versions on pypi, as you've noted](https://pypi.org/simple/cloudtools/). There was some earlier confusion wherein I thought we should only support `python2`, but that was a mistake on my end. We should support both versions, and when the user tries to start a cluster, `gsutil` will provide an error message guiding them to install `python2`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4240#issuecomment-419912588:1625,error,error,1625,https://hail.is,https://github.com/hail-is/hail/pull/4240#issuecomment-419912588,1,['error'],['error']
Availability,"@cseed, this carries anchor style down to `code` elements contained within them. I don't know if this is ideal, but it's at least consistent with anchors and informs the user that they can click the command names.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/643#issuecomment-241108325:34,down,down,34,https://hail.is,https://github.com/hail-is/hail/pull/643#issuecomment-241108325,1,['down'],['down']
Availability,"@cseed,. > The point isn't to save the few untars, the point is to make the general facilities performant for everyone. Basically, I think directory outputs are untenable in the current design unless they are very small, which is why you're doing all this for your use case, and the tar is still probably as good (if not better) in that case. Fix it for everyone's use case so nobody has to go through this in the future. I agree directory outputs with large file counts are untenable. Are you suggesting we do this at the batch level for any directory? That feels a bit opaque, because users may expect that if they specify their output is a directory that they can selectively download certain subdirectories. At the build.yaml level, I see a couple explicit options:; ```; outputs:; - from: /io/repo/hail/resources; to: /resources.tgz; codec: gzip; ```; and; ```; inputs:; - from: /resources.tgz; to: /io/resources; codec: gzip; ```; ?. There's also this, which irks me a bit because it's punny, but:; ```; outputs:; - from: /io/repo/hail/resources; to: /resources.tgz; ```; and. ```; inputs:; - from: /resources.tgz; to: /io/resources; extract:; - .; ```; ```; inputs:; - from: /resources.tgz; to: /io/resources; extract:; - foo; - bar; ```. A little bit my reaction to this is that we're creating a DSL that provides minor value relative to the user using `tar` in their `runImage` steps. E.g. build hail is explicit and not verbose:; ```; ...; tar czf test.tar.gz -C python test; tar czf resources.tar.gz -C src/test resources; tar czf data.tar.gz -C python/hail/docs data; tar czf www-src.tar.gz www; tar czf cluster-tests.tar.gz python/cluster-tests; ```; and `test_hail_java` is fine:; ```; ...; tar xzf resources.tar.gz -C src/test; ...; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7626#issuecomment-560470857:679,down,download,679,https://hail.is,https://github.com/hail-is/hail/pull/7626#issuecomment-560470857,1,['down'],['download']
Availability,@cseed: Is this issue for the files that are known to exist but get 404 errors (due to capitalization with the importbgen etc. files) or all 404 errors? I don't think we can remove the 404 errors from the console for any command that doesn't have a corresponding markdown file in the commands directory. See this link: http://stackoverflow.com/questions/7035466/check-if-file-exists-but-prevent-404-error-in-console-from-showing-up,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/606#issuecomment-240906565:72,error,errors,72,https://hail.is,https://github.com/hail-is/hail/issues/606#issuecomment-240906565,4,['error'],"['error-in-console-from-showing-up', 'errors']"
Availability,"@cseed: It would be great if we could merge this into master soon -- there's a lot of changes here!. Highlight of major changes:; 1. Dosage is implemented in Genotype.scala; - A user can get either dosages `.dosage` or PLs `.pl`; - To go from PLs to Dosages: rescale each PL (10^(-PL/10)), take the sum of the rescaled numbers, then divide by the sum. This is assuming equal weights prior (can incorporate alternate prior later); - To go from Dosages to PLs: same transformation as before; 2. INFO score is implemented in variantqc; - No tests for info score yet as still uncertain which method to use; - My computation agrees with SNPTEST but not QCTOOL; 3. `importgen` and `exportgen` are now implemented; 4. SplitMulti will split dosages correctly except for the setting of false ref. If the original dosage with N genotypes had more than one maximum value [ex: (0.2, 0.2, 0.1, 0.1, 0.1, 0.3)], then the original genotype is -1. But after combining dosages, then there is one unique maximum value. The fakeref flag is not set in this case, but the genotype is > 0.; 5. A randomly generated genotype can have two values very close together (0.4035, 0.4036, 0.2...) that when read back in via gen file or bgen file will have rounding error (0.4035, 0.4035, 0.2...) so there is no maximal genotype anymore (gt = -1). I don't think this is a huge concern as it can only happen if the max dosage is <= 0.5, and these will get filtered out by most users anyways. **To-Do:; 1. Finalize INFO score calculation and write tests; 2. Fix null variant in PLINK code (want to do this in separate branch); 3. Modify variant qc to read parameter about data so info score only calculated for dosage data and likewise for statistics about depth, gq etc.; 4. Handle sex chromosome names in import PLINK properly (do we need to map ""23"" to ""X"", etc.?); 5. Update the readFam function in `importplink` to utilize functionality Jon wrote already",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/243#issuecomment-218212906:1235,error,error,1235,https://hail.is,https://github.com/hail-is/hail/pull/243#issuecomment-218212906,1,['error'],['error']
Availability,@daniel-goldstein I found an error in async_cancel that was exposed by the new version of nest_asyncio. I'm 99% sure the change is correct. Feel free to ask Dan to double check it. The issue was that `fetch_coro` is a Task and not a Future. Cancelling a task just adds the cancellation event to the event loop. You have to actually wait for it to finish before the state of the task will be cancelled. Dan wrote a bunch of tests that asserted `cancel` results in `cancelled == True`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10705#issuecomment-888513583:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/10705#issuecomment-888513583,1,['error'],['error']
Availability,"@daniel-goldstein The logs show this:. ```; insertId: ""88db8ey9nom69366""; jsonPayload: {; asctime: ""2022-02-16 23:07:40,794""; exc_info: ""Traceback (most recent call last):; File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 65, in notify_batch_job_complete; await request(session); File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 56, in request; await session.post(callback, json=batch_record_to_dict(record)); File ""/usr/local/lib/python3.7/dist-packages/batch/batch.py"", line 18, in batch_record_to_dict; elif record['n_failed'] > 0:; KeyError: 'n_failed'""; filename: ""job.py""; funcNameAndLine: ""notify_batch_job_complete:69""; hail_log: 1; levelname: ""ERROR""; message: ""callback for batch 1731 failed, will not retry.""; ```. `notify_batch_job_complete` just needs to join against the volatile table.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11352#issuecomment-1049107348:699,ERROR,ERROR,699,https://hail.is,https://github.com/hail-is/hail/pull/11352#issuecomment-1049107348,1,['ERROR'],['ERROR']
Availability,@daniel-goldstein can you ping #general when this merges about:; > - (hail#12801) Hitting CTRL-C while interactively using Query on Batch cancels the underlying batch.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12853#issuecomment-1500328024:26,ping,ping,26,https://hail.is,https://github.com/hail-is/hail/pull/12853#issuecomment-1500328024,1,['ping'],['ping']
Availability,@daniel-goldstein looks like there's still a test failure,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5686#issuecomment-477168302:50,failure,failure,50,https://hail.is,https://github.com/hail-is/hail/pull/5686#issuecomment-477168302,1,['failure'],['failure']
Availability,"@daniel-goldstein sorry I was a dummy, what I had didn't actually do what I thought it did. It's a bit complex to get access to test information in a fixture, but there's some docs on how to do it. I did that. Now the fixture checks and only tears down a batch when the test failed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13326#issuecomment-1664664775:248,down,down,248,https://hail.is,https://github.com/hail-is/hail/pull/13326#issuecomment-1664664775,1,['down'],['down']
Availability,@daniel-goldstein still got some parser errors in the python tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5662#issuecomment-476883070:40,error,errors,40,https://hail.is,https://github.com/hail-is/hail/pull/5662#issuecomment-476883070,1,['error'],['errors']
Availability,"@danking , I'm a bit stuck on how to proceed with the credential refreshing. Here's the layout of the problem:. 1. In normal Azure, we accept user-provided SAS tokens. Since they are user-provided, we have no way of obtaining new ones and the onus is on the user to obtain a SAS token for however long they expect to need to use it.; 2. This current design in Terra is to not make the user have to do that, because that seems annoying, and for terra-controlled ABS containers we have an endpoint we can hit to get a SAS token. Ok, but now we need to update our Azure FS infrastructure to refresh a credential if it expires. But, we use the azure client lib and don't control all http requests. For example, for `AzureStorageFS.open`, we call `downloader.readall()` if we want to load the whole file into memory. I went spelunking through their source and looks like `readall` mostly wraps a sequence of range reads, but regardless if we were to use that method we would have to catch credential expiration errors, reset credentials on the blob client and retry hoping that we didn't break any invariants -- I don't want to do that as I wouldn't trust a stream that encountered a non-transient error like that. It could be that getting rid of `downloader.readall` is the only thing we have to worry about, but it makes me uneasy not having control of the http requests we're making to ABS. Do you see a solution other than raking through our `aioazure.fs` and making sure that we only use ""quick"" methods and possibly retrying 401s? It just seems to me like we're going against the grain and even though it feels user-hostile the intention of SAS tokens are to have users own credential expiration.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715:743,down,downloader,743,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715,4,"['down', 'error']","['downloader', 'error', 'errors']"
Availability,"@danking , no worry. I am aware that my current EMR environment is not as clean as we wish. Not easy to find the right alignment of version of all the components. Thanks for your pointers. ; `spark-shell --version` was the right spot. It appears that I am runing on `scala 2.12.13` and that would explain the error as you mentioned above . > That SettingsOps is an implicit nested class of the MutableSettings object. It is definitely present in [2.13](https://github.com/scala/scala/blob/2.13.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L70-L88) and [2.12](https://github.com/scala/scala/blob/2.12.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L83-L94). It appears to be missing in [2.11](https://github.com/scala/scala/blob/2.11.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L64-L68). It appears to have arrived in [2.12.14](https://github.com/scala/scala/commit/3bd24299fc34e5c3a480206c9798c055ca3a3439). Let me work on that and find a compatible scala version.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1767473029:309,error,error,309,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1767473029,1,['error'],['error']
Availability,"@danking . I can keep digging, but it looks like the ParamSpec feature isn't available in the Python version we're running. I'll see if there's a workaround, but I'd really not like to hold up this change anymore than needed. ```; Module ""typing"" has no attribute ""ParamSpec""; maybe ""_ParamSpec""?; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13237#issuecomment-1632525112:77,avail,available,77,https://hail.is,https://github.com/hail-is/hail/pull/13237#issuecomment-1632525112,1,['avail'],['available']
Availability,@danking Any idea why the new `hail-run` image would error on just the `test_python_docs` step with the error about spark not finding the hail jar?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13038#issuecomment-1551890279:53,error,error,53,https://hail.is,https://github.com/hail-is/hail/pull/13038#issuecomment-1551890279,2,['error'],['error']
Availability,@danking Can you let me know what I'm supposed to do here with these security errors? Thanks!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12794#issuecomment-1505755543:78,error,errors,78,https://hail.is,https://github.com/hail-is/hail/pull/12794#issuecomment-1505755543,1,['error'],['errors']
Availability,@danking Do you want me to adopt this PR? It looks like there's a bunch of annoying errors to fix with the doctests as well as maybe a missing field in the spec?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14224#issuecomment-1919651215:84,error,errors,84,https://hail.is,https://github.com/hail-is/hail/pull/14224#issuecomment-1919651215,1,['error'],['errors']
Availability,@danking Erroring in CI,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10114#issuecomment-786693004:9,Error,Erroring,9,https://hail.is,https://github.com/hail-is/hail/pull/10114#issuecomment-786693004,1,['Error'],['Erroring']
Availability,@danking Have you actually seen anymore of these errors after your fix of the hadoop tests erasing each others' files? I considering closing this because I've not seen further evidence that hadoop isn't properly addressing transient errors.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12411#issuecomment-1349563987:49,error,errors,49,https://hail.is,https://github.com/hail-is/hail/pull/12411#issuecomment-1349563987,2,['error'],['errors']
Availability,"@danking I ended up rewriting this a bit to make it work with the nginx timeout (instead of getting rid of the timeout, since having a heartbeat seems like a pretty reasonable thing); updated the PR description to match.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9636#issuecomment-717406840:135,heartbeat,heartbeat,135,https://hail.is,https://github.com/hail-is/hail/pull/9636#issuecomment-717406840,1,['heartbeat'],['heartbeat']
Availability,"@danking I have a mostly completed draft for SAIGE in QoB. Can you take a look? I'm mainly looking for enough feedback to get a green light to actually start testing this end to end, fill in the remaining not implemented components, add documentation, add verbosity and possibly a dry run feature, and support VEP annotations natively. There are a couple of core concepts:; 1. Phenotypes - Set of phenotypes to test. I support the ability to group phenotypes together. This is in anticipation of a new version of SAIGE that Wei is going to release soon.; 2. VariantChunks - The set of variant intervals of data to test per job. If it's SAIGE-GENE, then there's also the ""groups"" to actually test within that interval.; 3. io - There's a bunch of wrappers that handle input and output files so all of that logic combined with the checkpointing logic is abstracted away from what is actually going on.; 4. steps - These are the SAIGE modules to run. They are all dataclasses with configuration options; 5. saige - There's a class that can be instantiated in Python or I started writing the framework for a CLI. This has the code that builds the DAG end to end. All configuration happens with a yaml file that can overwrite default parameters for each step such as whether to checkpoint or where the results should be written to. For the CLI, I envision you can either give a config file and/or specify `--overrides step1_null_glmm.use_checkpoint=true`. For every Saige run, I write out the configuration used to a file in the output directory as well as information about the input data and variant chunks and the batch information.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13804:829,checkpoint,checkpointing,829,https://hail.is,https://github.com/hail-is/hail/pull/13804,2,['checkpoint'],"['checkpoint', 'checkpointing']"
Availability,@danking I made a fix that should make it so we don't need to manually delete instances and batch should recover.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8220#issuecomment-593645975:105,recover,recover,105,https://hail.is,https://github.com/hail-is/hail/pull/8220#issuecomment-593645975,1,['recover'],['recover']
Availability,"@danking I remember you wanted raise web.Response() here for a reason, so I'll let you decide if this is correct or not. ```; {""levelname"": ""ERROR"", ""asctime"": ""2020-03-13 15:53:52,139"", ""filename"": ""web_protocol.py"", ""funcNameAndLine"": ""log_exception:355"", ""message"": ""Error handling request"", ""exc_info"": ""Traceback (most recent call last):; File \""/usr/local/lib/python3.6/dist-packages/batch/front_end/front_end.py\"", line 635, in insert; jobs_args); File \""/usr/local/lib/python3.6/dist-packages/gear/database.py\"", line 172, in execute_many; return await cursor.executemany(sql, args_array); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 283, in executemany; self._get_db().encoding)); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 318, in _do_execute_many; r = await self.execute(sql + postfix); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 239, in execute; await self._query(query); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 457, in _query; await conn.query(q); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 428, in query; await self._read_query_result(unbuffered=unbuffered); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 622, in _read_query_result; await result.read(); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 1105, in read; first_packet = await self.connection._read_packet(); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 593, in _read_packet; packet.check_error(); File \""/usr/local/lib/python3.6/dist-packages/pymysql/protocol.py\"", line 220, in check_error; err.raise_mysql_exception(self._data); File \""/usr/local/lib/python3.6/dist-packages/pymysql/err.py\"", line 109, in raise_mysql_exception; raise errorclass(errno, errval); pymysql.err.IntegrityError: (1062, \""Duplicate entry '27-122310' for key 'PRIMARY'\""). During handling of the",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8307:141,ERROR,ERROR,141,https://hail.is,https://github.com/hail-is/hail/pull/8307,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,"@danking I then get; ```Error summary: HailException: expression has wrong type: expected `Int', got Boolean```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2178#issuecomment-327032041:24,Error,Error,24,https://hail.is,https://github.com/hail-is/hail/issues/2178#issuecomment-327032041,1,['Error'],['Error']
Availability,"@danking I try from the last commin of Hail. That seems to solve the issue of Spark version but not the java error... ```; // Setup EMR + python 3.9 + java 11 without installin hail; // Check pyspark; $ pyspark --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21. // Clone last commit of Hail & install; $ export PATH=$PATH:/home/hadoop/.local/bin; $ cd /tmp; $ git clone --depth 1 https://github.com/broadinstitute/hail.git; $ cd hail/hail/; $ make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; // Check pyspark; $ pyspark --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21. // Create symlink to hail-all-spark.jar; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python${PYTHON_VERSION}/site-packages/hail/backend /opt/hail/backend; // Launch spark-shell; $ spark-shell; Exception in thread ""main"" java.lang.NoSuchMethodError: 'scala.reflect.internal.settings.MutableSettings scala.reflect.internal.settings.MutableSettings$.SettingsOps(scala.reflect.internal.settings.MutableSettings)'; ```. Could it be a problem of PATH ? issue with where Hail is installed ?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1775200581:109,error,error,109,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1775200581,1,['error'],['error']
Availability,@danking I'm getting this error. Do you see any problem with granting that capability to the test service account?. ```; + retry gcloud -q auth activate-service-account '--key-file=/gsa-key/key.json'; + gcloud -q auth activate-service-account '--key-file=/gsa-key/key.json'; Activated service account credentials for: [test-665@hail-vdc.iam.gserviceaccount.com]; + mkdir -p /io/batch/27b395/inputs/wjDTI; + retry gsutil -u hail-vdc -m cp -R gs://hail-services-requester-pays/hello /io/batch/27b395/inputs/wjDTI/hello; + gsutil -u hail-vdc -m cp -R gs://hail-services-requester-pays/hello /io/batch/27b395/inputs/wjDTI/hello; AccessDeniedException: 403 test-665@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; CommandException: 1 file/object could not be transferred.; + sleep 2; + gsutil -u hail-vdc -m cp -R gs://hail-services-requester-pays/hello /io/batch/27b395/inputs/wjDTI/hello; AccessDeniedException: 403 test-665@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; CommandException: 1 file/object could not be transferred.; + sleep 5; + gsutil -u hail-vdc -m cp -R gs://hail-services-requester-pays/hello /io/batch/27b395/inputs/wjDTI/hello; AccessDeniedException: 403 test-665@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; CommandException: 1 file/object could not be transferred.; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9096#issuecomment-662085952:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/9096#issuecomment-662085952,1,['error'],['error']
Availability,"@danking IIUC the TeamCity build is now working with spark-2.1.0 but not spark-2.0.2; (even though running `./gradlew shadowJar archiveZip` on my laptop with spark-2.0.2 works fine.). From looking at the Maven repo; https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch-spark-20_2.11; and the elasticsearch-spark connector docs; https://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html; there's no indication that some versions only support v2.1, though it does say; ```; elasticsearch-hadoop allows Elasticsearch to be used in Spark in two ways: through the dedicated support available since 2.1 or through the Map/Reduce bridge since 2.0. Spark 2.0 is supported in elasticsearch-hadoop since version 5.0; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2049#issuecomment-320274234:604,avail,available,604,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320274234,1,['avail'],['available']
Availability,"@danking Looks like I'm still failing to configure a couple of settings related to references on the `ServiceBackend` but you can feel free to start looking. You'll notice that I made quite a substantial refactor in `ServiceBackend.scala` in an attempt to harmonize the scala backends a bit more. The rationale behind the refactor is I was having a hard time working with the various thunks passed around there. I saw them as a bit of poor-man's-object way to capture some state from the input file while keeping the `ServiceBackend` stateless. IMO there's no harm in keeping the `ServiceBackend` just as stateful as the other backends since it is single use. So I lifted a lot of that state into backend-creation time and created a harder delineation between which part of the input is for configuring the backend and which part is for the action being performed. This made it easier to reuse a couple of methods like `tableType` and such. I'm happy to take suggestions on ways to trim down this PR, but I thought you'd want to take a look at the whole thing given the time-sensitivity.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13797#issuecomment-1766521995:987,down,down,987,https://hail.is,https://github.com/hail-is/hail/pull/13797#issuecomment-1766521995,1,['down'],['down']
Availability,"@danking Pushed a version that should work on local, now focusing on deployment changes. This is a clean fork; I rolled back all notebook changes to master. notebook-api/notebook/notebook.py is the file to review. Corresponding client pr commit: https://github.com/hail-is/hail/pull/5162/commits/7afc4a5b599a233a4e4b40bb9c7a260b062dd925; - This also includes all CORS bits. With the caveat that this is my first attempt at Kubernetes events, I think this moves things in the right direction. We now have an authenticated, push-notification system for an arbitrary number of notebooks. There are a few issues with it currently, mostly in handling closed web socket connections in gevent, which I will move away from in the iteration after Wednesday, but I handle dead socket errors and they don't *seem* to accumulate over time. I also need to implement a reconnection system on the client. The neat thing about this synchronizes sessions between refresh. So if you have N collaborators all on the same window (or more likely, you have 2 windows open), they will all get consistent state as quickly as Kubernetes knows it. This may not seem useful atm, but it allows us to get really fine-grained view into svc/pod uptime. This also should be much faster, provided we don't overburden the server with watchers (can be solved using server implementation as well), say by using an interval of a second, because we query kubernetes directly, rather than hitting the liveness endpoint by traveling over public internet and then being proxied at the boundary by nginx. We know within ms of the true state. Remaining q is whether this completely replicates the liveness endpoint. I also tried to make the serializing the kubernetes object the domain of the caller; I like this because the called can stop thinking about whether something implements __getitem__, and can specify pretty arbitrary transformations on that data (see lines 172-210, 331, 360, and all other calls to marshall_json), and allows us t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-459839071:774,error,errors,774,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-459839071,1,['error'],['errors']
Availability,@danking Should I be able to see the `ci-test` failure details when using my Broad affiliation?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11698#issuecomment-1087141587:47,failure,failure,47,https://hail.is,https://github.com/hail-is/hail/pull/11698#issuecomment-1087141587,1,['failure'],['failure']
Availability,"@danking Tests are passing. What's the problem?. Strange, cloudtools is showing 2.0.0 available, but pip is installing 1.1.6. ```; + pip search cloudtools; cloudtools (2.0.0) - Collection of utilities for working on the Google Cloud Platform.; datawire-cloudtools (0.2.6) - Datawire Cloud Tools; cloudseed (0.0.1) - Cloudtools; + pip install -U cloudtools; Collecting cloudtools; Downloading https://files.pythonhosted.org/packages/47/f1/bec895151ea74b2117c66620840e9a86436b376927b557b080289b61f754/cloudtools-1.1.16-py3-none-any.whl; Installing collected packages: cloudtools; Successfully installed cloudtools-1.1.16; ```. Ah, cloudtools 1.2.0 and 2.0.0 were set up as python 2 packages, see https://pypi.org/simple/cloudtools/:. ```; cloudtools-1.1.16-py2-none-any.whl; cloudtools-1.1.16-py3-none-any.whl; cloudtools-1.2.0-py2-none-any.whl; cloudtools-2.0.0-py2-none-any.whl; ```. 1.1.16 is set up for both. @liameabbott I assume we're only supporting Python 3?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4240#issuecomment-419786154:86,avail,available,86,https://hail.is,https://github.com/hail-is/hail/pull/4240#issuecomment-419786154,2,"['Down', 'avail']","['Downloading', 'available']"
Availability,"@danking Thanks for taking this over! I commented out the mark_unscheduled if the sidecar fails for debugging. The sidecar is running, but I'm getting an error because it's trying to run the top level code in batch.py. Either sidecar.py needs to be separate or we need to reconfigure batch.py so it doesn't run that code. ```; Traceback (most recent call last):; File ""/usr/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/usr/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/usr/local/lib/python3.6/dist-packages/batch/sidecar.py"", line 14, in <module>; from .batch import REFRESH_INTERVAL_IN_SECONDS, HAIL_POD_NAMESPACE, KUBERNETES_TIMEOUT_IN_SECONDS; File ""/usr/local/lib/python3.6/dist-packages/batch/batch.py"", line 83, in <module>; db = BatchDatabase.create_synchronous('/batch-user-secret/sql-config.json'); File ""/usr/local/lib/python3.6/dist-packages/batch/database.py"", line 23, in create_synchronous; run_synchronous(cls.__init__(db, config_file)); File ""/usr/local/lib/python3.6/dist-packages/batch/database.py"", line 15, in run_synchronous; return loop.run_until_complete(coro); File ""uvloop/loop.pyx"", line 1451, in uvloop.loop.Loop.run_until_complete; File ""/usr/local/lib/python3.6/dist-packages/batch/database.py"", line 210, in __init__; await super().__init__(config_file); File ""/usr/local/lib/python3.6/dist-packages/batch/database.py"", line 27, in __init__; with open(config_file, 'r') as f:; FileNotFoundError: [Errno 2] No such file or directory: '/batch-user-secret/sql-config.json'; ```. To see the logs `kubectl -n namespace logs pod_name cleanup`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6600#issuecomment-510272888:154,error,error,154,https://hail.is,https://github.com/hail-is/hail/pull/6600#issuecomment-510272888,1,['error'],['error']
Availability,"@danking The latest version is the code in hail/methods/. I'm having trouble with all of the configs and how to instantiate that properly. After that, I need to figure out what inputs `run_saige` actually needs. Then I need to write util functions for creating the testing chunks and annotating the matrix table. Then I think after testing and cleaning it up, it will be sufficient for the workshop. To get it into main is going to be a lot more work to have helpful error messages, check MT is valid for this analysis, integrate it more carefully into QoB.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13588:467,error,error,467,https://hail.is,https://github.com/hail-is/hail/pull/13588,1,['error'],['error']
Availability,"@danking This is far from done, evidenced by the fact that for some reason I'm getting tons of QoB test failures (but some are passing! :/) but I would appreciate a first pass on this if you want to do a high-level review. I do have a rough RFC that is not up to date, so let me know if you'd prefer to start the discussion from such a doc instead of the code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13131#issuecomment-1581539600:104,failure,failures,104,https://hail.is,https://github.com/hail-is/hail/pull/13131#issuecomment-1581539600,1,['failure'],['failures']
Availability,@danking What do you think about having a version ID inside the JAR file (MANIFEST???). We already download the JAR file on the worker. Not sure how much extra time it would be to look for the version inside the JAR (maybe cache this?) and then pass the right argument configuration.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12222#issuecomment-1258646909:99,down,download,99,https://hail.is,https://github.com/hail-is/hail/pull/12222#issuecomment-1258646909,1,['down'],['download']
Availability,"@danking What do you think about this change? I think it's fine, but if it's not fine, then we need to lock down this feature as anyone can just set it to True in the batch_client.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9907#issuecomment-767596412:108,down,down,108,https://hail.is,https://github.com/hail-is/hail/pull/9907#issuecomment-767596412,1,['down'],['down']
Availability,"@danking and I are giving feedback on this branch. Patrick, the test failure is due to you testing on files in scratch that are only local to your system. You should remove the test annotation @Test on scratch before pushing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1697#issuecomment-297083904:69,failure,failure,69,https://hail.is,https://github.com/hail-is/hail/pull/1697#issuecomment-297083904,1,['failure'],['failure']
Availability,"@danking i'm also not really certain why this works haha, i pretty much just did a bunch of trial and error. it would probably be worth taking a deeper look at how we manage our jvm dependencies (especially spark) at some point, but i figured it made sense to just revert a couple lines to fix the bug in the short term",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13759#issuecomment-1745640178:102,error,error,102,https://hail.is,https://github.com/hail-is/hail/pull/13759#issuecomment-1745640178,1,['error'],['error']
Availability,@danking off by 1 error in test:; `org.scalatest.exceptions.TestFailedException: Some(-9223372036854775807) did not contain -9223372036854775808`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1115#issuecomment-262351018:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/1115#issuecomment-262351018,1,['error'],['error']
Availability,"@danking once this builds again, can you see whether the docs failure is related to your change? it could have also been disk.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1598#issuecomment-290948269:62,failure,failure,62,https://hail.is,https://github.com/hail-is/hail/pull/1598#issuecomment-290948269,1,['failure'],['failure']
Availability,@danking the lmm change can be considered a bug fix since delta should never be negative. The log change should make the tests more robust to which JVM. Let me know if this fixes the failures and I'll PR against 0.1 as well.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2132:132,robust,robust,132,https://hail.is,https://github.com/hail-is/hail/pull/2132,2,"['failure', 'robust']","['failures', 'robust']"
Availability,@danking we should merge the delta change anyway as that's a bug that may result in test failures in the future (I just made PR of fix to 0.1). I think the log reg change is fine to go in as well.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2132#issuecomment-326109741:89,failure,failures,89,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-326109741,1,['failure'],['failures']
Availability,"@danking. Here what I have done in my environment ( AWS EMR ); * Create EMR without installing hail; * Update PATH ( this is needed or I get an error with `hailctl not found` at the installation step); ```sh; export PATH=$PATH:/home/hadoop/.local/bin; ```; * Clone latest commit of Hail; ```sh; cd /tmp; git clone --depth 1 https://github.com/broadinstitute/hail.git; cd hail/hail/; ```; * Edit `build.gradle` and add `exclude group: 'org.scala-lang', module: 'scala-reflect'`; * Build Hail; ```sh; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; ```; * Symlink hail-all-spark.jar into /opt ( At the EMR creation step (before hail installation) I edit the `spark-defaults` properties in order to link `hail-all-spark.jar`... This config was needed & works successfuly for an old version of Hail (0.2.60)... can be revisit if not appropriate for recent version; ```sh; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python3.9/site-packages/hail/backend /opt/hail/backend; ```; * start pyspark; ```sh; $ pyspark; Python 3.9.18 (main, Oct 25 2023, 05:26:35) ; [GCC 7.3.1 20180712 (Red Hat 7.3.1-17)] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:144,error,error,144,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949,1,['error'],['error']
Availability,"@danking; ```; [root@mg hail]# echo $HAIL_HOME; /opt/Software/hail; [root@mg hail]# echo $PYTHONPATH; :/opt/Software/hail/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.4-src.zip; [root@mg hail]# cd /opt/Software/hail/python; [root@mg python]# ls; hail; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python; [root@mg python]# ls; docs lib MANIFEST.in pylintrc pyspark README.md run-tests run-tests.py setup.cfg setup.py test_support; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/; [root@mg lib]# ls; py4j-0.10.4-src.zip PY4J_LICENSE.txt pyspark.zip; [root@mg lib]# echo $SPARK_CLASSPATH; /opt/Software/hail/build/libs/hail-all-spark.jar; [root@mg lib]# cd /opt/Software/hail/build/libs/; [root@mg libs]# ls; hail-all-spark.jar; ```; the configuration file:; ```; export SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2; export HAIL_HOME=/opt/Software/hail; export PYTHONPATH=""$PYTHONPATH:$HAIL_HOME/python:$SPARK_HOME/python:`echo $SPARK_HOME/python/lib/py4j*-src.zip`""; export SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-337442177:31,echo,echo,31,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337442177,4,['echo'],['echo']
Availability,"@huy-nguyen is getting a segfault on on current release (0.2.33-5d8cae649505):; ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fa4b25e18cd, pid=6637, tid=0x00007f9a4f1fc700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-1~deb9u1-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # J 8451 C2 is.hail.annotations.Region$.loadBit(JJ)Z (33 bytes) @ 0x00007fa4b25e18cd [0x00007fa4b25e18a0+0x2d]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /tmp/cac7924b3c14494b9702ac2689c0c52d/hs_err_pid6637.log; ```; with this pipeline:; ```; def normalize_contig(input_contig: hl.expr.StringExpression) -> hl.expr.StringExpression:; return input_contig.replace(""^chr"", """"). def downsample_matrix_table(mt: hl.MatrixTable, n_divisions: int, p_threshold: float) -> hl.Table:;  mt = mt.choose_cols(list(range(10))); ; x = mt.locus.global_position(); y = -hl.log10(mt.Pvalue); ; downsampled = mt.annotate_cols(; binned=hl.agg.filter(; mt.Pvalue > p_threshold,; hl.agg.downsample(; x,; y,; label=[; normalize_contig(mt.locus.contig),; hl.str(mt.locus.position),; hl.str(mt.Pvalue),; ],; n_divisions=n_divisions; ); ),; unbinned=hl.agg.filter(; mt.Pvalue <= p_threshold,; hl.agg.collect(hl.struct(; pval=mt.Pvalue,; chrom=normalize_contig(mt.locus.contig),; pos=mt.locus.position,; ac=mt.AC,; af=mt.AF,; an=mt.N,; alleles=mt.alleles,; beta=mt.BETA,; consequence=hl.if_else(; hl.is_defined(mt.annotation),; mt.annotation,; ""N/A""; ),; gene_name=mt.gene,; is_binned=False; ); ); ); ); ; downsampled = downsampled.select_cols(; binned=downsampled.binned.map(; lambda a_bin: hl.struct(; pval=hl.float64(a_bin[2][2]),; chrom=a_bin[2][0],; pos=hl.int32(a_bin[2][1]),; ac=hl.literal(0.0),; af=hl.literal(0.0),; an=",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8240:98,error,error,98,https://hail.is,https://github.com/hail-is/hail/issues/8240,2,['error'],['error']
Availability,@ihelbig Did you install through brew or pip? Normally we recommend downloading the official Spark distribution. @danking Did you install through brew? Did you see anything like this?. /Users/ih/hailenv/lib/python2.7/site-packages/pyspark/java_gateway.py:77 is trying to start Spark by invoking $SPARK_HOME/bin/spark-submit. What is $SPARK_HOME?. You might modify java_gateway.py before like 77 to print out `command` to see what command in detail it is trying to invoke.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2062#issuecomment-319701721:68,down,downloading,68,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319701721,1,['down'],['downloading']
Availability,@iitalics can you ping me once this is rebased?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6822#issuecomment-531877691:18,ping,ping,18,https://hail.is,https://github.com/hail-is/hail/pull/6822#issuecomment-531877691,1,['ping'],['ping']
Availability,"@iris-garden Let me know if you want to meet to get a low-down on what's happening here, I realize I'm asking for a review on something only dan and I ever really laid eyes on.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14450#issuecomment-2040359083:58,down,down,58,https://hail.is,https://github.com/hail-is/hail/pull/14450#issuecomment-2040359083,1,['down'],['down']
Availability,@iris-garden do you have a sense of what work remains to be done here or whether this branch is worth reviving? Just had a support issue because of a `Hail Internal Error:  404 ` that turned out to be the worker jobs ran out of memory,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12468#issuecomment-2161303529:165,Error,Error,165,https://hail.is,https://github.com/hail-is/hail/pull/12468#issuecomment-2161303529,1,['Error'],['Error']
Availability,"@jbloom I passed a 500x500 matrix and a 5000x5000 matrix of zeros from Scala. The 500x500 matrix took ~.3 seconds, and the 5000x5000 matrix took ~30 seconds to pass through. Almost all of this is spent retrieving the byte array from Java -> Python, so I don't know if we'll be able to get this noticeably faster. The 0x100000 threshold for breaking up the blocks of bytes (semi-arbitrarily) because larger blocks caused me to run out of heap space, but wiggling that value up and down seems not to really affect the amount of time it takes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2751#issuecomment-359146225:480,down,down,480,https://hail.is,https://github.com/hail-is/hail/pull/2751#issuecomment-359146225,1,['down'],['down']
Availability,@jbloom this is my fault. I changed the expression to code without ensuring the VDS actually had the relevant fields. The doc test correctly points this out. I'll fix Monday.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1598#issuecomment-290987968:19,fault,fault,19,https://hail.is,https://github.com/hail-is/hail/pull/1598#issuecomment-290987968,1,['fault'],['fault']
Availability,"@jbloom22 : Back to you. To remove the red error box on the plot output, I ended up adding CSS to hide the stderr div elements in the HTML.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1374#issuecomment-280135164:43,error,error,43,https://hail.is,https://github.com/hail-is/hail/pull/1374#issuecomment-280135164,1,['error'],['error']
Availability,@jbloom22 can you give the latest commit on this PR a second set of eyes? I had to fiddle with some tolerances due to https://storage.googleapis.com/hail-ci-0-1/ci/7a0732726e6873e2c0d85fed5183324ac9441d52/194ea22cd9f744a5463340130e799c8a65ca885e/index.html . I expected the test I added (`test_pcrelate_issue_5263`) to be exactly the same but it differed out at the 10th or so position.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5250#issuecomment-461123275:100,toler,tolerances,100,https://hail.is,https://github.com/hail-is/hail/pull/5250#issuecomment-461123275,1,['toler'],['tolerances']
Availability,@jbloom22 ping a ding ding,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3348#issuecomment-380924677:10,ping,ping,10,https://hail.is,https://github.com/hail-is/hail/pull/3348#issuecomment-380924677,1,['ping'],['ping']
Availability,"@jigold Do I understand correctly that g2-standard-4 can only be created as a job private instance because there is no matching pool? If that's right, it looks like, unlike pool jobs, a JPIM job [will be correctly marked as error](https://github.com/hail-is/hail/blob/main/batch/batch/driver/instance_collection/job_private.py#L457-L467) if there are no available regions. Assuming all that is correct, do I also understand correctly that the only reason to block incoming jobs at the front-end is for a better user experience, not to protect the system from bad data? If yes, then I agree that need not be part of this PR because it merely improves user experience rather than being critical for correct functioning of the system. Are any of my assumptions or inferences wrong?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13430#issuecomment-1725778672:224,error,error,224,https://hail.is,https://github.com/hail-is/hail/pull/13430#issuecomment-1725778672,2,"['avail', 'error']","['available', 'error']"
Availability,"@jigold Doesn't this suggest that the error's message is `'job_id'`? ; ```; > assert data['check_resource_aggregation_error'] is None, data; E AssertionError: {'check_incremental_error': None, 'check_resource_aggregation_error': ""'job_id'""}; E assert ""'job_id'"" is None; ```; The select statement for `attempt_by_job_group_resources` doesn't include a `job_id` column.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14282#issuecomment-1940328506:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/14282#issuecomment-1940328506,1,['error'],['error']
Availability,@jigold I added a commit with many changes. Sorry. There were several broken links. I fixed all of them and enabled `nitpicky` which forces Sphinx to throw an error on all broken references. I also removed an unnecessary `rm -rf` from the Makefile.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9198#issuecomment-673110373:159,error,error,159,https://hail.is,https://github.com/hail-is/hail/pull/9198#issuecomment-673110373,1,['error'],['error']
Availability,"@jigold I made some changes to the annotation database web page, care to take a look?. Mainly got rid of the tree/query builder thing and moved that functionality to checkboxes in the documentation. Seemed redundant to have both.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2144:206,redundant,redundant,206,https://hail.is,https://github.com/hail-is/hail/pull/2144,1,['redundant'],['redundant']
Availability,"@jigold I stood up batch/ci in my own project from `hail-is/hail:main` and then deployed this branch, taking notes of any changes I needed to make and all seemed to work out OK. I think that's about as much as I can properly test this without trying things out in haildev/hail-vdc. The steps were as follows:. 1. Generate the configmaps used by gateway/internal-gateway. These will have the routing configuration for production services (I've edited the bootstrap instructions to match); `make -C gateway envoy-xds-config && make -C internal-gateway envoy-xds-config`; 2.  wait a few seconds for CI to quietly update these configmaps with information about testing namespaces  (can manually verify changes with `download-configmap gateway-xds-config`); 3. Deploy the new versions of gateway/internal-gateway; `make -C gateway deploy NAMESPACE=default && make -C internal-gateway NAMESPACE=default`. This worked for me in my project with no downtime, but either way I would probably do the same thing as with the previous PR where I test it in azure before making changes to hail-vdc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12095#issuecomment-1293703346:714,down,download-configmap,714,https://hail.is,https://github.com/hail-is/hail/pull/12095#issuecomment-1293703346,2,"['down', 'downtime']","['download-configmap', 'downtime']"
Availability,"@jigold OK, so here's the summary of what I learned:. We don't have tabix files for GRCh38 and we only test on small positions. Many large positions without tabix files seems to cause a problem for VEP (and make it slow, unsurprisingly). Fix seems to be to download the *indexed* homo_sapiens cache https://ftp.ensembl.org/pub/release-95/variation/indexed_vep_cache/ and upload that to our QoB VEP bucket. I presume you copied from the data we use in Dataproc? If yes, we should update that to also have tabix files. Also, in Dataproc, we use highmem machines for VEP. We should change _service_vep to also use highmem machines. <details><summary>Listing the tabix files for GRCh38 and GRCh37</summary>. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch38-us-central1/homo_sapiens/95_GRCh38/\*/\*.tbi; CommandException: One or more URLs matched no objects.; ```. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/\*/\*.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/1/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/10/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/11/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/12/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/13/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/14/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/15/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/16/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/17/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/18/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/19/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/2/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145:257,down,download,257,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145,1,['down'],['download']
Availability,@jigold So the pylint errors are now resolved?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5563#issuecomment-471734576:22,error,errors,22,https://hail.is,https://github.com/hail-is/hail/pull/5563#issuecomment-471734576,1,['error'],['errors']
Availability,@jigold This should fix your build failure :),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1232#issuecomment-271977973:35,failure,failure,35,https://hail.is,https://github.com/hail-is/hail/pull/1232#issuecomment-271977973,1,['failure'],['failure']
Availability,@jigold could your recent changes have prevented doctest from flagging this? Erm. Well. This must be a really old error.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3700#issuecomment-394033932:114,error,error,114,https://hail.is,https://github.com/hail-is/hail/pull/3700#issuecomment-394033932,1,['error'],['error']
Availability,"@jigold https://azure.github.io/Storage/docs/application-and-user-data/code-samples/concurrent-uploads-with-versioning. Looks like this is the expected behavior from Azure Blob Storage when concurrently uploading blobs. It seems like *all* blocks are purged when any single upload succeeds. Unfortunately, it doesn't seem possible to distinguish between a truly invalid block list and this transiently invalid block list. I dislike this interface, but it is what we have. It seems to me that the right fix is to deduplicate the file list before uploading. Multiple files uploading to the same target should be an error if they're different source files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13812#issuecomment-1882088862:613,error,error,613,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1882088862,1,['error'],['error']
Availability,@jigold ready; I also fixed the recently added `echo` image.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9594#issuecomment-724108391:48,echo,echo,48,https://hail.is,https://github.com/hail-is/hail/pull/9594#issuecomment-724108391,1,['echo'],['echo']
Availability,@jigold rightly pointed out I didn't add a regression test for this. @jigold next time request changes! @jbloom22 next time request tests! @cseed write tests for failures!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1272#issuecomment-273972707:162,failure,failures,162,https://hail.is,https://github.com/hail-is/hail/pull/1272#issuecomment-273972707,1,['failure'],['failures']
Availability,@jigold sorry I pushed a change literally as you approved it! It was just removing a redundant cast of `this.asInstanceOf[ReferenceGenome]` that was called on a ReferenceGenome object.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6947#issuecomment-525030201:85,redundant,redundant,85,https://hail.is,https://github.com/hail-is/hail/pull/6947#issuecomment-525030201,1,['redundant'],['redundant']
Availability,"@jigold sorry about that CI frigged up, but things look good now, there's an error:; ```; =================================== FAILURES ===================================; ___________________ [doctest] hail.methods.impex.import_bgen ___________________; [gw0] linux -- Python 3.6.6 /home/hail/.conda/envs/hail/bin/python; 067 ; 068 Import a BGEN file as a matrix table with genotype dosage entry field:; 069 ; 070 >>> ds_result = hl.import_bgen(""data/example.8bits.bgen"",; 071 ... entry_fields=['dosage'],; 072 ... sample_file=""data/example.8bits.sample""); 073 ; 074 Load a single variant from a BGEN file:; 075 ; 076 >>> ds_result = hl.import_bgen(""data/example.8bits.bgen"",; UNEXPECTED EXCEPTION: TypeError(""import_bgen: parameter 'variants': expected (None or Sequence[hail.utils.struct.Struct] or hail.expr.expressions.typed_expressions.StructExpression or hail.table.Table), found list: [<StructExpression of type struct{locus: locus<GRCh37>, alleles: array<str>}>]"",); Traceback (most recent call last):. File ""/hail/repo/hail/build/tmp/doctest/python/hail/typecheck/check.py"", line 487, in check_all; args_.append(checker.check(arg, name, arg_name)). File ""/hail/repo/hail/build/tmp/doctest/python/hail/typecheck/check.py"", line 59, in check; raise TypecheckFailure(). hail.typecheck.check.TypecheckFailure. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/home/hail/.conda/envs/hail/lib/python3.6/doctest.py"", line 1330, in __run; compileflags, 1), test.globs). File ""<doctest hail.methods.impex.import_bgen[2]>"", line 4, in <module>. File ""<decorator-gen-904>"", line 2, in import_bgen. File ""/hail/repo/hail/build/tmp/doctest/python/hail/typecheck/check.py"", line 559, in wrapper; args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method). File ""/hail/repo/hail/build/tmp/doctest/python/hail/typecheck/check.py"", line 513, in check_all; )) from e. TypeError: import_bgen: parameter 'variants': exp",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4291#issuecomment-421486590:77,error,error,77,https://hail.is,https://github.com/hail-is/hail/pull/4291#issuecomment-421486590,2,"['FAILURE', 'error']","['FAILURES', 'error']"
Availability,"@jigold test are fixed, properly clean up; I think the test should be improved to check that deletion properly cleans up expected resources (rather than simply doesn't throw an error, which will happen if deletion fails for any reason other than 404), but I think that could wait for a subsequent PR, because as written, the only way they will fail to do so is if the wrong name or namespace are supplied (else they will throw an error and the test will fail).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5618#issuecomment-478175367:177,error,error,177,https://hail.is,https://github.com/hail-is/hail/pull/5618#issuecomment-478175367,2,['error'],['error']
Availability,"@jigold this jogged a memory, is there, perhaps, a really bad error message for `g.ad.sum()`?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/846#issuecomment-249638782:62,error,error,62,https://hail.is,https://github.com/hail-is/hail/issues/846#issuecomment-249638782,1,['error'],['error']
Availability,"@jigold to address your points from before:; 1. Pairing db update and/or self._pod_name with the k8s call, this might be a good idea but I think is orthogonal to this change. I want to focus on cleaning up k8s use and getting pods deleted, then think a little harder about how we should restructure the code more generally to be more understandable; 2. I always return at least the error so that the calling code has to decide what an error means; 3. I now always delete the pod after the db update, which I think is right b/c we don't want the refresh loop to recreate the pod.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6175#issuecomment-495393954:382,error,error,382,https://hail.is,https://github.com/hail-is/hail/pull/6175#issuecomment-495393954,2,['error'],['error']
Availability,"@jjfarrell I've been working with some other Broadies that also noted unusual results in Hail's PC-Relate. In this case, we found that about a quarter of variants being used in PC-Relate had terrible HWE p-values. We're tracking this down a bit as a possible explanation for the poor performance of PC-Relate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3490#issuecomment-388150598:234,down,down,234,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-388150598,1,['down'],['down']
Availability,"@jjfarrell Thanks for sharing that! This is really interesting information. I'm quite surprised, but the evidence is pointing to there being a PC that largely separates those 8 replicates from the entire remaining dataset (!!!). I'm personally quite surprised that 8 samples out of thousands could pull this off, but that definitely seems to be the issue, given that the PCs from PC-AiR avoid the issue. Thank you so much for hunting this down! It's very valuable information for us. ### Next Steps . So, clearly we need a solution for users that have substantial numbers of related individuals in their source dataset (especially if the pedigrees are unknown). For your _particular_ use case, I can add a blurb to the docs that recommends removing known replicates _before_ PCA and then projecting them using the loadings from PCA. A longer term solution is to simply implement PC-AiR in hail. I skimmed the implementation section of the paper earlier this week and it looks very straightforward. It seems to boil down to using the KING estimator to estimate relatedness, compute PCA on unrelated individuals, project related individuals into unrelated PC space. Finally, we can use pc_relate to improve on our original estimates of relatedness from KING. The timeline for the latter thing is kind of unclear and a bit further out given some other work I need to finish. I'll get the documentation improvement in this week. Is there anything else I can do that would have helped you avoid this issue? Is there anything else you need to resolve the issue now?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3490#issuecomment-391739992:439,down,down,439,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-391739992,2,['down'],['down']
Availability,"@jjfarrell Thanks for the information! This will be very helpful as I try to tease out what the issue is here. Also, I'm sorry my initial response was curt! I was a bit tired at the time and probably shouldn't have been responding to GitHub issues . Hail's version of pc-relate does not identify an initial set of related and unrelated individuals. The R `pcrelate` implementation (the official / reference implementation by the authors of the paper) does this to identify a set of individuals on which to run the principal components analysis. It is not entirely clear to me why this is necessary, and we don't currently have a mechanism for doing so (since pc_relate _is_ our mechanism for determining related and unrelated individuals when there is population structure in the data set). If you have prior knowledge about related samples, you might try filtering to an known unrelated set and computing the scores from that set. I'm curious if that makes any difference in the results. Your invocations look very reasonable. I'll get in touch with the gnomAD team here at the broad to learn more about their experiences with pc_relate and see if I can better understand what's happening with the replicate samples. It's definitely possible there is an implementation error; however, I also want to rule out that the pc_relate model itself isn't breaking down here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3490#issuecomment-386639531:1271,error,error,1271,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-386639531,2,"['down', 'error']","['down', 'error']"
Availability,"@jmarshall another way to do this might be to ignore/do nothing during the initial call of `job.command('')` when the argument is empty. Assuming we never want to do anything for empty/None commands we might as well eliminate them at source. That way you should only have to handle the situation in one place, and not have to handle the invalid data structure in multiple downstream places. I do like the idea of fixing this in the hail library, but you could also consider altering your upstream code so that it never makes an invalid ""`job.command('')`"" call in the first place. Eg by doing something like ; ```py; job.command('touch before'); for msg in messages:; job.command(f'echo {shlex.quote(msg)}); job.command('touch after'); ```. (assuming it doesn't matter to you whether the messages are handled in the same section of the resulting command or not). What do you think?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14700#issuecomment-2374458692:372,down,downstream,372,https://hail.is,https://github.com/hail-is/hail/pull/14700#issuecomment-2374458692,2,"['down', 'echo']","['downstream', 'echo']"
Availability,"@jmarshall, thanks doing this - would you mind adding a simple unit test to lock down the behaviour?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14700#issuecomment-2397543555:81,down,down,81,https://hail.is,https://github.com/hail-is/hail/pull/14700#issuecomment-2397543555,1,['down'],['down']
Availability,"@johnc1231 Had this idea for dealing with registry flakiness. I was hesitant at first because really I want buildkit to retry more transient errors, but maybe with its local cache it would be quick?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11666:141,error,errors,141,https://hail.is,https://github.com/hail-is/hail/pull/11666,1,['error'],['errors']
Availability,"@johnc1231 I uncommented some of the tests that I'd commented out before because they don't hit the prune error. I had to implement some stuff on PNDArray (mostly copy, and adding a case for setRequired) in order to make it work; let me know if those were missing for a reason and I'll take it out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8073#issuecomment-585372375:106,error,error,106,https://hail.is,https://github.com/hail-is/hail/pull/8073#issuecomment-585372375,1,['error'],['error']
Availability,@johnc1231 oh john this is definitely not your fault :P I lead you astray,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2274#issuecomment-333975584:47,fault,fault,47,https://hail.is,https://github.com/hail-is/hail/pull/2274#issuecomment-333975584,1,['fault'],['fault']
Availability,@konradjk @jtkoskel Ah the issue is two-fold: the compiler doesn't automatically cast types to booleans AND (perhaps more importantly) it doesn't signal a type error when the condition of an if expression is not a boolean. I'll look into this more on Monday.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2178#issuecomment-326819470:160,error,error,160,https://hail.is,https://github.com/hail-is/hail/issues/2178#issuecomment-326819470,1,['error'],['error']
Availability,@konradjk I think this error would have been specific enough for you to figure out what the problem was pretty quickly,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4088#issuecomment-410759919:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/pull/4088#issuecomment-410759919,1,['error'],['error']
Availability,"@konradjk is getting bogged down by the single-core implementation of BlockMatrix diagonal. This implementation pulls out the diagonal of each diagonal block in parallel, and then collects and flattens the result.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3216:28,down,down,28,https://hail.is,https://github.com/hail-is/hail/pull/3216,1,['down'],['down']
Availability,"@konradjk pssh, what is this ""server"" you speak of. The kubernetes pod indeed needs a newer version of cloud tools. We always grab the latest when running the hail PR jobs. Unfortunately the deploy for cloud tools on python3 was broken. That's being fixed by https://github.com/Nealelab/cloudtools/pull/101. `pip`, unhelpfully, tells you the latest version is X.Y even if X.Y isn't available for your version of python.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4347#issuecomment-422134593:382,avail,available,382,https://hail.is,https://github.com/hail-is/hail/pull/4347#issuecomment-422134593,1,['avail'],['available']
Availability,"@lfrancioli look at the built docs (under TeamCity, artifacts, index):; https://ci.hail.is/repository/download/HailSourceCode_HailMainline_BuildDocs/9716:id/www/hail/types.html#set-t. There is an issue of variable naming: your a is implicit (not named), and your b is our a. So for example:; ```; add(a: T): Set[T]  Returns the result of adding the element b to Set a.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1491#issuecomment-284773672:102,down,download,102,https://hail.is,https://github.com/hail-is/hail/pull/1491#issuecomment-284773672,1,['down'],['download']
Availability,"@lfrancioli see the docs, `parallel` takes a string. The PR adds a typechecker to give a better error message to future you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4033#issuecomment-408956343:96,error,error,96,https://hail.is,https://github.com/hail-is/hail/issues/4033#issuecomment-408956343,1,['error'],['error']
Availability,@lgruen are y'all running with this change now? I was vaguely concerned that with ~32 JVMs alive that would negatively impact the machine. Do you find that the JVM's RAM gets swapped out and the machines are generally stable?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12248#issuecomment-1266128264:91,alive,alive,91,https://hail.is,https://github.com/hail-is/hail/pull/12248#issuecomment-1266128264,1,['alive'],['alive']
Availability,"@liameabbott I think you should go ahead and merge #3859. Once this is in, you can then use `locus_windows` to simplify, reduce memory req, and be more robust to catching out-of-order loci.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3873#issuecomment-401440022:152,robust,robust,152,https://hail.is,https://github.com/hail-is/hail/pull/3873#issuecomment-401440022,1,['robust'],['robust']
Availability,"@maccum I made block_size an optional parameter, can you take a quick look before i merge? Using the larger block size fixed hadoop failure in UKBB case, but a smaller block size may still be preferable for fewer samples to increase write parallelism, so best to make it settable.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3697#issuecomment-393947795:132,failure,failure,132,https://hail.is,https://github.com/hail-is/hail/pull/3697#issuecomment-393947795,1,['failure'],['failure']
Availability,"@mhebrard. Just to be clear: *after* installing Hail, `/usr/bin/spark-shell --version` now shows `2.12.13` but `pip3 show pyspark` still shows ""Warning: Package(s) not found: pyspark""?. Is `/usr/bin/spark-shell` a symlink? What does it point to? Is `/usr/lib/spark` a symlink? Does it point to the same place? Actually, let's just check a bunch of things:; ```; ls -al /usr/bin/spark-shell; echo $(which spark-shell); ls -al $(which spark-shell); spark-shell --version. ls -al /usr/bin/spark-submit; echo $(which spark-submit); ls -al $(which spark-submit); spark-submit --version. ls -al /usr/bin/spark-class; echo $(which spark-class); ls -al $(which spark-class). echo SPARK_SCALA_VERSION=$SPARK_SCALA_VERSION. echo "">>>>>>>>>> before load-spark-env.sh <<<<<<<<<""; env. load-spark-env.sh. echo "">>>>>>>>>> after load-spark-env.sh <<<<<<<<<""; env. which scala; ls -al $(which scala); cat $(which scala); ```. And one more thing, can you edit `$(which spark-shell)` to add `set -x` then try `spark-shell` and see if there's anything mysterious?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222:391,echo,echo,391,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222,6,['echo'],['echo']
Availability,@natestockham As to your more specific issue can you tell me the output of this:. ```bash; echo $SPARK_HOME; echo $HAIL_HOME; echo $PYTHONPATH; ```. Can you also post the invocation you're using to trigger this test failure? I assume you're in a clone of the Hail repository and running:. ```bash; ./gradlew test -Dspark.version=2.1.0; ```. in a shell with `$SPARK_HOME` pointing to a `2.1.0` installation of Spark.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1419#issuecomment-281828119:91,echo,echo,91,https://hail.is,https://github.com/hail-is/hail/issues/1419#issuecomment-281828119,4,"['echo', 'failure']","['echo', 'failure']"
Availability,"@natestockham there's been some data science-y investigations on our end, final results not yet ready, but it looks like that test is way over constrained. Our confidence in the LMM method has not yet changed as a result of this failure. I'll be pushing a commit to remove the test failure by Monday.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1419#issuecomment-282453922:229,failure,failure,229,https://hail.is,https://github.com/hail-is/hail/issues/1419#issuecomment-282453922,2,['failure'],['failure']
Availability,"@patrick-schultz @tpoterba I removed the dependence on #6534 and wrote a test to exercise the IR nodes and all the aggregators we had written. This can now be reviewed/go in independently of the other one, which was failing on a match error in Emit. (I'll request changes to block the other one from going in until we've discussed a plan for using it, since that's now the one that will send everything through the new path.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6535#issuecomment-509383664:235,error,error,235,https://hail.is,https://github.com/hail-is/hail/pull/6535#issuecomment-509383664,1,['error'],['error']
Availability,"@patrick-schultz Are you okay with where the checkpoints are? If yes, then I'll do one last set of benchmarks and then this is ready to go!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12629#issuecomment-1409418048:45,checkpoint,checkpoints,45,https://hail.is,https://github.com/hail-is/hail/pull/12629#issuecomment-1409418048,1,['checkpoint'],['checkpoints']
Availability,"@patrick-schultz Do I understand the error message correctly to mean I need to implement an Interpret step for this? Is that like an hour of work, a day, a week?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13336#issuecomment-1664627297:37,error,error,37,https://hail.is,https://github.com/hail-is/hail/pull/13336#issuecomment-1664627297,1,['error'],['error']
Availability,@patrick-schultz I resolved the conflict by keeping main which seems to have encompassed your change but with a more descriptive error message.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11003#issuecomment-1476992958:129,error,error,129,https://hail.is,https://github.com/hail-is/hail/pull/11003#issuecomment-1476992958,1,['error'],['error']
Availability,"@patrick-schultz I rewrote the `ReadIterator` stuff as a wrapper for a `Reader` object that actually manages the state. I've left the Region management out of this for now; it's currently pulling the region from the downstream ContextRDD, but the next step is definitely to move the region management into c++.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4729#issuecomment-437161860:216,down,downstream,216,https://hail.is,https://github.com/hail-is/hail/pull/4729#issuecomment-437161860,1,['down'],['downstream']
Availability,@patrick-schultz I'm closing this for now because there's something erroring in the python tests that I don't understand. I'll re-open once I've fixed that and am more certain that I actually understand what's happening.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4165#issuecomment-413875178:68,error,erroring,68,https://hail.is,https://github.com/hail-is/hail/pull/4165#issuecomment-413875178,1,['error'],['erroring']
Availability,"@patrick-schultz I'm sending this back to you because I made some pretty drastic changes trying to fix some errors. The biggest non-refactoring change that the original this introduces is that we can't parse IR for a persisted block matrix reader if the persisted block matrix doesn't exist. (This makes some amount of sense if you consider that we also can't parse the IR for a native block matrix reader if the file doesn't exist.). This led me down a rabbit hole of test failures since we're parsing IR/types a fair number of times, through the execution and after we get the result. After fiddling with it for a little bit, I removed UnpersistBlockMatrix. I'm not sure what I was thinking when I added it. I re-added an ""unpersist"" function to the backend to handle unpersisting BlockMatrices. It differs from the current Table/MatrixTable unpersist functions in that we only pass the id of the thing we want to unpersist, not the entire IR, since that's all we need.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9421#issuecomment-691300692:108,error,errors,108,https://hail.is,https://github.com/hail-is/hail/pull/9421#issuecomment-691300692,3,"['down', 'error', 'failure']","['down', 'errors', 'failures']"
Availability,@patrick-schultz Lots of test failures,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10848#issuecomment-914526677:30,failure,failures,30,https://hail.is,https://github.com/hail-is/hail/pull/10848#issuecomment-914526677,1,['failure'],['failures']
Availability,"@patrick-schultz OK, I understand now. Can you ping Ed or find someone else to review? Let's get this in post-haste.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13939#issuecomment-1785257005:47,ping,ping,47,https://hail.is,https://github.com/hail-is/hail/pull/13939#issuecomment-1785257005,1,['ping'],['ping']
Availability,@patrick-schultz ping,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4836#issuecomment-445967344:17,ping,ping,17,https://hail.is,https://github.com/hail-is/hail/pull/4836#issuecomment-445967344,2,['ping'],['ping']
Availability,"@patrick-schultz rebase failure, I'll remove.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3186#issuecomment-375789384:24,failure,failure,24,https://hail.is,https://github.com/hail-is/hail/pull/3186#issuecomment-375789384,1,['failure'],['failure']
Availability,@patrick-schultz this is downstream of a `.entries()`. The latest errors indicate its a shuffle read error. Seems like shuffling our tiny 1kg downsample blows out spark's memory.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4242#issuecomment-417780228:25,down,downstream,25,https://hail.is,https://github.com/hail-is/hail/pull/4242#issuecomment-417780228,4,"['down', 'error']","['downsample', 'downstream', 'error', 'errors']"
Availability,"@ryerobinson, ah! This is because of xargs. You're building a Dockerfile, is that right? From where did you get this Dockerfile?. I think you need `xargs -d '\n'` or `xargs -0` to prevent xargs from splitting on the space between the semicolon and the sys_platform. e.g. in the python:3.8 container, this works:; ```; root@0c1415c108de:/# echo ""uvloop==0.16.0; sys_platform!='win32'"" | xargs -0 python3 -m pip install -U; Collecting uvloop==0.16.0; Downloading uvloop-0.16.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.7 MB);  4.7/4.7 MB 3.6 MB/s eta 0:00:00; Installing collected packages: uvloop; Successfully installed uvloop-0.16.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.; You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.; ```; but this does not:; ```; root@0c1415c108de:/# echo ""uvloop==0.16.0; sys_platform!='win32'"" | xargs python3 -m pip install -U; Requirement already satisfied: uvloop==0.16.0 in /usr/local/lib/python3.8/site-packages (0.16.0); ERROR: Could not find a version that satisfies the requirement sys_platform!=win32 (from versions: none); ERROR: No matching distribution found for sys_platform!=win32; WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.; You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255256786:339,echo,echo,339,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255256786,7,"['Down', 'ERROR', 'avail', 'echo']","['Downloading', 'ERROR', 'available', 'echo']"
Availability,"@tlangs Nothing on your end, we've had some CI instability lately that's causing some unrelated failures. I'll make sure to retest this once that's fixed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13129#issuecomment-1581217232:96,failure,failures,96,https://hail.is,https://github.com/hail-is/hail/pull/13129#issuecomment-1581217232,1,['failure'],['failures']
Availability,"@tmwong2003 OK, some progress on the CI front. Thanks for your patience. A team member needs to kick off the CI job. The assigned reviewer will be responsible for that. Right now, the tests involve some sensitive tokens which need more work to be protected, so the CI logs aren't public yet. Again, the assigned reviewer should be able to share the relevant part of the logs for failures, etc. @tpoterba I kicked off the build. Can you take another look, it looks like the comments were addressed. Finally, it looks like the PR history is a bit tangled. Is it possible to clean it up so we can a reasonable commit message? Thanks!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6262#issuecomment-501887788:379,failure,failures,379,https://hail.is,https://github.com/hail-is/hail/pull/6262#issuecomment-501887788,1,['failure'],['failures']
Availability,"@tpoterba , can you take a look as well?. Notes:. 1. Azure uses Spark 3.0.2, so I need to build and publish a wheel for Spark 3.0.2.; 2. Azure provides Jupyter Notebooks already.; 3. hail/Makefile (for manual deploys) was missing some changes for deploy.sh, so I updated it.; 4. Azure sets the `AZURE_SPARK` environment variable inside hosted Jupyter Notebooks. 5. In Azure's Jupyter, if you set `extraClassPath` you break the extant classpath (e.g. you cannot load Scala stdlib classes). However, the JARs specified in `spark.jars` are added to the classpath properly, so, in Azure, it suffices to specify `spark.jars`. 6. Azure lacks requester pays, so I require Azure users download, untar, and upload the VEP files to their own bucket. 7. Instead of ""submit"", Azure installs Livy, a Java job-queue system. I have no idea how to set environment variables in Livy and Azure does not set AZURE_SPARK in Livy jobs; therefore, I search for `hdinsight` in the CLASSPATH.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11187:677,down,download,677,https://hail.is,https://github.com/hail-is/hail/pull/11187,1,['down'],['download']
Availability,"@tpoterba . Hi Tim ,Thank you for answering , I run the ""gradle check --info"" again , there is a lot of infomation, so I save the standard output and standard error in ""check_info_1.txt"",as attached. Thank you for your help. [check_info_1.txt](https://github.com/broadinstitute/hail/files/345679/check_info_1.txt)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/457#issuecomment-230213155:159,error,error,159,https://hail.is,https://github.com/hail-is/hail/issues/457#issuecomment-230213155,1,['error'],['error']
Availability,"@tpoterba . Thanks for pointing out the extra step. ; So I have compiled hail to run on Centos 6 and it is running python scripts fine locally (master=local[*]). However, the following error occurs when running it with yarn. Any suggestions on this? . ```; [Stage 0:> (0 + 1) / 292]---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /restricted/projectnb/ukbiobank/ad/analysis/ad.v1/bgen_count.py in <module>; 10 mt=hl.import_bgen(bgen,sample_file=sample,entry_fields=['GT','GP','dosage']); 11 mt.describe(); ---> 12 print(""Count:"",mt.count()); 13 mt.s.show(); 14. /restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/matrixtable.py in count(self); 2129 Number of rows, number of cols.; 2130 """"""; -> 2131 r = self._jmt.count(); 2132 return r._1(), r._2(); 2133. /share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container marked as failed: container_e2435_1542127286896_0109_02_000004 on host: scc-q06.scc.bu.edu. Exit status: 1. Diagnostics: Exception from containe",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-446057705:185,error,error,185,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-446057705,1,['error'],['error']
Availability,"@tpoterba ; Hi Tim , thank you ,I tried the plink1.9, and it works. but when I use the ""importvcf"" command, there are some issues, I took the advice in ""http://www.slf4j.org/codes.html"", added one of the jars in my classpath,but the issue still appeared. (1) command and the info:; root hail $ ./build/install/hail/bin/hail importvcf src/test/resources/sample.vcf.gz -f write -o sample_4.vds; hail: info: running: importvcf src/test/resources/sample.vcf.gz -f; hail: info: running: write -o sample_4.vds; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; hail: info: while importing:; file:/***/hail/src/test/resources/sample.vcf.gz import clean; hail: info: timing:; importvcf: 736.849ms; write: 2.463s. (2) modify the classpath; I add the ""slf4j-nop.jar"" in the CLASSPATH,as follows:; root hail $ echo $CLASSPATH; .:/usr/share/java/slf4j/slf4j-nop.jar:/opt/BioDir/jdk/jdk1.8.0_91/lib/dt.jar:/opt/BioDir/jdk/jdk1.8.0_91/lib/tools.jar",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/457#issuecomment-230429438:962,echo,echo,962,https://hail.is,https://github.com/hail-is/hail/issues/457#issuecomment-230429438,1,['echo'],['echo']
Availability,"@tpoterba ; Hi, Tim; I installed plink, and set the pathas follows,but when excute ""gradle check"",still have problems,I don't know how I should do ?; ------------------(1) ; root ***\* $ plink --file test. @----------------------------------------------------------@; | PLINK! | v1.07 | 10/Aug/2009 |; |----------------------------------------------------------|; | (C) 2009 Shaun Purcell, GNU General Public License, v2 |; |----------------------------------------------------------|; | For documentation, citation & bug-report instructions: |; | http://pngu.mgh.harvard.edu/purcell/plink/ |; @----------------------------------------------------------@. Web-based version check ( --noweb to skip ); ......-----------------------------------------------------------------------------------; (2) The path; export PLINK_HOME=/***/plink. ## export PATH=$PLINK_HOME:$PATH. (3) The errors:; Gradle suite > Gradle test > org.broadinstitute.hail.methods.ExportPlinkSuite.testBiallelic FAILED; java.io.FileNotFoundException at ExportPlinkSuite.scala:17; Running test: Test method test(org.broadinstitute.hail.methods.ExportSuite); Gradle suite > Gradle test > org.broadinstitute.hail.driver.GRMSuite.test FAILED; java.io.FileNotFoundException at GRMSuite.scala:20; Running test: Test method testGenotypeStream(org.broadinstitute.hail.variant.GenotypeStreamSuite); Gradle suite > Gradle test > org.broadinstitute.hail.methods.ImputeSexSuite.testImputeSexPlinkVersion FAILED; java.io.FileNotFoundException at ImputeSexSuite.scala:17; Running test: Test method test(org.broadinstitute.hail.variant.IntervalListSuite)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/457#issuecomment-230191234:878,error,errors,878,https://hail.is,https://github.com/hail-is/hail/issues/457#issuecomment-230191234,1,['error'],['errors']
Availability,"@tpoterba @cseed. I ran into some issues building images that I addressed as a part of this PR. The main issue was that we needed the `beta` `gcloud` commands, so I added a line to the Dockerfile to load those. I also made a couple changes to the Docker build commands to ensure we at least reuse all images that are available in our GCR. I added `hail-pr-builder` as a cache source in an attempt to take advantage of successful local builds. This, unfortunately, does not allow us to reuse successful layers from a failing build. I noticed that if I build and fail once using `--cache-from`, then I cannot re-use the succeeding layers of the failed build, regardless of whether I supplied `--cache-from`. I also added `:latest` to the `docker images` command because I have a couple tagged images from earlier iterations of this script.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4362#issuecomment-424066734:317,avail,available,317,https://hail.is,https://github.com/hail-is/hail/pull/4362#issuecomment-424066734,1,['avail'],['available']
Availability,"@tpoterba @danking We at Databricks are still interested in this. Although Hail's frontend is in Python, it's still useful to publish to maven central. First, it makes the dependency information available. I've seen people write pipelines that are partly in Hail and partly in PySpark and can include Java libraries for things like data sources. There's a lot of tooling for resolving dependency conflicts between different libraries, but they're not very accessible unless all your dependencies are published to maven repos and have dependency poms available. It's also easier to update pipelines to the latest Hail version if the artifacts published to a standard location.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1963#issuecomment-481354319:195,avail,available,195,https://hail.is,https://github.com/hail-is/hail/issues/1963#issuecomment-481354319,2,['avail'],['available']
Availability,"@tpoterba @jbloom22 I've reviewed this PR but haven't approved it because I was waiting for the other one to go in. If someone pings me when it does, I'm happy to approve.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4971#issuecomment-448317746:127,ping,pings,127,https://hail.is,https://github.com/hail-is/hail/pull/4971#issuecomment-448317746,1,['ping'],['pings']
Availability,@tpoterba @jigold ping,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4720#issuecomment-437412681:18,ping,ping,18,https://hail.is,https://github.com/hail-is/hail/pull/4720#issuecomment-437412681,1,['ping'],['ping']
Availability,"@tpoterba Compilation error, I think maybe you can only mark things that are `val` or `var` transient",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9407#issuecomment-686630822:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/9407#issuecomment-686630822,1,['error'],['error']
Availability,@tpoterba Copy suggestions expected. I'm also confused by the test failures... Different tests are failing each time. Is master green? Random tests fail for me when I run unit tests against master locally as well.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4068#issuecomment-411199374:67,failure,failures,67,https://hail.is,https://github.com/hail-is/hail/pull/4068#issuecomment-411199374,1,['failure'],['failures']
Availability,"@tpoterba Do you have a specific example where this fails? I think the columns are already unkeyed before export with this line:. ```; dataset = dataset._select_all(col_exprs=fam_exprs,; col_key=[],; row_exprs=bim_exprs,; entry_exprs=entry_exprs); ```. I tried making the Python test more robust where I permute the columns first so not in alphabetical order before exporting, but couldn't replicate the error. The same is true for `export_gen`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4508#issuecomment-428976439:289,robust,robust,289,https://hail.is,https://github.com/hail-is/hail/issues/4508#issuecomment-428976439,2,"['error', 'robust']","['error', 'robust']"
Availability,@tpoterba How do I get the java stack trace to debug the error in the docs build (failed in the Tutorial testing)?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1430#issuecomment-282137009:57,error,error,57,https://hail.is,https://github.com/hail-is/hail/pull/1430#issuecomment-282137009,1,['error'],['error']
Availability,"@tpoterba I added [another PR](https://github.com/hail-is/hail/pull/1613) which adds a `./configure` script which walks the user through setting a spark version (in the future we can add other parameters too). Perhaps that's the best way to manage this going forward?. If the gradle.properties file doesn't exist, our gradle script errors and asks the user to run `./configure`. The `./configure` script queries the user for sparkVersion and generates a valid `gradle.properties` file. Afterwards, the user can execute gradle normally without any `-D` parameters. Users may still override the `sparkVersion` variable on the command line by specifying `-PsparkVersion=2.1.1`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1608#issuecomment-290198582:332,error,errors,332,https://hail.is,https://github.com/hail-is/hail/pull/1608#issuecomment-290198582,1,['error'],['errors']
Availability,"@tpoterba I also added a `hail-ci-build.sh` so we'll build the images in the PRs, ensuring we don't get deploy problems from image build failures.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4965#issuecomment-447034807:137,failure,failures,137,https://hail.is,https://github.com/hail-is/hail/pull/4965#issuecomment-447034807,1,['failure'],['failures']
Availability,@tpoterba I also got rid of max_shift and (hopefully) made things more robust. Can you take a quick look to see if you're happy with what I did?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2359#issuecomment-339549140:71,robust,robust,71,https://hail.is,https://github.com/hail-is/hail/pull/2359#issuecomment-339549140,1,['robust'],['robust']
Availability,"@tpoterba I had everything working locally, but hadn't updated master. Unfortunately, there's a test failure in the new test you added for `index_globals` and I can't figure out how to fix it. I tried creating the environment separately and the `pli` field was there. Could you please take a look?. ```; _____________ [doctest] hail.matrixtable.MatrixTable.index_globals _____________; [gw0] darwin -- Python 3.6.1 //anaconda/envs/py36/bin/python; UNEXPECTED EXCEPTION: AttributeError(""StructExpression instance has no field, method, or property 'pli'\n Hint: use 'describe()' to show the names of all data fields."",); Traceback (most recent call last):. File ""//anaconda/envs/py36/lib/python3.6/doctest.py"", line 1330, in __run; compileflags, 1), test.globs). File ""<doctest hail.matrixtable.MatrixTable.index_globals[0]>"", line 1, in <module>. File ""/Users/jigold/hail/build/tmp/doctest/python/hail/expr/expressions/typed_expressions.py"", line 1161, in __getattr__; raise AttributeError(get_nice_attr_error(self, item)). AttributeError: StructExpression instance has no field, method, or property 'pli'; Hint: use 'describe()' to show the names of all data fields. /Users/jigold/hail/build/tmp/doctest/python/hail/matrixtable.py:2197: UnexpectedException; ============== 1 failed, 420 passed, 13 skipped in 79.03 seconds ===============; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3620#issuecomment-390841993:101,failure,failure,101,https://hail.is,https://github.com/hail-is/hail/pull/3620#issuecomment-390841993,1,['failure'],['failure']
Availability,@tpoterba I think your error message is much better.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1406#issuecomment-280845674:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/pull/1406#issuecomment-280845674,1,['error'],['error']
Availability,"@tpoterba That example loses the singletons (nodes with no edges that are not passed to the maximal_independent_set method). With the old method, we worked around this by collecting all the nodes in python (both nodes with edges and singleton nodes) and then filtering to remove the nodes returned by maximal_independent_set. But collecting all the nodes in python and then passing them to filter_rows is slow. So I'm moving the logic of collecting all the nodes and filtering down to Scala.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2975#issuecomment-368108496:477,down,down,477,https://hail.is,https://github.com/hail-is/hail/pull/2975#issuecomment-368108496,1,['down'],['down']
Availability,"@tpoterba That test doesn't pass, even with this fix:. ```; 2021-04-26 15:57:13 Hail: INFO: Running Hail version 0.2.65-77eb6e1a1cf4; 2021-04-26 15:57:14 Hail: ERROR: error from strategy JvmCompile. java.lang.RuntimeException: unrealizable value unused asymmetrically: eos=false, ped=true. 	at is.hail.expr.ir.streams.StreamProducer$.defineUnusedLabels(EmitStream.scala:29); 	at is.hail.expr.ir.Emit.$anonfun$emitI$68(Emit.scala:1080); 	at is.hail.expr.ir.IEmitCodeGen.map(Emit.scala:304); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:1065); 	at is.hail.expr.ir.Emit.emitInNewBuilder$1(Emit.scala:674); 	at is.hail.expr.ir.Emit.$anonfun$emitI$26(Emit.scala:816); 	at is.hail.expr.ir.EmitCode$.fromI(Emit.scala:391); 	at is.hail.expr.ir.Emit.$anonfun$emitI$25(Emit.scala:816); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at scala.collection.TraversableLike.map(TraversableLike.scala:286); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:279); 	at scala.collection.AbstractTraversable.map(Traversable.scala:108); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:815); 	at is.hail.expr.ir.Emit$.$anonfun$apply$4(Emit.scala:99); 	at is.hail.expr.ir.EmitCodeBuilder$.scoped(EmitCodeBuilder.scala:19); 	at is.hail.expr.ir.EmitCodeBuilder$.scopedCode(EmitCodeBuilder.scala:24); 	at is.hail.expr.ir.EmitMethodBuilder.emitWithBuilder(EmitClassBuilder.scala:1044); 	at is.hail.expr.ir.WrappedEmitMethodBuilder.emitWithBuilder(EmitClassBuilder.scala:1095); 	at is.hail.expr.ir.WrappedEmitMethodBuilder.emitWithBuilder$(EmitClassBuilder.scala:1095); 	at is.hail.expr.ir.EmitFunctionBuilder.emitWithBuilder(EmitClassBuilder.scala:1192); 	at is.hail.expr.ir.Emit$.apply(Emit.scala:97); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:78); 	at",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10330#issuecomment-827119604:160,ERROR,ERROR,160,https://hail.is,https://github.com/hail-is/hail/pull/10330#issuecomment-827119604,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"@tpoterba fixed the config issue and changed n_partitions to ensure workers are scheduled for the FASTA reading. I tested this on a single batch worker so the jobs overlapped and flexed the shared mount code, but we don't really have a guarantee in our test setup because batch has no way to force collocation of jobs (and even so we can't exactly force that the runtimes will overlap). I suppose if there's an issue here it will bubble up as a nondeterministic failure. Not great but perhaps good enough for now?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12736#issuecomment-1499151688:462,failure,failure,462,https://hail.is,https://github.com/hail-is/hail/pull/12736#issuecomment-1499151688,1,['failure'],['failure']
Availability,@tpoterba is it obvious why this went wrong? Are `case` expressions allowed to have missing default statements (and we throw an error if we don't match anything?),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3696#issuecomment-393678445:128,error,error,128,https://hail.is,https://github.com/hail-is/hail/issues/3696#issuecomment-393678445,1,['error'],['error']
Availability,@tpoterba ping,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/753#issuecomment-257354062:10,ping,ping,10,https://hail.is,https://github.com/hail-is/hail/pull/753#issuecomment-257354062,1,['ping'],['ping']
Availability,"@tpoterba ping, are you cool with the page I mentioned?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3281#issuecomment-379044933:10,ping,ping,10,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-379044933,1,['ping'],['ping']
Availability,"@tpoterba this actually fails tests, am I being overly optimistic about what extract intervals can achieve? The following are the failures and they're all about the number of partitions after a filter.; ```; FAILED test/hail/extract_intervals/test_full_key.py::test_mt_lt[locus] - assert 20 == 15; FAILED test/hail/extract_intervals/test_full_key.py::test_mt_le[locus] - assert 20 == 15; FAILED test/hail/extract_intervals/test_full_key.py::test_mt_ge[locus] - assert 20 == 6; FAILED test/hail/extract_intervals/test_full_key.py::test_mt_gt[locus] - assert 20 == 6; FAILED test/hail/extract_intervals/test_full_key.py::test_ht_lt[locus] - assert 20 == 15; FAILED test/hail/extract_intervals/test_full_key.py::test_ht_le[locus] - assert 20 == 15; FAILED test/hail/extract_intervals/test_full_key.py::test_ht_ge[locus] - assert 20 == 6; FAILED test/hail/extract_intervals/test_full_key.py::test_ht_gt[locus] - assert 20 == 6; FAILED test/hail/extract_intervals/test_full_key.py::test_mt_lt[Locus] - assert 20 == 15; FAILED test/hail/extract_intervals/test_full_key.py::test_mt_le[Locus] - assert 20 == 15; FAILED test/hail/extract_intervals/test_full_key.py::test_mt_ge[Locus] - assert 20 == 6; FAILED test/hail/extract_intervals/test_full_key.py::test_mt_gt[Locus] - assert 20 == 6; FAILED test/hail/extract_intervals/test_full_key.py::test_ht_lt[Locus] - assert 20 == 15; FAILED test/hail/extract_intervals/test_full_key.py::test_ht_le[Locus] - assert 20 == 15; FAILED test/hail/extract_intervals/test_full_key.py::test_ht_ge[Locus] - assert 20 == 6; FAILED test/hail/extract_intervals/test_full_key.py::test_ht_gt[Locus] - assert 20 == 6; ======================================================================================================================================= 16 failed, 34 passed in 19.17s =======================================================================================================================================; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12484#issuecomment-1319322867:130,failure,failures,130,https://hail.is,https://github.com/hail-is/hail/pull/12484#issuecomment-1319322867,1,['failure'],['failures']
Availability,"@tpoterba this builds on your recent PR https://github.com/hail-is/hail/pull/3882. partition counts are computed through Interpret on demand and memoized in the IR. fastPartitionCounts means get the partition counts if you have them (either because the IR know their partition counts, or they were previously computed by counting the RVD partitions). partitionCounts means compute (and memoize) if they aren't available the fast way. I think this is now optimal except that MatrixTable.count potentially runs things twice. We might be able to fix this with a MatrixLet in the case you're calling MatrixTable.count(). Next Table.index/MatrixTable.indexRows should use partitionCounts instead of zipWithIndex because computing the partition counts via the optimizer will potentially be much faster.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3891:410,avail,available,410,https://hail.is,https://github.com/hail-is/hail/pull/3891,1,['avail'],['available']
Availability,"@tpoterba tried to run some jobs on the batch2 instance in the default namespace. He ran into two errors when trying to get log files (one while the job was running and the other when it terminated):. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py"", line 418, in start; resp = await task; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 458, in _handle; resp = await handler(request); File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_middlewares.py"", line 119, in impl; return await handler(request); File ""/usr/local/lib/python3.6/dist-packages/aiohttp_session/__init__.py"", line 152, in factory; response = await handler(request); File ""/usr/local/lib/python3.6/dist-packages/prometheus_async/aio/_decorators.py"", line 42, in time_decorator; rv = await wrapped(*args, **kw); File ""/usr/local/lib/python3.6/dist-packages/gear/auth.py"", line 86, in wrapped; return await fun(request, userdata, *args, **kwargs); File ""/usr/local/lib/python3.6/dist-packages/batch/front_end/front_end.py"", line 383, in ui_get_job_log; 'job_log': await _get_job_log(request.app, batch_id, job_id, user); File ""/usr/local/lib/python3.6/dist-packages/batch/front_end/front_end.py"", line 112, in _get_job_log; job_log = await job._read_logs(); File ""/usr/local/lib/python3.6/dist-packages/batch/batch.py"", line 49, in _read_logs; return await self.app['driver'].read_pod_logs(self._pod_name); File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 160, in __getitem__; return self._state[key]; KeyError: 'driver'; ```. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 636, in download_to_file; self._do_download(transport, file_obj, download_url, headers, start, end); File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 574, in _do_download; download.consume(transport); File ""/usr/local/lib/python3.6/dist-pac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7412:98,error,errors,98,https://hail.is,https://github.com/hail-is/hail/pull/7412,1,['error'],['errors']
Availability,@violetbrina there are just a couple of lint errors left on this branch. If you locally run `make check-ci` you should see the couple of suggestions to fix. I'm also happy to push the fixes to `populationgenomics:azure-upstream` if that's fine.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12065#issuecomment-1289400014:45,error,errors,45,https://hail.is,https://github.com/hail-is/hail/pull/12065#issuecomment-1289400014,1,['error'],['errors']
Availability,"@vladsaveliev no specific reason, we were just trying to roll up a bunch of updates at once instead of tons of tiny PRs and then got bogged down with some changes that needed to be made. Feel free to PR any version updates and I'll see them through!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11520#issuecomment-1123673359:140,down,down,140,https://hail.is,https://github.com/hail-is/hail/pull/11520#issuecomment-1123673359,1,['down'],['down']
Availability,"@zenghz What version of Hail are you using? It must be ancient. We no longer support Spark 1 and haven't for quite some time. We saw this in sporadically in some deployments, but never understood it or developed a reliable workaround. My advice would be to upgrade to Spark 2 and the latest version of Hail if possible. You might search on other forums for ideas/work arounds, for example: https://stackoverflow.com/questions/29960686/parquet-error-when-saving-from-spark",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1003#issuecomment-319526578:214,reliab,reliable,214,https://hail.is,https://github.com/hail-is/hail/issues/1003#issuecomment-319526578,2,"['error', 'reliab']","['error-when-saving-from-spark', 'reliable']"
Availability,A KeyError's __str__ is just the key that failed. This prints the traceback and the full; error message. It is far more useful.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9022:90,error,error,90,https://hail.is,https://github.com/hail-is/hail/pull/9022,1,['error'],['error']
Availability,A Missing Default Case Should Have An Informative Error Message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3696:50,Error,Error,50,https://hail.is,https://github.com/hail-is/hail/issues/3696,1,['Error'],['Error']
Availability,"A checklist of things to make this robust:. - [x] https://github.com/Nealelab/cloudtools/issues/72; - [x] we need more permissions:; ```; ++ cluster start ci-test-4d8a9b262c3687f33359d92afdae693c819dfb09-e9e8a40bb4f0c2337e5088c26186a4da4948bed2 --version devel --spark 2.2.0 --jar build/libs/hail-all-spark.jar --zip build/distributions/hail-python.zip; ERROR: (gcloud.dataproc.clusters.create) PERMISSION_DENIED: Request had insufficient authentication scopes.; ```; - [x] be certain clusters don't stick around. I am not too concerned about the latter. We should look carefully, but it appears that, by default, processes on pods [get 30s notice via TERM](https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods) before they're killed. All `cluster` needs to do is to send google a termination request. Although the command takes forever to exit after `cluster stop`, this is because it waits for the cluster to shut down before returning. I regularly issue `cluster stop` and then force-kill the `cluster` command instead of waiting for the cluster to shutdown.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4241#issuecomment-417653146:35,robust,robust,35,https://hail.is,https://github.com/hail-is/hail/pull/4241#issuecomment-417653146,3,"['ERROR', 'down', 'robust']","['ERROR', 'down', 'robust']"
Availability,"A couple of fixes to batch pool executor to both get rid of orphaned running forever jobs and exception not retrieved errors:. - `asyncio.wait` does not retrieve results. I had to change waits to gathers with return_exceptions=True to get the behavior we want.; - A timeout error with `asyncio.wait_for` cancels the task automatically. Therefore, the previous code would never cancel the batch because the task was already ""cancelled"".; - I made `asyncio_cancel` idempotent and made sure we cancel the batch if the task has been cancelled to address the issue above. I added a check to see if the batch is running before cancelling. I'm ambivalent on whether this change is necessary.; - I added an explicit test now to make sure all batches are terminated. I think this is a good change, but the downstream consequences could be if this runs forever on a deploy (relies on an explicit timeout). Although, `test_hailtop_batch_*` has explicit timeouts. So I think we're good.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10738:118,error,errors,118,https://hail.is,https://github.com/hail-is/hail/pull/10738,3,"['down', 'error']","['downstream', 'error', 'errors']"
Availability,"A few new test failures coming from better generators, I assume. IBD one looks like a weird corner case where we differ from plink when there are only three variants. I'll look at the rest soon.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1902#issuecomment-306294818:15,failure,failures,15,https://hail.is,https://github.com/hail-is/hail/pull/1902#issuecomment-306294818,1,['failure'],['failures']
Availability,"A forthcoming change to the hail ci system will introduce deployment. This change adds `hail-ci-deploy.sh` which replicates the [""Deploy Website""](https://ci.hail.is/admin/editRunType.html?id=buildType:HailSourceCode_HailMainline_DeployWebsite&runnerId=RUNNER_29) and [""Deploy Google Cloud""](https://ci.hail.is/admin/editRunType.html?id=buildType:HailSourceCode_HailMainline_DeployDocsAndGoogleCloudSpark220&runnerId=RUNNER_10) TeamCity jobs. My general thinking for deploy jobs from the CI is that, for the time being, we'll hardcode a mapping from GitHub repository to [Kubernetes Secret](https://kubernetes.io/docs/concepts/configuration/secret/). That's where this `/secret/ci.hail.is-web-updater-rsa-key` will come from. Moreover, the CI will always authorize a gcloud account (again with a baked in mapping from GitHub repository to GCP service account) before calling the deploy script. I did not retest the master branch here. Should we do that even though a PR is only merged to master if it passes the tests? Even after locking down merging, there's still the possibility of CI bugs. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4220:1038,down,down,1038,https://hail.is,https://github.com/hail-is/hail/pull/4220,1,['down'],['down']
Availability,"A lot of changes here. A summary:; - This subsumes notebook, so I deleted notebook and renamed notebook2 => notebook. Apologies, this makes the diff slightly harder to read.; - Added a simple messaging framework, stored in aiohttp session cookie, set message with `set_message`, handled by web_common by `base_context` by the default layout,; - Added notebook.hail.is/workshop-admin to manage and enable/disabled workshops. Workshops stored in the database.; - Workshop will be located at notebook.hail.is/workshop (I will move to workshop.hail.is as a later step); - Meta change: don't try to track dependencies on `make check` everywhere, it isn't really needed and it wasn't correct; - Rewrote code to monitor the spin up of notebooks: store notebook state in the database. I'm happy with how it turned out, it will be simpler and more reliable.; - I refactored the auth code to support the needs of workshops. I think it is also improved: simpler. Things left to do:; - ~~Port the load test code. And load test!~~; - The notebook link shouldn't be click-able if the notebook isn't ready. (Even better: If you click, launch the notebook when it is ready.); - ~~Didn't test the error case (when the notebook isn't actually available). This probably needs some work, and should get integrated into the message framework.~~; - The workshop header is a bit spare. Maybe add a slash (/) link. What would it link to?; - ~~Move notebook.hail.is/workshop to workshop.hail.is~~; - (low-prio) Finally, when the notebook state changes, we just refresh the page. Might be nice to just dynamically update HTML. Maybe react?; - (unrelated) The message framework should get used by the other services. @tpoterba I'm assigning this to you since you're point for the workshop. @akotlar knows this code if you want to re-assign. I gave you an account in my namespace, so you should be able to see/play with this at internal.hail.is/cseed/notebook. FYI @akotlar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7112:839,reliab,reliable,839,https://hail.is,https://github.com/hail-is/hail/pull/7112,3,"['avail', 'error', 'reliab']","['available', 'error', 'reliable']"
Availability,A merge failure creates a funny batch that doesn't have an id. This handles that properly.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8428:8,failure,failure,8,https://hail.is,https://github.com/hail-is/hail/pull/8428,1,['failure'],['failure']
Availability,"A miracle. It finally passed. That was a real slog. I pushed a bunch of non-trivial changes, so it is probably good if you give a skeptical, fresh look. Summary of new changes:; - added PType.literalPType that infers PTypes from Scala literals, use in a few places (emit for Literal, BroadcastRegionValue constructor from annotation, etc.); - require Table global and row types to be required; - same for MatrixValue, but also cols and entries (the entries array, not individual entries, which an be missing); - Don't upcast globals in TableKeyBy and TableOrderBy; - added EType setRequired; - AbstractCodecSpecs assert row and global etypes are present at the toplevel, and setRequired(true) if they are coming from encoders written by previous versions; - rename PType.copyFromType to PType.copyFromAdddres. Modify it so it can ""downcast"": convert to a PType with greater requiredness. This is used in converting TableValues to MatrixValues to satisfy the requiredness assertions. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8371#issuecomment-609070509:831,down,downcast,831,https://hail.is,https://github.com/hail-is/hail/pull/8371#issuecomment-609070509,1,['down'],['downcast']
Availability,"A mitigation, but not resolution, for #13402, this errors a job after 10 seconds of waiting on a network namespace, as it should never take that long to create one.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13403:51,error,errors,51,https://hail.is,https://github.com/hail-is/hail/pull/13403,1,['error'],['errors']
Availability,"A number of people have observed the same behavior, but the prometheus team closes it as not a bug. It appears to be related to suddenly adding a very large number of metrics. This started happening when I started the scale tests, which keeps the k8s system operating with about 2000 pods, working through 30k pods over time. It's possible all the added pod information is bringing down prometheus. It appears k8s is restarting prometheus between every ten and twenty minutes. It seems likely that prometheus is spending more than ten minutes to load its database. This is surprising given that the database is a mere 31 GB:. ```; Filesystem Size Used Available Use% Mounted on; overlay 94.3G 46.4G 47.9G 49% /; tmpfs 64.0M 0 64.0M 0% /dev; tmpfs 14.7G 0 14.7G 0% /sys/fs/cgroup; /dev/sdd 49.0G 31.2G 17.8G 64% /prometheus; /dev/sda1 94.3G 46.4G 47.9G 49% /etc/prometheus; /dev/sda1 94.3G 46.4G 47.9G 49% /dev/termination-log; /dev/sda1 94.3G 46.4G 47.9G 49% /etc/resolv.conf; /dev/sda1 94.3G 46.4G 47.9G 49% /etc/hostname; /dev/sda1 94.3G 46.4G 47.9G 49% /etc/hosts; shm 64.0M 0 64.0M 0% /dev/shm; tmpfs 14.7G 12.0K 14.7G 0% /var/run/secrets/kubernetes.io/serviceaccount; tmpfs 14.7G 0 14.7G 0% /proc/acpi; tmpfs 64.0M 0 64.0M 0% /proc/kcore; tmpfs 64.0M 0 64.0M 0% /proc/keys; tmpfs 64.0M 0 64.0M 0% /proc/timer_list; tmpfs 14.7G 0 14.7G 0% /proc/scsi; tmpfs 14.7G 0 14.7G 0% /sys/firmware; ```. Which isn't much larger than it was before the scaling tests. It appears to slowly increase the amount of memory it needs:; ```; 1 0 nobody S 30.9g103.7 1 11.5 /bin/prometheus --config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/prometheus --web.console.libraries=/usr/share/prometheus/console_libraries --web.console.templates=/usr/share/prometheus/consoles --web.external; ```. caping out at 31.5 GB (the disk is 31.2 GB). Now, it is presumably trying to recover. It's been up for about 7 minutes. Still unavailable:; ```; /prometheus $ wget localhost:9090/monitoring/prometheus; Connecti",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6773:382,down,down,382,https://hail.is,https://github.com/hail-is/hail/issues/6773,2,"['Avail', 'down']","['Available', 'down']"
Availability,"A revival of #12122, which was reverted because the web-based code path had an error. The last commit here fixes that bug and I tested that the web path works through a dev deploy.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12177:79,error,error,79,https://hail.is,https://github.com/hail-is/hail/pull/12177,1,['error'],['error']
Availability,"A simple pipeline to generate fingerprinting data for gnomad v4 failed. . ```python3; import hail as hl; from gnomad_qc.v4.resources.basics import get_gnomad_v4_vds; hl.init(default_reference='GRCh38'); ; ht = hl.import_table(; ""gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.haplotype_database.txt"",; comment=(""@""),; ); ht = ht.key_by(locus=hl.locus(ht['#CHROMOSOME'], hl.int(ht['POSITION'])), alleles=hl.array([ht.MAJOR_ALLELE, ht.MINOR_ALLELE])); vds = get_gnomad_v4_vds(split=True, remove_hard_filtered_samples=False); vds = hl.vds.filter_variants(vds, ht); mt = hl.vds.to_dense_mt(vds); mt = mt.checkpoint(""gs://gnomad/v4.0/sample_qc/exomes/gnomad.exomes.v4.0.fingerprinting_variants.mt"", overwrite=True); ```. We were able to get it to succeed, but filtering the variant data first on locus, splitting it, filtering it on variants. Then proceeding. There may be an ugly interaction with joins and explode but it needs more investigation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11717:625,checkpoint,checkpoint,625,https://hail.is,https://github.com/hail-is/hail/issues/11717,1,['checkpoint'],['checkpoint']
Availability,"A test failed because `hailctl config unset` now returns an error if the config variable does not exist. Let me know if you think we should maintain the current behavior -- otherwise, I slightly modified the tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13224#issuecomment-1677602623:60,error,error,60,https://hail.is,https://github.com/hail-is/hail/pull/13224#issuecomment-1677602623,1,['error'],['error']
Availability,"A user reported this error `concurrent.futures._base.TimeoutError` with no stack trace while copying files in a batch job. There's a comment in `is_transient_error` that we should catch this error, but I did not see it caught in the existing function.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11817:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/pull/11817,2,['error'],['error']
Availability,"A user was getting an index out-of-bounds error on `cdf.values[idx]`. I can't reproduce it, but this should guarantee the index is in bounds, and is a simplification besides.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10624:42,error,error,42,https://hail.is,https://github.com/hail-is/hail/pull/10624,1,['error'],['error']
Availability,"A very small PR but here's the background and context behind this change. When talking to either GCP or Azure, hail chooses credentials in the following order from highest priority to lowest priority:. 1. An explicit `credential_file` argument passed to the relevant credentials class; 2. An environment variable containing the path to the credentials (`GOOGLE_APPLICATION_CREDENTIALS` or `AZURE_APPLICATION_CREDENTIALS`) (from this you can see why the code that was here is totally redundant); 3. The latent credentials present on the machine. This might be `gcloud` or `az` credentials, or the metadata server if you're on a cloud VM. I'm trying to rid the codebase of most explicit providing of credentials file paths, for two reasons:; - Quality of life. I'm already signed into the cloud with `gcloud` and `az`. I shouldn't need to download some file and provide `AZURE_APPLICATION_CREDENTIALS` to run this test. It should just use the latent credentials.; - We are trying to phase out credentials files altogether for security reasons. These files are long-lived secrets that you really don't want to leak and are currently exposed to users in Batch jobs, so they can be easily exfiltrated. Using the latent credentials on a cloud VM (the metadata server) has the benefit of only issuing short-lived access tokens which last for hours not months, so it's basically always better to use the latent credentials when possible.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13981:483,redundant,redundant,483,https://hail.is,https://github.com/hail-is/hail/pull/13981,2,"['down', 'redundant']","['download', 'redundant']"
Availability,"A/pylint/issues/5998"">#5998</a></p>; </li>; <li>; <p>Fix false positive for 'nonexistent-operator' when repeated '-' are; separated (e.g. by parens).</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5769"">#5769</a></p>; </li>; </ul>; <h1>What's New in Pylint 2.13.2?</h1>; <p>Release date: 2022-03-27</p>; <ul>; <li>; <p>Fix crash when subclassing a <code>namedtuple</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5982"">#5982</a></p>; </li>; <li>; <p>Fix false positive for <code>superfluous-parens</code> for patterns like; &quot;return (a or b) in iterable&quot;.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5803"">#5803</a></p>; </li>; <li>; <p>Fix a false negative regression in 2.13.0 where <code>protected-access</code> was not; raised on functions.</p>; <p>Fixes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5989"">#5989</a></p>; </li>; <li>; <p>Better error messages in case of crash if pylint can't write the issue template.</p>; <p>Refer to <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5987"">#5987</a></p>; </li>; </ul>; <h1>What's New in Pylint 2.13.1?</h1>; <p>Release date: 2022-03-26</p>; <ul>; <li>; <p>Fix a regression in 2.13.0 where <code>used-before-assignment</code> was emitted for; the usage of a nonlocal in a try block.</p>; <p>Fixes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5965"">#5965</a></p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pylint/commit/7591ac04dcefc527c42fd7713c909d1319e83fab""><code>7591ac0</code></a> Bump pylint to 2.13.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/a880bd6d85d2487f509d1505b5146d608b15d870""><code>a880bd6</code></a> Change 'nonexistent-operator' to allow repeated unary ops (with space or",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11702:1666,error,error,1666,https://hail.is,https://github.com/hail-is/hail/pull/11702,1,['error'],['error']
Availability,"AFAICT, labels are free. Without this, I cannot narrow the cost of, say, a Local SSD, down to one instance. https://cloud.google.com/resource-manager. Also, just, generally, I need to be able to know to which namespace a disk belongs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13053:86,down,down,86,https://hail.is,https://github.com/hail-is/hail/pull/13053,1,['down'],['down']
Availability,"AFAIK, everything has been addressed. Are you referring to [this](https://github.com/hail-is/hail/pull/7875#discussion_r367430472)? Now we user `insert` and catch the duplicate key error instead of the previous `select ... for update` followed by an `insert`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7875#issuecomment-575750888:181,error,error,181,https://hail.is,https://github.com/hail-is/hail/pull/7875#issuecomment-575750888,1,['error'],['error']
Availability,"AFAIK, the ClientResponseError only contains information from the original request or the headers. The RequestInfo contains information from our request to Google, like the URL. You're right, incorporating this into is_transient_error is a bit complex. We need to somehow communicate the body, if any, to is_transient_error. I started to go down this route with httpx.py. I wanted to wrap ClientSession with a new HailClientSession whose `get`, `post` etc. methods would check for non-successful statuses themselves, read the body, and raise HailHTTPException which included the status code *and the body*. Then in is_transient_error we can look for HailHTTPException and use the body to determine if we should retry. For now, we can just fix the compute client.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10432#issuecomment-840652602:341,down,down,341,https://hail.is,https://github.com/hail-is/hail/pull/10432#issuecomment-840652602,1,['down'],['down']
Availability,"AFAIK, the `retryTransientErrors` in `createNoCompression` would only retry any errors in creating the `ReadChannel`, but we still want to retry transient errors when calling read later down the line.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11832:80,error,errors,80,https://hail.is,https://github.com/hail-is/hail/pull/11832,3,"['down', 'error']","['down', 'errors']"
Availability,AIL_PIP_VERSION=0.2.128 \; HAIL_VERSION=0.2.128-91d328e7fc84 \; GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a \; REMOTE=origin \; WHEEL=build/deploy/dist/hail-0.2.128-py3-none-any.whl \; GITHUB_OAUTH_HEADER_FILE=abc123 \; HAIL_GENETICS_HAIL_IMAGE=abc123 \; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=a \; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=b \; HAIL_GENETICS_HAILTOP_IMAGE=c \; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=d \; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=e \; WHEEL_FOR_AZURE=f \; WEBSITE_TAR=g \; bash scripts/release.sh; +++ dirname -- scripts/release.sh; ++ cd -- scripts; ++ pwd; + SCRIPT_DIR=/Users/dking/projects/hail/hail/scripts; + arguments='HAIL_PIP_VERSION HAIL_VERSION GIT_VERSION REMOTE WHEEL GITHUB_OAUTH_HEADER_FILE HAIL_GENETICS_HAIL_IMAGE HAIL_GENETICS_HAIL_IMAGE_PY_3_10 HAIL_GENETICS_HAIL_IMAGE_PY_3_11 HAIL_GENETICS_HAILTOP_IMAGE HAIL_GENETICS_VEP_GRCH37_85_IMAGE HAIL_GENETICS_VEP_GRCH38_95_IMAGE WHEEL_FOR_AZURE WEBSITE_TAR'; + for varname in '$arguments'; + '[' -z 0.2.128 ']'; + echo HAIL_PIP_VERSION=0.2.128; HAIL_PIP_VERSION=0.2.128; + for varname in '$arguments'; + '[' -z 0.2.128-91d328e7fc84 ']'; + echo HAIL_VERSION=0.2.128-91d328e7fc84; HAIL_VERSION=0.2.128-91d328e7fc84; + for varname in '$arguments'; + '[' -z 91d328e7fc84686936ffd4f370c8c104b2d78b2a ']'; + echo GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a; GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a; + for varname in '$arguments'; + '[' -z origin ']'; + echo REMOTE=origin; REMOTE=origin; + for varname in '$arguments'; + '[' -z build/deploy/dist/hail-0.2.128-py3-none-any.whl ']'; + echo WHEEL=build/deploy/dist/hail-0.2.128-py3-none-any.whl; WHEEL=build/deploy/dist/hail-0.2.128-py3-none-any.whl; + for varname in '$arguments'; + '[' -z abc123 ']'; + echo GITHUB_OAUTH_HEADER_FILE=abc123; GITHUB_OAUTH_HEADER_FILE=abc123; + for varname in '$arguments'; + '[' -z abc123 ']'; + echo HAIL_GENETICS_HAIL_IMAGE=abc123; HAIL_GENETICS_HAIL_IMAGE=abc123; + for varname in '$arguments'; + '[' -z a ']'; + echo HAI,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:11442,echo,echo,11442,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['echo'],['echo']
Availability,"ALLED,Number=1,Type=Integer,Description=""1 for variants that were called after phasing via splitting the bam into its component haplotypes and calling variants in haploid mode"">; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">; ##FORMAT=<ID=BX,Number=.,Type=String,Description=""Barcodes and Associated Qual-Scores Supporting Alleles"">; ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""ID of Phase Set for Variant"">; ##FORMAT=<ID=PQ,Number=1,Type=Integer,Description=""Phred QV indicating probability at this variant is incorrectly phased"">; ##FORMAT=<ID=JQ,Number=1,Type=Integer,Description=""Phred QV indicating probability of a phasing switch error in gap prior to this variant"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FILTER=<ID=UNSUPPORTED_GENOTYPE,Description=""If genotype field contains '.' we assume that this is due to making a single sample vcf from a multiple sample vcf in which this sample does not contain the variant."">; ##FILTER=<ID=10X_RESCUED_MOLECULE_HIGH_DIVERSITY,Description=""Set if true: (((RESCUED+NOT_RESCUED) > 0 & RESCUED/(RESCUED+NOT_RESCUED) > 0.1) & (MMD == -1 | MMD >= 3.0))"">; ##FILTER=<ID=10X_QUAL_FILTER,Description=""Set if true: (%QUAL <= 15 || (AF[0] > 0.5 && %QUAL < 50))"">; ##FILTER=<ID=10X_ALLELE_FRACTION_FILTER,Description=""Set if true: (AO[0] < 2 || AO[0]/(AO[0] + RO) < 0.15)"">; ##FILTER=<ID=10X_PHASING_INCONSISTENT,Description=""Uses haplotype information from the fragments and the alleles to filter some variants that are not consistent with phasing."">; ##FILTER=<ID=10X_H",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:12086,error,error,12086,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['error'],['error']
Availability,"ARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:2240,Error,Error,2240,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071,1,['Error'],['Error']
Availability,"ARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spark-defaults; ConfigurationProperties:; spark.jars: /opt/hail/backend/hail-all-spark.jar; spark.driver.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:2735,avail,available,2735,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949,1,['avail'],['available']
Availability,Abstract properties need to be declared [this way](https://stackoverflow.com/questions/2736255/abstract-attributes-in-python) to be enforceable. If I delete `self.billing_manager` in one of the driver subclasses it still typechecks but would error at runtime. I also deleted the `create` method on the `CloudDriver` interface because it is never really used as an interface method (we only ever explicitly use the method from the concrete classes). As such it doesn't really enforce a contract and can be a little restrictive (in terra there is no sensible `credentials_file` input to such a method to create a terra driver.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13186:242,error,error,242,https://hail.is,https://github.com/hail-is/hail/pull/13186,1,['error'],['error']
Availability,"AbstractUnsafe$7.run(AbstractChannel.java:691); at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:367); at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:671); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:456); at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144); at java.lang.Thread.run(Thread.java:745); 2019-01-22 13:12:06 SparkContext: INFO: Successfully stopped SparkContext; 2019-01-22 13:12:06 NettyRpcEnv: WARN: Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@115b6ba4 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@3f21bf73[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]; 2019-01-22 13:12:06 YarnSchedulerBackend$YarnSchedulerEndpoint: ERROR: Error requesting driver to remove executor 14 after disconnection.; org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.; at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:155); at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:132); at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:228); at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:515); at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:63); at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint$$anonfun$org$apache$spark$scheduler$cluster$YarnSchedulerBackend$$handleExecutorDisconnectedFromDriver$2.apply(YarnSchedulerBackend.scala:253); at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint$$anonfun$org$apache$spark$scheduler$cluster$YarnSchedulerBackend$$handleExecutorDisconnectedFromDriver$2.apply(YarnSch",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:214246,ERROR,ERROR,214246,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,"According to @johnc1231 in https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/Troubles.20getting.20started.20(Python.203.2E8):. > It's intentionally limited to 3.7 because of precisely that error; >; > John Compitello: This is because of our dependence on spark 2. Spark 3 won't have that restriction, we are in the process of upgrading, hopefully should be fixed next week. I'll close this and wait for the release with Spark 3.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10197#issuecomment-800706947:215,error,error,215,https://hail.is,https://github.com/hail-is/hail/issues/10197#issuecomment-800706947,1,['error'],['error']
Availability,"According to the makefile documentation https://www.gnu.org/software/make/manual/html_node/Splitting-Recipe-Lines.html:; ```; Notice how the backslash/newline pair was removed inside the string quoted with double quotes (""""), ; but not from the string quoted with single quotes (''). This is the way the default shell (/bin/sh) ; handles backslash/newline pairs. If you specify a different shell in your makefiles it may treat them differently.; ```. Seems you (or `brew`) may have configured `make` to use something other than `/bin/sh`.; Quick way to verify:. ```Makefile; .PHONY: print-shell; print-shell:; 	@echo $(SHELL); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14138#issuecomment-1890075303:614,echo,echo,614,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1890075303,1,['echo'],['echo']
Availability,"Actually I get a different error when doing a small reproducible example, but looks related:. ```; ht = hl.utils.range_table(10).annotate_globals(test='yay'); ht2 = hl.utils.range_table(10).annotate_globals(test='yay'); ht.join(ht2).show(); ```; gives:; ```; Hail version: devel-c2508f35dc41; Error summary: HailException: optimization changed type!; before: Table{global:Struct{test:String,test_1:String},key:[idx],row:Struct{idx:Int32}}; after: Table{global:Struct{test:String},key:[idx],row:Struct{idx:Int32}}; Before IR:; ----------; (TableHead 11; (TableJoin inner 1; (TableMapGlobals; (TableRange 10 8); (InsertFields; (Ref Struct{} global); (test; (Str ""yay"")))); (TableMapGlobals; (TableRange 10 8); (InsertFields; (Ref Struct{} global); (test; (Str ""yay"")))))); After IR:; ---------; (TableHead 11; (TableJoin inner 1; (TableMapGlobals; (TableRange 10 8); (InsertFields; (Ref Struct{} global); (test; (Str ""yay"")))); (TableMapGlobals; (TableRange 10 8); (InsertFields; (Ref Struct{} global))))); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4311#issuecomment-420251986:27,error,error,27,https://hail.is,https://github.com/hail-is/hail/issues/4311#issuecomment-420251986,2,"['Error', 'error']","['Error', 'error']"
Availability,"Actually I just went ahead and looked at this PR to make sure highcpus were indeed highcpus. They are!; <img width=""1476"" alt=""Screen Shot 2021-12-09 at 11 56 56 AM"" src=""https://user-images.githubusercontent.com/106194/145441305-fec38573-9c66-4a95-9fb7-0e6dc3a7c2e9.png"">. I also grabbed all the VM details and all the things that should be different (vm name, Nic name, etc.) are different. The userData is myseriously null, but its null for every VM in Azure currently (other PRs, namespaces, and default). ```; {; ""additionalCapabilities"": null,; ""applicationProfile"": null,; ""availabilitySet"": null,; ""billingProfile"": {; ""maxPrice"": -1.0; },; ""capacityReservation"": null,; ""diagnosticsProfile"": null,; ""evictionPolicy"": ""Delete"",; ""extendedLocation"": null,; ""extensionsTimeBudget"": null,; ""hardwareProfile"": {; ""vmSize"": ""Standard_F16s_v2"",; ""vmSizeProperties"": null; },; ""host"": null,; ""hostGroup"": null,; ""id"": ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.Compute/virtualMachines/batch-worker-pr-11144-default-nbthv8fduvd6-highcpu-robv5"",; ""identity"": {; ""principalId"": null,; ""tenantId"": null,; ""type"": ""UserAssigned"",; ""userAssignedIdentities"": {; ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.ManagedIdentity/userAssignedIdentities/batch-worker"": {; ""clientId"": ""890af904-42f1-4136-810a-c52f4e132c6b"",; ""principalId"": ""b952a3bb-1091-4f11-803b-9d5199219a27""; }; }; },; ""instanceView"": null,; ""licenseType"": null,; ""location"": ""eastus"",; ""name"": ""batch-worker-pr-11144-default-nbthv8fduvd6-highcpu-robv5"",; ""networkProfile"": {; ""networkApiVersion"": null,; ""networkInterfaceConfigurations"": null,; ""networkInterfaces"": [; {; ""deleteOption"": ""Delete"",; ""id"": ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.Network/networkInterfaces/batch-worker-pr-11144-default-nbthv8fduvd6-highcpu-robv5-nic"",; ""primary"": null,; ""resourceGroup"": ""dgoldste""",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11144#issuecomment-990039686:581,avail,availabilitySet,581,https://hail.is,https://github.com/hail-is/hail/pull/11144#issuecomment-990039686,1,['avail'],['availabilitySet']
Availability,Actually looks like just a bad error message. One of the Tables had 0 rows.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4216#issuecomment-416051659:31,error,error,31,https://hail.is,https://github.com/hail-is/hail/issues/4216#issuecomment-416051659,1,['error'],['error']
Availability,"Actually the endpoint does seem to be an issue. https://internal.hail.is/pr-7381-default-sx9ail9zkm77/blog/ works great. edit: Endpoint is / (`+ python3 wait-for.py 60 pr-7381-default-sx9ail9zkm77 Service -p 80 blog --endpoint /`), when I think it should be /blog? We could try setting the endpoint to /blog/ or /default/blog/. The failure also has a line about not being able to connect to hostname blog.pr-7381-default-sx9ail9zkm77. I don't know enough about CI to determine whether this is a problem, but my guess is that is normal. edit2: The wait command's port is 80, not 443. Do we need to force X-Forward-Proto to https to fix it? Although if this is going through gateway, I think the protocol should be https after the redirect from 80/http. edit3: Actually, wait-for.py allows a port to be set, so it seems appropriate to set `port: 443` in the wait command. edit4: Nevermind, 443 will not set protocol to https. It shouldn't matter, I don't think, as long as gateway is redirecting to https, but you could try setting X-Forwarded-Proto to https. I suspect the issue is in the url or domain.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7381#issuecomment-548089835:332,failure,failure,332,https://hail.is,https://github.com/hail-is/hail/pull/7381#issuecomment-548089835,1,['failure'],['failure']
Availability,"Actually, comparing singular vectors is not a robust test, even accounting for sign. Suppose `A` has two equal (or nearly equal) singular values. Then there is a 2-dimensional subspace of vectors, all of which are equally good singular vectors for that singular value. If the singular values are sufficiently separated, then comparing singular vectors should be safe, but I don't think it's necessary; the other checks should force that. I think we only need to check (all approximate comparisons),; * we got the right singular values, by comparing with numpy (unless we constructed a test matrix with known singular values); * the singular vectors are orthonormal (i.e. `Ut U = Id` and `Vt V = Id`); * the factorization `A = U Sigma Vt`. Then it follows that for each right singular vector `V_i`, `A v_i = sigma_i u_i` holds approximately, so `v_i` is a good singular vector, i.e. it really does capture `sigma_i` variance, and we checked that `sigma_i` is close to the true singular value.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9727#issuecomment-730626936:46,robust,robust,46,https://hail.is,https://github.com/hail-is/hail/pull/9727#issuecomment-730626936,1,['robust'],['robust']
Availability,"Actually, even simpler: . ```; def downsample_matrix_table(mt: hl.MatrixTable, n_divisions: int, p_threshold: float) -> hl.Table:; mt = mt.choose_cols(list(range(10))). x = mt.locus.global_position(); y = -hl.log10(mt.Pvalue). downsampled = mt.annotate_cols(; binned=hl.agg.downsample(; x,; y,; label=hl.str(mt.Pvalue),; n_divisions=n_divisions; ); ; ); downsampled = downsampled.cols(). return downsampled. mt = hl.balding_nichols_model(3, 100, 1000); pmt = mt.annotate_rows(Pvalue = hl.rand_unif(0, 1)); downed = downsample_matrix_table(pmt, 4, .05); downed.show(); ```. I'm now somewhat convinced that the downsample aggregator is accessing cleared memory",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8240#issuecomment-594754052:227,down,downsampled,227,https://hail.is,https://github.com/hail-is/hail/issues/8240#issuecomment-594754052,8,['down'],"['downed', 'downsample', 'downsampled']"
Availability,"Actually, maybe this code just suppresses the error. I was hoping there would be a missing error to retry in `retry_transient_errors`, but all the downloads succeeded.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10534#issuecomment-853101143:46,error,error,46,https://hail.is,https://github.com/hail-is/hail/pull/10534#issuecomment-853101143,3,"['down', 'error']","['downloads', 'error']"
Availability,"Add 2 new tutorials, document distributions as preferred way to run locally, small fixes to error messages and printouts",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1900:92,error,error,92,https://hail.is,https://github.com/hail-is/hail/pull/1900,1,['error'],['error']
Availability,Add Error Handling Improvements,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1739:4,Error,Error,4,https://hail.is,https://github.com/hail-is/hail/pull/1739,1,['Error'],['Error']
Availability,"Add a `keepRatio` parameter to the ApproxCDF aggregator. When compacting any level, always keep a fixed fraction of the smallest and largest values at that level. Also keep counts of the number of times each level is compacted, for use in downstream error estimates.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6076:239,down,downstream,239,https://hail.is,https://github.com/hail-is/hail/pull/6076,2,"['down', 'error']","['downstream', 'error']"
Availability,Add a link to downloadable archive of tutorials to docs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6520:14,down,downloadable,14,https://hail.is,https://github.com/hail-is/hail/issues/6520,1,['down'],['downloadable']
Availability,Add an a postiori error estimate for the approximate cdf aggregator. Use in new pdf plotting method than makes no assumption about the smoothness of the true distribution.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6039:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/6039,1,['error'],['error']
Availability,Add better error message for call_stats error mode,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4380:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/pull/4380,2,['error'],['error']
Availability,Add better sparse split multi error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6877:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/pull/6877,1,['error'],['error']
Availability,Add error message to genotype check assertions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1744:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/1744,1,['error'],['error']
Availability,Add error on matrixtable iter,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3044:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/pull/3044,1,['error'],['error']
Availability,Add error output to VEP exceptions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5224:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/pull/5224,1,['error'],['error']
Availability,"Add errorId tracking to MakeNDArray, allowing user to get a good python error highlighting where an error is thrown from.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10095:4,error,errorId,4,https://hail.is,https://github.com/hail-is/hail/pull/10095,3,['error'],"['error', 'errorId']"
Availability,Add expr support and nicer error messages to key_by functions.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2916:27,error,error,27,https://hail.is,https://github.com/hail-is/hail/pull/2916,1,['error'],['error']
Availability,Add mendel error counts to variant and sample qc.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/148:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/issues/148,1,['error'],['error']
Availability,Add more examples to the Expression.__nonzero__ error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2764:48,error,error,48,https://hail.is,https://github.com/hail-is/hail/issues/2764,1,['error'],['error']
Availability,Add retry infrastructure mirroring Python. This will hopefully fix the deploy issue. I think we'll have to grow another set of transient errors to retry related to lower-level networking issues.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8802:137,error,errors,137,https://hail.is,https://github.com/hail-is/hail/pull/8802,1,['error'],['errors']
Availability,Add selection to PCA to push down optimization,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3888:29,down,down,29,https://hail.is,https://github.com/hail-is/hail/pull/3888,1,['down'],['down']
Availability,Add support for container checkpoint/restore,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11888:26,checkpoint,checkpoint,26,https://hail.is,https://github.com/hail-is/hail/pull/11888,1,['checkpoint'],['checkpoint']
Availability,"Add the `filter` and `find_replace` arguments to `import_table` and `import_vcf`. These are regex filter and substitution arguments, which will make it possible to tolerate some invalid inputs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5300:164,toler,tolerate,164,https://hail.is,https://github.com/hail-is/hail/pull/5300,1,['toler'],['tolerate']
Availability,Add the nice errors to struct / struct expression,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2797:13,error,errors,13,https://hail.is,https://github.com/hail-is/hail/issues/2797,1,['error'],['errors']
Availability,"Added a region argument, and mandated that users have either configured a region or are using `--region`. I believe older versions of gcloud assume the region is the default region for your project if you don't have anything specified, which causes users to have random errors when they update gcloud that they ask about on Zulip. This way, everyone gets a good error message",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8281#issuecomment-597307671:270,error,errors,270,https://hail.is,https://github.com/hail-is/hail/pull/8281#issuecomment-597307671,2,['error'],"['error', 'errors']"
Availability,"Added batch2_check step in build, fixed lint errors.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7208:45,error,errors,45,https://hail.is,https://github.com/hail-is/hail/pull/7208,1,['error'],['errors']
Availability,Added error message if keyspace or table don't exist in Cassandra,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/680:6,error,error,6,https://hail.is,https://github.com/hail-is/hail/pull/680,1,['error'],['error']
Availability,Added logging line for ci error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6685:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/6685,1,['error'],['error']
Availability,Added nd array map2 to correspond to existing scala nd array map2 ir. Also used map2 to facilitate writing user facing features hl.nd.maximum and hl.nd.minimum which echo np.maximum and np.minimum.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10635:166,echo,echo,166,https://hail.is,https://github.com/hail-is/hail/pull/10635,1,['echo'],['echo']
Availability,"Added some stuff, since `stop` didn't actually work on `LocalBackend` since we weren't shutting down the java gateway",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11669#issuecomment-1079149099:96,down,down,96,https://hail.is,https://github.com/hail-is/hail/pull/11669#issuecomment-1079149099,1,['down'],['down']
Availability,"Added stats.LeveneHaldane and tests. Created doc folder, LeveneHaldane.tex, and bibfile.bib; Added docs/.gitignore. Added HWEPerVariant, test/resources/HWE_test.vcf and tests. Added Utils.time, now replaced by Utils.printTime. Used Option in ""r*"" (ratio) methods for missing values, now abstracted with Utils.divOption and Utils.someIf. Added rounding-error-tolerant comparison operators Utils.D_\* and used where appropriate. replaced closeEnough with D_==",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/73:352,error,error-tolerant,352,https://hail.is,https://github.com/hail-is/hail/pull/73,1,['error'],['error-tolerant']
Availability,"Adding ""WIP"" tag since I had a test failure from `make test-dataproc`. Seems like I have a mix of reference genomes somewhere.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8268#issuecomment-596564071:36,failure,failure,36,https://hail.is,https://github.com/hail-is/hail/pull/8268#issuecomment-596564071,1,['failure'],['failure']
Availability,"Adding a simple reproducible example. ```python; ht = hl.Table.from_pandas(pd.DataFrame({""variant"":['chr1:123:C:T']})); ht = ht.key_by(**hl.parse_variant(ht.variant)); pd_table = ht.to_pandas(); pd_table.to_pickle(os.path.join(bucket, 'test.pkl')); ```. The two examples below do not cause the same error. ; ```python; ht = hl.Table.from_pandas(pd.DataFrame({""foo"":['bar']})); ht = hl.Table.from_pandas(pd.DataFrame({""foo"":[1, 2, 3]})); ```. Hope this helps.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14004#issuecomment-1808416604:299,error,error,299,https://hail.is,https://github.com/hail-is/hail/issues/14004#issuecomment-1808416604,1,['error'],['error']
Availability,Adding checkpointing as a quality of life improvement for block matrices.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6933:7,checkpoint,checkpointing,7,https://hail.is,https://github.com/hail-is/hail/pull/6933,1,['checkpoint'],['checkpointing']
Availability,Adding support to nd arrays to include less than max dimension indexing and the use of ellipses to echo numpy behavior.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10551:99,echo,echo,99,https://hail.is,https://github.com/hail-is/hail/pull/10551,1,['echo'],['echo']
Availability,"Adding this signature appeases `pyright` in my editor. Unfortunately, `pylint` still [gets confused](https://github.com/pylint-dev/pylint/issues/259) so I disabled this particular check. I made sure that `mypy` still errors when forgetting to provide a required parameter to a function call.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13308:217,error,errors,217,https://hail.is,https://github.com/hail-is/hail/pull/13308,1,['error'],['errors']
Availability,Additional transient errors from GCS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14516:21,error,errors,21,https://hail.is,https://github.com/hail-is/hail/pull/14516,1,['error'],['errors']
Availability,Addressed comments (apart from question on tolerance),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2248#issuecomment-332370854:43,toler,tolerance,43,https://hail.is,https://github.com/hail-is/hail/pull/2248#issuecomment-332370854,1,['toler'],['tolerance']
Availability,Addressed comments. ; - Refactored to a separate module and added module-level tests. ; - Cleaned up TypeChecker interface to call recursively down,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1727#issuecomment-299293790:143,down,down,143,https://hail.is,https://github.com/hail-is/hail/pull/1727#issuecomment-299293790,1,['down'],['down']
Availability,Addressed comments. Rebooting IntelliJ didn't fix it. I added some extra braces and now it looks correct. Also included @danking's suggestion.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/885#issuecomment-251244777:20,Reboot,Rebooting,20,https://hail.is,https://github.com/hail-is/hail/pull/885#issuecomment-251244777,1,['Reboot'],['Rebooting']
Availability,"Addressed your initial problem and merge conflicts, but looks like there's more that's going wrong. Seems like it's mostly data comparison failures with reasonableish looking data, probably a striding issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9960#issuecomment-771116898:139,failure,failures,139,https://hail.is,https://github.com/hail-is/hail/pull/9960#issuecomment-771116898,1,['failure'],['failures']
Availability,"Addresses #1943 . [JVM Spec, Chapter 6](https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-6.html) states, regarding, DCMPGand DCMPL:; > NaN is unordered, so any double comparison fails if either or both of its operands are NaN. With both dcmpg and dcmpl available, any double comparison may be compiled to push the same result onto the operand stack whether the comparison fails on non-NaN values or fails because it encountered a NaN. For more information, see [3.5](https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-3.html#jvms-3.5). The `G` and `L` suffices refer to whether the presence of one or more `NaN`s should be indicated by returning ""greater than"" or ""less than"". Ergo, when we're checking `x > y` we use `DCMPL` so the NaN case produces `-1` with which the downstream comparison to `0` produces `false`. Confusingly, the simple intuition is, if you're checking **L**ess Than, you should use the **G** version. If you're checking **G**reater Than, you should use the **L** version.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1952:261,avail,available,261,https://hail.is,https://github.com/hail-is/hail/pull/1952,2,"['avail', 'down']","['available', 'downstream']"
Availability,"Addresses this error:; ```; ERROR | 2019-06-17 09:41:59,615 | web_protocol.py | log_exception:355 | Error handling request; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py"", line 418, in start; resp = await task; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 458, in _handle; resp = await handler(request); File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_urldispatcher.py"", line 157, in handler_wrapper; result = await result; File ""/usr/local/lib/python3.6/dist-packages/batch/server/server.py"", line 849, in create_batch; await create_job(batch.id, userdata, job_params); File ""/usr/local/lib/python3.6/dist-packages/batch/server/server.py"", line 628, in create_job; pvc_size=pvc_size); File ""/usr/local/lib/python3.6/dist-packages/batch/server/server.py"", line 398, in create_job; await job._create_pod(); File ""/usr/local/lib/python3.6/dist-packages/batch/server/server.py"", line 190, in _create_pod; self._pvc_name = await self._create_pvc(); File ""/usr/local/lib/python3.6/dist-packages/batch/server/server.py"", line 165, in _create_pvc; await self.mark_complete(None, failed=True, failure_reason=str(err)); File ""/usr/local/lib/python3.6/dist-packages/batch/server/server.py"", line 526, in mark_complete; await self._mark_job_task_complete(task_name, pod_log, exit_code); File ""/usr/local/lib/python3.6/dist-packages/batch/server/server.py"", line 288, in _mark_job_task_complete; assert self._pod_name is not None; AssertionError; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6367:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/6367,3,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,Addresses this transient error I just encountered.; ```; + docker push gcr.io/hail-vdc/ci-intermediate:tn05m3kr79i2; The push refers to repository [gcr.io/hail-vdc/ci-intermediate]; Get https://gcr.io/v2/: dial tcp: lookup gcr.io: Temporary failure in name resolution; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8112:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/8112,2,"['error', 'failure']","['error', 'failure']"
Availability,Addresses user confusion in https://discuss.hail.is/t/potential-outdated-error-statement-for-hail-version-incompatibility/3562.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13494:73,error,error-statement-for-hail-version-incompatibility,73,https://hail.is,https://github.com/hail-is/hail/pull/13494,1,['error'],['error-statement-for-hail-version-incompatibility']
Availability,Adds [CADD](https://cadd.gs.washington.edu/download) v1.6 Hail Tables to datasets API/annotation DB.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10474:43,down,download,43,https://hail.is,https://github.com/hail-is/hail/pull/10474,1,['down'],['download']
Availability,"Adds `copy_spark_log_on_error` init configuration option. When true, driver logs are copied to the remote tmpdir if an error occurs. This is useful in support cases where users cannot copy logs off the dataproc server themselves as it has already shut down.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14447:119,error,error,119,https://hail.is,https://github.com/hail-is/hail/pull/14447,2,"['down', 'error']","['down', 'error']"
Availability,"Adds `writekudu` and `readkudu` commands for storing a VariantSampleMatrix in Kudu. Note that only biallelic variants can be stored at the moment, so `splitmulti` should be used. Sample run. ```; SPARK_MASTER=yarn-client; # chr1 in 6m52.6s; spark-submit \; --master $SPARK_MASTER \; --driver-memory 3G \; --num-executors 14 \; --executor-cores 1 \; --executor-memory 3G \; --conf spark.io.compression.codec=lzf \; --conf spark.yarn.executor.memoryOverhead=600 \; build/libs/hail-all-spark.jar \; importvcf -f vcf-1000genomes/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf splitmulti writekudu -o file:///home/tom/sample.vds -t variants -m bottou06.sjc.cloudera.com --drop; # read (2 min or so); spark-submit \; --master $SPARK_MASTER \; --driver-memory 3G \; --num-executors 14 \; --executor-cores 1 \; --executor-memory 3G \; --conf spark.io.compression.codec=lzf \; --conf spark.yarn.executor.memoryOverhead=600 \; build/libs/hail-all-spark.jar \; readkudu -i file:///home/tom/sample.vds -t variants -m bottou06.sjc.cloudera.com count ; ```. To install Kudu on a cluster, see http://www.cloudera.com/documentation/betas/kudu/0-5-0/topics/kudu_installation.html#concept_u4s_tbq_dt_unique_1, and follow the instructions for installing from parcels. The CDS file is available at http://archive.cloudera.com/beta/kudu/csd/. You can also run Kudu locally using a VM, see http://getkudu.io/docs/quickstart.html. This is suitable for running unit tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/242:1289,avail,available,1289,https://hail.is,https://github.com/hail-is/hail/pull/242,1,['avail'],['available']
Availability,"Adds a MatrixTable for all variant-gene cis-eQTL associations tested in each tissue (including non-significant associations) for GTEx v8. MatrixTable has columns keyed by tissue, and contain all available tissues from GTEx V8. The `GTEx_MatrixTables` notebook documents how the MatrixTable were generated. . The eQTL MatrixTable is ~220 GiB.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10535:195,avail,available,195,https://hail.is,https://github.com/hail-is/hail/pull/10535,1,['avail'],['available']
Availability,Adds a `pre-commit` linting rule to run on our html files that is jinja-aware. The ~ resilience ~ of html continues to astound me.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10031:85,resilien,resilience,85,https://hail.is,https://github.com/hail-is/hail/pull/10031,1,['resilien'],['resilience']
Availability,Adds optimization available in lowering process if number of rows per partition from child TableIR is known,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10798:18,avail,available,18,https://hail.is,https://github.com/hail-is/hail/pull/10798,1,['avail'],['available']
Availability,"Adds retry for specific 500 errors:. ```; aiodocker.exceptions.DockerError: DockerError(500, 'error creating overlay mount to /var/lib/docker/overlay2/545a1337742e0292d9ed197b06fe900146c85ab06e468843cd0461c3f34df50d/merged: device or resource busy'; ```. ```; aiodocker.exceptions.DockerError: DockerError(500, 'Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7715:28,error,errors,28,https://hail.is,https://github.com/hail-is/hail/pull/7715,2,['error'],"['error', 'errors']"
Availability,"Adds the available [GIANT 2018 Exome Array Summary Statistics](https://portals.broadinstitute.org/collaboration/giant/index.php/GIANT_consortium_data_files#2018_Exome_Array_Summary_Statistics) datasets for WHR, BMI, and height as Hail Tables. For reproducibility, I added the notebook I used to generate the tables and schemas. The datasets were small in this case, and I ended up doing things locally on my machine. It didn't seem to make sense to try to redo things to fit into the older extract/load workflow once everything had already been generated.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10235:9,avail,available,9,https://hail.is,https://github.com/hail-is/hail/pull/10235,1,['avail'],['available']
Availability,"After I set-up my spark context on my spark cluster, I ran hail.init() and ran into the following: ; `py4j.protocol.Py4JError: An error occurred while calling z:is.hail.HailContext.apply. Trace:; py4j.Py4JException: Method apply([null, class java.lang.String, class scala.None$, class java.lang.String, class java.lang.String, class java.lang.Boolean, class java.lang.Boolean, class java.lang.Integer, class java.lang.Integer, class java.lang.String, class java.lang.Integer]) does not exist`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8423:130,error,error,130,https://hail.is,https://github.com/hail-is/hail/issues/8423,1,['error'],['error']
Availability,After a clean `make shadowJar` takes 2m33s on my laptop now. I just downloaded the latest Gradle from home-brew and ran `gradle wrapper` in the hail directory.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10245:68,down,downloaded,68,https://hail.is,https://github.com/hail-is/hail/pull/10245,1,['down'],['downloaded']
Availability,"After its singular additional dependency got shoved down into `hailtop`, auth no longer needs anything beyond the `hailtop/gear/web_common dependencies`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13655:52,down,down,52,https://hail.is,https://github.com/hail-is/hail/pull/13655,1,['down'],['down']
Availability,"After spending a couple of hours reading about g++ ABI versions, I'm feeling much less; positive about the plan of building multiple libraries. It seems there are 11 different ABI versions; (most of them are minor bugfixes which were never default behavior for any version of g++,; but still ...). I'm mulling an alternative plan of saying ""well, you've got to have g++, c++, or clang++ somewhere; on your $PATH, or else you've got to define CXX, and also make, but I've got the C++ sources in the ; jarfile and I'll build you a fresh libboot.so and libhail.so if I haven't done it already"". That would involve a little bit more jarfile/Resource magic - but nothing any harder than I've already; done with the header files; avoid a big testing headache; and I hope get us past the whole; ""locking-down"" argument. And then at a later date I'll think about how to have the option of packaging; a recent clang so that we can get C++17 (and perhaps more consistent compile speed than g++); across a wide range on Linuxes. Accordingly I'll close this for now and re-open it when I have a working solution for the library issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-410111491:797,down,down,797,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410111491,1,['down'],['down']
Availability,"After the first commit, lots of unrelated type errors popped up from mypy. I think this is because I have the new mypy installed and it's actually catching more errors that were there all along. It might help to see the errors that it gave me (also visible in old CI builds of the PR:. ```; ci/github.py:508: error: Incompatible types in assignment (expression has type ""bool"", variable has type ""Optional[str]""); ci/github.py:551: error: Incompatible types in assignment (expression has type ""bool"", variable has type ""Optional[str]""); ci/github.py:554: error: Incompatible types in assignment (expression has type ""bool"", variable has type ""Optional[str]""); ci/github.py:574: error: Unsupported operand types for > (""int"" and ""None""); ci/github.py:574: note: Left operand is of type ""Optional[int]""; ci/github.py:575: error: Unsupported operand types for + (""None"" and ""int""); ci/github.py:575: note: Left operand is of type ""Optional[int]""; ci/github.py:817: error: Item ""None"" of ""Optional[Dict[str, PR]]"" has no attribute ""values""; ci/github.py:828: error: Item ""None"" of ""Optional[Dict[str, PR]]"" has no attribute ""values""; ci/github.py:840: error: Item ""None"" of ""Optional[Dict[str, PR]]"" has no attribute ""values""; ci/github.py:842: error: Item ""None"" of ""Optional[Dict[str, PR]]"" has no attribute ""values""; ci/github.py:849: error: Item ""MergeFailureBatch"" of ""Union[Batch, Any, MergeFailureBatch]"" has no attribute ""id""; ci/github.py:849: error: Item ""None"" of ""Optional[Dict[str, PR]]"" has no attribute ""values""; Found 11 errors in 1 file (checked 19 source files); ```. It might be helpful to look at the first commit and last commit in isolation. Or if you'd like I can make a separate PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11530#issuecomment-1062214775:47,error,errors,47,https://hail.is,https://github.com/hail-is/hail/pull/11530#issuecomment-1062214775,15,['error'],"['error', 'errors']"
Availability,"After this, there are only 150ish warnings remaining, which shouldn't be too hard to fix by hand. Most are unused locals. Scalafix can delete unused locals, but I disable that, because there were too many cases where it left the rhs unnecessarily, e.g.; ```; ...; val idx = Symbol(genUID()); ...; ```; rewrites to; ```; ...; Symbol(genUID()); ...; ```; I'd rather just leave those as errors to be fixed manually. This is intended to replace #14103, which ended up mixing manual changes to fix warnings with scalafix changes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14156:384,error,errors,384,https://hail.is,https://github.com/hail-is/hail/pull/14156,1,['error'],['errors']
Availability,"After updating from hail from v0.2.92 to v0.2.105 , I've started getting the ""Bucket is a requester pays bucket but no user project provided"" error (with further details in https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/hl.2Ehadoop_stat.20no.20longer.20works.20for.20requester.20pays.20bucket)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12540:142,error,error,142,https://hail.is,https://github.com/hail-is/hail/issues/12540,1,['error'],['error']
Availability,"Agh, the unsafeRow and UnsafeIndexedSeq optimizations must be wrong, getting out of bounds memory errors.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9892#issuecomment-770085173:98,error,errors,98,https://hail.is,https://github.com/hail-is/hail/pull/9892#issuecomment-770085173,1,['error'],['errors']
Availability,"Agh, this isn't good enough. It feels like the right thing might be to lift up the lets, optimize, then push down. This has the added benefit of making it trivial to collapse multiple identical let bindings.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5041#issuecomment-449743945:109,down,down,109,https://hail.is,https://github.com/hail-is/hail/pull/5041#issuecomment-449743945,1,['down'],['down']
Availability,Ah I didn't notice that the two loops were in different scripts (startup vs. run). If the run-script exits cleanly will the worker shut down?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10640#issuecomment-874953507:136,down,down,136,https://hail.is,https://github.com/hail-is/hail/pull/10640#issuecomment-874953507,1,['down'],['down']
Availability,"Ah I didn't see you had posted this a couple of days ago. I'm also getting this error on the pipeline below (which works on ~15K genomes, but not ~125K exomes):; ```; mt = mt.select_cols(group_membership=tuple(x[1] for x in sample_group_filters), project_id=mt.meta.project_id); mt = mt.select_rows(*mt.row_key); mt = mt.select_entries(n_alt=mt.GT.n_alt_alleles(), adj=mt.adj). frequency_expression = []; for i in range(len(sample_group_filters)):; subgroup_dict = sample_group_filters[i][0]; subgroup_dict['group'] = 'adj'. freq_expression = hl.struct(; ac=hl.agg.sum(hl.agg.filter(mt.group_membership[i] & mt.adj, mt.n_alt)),; an=2 * hl.agg.count_where(mt.group_membership[i] & mt.adj & hl.is_defined(mt.n_alt)),; hom=hl.agg.count_where(mt.group_membership[i] & mt.adj & (mt.n_alt == 2)),; meta=subgroup_dict; ); frequency_expression.append(freq_expression); freq_expression = hl.struct(; ac=hl.agg.sum(mt.n_alt),; an=2 * hl.agg.count_where(hl.is_defined(mt.n_alt)),; hom=hl.agg.count_where(mt.n_alt == 2),; meta={'group': 'raw'}; ); frequency_expression.insert(1, freq_expression). mt = mt.annotate_rows(freq=frequency_expression); mt.rows().write(); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508#issuecomment-386942393:80,error,error,80,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-386942393,1,['error'],['error']
Availability,"Ah ok. I was seeing some `kill -9` that are now gone when excluding the `current_task`. > It is problematic because somewhere else we're not properly stopping an infinite loop. Ideally we'll get to a place where we try to kill a pod and if it doesn't terminate in, say, 5 seconds, we fail the CI tests. Ya it might not deliver great clarity on where the error is coming from but at least we can actively kill and log an error if it's unable to do the ""right"" thing within say 5 seconds. That and I'm unsure how else to solve this problem",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9944#issuecomment-769239445:354,error,error,354,https://hail.is,https://github.com/hail-is/hail/pull/9944#issuecomment-769239445,2,['error'],['error']
Availability,"Ah sorry, I forgot to update the original commit message as that's not actually correct. The optimization is that we don't need to iterate through all blobs until we find the exact blob matching our path name. The list operation returns all blobs that start with the prefix of that path. If we see a blob with a different name that is a child of our path `f'{path}/foo`, then we know it's a directory and don't need to iterate anymore (although it could be a file as well, but in Scala we don't currently throw errors on paths that are both files and directories, so we just choose the first we see). If we see a blob that matches the path exactly, then we know it's a file and stop iterating. The only reason we need to iterate through more than one blob is if there's blobs that are like `'{path}zzzzz/foo` or `'{path}szzzzz`. We need to ignore these as they don't provide any information on whether `{path}` is a file or directory. This is where `isChildOf` is needed because we need to make sure the blob is actually a child of the path such as `'{path}/file` and not `{path}zzzzz/file`. As for `getValues` versus `iterateAll`, I just used the one that was in the Java documentation for using the `list` method.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13390#issuecomment-1673853274:511,error,errors,511,https://hail.is,https://github.com/hail-is/hail/pull/13390#issuecomment-1673853274,1,['error'],['errors']
Availability,"Ah the timings were slightly off as I had not downloaded all the data and was using some from `hail_search/fixtures`.; After pulling down the `SNV_INDELS` data, my updated timings are:. | query | results | elapsed |; | ----- | ------- | ------- |; | 0 | 4 | 7s |; | 1 | 83 | 50s |",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13882#issuecomment-1821595905:46,down,downloaded,46,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1821595905,2,['down'],"['down', 'downloaded']"
Availability,"Ah yeah good point I forgot about that. You have to construct a string to avoid truncation a la:; ```; (base) dking@wm28c-761 /tmp % cat foo.py; def test():; assert False, 'b' * 1000; =========================================== test session starts ============================================; (base) dking@wm28c-761 /tmp % pytest foo.py; platform darwin -- Python 3.10.9, pytest-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:751,FAILURE,FAILURES,751,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019,1,['FAILURE'],['FAILURES']
Availability,"Ah! Because creating a pod can fail with a non-recoverable error. Then I think it is:. Pending -> Ready -> Error, Created; Created -> Running; Running -> Error, Failed, Success. Question is, what causes Created -> Running?. If it is seeing the pod running, then when the pod gets deleted (e.g. preemption), you'll also need:; Running -> Ready. You might also need:; Running -> Created; if you update the pod state and it exists but isn't actually running yet. I'm not sure if that can happen, but seems safe. I would probably just have Running (= Created), and I wouldn't track if the pod is running or not (if we're trying to inform the user, let's just make the batch UI better, e.g. give more information about the pod ... aside: I have some awesome ideas for this)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6268#issuecomment-499339683:47,recover,recoverable,47,https://hail.is,https://github.com/hail-is/hail/pull/6268#issuecomment-499339683,4,"['Error', 'error', 'recover']","['Error', 'error', 'recoverable']"
Availability,"Ah, I misunderstood. So you can't ask pip-compile to accept as input a requirements.txt and a pinned-requirements.txt and output a new pinned-requirements.txt? That's what I was imagining. With the main effect being if we add something to requirements.txt without changing pinned-requirements.txt, we'd get an error. Having pip-compile constantly bump requirements in every PR seems not ideal. What I'm trying to achieve is that our pinned-requirements always represent *a* version-compatible, transitive closure of requirements.txt",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11842#issuecomment-1131901848:310,error,error,310,https://hail.is,https://github.com/hail-is/hail/pull/11842#issuecomment-1131901848,1,['error'],['error']
Availability,"Ah, I see. If those paths point to the same location then it shouldn't make any difference. This error almost certainly means that `pyspark` cannot find your hail jar. I suspect that Spark 2.2.x has dropped support for the `SPARK_CLASSPATH` environment variable. Can you try starting `pyspark` with these options:; ```; pyspark \; --jars $HAIL_HOME/build/libs/hail-all-spark.jar \; --conf=spark.driver.extraClassPath=$HAIL_HOME/build/libs/hail-all-spark.jar \; --conf=spark.executor.extraClassPath=./hail-all-spark.jar. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-337639898:97,error,error,97,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337639898,1,['error'],['error']
Availability,"Ah, I thought that besides MatrixIR, TableIR, and BlockMatrixIR, aggregations were included (since I saw these as being operations over rows/columns. What is the definition of a relational ir? Brief search didn't yield much, just the concept of relational operators, which appear to be too general to apply here (==, >= are relational operator). Besides various Agg* irs, we also have CollectDistributedArray, and a bunch of others. I will add the missing ones (that are present in InferType), until I no longer get match errors, and we can review.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7959#issuecomment-578544609:522,error,errors,522,https://hail.is,https://github.com/hail-is/hail/pull/7959#issuecomment-578544609,1,['error'],['errors']
Availability,"Ah, I was accidentally modifying an installed version of Hail. I recovered the files and brought them in. I deleted that other debug_info. It doesn't include the batch information. Now every batch test in batch/ and in hail/ should be consistently using `Batch.debug_info`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10953#issuecomment-939112813:65,recover,recovered,65,https://hail.is,https://github.com/hail-is/hail/pull/10953#issuecomment-939112813,1,['recover'],['recovered']
Availability,"Ah, I was hoping the pca tests would start passing on the local backend with this change, but there are of course pruner issues. I'll have to try and craft a test that runs into this error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10330#issuecomment-820620715:183,error,error,183,https://hail.is,https://github.com/hail-is/hail/pull/10330#issuecomment-820620715,1,['error'],['error']
Availability,"Ah, duh, thanks! And ya I do want to make it easier to get to error logs from the PR namespace.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11352#issuecomment-1049187048:62,error,error,62,https://hail.is,https://github.com/hail-is/hail/pull/11352#issuecomment-1049187048,1,['error'],['error']
Availability,"Ah, figured out what's going on:; ```; ERROR	2020-01-15 18:17:49,022	batch.py	schedule_job:385	error while scheduling job (11, 3) on instance batch-worker-pr-7886-default-npqddriu0gh7-z20pv	Traceback (most recent call last):\n File ""/usr/local/lib/python3.6/dist-packages/batch/batch.py"", line 375, in schedule_job\n raise e\n File ""/usr/local/lib/python3.6/dist-packages/batch/batch.py"", line 366, in schedule_job\n await session.post(url, json=body)\n File ""/usr/local/lib/python3.6/dist-packages/aiohttp/client.py"", line 589, in _request\n resp.raise_for_status()\n File ""/usr/local/lib/python3.6/dist-packages/aiohttp/client_reqrep.py"", line 947, in raise_for_status\n headers=self.headers)\naiohttp.client_exceptions.ClientResponseError: 413, message='Request Entity Too Large', url='http://10.128.0.25:5000/api/v1alpha/batches/jobs/create; ```. This is causing an instance to be marked unhealthy. Somehow that's causing an always_run job to not run before a batch is considered finished.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7886#issuecomment-574813815:39,ERROR,ERROR,39,https://hail.is,https://github.com/hail-is/hail/pull/7886#issuecomment-574813815,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Ah, my Make is interpreting the slashes it self, which is what I would have expected from Make. . ```; # make echo; echo 'hello \; foo'; hello foo; # echo 'hello \; quote> foo'; hello \; foo; # cat Makefile; echo:; 	echo 'hello \; foo'. # ; ```. I guess newer GNU Make doesn't interpret the slashes before sending it to sh?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6956#issuecomment-525801961:110,echo,echo,110,https://hail.is,https://github.com/hail-is/hail/pull/6956#issuecomment-525801961,5,['echo'],['echo']
Availability,"Ah, that explains the pylint error. Thanks!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9797#issuecomment-738988432:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/9797#issuecomment-738988432,1,['error'],['error']
Availability,"Ah, the reason this never went in is a lint failure. . ```; /usr/local/lib/python3.7/dist-packages/hailtop/hailctl/dataproc/submit.py:27:59: E713 test for membership should be 'not in'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10863#issuecomment-941145164:44,failure,failure,44,https://hail.is,https://github.com/hail-is/hail/pull/10863#issuecomment-941145164,1,['failure'],['failure']
Availability,"Ah. This has nothing to do with notebook2. We have a wildcard DNS entry for *.hail.is so we don't have to modify DNS every time we add/remove a service. However, Let's Encrypt didn't support wildcard certificates when I wrote that code. So anything.hail.is will get a cert error. To fix this we either need to get a wildcard cert or fix the subdomains we use in DNS.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7145#issuecomment-536222416:273,error,error,273,https://hail.is,https://github.com/hail-is/hail/pull/7145#issuecomment-536222416,1,['error'],['error']
Availability,All python tests are failing with import errors.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8656#issuecomment-621225819:41,error,errors,41,https://hail.is,https://github.com/hail-is/hail/pull/8656#issuecomment-621225819,1,['error'],['errors']
Availability,"All test/checks for this pr pass. There is a CI related error, a cluster being issued a delete operation when existing delete operations:. """"""; + gcloud dataproc clusters delete ci-test-n42my5i1 --async; The cluster 'ci-test-n42my5i1' and all attached disks will be deleted. Do you want to continue (Y/n)? ; ERROR: (gcloud.dataproc.clusters.delete) FAILED_PRECONDITION: Cannot delete cluster 'ci-test-n42my5i1' while it has other pending delete operations.; """"""",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5878#issuecomment-485153266:56,error,error,56,https://hail.is,https://github.com/hail-is/hail/pull/5878#issuecomment-485153266,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,Allow `expect` in tests that don't kill and print multiple failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/169:59,failure,failures,59,https://hail.is,https://github.com/hail-is/hail/issues/169,1,['failure'],['failures']
Availability,"Almost by definition I'd suspect that adding a system administrator is a high security impact (that's not a judgement on you, just a statement about the security boundary getting wider). This is obviously fine in this case because we want you to be a system administrator, but we should let appsec know regardless. They'll also probably want to send you some standard trainings (and maybe background check forms?). I'll ping them.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14717#issuecomment-2400614863:420,ping,ping,420,https://hail.is,https://github.com/hail-is/hail/pull/14717#issuecomment-2400614863,1,['ping'],['ping']
Availability,"Alright, I'll look at that. I was copying pc_relate above, which does the balding nichols and checkpoint process as well.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8050#issuecomment-583033913:94,checkpoint,checkpoint,94,https://hail.is,https://github.com/hail-is/hail/pull/8050#issuecomment-583033913,1,['checkpoint'],['checkpoint']
Availability,Also add test case for unterminated string with nice error message (use `interceptFatal`).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/493#issuecomment-235044203:53,error,error,53,https://hail.is,https://github.com/hail-is/hail/issues/493#issuecomment-235044203,1,['error'],['error']
Availability,Also added it to third-party images so we're not pulling from DockerHub. Turns out the \ufeff bug we were seeing is hitting a lot of people and is addressed in this release. I put this up in my namespace to see that I can load it without error (though didn't try copying over dashboards and such).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12300:238,error,error,238,https://hail.is,https://github.com/hail-is/hail/pull/12300,1,['error'],['error']
Availability,Also added redundant interval pruning for `filtervariants intervals`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1041#issuecomment-257949279:11,redundant,redundant,11,https://hail.is,https://github.com/hail-is/hail/pull/1041#issuecomment-257949279,1,['redundant'],['redundant']
Availability,"Also ask Tim about limiting RAM available to Hail & Java, we should probably keep at least a gig dedicated to Python. Maybe that will cause memory errors to appear closer to where they belong.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12731#issuecomment-1507077467:32,avail,available,32,https://hail.is,https://github.com/hail-is/hail/pull/12731#issuecomment-1507077467,2,"['avail', 'error']","['available', 'errors']"
Availability,"Also fixed getting the logs for a job. - I didn't realize the context manager for asyncio_timeout was throwing an asyncio.TimeoutError. Now, I handle the TimeoutError exception and then throw our own exception after we've uploaded the logs and cleaned up the container. This way it still shows up as an error. - I noticed the logs were being cached when a user gets the logs while the job is running and we don't update the cache until the job is complete. Therefore, I think from the code, if the user asks for the logs part-way through the job running, they wouldn't see any updates until the job is completed. I'm not sure why no-one has complained about this yet, so might be good to double check that this is indeed a bug.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8280:303,error,error,303,https://hail.is,https://github.com/hail-is/hail/pull/8280,1,['error'],['error']
Availability,"Also included useful changes that made it possible to diagnose and fix this problem including:. - No longer dropping metrics for test namespaces. I checked the prometheus disk and we have plenty of space to add these additional metrics. Very useful for diagnosing test time latencies.; - Add prometheus scraping for envoy pods. Gives us many great metrics like number of 2xx, 3xx, 4xx and 5xx requests per upstream, rate limit enforcement, even time until the cert expires; - Made `Connection reset` a retry-once error. A connection reset can sometimes be indistinguishable from non-transient errors when the client is not able to inspect the response code before the reset clears the TCP buffer. We take multiple consecutive resets to mean an intentional action from the server indicating that the client is doing something wrong and retrying will not help. I have put off adding gzip compression to gateway in this PR. It was working fine with all of our services except for grafana, in which it was messing up the websocket connection for some reason. I'll dig into that separately.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12425:513,error,error,513,https://hail.is,https://github.com/hail-is/hail/pull/12425,2,['error'],"['error', 'errors']"
Availability,Also moved runAssoc code down so it only executes when needed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1475:25,down,down,25,https://hail.is,https://github.com/hail-is/hail/pull/1475,1,['down'],['down']
Availability,"Also sorry for the high latency on a response, apparently Verizon has an outage in my neighborhood until tomorrow morning.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13513#issuecomment-1701854993:73,outage,outage,73,https://hail.is,https://github.com/hail-is/hail/pull/13513#issuecomment-1701854993,1,['outage'],['outage']
Availability,Also those service backend failures are :100: because we need #11624 to merge. Feel free to @fails them and I'll deal with the conflict.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10792#issuecomment-1075927168:27,failure,failures,27,https://hail.is,https://github.com/hail-is/hail/pull/10792#issuecomment-1075927168,1,['failure'],['failures']
Availability,"Also when there is a binding outside the tiebreaker used in the tiebreaker it fails in python. The error is very inscrutable, but it simply does not work.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12295#issuecomment-1431843216:99,error,error,99,https://hail.is,https://github.com/hail-is/hail/pull/12295#issuecomment-1431843216,1,['error'],['error']
Availability,"Also, I created `gs://hail-common/vep/vep/GRCh37`, `gs://hail-common/vep/vep/GRCh38`; directories with VEP configs and loftee data files, so you can now run ; ```; gcloud dataproc clusters create $CLUSTER; ...; --initialization-actions gs://hail-common/hail-init.sh,gs://hail-common/vep/vep/GRCh37/vep85-GRCh37-init.sh. or . --initialization-actions gs://hail-common/hail-init.sh,gs://hail-common/vep/vep/GRCh38/vep85-GRCh38-init.sh; ```; along with ; ```; gs://hail-common/vep/vep/GRCh37/vep85-GRCh37-gcloud.properties. or . gs://hail-common/vep/vep/GRCh38/vep85-GRCh38-gcloud.properties; ```. though the init.sh script ties the cluster to a particular genome build. . Also, it would be nice if hail could throw an error if trying to annotate a GRCh37 callset with GRCh38 VEP, etc. Would it make sense to put this check in the VEP command?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1779#issuecomment-299721946:716,error,error,716,https://hail.is,https://github.com/hail-is/hail/pull/1779#issuecomment-299721946,1,['error'],['error']
Availability,"Also, I'm forging ahead for the rest of the day at least. I can't seem to figure out where the issue is for the validation errors that I'm seeing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7803#issuecomment-571283839:123,error,errors,123,https://hail.is,https://github.com/hail-is/hail/pull/7803#issuecomment-571283839,1,['error'],['errors']
Availability,"Also, I'm gonna add parameters to `hl.init` and set the flags in there. That punts the interface decision down the road by slightly restricting users (you can't change user project mid-pipeline).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12133#issuecomment-1230490168:106,down,down,106,https://hail.is,https://github.com/hail-is/hail/pull/12133#issuecomment-1230490168,1,['down'],['down']
Availability,"Also, having the migration be online and in multiple stages was making my head hurt a lot. Maybe on Monday we should sit down and white board this and make sure there's no edge cases.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12010#issuecomment-1221109901:121,down,down,121,https://hail.is,https://github.com/hail-is/hail/pull/12010#issuecomment-1221109901,1,['down'],['down']
Availability,"Also, make batch pods eviction-safe. This should allow the cluster autoscaler to scale the cluster down, according to: https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#what-types-of-pods-can-prevent-ca-from-removing-a-node",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7432:99,down,down,99,https://hail.is,https://github.com/hail-is/hail/pull/7432,1,['down'],['down']
Availability,"Also, make sure we always delete the disk despite any failures",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10429:54,failure,failures,54,https://hail.is,https://github.com/hail-is/hail/pull/10429,1,['failure'],['failures']
Availability,"Also, now that we are not going with the ""run a highmem node premptible pool"" approach, should we still have Prometheus tolerate preemptibles? It would probably be better if it was on one of our always running nodes, especially since it has a nontrivial amount of startup time in my experience",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6774#issuecomment-518774162:120,toler,tolerate,120,https://hail.is,https://github.com/hail-is/hail/pull/6774#issuecomment-518774162,1,['toler'],['tolerate']
Availability,"Also, strangely https://internal.hail.is/pr-7381-default-sx9ail9zkm77/blog/ now goes to 403 Forbidden, and a maintenance error is generated in Ghost. Shortly after the PR was built, that link worked. edit: The maintenance error potentially suggests we should wait longer to initiate our probes, although I can't tell until I know where the /blog GET at 31 minutes came from. That request happens 5 minutes before Ghost is actually up, so maybe a previous PR? Not certain. Separately, it takes ghost 6 seconds to actually boot, so if our readiness probe fires off 5s after the container is running, that may not be enough.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7381#issuecomment-548098857:109,mainten,maintenance,109,https://hail.is,https://github.com/hail-is/hail/pull/7381#issuecomment-548098857,4,"['error', 'mainten']","['error', 'maintenance']"
Availability,"Also, the quota documentation says the error should be this:. If you exceeded a quota with an HTTP/REST request, Google Cloud returns an HTTP 429 TOO MANY REQUESTS status code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10432#issuecomment-832973603:39,error,error,39,https://hail.is,https://github.com/hail-is/hail/pull/10432#issuecomment-832973603,1,['error'],['error']
Availability,"Also, wrt the `hail` alias, that only sets the environment variable for that single execution of `python`. You will need to run:; ```bash; export PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.4-src.zip:$HAIL_HOME/python; ```; before running `./gradlew test`, otherwise it's very likely that you will see a variety of errors related to Spark. I am surprised that you saw an error about Breeze natives. An inappropriate `$PYTHON_PATH` should trigger a failure much earlier than the section of code that uses of Breeze natives.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1419#issuecomment-281862423:334,error,errors,334,https://hail.is,https://github.com/hail-is/hail/issues/1419#issuecomment-281862423,3,"['error', 'failure']","['error', 'errors', 'failure']"
Availability,"Although Dataproc does not have a public Spark 3-based GA release schedule yet, it'd probably be helpful to start supporting a Spark 3 build; tagging @tpoterba for context. I'm not familiar with the release process internally, so let me know what other changes need to be made to accommodate this. In particular, this PR likely needs to change the PySpark requirements specified in https://github.com/hail-is/hail/blob/main/hail/python/requirements.txt. This PR builds on changes from #9199. The code changes are due to Scala 2.12 and Spark 3 changes:. - `y` in `x << y` must be an int; - `mutable.Stack` is deprecated; - `JavaConversions` is deprecated; - `addTaskCompletionListener` is overloaded; - `Row.merge()` is deprecated. The build changes are as follows:. - Upgraded Breeze from 1.0 to 1.1 due to a known bug: https://github.com/scalanlp/breeze/issues/772; - Downgraded from Json4s 3.7.0-M5 to 3.5.3 due to a known bug: https://github.com/json4s/json4s/issues/507; - Upgraded to `scalatest 3.0.5` for Scala 2.12 compatibility; - Update the `pyspark` version in `python/requirements.txt` to match `SCALA_VERSION` during `make install-deps`. The following testing commands pass (at least to the degree that `main` does):. - `make -j8 test SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5`; - `make -j8 test SCALA_VERSION=2.12.8 SPARK_VERSION=3.0.0`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9524:869,Down,Downgraded,869,https://hail.is,https://github.com/hail-is/hail/pull/9524,1,['Down'],['Downgraded']
Availability,"Although we generally want unshared IRs for downstream passes, there are many instances where we construct IRs with shared nodes (common case: using the same Ref for the table row in TableMapRows expressions). . Requiredness correctness should not be affected by node-sharing, and deduplicating every time we want to run the requiredness analysis is potentially very expensive since the goal is to be able to run it at arbitrary points in the lowering stack, so I'm going to allow Requiredness to handle shared nodes. This could potentially mess up if there are instances where a ref is created and used to represent two separate values for whatever reason, but I think we should consider that to be a bug---e.g.; ```; val r = Ref(""foo"", TInt32); If(, ; Let(""foo"", NA(TInt32), r + 3); Let(""foo"", I32(5), r + 5)); ```; should never exist. I've done the same for ComputeUsesAndDefs, which Requiredness needs, but same comment applies---correctness should not be affected by node sharing, unless we have improperly constructed IR with scoping issues.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8858:44,down,downstream,44,https://hail.is,https://github.com/hail-is/hail/pull/8858,1,['down'],['downstream']
Availability,"Am I strange in that I want to name something what it is (ci, batch, etc.) rather than give everything codenames? The purpose of codenames is to hide and obscure, you know. I think this should be called tutorial. And when it becomes a notebook service, notebook. And when it becomes the Hail service, it should just be the main website. The landing page should be password protected. We should think about whether we want to collect additional information there (e.g. email), although for now I don't think we need to, as everyone who signed up for the next tutorial filled out a questionnaire. I'm getting proxy timeouts. We need an ready endpoint and something on the client side to poll and redirect. Actually, awesome if it doesn't poll but uses, say, websockets, and the server watches the pod for a notification for k8s (or does this and also polls, which seems to be our standard pattern). Should we have an auto-scaling non-preemptible pool and schedule these there? If we do that, to optimize startup time, we should have imagePullPolicy: Never and then pull the image on startup and push it on update. When do you reap jupyter pods? jupyterhub has a simple management console that lets you shut down notebooks. > figure out how to teach flask url_for to use a root other than /. I don't think you can do this dynamically using headers. Blueprints seem to be the answer in Flask: https://stackoverflow.com/questions/18967441/add-a-prefix-to-all-flask-routes/18969161#18969161. Is there a reason you didn't make it a subdomain? I thought we decided we preferred that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4576#issuecomment-431037869:1205,down,down,1205,https://hail.is,https://github.com/hail-is/hail/pull/4576#issuecomment-431037869,1,['down'],['down']
Availability,"Amanda added some stuff so that `hl.is_snp` and friends will run without error for these alleles, but we never support to scala for sampleqc. I'll do that now. I think I'll just relax this error to treat ""invalid"" (which includes symbolic at the moment) alleles the same as ""Complex"" alleles, which aren't counted toward any sampleqc field.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413#issuecomment-386181958:73,error,error,73,https://hail.is,https://github.com/hail-is/hail/issues/3413#issuecomment-386181958,2,['error'],['error']
Availability,An error is being treated as a timeout but then the job is still considered running?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11397#issuecomment-1076794055:3,error,error,3,https://hail.is,https://github.com/hail-is/hail/pull/11397#issuecomment-1076794055,1,['error'],['error']
Availability,"An example of an error that wasn't retried properly:; https://ci.hail.is/batches/7377528/jobs/81; ```; Traceback (most recent call last):; File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/usr/local/lib/python3.8/dist-packages/hailtop/aiotools/copy.py"", line 129, in <module>; asyncio.run(main()); File ""/usr/lib/python3.8/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/usr/local/lib/python3.8/dist-packages/hailtop/aiotools/copy.py"", line 119, in main; await copy_from_dict(; File ""/usr/local/lib/python3.8/dist-packages/hailtop/aiotools/copy.py"", line 85, in copy_from_dict; await copy(; File ""/usr/local/lib/python3.8/dist-packages/hailtop/aiotools/copy.py"", line 58, in copy; copy_report = await Copier.copy(; File ""/usr/local/lib/python3.8/dist-packages/hailtop/aiotools/fs/copier.py"", line 455, in copy; await copier._copy(sema, copy_report, transfer, return_exceptions); File ""/usr/local/lib/python3.8/dist-packages/hailtop/aiotools/fs/copier.py"", line 548, in _copy; raise e; File ""/usr/local/lib/python3.8/dist-packages/hailtop/aiotools/fs/copier.py"", line 540, in _copy; await bounded_gather2(sema, *[; File ""/usr/local/lib/python3.8/dist-packages/hailtop/utils/utils.py"", line 545, in bounded_gather2; return await bounded_gather2_raise_exceptions(sema, *pfs, cancel_on_error=cancel_on_error); File ""/usr/local/lib/python3.8/dist-packages/hailtop/utils/utils.py"", line 525, in bounded_gather2_raise_exceptions; return await asyncio.gather(*tasks); File ""/usr/local/lib/python3.8/dist-packages/hailtop/utils/utils.py"", line 515, in run_with_sema; return await pf(); File ""/usr/local/lib/python3.8/dist-packages/hailtop/aiotools/fs/copier.py"", line 525, in _copy_one_transfer; raise e; File ""/usr/local/lib/python3.8/dist-pack",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13029#issuecomment-1542329456:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/13029#issuecomment-1542329456,1,['error'],['error']
Availability,And a typical interaction for a current 2.0.2 user:. ```bash; dking@wmb16-359 # gradle compileScala . FAILURE: Build failed with an exception. * Where:; Build file '/Users/dking/projects/hail2/build.gradle' line: 39. * What went wrong:; A problem occurred evaluating root project 'hail'.; > Please generate a gradle.properties file first by executing ./configure. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 1.413 secs; 1 dking@wmb16-359 # ./configure; With what version of Spark will you run Hail? (default: 2.0.2); ; using default version: 2.0.2; dking@wmb16-359 # gradle compileScala; The Task.leftShift(Closure) method has been deprecated and is scheduled to be removed in Gradle 5.0. Please use Task.doLast(Action) instead.; at build_2mbp15794fq4sj14khxclz0wz.run(/Users/dking/projects/hail2/build.gradle:168); :compileJava UP-TO-DATE; :nativeLib; (cd libsimdpp-2.0-rc2 && cmake .); -- Configuring done; -- Generating done; -- Build files have been written to: /Users/dking/projects/hail2/src/main/c/libsimdpp-2.0-rc2; :compileScala UP-TO-DATE. BUILD SUCCESSFUL. Total time: 4.418 secs,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1613#issuecomment-290201637:102,FAILURE,FAILURE,102,https://hail.is,https://github.com/hail-is/hail/pull/1613#issuecomment-290201637,1,['FAILURE'],['FAILURE']
Availability,And generate nice error message on Java 7.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/773:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/issues/773,1,['error'],['error']
Availability,And mendel errors (which still needs to be rewritten in Python),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3066#issuecomment-370152354:11,error,errors,11,https://hail.is,https://github.com/hail-is/hail/pull/3066#issuecomment-370152354,1,['error'],['errors']
Availability,"And separate preemptible and non-preemptible workloads to run in their own pools. This should fix the problem where the non-preemptible pool fills up with preemptible things but k8s can't evict. When this is ready to go in, I will remove the preemptible pool toleration and redeploy the infrastructure components by hand.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7636:259,toler,toleration,259,https://hail.is,https://github.com/hail-is/hail/pull/7636,1,['toler'],['toleration']
Availability,"And to directly respond to this comment:. > If we are just using the bytes uploaded and downloaded that are tracked by the resource usage monitor, then I think we can do a first pass at adding this functionality. This sounds great! This would resolve question 1 and eliminate the risk. We should charge the highest possible price: 0.23 USD/GiB. Answering question 2 can proceed slowly and carefully knowing that we don't have a cost risk.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13428#issuecomment-1692171657:88,down,downloaded,88,https://hail.is,https://github.com/hail-is/hail/issues/13428#issuecomment-1692171657,1,['down'],['downloaded']
Availability,"And what is this mean :; ```; EnvironmentError: no Hail context initialized, create one first; ```; how to initialize the hail context?; ```; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-289>"", line 2, in __init__; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); File ""/opt/Software/hail/python/hail/java.py"", line 42, in hc; raise EnvironmentError('no Hail context initialized, create one first'); EnvironmentError: no Hail context initialized, create one first; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-337917356:338,Error,Error,338,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337917356,1,['Error'],['Error']
Availability,Andrea didn't get an error on single quote string comparison,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/388:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/issues/388,1,['error'],['error']
Availability,Annotates no variants without error. See gitter discussion with @lescai.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/838:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/issues/838,1,['error'],['error']
Availability,"Another attempt at dropdown menus. I like this better, too, for the reasons you described. Changes:; - change dropdowns to ""caret"" style, with a triangle on the top of the dropdown that points to the header item it dropped down from; - move monitoring links into their own dropdown. To issues I'm not totally happy with:; - Monitoring can't be clicked on, so it is grayed out, but styling matches hover styling for active header items; - To center the triangle under the header item, I had to measure the width of the header items in the browser first. It would be nice to do this from within CSS, but I don't know how to do that: the caret and the header item are in different parts of the DOM, and I don't know how to communicate the width of the header item to the left property of the caret. It is deployed in my namespace if you want to take a look.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7196:223,down,down,223,https://hail.is,https://github.com/hail-is/hail/pull/7196,1,['down'],['down']
Availability,"Another set of eyes on this would be great. My current thoughts on this:. I only looked at the failure in PCA. I was never able to reproduce. My next step to try to reproduce was to run PCA on Lindo's full dataset on dataproc (can't use batch because the error is in spark PCA). I did look carefully through the stack trace, trying to understand what could possibly be happening. The number 177860 from the error isn't either matrix dimension, which is 210234 by 8893. Everything in `org.apache.spark.mllib.linalg.EigenValueDecomposition$.symmetricEigs(EigenValueDecomposition.scala:106)` is independent of the number of rows, so only the number 8893 of cols should be relevent. I wrote a simple test to execute spark PCA with 8893 rows in scala, so I could step through with a debugger:; ```scala; var mt = rangeMatrix(10000, 8893); mt = MatrixMapEntries(mt, InsertFields(Ref(""g"", mt.typ.entryType), Seq(""a"" -> F64(1)))); val t = MatrixToTableApply(mt, PCA(""a"", 10, false)); val n = TableToValueApply(t, ForceCountTable()); assertEvalsTo(n, 8893L); ```; The array `v` in `symmetricEigs` has length 177860 = 8893*20, and I didn't find anything else with that size. The only line I could find that could generate an exception that looks like this is line 555 of `dev.ludovic.netlib.arpack.AbstractARPACK.dsaupd`; ```scala; public void dsaupd(org.netlib.util.intW ido, String bmat, int n, String which, int nev, org.netlib.util.doubleW tol, double[] resid, int offsetresid, int ncv, double[] v, int offsetv, int ldv, int[] iparam, int offsetiparam, int[] ipntr, int offsetipntr, double[] workd, int offsetworkd, double[] workl, int offsetworkl, int lworkl, org.netlib.util.intW info) {; if (debug) System.err.println(""dsaupd"");; checkArgument(""DSAUPD"", 2, lsame(""I"", bmat) || lsame(""G"", bmat));; checkArgument(""DSAUPD"", 3, n >= 0);; checkArgument(""DSAUPD"", 4, lsame(""LA"", which) || lsame(""SA"", which) || lsame(""LM"", which) || lsame(""SM"", which) || lsame(""BE"", which));; checkArgument(""DSAUPD"", 5, 0 < ne",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313:95,failure,failure,95,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313,3,"['error', 'failure']","['error', 'failure']"
Availability,"Another strange dataproc failure:. ```; + cluster submit ci-test-e8jon1wrnx2o python/cluster-tests/cluster-read-vcfs-check.py; Job [38fe2b2b5b92430d9961e3226e0c0731] submitted.; Waiting for job output...; WARNING: Job terminated, but output did not finish streaming.; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [38fe2b2b5b92430d9961e3226e0c0731] failed with error:; Task not found; ```. I'm not even sure what a task is in this context. Will bump to retest.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6010#issuecomment-489360265:25,failure,failure,25,https://hail.is,https://github.com/hail-is/hail/pull/6010#issuecomment-489360265,3,"['ERROR', 'error', 'failure']","['ERROR', 'error', 'failure']"
Availability,"Another thing I just thought of, I think we should add raise some form of error if a job that is `always_run` has inputs from a job that is not `always_copy_output`. I can't imagine something like that being intentional, but if there is a valid use case, maybe we have a warning instead of an error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11884#issuecomment-1162862002:74,error,error,74,https://hail.is,https://github.com/hail-is/hail/pull/11884#issuecomment-1162862002,2,['error'],['error']
Availability,"Another very simple pipeline reported https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/zip.3A.20length.20mismatch . We can get access to these files via Sam B. ```python3; context_mis_freq_ht = hl.read_table(""gs://epi25/misc-data/gnomAD_v4/grch38_context_vep_annotated.v105.prefiltered.missense_freq_ensp.ht""); ensp2uniprot_ht = hl.import_table(""gs://epi-mis-3d/misc/ensp2uniprot_mart_export.ensp2uniprot.txt""). context_mis_freq_ht = context_mis_freq_ht.key_by(""ensp""); ensp2uniprot_ht = ensp2uniprot_ht.key_by(""ensp""). context_mis_freq_ht = context_mis_freq_ht.annotate(; uniprot = ensp2uniprot_ht[context_mis_freq_ht.ensp].uniprot); ```. notice that the error is removed if you instead use:; ```python3; context_mis_freq_ht = hl.read_table(""gs://epi25/misc-data/gnomAD_v4/grch38_context_vep_annotated.v105.prefiltered.missense_freq_ensp.ht""); ensp2uniprot_ht = hl.import_table(""gs://epi-mis-3d/misc/ensp2uniprot_mart_export.ensp2uniprot.txt""). context_mis_freq_ht = context_mis_freq_ht.key_by(""ensp""); ensp2uniprot_ht = ensp2uniprot_ht.key_by(""ensp""). context_mis_freq_ht = context_mis_freq_ht.join(ensp2uniprot_ht,'left'). ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13486#issuecomment-1883607858:687,error,error,687,https://hail.is,https://github.com/hail-is/hail/issues/13486#issuecomment-1883607858,1,['error'],['error']
Availability,"Anyone using recent versions of the hail-base image to connect to Google Storage has encountered MethodNotFound errors like this:; ```; Activated service account credentials for: [dpalmer-o8fe7@hail-vdc.iam.gserviceaccount.com]; 2020-03-23 20:00:58 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Initializing Spark and Hail with default parameters...; Running on Apache Spark version 2.4.0; SparkUI available at http://59dd09c396e8:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.34-2684f0214a05; LOGGING: writing to /hail-20200323-2000-0.2.34-2684f0214a05.log; Traceback (most recent call last):; File ""/scripts/hail_test.py"", line 3, in <module>; bam = hl.import_table('gs://dalio_bipolar_w1_w2_hail_02/analysis/gene_sets/BP_including_BPSCZ_MAC5_gene_set_counts_per_sample.tsv'); File ""</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-1276>"", line 2, in import_table; File ""/hail/python/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/hail/python/hail/methods/impex.py"", line 1511, in import_table; t = Table(TableRead(tr)); File ""/hail/python/hail/table.py"", line 334, in __init__; self._type = self._tir.typ; File ""/hail/python/hail/ir/base_ir.py"", line 303, in typ; self._compute_type(); File ""/hail/python/hail/ir/table_ir.py"", line 215, in _compute_type; self._type = Env.backend().table_type(self); File ""/hail/python/hail/backend/backend.py"", line 121, in table_type; jir = self._to_java_ir(tir); File ""/hail/python/hail/backend/backend.py"", line 105, in _to_java_ir; ir._jir = ir.parse(r(ir), ir_map=r.jirs); File ""/hail/python/hail/ir/base_ir.py"", line 311, in parse; return Env.hail().expr.ir.IRParser.parse_table_ir(code, ref_map, ir_map); File ""/spark-2.4.0-b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8343:112,error,errors,112,https://hail.is,https://github.com/hail-is/hail/issues/8343,2,"['avail', 'error']","['available', 'errors']"
Availability,"Apologies for the size, this PR got a bit out of hand. Let me know if you want me to try to break it up. Changes:; - Use custom status for pods, stored in pod and job tables as json. See Pod.status and Container.status in worker.py for the format. Example at the end. Note, ""container_statuses"" items have a field ""container_status"", because container is used in two ways: as a substep of a pod/job, and as docker container. My last renaming proposal got shot down, but we clearly need to improve this in a later PR.; - Heavily reworked worker.py. I believe this fixes https://github.com/hail-is/hail/issues/7350. The main design idea is to having all state creation and cleanup in Pod.run and Container.run.; - worker: Just support pods/status and pods/log, not container level status or logs.; - Pod now writes final status, not containers. Individual containers write their logs.; - I time all the steps of the Pod container (creating, starting, running, uploading log, etc.) with a timing called ""runtime"" which is how long the docker container itself took to start/run. That's usually 4-6 seconds. However, if you log into a machine and run `docker run --rm ubuntu:18.04 echo hi` it takes 1-2 seconds. It would be good to find out where the extra 3-4 seconds are coming from (I feel like @jigold might have some insight into this. Comparing our container config to the docker command line's might be useful here.); - Stop using (value, err) style exception handling. I think we should be able to design this with very little explicit exception handling, mainly in critical blocks to maintain the program invariants.; - Pods can have error status in 1 of 3 ways: the pod itself failed (e.g. couldn't read k8s secrets), one of the pod containers error out (e.g. pull failed due to invalid image), and the docker container finished but the final container status had an ""Error"" field. Next step is to remove pods and merge the pod and job tables. ```; {; ""name"": ""batch-2-job-1"",; ""batch_id"": 2,; ""j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7354:460,down,down,460,https://hail.is,https://github.com/hail-is/hail/pull/7354,1,['down'],['down']
Availability,"Apparently, creating a zip file of all our dependencies and the Hail code takes ~30s. This change skips the shadow JAR for local development. We still need a shadow JAR to produce a shareable wheel file; however, when doing local development, we can simply tell Py4J (and the JVM) where to find our dependencies class files. Also notice that I made install-editable non-PHONY. It need not be PHONY as long as we can reliably determine if `hail/python` is the pip-installed version. To do so, we simply check if the `__init__.py` at the root of the pip package is newer than when we last installed. If its newer, then either:; 1. We edited `__init__.py`, or; 2. The pip location of Hail has changed since we last ran install-editable. I also deleted eggs because nobody uses eggs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13639:416,reliab,reliably,416,https://hail.is,https://github.com/hail-is/hail/pull/13639,1,['reliab'],['reliably']
Availability,"Arcturus -- I'm assigning this to you, but please don't take off the WIP tag as merging this will cause Batch to shutdown (database migration). If we're not prepared for it, then it could cause an extended outage.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9441#issuecomment-691229759:206,outage,outage,206,https://hail.is,https://github.com/hail-is/hail/pull/9441#issuecomment-691229759,1,['outage'],['outage']
Availability,Are you asking how to detect that one command of many in a bash *pipeline* failed? We need pipe fail enabled for that:. ```bash; # bad; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 0; ```; ```bash; # good; (base) dking@wm28c-761 ~ % set -o pipefail; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 1; ```. Permissions issues indeed fail the `gcloud` command:; ```; (base) dking@wm28c-761 ~ % gcloud compute instances list --project notmyproject; API [compute.googleapis.com] not enabled on project [notmyproject]. Would you ; like to enable and retry (this will take a few minutes)? (y/N)? y. Enabling service [compute.googleapis.com] on project [notmyproject]...; ERROR: (gcloud.compute.instances.list) PERMISSION_DENIED: Permission denied to enable service [compute.googleapis.com]; Help Token: AVzH8v0NCN6UR5g5Xtu_gFde3SeZCmToYDDOlz7hp5HiVvGHKX8aeJ-kn0N0n72nMovbuw4ksm8MB0OifqPrdxlc6lWwJJKi0CsIJon1a7SSlF_H; - '@type': type.googleapis.com/google.rpc.PreconditionFailure; violations:; - subject: ?error_code=110002&service=serviceusage.googleapis.com&permission=serviceusage.services.enable&resource=notmyproject; type: googleapis.com; - '@type': type.googleapis.com/google.rpc.ErrorInfo; domain: serviceusage.googleapis.com; metadata:; permission: serviceusage.services.enable; resource: notmyproject; service: serviceusage.googleapis.com; reason: AUTH_PERMISSION_DENIED; (base) dking@wm28c-761 ~ % echo $?; 1; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268:182,echo,echo,182,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268,7,"['ERROR', 'Error', 'echo']","['ERROR', 'ErrorInfo', 'echo']"
Availability,"Are you sure that you installed all the necessary packages listed here: https://hail.is/docs/0.2/install/linux.html ? In particular this kind of error can happen if you did not install openblas. In the future, please use https://discuss.hail.is for support questions, we don't monitor GitHub issues.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939#issuecomment-786236682:145,error,error,145,https://hail.is,https://github.com/hail-is/hail/issues/9939#issuecomment-786236682,1,['error'],['error']
Availability,"Argh, sorry, it's actually the parens, not the spaces:; ```; /bin/sh: -c: line 9: syntax error near unexpected token `('; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5759#issuecomment-479599142:89,error,error,89,https://hail.is,https://github.com/hail-is/hail/issues/5759#issuecomment-479599142,1,['error'],['error']
Availability,"Around 0348 I was executing `curl ci.hail.is/status` and repeatedly getting error responses, unfortunately I lost the error responses (that curl was piping into something that blew up on non-json data). The most recent response was a gateway timeout. The most recent logs are:. ```; INFO	| 2018-10-23 03:41:29,166 	| prs.py 	| heal_target:139 | deploying Nealelab/cloudtools:master; INFO	| 2018-10-23 03:41:29,350 	| prs.py 	| try_deploy:179 | already deployed c49bb905d3ba4d791150c3627c3c9ebde006a55a; INFO	| 2018-10-23 03:41:29,351 	| ci.py 	| <lambda>:366 | 127.0.0.1 ""POST /heal HTTP/1.1"" 200 -; INFO	| 2018-10-23 03:42:04,032 	| ci.py 	| <lambda>:366 | 10.56.143.15 ""POST /test-ci-6oi3jysu.batch-pods/push HTTP/1.0"" 404 -; INFO	| 2018-10-23 03:42:04,196 	| ci.py 	| <lambda>:366 | 10.56.143.15 ""POST /test-ci-6oi3jysu.batch-pods/pull_request HTTP/1.0"" 404 -; INFO	| 2018-10-23 03:42:04,677 	| ci.py 	| <lambda>:366 | 10.56.143.15 ""POST /test-ci-6oi3jysu.batch-pods/pull_request_review HTTP/1.0"" 404 -; INFO	| 2018-10-23 03:42:37,944 	| ci.py 	| <lambda>:366 | 127.0.0.1 ""POST /refresh_github_state HTTP/1.1"" 200 -; ERROR	| 2018-10-23 03:48:38,045 	| ci.py 	| polling_event_loop:357 | Could not poll due to exception: HTTPConnectionPool(host='127.0.0.1', port=5000): Read timed out. (read timeout=360); ```; [hail-ci.log](https://github.com/hail-is/hail/files/2504423/hail-ci.log)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4607:76,error,error,76,https://hail.is,https://github.com/hail-is/hail/issues/4607,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,Array[Int].sum() error message leaves something to be desired,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/933:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/issues/933,1,['error'],['error']
Availability,"As a data point, we saw this error for IR sizes beyond 20000000 in our 0.2.132ish deployment too, when using ServiceBackend. PR #14567 was present in 0.2.132, so unless something weird was going on with our installation (certainly a possibility) I think this means #14567 wasn't effective for us either. We're very much looking forward to giving #14750 a try.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14749#issuecomment-2458392840:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/issues/14749#issuecomment-2458392840,1,['error'],['error']
Availability,"As currently written, if `git clone` returns a non-zero exit code, the script; should exit immediately. I am not sure why this GnuTLS recv error (pasted below); does not trigger a non-zero exit code from git clone. This change both; explicitly echoes the exit code so we can be sure of our sanity and adds a check; that I'm confident will fail if no git repository was cloned (`git status`). ```; + date; Wed Apr 29 21:15:15 UTC 2020; + rm -rf repo; + mkdir repo; + cd repo; + '[' '!' -d .git ']'; + retry clone; + clone; + set -e; ++ mktemp -d; + dir=/tmp/tmp.5R5aJAlgEm; + git clone https://github.com/hail-is/hail.git /tmp/tmp.5R5aJAlgEm; Cloning into '/tmp/tmp.5R5aJAlgEm'...; error: RPC failed; curl 56 GnuTLS recv error (-54): Error in the pull function.; fatal: The remote end hung up unexpectedly; fatal: early EOF; fatal: index-pack failed; ++ ls -A /tmp/tmp.5R5aJAlgEm. real	0m0.998s; user	0m0.008s; sys	0m0.017s; + git config user.email ci@hail.is; fatal: not in a git directory; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8667:139,error,error,139,https://hail.is,https://github.com/hail-is/hail/pull/8667,5,"['Error', 'echo', 'error']","['Error', 'echoes', 'error']"
Availability,"As described in #9600, `hl.hadoop_ls` currently raises a NullPointerException when called with a path that does not exist. The error originates in `is.hail.io.fs.HadoopFS.listStatus`. The [hadoop.fs.FileSystem docs](https://hadoop.apache.org/docs/current/api/org/apache/hadoop/fs/FileSystem.html#globStatus-org.apache.hadoop.fs.Path-) list two forms of `globStatus`:; * public FileStatus[] globStatus(Path pathPattern); * public FileStatus[] globStatus(Path pathPattern, PathFilter filter). The first makes no mention of returning null. The second however, says:; > Returns: null if pathPattern has no glob and the path does not exist an empty array if pathPattern has a glob and no path matches it else an array of FileStatus objects matching the pattern. This matches the behavior seen with `hl.hadoop_ls`. This change checks for a null value returned from `globStatus` and raises a `FileNotFoundException` in that case. Resolves #9600",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10007:127,error,error,127,https://hail.is,https://github.com/hail-is/hail/pull/10007,1,['error'],['error']
Availability,"As discussed at team meeting today, filebeat needs a toleration to run on preemptibles.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6820:53,toler,toleration,53,https://hail.is,https://github.com/hail-is/hail/pull/6820,1,['toler'],['toleration']
Availability,"As discussed in #14240, we emit warnings on database deadlocks, which there are enough of to trigger noisy alerts. Since there's nothing to be done operationally (and there's no current work underway to get rid of them), these alerts only contribute to alert fatigue and hide potential problems in the system that could be addressed. This demotes a deadlock to the `info` level so we can still see how often they occur but are not alerted by them. In the future when we resolve the current deadlock we can re-escalate this error so that we can catch new deadlocks that are introduced.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14251:523,error,error,523,https://hail.is,https://github.com/hail-is/hail/pull/14251,1,['error'],['error']
Availability,"As discussed in Zulip, `BlockMatrix.write_from_entry_expr` throws OOM error when running on a cluster without `--properties 'core:fs.gs.outputstream.upload.chunk.size=1048576'`. The reason is as documented in [the Hail doc](https://hail.is/docs/0.2/linalg/hail.linalg.BlockMatrix.html#hail.linalg.BlockMatrix.from_entry_expr), but I hope either Hail 1) makes this property as default, or 2) throws more appropriate error/warning message. > This method opens n_cols / block_size files concurrently per task. To not blow out memory when the number of columns is very large, limit the Hadoop write buffer size. Error:; ```20/03/03 21:39:46 ERROR org.apache.spark.util.SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 1213,5,main]; java.lang.OutOfMemoryError: GC overhead limit exceeded; 20/03/03 21:39:50 ERROR org.apache.spark.executor.Executor: Exception in task 55.0 in stage 3.0 (TID 1197); java.lang.NullPointerException; at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.mkdirs(GoogleCloudStorageFileSystem.java:515); at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.create(GoogleCloudStorageFileSystem.java:261); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopOutputStream.createChannel(GoogleHadoopOutputStream.java:82); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopOutputStream.<init>(GoogleHadoopOutputStream.java:74); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.create(GoogleHadoopFileSystemBase.java:797); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1067); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1048); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:937); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:925); at is.hail.io.fs.HadoopFS.create(HadoopFS.scala:91); at is.hail.io.fs.HadoopFS.unsafeWriter(HadoopFS.scala:445); at is.hail.linalg.WriteBlocksRDD$$anonfu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8239:70,error,error,70,https://hail.is,https://github.com/hail-is/hail/issues/8239,5,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"As mentioned in #14580, IR can get quite big, especially as it can contain an arbitrary amount of encoded literals from the user's python session. Tested manually, by making a very very large literal, running a pipeline with it on 0.2.132, observing the failure seen in #14650, then running the same pipeline with this change, and it succeeds as normal. Resolves #14650",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14651:254,failure,failure,254,https://hail.is,https://github.com/hail-is/hail/pull/14651,1,['failure'],['failure']
Availability,"As much as possible, avoid network requests. In particular, we know the type of tables that are read in checkpoint and Expression.persist.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11677:104,checkpoint,checkpoint,104,https://hail.is,https://github.com/hail-is/hail/pull/11677,1,['checkpoint'],['checkpoint']
Availability,"As of [nest_asyncio 1.5.2](https://github.com/erdewit/nest_asyncio/commit/1856573ac86954d15b0f617c97c02844bcbc7ea4), we can initialize nest_asyncio inside running loops (e.g. Jupyter). If nest_asyncio is initialized after even one task is created, [users receive inscrutable errors](https://github.com/erdewit/nest_asyncio/issues/22\#issuecomment-874710264). This error happened during the QoB workshop I ran. This change takes advantage of nest_asyncio 1.5.2 to initialize nest_asyncio before *everything*, thus ensuring it can completely patch the event loop. You can reproduce the error yourself by running `python3 -c ""import hail as hl; hl.init(billing_project=\""not-a-real-billing-project\"")""` repeatedly in a terminal. I encounter the error ~50% of the time. With this change, I did not see the error after 5 invocations of that command.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12413:275,error,errors,275,https://hail.is,https://github.com/hail-is/hail/pull/12413,5,['error'],"['error', 'errors']"
Availability,"As part of our work with generating All of Us datasets, we needed to copy around a million gcs objects. Our `Copier` infrastructure 'should' be able to handle that, but it kept falling with robustness issues. What finally worked was using GCS's [rewrite](https://cloud.google.com/storage/docs/json_api/v1/objects/rewrite) api. This allowed us to copy data without reading it, allowing the copies to complete in a fraction of the time while also reducing bandwidth needs. There are two components to this:; 1. Research what specific APIs we can take advantage of; 2. Update our code to use them when we can, for the `Copier`, and the new sync tool (#14248). Here's the code I used for making the rewrite requests for merging a set of matrix tables together, the progress bar code was for visibility. ```python3; async def rewrite(; gfs: GoogleStorageAsyncFS,; src: str,; dst: str,; progress: Optional[rich.progress.Progress] = None,; file_tid: Optional[rich.progress.TaskID] = None,; requests_tid: Optional[rich.progress.TaskID] = None,; ):; assert (progress is None) == (file_tid is None) == (requests_tid is None); src_bkt, src_name = gfs.get_bucket_and_name(src); dst_bkt, dst_name = gfs.get_bucket_and_name(dst); if not src_name:; raise IsABucketError(src); if not dst_name:; raise IsABucketError(dst); client = gfs._storage_client; path = (; f'/b/{src_bkt}/o/{urllib.parse.quote(src_name, safe="""")}/rewriteTo'; f'/b/{dst_bkt}/o/{urllib.parse.quote(dst_name, safe="""")}'; ); kwargs = {'json': '', 'params': {}}; client._update_params_with_user_project(kwargs, src_bkt); response = await retry_transient_errors(client.post, path, **kwargs); if progress is not None:; progress.update(requests_tid, advance=1); while not response['done']:; kwargs['params']['rewriteToken'] = response['rewriteToken']; response = await retry_transient_errors(client.post, path, **kwargs); if progress is not None:; progress.update(requests_tid, advance=1); if progress is not None:; progress.update(file_tid, advance=1)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14601:190,robust,robustness,190,https://hail.is,https://github.com/hail-is/hail/issues/14601,1,['robust'],['robustness']
Availability,"As the docs state, inParX should be ""true if in pseudo-autosomal region on chromosome X."" Likewise, inParY should be ""true if in pseudo-autosomal region on chromosome Y."" However, these flags are currently being applied regardless of chromosome. That is, currently any variant that meets (60001 <= start && start <= 2699520) || (154931044 <= start && start <= 155260560) gets inParX = true, and similarly for inParY. This is confusing and, I would guess, in error. inParX should only be able to be true if v.contig == ""X"" is true, and inParY should only be able to be true if v.contig == ""Y"" is true.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/452:458,error,error,458,https://hail.is,https://github.com/hail-is/hail/issues/452,1,['error'],['error']
Availability,"As written here, this feature is incompatible with `overwrite=True`. The checkpoint file makes it possible to recover progress from a partially written file at `url`, so I'm not sure what overwriting would mean in this context. Is there a particular use case you have in mind? This was built for a specific application, and I am eager to hear others.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10215#issuecomment-822958412:73,checkpoint,checkpoint,73,https://hail.is,https://github.com/hail-is/hail/pull/10215#issuecomment-822958412,2,"['checkpoint', 'recover']","['checkpoint', 'recover']"
Availability,Assertion Error when reading table,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4325:10,Error,Error,10,https://hail.is,https://github.com/hail-is/hail/issues/4325,1,['Error'],['Error']
Availability,Assertion error in RVB,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7693#issuecomment-563585896:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/pull/7693#issuecomment-563585896,1,['error'],['error']
Availability,Assertion error related to ndarray/extract,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8325:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/issues/8325,1,['error'],['error']
Availability,Assertion error when filtering rows based on locus position,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12280:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/issues/12280,1,['error'],['error']
Availability,Assertion error when using mt.annotate_rows() with different partition keys,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3119:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/issues/3119,1,['error'],['error']
Availability,"Assigned to Patrick, but anyone should feel free to approve, small change to add better error messages on `MakeNDArray`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10095#issuecomment-784448517:88,error,error,88,https://hail.is,https://github.com/hail-is/hail/pull/10095#issuecomment-784448517,1,['error'],['error']
Availability,"Assigning @tpoterba since he (and cotton) have the most context to review this. A few preliminaries:. 1. I noticed the proxy headers were not quite right when you're testing this without SSL or on some non-standard port. `$host` does not include the port, `$http_host` does. `$scheme` returns `http` or `https` depending on how the user connected to gateway; 2. The admin privilege check was too restrictive, if `delete_worker_pod` is called by `/new` there's no need to check admin privs; 3. I realized that the timeout logic wasn't quite right because a misconfigured gateway (I was testing with a broken gateway config) will return 5xx codes, but that doesn't mean the server is alive. We probably should error here, but I'm hesitant to add new error modes so close to a tutorial. Ok, how does this work? Basically, if the gateway cannot connect to the notebook pod, we intercept the error and redirect the user to the ""create new notebook"" webpage. That webpage deletes whatever remains of the users previous notebook pod & service. Here are the pieces:. 1. `recursive_error_pages on;` the internet suggests that without this we cannot use `error_page` with an ""internal"" rule (the `@` rules are internal rules that users cannot directly access); 2. `proxy_connect_timeout` defaults to 60s which is a shit user experience if your pod dies. Honestly, I might set this to 100ms. This is all inside a datacenter.; 3. `proxy_intercept_errors` permits us to use `error_page` with 5xx errors from failing to connect to the proxy. ---. I tested this with a pile of hacks to deploy this into an anonymous namespace in `vdc`. I'm not ready to PR those changes, they need a clean up before others use them. Sometime next week I hope to get that in. Getting it requires some restructuring of `vdc/` and `gateway/` to be more modular.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4974:682,alive,alive,682,https://hail.is,https://github.com/hail-is/hail/pull/4974,5,"['alive', 'error']","['alive', 'error', 'errors']"
Availability,"Assigning to Daniel 2 because the scorecard beacon is tired. This removes the workshop login option (previously agreed upon with Cotton), which makes the login.html page totally useless; so I've converted the login link to hit the old /login POST endpoint, and converted the POST to a GET. I think this is semantically fine, because no credentials (or other data) is actually sent to that endpoint (as workshop password is kaput), making that endpoint solely issue a redirect. Since login.html is gone, I also no longer redirect to it. Instead, unauthorized users are redirected to /error, and I refactored this redirect into a function since it's now used identically in 2 places. I've also imported the jwt library, so that jwt.exceptions.InvalidTokenError is in scope, and made some minor cleanup. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6078:583,error,error,583,https://hail.is,https://github.com/hail-is/hail/pull/6078,1,['error'],['error']
Availability,"At some point (highly likely that it was the Ubuntu 20.04 -> 22.04 upgrade) Batch went from using cgroups v1 to cgroups v2 for setting containers' CPU and memory limits. We mostly don't touch cgroups, the container runtime handles that for us, but we poll the `cgroupfs` for recoding memory usage and CPU utilization. The accounting mechanism changed between v1 and v2 so batch was silently failing to collect these metrics. Deploying these changes into my namespace got me back the following plots (compiling hail):. <img width=""701"" alt=""Screenshot 2023-09-14 at 5 47 24 PM"" src=""https://github.com/hail-is/hail/assets/24440116/0f470e5a-7feb-4b9e-bac6-f560c8366d8e"">. The reason why we fail silently when the file doesn't exist is because we are letting the container runtime manage the cgroup, and there is a race condition between the container exiting + the cgroup getting destroyed and our polling of this file. We could probably do a better job reporting an error, like this though, perhaps logging errors if we fail to read this file more than X number of times.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13626:965,error,error,965,https://hail.is,https://github.com/hail-is/hail/pull/13626,2,['error'],"['error', 'errors']"
Availability,"At some point, we should think about how to improve the discoverability and machine-verifiability of our APIs. Currently the tightest type of job log is rather complex. If the performance is OK, I think we should move towards classes that define the request and response types of each call. ---. The main difference is `hail-pip-install` having `retry`. If pip exits with a non-zero exit code, we'll just rerun the command exactly, at most four more times. This mitigates missing retry logic in `pip` itself. For example, [this job](https://ci.hail.is/batches/167314/jobs/27) failed because pip encountered a connection reset while downloading a file. Ideally, pip would simply retry the download. Since we don't control the pip source code, I use a retry that treats all of pip as a black box. There's definitely a failure mode: if you specify a package that doesn't exist, pip will error five times in a row and take ~30 seconds before the retry logic gives up. I'm OK with this because pip should basically never fail for legitimate reasons.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9906#issuecomment-775241278:632,down,downloading,632,https://hail.is,https://github.com/hail-is/hail/pull/9906#issuecomment-775241278,4,"['down', 'error', 'failure']","['download', 'downloading', 'error', 'failure']"
Availability,Attempting to export NA loci gives bad error message.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4011:39,error,error,39,https://hail.is,https://github.com/hail-is/hail/issues/4011,1,['error'],['error']
Availability,Attempting to install hail on dataproc using the `init_notebook.py` script errors out because hail depends on a more recent version of `jinja2` than the version of `notebook` pinned in the script allows for. This change upgrades the pinned version of `notebook` in the script to be compatible with hail's pinned `jinja2` version. Fixes #12926.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12965:75,error,errors,75,https://hail.is,https://github.com/hail-is/hail/pull/12965,1,['error'],['errors']
Availability,"Awesome. God, how long was this in coming. No for this PR, but I observe this seems a bit error prone:. > --vep; > actual = hl.vep(expected.select_rows(), 'gs://hail-common/vep/vep/vep85-loftee-gcloud.json', csq=csq). We should probably think a bit more about the vep/cloudtools interface after this. I'm thinking `cloudtools --vep --vep-version=85 --vep-assembly=GRCh37 --loffee-version=beta ...` and then just `hl.vep(foo, csq=csq)` where the properties file defaults to something set up by cloudtools. @konradjk?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4347#issuecomment-422170789:90,error,error,90,https://hail.is,https://github.com/hail-is/hail/pull/4347#issuecomment-422170789,1,['error'],['error']
Availability,Azure default credentials will use the metadata server when available so we can just use those instead of manually reaching out to the metadata server.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13225:60,avail,available,60,https://hail.is,https://github.com/hail-is/hail/pull/13225,1,['avail'],['available']
Availability,"B, free 434.4 MiB); 2022-05-14 12:09:09 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 434.4 MiB); 2022-05-14 12:09:09 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on 10.40.3.21:33951 (size: 3.2 KiB, free: 434.4 MiB); 2022-05-14 12:09:09 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:311; 2022-05-14 12:09:11 root: INFO: RegionPool: FREE: 64.0K allocated (64.0K blocks / 0 chunks), regions.size = 1, 0 current java objects, thread 30: Thread-4; 2022-05-14 12:09:11 root: ERROR: HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; From is.hail.utils.HailException: /data/public/prs/ex_antonk.bim:1013423: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; offending line: 11	.	0	135009883	CT	C; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:30); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:28); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.utils.Context.wrapException(Context.scala:21); 	at is.hail.utils.WithContext.foreach(Context.scala:51); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1(LoadPlink.scala:36); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1$adapted(LoadPlink.scala:35); 	at is.hail.io.fs.FS.$anonfun$readLines$1(FS.scala:222); 	at is.hail.utils.package$.using(package.scala:640); 	at is.hail.io.fs.FS.readLines(FS.scala:213); 	at is.hail.io.fs.FS.readLines$(FS.scala:211); 	at is.hail.io.fs.HadoopFS.readLines(HadoopFS.sca",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:1575,Error,ErrorHandling,1575,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['Error'],['ErrorHandling']
Availability,"Back to you. I didn't do the octal changes or the desired error handling, but I made an issue to do that when I have a little more time.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/468#issuecomment-234586874:58,error,error,58,https://hail.is,https://github.com/hail-is/hail/pull/468#issuecomment-234586874,1,['error'],['error']
Availability,"Back to you. I made some inline comments before starting review, see both. Test failure is due to not changing high_kin to related_pairs on the right hand side, etc. in doc example.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2148#issuecomment-326106858:80,failure,failure,80,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326106858,1,['failure'],['failure']
Availability,"Back to you. I've re-pushed to accommodate space-delimited .fam again (will throw error if some sample name has space too). While you look at the rest, I'll work in another branch on .fam importer to annotations which will give user a delimiter option.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/234#issuecomment-204439315:82,error,error,82,https://hail.is,https://github.com/hail-is/hail/pull/234#issuecomment-204439315,1,['error'],['error']
Availability,Bad error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9163:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/9163,1,['error'],['error']
Availability,Bad error message for filter_alleles exception,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1202:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/1202,1,['error'],['error']
Availability,Bad error message prints Java Bytecode,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1705:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/1705,1,['error'],['error']
Availability,Bad error message when indexing a matrix table with itself,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9121:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/9121,1,['error'],['error']
Availability,Bad error message when passing `dict` with a `None` key,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5700:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/5700,1,['error'],['error']
Availability,Bad error message when using a non-aggregator expr in aggregate,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4110:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/4110,1,['error'],['error']
Availability,"Bad error message: MatrixTable and Table files are directories, path 'blah' is not a directory",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10843:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/10843,1,['error'],['error']
Availability,Bad error on different length division,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3653:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/3653,1,['error'],['error']
Availability,Bad error on key mismatch,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4951:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/4951,1,['error'],['error']
Availability,Bad error on old agg.filter syntax,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4770:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/4770,1,['error'],['error']
Availability,Bad error on transmuting a key,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4085:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/4085,1,['error'],['error']
Availability,Bad error when using `annotate_cols` instead of `annotate_rows`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5415:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/5415,1,['error'],['error']
Availability,"Bascially grabbed the relevant bits from SparkBackend and ServiceBackend. Enabled by setting HAIL_QUERY_BACKEND=local. Needs HAIL_HOME and SPARK_HOME set to find jars, and hardcodes the py4j jar version that comes with Spark 2.4.x. Will have to work on ripping out Spark dependency. Currently uses HadoopFS for the file system in Java. GoogleFS in Python works with gs:// or local files, I just copied it and ripped out the Google stuff. Some some rough ideas from some of your old work, @johnc1231 (py4jbackend). Current results on the Python tests:. > == 470 failed, 245 passed, 87 skipped, 15 warnings, 1 error in 270.61 seconds ==",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8860:608,error,error,608,https://hail.is,https://github.com/hail-is/hail/pull/8860,1,['error'],['error']
Availability,Based on https://clang.llvm.org/cxx_status.html and https://gcc.gnu.org/gcc-4.7/cxx0x_status.html Clang 3.3 and GCC 4.7 should be sufficient to prevent compile errors arising from not supporting C++11 features. FYI @cseed @tpoterba,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1340:160,error,errors,160,https://hail.is,https://github.com/hail-is/hail/pull/1340,1,['error'],['errors']
Availability,"Based on https://hail.zulipchat.com/#narrow/stream/300487-Hail-Batch-Dev/topic/resource.20table.20query.20woes/near/338629272, merge to `9e0081c` and future commits (none of which are available now) need to be merged manually.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12744:184,avail,available,184,https://hail.is,https://github.com/hail-is/hail/pull/12744,1,['avail'],['available']
Availability,"Basically all naming, rids these test files of linting errors. We do a lot of reassigning a `BatchBuilder` variable to a `Batch` and so I consolidated around `bb` and `b`. A couple instances where I remove debug_info from an assert statement is because the associated `Batch` object would not exist, since that assert is triggered by an error that's raised before the `Batch` object is created.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12147:55,error,errors,55,https://hail.is,https://github.com/hail-is/hail/pull/12147,2,['error'],"['error', 'errors']"
Availability,Batch Driver Does not shut down tasks in the correct order,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13324:27,down,down,27,https://hail.is,https://github.com/hail-is/hail/issues/13324,1,['down'],['down']
Availability,Batch dropped a job that error'ed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4591:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/issues/4591,1,['error'],['error']
Availability,"Batch page shows max 50 jobs paginated, with next page button. Search box supports search with a simple language of terms:; - k=v - match jobs with attribute key k and value v; - has:k - match jobs with attribute k, any value; - state - match jobs with the corresponding states. Search state terms are lower case (unlike actual job states, which I plan to change) and the recognized state terms are:. ```; state_query_values = {; 'pending': ['Pending'],; 'ready': ['Ready'],; 'running': ['Running'],; 'live': ['Ready', 'Running'],; 'cancelled': ['Cancelled'],; 'error': ['Error'],; 'failed': ['Failed'],; 'bad': ['Error', 'Failed'],; 'success': ['success'],; 'done': ['Cancelled', 'Error', 'Failed', 'Success']; }; ```; as you can see, some state search terms, like done, match multiple job states. ; - !term - match jobs that don't match term. To select specific names, you can do `name=foo`. Next steps:; - Make the corresponding changes to the API so you can iterate paginated through all jobs in a batch.; - Make batches page paginated, too.; - Help information about the search syntax.; - We'll probably want to order by fields other than just id.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7635:562,error,error,562,https://hail.is,https://github.com/hail-is/hail/pull/7635,4,"['Error', 'error']","['Error', 'error']"
Availability,Batches themselves can now have callbacks. You receive a callback for each member job's completion (success or failure). CI will use this to wait for completion of the entire DAG. Stacked on https://github.com/hail-is/hail/pull/4930,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5035:111,failure,failure,111,https://hail.is,https://github.com/hail-is/hail/pull/5035,1,['failure'],['failure']
Availability,"Because HttpResponseException is a subclass of IOException, the match clause for HttpResponseException in isRetryOnceError is unreachable. As a result, account-not-found errors for Google Cloud Storage are not handled correctly. This change reorders the match clauses accordingly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12166:170,error,errors,170,https://hail.is,https://github.com/hail-is/hail/pull/12166,1,['error'],['errors']
Availability,"Because `HttpResponseException` is a subclass of `IOException`, the `match` clause for `HttpResponseException` in `isRetryOnceError` is unreachable. As a result, account-not-found errors for Google Cloud Storage are not handled correctly. This change reorders the `match` clauses accordingly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12160:180,error,errors,180,https://hail.is,https://github.com/hail-is/hail/pull/12160,1,['error'],['errors']
Availability,"Because node selectors are ""recommended"": https://kubernetes.io/docs/concepts/configuration/assign-pod-node/ ""the recommended approaches all use label selectors to make the selection."" ""nodeSelector is the simplest recommended form of node selection constraint."". The taint/toleration documentation use no such language and their suggested use cases don't match ours: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/. I'm not sure what to read into this, if anything. I had a mark set in my mind against taints since I remember reading that some scheduler features (maybe eviction or downsizing?) were disabled with taints. I can't find this in the docs anymore, so it was probably fixed (or I'm not searching hard enough?), but the bad feeling remains. I see your argument, although missing the tag means either paying too much (running a preemptible pod on a non-preemptible node) which we should discovery by monitoring the non-preemptible node workload, or we get excessive downtime on preemptions which we should notice through uptime monitoring. I'm mostly just frustrated with the autoscheduler and trying to simplify things to get it to behave reasonably before I end up writing our own.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7636#issuecomment-560696683:274,toler,toleration,274,https://hail.is,https://github.com/hail-is/hail/pull/7636#issuecomment-560696683,4,"['down', 'downtime', 'toler']","['downsizing', 'downtime', 'toleration']"
Availability,"Because that won't work at all, because the input file name expected by `gatk IndexFeatureFile` won't exist. But perhaps you meant to connect the unrelated filenames via something like. ```; ; bgzip -c {j.tsv_counts} > {j.counts['tsv.gz']}; ; ```. Reasons for not doing that would include:. 1. Filename extensions are significant to GATK, so I would not trust `SubCommand` to write the output file in the right format if the filename did not have the expected extension. (This could be ameliorated via `j.tsv_counts.set_extension`.). 2. Using bgzip with `-c  >` is not its natural mode of operation, so is more likely to encounter bugs than the more typical `bgzip filename` invocation. (For example, plain gzip burns the input filename into the compressed file's header, so the redirection version produces different results from the typical invocation for gzip; bgzip does not embed the filename but the change may have other effects. For example, bgzip's error checking (e.g. in disk full situations) may well be more complete in the typical invocation than when writing to standard output.). It is also less clear than the straightforward invocation, so using this would be a hack. 4. The resulting code is IMHO overall less clear than the original version in which the resource group models the relationship between all three filenames. If Hail Batch is a well-rounded orthogonal API, then that code ought to work too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13191#issuecomment-1599478181:961,error,error,961,https://hail.is,https://github.com/hail-is/hail/issues/13191#issuecomment-1599478181,1,['error'],['error']
Availability,"Because we're running the bash script that is generated with +e so it will fail on the first error. To try and implement always_run would require implementing something more complicated in the local backend and not just building up a script. Because you'd have to check whether the parents succeeded for each task. It's not out of the question, but I don't think it's worth doing right now. Hence, the NotImplementedError. Same reasoning for timeout.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8258#issuecomment-596109210:93,error,error,93,https://hail.is,https://github.com/hail-is/hail/pull/8258#issuecomment-596109210,1,['error'],['error']
Availability,"Before we can simplify the binding structure, we need to stop duplicating it all over the place. This PR rewrites `FreeVariables` so that it no longer needs special logic for particular nodes, hard coding binding structure (redundantly). To do this, it takes advantage of the new `Bindings`, which operates on a `GenericBindingEnv` interface. It adds a new implementation of this interface specifically for computing free variables, then simply does a generic traversal of the IR using this custom binging environment. While I find the new implementation far simpler and more obviously correct than the old, I do expect it to further simplify once I'm able to start modifying the core binding structure.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14451:224,redundant,redundantly,224,https://hail.is,https://github.com/hail-is/hail/pull/14451,1,['redundant'],['redundantly']
Availability,"Below is the first part of the stack trace for for a job using pyhail with a user error in the expression language. The text on line 7 isn't in the `utils.py` from pyspark but in my provided `utils.py` (though the error certainly did come from pyspark `utils.py`). ```; Traceback (most recent call last):; File ""/tmp/5d145552-3077-4992-8d29-3df6975c7247/genomes_qc.py"", line 161, in <module>; .export_variants(rf_path + "".va.txt.bgz"", "","".join(out_metrics)); File ""/home/teamcity/TeamCityAgent1/work/591c293e3f6bfb1d/python/pyhail/dataset.py"", line 489, in export_variants; File ""/tmp/5d145552-3077-4992-8d29-3df6975c7247/utils.py"", line 209, in run_command; cmd_args); File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; expression.append('va.calldata.%(pop_upper)s = gs.filter(g => %(criterion)s == ""%(pop)s"").callStats(v)' % input_dict); File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o93.run.; : org.broadinstitute.hail.utils.package$FatalException: `Struct' has no field `type'; ``",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1184:82,error,error,82,https://hail.is,https://github.com/hail-is/hail/issues/1184,3,['error'],['error']
Availability,"Ben came across an image in the wild with a null `Env` field in the manifest, which caused the following error:; ```; Error; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 868, in _run; timed_out = await self._run_until_done_or_deleted(self._run_container); File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1010, in _run_until_done_or_deleted; return await run_until_done_or_deleted(self.deleted_event, f, *args, **kwargs); File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 680, in run_until_done_or_deleted; return step.result(); File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1066, in _run_container; await self._write_container_config(); File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1106, in _write_container_config; config = await self.container_config(); File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1166, in container_config; 'env': self._env(),; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1354, in _env; self.image.image_config['Config']['Env'] + self.env + CLOUD_WORKER_API.cloud_specific_env_vars_for_user_jobs; TypeError: unsupported operand type(s) for +: 'NoneType' and 'list'; ```. He fixed it by creating the following docker image:. ```docker; FROM jargene/hapice:1.0; ```. It could be that old versions of docker allowed this to be empty but have since made it `[]`, which would mean this would be unfortunately very annoying to test but nonetheless pretty trivial to fix.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13720:105,error,error,105,https://hail.is,https://github.com/hail-is/hail/pull/13720,2,"['Error', 'error']","['Error', 'error']"
Availability,Ben confirmed this was a user error.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10645#issuecomment-875824135:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/pull/10645#issuecomment-875824135,1,['error'],['error']
Availability,Better Fam file error reporting,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/709:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/issues/709,1,['error'],['error']
Availability,Better HailContext error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3586:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/3586,1,['error'],['error']
Availability,Better Python Errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9398:14,Error,Errors,14,https://hail.is,https://github.com/hail-is/hail/pull/9398,1,['Error'],['Errors']
Availability,Better VEP error 2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4426:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/pull/4426,1,['error'],['error']
Availability,Better catch-all error message for weird out-of-place exprs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1626:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/1626,1,['error'],['error']
Availability,Better error checking,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1440:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/1440,1,['error'],['error']
Availability,"Better error handling:. Attempt to verify correctness of byte code using automatically computed maxes and stack frames. ; - If that prints no messages and throws no exceptions, then everything worked fine.; - If that throws no exception, but prints a message, then verification failed. Print the verification failure message and throw an exception.; - If that throws an exception, then it is likely that auto-computing stack frames failed, so let's try to verify again without the stack frames; - If that prints no messages, then something weird happened, rethrow the original verification exception.; - If that prints a message, then verification failed. Print the verification failure message and throw an exception.; - I've never seen the max-only verifier throw an exception. I also added a bit that would print out the byte code if given a `PrintWriter` to print to. This functionality is currently unused, but was useful for debugging.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2330:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/2330,3,"['error', 'failure']","['error', 'failure']"
Availability,Better error message for Expression.__nonzero__,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2774:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/2774,1,['error'],['error']
Availability,Better error message for filtervariants,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/383:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/issues/383,1,['error'],['error']
Availability,Better error message for linear dependence of covariates in regression models,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1156:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/issues/1156,1,['error'],['error']
Availability,Better error message for spark.serializer unset,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3865:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/3865,1,['error'],['error']
Availability,"Better error message for unix files not preceded with ""file:///""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/381:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/issues/381,1,['error'],['error']
Availability,Better error message on interval parse failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5758:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/5758,2,"['error', 'failure']","['error', 'failure']"
Availability,Better error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/163:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/issues/163,1,['error'],['error']
Availability,Better error messages for __getitem__,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3584:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/3584,1,['error'],['error']
Availability,Better error messages from returned aggregable types,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1492:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/1492,1,['error'],['error']
Availability,"Better error on ""if expression""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4172:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/4172,1,['error'],['error']
Availability,Better errors for hl.utils.range_table / range_matrix_table,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3680:7,error,errors,7,https://hail.is,https://github.com/hail-is/hail/pull/3680,1,['error'],['errors']
Availability,Better errors for read,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3146:7,error,errors,7,https://hail.is,https://github.com/hail-is/hail/pull/3146,1,['error'],['errors']
Availability,Better errors on read_table/read_matrix_table for 0.1 formats,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3911:7,error,errors,7,https://hail.is,https://github.com/hail-is/hail/pull/3911,1,['error'],['errors']
Availability,Better fam file error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/854:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/854,1,['error'],['error']
Availability,Better orderedRVD partition errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3997:28,error,errors,28,https://hail.is,https://github.com/hail-is/hail/pull/3997,1,['error'],['errors']
Availability,Both Cotton and I have PRs failing due to pod failures that are impossible to debug without this.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9781:46,failure,failures,46,https://hail.is,https://github.com/hail-is/hail/pull/9781,1,['failure'],['failures']
Availability,"Both of these support a number of features not available in hail.plot:; - interactive legend (click to hide/show elements); - labelling with continuous expressions; - labelling using multiple expressions (will display a dropdown selection widget); - specifying color schemes; - hovering on points displays their coordinates, labels and additional source fields; - legend is also displayed outside of the plotting space to be unobtrusive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5601:47,avail,available,47,https://hail.is,https://github.com/hail-is/hail/pull/5601,1,['avail'],['available']
Availability,"Both these fail with the same error:; ```; broken_ht = hl.import_table('../data/bikes.csv'); broken_ht = hl.import_table('../data/bikes.csv', delimiter=';'); ```. I think this is an encoding issue. This file is encoded with latin-1 and contains French diacritics.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5221#issuecomment-459112810:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/issues/5221#issuecomment-459112810,1,['error'],['error']
Availability,"Btw the docs say `If `mt` contains an entry field `GT` of type :py:data:`.tcall`, then the following fields are computed:` but the code would error out if it didn't have it",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3629#issuecomment-392932165:142,error,error,142,https://hail.is,https://github.com/hail-is/hail/pull/3629#issuecomment-392932165,1,['error'],['error']
Availability,"Building from source - hail 0.2.74. `$ git clone https://github.com/hail-is/hail.git`; `$ cd hail`; `$ git checkout tags/0.2.74`; `$ cd hail`; `$ make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12 SPARK_VERSION=3.1.2`; `...`; `curl -sSL https://storage.googleapis.com/hail-common/libsimdpp-2.1.tar.gz > libsimdpp-2.1.tar.gz; tar -xzf libsimdpp-2.1.tar.gz`. `c++ -o build/ibs.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/include/darwin -MD -MF build/ibs.d -MT build/ibs.o -c ibs.cpp`. `make[1]: *** No rule to make target `lz4.h', needed by `build/Decoder.o'. Stop.`; `make: *** [native-lib-prebuilt] Error 2`. I've installed lz4 and still get this error. . https://hail.is/docs/0.2/getting_started.html?highlight=lz4#requirements no longer documents lz4 as required, but 0.2.74 is breaking on it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10747:838,Error,Error,838,https://hail.is,https://github.com/hail-is/hail/issues/10747,2,"['Error', 'error']","['Error', 'error']"
Availability,"Builds on #3500 . This PR introduces support for sparse block matrices. The only new command exposed in Python is `sparsify_row_intervals`. Matrix product currently always results in a dense block matrix. Sparse block matrices also support transpose, diagonal, and all non-mathematical operations except filtering. Element-wise mathematical operations are currently supported if and only if they cannot transform zeroed blocks to non-zero blocks. For example, all forms of element-wise multiplication are supported,; and element-wise multiplication results in a sparse block matrix with block support equal to the intersection of that of the operands. On the other hand, scalar addition is not supported, and matrix addition is supported only between block matrices with the same block sparsity. Once this is in, I'll expose a couple more sparsifiers (rectangles, band) and also bring in parallel export of many rectangles to TSV from another branch, so that users can proceed with LD / fine mapping applications. Down the line I plan to support for all operations by expanding to union of block support, or to all blocks, for some operations. And matrix multiplication ought to return the minimal number of blocks as well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3501:1014,Down,Down,1014,https://hail.is,https://github.com/hail-is/hail/pull/3501,1,['Down'],['Down']
Availability,Builds on: https://github.com/hail-is/hail/pull/2825. added RVD (should be UnpartitionedRVD) and OrderedRVD; allows to add new rvd types (HashedRVD); added list of partition files to current specs (to support safe object storage write strategy in presence of failure),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2828:259,failure,failure,259,https://hail.is,https://github.com/hail-is/hail/pull/2828,1,['failure'],['failure']
Availability,"Builds on: https://github.com/hail-is/hail/pull/5101. I'm not going to assign this directly, but break it up because it is pretty spicy (>5K lines changed). This gets us to 9 tests failing against the service, with 22 tests skipped that use to/from_spark or BlockMatrix. Start the server:. ```; $ hail python/hail-apiserver/hail-apiserver.py; ```. Run the tests:. ```; $ HAIL_TEST_SERVICE_BACKEND_URL='http://localhost:5000' gw testPython; ```. Failures:. ```; FAIL python/test/hail/methods/test_family_methods.py::Tests::test_tdt; FAIL python/test/hail/methods/test_impex.py::ImportMatrixTableTests::test_import_matrix_table; FAIL python/test/hail/methods/test_misc.py::Tests::test_maximal_independent_set; FAIL python/test/hail/methods/test_misc.py::Tests::test_maximal_independent_set2; FAIL python/test/hail/methods/test_misc.py::Tests::test_maximal_independent_set3; FAIL python/test/hail/methods/test_misc.py::Tests::test_maximal_independent_set_types; FAIL python/test/hail/methods/test_misc.py::Tests::test_rename_duplicates; FAIL python/test/hail/methods/test_qc.py::Tests::test_concordance; FAIL python/test/hail/methods/test_statgen.py::Tests::test_ibd; ======= 9 failed, 460 passed, 22 skipped, 24 warnings in 233.52 seconds ========; ```. The tdt failure is due to a latent pruner bug I haven't finished tracking down yet. The remaining tests are easily fixed but adding relational functions for: import table, MIS and IBD. Rename duplicates and concordance should just be re-written in Python. Reference genomes will need some work to be multi-user. We need to eliminate the global reference genome state in the JVM, add it to Python, and include references with requests. This means the reference function registration will need to get revamped.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5121:445,Failure,Failures,445,https://hail.is,https://github.com/hail-is/hail/pull/5121,3,"['Failure', 'down', 'failure']","['Failures', 'down', 'failure']"
Availability,Bump de.undercouch.download from 3.2.0 to 5.2.1 in /hail,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:19,down,download,19,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['down'],['download']
Availability,Bump de.undercouch.download from 3.2.0 to 5.3.0 in /hail,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:19,down,download,19,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download']
Availability,Bump de.undercouch.download from 5.3.0 to 5.3.1 in /hail,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:19,down,download,19,https://hail.is,https://github.com/hail-is/hail/pull/12707,1,['down'],['download']
Availability,Bump de.undercouch.download from 5.3.1 to 5.4.0 in /hail,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:19,down,download,19,https://hail.is,https://github.com/hail-is/hail/pull/12893,1,['down'],['download']
Availability,"Bump, deadlock errors are absolutely hammering the cluster today.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10985#issuecomment-949085569:15,error,errors,15,https://hail.is,https://github.com/hail-is/hail/pull/10985#issuecomment-949085569,1,['error'],['errors']
Availability,"Bumping this PR, I'd like it to land so I can nail down exactly why my flags PR is causing BN tests to fail.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12139#issuecomment-1317326725:51,down,down,51,https://hail.is,https://github.com/hail-is/hail/pull/12139#issuecomment-1317326725,1,['down'],['down']
Availability,"Bumps [aiodns](https://github.com/saghul/aiodns) from 2.0.0 to 3.0.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/saghul/aiodns/releases"">aiodns's releases</a>.</em></p>; <blockquote>; <h2>3.0.0</h2>; <ul>; <li>Release wheels and source to PyPI with GH actions</li>; <li>Try to make tests more resilient</li>; <li>Don't build universal wheels</li>; <li>Migrate CI to GH Actions</li>; <li>Fix TXT CHAOS test</li>; <li>Add support for CAA queries</li>; <li>Support Python &gt;= 3.6</li>; <li>Bump pycares dependency</li>; <li>Drop tasks.py</li>; <li>Allow specifying dnsclass for queries</li>; <li>Set URL to https</li>; <li>Add license args in setup.py</li>; <li>Converted Type Annotations to Py3 syntax Closes</li>; <li>Only run mypy on cpython versions</li>; <li>Also fix all type errors with latest mypy - pycares seems to have no typing / stubs so lets ignore it via <code>mypy.ini</code></li>; <li>setup: typing exists since Python 3.5</li>; <li>Fix type annotation of gethostbyname()</li>; <li>Updated README</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/saghul/aiodns/blob/master/ChangeLog"">aiodns's changelog</a>.</em></p>; <blockquote>; <h1>3.0.0</h1>; <ul>; <li>Release wheels and source to PyPI with GH actions</li>; <li>Try to make tests more resilient</li>; <li>Don't build universal wheels</li>; <li>Migrate CI to GH Actions</li>; <li>Fix TXT CHAOS test</li>; <li>Add support for CAA queries</li>; <li>Support Python &gt;= 3.6</li>; <li>Bump pycares dependency</li>; <li>Drop tasks.py</li>; <li>Allow specifying dnsclass for queries</li>; <li>Set URL to https</li>; <li>Add license args in setup.py</li>; <li>Converted Type Annotations to Py3 syntax Closes</li>; <li>Only run mypy on cpython versions</li>; <li>Also fix all type errors with latest mypy - pycares seems to have no typing / stubs so lets ignore it via <code>mypy.ini</code></li>; <li>setup:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11570:344,resilien,resilient,344,https://hail.is,https://github.com/hail-is/hail/pull/11570,2,"['error', 'resilien']","['errors', 'resilient']"
Availability,"Bumps [aiodocker](https://github.com/aio-libs/aiodocker) from 0.17.0 to 0.21.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiodocker/releases"">aiodocker's releases</a>.</em></p>; <blockquote>; <h2>aiodocker 0.18.0 release</h2>; <h2>Features</h2>; <ul>; <li>Improve the error text message if cannot connect to docker engine. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/411"">#411</a>)</li>; <li>Implement docker exec protocol. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/415"">#415</a>)</li>; <li>Implement container commit, pause and unpause functionality. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/418"">#418</a>)</li>; <li>Implement auto-versioning of the docker API by default. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/419"">#419</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiodocker/blob/master/CHANGES.rst"">aiodocker's changelog</a>.</em></p>; <blockquote>; <h1>0.21.0 (2021-07-23)</h1>; <h2>Bugfixes</h2>; <ul>; <li>Use ssl_context passsed to Docker constructor for creating underlying connection to docker engine. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/536"">#536</a>)</li>; <li>Fix an error when attach/exec when container stops before close connection to it. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/608"">#608</a>)</li>; </ul>; <h1>0.20.0 (2021-07-21)</h1>; <h2>Bugfixes</h2>; <ul>; <li>Accept auth parameter by <code>run()</code> method; it allows auto-pulling absent image from private storages. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/295"">#295</a>)</li>; <li>Fix passing of JSON params. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/543"">#543</a>)</li>; <li>Fix issue wit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11537:329,error,error,329,https://hail.is,https://github.com/hail-is/hail/pull/11537,1,['error'],['error']
Availability,"Bumps [aiohttp](https://github.com/aio-libs/aiohttp) from 3.8.1 to 3.8.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/releases"">aiohttp's releases</a>.</em></p>; <blockquote>; <h2>3.8.3</h2>; <p>.. attention::</p>; <p>This is the last :doc:<code>aiohttp &lt;index&gt;</code> release tested under; Python 3.6. The 3.9 stream is dropping it from the CI and the; distribution package metadata.</p>; <h2>Bugfixes</h2>; <ul>; <li>; <p>Increased the upper boundary of the :doc:<code>multidict:index</code> dependency; to allow for the version 6 -- by :user:<code>hugovk</code>.</p>; <p>It used to be limited below version 7 in :doc:<code>aiohttp &lt;index&gt;</code> v3.8.1 but; was lowered in v3.8.2 via :pr:<code>6550</code> and never brought back, causing; problems with dependency pins when upgrading. :doc:<code>aiohttp &lt;index&gt;</code> v3.8.3; fixes that by recovering the original boundary of <code>&lt; 7</code>.; (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/6950"">#6950</a>)</p>; </li>; </ul>; <hr />; <h1>3.8.2 (2022-09-20, subsequently yanked on 2022-09-21)</h1>; <p>.. note::</p>; <p>This release has some compatibility fixes for Python 3.11 but it may; still have some quirks. Some tests are still flaky in the CI.</p>; <p>.. caution::</p>; <p>This release has been yanked from PyPI. Modern pip will not pick it; up automatically. The reason is that is has <code>multidict &lt; 6</code> set in; the distribution package metadata (see :pr:<code>6950</code>). Please, use; <code>aiohttp ~= 3.8.3, != 3.8.1</code> instead, if you can.</p>; <h2>Bugfixes</h2>; <ul>; <li>Added support for registering :rfc:<code>OPTIONS &lt;9110#OPTIONS&gt;</code>; HTTP method handlers via :py:class:<code>~aiohttp.web.RouteTableDef</code>.; (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/4663"">#4663</a>)</li>; <li>Started supporting :rfc:<code>authority-form &lt;9112#authority-form&gt;</",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12296:929,recover,recovering,929,https://hail.is,https://github.com/hail-is/hail/pull/12296,1,['recover'],['recovering']
Availability,"Bumps [aiohttp](https://github.com/aio-libs/aiohttp) from 3.8.4 to 3.8.5.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/releases"">aiohttp's releases</a>.</em></p>; <blockquote>; <h2>3.8.5</h2>; <h2>Security bugfixes</h2>; <ul>; <li>; <p>Upgraded the vendored copy of llhttp_ to v8.1.1 -- by :user:<code>webknjaz</code>; and :user:<code>Dreamsorcerer</code>.</p>; <p>Thanks to :user:<code>sethmlarson</code> for reporting this and providing us with; comprehensive reproducer, workarounds and fixing details! For more; information, see; <a href=""https://github.com/aio-libs/aiohttp/security/advisories/GHSA-45c4-8wx5-qw6w"">https://github.com/aio-libs/aiohttp/security/advisories/GHSA-45c4-8wx5-qw6w</a>.</p>; <p>.. _llhttp: <a href=""https://llhttp.org"">https://llhttp.org</a></p>; <p>(<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7346"">#7346</a>)</p>; </li>; </ul>; <h2>Features</h2>; <ul>; <li>; <p>Added information to C parser exceptions to show which character caused the error. -- by :user:<code>Dreamsorcerer</code></p>; <p>(<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7366"">#7366</a>)</p>; </li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>; <p>Fixed a transport is :data:<code>None</code> error -- by :user:<code>Dreamsorcerer</code>.</p>; <p>(<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/3355"">#3355</a>)</p>; </li>; </ul>; <hr />; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/v3.8.5/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.8.5 (2023-07-19)</h1>; <h2>Security bugfixes</h2>; <ul>; <li>; <p>Upgraded the vendored copy of llhttp_ to v8.1.1 -- by :user:<code>webknjaz</code>; and :user:<code>Dreamsorcerer</code>.</p>; <p>Thanks to :user:<code>sethmlarson</code> for reporting this and providing us with; comprehensive reproducer, workarounds and fixing details! For mo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13270:1055,error,error,1055,https://hail.is,https://github.com/hail-is/hail/pull/13270,5,['error'],['error']
Availability,"Bumps [async-timeout](https://github.com/aio-libs/async-timeout) from 3.0.1 to 4.0.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/async-timeout/releases"">async-timeout's releases</a>.</em></p>; <blockquote>; <h2>v4.0.2</h2>; <h2>Misc</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/259"">#259</a>, <a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/274"">#274</a></li>; </ul>; <h2>v4.0.1</h2>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h2>async-timeout 4.0.0</h2>; <h1>Changes</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Drooped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:961,avail,available,961,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['avail'],['available']
Availability,"Bumps [authlib](https://github.com/lepture/authlib) from 0.11 to 0.15.5.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/authlib/releases"">authlib's releases</a>.</em></p>; <blockquote>; <h2>Version 0.15.5</h2>; <ul>; <li>Make Authlib compatible with latest httpx</li>; <li>Make Authlib compatible with latest werkzeug</li>; <li>Allow customize RFC7523 <code>alg</code> value</li>; </ul>; <h2>Version 0.15.4</h2>; <p>Security fix when JWT claims is None.</p>; <p>For example, JWT payload has <code>iss=None</code>:</p>; <pre><code>{; &quot;iss&quot;: None,; ...; }; </code></pre>; <p>But we need to decode it with claims:</p>; <pre><code>claims_options = {; 'iss': {'essential': True, 'values': ['required']}; }; jwt.decode(token, key, claims_options=claims_options); </code></pre>; <p>It didn't raise an error before this fix.</p>; <h2>Version 0.15.3</h2>; <p>Fixed <code>.authorize_access_token</code> for OAuth 1.0 services, via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/308"">lepture/authlib#308</a></p>; <h2>Version 0.15.2</h2>; <p>Fixed httpx authentication bug via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/283"">#283</a></p>; <h2>Version 0.15.1</h2>; <p>Backward compitable fix for using JWKs in JWT, via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/280"">#280</a>.</p>; <h2>Version 0.15</h2>; <p>This is the last release before v1.0. In this release, we added more RFCs; implementations and did some refactors for JOSE:</p>; <ul>; <li>RFC8037: CFRG Elliptic Curve Diffie-Hellman (ECDH) and Signatures in JSON Object Signing and Encryption (JOSE)</li>; <li>RFC7638: JSON Web Key (JWK) Thumbprint</li>; </ul>; <p>We also fixed bugs for integrations:</p>; <ul>; <li>Fixed support for HTTPX&gt;=0.14.3</li>; <li>Added OAuth clients of HTTPX back via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/270"">#270</a></li>; <li>Fixed parallel t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11483:859,error,error,859,https://hail.is,https://github.com/hail-is/hail/pull/11483,1,['error'],['error']
Availability,"Bumps [azure-identity](https://github.com/Azure/azure-sdk-for-python) from 1.8.0 to 1.9.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Azure/azure-sdk-for-python/releases"">azure-identity's releases</a>.</em></p>; <blockquote>; <h2>azure-identity_1.9.0</h2>; <h2>1.9.0 (2022-04-05)</h2>; <h3>Features Added</h3>; <ul>; <li>Added PII logging if logging.DEBUG is enabled. (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23203"">#23203</a>)</li>; </ul>; <h3>Breaking Changes</h3>; <ul>; <li><code>validate_authority</code> support is not available in 1.9.0.</li>; </ul>; <h3>Bugs Fixed</h3>; <ul>; <li>Added check on <code>content</code> from msal response. (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23483"">#23483</a>)</li>; <li>Fixed the issue that async OBO credential does not refresh correctly. (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/21981"">#21981</a>)</li>; </ul>; <h3>Other Changes</h3>; <ul>; <li>Removed <code>resource_id</code>, please use <code>identity_config</code> instead.</li>; <li>Renamed argument name <code>get_assertion</code> to <code>func</code> for <code>ClientAssertionCredential</code>.</li>; </ul>; <h2>azure-identity_1.9.0b1</h2>; <h2>1.9.0b1 (2022-03-08)</h2>; <h3>Features Added</h3>; <ul>; <li>Added <code>validate_authority</code> support for msal client (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22625"">#22625</a>)</li>; <li>Added <code>resource_id</code> support for user-assigned managed identity (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22329"">#22329</a>)</li>; <li>Added <code>ClientAssertionCredential</code> support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22328"">#22328</a>)</li>; <li>Updated App service API version to &quot;2019-08-01&quot; (<a href=""https://github-redir",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11752:618,avail,available,618,https://hail.is,https://github.com/hail-is/hail/pull/11752,1,['avail'],['available']
Availability,"Bumps [azure-storage-blob](https://github.com/Azure/azure-sdk-for-python) from 12.11.0 to 12.13.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Azure/azure-sdk-for-python/releases"">azure-storage-blob's releases</a>.</em></p>; <blockquote>; <h2>azure-storage-blob_12.13.1</h2>; <h2>12.13.1 (2022-08-04)</h2>; <h3>Bugs Fixed</h3>; <ul>; <li>Fixed two rare issues with ranged blob download when using client-side encryption V1 or V2.</li>; </ul>; <h2>azure-storage-blob_12.13.0</h2>; <h2>12.13.0 (2022-07-07)</h2>; <h3>Bugs Fixed</h3>; <ul>; <li>Stable release of features from 12.13.0b1.</li>; <li>Added support for deleting versions in <code>delete_blobs</code> by supplying <code>version_id</code>.</li>; </ul>; <h2>azure-storage-blob_12.13.0b1</h2>; <h2>12.13.0b1 (2022-06-15)</h2>; <h3>Features Added</h3>; <ul>; <li>Added support for service version 2021-08-06.</li>; <li>Added a new version of client-side encryption for blobs (version 2.0) which utilizes AES-GCM-256 encryption.; If you are currently using client-side encryption, it is <strong>highly recommended</strong> to switch to a form of server-side; encryption (Customer-Provided Key, Encryption Scope, etc.) or version 2.0 of client-side encryption. The encryption; version can be specified on any client constructor via the <code>encryption_version</code> keyword (<code>encryption_version='2.0'</code>).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/13989b5b1253e26f3f3ee24013a3013fea1bdf73""><code>13989b5</code></a> [Storage] Fix ranged download for client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25522"">#25522</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e90af4374bfd7c139737ad2888fcd269b3023520""><code>e90af43</code></a> DataLake funny dependency (<a href=""https://github-redirect.depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:427,down,download,427,https://hail.is,https://github.com/hail-is/hail/pull/12109,1,['down'],['download']
Availability,"Bumps [boto3](https://github.com/boto/boto3) from 1.17.54 to 1.21.13.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/boto/boto3/blob/develop/CHANGELOG.rst"">boto3's changelog</a>.</em></p>; <blockquote>; <h1>1.21.13</h1>; <ul>; <li>api-change:<code>synthetics</code>: [<code>botocore</code>] Allow custom handler function.</li>; <li>api-change:<code>transfer</code>: [<code>botocore</code>] Add waiters for server online and offline.</li>; <li>api-change:<code>devops-guru</code>: [<code>botocore</code>] Amazon DevOps Guru now integrates with Amazon CodeGuru Profiler. You can view CodeGuru Profiler recommendations for your AWS Lambda function in DevOps Guru. This feature is enabled by default for new customers as of 3/4/2022. Existing customers can enable this feature with UpdateEventSourcesConfig.</li>; <li>api-change:<code>macie</code>: [<code>botocore</code>] Amazon Macie Classic (macie) has been discontinued and is no longer available. A new Amazon Macie (macie2) is now available with significant design improvements and additional features.</li>; <li>api-change:<code>ec2</code>: [<code>botocore</code>] Documentation updates for Amazon EC2.</li>; <li>api-change:<code>sts</code>: [<code>botocore</code>] Documentation updates for AWS Security Token Service.</li>; <li>api-change:<code>connect</code>: [<code>botocore</code>] This release updates the *InstanceStorageConfig APIs so they support a new ResourceType: REAL_TIME_CONTACT_ANALYSIS_SEGMENTS. Use this resource type to enable streaming for real-time contact analysis and to associate the Kinesis stream where real-time contact analysis segments will be published.</li>; </ul>; <h1>1.21.12</h1>; <ul>; <li>api-change:<code>greengrassv2</code>: [<code>botocore</code>] Doc only update that clarifies Create Deployment section.</li>; <li>api-change:<code>fsx</code>: [<code>botocore</code>] This release adds support for data repository associations to use root (&quot;/&quot;) as the fil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11504:980,avail,available,980,https://hail.is,https://github.com/hail-is/hail/pull/11504,1,['avail'],['available']
Availability,"Bumps [boto3](https://github.com/boto/boto3) from 1.26.7 to 1.26.17.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/boto/boto3/blob/develop/CHANGELOG.rst"">boto3's changelog</a>.</em></p>; <blockquote>; <h1>1.26.17</h1>; <ul>; <li>bugfix:dynamodb: Fixes duplicate serialization issue in DynamoDB BatchWriter</li>; <li>api-change:<code>backup</code>: [<code>botocore</code>] AWS Backup introduces support for legal hold and application stack backups. AWS Backup Audit Manager introduces support for cross-Region, cross-account reports.</li>; <li>api-change:<code>cloudwatch</code>: [<code>botocore</code>] Update cloudwatch client to latest version</li>; <li>api-change:<code>drs</code>: [<code>botocore</code>] Non breaking changes to existing APIs, and additional APIs added to support in-AWS failing back using AWS Elastic Disaster Recovery.</li>; <li>api-change:<code>ecs</code>: [<code>botocore</code>] This release adds support for ECS Service Connect, a new capability that simplifies writing and operating resilient distributed applications. This release updates the TaskDefinition, Cluster, Service mutation APIs with Service connect constructs and also adds a new ListServicesByNamespace API.</li>; <li>api-change:<code>efs</code>: [<code>botocore</code>] Update efs client to latest version</li>; <li>api-change:<code>iot-data</code>: [<code>botocore</code>] This release adds support for MQTT5 properties to AWS IoT HTTP Publish API.</li>; <li>api-change:<code>iot</code>: [<code>botocore</code>] Job scheduling enables the scheduled rollout of a Job with start and end times and a customizable end behavior when end time is reached. This is available for continuous and snapshot jobs. Added support for MQTT5 properties to AWS IoT TopicRule Republish Action.</li>; <li>api-change:<code>iotwireless</code>: [<code>botocore</code>] This release includes a new feature for customers to calculate the position of their devices by adding three new APIs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12507:876,Recover,Recovery,876,https://hail.is,https://github.com/hail-is/hail/pull/12507,2,"['Recover', 'resilien']","['Recovery', 'resilient']"
Availability,"Bumps [click](https://github.com/pallets/click) from 8.1.1 to 8.1.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/click/releases"">click's releases</a>.</em></p>; <blockquote>; <h2>8.1.2</h2>; <p>This is a fix release for the <a href=""https://github.com/pallets/click/releases/tag/8.1.0"">8.1.0</a> feature release.</p>; <ul>; <li>Changes: <a href=""https://click.palletsprojects.com/en/8.1.x/changes/#version-8-1-2"">https://click.palletsprojects.com/en/8.1.x/changes/#version-8-1-2</a></li>; <li>Milestone: <a href=""https://github.com/pallets/click/milestone/17?closed=1"">https://github.com/pallets/click/milestone/17?closed=1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/click/blob/main/CHANGES.rst"">click's changelog</a>.</em></p>; <blockquote>; <h2>Version 8.1.2</h2>; <p>Released 2022-03-31</p>; <ul>; <li>Fix error message for readable path check that was mixed up with the; executable check. :pr:<code>2236</code></li>; <li>Restore parameter order for <code>Path</code>, placing the <code>executable</code>; parameter at the end. It is recommended to use keyword arguments; instead of positional arguments. :issue:<code>2235</code></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/click/commit/030f53cf677ee1de534359c535d465eed0ec1d99""><code>030f53c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2238"">#2238</a> from pallets/release-8.1.2</li>; <li><a href=""https://github.com/pallets/click/commit/2f1c35a43652e565802c230dbc47a9a358a0c6fd""><code>2f1c35a</code></a> release version 8.1.2</li>; <li><a href=""https://github.com/pallets/click/commit/77dd30f8c54ebbdfbf461cedcd3d1fc1d7673f95""><code>77dd30f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2237"">#2237</a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11726:965,error,error,965,https://hail.is,https://github.com/hail-is/hail/pull/11726,1,['error'],['error']
Availability,"Bumps [comm](https://github.com/ipython/comm) from 0.2.1 to 0.2.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/ipython/comm/releases"">comm's releases</a>.</em></p>; <blockquote>; <h2>v0.2.2</h2>; <h2>0.2.2</h2>; <p>(<a href=""https://github.com/ipython/comm/compare/v0.2.1...76149e7ee0f331772c964ae86cdb8bafebe6dfa2"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Update Release Scripts <a href=""https://redirect.github.com/ipython/comm/pull/27"">#27</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; </ul>; <h3>Other merged PRs</h3>; <ul>; <li>chore: update pre-commit hooks <a href=""https://redirect.github.com/ipython/comm/pull/26"">#26</a> (<a href=""https://github.com/pre-commit-ci""><code>@pre-commit-ci</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/ipython/comm/graphs/contributors?from=2024-01-02&amp;to=2024-03-12&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Aipython%2Fcomm+involves%3Ablink1073+updated%3A2024-01-02..2024-03-12&amp;type=Issues""><code>@blink1073</code></a> | <a href=""https://github.com/search?q=repo%3Aipython%2Fcomm+involves%3Apre-commit-ci+updated%3A2024-01-02..2024-03-12&amp;type=Issues""><code>@pre-commit-ci</code></a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/ipython/comm/blob/main/CHANGELOG.md"">comm's changelog</a>.</em></p>; <blockquote>; <h2>0.2.2</h2>; <p>(<a href=""https://github.com/ipython/comm/compare/v0.2.1...76149e7ee0f331772c964ae86cdb8bafebe6dfa2"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Update Release Scripts <a href=""https://redirect.github.com/ipython/comm/pull/27"">#27</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; </ul>; <h3>Other merged PRs</h3>; <ul>; <li>chore: ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14492:395,Mainten,Maintenance,395,https://hail.is,https://github.com/hail-is/hail/pull/14492,1,['Mainten'],['Maintenance']
Availability,"Bumps [cryptography](https://github.com/pyca/cryptography) from 38.0.4 to 39.0.1.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyca/cryptography/blob/main/CHANGELOG.rst"">cryptography's changelog</a>.</em></p>; <blockquote>; <p>39.0.1 - 2023-02-07</p>; <pre><code>; * **SECURITY ISSUE** - Fixed a bug where ``Cipher.update_into`` accepted Python; buffer protocol objects, but allowed immutable buffers. **CVE-2023-23931**; * Updated Windows, macOS, and Linux wheels to be compiled with OpenSSL 3.0.8.; <p>.. _v39-0-0:</p>; <p>39.0.0 - 2023-01-01; </code></pre></p>; <ul>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for OpenSSL 1.1.0 has been removed.; Users on older version of OpenSSL will need to upgrade.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for LibreSSL &lt; 3.5. The new; minimum LibreSSL version is 3.5.0. Going forward our policy is to support; versions of LibreSSL that are available in versions of OpenBSD that are; still receiving security support.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Removed the <code>encode_point</code> and; <code>from_encoded_point</code> methods on; :class:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicNumbers</code>,; which had been deprecated for several years.; :meth:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicKey.public_bytes</code>; and; :meth:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicKey.from_encoded_point</code>; should be used instead.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for using MD5 or SHA1 in; :class:<code>~cryptography.x509.CertificateBuilder</code>, other X.509 builders, and; PKCS7 has been removed.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for macOS 10.10 and 10.11, macOS; users must upgrade to 10.12 or newer.</li>; <li><strong>ANNOUNCEMENT:</strong> The next version of <code>cryptography</code> (40.0) will change;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:966,avail,available,966,https://hail.is,https://github.com/hail-is/hail/pull/12668,4,['avail'],['available']
Availability,"Bumps [cryptography](https://github.com/pyca/cryptography) from 42.0.2 to 42.0.4.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyca/cryptography/blob/main/CHANGELOG.rst"">cryptography's changelog</a>.</em></p>; <blockquote>; <p>42.0.4 - 2024-02-20</p>; <pre><code>; * Fixed a null-pointer-dereference and segfault that could occur when creating; a PKCS#12 bundle. Credit to **Alexander-Programming** for reporting the; issue. **CVE-2024-26130**; * Fixed ASN.1 encoding for PKCS7/SMIME signed messages. The fields ``SMIMECapabilities``; and ``SignatureAlgorithmIdentifier`` should now be correctly encoded according to the; definitions in :rfc:`2633` :rfc:`3370`.; <p>.. _v42-0-3:</p>; <p>42.0.3 - 2024-02-15; </code></pre></p>; <ul>; <li>Fixed an initialization issue that caused key loading failures for some; users.</li>; </ul>; <p>.. _v42-0-2:</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/fe18470f7d05f963e7267e34fdf985d81ea6ceea""><code>fe18470</code></a> Bump for 42.0.4 release (<a href=""https://redirect.github.com/pyca/cryptography/issues/10445"">#10445</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/aaa2dd06ed470695de818405a982d4c459869803""><code>aaa2dd0</code></a> Fix ASN.1 issues in PKCS#7 and S/MIME signing (<a href=""https://redirect.github.com/pyca/cryptography/issues/10373"">#10373</a>) (<a href=""https://redirect.github.com/pyca/cryptography/issues/10442"">#10442</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/7a4d012991061974da5d9cb7614de65eac94f49b""><code>7a4d012</code></a> Fixes <a href=""https://redirect.github.com/pyca/cryptography/issues/10422"">#10422</a> -- don't crash when a PKCS#12 key and cert don't match (<a href=""https://redirect.github.com/pyca/cryptography/issues/10423"">#10423</a>) ...</li>; <li><a href=""https://github.com/pyca/cryptography/commit/df314bb182bdfd661333969a94325e4680d785f6""><",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14332:836,failure,failures,836,https://hail.is,https://github.com/hail-is/hail/pull/14332,3,['failure'],['failures']
Availability,"Bumps [curlylint](https://github.com/thibaudcolas/curlylint) from 0.12.0 to 0.13.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/thibaudcolas/curlylint/releases"">curlylint's releases</a>.</em></p>; <blockquote>; <h2>v0.13.0 Quality-of-life improvements</h2>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.13.0"">v0.13.0</a> 2021-04-24</h2>; <p>This release comes with a blog post! Read on <a href=""https://www.curlylint.org/blog/quality-of-life-improvements"">Quality-of-life improvements</a>.</p>; <h3>Added</h3>; <ul>; <li>Implement --template-tags CLI flag (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/25"">#25</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/77"">#77</a>).</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Add more descriptive error message for missing whitespace between HTML attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/23#issuecomment-700622837"">#23 (comment)</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Move development dependencies from extras to separate <code>requirements.txt</code> (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Declare support for Python 3.9.</li>; <li>Tentatively declare support for Python 3.10 (tested with <code>Python 3.10.0a6+</code>).</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix Python 3.10 deprecation warning by importing Iterable from collections.abc (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; </ul>; <h2>v0.12.2</h2>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.2"">v0.12.2</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The <code>image_alt</code> rule no longer crashes when encountering template conditionals in img attributes (<a href=""https://github-redirect.dependa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11494:878,error,error,878,https://hail.is,https://github.com/hail-is/hail/pull/11494,2,['error'],['error']
Availability,"Bumps [de.undercouch.download](https://github.com/michel-kraemer/gradle-download-task) from 3.2.0 to 5.2.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/michel-kraemer/gradle-download-task/releases"">de.undercouch.download's releases</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Use pooling connection manager of Apache HttpClient instead of basic one. The basic one is not meant to be used by multiple threads. This fixes an issue that could cause an <code>IllegalStateException</code> with the message <code>Connection is still allocated</code>. Thanks to <a href=""https://github.com/dmarks2""><code>@dmarks2</code></a> for spotting this.</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>eachFile</code> method that adds an action to be applied to each source URL before it is downloaded. The action can be used to modify the filename of the target file.</li>; <li>Add <code>runAsync</code> method to download extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:21,down,download,21,https://hail.is,https://github.com/hail-is/hail/pull/12332,6,"['Mainten', 'down']","['Maintenance', 'download', 'download-task', 'downloaded']"
Availability,"Bumps [de.undercouch.download](https://github.com/michel-kraemer/gradle-download-task) from 3.2.0 to 5.3.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/michel-kraemer/gradle-download-task/releases"">de.undercouch.download's releases</a>.</em></p>; <blockquote>; <h2>5.3.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>path</code> and <code>relativePath</code> properties to the <code>DownloadDetails</code> class so <code>eachFile</code> actions can also change the relative path of a target file and not only its name</li>; <li>Duplicate destination files are now prevented. Specifying a duplicate destination file (e.g. in an <code>eachFile</code> action) will lead to an exception being thrown.</li>; </ul>; <p>Bug fixes:</p>; <ul>; <li>Call <code>eachFile</code> action only once per source</li>; <li>Correctly create list of output files (even if the destination is the project's build directory)</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Use pooling connection manager of Apache HttpClient instead of basic one. The basic one is not meant to be used by multiple threads. This fixes an issue that could cause an <code>IllegalStateException</code> with the message <code>Connection is still allocated</code>. Thanks to <a href=""https://github.com/dmarks2""><code>@dmarks2</code></a> for spotting this.</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>eachFile</code> method that adds an action to be applied to each source URL before it is downloaded. The action can be used to modify the filename of the target file.</li>; <li>Add <code>runAsync</code> method to download extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:21,down,download,21,https://hail.is,https://github.com/hail-is/hail/pull/12345,6,"['Down', 'Mainten', 'down']","['DownloadDetails', 'Maintenance', 'download', 'download-task']"
Availability,"Bumps [de.undercouch.download](https://github.com/michel-kraemer/gradle-download-task) from 5.3.0 to 5.3.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/michel-kraemer/gradle-download-task/releases"">de.undercouch.download's releases</a>.</em></p>; <blockquote>; <h2>5.3.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Downgrade slf4j to fix warning on console about missing slf4j provider</li>; <li>Allow <code>download</code> and <code>verify</code> extensions to be created on demand in custom tasks, so these tasks can be made compatible with Gradle's configuration cache (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/284"">#284</a>). Thanks to <a href=""https://github.com/liblit""><code>@liblit</code></a> for testing!</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; <li>Improve documentation</li>; <li>Add integration tests for Gradle 6.9.3 and 7.6</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a0374fc7c895ae53309ea351e989571204e0ea5f""><code>a0374fc</code></a> Bump up version number to 5.3.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/612f57a382b8640cc730dc5e75d1c809e3e772bd""><code>612f57a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/291"">#291</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/53af1049f5514afe58e884d487d7c57dae47759d""><code>53af104</code></a> Bump http-cache-semantics from 4.1.0 to 4.1.1 in /screencast</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/398c14c05c6448b380ac35c6095598299c5e23c5""><code>398c14c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:21,down,download,21,https://hail.is,https://github.com/hail-is/hail/pull/12707,8,"['Down', 'Mainten', 'down']","['Downgrade', 'Maintenance', 'download', 'download-task']"
Availability,"Bumps [de.undercouch.download](https://github.com/michel-kraemer/gradle-download-task) from 5.3.1 to 5.4.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/michel-kraemer/gradle-download-task/releases"">de.undercouch.download's releases</a>.</em></p>; <blockquote>; <h2>5.4.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to set request <code>method</code> and <code>body</code></li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; <li>Improve documentation</li>; <li>Add integration tests for Gradle 8.0.1</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4c983ed5cd229fa64912294737c858c2ba8486d6""><code>4c983ed</code></a> Bump up version number to 5.4.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/cc20442ab67bf37687c08e67af7e7de3a21c8fbe""><code>cc20442</code></a> Add integration tests for Gradle 8.0.2</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/472920e572e4cf45d321868874ced50ad8d1e2d5""><code>472920e</code></a> Add possibility to set request method and body</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/82e70cae2a8d48b4f5165a9b543d4e65bb793d88""><code>82e70ca</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86a15f1c16eb729dc71b6caf30237d07b8e0bb01""><code>86a15f1</code></a> Fix compiler warnings and deprecations</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86363072c8239330b28976109a622bdd073507b6""><code>8636307</code></a> Negative timeouts are actually not allowed</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4ff0ff0e63e0dd45f231990d0dcebffde6e6b709""><code>4ff0ff0</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:21,down,download,21,https://hail.is,https://github.com/hail-is/hail/pull/12893,7,"['Mainten', 'down']","['Maintenance', 'download', 'download-task']"
Availability,"Bumps [dictdiffer](https://github.com/inveniosoftware/dictdiffer) from 0.8.1 to 0.9.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/inveniosoftware/dictdiffer/releases"">dictdiffer's releases</a>.</em></p>; <blockquote>; <h2>Dictdiffer v0.9.0</h2>; <ul>; <li>Adds absolute tolerance feature for floats (<a href=""https://github.com/adrien-berchet""><code>@adrien-berchet</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/152"">#152</a>)</li>; <li>Drops support of Python&lt;3.5 (<a href=""https://github.com/adrien-berchet""><code>@adrien-berchet</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/160"">#160</a>)</li>; <li>Adds <code>assert_no_diff</code> helper to assist pytest users (<a href=""https://github.com/joesolly""><code>@joesolly</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/153"">#153</a>)</li>; <li>Migrates CI to gh-actions (<a href=""https://github.com/ParthS007""><code>@ParthS007</code></a> <a href=""https://github.com/diegodelemos""><code>@diegodelemos</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/145"">#145</a>)</li>; <li>Removes dependency on pkg_resources (<a href=""https://github.com/eldruin""><code>@eldruin</code></a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/inveniosoftware/dictdiffer/blob/master/CHANGES"">dictdiffer's changelog</a>.</em></p>; <blockquote>; <h1>Changes</h1>; <p>Version 0.9.0 (released 2021-07-22)</p>; <ul>; <li>Adds absolute tolerance feature for floats (<a href=""https://github.com/adrien-berchet""><code>@adrien-berchet</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/152"">#152</a>)</li>; <li>Drops support of Python&lt;3.5 (<a href=""https://github.com/adrien-berchet""><code>@adrien-be",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11485:321,toler,tolerance,321,https://hail.is,https://github.com/hail-is/hail/pull/11485,1,['toler'],['tolerance']
Availability,"Bumps [docker](https://github.com/docker/docker-py) from 5.0.3 to 6.0.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/docker/docker-py/releases"">docker's releases</a>.</em></p>; <blockquote>; <h2>6.0.1</h2>; <h2> Bugfixes</h2>; <ul>; <li>Fix for <code>The pipe has been ended</code> errors on Windows (<a href=""https://github-redirect.dependabot.com/docker/docker-py/issues/3056"">#3056</a>)</li>; <li>Support floats for timestamps in Docker logs (<code>since</code> / <code>until</code>) (<a href=""https://github-redirect.dependabot.com/docker/docker-py/issues/3031"">#3031</a>)</li>; </ul>; <h2>What's Changed</h2>; <ul>; <li>docs: install package in ReadTheDocs build by <a href=""https://github.com/milas""><code>@milas</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3032"">docker/docker-py#3032</a></li>; <li>Use latest stable syntax for Dockerfiles by <a href=""https://github.com/thaJeztah""><code>@thaJeztah</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3035"">docker/docker-py#3035</a></li>; <li>feat: add support for floats to docker logs params since / until sinc by <a href=""https://github.com/ArchiMoebius""><code>@ArchiMoebius</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3031"">docker/docker-py#3031</a></li>; <li>Change prune test to use anonymous volumes by <a href=""https://github.com/cpuguy83""><code>@cpuguy83</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3051"">docker/docker-py#3051</a></li>; <li>socket: handle npipe close by <a href=""https://github.com/nicks""><code>@nicks</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3056"">docker/docker-py#3056</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/ArchiMoebius""><code>@ArchiMoebius</code></a> made their first contribution in <a href=""https://github-redirect.de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12475:333,error,errors,333,https://hail.is,https://github.com/hail-is/hail/pull/12475,1,['error'],['errors']
Availability,"Bumps [elasticsearch-spark-20_2.12](https://github.com/elastic/elasticsearch-hadoop) from 7.17.1 to 8.4.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch-hadoop/releases"">elasticsearch-spark-20_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.4.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html</a></p>; <h2>Elasticsearch Hadoop 8.4.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""htt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12358:348,Down,Downloads,348,https://hail.is,https://github.com/hail-is/hail/pull/12358,6,"['Down', 'down']","['Downloads', 'downloads']"
Availability,"Bumps [elasticsearch-spark-20_2.12](https://github.com/elastic/elasticsearch-hadoop) from 8.4.3 to 8.6.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch-hadoop/releases"">elasticsearch-spark-20_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.6.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:347,Down,Downloads,347,https://hail.is,https://github.com/hail-is/hail/pull/12601,6,"['Down', 'down']","['Downloads', 'downloads']"
Availability,"Bumps [elasticsearch-spark-20_2.12](https://github.com/elastic/elasticsearch-hadoop) from 8.4.3 to 8.6.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch-hadoop/releases"">elasticsearch-spark-20_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.6.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.1.html</a></p>; <h2>Elasticsearch Hadoop 8.6.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:347,Down,Downloads,347,https://hail.is,https://github.com/hail-is/hail/pull/12623,6,"['Down', 'down']","['Downloads', 'downloads']"
Availability,"Bumps [elasticsearch-spark-30_2.12](https://github.com/elastic/elasticsearch-hadoop) from 8.0.0 to 8.4.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch-hadoop/releases"">elasticsearch-spark-30_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.4.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html</a></p>; <h2>Elasticsearch Hadoop 8.4.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:347,Down,Downloads,347,https://hail.is,https://github.com/hail-is/hail/pull/12319,6,"['Down', 'down']","['Downloads', 'downloads']"
Availability,"Bumps [filelock](https://github.com/tox-dev/py-filelock) from 3.7.1 to 3.8.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/tox-dev/py-filelock/releases"">filelock's releases</a>.</em></p>; <blockquote>; <h2>3.8.0</h2>; <h2>What's Changed</h2>; <ul>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/149"">tox-dev/py-filelock#149</a></li>; <li>Bump actions/upload-artifact from 2 to 3 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/154"">tox-dev/py-filelock#154</a></li>; <li>Bump actions/download-artifact from 2 to 3 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/152"">tox-dev/py-filelock#152</a></li>; <li>Bump pre-commit/action from 2.0.3 to 3.0.0 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/151"">tox-dev/py-filelock#151</a></li>; <li>Bump actions/checkout from 2 to 3 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/153"">tox-dev/py-filelock#153</a></li>; <li>Bump actions/setup-python from 2 to 4 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/150"">tox-dev/py-filelock#150</a></li>; <li>Add timeout unit to docstrings by <a href=""https://github.com/jnordberg""><code>@jnordberg</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/148"">tox-dev/py-filelock#148</a></li>; <li>Unify badges style by <a href=""https://github.com/DeadNews""><code>@DeadNews</code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12157:784,down,download-artifact,784,https://hail.is,https://github.com/hail-is/hail/pull/12157,1,['down'],['download-artifact']
Availability,"Bumps [flake8](https://github.com/pycqa/flake8) from 3.8.3 to 4.0.1.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/flake8/commit/82b698e09996cdde5d473e234681d8380810d7a2""><code>82b698e</code></a> Release 4.0.1</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/0fac346d8437d205e508643253c7a7d5fdf5dee7""><code>0fac346</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/flake8/issues/1410"">#1410</a> from PyCQA/parallel-syntax-error</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/aa54693c9ec03368c6e592efff4dd4757dd72a47""><code>aa54693</code></a> fix parallel execution collecting a SyntaxError</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/d31c5356bbb0a884555662185697ddc6bb46a44c""><code>d31c535</code></a> Release 4.0.0</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/afd2399b4cc9b27c4e8a5c2dec8444df8f480293""><code>afd2399</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/flake8/issues/1407"">#1407</a> from asottile/setup-cfg-fmt</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/960cf8cf2044359d5fbd3454a2a9a1d7a0586594""><code>960cf8c</code></a> rerun setup-cfg-fmt (and restore comments)</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/d7baba5f14091e7975d2abb3ba9bf321b5be6102""><code>d7baba5</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/flake8/issues/1406"">#1406</a> from asottile/update-versions</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/d79021aafc809d999c4cbbc0a513a5ceb473efa2""><code>d79021a</code></a> update dependency versions</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/283f0c81241673221d9628beb11e2d7356826f00""><code>283f0c8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/flake8/issues/1404"">#1404</a> from PyCQA/drop-xdg-config</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/807904aebc20814ac595b0004ab526fff",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11456:503,error,error,503,https://hail.is,https://github.com/hail-is/hail/pull/11456,2,['error'],['error']
Availability,"Bumps [gidgethub](https://github.com/brettcannon/gidgethub) from 4.2.0 to 5.2.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/brettcannon/gidgethub/releases"">gidgethub's releases</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <ul>; <li>; <p>Fix cgi and importlib_resources deprecations.; [PR <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/185"">#185</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/pull/185"">brettcannon/gidgethub#185</a>)</p>; </li>; <li>; <p>Add support for Python 3.11 and drop EOL Python 3.6; [PR <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/184"">#184</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/pull/184"">brettcannon/gidgethub#184</a>)</p>; </li>; </ul>; <h2>5.2.0</h2>; <ul>; <li>Make the minimum version of PyJWT be v2.4.0.</li>; </ul>; <h2>5.1.0</h2>; <ul>; <li>; <p>Use <code>X-Hub-Signature-256</code> header for webhook validation when available.; ([PR <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/160"">#160</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/pull/160"">brettcannon/gidgethub#160</a>)).</p>; </li>; <li>; <p>The documentation is now built using Sphinx v&gt;= 4.0.0.; ([Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/143"">#143</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/143"">brettcannon/gidgethub#143</a>))</p>; </li>; <li>; <p><code>gidgethub.abc.GitHubAPI.getiter</code> now accepts <code>iterable_key</code> parameter; in order to support the Checks API.; ([Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/164"">#164</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/164"">brettcannon/gidgethub#164</a>))</p>; </li>; <li>; <p>Accept HTTP 202 ACCEPTED as successful.; ([PR <a href=""https://github",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:1029,avail,available,1029,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['avail'],['available']
Availability,"Bumps [junixsocket-core](https://github.com/kohlschutter/junixsocket) from 2.3.2 to 2.6.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/kohlschutter/junixsocket/releases"">junixsocket-core's releases</a>.</em></p>; <blockquote>; <h2>junixsocket 2.6.1</h2>; <ul>; <li>Add AFSocket.checkConnectionClosed to probe connection status</li>; <li>Fix connection status checks and error handling</li>; <li>Fix bind behavior on Windows, support re-bind with reuseAddress</li>; <li>Fix and improve unit tests/selftests, remove several false-positive errors found in the wild (Azure Cloudshell/Microsoft CBL-Mariner 2.0, Amazon EC2, OpenBSD, etc.)</li>; <li>Fix SimpleTestServer demo, actually counting now to 5, not 6.</li>; <li>Make builds reproducible, align timestamps with git commit</li>; </ul>; <p>NOTE: If you're seeing unexpected errors in selftest, please verify with the attached <code>junixsocket-selftest-2.6.1-hotpatch-jar-with-dependencies.jar</code>. There may be false-positive socket timeout issues on very slow machines (e.g., qemu s390).</p>; <h2>junixsocket 2.6.0</h2>; <ul>; <li>Add support for GraalVM native-image</li>; <li>Add support for native-image selftest</li>; <li>Add support for AF_VSOCK (on Linux, and some macOS VMs)</li>; <li>Reintroduce deprecated legacy constructors for AFUNIXSocketAddress that were removed in 2.5.0.</li>; <li>Parent POM has been renamed from junixsocket-parent to junixsocket</li>; </ul>; <h2>junixsocket 2.5.2</h2>; <ul>; <li>Fix address handling in the Abstract Namespace</li>; <li>Fix support for very large datagrams (&gt; 1MB)</li>; <li>Fix InetAddress-wrapping of long addresses</li>; <li>Update Xcode support script, crossclang</li>; <li>Bump postgresql version in demo code</li>; <li>Fix dependency for custom architecture artifact</li>; </ul>; <h2>junixsocket 2.5.1</h2>; <ul>; <li>Add support for IBM z/OS (experimental, binary not included)</li>; <li>Add support for building from source on arm64",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12483:420,error,error,420,https://hail.is,https://github.com/hail-is/hail/pull/12483,3,['error'],"['error', 'errors']"
Availability,"Bumps [jupyter-client](https://github.com/jupyter/jupyter_client) from 7.3.1 to 7.3.4.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_client/releases"">jupyter-client's releases</a>.</em></p>; <blockquote>; <h2>v7.3.4</h2>; <h2>7.3.4</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.3...ca4cb2d6a4b95a6925de85a47b323d2235032c74"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Revert latest changes to <code>ThreadedZMQSocketChannel</code> because they break Qtconsole <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/803"">#803</a> (<a href=""https://github.com/ccordoba12""><code>@ccordoba12</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Fix sphinx 5.0 support <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/804"">#804</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>[pre-commit.ci] pre-commit autoupdate <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/799"">#799</a> (<a href=""https://github.com/pre-commit-ci""><code>@pre-commit-ci</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2022-06-07&amp;to=2022-06-08&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2022-06-07..2022-06-08&amp;type=Issues""><code>@blink1073</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Accordoba12+updated%3A2022-06-07..2022-06-08&amp;type=Issues""><code>@ccordoba12</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Apre-commit-ci+updated%3A2022-06-07..2022-06-08&amp;type=Issues""><code>@pre-commit-ci</code></a></p>; <h2>v7.3.3</h2>; <h2>7.3.3</h2>; <p>(<a href=""https:/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12110:743,Mainten,Maintenance,743,https://hail.is,https://github.com/hail-is/hail/pull/12110,1,['Mainten'],['Maintenance']
Availability,"Bumps [jupyter-client](https://github.com/jupyter/jupyter_client) from 7.4.4 to 7.4.5.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_client/releases"">jupyter-client's releases</a>.</em></p>; <blockquote>; <h2>v7.4.5</h2>; <h2>7.4.5</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.4.4...d27c8a497c6cbb1a232fbbe75cb1fd0f53faa9b0"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>[7.x] Handle Jupyter Core Warning <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/875"">#875</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Clean up 7.x workflows <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/865"">#865</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2022-10-25&amp;to=2022-11-10&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2022-10-25..2022-11-10&amp;type=Issues""><code>@blink1073</code></a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_client/blob/v7.4.5/CHANGELOG.md"">jupyter-client's changelog</a>.</em></p>; <blockquote>; <h2>7.4.5</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.4.4...d27c8a497c6cbb1a232fbbe75cb1fd0f53faa9b0"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>[7.x] Handle Jupyter Core Warning <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/875"">#875</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Clean up 7.x workflows <a href=""https://github-redirect.dependabot.com/jupyter/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12459:445,Mainten,Maintenance,445,https://hail.is,https://github.com/hail-is/hail/pull/12459,1,['Mainten'],['Maintenance']
Availability,"Bumps [jupyter-client](https://github.com/jupyter/jupyter_client) from 7.4.8 to 8.0.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_client/releases"">jupyter-client's releases</a>.</em></p>; <blockquote>; <h2>v8.0.2</h2>; <h2>8.0.2</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v8.0.1...717d36edcd9ce595f727d8b5a27e270c2a6e2c46"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Add papermill downstream check and fix kernel client replies <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/925"">#925</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Adopt more ruff rules <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/924"">#924</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Prefer print in kernelspecapp <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/923"">#923</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2023-01-26&amp;to=2023-01-30&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2023-01-26..2023-01-30&amp;type=Issues""><code>@blink1073</code></a></p>; <h2>v8.0.1</h2>; <h2>8.0.1</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v8.0.0...dc6113c360e05122430b8e130374e9f4e4b701d7"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Fix json_output in kernelspec app <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/921"">#921</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12656:486,down,downstream,486,https://hail.is,https://github.com/hail-is/hail/pull/12656,2,"['Mainten', 'down']","['Maintenance', 'downstream']"
Availability,"Bumps [jupyter-core](https://github.com/jupyter/jupyter_core) from 5.7.1 to 5.7.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_core/releases"">jupyter-core's releases</a>.</em></p>; <blockquote>; <h2>v5.7.2</h2>; <h2>5.7.2</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_core/compare/v5.7.1...1264a81fc834f18db2b41e136ec4ac9d1a4ad993"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Update Release Scripts <a href=""https://redirect.github.com/jupyter/jupyter_core/pull/396"">#396</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Enforce pytest 7 <a href=""https://redirect.github.com/jupyter/jupyter_core/pull/393"">#393</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>chore: update pre-commit hooks <a href=""https://redirect.github.com/jupyter/jupyter_core/pull/392"">#392</a> (<a href=""https://github.com/pre-commit-ci""><code>@pre-commit-ci</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_core/graphs/contributors?from=2024-01-08&amp;to=2024-03-12&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_core+involves%3Ablink1073+updated%3A2024-01-08..2024-03-12&amp;type=Issues""><code>@blink1073</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_core+involves%3Apre-commit-ci+updated%3A2024-01-08..2024-03-12&amp;type=Issues""><code>@pre-commit-ci</code></a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_core/blob/main/CHANGELOG.md"">jupyter-core's changelog</a>.</em></p>; <blockquote>; <h2>5.7.2</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_core/compare/v5.7.1...1264a81fc834f18db2b41e136ec4ac9d1a4ad993"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep impr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14484:435,Mainten,Maintenance,435,https://hail.is,https://github.com/hail-is/hail/pull/14484,1,['Mainten'],['Maintenance']
Availability,"Bumps [jupyterlab](https://github.com/jupyterlab/jupyterlab) from 4.0.9 to 4.0.12.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/jupyterlab/jupyterlab/releases"">jupyterlab's releases</a>.</em></p>; <blockquote>; <h2>v4.0.12</h2>; <h2>4.0.12</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/compare/v4.0.11...69079ec413cbe6d173f0a667c15802b76423ece5"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Fix jupyterlab downgrade issue on extension installation <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15650"">#15650</a> (<a href=""https://github.com/Sarthug99""><code>@Sarthug99</code></a>)</li>; <li>Fix search highlights removal on clearing input box <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15690"">#15690</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Add scroll margin to headings for better alignment <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15703"">#15703</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Fix shortcut UI failing on filtering when empty command is given <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15695"">#15695</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Fix connection loop issue with standalone foreign document in LSP <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15262"">#15262</a> (<a href=""https://github.com/trungleduc""><code>@trungleduc</code></a>)</li>; <li>Fix outputarea package from not detecting updates <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15642"">#15642</a> (<a href=""https://github.com/MFA-X-AI""><code>@MFA-X-AI</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15524"">#15524</a>: Fix visual tests <a href=""https://redirect.github.com/jupyter",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:480,down,downgrade,480,https://hail.is,https://github.com/hail-is/hail/pull/14218,1,['down'],['downgrade']
Availability,"Bumps [nbsphinx](https://github.com/spatialaudio/nbsphinx) from 0.8.3 to 0.8.8.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/spatialaudio/nbsphinx/releases"">nbsphinx's releases</a>.</em></p>; <blockquote>; <h2>nbsphinx 0.8.8</h2>; <p><a href=""https://pypi.org/project/nbsphinx/0.8.8/"">https://pypi.org/project/nbsphinx/0.8.8/</a></p>; <ul>; <li>Support for the <code>sphinx_codeautolink</code> extension</li>; <li>Basic support for the <code>text</code> builder</li>; </ul>; <h2>nbsphinx 0.8.7</h2>; <p><a href=""https://pypi.org/project/nbsphinx/0.8.7/"">https://pypi.org/project/nbsphinx/0.8.7/</a></p>; <ul>; <li>Fix assertion error in LaTeX build with Sphinx 4.1.0+</li>; </ul>; <h2>nbsphinx 0.8.6</h2>; <p><a href=""https://pypi.org/project/nbsphinx/0.8.6/"">https://pypi.org/project/nbsphinx/0.8.6/</a></p>; <ul>; <li>Support for Jinja2 version 3</li>; </ul>; <h2>nbsphinx 0.8.5</h2>; <p><a href=""https://pypi.org/project/nbsphinx/0.8.5/"">https://pypi.org/project/nbsphinx/0.8.5/</a></p>; <ul>; <li>Freeze Jinja2 version to 2.11 (for now, until a bugfix is found)</li>; <li>Add <code>theme_comparison.py</code> tool for creating multiple versions (with different HTML themes) of the docs at once</li>; </ul>; <h2>nbsphinx 0.8.4</h2>; <p><a href=""https://pypi.org/project/nbsphinx/0.8.4/"">https://pypi.org/project/nbsphinx/0.8.4/</a></p>; <ul>; <li>Support for <code>mathjax3_config</code> (for Sphinx &gt;= 4)</li>; <li>Force loading MathJax on HTML pages generated from notebooks (can be disabled with <code>nbsphinx_assume_equations = False</code>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/spatialaudio/nbsphinx/blob/master/NEWS.rst"">nbsphinx's changelog</a>.</em></p>; <blockquote>; <p>Version 0.8.8 -- 2021-12-31 -- PyPI__ -- diff__</p>; <ul>; <li>Support for the <code>sphinx_codeautolink</code> extension</li>; <li>Basic support for the <code>text</code> b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11477:677,error,error,677,https://hail.is,https://github.com/hail-is/hail/pull/11477,1,['error'],['error']
Availability,"Bumps [nest-asyncio](https://github.com/erdewit/nest_asyncio) from 1.5.4 to 1.5.6.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/erdewit/nest_asyncio/commit/fe3616358ce3cd7fdd5d50acb50020ac6eb6902b""><code>fe36163</code></a> Remove old travis file</li>; <li><a href=""https://github.com/erdewit/nest_asyncio/commit/5d3795ca0f2024d6e4d475101560e1dc96db93e9""><code>5d3795c</code></a> v1.5.6</li>; <li><a href=""https://github.com/erdewit/nest_asyncio/commit/9dd34446e87ad5bc30d6f151932d7f26899f0a31""><code>9dd3444</code></a> Add Python 3.11 support</li>; <li><a href=""https://github.com/erdewit/nest_asyncio/commit/ae731dcc2a779f4c27e0188100a72fb7ac2f129a""><code>ae731dc</code></a> Update test workflow, add mypy and flake8</li>; <li><a href=""https://github.com/erdewit/nest_asyncio/commit/99d4ddde7c1df05537f6a31f5e9adf1c9c80fdb7""><code>99d4ddd</code></a> Fix flake8 and mypy errors</li>; <li><a href=""https://github.com/erdewit/nest_asyncio/commit/8b5ec6c6fda3d45eab0cd08af1f9cf49855ebbcf""><code>8b5ec6c</code></a> v1.5.5</li>; <li><a href=""https://github.com/erdewit/nest_asyncio/commit/3cfd2c8bc453174ec0be57cd3bb8ec16dbcde1b4""><code>3cfd2c8</code></a> Potential fix for issue <a href=""https://github-redirect.dependabot.com/erdewit/nest_asyncio/issues/65"">#65</a></li>; <li><a href=""https://github.com/erdewit/nest_asyncio/commit/616d9a5e15d8d75e3343422778e49af2e9ac80ea""><code>616d9a5</code></a> Patch asyncio.get_event_loop to not require a running loop, fixes <a href=""https://github-redirect.dependabot.com/erdewit/nest_asyncio/issues/70"">#70</a></li>; <li>See full diff in <a href=""https://github.com/erdewit/nest_asyncio/compare/v1.5.4...v1.5.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nest-asyncio&package-manager=pip&previous-version=1.5.4&new-version=1.5.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12303:904,error,errors,904,https://hail.is,https://github.com/hail-is/hail/pull/12303,1,['error'],['errors']
Availability,"Bumps [notebook](https://github.com/jupyter/notebook) from 7.0.6 to 7.0.7.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/notebook/releases"">notebook's releases</a>.</em></p>; <blockquote>; <h2>v7.0.7</h2>; <h2>7.0.7</h2>; <p>(<a href=""https://github.com/jupyter/notebook/compare/@jupyter-notebook/application-extension@7.0.6...089c78c48fd00b2b0d2f33e4463eb42018e86803"">Full Changelog</a>)</p>; <h3>Enhancements made</h3>; <ul>; <li>Update to JupyterLab 4.0.11 <a href=""https://redirect.github.com/jupyter/notebook/pull/7215"">#7215</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Update ruff config and typing <a href=""https://redirect.github.com/jupyter/notebook/pull/7145"">#7145</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Clean up lint handling <a href=""https://redirect.github.com/jupyter/notebook/pull/7142"">#7142</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Adopt ruff format <a href=""https://redirect.github.com/jupyter/notebook/pull/7132"">#7132</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>[7.0.x] Install stable JupyterLab 4.0 in the releaser hook <a href=""https://redirect.github.com/jupyter/notebook/pull/7183"">#7183</a> (<a href=""https://github.com/jtpio""><code>@jtpio</code></a>)</li>; <li>Update publish-release workflow for PyPI trusted publisher <a href=""https://redirect.github.com/jupyter/notebook/pull/7176"">#7176</a> (<a href=""https://github.com/jtpio""><code>@jtpio</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/notebook/graphs/contributors?from=2023-10-17&amp;to=2024-01-19&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fnotebook+involves%3Abrichet+updated%3A2023-10-17..2024-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14182:680,Mainten,Maintenance,680,https://hail.is,https://github.com/hail-is/hail/pull/14182,1,['Mainten'],['Maintenance']
Availability,"Bumps [numpy](https://github.com/numpy/numpy) from 1.21.6 to 1.23.4.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/numpy/numpy/releases"">numpy's releases</a>.</em></p>; <blockquote>; <h2>v1.23.4</h2>; <h1>NumPy 1.23.4 Release Notes</h1>; <p>NumPy 1.23.4 is a maintenance release that fixes bugs discovered after; the 1.23.3 release and keeps the build infrastructure current. The main; improvements are fixes for some annotation corner cases, a fix for a; long time <code>nested_iters</code> memory leak, and a fix of complex vector dot; for very large arrays. The Python versions supported for this release; are 3.8-3.11.</p>; <p>Note that the mypy version needs to be 0.981+ if you test using Python; 3.10.7, otherwise the typing tests will fail.</p>; <h2>Contributors</h2>; <p>A total of 8 people contributed to this release. People with a &quot;+&quot; by; their names contributed a patch for the first time.</p>; <ul>; <li>Bas van Beek</li>; <li>Charles Harris</li>; <li>Matthew Barber</li>; <li>Matti Picus</li>; <li>Ralf Gommers</li>; <li>Ross Barnowski</li>; <li>Sebastian Berg</li>; <li>Sicheng Zeng +</li>; </ul>; <h2>Pull requests merged</h2>; <p>A total of 13 pull requests were merged for this release.</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22368"">#22368</a>: BUG: Add <code>__array_api_version__</code> to <code>numpy.array_api</code> namespace</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22370"">#22370</a>: MAINT: update sde toolkit to 9.0, fix download link</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22382"">#22382</a>: BLD: use macos-11 image on azure, macos-1015 is deprecated</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22383"">#22383</a>: MAINT: random: remove <code>get_info</code> from &quot;extending with Cython&quot;...</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pul",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12441:307,mainten,maintenance,307,https://hail.is,https://github.com/hail-is/hail/pull/12441,1,['mainten'],['maintenance']
Availability,"Bumps [numpy](https://github.com/numpy/numpy) from 1.21.6 to 1.23.5.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/numpy/numpy/releases"">numpy's releases</a>.</em></p>; <blockquote>; <h2>v1.23.5</h2>; <h1>NumPy 1.23.5 Release Notes</h1>; <p>NumPy 1.23.5 is a maintenance release that fixes bugs discovered after; the 1.23.4 release and keeps the build infrastructure current. The; Python versions supported for this release are 3.8-3.11.</p>; <h2>Contributors</h2>; <p>A total of 7 people contributed to this release. People with a &quot;+&quot; by; their names contributed a patch for the first time.</p>; <ul>; <li><a href=""https://github.com/DWesl""><code>@DWesl</code></a></li>; <li>Aayush Agrawal +</li>; <li>Adam Knapp +</li>; <li>Charles Harris</li>; <li>Navpreet Singh +</li>; <li>Sebastian Berg</li>; <li>Tania Allard</li>; </ul>; <h2>Pull requests merged</h2>; <p>A total of 10 pull requests were merged for this release.</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22489"">#22489</a>: TST, MAINT: Replace most setup with setup_method (also teardown)</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22490"">#22490</a>: MAINT, CI: Switch to cygwin/cygwin-install-action@v2</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22494"">#22494</a>: TST: Make test_partial_iteration_cleanup robust but require leak...</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22592"">#22592</a>: MAINT: Ensure graceful handling of large header sizes</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22593"">#22593</a>: TYP: Spelling alignment for array flag literal</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22594"">#22594</a>: BUG: Fix bounds checking for <code>random.logseries</code></li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22595"">#22595</a>: DEV: Update ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12515:307,mainten,maintenance,307,https://hail.is,https://github.com/hail-is/hail/pull/12515,1,['mainten'],['maintenance']
Availability,"Bumps [numpy](https://github.com/numpy/numpy) from 1.21.6 to 1.24.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/numpy/numpy/releases"">numpy's releases</a>.</em></p>; <blockquote>; <h2>v1.24.2</h2>; <h1>NumPy 1.24.2 Release Notes</h1>; <p>NumPy 1.24.2 is a maintenance release that fixes bugs and regressions; discovered after the 1.24.1 release. The Python versions supported by; this release are 3.8-3.11.</p>; <h2>Contributors</h2>; <p>A total of 14 people contributed to this release. People with a &quot;+&quot; by; their names contributed a patch for the first time.</p>; <ul>; <li>Bas van Beek</li>; <li>Charles Harris</li>; <li>Khem Raj +</li>; <li>Mark Harfouche</li>; <li>Matti Picus</li>; <li>Panagiotis Zestanakis +</li>; <li>Peter Hawkins</li>; <li>Pradipta Ghosh</li>; <li>Ross Barnowski</li>; <li>Sayed Adel</li>; <li>Sebastian Berg</li>; <li>Syam Gadde +</li>; <li>dmbelov +</li>; <li>pkubaj +</li>; </ul>; <h2>Pull requests merged</h2>; <p>A total of 17 pull requests were merged for this release.</p>; <ul>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22965"">#22965</a>: MAINT: Update python 3.11-dev to 3.11.</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22966"">#22966</a>: DOC: Remove dangling deprecation warning</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22967"">#22967</a>: ENH: Detect CPU features on FreeBSD/powerpc64*</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22968"">#22968</a>: BUG: np.loadtxt cannot load text file with quoted fields separated...</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22969"">#22969</a>: TST: Add fixture to avoid issue with randomizing test order.</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22970"">#22970</a>: BUG: Fix fill violating read-only flag. (<a href=""https://redirect.github.com/numpy/numpy/issues/22959"">#22959</a>)</li>; <li><a href=""https://redirect.github.com/numpy/numpy/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12898:307,mainten,maintenance,307,https://hail.is,https://github.com/hail-is/hail/pull/12898,1,['mainten'],['maintenance']
Availability,"Bumps [orjson](https://github.com/ijl/orjson) from 3.6.4 to 3.6.7.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/ijl/orjson/releases"">orjson's releases</a>.</em></p>; <blockquote>; <h2>3.6.7</h2>; <h3>Changed</h3>; <ul>; <li>Improve performance of deserializing almost-empty documents.</li>; <li>Publish arm7l <code>manylinux_2_17</code> wheels to PyPI.</li>; <li>Publish amd64 <code>musllinux_1_1</code> wheels to PyPI.</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix build requiring <code>python</code> on <code>PATH</code>.</li>; </ul>; <h2>3.6.6</h2>; <h3>Changed</h3>; <ul>; <li>Improve performance of serializing <code>datetime.datetime</code> using <code>tzinfo</code> that; are <code>zoneinfo.ZoneInfo</code>.</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix invalid indexing in line and column number reporting in; <code>JSONDecodeError</code>.</li>; <li>Fix <code>orjson.OPT_STRICT_INTEGER</code> not raising an error on; values exceeding a 64-bit integer maximum.</li>; </ul>; <h2>3.6.5</h2>; <h3>Fixed</h3>; <ul>; <li>Fix build on macOS aarch64 CPython 3.10.</li>; <li>Fix build issue on 32-bit.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/ijl/orjson/blob/master/CHANGELOG.md"">orjson's changelog</a>.</em></p>; <blockquote>; <h2>3.6.7 - 2022-02-14</h2>; <h3>Changed</h3>; <ul>; <li>Improve performance of deserializing almost-empty documents.</li>; <li>Publish arm7l <code>manylinux_2_17</code> wheels to PyPI.</li>; <li>Publish amd4 <code>musllinux_1_1</code> wheels to PyPI.</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix build requiring <code>python</code> on <code>PATH</code>.</li>; </ul>; <h2>3.6.6 - 2022-01-21</h2>; <h3>Changed</h3>; <ul>; <li>Improve performance of serializing <code>datetime.datetime</code> using <code>tzinfo</code> that; are <code>zoneinfo.ZoneInfo</code>.</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix invalid indexing in line and column number",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11572:959,error,error,959,https://hail.is,https://github.com/hail-is/hail/pull/11572,1,['error'],['error']
Availability,"Bumps [pandas](https://github.com/pandas-dev/pandas) from 1.3.0 to 1.4.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pandas-dev/pandas/releases"">pandas's releases</a>.</em></p>; <blockquote>; <h2>Pandas 1.4.1</h2>; <p>This is the first patch release in the 1.4.x series and includes some regression fixes and bug fixes. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4.1/whatsnew/v1.4.1.html"">full whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <h2>Pandas 1.4.0</h2>; <p>This release includes some new features, bug fixes, and performance improvements. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4.0/whatsnew/v1.4.0.html"">full whatsnew</a> for a list of all the changes. pandas 1.4.0 supports Python 3.8 and higher.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install -c conda-forge pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <h2>Pandas 1.4.0rc0</h2>; <p>We are pleased to announce a release candidate for pandas 1.4.0. If all goes well, we'll release pandas 1.4.0 in about two weeks.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4/whatsnew/v1.4.0.html"">whatsnew</a> for a list of all the changes. pandas 1.4.0 supports Python 3.8 and higher.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11539:600,avail,available,600,https://hail.is,https://github.com/hail-is/hail/pull/11539,1,['avail'],['available']
Availability,"Bumps [pandas](https://github.com/pandas-dev/pandas) from 1.3.5 to 1.5.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pandas-dev/pandas/releases"">pandas's releases</a>.</em></p>; <blockquote>; <h2>Pandas 1.5.0</h2>; <p>This release includes some new features, bug fixes, and performance improvements. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.5.0/whatsnew/v1.5.0.html"">full whatsnew</a> for a list of all the changes. pandas 1.5.0 supports Python 3.8 and higher.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <p><code>conda install -c conda-forge pandas</code></p>; <p>Or via PyPI:</p>; <p><code>python3 -m pip install --upgrade pandas</code></p>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <h2>Pandas 1.5.0rc0</h2>; <p>We are pleased to announce a release candidate for pandas 1.5.0. If all goes well, we'll release pandas 1.5.0 in about two weeks.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.5/whatsnew/v1.5.0.html"">whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on conda-forge and PyPI.</p>; <p>The release can be installed from PyPI</p>; <pre><code>python -m pip install --upgrade --pre pandas==1.5.0rc0; </code></pre>; <p>Or from conda-forge</p>; <pre><code>conda install -c conda-forge/label/pandas_rc pandas==1.5.0rc0; </code></pre>; <p>Please report any issues with the release candidate on the pandas issue tracker.</p>; <h2>Pandas 1.4.4</h2>; <p>This is a patch release in the 1.4.x series and includes some regression and bug fixes. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4.4/whatsnew/v1.4.4.html"">full whatsnew</a> for a list of all the changes.</p>; <p>The release will ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12292:625,avail,available,625,https://hail.is,https://github.com/hail-is/hail/pull/12292,1,['avail'],['available']
Availability,"Bumps [pandas](https://github.com/pandas-dev/pandas) from 1.3.5 to 1.5.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pandas-dev/pandas/releases"">pandas's releases</a>.</em></p>; <blockquote>; <h2>Pandas 1.5.2</h2>; <p>This is a patch release in the 1.5.x series and includes some regression and bug fixes. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.5.2/whatsnew/v1.5.2.html"">full whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <p>Thanks to all the contributors who made this release possible.</p>; <h2>Pandas 1.5.1</h2>; <p>This is a patch release in the 1.5.x series and includes some regression and bug fixes. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.5.1/whatsnew/v1.5.1.html"">full whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <p>Thanks to all the contributors who made this release possible.</p>; <h2>Pandas 1.5.0</h2>; <p>This release includes some new features, bug fixes, and performance improvements. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.5.0/whatsnew/v1.5.0.html"">full whats",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12564:586,avail,available,586,https://hail.is,https://github.com/hail-is/hail/pull/12564,1,['avail'],['available']
Availability,"Bumps [pandas](https://github.com/pandas-dev/pandas) from 1.3.5 to 1.5.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pandas-dev/pandas/releases"">pandas's releases</a>.</em></p>; <blockquote>; <h2>Pandas 1.5.3</h2>; <p>This is a patch release in the 1.5.x series and includes some regression and bug fixes. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.5.3/whatsnew/v1.5.3.html"">full whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <p>Thanks to all the contributors who made this release possible.</p>; <h2>Pandas 1.5.2</h2>; <p>This is a patch release in the 1.5.x series and includes some regression and bug fixes. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.5.2/whatsnew/v1.5.2.html"">full whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <p>Thanks to all the contributors who made this release possible.</p>; <h2>Pandas 1.5.1</h2>; <p>This is a patch release in the 1.5.x series and includes some regression and bug fixes. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.5.1/whatsnew/v1.5.1.html"">full",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12610:586,avail,available,586,https://hail.is,https://github.com/hail-is/hail/pull/12610,1,['avail'],['available']
Availability,"Bumps [pillow](https://github.com/python-pillow/Pillow) from 9.5.0 to 10.0.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/python-pillow/Pillow/releases"">pillow's releases</a>.</em></p>; <blockquote>; <h2>10.0.0</h2>; <p><a href=""https://pillow.readthedocs.io/en/stable/releasenotes/10.0.0.html"">https://pillow.readthedocs.io/en/stable/releasenotes/10.0.0.html</a></p>; <h2>Changes</h2>; <ul>; <li>Fixed deallocating mask images <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7246"">#7246</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Added ImageFont.MAX_STRING_LENGTH <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7244"">#7244</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Fix Windows build with pyproject.toml <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7230"">#7230</a> [<a href=""https://github.com/nulano""><code>@nulano</code></a>]</li>; <li>Do not close provided file handles with libtiff <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7199"">#7199</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Convert to HSV if mode is HSV in getcolor() <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7226"">#7226</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Added alpha_only argument to getbbox() <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7123"">#7123</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Prioritise speed in <em>repr_png</em> <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7242"">#7242</a> [<a href=""https://github.com/radarhere""><code>@radarhere</code></a>]</li>; <li>Limit size even if one dimension is zero in decompression bomb check <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7235"">#7235</a> [<a href=""h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13321:466,mask,mask,466,https://hail.is,https://github.com/hail-is/hail/pull/13321,1,['mask'],['mask']
Availability,"Bumps [psutil](https://github.com/giampaolo/psutil) from 5.8.0 to 5.9.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/giampaolo/psutil/blob/master/HISTORY.rst"">psutil's changelog</a>.</em></p>; <blockquote>; <h1>5.9.0</h1>; <p>2021-12-29</p>; <p><strong>Enhancements</strong></p>; <ul>; <li>1851_, [Linux]: <code>cpu_freq()</code>_ is slow on systems with many CPUs. Read current; frequency values for all CPUs from <code>/proc/cpuinfo</code> instead of opening many; files in <code>/sys</code> fs. (patch by marxin)</li>; <li>1992_: <code>NoSuchProcess</code>_ message now specifies if the PID has been reused.</li>; <li>1992_: error classes (<code>NoSuchProcess</code><em>, <code>AccessDenied</code></em>, etc.) now have a better; formatted and separated <code>__repr__</code> and <code>__str__</code> implementations.</li>; <li>1996_, [BSD]: add support for MidnightBSD. (patch by Saeed Rasooli)</li>; <li>1999_, [Linux]: <code>disk_partitions()</code>_: convert <code>/dev/root</code> device (an alias; used on some Linux distros) to real root device path.</li>; <li>2005_: <code>PSUTIL_DEBUG</code> mode now prints file name and line number of the debug; messages coming from C extension modules.</li>; <li>2042_: rewrite HISTORY.rst to use hyperlinks pointing to psutil API doc.</li>; </ul>; <p><strong>Bug fixes</strong></p>; <ul>; <li>1456_, [macOS], <strong>[critical]</strong>: <code>cpu_freq()</code>_ <code>min</code> and <code>max</code> are set to; 0 if can't be determined (instead of crashing).</li>; <li>1512_, [macOS]: sometimes <code>Process.connections()</code>_ will crash with; <code>EOPNOTSUPP</code> for one connection; this is now ignored.</li>; <li>1598_, [Windows]: <code>disk_partitions()</code>_ only returns mountpoints on drives; where it first finds one.</li>; <li>1874_, [SunOS]: swap output error due to incorrect range.</li>; <li>1892_, [macOS]: <code>cpu_freq()</code>_ broken on Apple M1.</li>; <li>1901_, [macOS]: diff",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:674,error,error,674,https://hail.is,https://github.com/hail-is/hail/pull/11459,1,['error'],['error']
Availability,"Bumps [pylint](https://github.com/PyCQA/pylint) from 2.12.2 to 2.13.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/PyCQA/pylint/blob/main/ChangeLog"">pylint's changelog</a>.</em></p>; <blockquote>; <h1>What's New in Pylint 2.13.0?</h1>; <p>Release date: 2022-03-24</p>; <ul>; <li>; <p>Add missing dunder methods to <code>unexpected-special-method-signature</code> check.</p>; </li>; <li>; <p>No longer emit <code>no-member</code> in for loops that reference <code>self</code> if the binary operation that; started the for loop uses a <code>self</code> that is encapsulated in tuples or lists.</p>; <p>Ref <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1360"">PyCQA/astroid#1360</a>; Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/4826"">#4826</a></p>; </li>; <li>; <p>Output better error message if unsupported file formats are used with <code>pyreverse</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5950"">#5950</a></p>; </li>; <li>; <p>Fix pyreverse diagrams type hinting for classmethods and staticmethods.</p>; </li>; <li>; <p>Fix pyreverse diagrams type hinting for methods returning None.</p>; </li>; <li>; <p>Fix matching <code>--notes</code> options that end in a non-word character.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5840"">#5840</a></p>; </li>; <li>; <p>Updated the position of messages for class and function defintions to no longer cover; the complete definition. Only the <code>def</code> or <code>class</code> + the name of the class/function; are covered.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5466"">#5466</a></p>; </li>; <li>; <p><code>using-f-string-in-unsupported-version</code> and <code>using-final-decorator-in-unsupported-version</code> msgids; were renamed from <code>W1601</code> and <code>W1602</code> to <code>W2601</code> and <code>W2602</code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11674:875,error,error,875,https://hail.is,https://github.com/hail-is/hail/pull/11674,1,['error'],['error']
Availability,"Bumps [pytest](https://github.com/pytest-dev/pytest) from 7.1.1 to 7.1.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pytest-dev/pytest/releases"">pytest's releases</a>.</em></p>; <blockquote>; <h2>7.1.3</h2>; <h1>pytest 7.1.3 (2022-08-31)</h1>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/10060"">#10060</a>: When running with <code>--pdb</code>, <code>TestCase.tearDown</code> is no longer called for tests when the <em>class</em> has been skipped via <code>unittest.skip</code> or <code>pytest.mark.skip</code>.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/10190"">#10190</a>: Invalid XML characters in setup or teardown error messages are now properly escaped for JUnit XML reports.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/10230"">#10230</a>: Ignore <code>.py</code> files created by <code>pyproject.toml</code>-based editable builds introduced in <a href=""https://pip.pypa.io/en/stable/news/#v21-3"">pip 21.3</a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/3396"">#3396</a>: Doctests now respect the <code>--import-mode</code> flag.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9514"">#9514</a>: Type-annotate <code>FixtureRequest.param</code> as <code>Any</code> as a stop gap measure until <code>8073</code>{.interpreted-text role=&quot;issue&quot;} is fixed.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9791"">#9791</a>: Fixed a path handling code in <code>rewrite.py</code> that seems to work fine, but was incorrect and fails in some systems.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9917"">#9917</a>: Fixed string representation for <code>pytest.approx</code>{.interpreted-text role=&quot;func&quot;} when used to compare tuples.</li>; </ul>; <h2>Imp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12187:768,error,error,768,https://hail.is,https://github.com/hail-is/hail/pull/12187,1,['error'],['error']
Availability,"Bumps [regex](https://github.com/mrabarnett/mrab-regex) from 2023.3.23 to 2023.5.5.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/mrabarnett/mrab-regex/blob/hg/changelog.txt"">regex's changelog</a>.</em></p>; <blockquote>; <p>Version: 2023.5.5</p>; <pre><code>Removed semicolon after 'else' in 'munge_name'.; </code></pre>; <p>Version: 2023.5.4</p>; <pre><code>Fixed pyproject.toml and setup.py.; </code></pre>; <p>Version: 2023.5.3</p>; <pre><code>pyproject.toml was missing.; </code></pre>; <p>Version: 2023.5.2</p>; <pre><code>Added pyproject.toml.; </code></pre>; <p>Version: 2023.3.23</p>; <pre><code>Git issue 495: Running time for failing fullmatch increases rapidly with input length; Re-enabled modified repeat guards due to regression in speed caused by excessive backtracking.; </code></pre>; <p>Version: 2023.3.22</p>; <pre><code>Git issue 494: Backtracking failure matching regex `^a?(a?)b?c\1$` against string `abca`; Disabled repeat guards. They keep causing issues, and it's just simpler to rely on timeouts.; </code></pre>; <p>Version: 2022.10.31</p>; <pre><code>Updated text for supported Unicode and Python versions.; </code></pre>; <p>Version: 2022.9.13</p>; <pre><code>Updated to Unicode 15.0.0.; </code></pre>; <p>Version: 2022.9.11</p>; <pre><code>Updated version.; </code></pre>; <p>Version: 2022.8.17</p>; <pre><code>Git issue 477: \v for vertical spacing; <p>Added \p{HorizSpace} (\p{H}) and \p{VertSpace} (\p{V}).; </code></pre></p>; <p>Version: 2022.7.25</p>; <pre><code>Git issue 475: 2022.7.24 improperly released; <p>The file <a href=""https://pypi.org/pypi/regex/2022.7.24/json"">https://pypi.org/pypi/regex/2022.7.24/json</a> was missing references to most of the wheels, so this is a new release in the hope that it was just a glitch in GitHub Actions.; </code></pre></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12989:913,failure,failure,913,https://hail.is,https://github.com/hail-is/hail/pull/12989,1,['failure'],['failure']
Availability,"Bumps [rich](https://github.com/Textualize/rich) from 12.6.0 to 13.5.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Textualize/rich/releases"">rich's releases</a>.</em></p>; <blockquote>; <h2>v13.5.2</h2>; <p>Bugfix</p>; <h2>[13.5.2] - 2023-08-01</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs assertion error</li>; </ul>; <h2>v13.5.1</h2>; <p>Very minor update to URL highlighting</p>; <h2>[13.5.1] - 2023-07-31</h2>; <h3>Fixed</h3>; <ul>; <li>Fix tilde character (<code>~</code>) not included in link regex when printing to console <a href=""https://redirect.github.com/Textualize/rich/issues/3057"">Textualize/rich#3057</a></li>; </ul>; <h2>Mostly cake, one or two puppies</h2>; <p><a href=""https://textual.textualize.io/blog/2023/07/29/pull-requests-are-cake-or-puppies/"">https://textual.textualize.io/blog/2023/07/29/pull-requests-are-cake-or-puppies/</a></p>; <h2>[13.5.0] - 2023-07-29</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs not expanding spans.</li>; <li>Fixed TimeElapsedColumn from showing negative.</li>; <li>Fix for escaping strings with a trailing backslash <a href=""https://redirect.github.com/Textualize/rich/issues/2987"">Textualize/rich#2987</a></li>; <li>Fixed exception in Markdown with partial table <a href=""https://redirect.github.com/Textualize/rich/issues/3053"">Textualize/rich#3053</a></li>; <li>Fixed the HTML export template so that the <code>&lt;html&gt;</code> tag comes before the <code>&lt;head&gt;</code> tag <a href=""https://redirect.github.com/Textualize/rich/issues/3021"">Textualize/rich#3021</a></li>; <li>Fixed issue with custom classes overwriting <code>__eq__</code> <a href=""https://redirect.github.com/Textualize/rich/issues/2875"">Textualize/rich#2875</a></li>; <li>Fix rich.pretty.install breakage in iPython <a href=""https://redirect.github.com/Textualize/rich/issues/3013"">Textualize/rich#3013</a></li>; </ul>; <h3>Added</h3>; <ul>; <li>Added Text.extend_style method.</li>; <li>Added Spa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13380:361,error,error,361,https://hail.is,https://github.com/hail-is/hail/pull/13380,2,['error'],['error']
Availability,"Bumps [rich](https://github.com/Textualize/rich) from 12.6.0 to 13.5.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Textualize/rich/releases"">rich's releases</a>.</em></p>; <blockquote>; <h2>Markdown fixes</h2>; <h2>[13.5.3] - 2023-09-17</h2>; <h3>Fixed</h3>; <ul>; <li>Markdown table rendering issue with inline styles and links <a href=""https://redirect.github.com/Textualize/rich/issues/3115"">Textualize/rich#3115</a></li>; <li>Fix Markdown code blocks on a light background <a href=""https://redirect.github.com/Textualize/rich/issues/3123"">Textualize/rich#3123</a></li>; </ul>; <h2>v13.5.2</h2>; <p>Bugfix</p>; <h2>[13.5.2] - 2023-08-01</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs assertion error</li>; </ul>; <h2>v13.5.1</h2>; <p>Very minor update to URL highlighting</p>; <h2>[13.5.1] - 2023-07-31</h2>; <h3>Fixed</h3>; <ul>; <li>Fix tilde character (<code>~</code>) not included in link regex when printing to console <a href=""https://redirect.github.com/Textualize/rich/issues/3057"">Textualize/rich#3057</a></li>; </ul>; <h2>Mostly cake, one or two puppies</h2>; <p><a href=""https://textual.textualize.io/blog/2023/07/29/pull-requests-are-cake-or-puppies/"">https://textual.textualize.io/blog/2023/07/29/pull-requests-are-cake-or-puppies/</a></p>; <h2>[13.5.0] - 2023-07-29</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs not expanding spans.</li>; <li>Fixed TimeElapsedColumn from showing negative.</li>; <li>Fix for escaping strings with a trailing backslash <a href=""https://redirect.github.com/Textualize/rich/issues/2987"">Textualize/rich#2987</a></li>; <li>Fixed exception in Markdown with partial table <a href=""https://redirect.github.com/Textualize/rich/issues/3053"">Textualize/rich#3053</a></li>; <li>Fixed the HTML export template so that the <code>&lt;html&gt;</code> tag comes before the <code>&lt;head&gt;</code> tag <a href=""https://redirect.github.com/Textualize/rich/issues/3021"">Textualize/rich#3021</a></li>;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13651:756,error,error,756,https://hail.is,https://github.com/hail-is/hail/pull/13651,2,['error'],['error']
Availability,"Bumps [rich](https://github.com/Textualize/rich) from 12.6.0 to 13.6.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Textualize/rich/releases"">rich's releases</a>.</em></p>; <blockquote>; <h2>The Python 3.12 release</h2>; <p>Mostly a meta update in readiness for the release of Python3.12</p>; <h2>[13.6.0] - 2023-09-30</h2>; <h3>Added</h3>; <ul>; <li>Added Python 3.12 to classifiers.</li>; </ul>; <h2>Markdown fixes</h2>; <h2>[13.5.3] - 2023-09-17</h2>; <h3>Fixed</h3>; <ul>; <li>Markdown table rendering issue with inline styles and links <a href=""https://redirect.github.com/Textualize/rich/issues/3115"">Textualize/rich#3115</a></li>; <li>Fix Markdown code blocks on a light background <a href=""https://redirect.github.com/Textualize/rich/issues/3123"">Textualize/rich#3123</a></li>; </ul>; <h2>v13.5.2</h2>; <p>Bugfix</p>; <h2>[13.5.2] - 2023-08-01</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs assertion error</li>; </ul>; <h2>v13.5.1</h2>; <p>Very minor update to URL highlighting</p>; <h2>[13.5.1] - 2023-07-31</h2>; <h3>Fixed</h3>; <ul>; <li>Fix tilde character (<code>~</code>) not included in link regex when printing to console <a href=""https://redirect.github.com/Textualize/rich/issues/3057"">Textualize/rich#3057</a></li>; </ul>; <h2>Mostly cake, one or two puppies</h2>; <p><a href=""https://textual.textualize.io/blog/2023/07/29/pull-requests-are-cake-or-puppies/"">https://textual.textualize.io/blog/2023/07/29/pull-requests-are-cake-or-puppies/</a></p>; <h2>[13.5.0] - 2023-07-29</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs not expanding spans.</li>; <li>Fixed TimeElapsedColumn from showing negative.</li>; <li>Fix for escaping strings with a trailing backslash <a href=""https://redirect.github.com/Textualize/rich/issues/2987"">Textualize/rich#2987</a></li>; <li>Fixed exception in Markdown with partial table <a href=""https://redirect.github.com/Textualize/rich/issues/3053"">Textualize/rich#3053</a></li>; <li>Fixed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13758:967,error,error,967,https://hail.is,https://github.com/hail-is/hail/pull/13758,2,['error'],['error']
Availability,"Bumps [sphinx-rtd-theme](https://github.com/readthedocs/sphinx_rtd_theme) from 1.3.0 to 2.0.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/readthedocs/sphinx_rtd_theme/blob/master/docs/changelog.rst"">sphinx-rtd-theme's changelog</a>.</em></p>; <blockquote>; <h1>2.0.0</h1>; <h2>Added</h2>; <ul>; <li>Support for Sphinx versions <code>6.x</code> and <code>7.x</code></li>; <li>Support for docutils <code>&lt;=0.20</code></li>; </ul>; <h2>Deprecations</h2>; <ul>; <li>The HTML4 writer is now officially deprecated. An error will be thrown if your; project configuration still uses the HTML4 writer.</li>; <li>Support for Sphinx versions &lt; 5.0 was removed.</li>; <li>In addition, our supported dependencies will match the dependencies from our; lowest supported Sphinx release, version 5.0: Python &gt;= 3.6 and docutils &gt; 0.14 and &lt; 0.19</li>; </ul>; <p>.. _release-1.3.0:</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/7c9b1b5d391f6d7fae72274393eb25d1df96e546""><code>7c9b1b5</code></a> Release 2.0 final (<a href=""https://redirect.github.com/readthedocs/sphinx_rtd_theme/issues/1544"">#1544</a>)</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/c1044107602faf9be43e4358bc4f8b6abff9b420""><code>c104410</code></a> Bump for next potential release, 2.0.0rc5 (<a href=""https://redirect.github.com/readthedocs/sphinx_rtd_theme/issues/1539"">#1539</a>)</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/53ca116ef64123735e5e445258b8b103ad31a26e""><code>53ca116</code></a> Release 2.0.0rc4 (<a href=""https://redirect.github.com/readthedocs/sphinx_rtd_theme/issues/1538"">#1538</a>)</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/4498e97b462688bac2ff3615ac1da1b867b21842""><code>4498e97</code></a> Fix AttributeError when one of <code>css_files</code> is a string (<a href=""https://redire",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14502:562,error,error,562,https://hail.is,https://github.com/hail-is/hail/pull/14502,1,['error'],['error']
Availability,"Bundling working well now:. For instance, the addition of this file, which handles the auth0 callback/sets cookie, adds only *501B* despite importing Auth and react-easy-state :tada:. The entirety of Auth dependency, react-easy-state (just observable JS properties for easy event notification), js-cookie to simplify cookie management, all other imports that are used at least 2x, poly fills for IE11 compat (promises, object.assign) + React + React-Dom is 99KB, and served in parallel with the page, so initial render doesn't incur the cost. Not bad; we can get this down a bit by removing js-cookie (2KB). ```jsx; // TODO: Replace Loading component without Material UI; import { Component } from 'react';; import Router from 'next/router';; import { view } from 'react-easy-state';; import Auth from '../lib/Auth';. class Callback extends Component {; componentDidMount() {; Auth.handleAuthenticationAsync(err => {; // TODO: notify in modal if error; if (err) {; console.error('ERROR in callback!', err);; }. Router.push('/');; });; }. render() {; return !Auth.isAuthenticated() ? <div>Loading</div> : <div>Hello</div>;; }; }. export default view(Callback);; ```. <img width=""353"" alt=""screen shot 2018-12-19 at 5 06 59 pm"" src=""https://user-images.githubusercontent.com/5543229/50251076-ad695680-03b0-11e9-88f2-28d3ff7daa33.png"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-448761682:568,down,down,568,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-448761682,4,"['ERROR', 'down', 'error']","['ERROR', 'down', 'error']"
Availability,"By using Double and converting to Long:; 1) there may be off-by-one errors from what is expected (both 0.99999999 and -0.99999999 go to 0); 2) you can only represent positive integers up to 2^53 = 9e15 exactly, rather than 2^63:; https://en.wikipedia.org/wiki/Double-precision_floating-point_format#IEEE_754_double-precision_binary_floating-point_format:_binary64. So question is whether to create a Long version of aggregator for both Int and Long, analogous to Double for Float and Double.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1051#issuecomment-259964811:68,error,errors,68,https://hail.is,https://github.com/hail-is/hail/pull/1051#issuecomment-259964811,1,['error'],['errors']
Availability,Bytecode failed verification error with group_by,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4853:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/issues/4853,1,['error'],['error']
Availability,"C1). ```; hailctl dataproc start ; --autoscaling-policy={autoscaling_policy}; --worker-machine-type {worker_machine_type}; --region {region}; --project {gcs_project}; --service-account {account}; --num-master-local-ssds 1; --num-worker-local-ssds 1 ; --max-idle=60m; --max-age=1440m; --subnet=projects/{gcs_project}/regions/{region}/subnetworks/subnetwork; {cluster_name}; ```. </details>. I have the driver node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43 of 52223 MiB ( 0.08%), swap free: 0 of 0 MiB ( 0.00%); Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: low memory! at or below SIGTERM limits: mem 0.12%, swap 1.00%; Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM to process 8421 uid 0 ""java"": badness 1852, VmRSS 40578 MiB; ```. Indeed, the VmRSS is the memory in use from the kernel's perspe",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:1393,down,down,1393,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419,1,['down'],['down']
Availability,"CC: @danking . I tested this change works by replicating Lindo's job download (~80 Gi) on an overloaded node with 8 simultaneous jobs trying to download data in parallel. Before this proposed change and after I fixed some other issues in #10522, 75% of his jobs would fail with this error (the ones I presume on the persistent SSDs rather than the local SSDs):. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/usr/local/lib/python3.7/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/usr/local/lib/python3.7/site-packages/batch/copy/__main__.py"", line 34, in <module>; asyncio.run(main()); File ""/usr/local/lib/python3.7/asyncio/runners.py"", line 43, in run; return loop.run_until_complete(main); File ""/usr/local/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); concurrent.futures._base.CancelledError; ```. Now, all of the downloads succeed after my change. I found this link to be very helpful figuring out what the issue was. ; https://bugs.python.org/issue33413",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10534:69,down,download,69,https://hail.is,https://github.com/hail-is/hail/pull/10534,4,"['down', 'error']","['download', 'downloads', 'error']"
Availability,CHANGELOG: Add `hl.die` function that can be used to generate errors. Useful in data validation.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8865:62,error,errors,62,https://hail.is,https://github.com/hail-is/hail/pull/8865,1,['error'],['errors']
Availability,"CHANGELOG: Added a new method Job.regions() as well as a configurable parameter to the ServiceBackend to specify which cloud regions a job can run in. The default value is a job can run in any available region. Stacked on #12212 . This PR threads through region requests from the user and feeds that information into the scheduler. The architecture of a pool per machine type has not changed. We explicitly chose not to have a new pool per region x machine_type. Instead, the control loop looks at the front of the job queue and tries to predict which jobs are likely to be scheduled. From those jobs, we then find which regions the jobs can run in and create the number of corresponding instances. We use the fair share calculation to estimate how many jobs per user can be scheduled in 2.5 minutes assuming the scheduling loop runs once per second. We then grab this many jobs from the queue for each user and estimate the ""scheduling iteration"" at which each iteration of the scheduler each chunk of user jobs would be scheduled. We sort the overall set of jobs that we've chosen by the ""scheduling iteration"". We also include the regions as part of the sorting queries with None (any region) being sorted last. This is to compact the free cores across jobs so as to avoid fragmentation of instances created and for jobs with no region specifications to fill in the remaining cores in any region. For the hailtop.batch client, I added a new setting in `~/.config/hail` to set the default regions for all jobs in the ServiceBackend and a new method on `Job` that sets the list of regions to run in. Things to double check once everything is working is the sort orders on the scheduling queries are correct. . Once this PR goes in, then we can merge #11840 with some minor changes. There will also be a follow-up PR that gets rid of the CI-specific code in the scheduler.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12221:193,avail,available,193,https://hail.is,https://github.com/hail-is/hail/pull/12221,1,['avail'],['available']
Availability,"CHANGELOG: BatchPoolExecutor now raises an informative error message for a variety of ""system"" errors, such as missing container images. If the main container fails for reasons beyond BatchPoolExecutor's control, such; as a missing container image, we previously did not report these errors. In; fact, we encountered errors when trying to load the output file that cannot; exist if the main container errors. Smaller included changes:; - directly use the asynchronous, low-level client instead of the synchronous,; low-level client; - introduce an `async_cancel` now that we have access to the async client.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9543:55,error,error,55,https://hail.is,https://github.com/hail-is/hail/pull/9543,5,['error'],"['error', 'errors']"
Availability,CHANGELOG: Bokeh 3.x.x is now required which allows for compatibility with pandas 2.x.x. There were a lot of issues in this file that I tried to clean up. The mypy errors are now just things that are poorly typed by Bokeh. I also changed how manhattan plot hides irrelevant tooltip information. I made it an explicit argument to the `_get_scatter_plot_elements`. I verified the plots in the GWAS Tutorial look the same by eye. I also verified the tooltips look the same with a few spot checks. I also built the docs to ensure those were fine.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12927:164,error,errors,164,https://hail.is,https://github.com/hail-is/hail/pull/12927,1,['error'],['errors']
Availability,CHANGELOG: Changed cost per instance from $0.02170 to $0.021935 from switching to using local SSDs. - Added 1 local SSD (375 GB) and formatted it in the worker run script.; - Changed the resource for boot-disk to just disk and modified the worker config. I figured there was no reason to have a separate boot disk in the resources as long as all disks are assumed to be fractions of the instance based on the number of cores being used.; - Changed the worker boot disk from 100 GB to 20 GB; - Changed the worker to move all docker files and batch files to the Local SSD from the boot disk. Can you double check my math for the documentation?. Is it possible it takes longer for an instance to boot up with a local SSD? One of my earlier tests had workers stuck in STAGING. This resolved itself later on so I'm assuming it was a Google error.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8844:835,error,error,835,https://hail.is,https://github.com/hail-is/hail/pull/8844,1,['error'],['error']
Availability,"CHANGELOG: Fix #13356 and fix #13409. In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. I now assume we cannot reuse a ReadChannel after any exception occurs during read. We also do not assume that the ReadChannel ""atomically"", in some sense, modifies the ByteBuffer. In particular, if we encounter any error, we blow away the ByteBuffer and restart our read entirely. As I described in [this comment to #13409](https://github.com/hail-is/hail/issues/13409#issuecomment-1737926184), I have a 10K partition pipeline which was reliably producing this error but now reliably *does not* produce this error (it produces another one, #13721, fix forthcoming for that too).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13730:121,error,errors,121,https://hail.is,https://github.com/hail-is/hail/pull/13730,6,"['error', 'reliab']","['error', 'errors', 'reliably']"
Availability,CHANGELOG: Fix #13937 caused by faulty library code in the Google Cloud Storage API Java client library.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14022:32,fault,faulty,32,https://hail.is,https://github.com/hail-is/hail/pull/14022,1,['fault'],['faulty']
Availability,"CHANGELOG: Fix #13979, affecting Query-on-Batch and manifesting most frequently as ""com.github.luben.zstd.ZstdException: Corrupted block detected"". This PR upgrades google-cloud-storage from 2.29.1 to 2.30.1. The google-cloud-storage java library has a bug present at least since 2.29.0 in which simply incorrect data was returned. https://github.com/googleapis/java-storage/issues/2301 . The issue seems related to their use of multiple intremediate ByteBuffers. As far as I can tell, this is what could happen:. 1. If there's no channel, open a new channel with the current position.; 2. Read *some* data from the input ByteChannel into an intermediate ByteBuffer.; 3. While attempting to read more data into a subsequent intermediate ByteBuffer, an retryable exception occurs.; 4. The exception bubbles to google-cloud-storage's error handling, which frees the channel and loops back to (1). The key bug is that the intermediate buffers have data but the `position` hasn't been updated. When we recreate the channel we will jump to the wrong position and re-read some data. Lucky for us, between Zstd and our assertions, this usually crashes the program instead of silently returning bad data. This is the third bug we have found in Google's cloud storage java library. The previous two:. 1. https://github.com/hail-is/hail/issues/13721; 2. https://github.com/hail-is/hail/issues/13937. Be forewarned: the next time we see bizarre networking or data corruption issues, check if updating google-cloud-storage fixes the problem.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14080:832,error,error,832,https://hail.is,https://github.com/hail-is/hail/pull/14080,1,['error'],['error']
Availability,"CHANGELOG: Fix `RuntimeError: This event loop is already running` error when running hail in a Jupyter Notebook. Man this is really complicated. OK, so, things I learned:. 1. [asyncio will not create a new event loop if `set_event_loop` has been called even if `set_event_loop(None)` has since been called.](https://github.com/python/cpython/blob/main/Lib/asyncio/events.py#L676); 2. [asyncio will not create a new event loop in a thread other than the main thread.](https://github.com/python/cpython/blob/main/Lib/asyncio/events.py#L677); 3. `aiohttp.ClientSession` stashes a copy of the event loop present when it starts. This can cause all manner of extremely confusing behavior if you later change the event loop or use that session from a different thread. The fix, in the end, wasn't that complicated. Anywhere Hail explicitly asks for an event loop (so that we can run async code), we apply nest asyncio if the event loop is already running. Otherwise we do nothing. Nest asyncio appears to [no longer require](https://github.com/erdewit/nest_asyncio/tree/master#usage) `apply` to be called before the event loop starts running. This PR *does not* address:; 1. Hail nesting async code in sync code in async code. I think we should avoid this, but the `hailtop.fs` and `hailtop.batch` APIs, among others, need async versions before we can do that.; 2. This `aiohttp.ClientSession` nonsense. We really should take pains to ensure we create one `ClientSession` per loop and we never mix loops.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13899:66,error,error,66,https://hail.is,https://github.com/hail-is/hail/pull/13899,1,['error'],['error']
Availability,"CHANGELOG: Fix a major correctness bug ocurring when calling `BlockMatrix.transpose` on sparse BlockMatrices. Symmetric matrices are not affected. It seems like `BlockMatrix.transpose` has been broken for a while when the matrix is sparse. . I added `PerBlockMatrixSparsifier` as a way to sparsify particular blocks of a `BlockMatrix` from python. This is just so we can write tests / diagnose user errors based on sparsity patterns. I also wrote a helper function to sparsify numpy matrices for testing purposes. . The crucial fix here is to `GridPartitioner.transpose`. That function is supposed to return a pair of the form `(GridPartitioner, Int => Int)`, where the first of the pair is the new `GridPartitioner` for the transposed thing, and the second of the pair is a function that takes in a partition number and returns the partition number of its parent partition. Crucially, it's a function from new partition ids to old partition ids. I believe that code I'm removing did the opposite. Refresher on `GridPartitioner`: There are 3 coordinate systems:. There's ""coordinate"", which is (row, column). There's ""blockIndex"", which is the column major numbering of all blocks. And there's ""partitionIndex"", which is similar to numbering by blockIndex but it skips the sparse blocks",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8867:399,error,errors,399,https://hail.is,https://github.com/hail-is/hail/pull/8867,1,['error'],['errors']
Availability,CHANGELOG: Fix bug made more likely by 0.2.101 in which Hail errors when interacting with a NumPy integer or floating point type.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12278:61,error,errors,61,https://hail.is,https://github.com/hail-is/hail/pull/12278,1,['error'],['errors']
Availability,"CHANGELOG: Fix long-standing bug wherein `hl.agg.collect_as_set` and `hl.agg.counter` error when applied to types which, in Python, are unhashable. For example, `hl.agg.counter(t.list_of_genes)` will not error when `t.list_of_genes` is a list. Instead, the counter dictionary will use `FrozenList` keys from the `frozenlist` package. Hey @iris-garden ! I figured this was good reviewing practice for you and also a chance to see how we convert data to/from JSON and to/from the JVM (by way of this ""encoded"" representation which is a binary one). The details of that are not super important to this PR, but you might take a peek to understand the change. The main issue here is that in Python, you can't write:; ```; {[1]}; ```; Because sets must contain ""hashable"" data. Python lists are not hashable because they're mutable. This is transitively a problem. For example, the following also fails with the same error because the list inside the tuple is mutable thus the tuple is not (safely) hashable.; ```; {(""tuples"", ""are"", ""immutable"", [""lists"", ""are"", ""not""])}; ```. Hail's internal language is fully immutable, so every type can be placed inside a set (or used as the keys of a dict). When we convert from Hail's internal representation to Python, we cannot use mutable types in hashable positions. Unfortunately, we also need to maintain backwards compatibility with the way the code currently works. You can see this pretty clearly in the difference between `hl.agg.collect` and `hl.agg.collect_as_set`:; ```; t = hl.utils.range_table(1); t = t.annotate(ls = [1, 2, 3]); collected_ls = t.aggregate(hl.agg.collect(t.ls)); collected_as_set_ls = t.aggregate(hl.agg.collect_as_set(t.ls)); ```; `collected_ls` should be `[[1, 2, 3]]` whereas `collected_as_set_ls` necessarily uses hashable types: `{frozenlist([1, 2, 3])}`. Things are particularly subtle with dictionaries whose keys must always be hashable and whose values need only be hashable if the dictionary itself must be hashable. For exa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12265:86,error,error,86,https://hail.is,https://github.com/hail-is/hail/pull/12265,3,['error'],['error']
Availability,"CHANGELOG: Fixed #13346. Previously, when parsing VCFs, Hail failed on INFO or FORMAT fields with missing elements because the meaning of ""."" could be ambiguous. Hail now resovles the ambiguity, when possible, using the number of alleles. If the meaning is still ambiguous after considering the number of alleles, Hail uses a new `hl.import_vcf` parameter to resolve the ambiguity. See the `hl.import_vcf` docs for details. See https://github.com/hail-is/hail-rfcs/pull/8 for details on the problem and the solution. I assessed the effect of removing the `array_elements_required=True` fast path by evaluating the following code against this PR's tip commit `cd06c248e4` and `0.2.120` (`f00f916faf`). I ran it three times per commit and report each individual time as well as the average. ```; In [1]: import hail as hl. In [2]: %%time; ...: mt = hl.import_vcf(; ...: '/Users/dking/projects/hail-data/ALL.chr21.raw.HC.vcf.bgz'; ...: ); ...: mt._force_count_rows(); ```. | commit | run 1 (s) | run 2 (s) | run 3 (s) | average (s) | warm average (s) |; |--------------------------|-----------|-----------|-----------|-------------|------------------|; | `cd06c248e4` (this PR) | 116s | 80s | 77s | 91+-18 | 78.5 +- 1.5 |; | `f00f916faf` (`0.2.120`) | 112s | 80s | 79s | 90+-15 | 79.5 +- 0.5 |. This is what I expected. For a VCF with no ambiguity and few instances of ""."", we've added a very minor amount of new work. ---. Note that I had to specifically override the Number setting for certain FORMAT and INFO fields because they were set to `.` in the benchmarked VCF. If this error appears in a 1KG VCF, it must be fairly common.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13465:1577,error,error,1577,https://hail.is,https://github.com/hail-is/hail/pull/13465,1,['error'],['error']
Availability,"CHANGELOG: Fixed a bug in `hail.ggplot.scale_color_continuous` that sometimes caused errors by generating invalid colors. For example, this code:. ```python; import hail as hl; from hail.ggplot import ggplot, aes, geom_point; t = hl.utils.range_table(10); t = t.annotate(x=hl.rand_unif(), y=hl.rand_unif(), z=hl.rand_unif(1, 10)); fig = ggplot(t, aes(x=t.x, y=t.y, color=t.z)) + geom_point(); fig.show(); ```. Produces an error like this:. ```; ValueError:; Invalid element(s) received for the 'color' property of scatter.marker; Invalid elements include: ['rgb(-84, -187, 123)', 'rgb(-116, -227, 131)', 'rgb(-29, -120, 109)', 'rgb(-33, -125, 110)', 'rgb(15, -65, 97)', 'rgb(10, -71, 99)', 'rgb(-112, -223, 130)', 'rgb(-63, -162, 117)', 'rgb(-81, -185, 122)', 'rgb(31, -45, 93)']; ```. But after this change is applied, it produces a plot like this:. ![newplot(2)](https://github.com/hail-is/hail/assets/84595986/0da82782-2409-46f6-b924-eea72eb6ce97)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13609:85,error,errors,85,https://hail.is,https://github.com/hail-is/hail/pull/13609,2,['error'],"['error', 'errors']"
Availability,CHANGELOG: Fixed bug in reading tables/matrixtables with partition intervals that led to error or segfault.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12277:89,error,error,89,https://hail.is,https://github.com/hail-is/hail/pull/12277,1,['error'],['error']
Availability,"CHANGELOG: Fixed bugs in the identity by descent implementation for Query on Batch. This PR fixes #14052. There were two bugs in how we compute IBD. In addition, the tests weren't running in QoB and the test dataset we were using doesn't have enough variability to catch errors. I used Balding Nichols generated data instead. Do we need to set the seed in the tests here?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14062:271,error,errors,271,https://hail.is,https://github.com/hail-is/hail/pull/14062,1,['error'],['errors']
Availability,CHANGELOG: Fixed compiler errors related to interval filter pushdown.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9179:26,error,errors,26,https://hail.is,https://github.com/hail-is/hail/pull/9179,1,['error'],['errors']
Availability,"CHANGELOG: Fixed incorrect error message when incorrect type specifid with hl.loop. I added a test that gave a bad error message, then rearranged code in `hl.loop` to improve the error message. Prior to this change, the error a user would get here is that they wrote a loop that isn't tail recursive, because hail would insert an implicit cast when trying to unify types, and the casting would wrap the recursive loop call. Now, we check to make sure the loop's return type is correct before analyzing whether it's tail recursive, which I believe removes the possibility of getting a tail recursion error when you should be getting a type error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10174:27,error,error,27,https://hail.is,https://github.com/hail-is/hail/pull/10174,6,['error'],['error']
Availability,"CHANGELOG: Fixed issue where ndarrays being sliced and indexed into in one expression didn't have sufficient bounds checks. Fixes #9144 by checking if indices provided in a slicing expression that mixes slices and single indices are out of bounds. . Alex, please tell me if you're able to get anymore errors from #9144 with this change. I wasn't able to, but that issue was not super well defined at first so it's unclear to me if this covers all of your problems. I retitled the issue to reflect my understanding of the problems. . More detail:. In numpy, it is ok for the upper bound of a slice to go past the end of an array, but it is not ok for an indexing operation to do the same. For example:. ```; n = np.array([[1,2,3,4], [1,2,3,4]]); n[0:1000, 0:1000]; ```. is allowed, the bounds just get clamped. However, this is not allowed:. ```; n[1000, 1000]; ```. nor is:. ```; n[1000, 0:1000]; ```. Hail was not handling that last case with a mix of slices and indices correctly. Namely, it was not throwing an out bounds error on the first axis index.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9223:301,error,errors,301,https://hail.is,https://github.com/hail-is/hail/pull/9223,2,['error'],"['error', 'errors']"
Availability,CHANGELOG: Fixed the error 'Argument list too long: '/bin/sh'' when using the LocalBackend,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10508:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/pull/10508,1,['error'],['error']
Availability,"CHANGELOG: Fixes #13697, a long standing issue with QoB, in which a failing partition job or driver job is not failed in the Batch UI. I am not sure why we did not do this this way in the first place. If a JVMJob raises an exception, Batch will mark the job as failed. Ergo, we should raise an exception when a driver or a worker fails!. Here's an example: I used a simple pipeline that write to a bucket to which I have read-only access. You can see an example Batch (where every partition fails): https://batch.hail.is/batches/8046901. [1]. ```python3; import hail as hl; hl.utils.range_table(3, n_partitions=3).write('gs://neale-bge/foo.ht'); ```. NB: I removed the `log.error` in `handleForPython` because that log is never necessary. That function converts a stack of exceptions into a triplet of the short message, the full exception with stack trace, and a Hail error id (if present). That triplet is always passed along to someone else who logs the exception. (FWIW, the error id indicates a Python source location that is associated with the error. On the Python-side, we can look up that error id and provide a better stack trace.). [1] You'll notice the logs are missing. I noticed this as well, it's a new bug. I fixed it in https://github.com/hail-is/hail/pull/13729.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13715:674,error,error,674,https://hail.is,https://github.com/hail-is/hail/pull/13715,5,['error'],['error']
Availability,"CHANGELOG: Fixes #13704, in which Hail could encounter an IllegalArgumentException if there are too many transient errors. I need to do the multiplication in 64-bits so that it does not wrap around to a large negative value. Then I can use `math.min` with the maxDelayMs to get us back into 32-bits. I'm just pushing through a bunch of bugs to get Wenhan unblocked today.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13713:115,error,errors,115,https://hail.is,https://github.com/hail-is/hail/pull/13713,1,['error'],['errors']
Availability,"CHANGELOG: Hail Query-on-Batch previously used Class A Operations for all interaction with blobs. This change ensures that QoB only uses Class A Operations when necessary. Inspired by @jigold 's file system improvement campaign, I fell down the rabbit hole of not issuing ""list"" operations unless we really need to know if a file is a directory. This should partly help reduce the flakiness in Azure (which is tracked in #13351) as well as high costs in Azure both of which are at least partly suspected to be caused by our frequent use of ""list"" operations.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13450:236,down,down,236,https://hail.is,https://github.com/hail-is/hail/pull/13450,2,['down'],['down']
Availability,"CHANGELOG: Hail no longer officially supports Python 3.7. Combines https://github.com/hail-is/hail/pull/12927 and https://github.com/hail-is/hail/pull/12908. Many changes. All seem to be necessary together. ---. I fixed any new mypy errors or deprecation warnings. I also cleaned up plots.py (which isn't CI'd by mypy) because I was in there and it was a mess. I unified all our pip-tools versions. Require pandas 2 now. That requires Bokeh 3.x.x. Fix the pinned-requirements.txt dependencies so they reflect the actual necessary runtime harmony. Upgraded Sphinx. The method names lose their fixed-width styling but I think it looks fine. Version policy added. Updating everything means Jinja2 can jump to the latest version too. Numpy deprecated some of its types, using `_` gets rid of the warning.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12929:233,error,errors,233,https://hail.is,https://github.com/hail-is/hail/pull/12929,1,['error'],['errors']
Availability,"CHANGELOG: Hail supports identity_by_descent on Apple M1 and M2 chips; however, your Java installation must be an arm64 installation. Using x86_64 Java with Hail on Apple M1 or M2 will cause SIGILL errors. If you have an Apple M1 or Apple M2 and `/usr/libexec/java_home -V` does not include `(arm64)`, you must switch to an arm64 version of the JVM. Fixes (hail#14000). Fixes #14000. Hail has never supported its native functionality on Mac OS X Apple M1 chips. In particular, we only built x86_64 compatible dylibs. M1 chips will try to simulate a very basic x86_64 ISA using Rosetta 2 but our x86_64 dylibs expect the ISA of at least sandybridge, which includes some SIMD instructions not supported by Rosetta 2. This PR bifurcates our native build into x86_64 and arm64 targets which live in build/x86_64 and build/arm64, respectively. In Linux, this moves where the object files live, but should otherwise have no effect. The test and benchmark targets use the ""native"" build which always points at the x86_64 object files. The shared object targets, LIBBOOT & LIBHAIL, explicitly depend on x86_64 because that is the only linux architecture we support. In OS X, we only test and benchmark the ""native"" build, which is detected using `uname -m`. For the shared objects (the dylibs) we have four new files: libboot and libbhail for x86_64 and for arm64. Each pair files is placed in `darwin/x86_64/` and `darwin/arm64/`, respectively. Those dylibs are never meant to escape the src/main/c world. The LIBBOOT and LIBHAIL targets (which are invoked by hail/Makefile) combine the two architecture-specific dylibs into a ""universal"" dylib. You can verify this by running `file` on the dylibs. Here I run them on the new ""prebuilt"" files which are in this PR:. ```; (base) dking@wm28c-761 hail % file hail/prebuilt/lib/darwin/libboot.dylib; hail/prebuilt/lib/darwin/libboot.dylib: Mach-O universal binary with 2 architectures: [x86_64:Mach-O 64-bit dynamically linked shared library x86_64] [arm64:Mach-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14006:198,error,errors,198,https://hail.is,https://github.com/hail-is/hail/pull/14006,1,['error'],['errors']
Availability,"CHANGELOG: Improve error message when combining incompatibly indexed fields in certain operations including array indexing. See test cases for straightforward examples. In main, none of the test code triggers errors. You have to execute the table to actually trigger an error in IR serialization which will reference `""sa""` which is totally meaningless to the user (let alone many Hail engineers).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12566:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/12566,3,['error'],"['error', 'errors']"
Availability,"CHANGELOG: In Query-on-Batch, retries of certain errors has been increased from once to five times. This should reduce the occurrence of transient errors such as ""Connection reset"" and `SocketException`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13012:49,error,errors,49,https://hail.is,https://github.com/hail-is/hail/pull/13012,2,['error'],['errors']
Availability,"CHANGELOG: In Query-on-Batch, retries of certain errors has been increased from once to five times. This should reduce the occurrence of transient errors such as ""Connection reset"" and `SocketException`. ---. The old approach doesn't work because it doesn't have the retry logic around the invocation. Moreover, the old approach wouldn't retry transient errors encountered after a retry once error. The new approach address both.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13021:49,error,errors,49,https://hail.is,https://github.com/hail-is/hail/pull/13021,4,['error'],"['error', 'errors']"
Availability,"CHANGELOG: Introduce `hailctl fs sync` which robustly transfers one or more files between Amazon S3, Azure Blob Storage, and Google Cloud Storage. There are really two distinct conceptual changes remaining here. Given my waning time available, I am not going to split them into two pull requests. The changes are:. 1. `basename` always agrees with the [`basename` UNIX utility](https://en.wikipedia.org/wiki/Basename). In particular, the folder `/foo/bar/baz/`'s basename is *not* `''` it is `'baz'`. The only folders or objects whose basename is `''` are objects whose name literally ends in a slash, e.g. an *object* named `gs://foo/bar/baz/`. 2. `hailctl fs sync`, a robust copying tool with a user-friendly CLI. `hailctl fs sync` comprises two pieces: `plan.py` and `sync.py`. The latter, `sync.py` is simple: it delegates to our existing copy infrastructure. That copy infastructure has been lightly modified to support this use-case. The former, `plan.py`, is a concurrent file system `diff`. `plan.py` generates and `sync.py` consumes a ""plan folder"" containing these files:. 1. `matches` files whose names and sizes match. Two columns: source URL, destination URL. 2. `differs` files or folders whose names match but either differ in size or differ in type. Four columns: source URL, destination URL, source state, destination state. The states are either: `file`, `dif`, or a size. If either state is a size, both states are sizes. 3. `srconly` files only present in the source. One column: source URL. 4. `dstonly` files only present in the destination. One column: destination URL. 5. `plan` a proposed set of object-to-object copies. Two columns: source URL, destination URL. 6. `summary` a one-line file containing the total number of copies in plan and the total number of bytes which would be copied. As described in the CLI documentation, the intended use of these commands is:. ```; hailctl fs sync --make-plan plan1 --copy-to gs://gcs-bucket/a s3://s3-bucket/b; hailctl fs sync --use",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14248:45,robust,robustly,45,https://hail.is,https://github.com/hail-is/hail/pull/14248,3,"['avail', 'robust']","['available', 'robust', 'robustly']"
Availability,"CHANGELOG: Mitigate new transient error from Google Cloud Storage which manifests as `aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548)`. As of around 1500 ET 2023-10-16, this exception happens whenever we issue a lot of requests to GCS. See [Zulip thread](https://hail.zulipchat.com/#narrow/stream/300487-Hail-Batch-Dev/topic/cluster.20size/near/396777320).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13817:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/13817,1,['error'],['error']
Availability,"CHANGELOG: Raise an error instead of silently returning bad results when using a negative index with an `hl.nd.array`. In practice, I always saw this return a positive value very close to zero. We should fix this to just support Python-style indexing, but I wanted to fix ASAP given the severity.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12803:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/pull/12803,1,['error'],['error']
Availability,"CHANGELOG: Requester pays buckets now work in `hailtop.fs` and `hl.hadoop_*`. This has been broken since at least 0.2.115. I first check for an explicit argument or the standard hailctl configuration. If neither of those exist, I try to parse spark-defaults.conf with lots of error handling and warning.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13089:276,error,error,276,https://hail.is,https://github.com/hail-is/hail/pull/13089,1,['error'],['error']
Availability,"CHANGELOG: Since 0.2.110, `hailctl dataproc` set the heap size of the driver JVM dangerously high. It is now set to an appropriate level. This issue manifests in a variety of inscrutable ways including RemoteDisconnectedError and socket closed. See issue #13960 for details. In Dataproc versions 1.5.74, 2.0.48, and 2.1.0, Dataproc introduced [""memory protection""](https://cloud.google.com/dataproc/docs/support/troubleshoot-oom-errors#memory_protection) which is a euphemism for a newly aggressive OOMKiller. When the OOMKiller kills the JVM driver process, there is no hs_err_pid...log file, no exceptional log statements, and no clean shutdown of any sockets. The process is simply SIGTERM'ed and then SIGKILL'ed. From Hail 0.2.83 through Hail 0.2.109 (released February 2023), Hail was pinned to Dataproc 2.0.44. From Hail 0.2.15 onwards, `hailctl dataproc`, by default, reserves 80% of the advertised memory of the driver node for the use of the Hail Query Driver JVM process. For example, Google advertises that an n1-highmem-8 has 52 GiB of RAM, so Hail sets the `spark:spark.driver.memory` property to 41g (we always round down). Before aggressive memory protection, this setting was sufficient to protect the driver from starving itself of memory. Unfortunately, Hail 0.2.110 upgraded to Dataproc 2.1.2 which enabled ""memory protection"". Moreover, in the years since Hail 0.2.15, the memory in use by system processes on Dataproc driver nodes appears to have increased. Due to these two circumstances, the driver VM's memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14066:429,error,errors,429,https://hail.is,https://github.com/hail-is/hail/pull/14066,1,['error'],['errors']
Availability,"CHANGELOG: Teach `hailctl dataproc start` about `--expiration-time`. Teach `hailctl dataproc modify` about `--no-max-idle`, `no-max-age`, `--max-age`, and `--expiration-time`. These flags were always available as pass-throughs. This change adds them to the; help documentation and improves error messages in the case that an incompatible; set of arguments are provided together.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9263:200,avail,available,200,https://hail.is,https://github.com/hail-is/hail/pull/9263,2,"['avail', 'error']","['available', 'error']"
Availability,"CHANGELOG: Teach `hailctl dataproc` to use new `gcloud` flag names which suppresses the warnings about `--num-secondary-workers`. `hailctl` now requires at least gcloud 284.0.0. Run `gcloud components update` to update. This has been available since March, it seems high time to fix this and recommend people update gcloud.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9262:234,avail,available,234,https://hail.is,https://github.com/hail-is/hail/pull/9262,1,['avail'],['available']
Availability,"CHANGELOG: The Batch LocalBackend now supports `always_run` jobs. The LocalBackend will no longer immediately error when a job fails, rather now aligns with the ServiceBackend in running all jobs whose parents have succeeded. See [Zulip thread](https://hail.zulipchat.com/#narrow/stream/223457-Hail-Batch-support/topic/.60always_on.60.20for.20local.20backend/near/341620608) for some discussion. The question to whether we can support `always_run` in the local backend depends on whether to make a breaking change in the local backend where a failure in a job does not immediately raise an exception. Seemed there was no issue with this on zulip.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12780:110,error,error,110,https://hail.is,https://github.com/hail-is/hail/pull/12780,2,"['error', 'failure']","['error', 'failure']"
Availability,CHANGELOG: The Resource class is now also available at hailtop.batch.Resource. I screwed up my branches. This is just #9515.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9575:42,avail,available,42,https://hail.is,https://github.com/hail-is/hail/pull/9575,1,['avail'],['available']
Availability,CHANGELOG: The `Resource` class is now also available at hailtop.batch.Resource.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9515:44,avail,available,44,https://hail.is,https://github.com/hail-is/hail/pull/9515,1,['avail'],['available']
Availability,CHANGELOG: The `batch_size` parameter of `vds.new_combiner` is deprecated in favor of `gvcf_batch_size`. This avoids a confusing error message: https://dev.hail.is/t/vds-new-combiner/269/4?u=dking. @tpoterba do you think this is better?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12213:129,error,error,129,https://hail.is,https://github.com/hail-is/hail/pull/12213,1,['error'],['error']
Availability,"CHANGELOG: Use indexed VEP cache files for GRCh38 on both dataproc and QoB. Fixes #13989. In this PR, I did the following:; 1. Installed samtools into the Docker image to get rid of errors in the log output; 2. Added the `--merged` flag so that VEP will use the directory `homo_sapiens_merged` for the cache. Outstanding Issues:; 1. The FASTA files that are in `homo_sapiens/` were not present in the merged dataset. Do we keep both the `homo_sapiens` and `homo_sapiens_merged/` directories in our bucket or do we transfer the FASTA files to the merged directory?; 2. Once we decide the answer to (1), then I can fix this in dataproc. The easiest thing to do is to add the tar file with the `_merged` data to the dataproc vep folders and use the `--merged` flag. However, that will double the startup time for VEP on a worker node in dataproc. Before:; <img width=""617"" alt=""Screenshot 2023-12-05 at 12 42 16 PM"" src=""https://github.com/hail-is/hail/assets/1693348/bee7fff5-782c-4f19-aa88-26383ed386b7"">. After:; <img width=""619"" alt=""Screenshot 2023-12-05 at 12 46 30 PM"" src=""https://github.com/hail-is/hail/assets/1693348/3d731759-6c69-4f1c-9c73-92bfb05c239a"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14071:182,error,errors,182,https://hail.is,https://github.com/hail-is/hail/pull/14071,1,['error'],['errors']
Availability,"CHANGELOG: `PythonJob.call` now immediately errors when supplied arguments are incompatible with the called function instead of erroring only when the job is run. inspect.Signature allows you to inspect the signature of some function, and [inspect.Signature.bind](https://docs.python.org/3/library/inspect.html#inspect.Signature.binds) takes arguments to the function and maps those arguments to method parameters. If the invocation is invalid, i.e. would raise a TypeError when *actually* invoking the function with those arguments, this method raises a similar error. This can help a user immediately catch something like not passing the correct number of arguments to a PythonJob call without having to submit and run it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12734:44,error,errors,44,https://hail.is,https://github.com/hail-is/hail/pull/12734,3,['error'],"['error', 'erroring', 'errors']"
Availability,"CHANGELOG: `hailctl dataproc` now creates clusters using Dataproc version 2.1.33. It previously used version 2.1.2. Dataproc verifications:; 1. Memory available after startup: `mem avail: 42959 of 52223 MiB`. OK.; 2. SparkMonitor still shows up.; 3. Native code (`hl.identity_by_descent`) still works. The Dataproc version list only keeps the most recent five, sadly. Lucky for us, archive.org happens to have a capture with 2.1.2. I also requested a capture of the current state of the page. - https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1. - 2023-03-07: https://web.archive.org/web/20230307225815/https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1. - 2023-12-12: https://web.archive.org/web/20231212001716/https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1. | Component | 2.1.33-debian11 | 2.1.2-debian11 |; | --- | --- | --- |; | Apache Atlas | 2.2.0 | 2.2.0 |; | Apache Flink | 1.15.4 | 1.15.0 |; | Apache Hadoop | 3.3.6 | 3.3.3 |; | Apache Hive | 3.1.3 | 3.1.3 |; | Apache Hive WebHCat | 3.1.3 | 3.1.3 |; | Apache Hudi | 0.12.3 | 0.12.0 |; | Apache Kafka | 3.1.0 | 3.1.0 |; | Apache Pig | 0.18.0-SNAPSHOT | 0.18.0-SNAPSHOT | | Apache Spark | 3.3.2 | 3.3.0 |; | Apache Sqoop v1 | 1.5.0-SNAPSHOT | 1.5.0-SNAPSHOT | | Apache Sqoop v2 | N/A | 1.99.6 |; | Apache Tez | N/A | 0.10.1 |; | Cloud Storage Connector | hadoop3-2.2.18 | hadoop3-2.2.9 | | Conscrypt | 2.5.2 | 2.5.2 |; | Docker | 20.10 | 20.10 |; | Hue | 4.10.0 | 4.10.0 |; | Java | 11 | 11 |; | JupyterLab Notebook | 3.4 | 3.4 |; | Oozie | 5.2.1 | 5.2.1 |; | Trino | 376 | 376 |; | Python | Python 3.10 | Python 3.10 |; | R | R 4.1 | R 4.1 |; | Ranger | 2.2.0 | 2.2.0 |; | Scala | 2.12.18 | 2.12.14 |; | Solr | 9.0.0 | 9.0.0 |; | Zeppelin Notebook | 0.10.1 | 0.10.1 |; | Zookeeper | 3.8.3 | 3.8.0 |. Here's a diff. I think the things that may affect us are:. 1. Scala patch version; 4. Cloud Storage Connector patch version (this is the motivation fo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14093:151,avail,available,151,https://hail.is,https://github.com/hail-is/hail/pull/14093,2,['avail'],"['avail', 'available']"
Availability,"CHANGELOG: `hl.import_table` is up to twice as fast for small tables. The big change is optimizing for the single file, no filters case in which; we need not scan for the first extant row, that row *must* be in the first; partition, if it exists at all. Unfortunately there is no zero-RPC way to; determine the number of partitions in a table, so I must catch an error; about the lack of a zeroth partition. I also did some refactoring:. 1. Move some functions to a utility file and add lots of indents and newlines to make them readable.; 2. Use `hl.format` for constructing strings.; 3. Make `should_filter_line` into `should_remove_line` for clarity of name.; 4. Modify `should_remove_line` to use short-circuiting and/or instead of array folds.; 5. Modify `should_remove_line` to indicate (via returning None) when there are no filters enabled.; 6. Add types.; 7. Fix a bug where we assumed that `.collect()[0]` would be `None` if there were no values in the table. (It raises an error); 8. Deduplicate `hail.utils.deduplicate` (haha: I mean, there is already code for doing field dedupe)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11782:363,error,error,363,https://hail.is,https://github.com/hail-is/hail/pull/11782,2,['error'],['error']
Availability,"CHANGELOG: `hl.logistic_regression_rows`, `hl.poisson_regression_rows`, and `hl.skat` all now support configuration of the maximum number of iterations and the tolerance. I had to make some fixes to how we count the number of iterations. It was quite screwy. Now it should reliably report the correct number of iterations regardless of failure, non-convergence, or explosion. This was requested [on Zulip](https://hail.zulipchat.com/#narrow/stream/127634-Feature-Requests/topic/Convergence.20issues.20with.20hl.2Elogistic_regression_rows).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11759:160,toler,tolerance,160,https://hail.is,https://github.com/hail-is/hail/pull/11759,3,"['failure', 'reliab', 'toler']","['failure', 'reliably', 'tolerance']"
Availability,CHANGELOG: `hl.nd.vstack` and `hl.nd.hstack` provide clear error messages when used with incompatible matrices or with no arguments.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12636:59,error,error,59,https://hail.is,https://github.com/hail-is/hail/pull/12636,1,['error'],['error']
Availability,"CHANGELOG: fix LocalBackend.run() succeeding when intermediate command fails. Stacked on #9219 as that PR is essentially approved, and to avoid a merge conflict. The commit in this PR is https://github.com/hail-is/hail/pull/9297/commits/cbc3bbe7f14c01d44c89995a03375d983fc14f4f. Caused by associativity of the ternary conditional ('set -e' + 'x' is the operand `a` in `a if cond else b`). Easy reproduction case on main:. ```python; def test_single_job_with_mixed_shells(self):; b = self.batch(); j = b.new_job(); j.command(f'echoddd ""hello""'); j2 = b.new_job(); j2.command(f'echo ""world""'). self.assertRaises(Exception, b.run); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9297:526,echo,echoddd,526,https://hail.is,https://github.com/hail-is/hail/pull/9297,2,['echo'],"['echo', 'echoddd']"
Availability,"CHANGELOG: make hail's optimization rewriting filters to interval-filters smarter and more robust. Completely rewrites ExtractIntervalFilters. Instead of matching against very specific patterns, and failing completely for things that don't quite match (e.g. an input is let bound, or the fold implementing ""locus is contained in a set of intervals"" is written slightly differently), this uses a standard abstract interpretation framework, which is almost completely insensitive to the form of the IR, only depending on the semantics. It also correctly handles missing key fields, where the previous implementation often produced an unsound transformation of the IR. Also adds a much more thorough test suite than we had before. At the top level, the analysis takes a boolean typed IR `cond` in an environment where there is a reference to some `key`, and produces a set `intervals`, such that `cond` is equivalent to `cond & intervals.contains(key)` (in other words `cond` implies `intervals.contains(key)`, or `intervals` contains all rows where `cond` is true). This means for instance it is safe to replace `TableFilter(t, cond)` with `TableFilter(TableFilterIntervals(t, intervals), cond)`. Then in a second pass it rewrites `cond` to `cond2`, such that `cond & (intervals.contains(key))` is equivalent to `cond2 & intervals.contains(key)` (in other words `cond` implies `cond2`, and `cond2 & intervals.contains(key)` implies `cond`). This means it is safe to replace the `TableFilter(t, cond)` with `TableFilter(TableFilterIntervals(t, intervals), cond2)`. A common example is when `cond` can be completely captured by the interval filter, i.e. `cond` is equivant to `intervals.contains(key)`, in which case we can take `cond2 = True`, and the `TableFilter` can be optimized away. This all happens in the function; ```scala; def extractPartitionFilters(ctx: ExecuteContext, cond: IR, ref: Ref, key: IndexedSeq[String]): Option[(IR, IndexedSeq[Interval])] = {; if (key.isEmpty) None; else {; val e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13355:91,robust,robust,91,https://hail.is,https://github.com/hail-is/hail/pull/13355,1,['robust'],['robust']
Availability,CI deploy is broken due to checkout failure.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8577#issuecomment-616211238:36,failure,failure,36,https://hail.is,https://github.com/hail-is/hail/pull/8577#issuecomment-616211238,1,['failure'],['failure']
Availability,"CI had a hiccup. I hope this will finally pass, unless the latest master-merge introduced more issues. Needs a careful walk through tomorrow to ensure everything is in place and no unnecessary slow downs were added.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3414#issuecomment-386497740:198,down,downs,198,https://hail.is,https://github.com/hail-is/hail/pull/3414#issuecomment-386497740,1,['down'],['downs']
Availability,"CI is currently erroring on line 555 because when it starts up `last_known_github_status` is empty. Pre #11156, `last_known_github_status` initialized to `None` so using `get` here should have the same effect, and allow CI to post statuses to github.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11222:16,error,erroring,16,https://hail.is,https://github.com/hail-is/hail/pull/11222,1,['error'],['erroring']
Availability,CI recovered once the PR was closed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6377#issuecomment-503584053:3,recover,recovered,3,https://hail.is,https://github.com/hail-is/hail/pull/6377#issuecomment-503584053,1,['recover'],['recovered']
Availability,"CI test failure means not known to be safe to merge into master. Agreed re: minimizing false failures (i.e. failure due to system load but it's actually an OK change). I think in practice much less than 30s is fine, this test has been in for a month or two and this is the first time I saw it fail.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5503#issuecomment-470264865:8,failure,failure,8,https://hail.is,https://github.com/hail-is/hail/pull/5503#issuecomment-470264865,3,['failure'],"['failure', 'failures']"
Availability,"CI was getting 422s from GitHub. Using a; `raise_for_status=True` ClientSession circumvented gidgethubs native; error handling logic smothering the HTTP response body where github; places critical debugging information. Aiohttp is aware that; `raise_for_status` provides no access to the response body. They addressed; this in https://github.com/aio-libs/aiohttp/pulls/3892, but that has not; been released because 4.0.0 has not yet been released. Moreover, `gidgethub` incorrectly handles the too many statuses response. I'll PR a fix into their repo. For now, I've added a bit more information the logs and fixed the main issue, the missing `['status']`. Another relevant issue: https://github.com/aio-libs/aiohttp/issues/4600.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8480:112,error,error,112,https://hail.is,https://github.com/hail-is/hail/pull/8480,1,['error'],['error']
Availability,CRIU/checkpoint-restore using Eclipse OpenJ9 JVM https://blog.openj9.org/2022/09/26/getting-started-with-openj9-criu-support/,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13675#issuecomment-1728033312:5,checkpoint,checkpoint-restore,5,https://hail.is,https://github.com/hail-is/hail/issues/13675#issuecomment-1728033312,1,['checkpoint'],['checkpoint-restore']
Availability,CS_HAIL_IMAGE_PY_3_11=b \; HAIL_GENETICS_HAILTOP_IMAGE=c \; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=d \; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=e \; WHEEL_FOR_AZURE=f \; WEBSITE_TAR=g \; bash scripts/release.sh; +++ dirname -- scripts/release.sh; ++ cd -- scripts; ++ pwd; + SCRIPT_DIR=/Users/dking/projects/hail/hail/scripts; + arguments='HAIL_PIP_VERSION HAIL_VERSION GIT_VERSION REMOTE WHEEL GITHUB_OAUTH_HEADER_FILE HAIL_GENETICS_HAIL_IMAGE HAIL_GENETICS_HAIL_IMAGE_PY_3_10 HAIL_GENETICS_HAIL_IMAGE_PY_3_11 HAIL_GENETICS_HAILTOP_IMAGE HAIL_GENETICS_VEP_GRCH37_85_IMAGE HAIL_GENETICS_VEP_GRCH38_95_IMAGE WHEEL_FOR_AZURE WEBSITE_TAR'; + for varname in '$arguments'; + '[' -z 0.2.128 ']'; + echo HAIL_PIP_VERSION=0.2.128; HAIL_PIP_VERSION=0.2.128; + for varname in '$arguments'; + '[' -z 0.2.128-91d328e7fc84 ']'; + echo HAIL_VERSION=0.2.128-91d328e7fc84; HAIL_VERSION=0.2.128-91d328e7fc84; + for varname in '$arguments'; + '[' -z 91d328e7fc84686936ffd4f370c8c104b2d78b2a ']'; + echo GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a; GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a; + for varname in '$arguments'; + '[' -z '' ']'; + echo. + usage; + cat; ++ basename scripts/release.sh; ++ basename scripts/release.sh; usage: release.sh. All arguments are specified by environment variables. For example:. HAIL_PIP_VERSION=0.2.123; HAIL_VERSION=0.2.123-abcdef123; GIT_VERSION=abcdef123; REMOTE=origin; WHEEL=/path/to/the.whl; GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch3,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:14827,echo,echo,14827,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,2,['echo'],['echo']
Availability,Call htsjdk's disableOnTheFlyModifications do disable header repairs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6013:61,repair,repairs,61,https://hail.is,https://github.com/hail-is/hail/pull/6013,1,['repair'],['repairs']
Availability,"Calling `fb.result()` generates stalled execution, no warnings or errors raised. Should generate some error message, or potentially the result (memory address). cc @catoverdrive . Test case. ```scala; def testString() {; val rt = PString(); val input = ""hello""; val fb = FunctionBuilder.functionBuilder[Region, String, Long]; val srvb = new StagedRegionValueBuilder(fb, rt). fb.emit(; Code(; srvb.start(),; srvb.addString(fb.getArg[String](2)),; srvb.end(); ); ). val region = Region(); val rv = RegionValue(region). val res1 = fb.result()()(region, input); println(""Past res1""). val res2 = fb.result()()(region, input); // never reached; println(""Past res2""); }; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7384:66,error,errors,66,https://hail.is,https://github.com/hail-is/hail/issues/7384,2,['error'],"['error', 'errors']"
Availability,"Calling that the ""right"" error is a little bit bold, but you certainly fixed the bug!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1502#issuecomment-284850456:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/1502#issuecomment-284850456,1,['error'],['error']
Availability,"Can confirm that this ""fixes"" it, since current master results in:; ```; Hail version: devel-f4fc571b4570; Error summary: AssertionError: assertion failed: type mismatch:; name: global; actual: +Struct{}; expect: Struct{}; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4128#issuecomment-412775955:107,Error,Error,107,https://hail.is,https://github.com/hail-is/hail/pull/4128#issuecomment-412775955,1,['Error'],['Error']
Availability,"Can we follow up with a test that creates one job which echos its IP and port and then listens, then the test will try to curl the public IP and port?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11250#issuecomment-1021554196:56,echo,echos,56,https://hail.is,https://github.com/hail-is/hail/pull/11250#issuecomment-1021554196,1,['echo'],['echos']
Availability,"Can we make a ""backup"" of what the data source settings are that are working now before we redeploy this in default? I want to make sure we can recover if these changes put us in a bad state.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10772#issuecomment-905883214:144,recover,recover,144,https://hail.is,https://github.com/hail-is/hail/pull/10772#issuecomment-905883214,1,['recover'],['recover']
Availability,Can you fix the following pylint formatting errors?. ```; batch/front_end/front_end.py:1455:1: W293 blank line contains whitespace; batch/front_end/front_end.py:1462:1: W293 blank line contains whitespace; batch/front_end/front_end.py:1463:13: W291 trailing whitespace; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10800#issuecomment-902867954:44,error,errors,44,https://hail.is,https://github.com/hail-is/hail/pull/10800#issuecomment-902867954,1,['error'],['errors']
Availability,Can you post the output of:; ```; cat /proc/cpuinfo | grep flags; ```. I suspect this error might arise if your processor doesn't support the pop count intrinsic. If this is the case it's my mistake for not including a back up implementation in terms of bit shifting. I can fix this tonight if that's the issue.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1520#issuecomment-285803343:86,error,error,86,https://hail.is,https://github.com/hail-is/hail/issues/1520#issuecomment-285803343,1,['error'],['error']
Availability,"Can you take a look at the new structure and see if it's better? If so, then I'll test everything again making sure there's no errors in the logs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10920#issuecomment-949956416:127,error,errors,127,https://hail.is,https://github.com/hail-is/hail/pull/10920#issuecomment-949956416,1,['error'],['errors']
Availability,Can you take another look? I'm getting test errors in other PRs that I hope this PR fixes.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10696#issuecomment-887830765:44,error,errors,44,https://hail.is,https://github.com/hail-is/hail/pull/10696#issuecomment-887830765,1,['error'],['errors']
Availability,"Can you verify; 1. Batch has access to the hail-query bucket; 2. Our terraform correctly grants permissions for that? And if it currently doesnt, we should ping AUS to make sure theyre aware of this change",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11870#issuecomment-1138729334:157,ping,ping,157,https://hail.is,https://github.com/hail-is/hail/pull/11870#issuecomment-1138729334,1,['ping'],['ping']
Availability,Can't figure out the error. Some segmentation fault. Can trigger on regressionTestUnifyBug. Looks to be triggered in Compile(MakeTuple.ordered),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7733#issuecomment-566223349:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/pull/7733#issuecomment-566223349,2,"['error', 'fault']","['error', 'fault']"
Availability,"Can't quite figure out the failure in LDPruneSuite, will follow up tomorrow",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7687#issuecomment-563878450:27,failure,failure,27,https://hail.is,https://github.com/hail-is/hail/pull/7687#issuecomment-563878450,1,['failure'],['failure']
Availability,"Can't really test this easily, unfortunately. CHANGELOG: Fix integer overflow error when reading files >2G with `hl.import_plink`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8948:78,error,error,78,https://hail.is,https://github.com/hail-is/hail/pull/8948,1,['error'],['error']
Availability,"CaseBuilder has an `or_error` method to throw an error if no `when` conditions are true. Currently, SwitchBuilder does not have an equivalent method: it only supports returning a default value or missing. The option to throw an error on an unhandled value can be useful for making sure that all possible values for an enum expression have been accounted for in switch cases.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9749:49,error,error,49,https://hail.is,https://github.com/hail-is/hail/pull/9749,2,['error'],['error']
Availability,"CastOverride>::run(const T&) [with R = simdpp::arch_avx2::int16<8>; T = simdpp::arch_avx2::uint16<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int16<8>; T = simdpp::arch_avx2::uint16<8>]; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:62:35: required from simdpp::arch_avx2::int16<8>& simdpp::arch_avx2::int16<8>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint16<8>]; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:55:73: required from simdpp::arch_avx2::int16<8>::int16(const simdpp::arch_avx2::uint16<8, E>&) [with E = void]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:42:28: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int16<8> with private member simdpp::arch_avx2::int16<8>::d_ from an array of const class simdpp::arch_avx2::uint16<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:21,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:33:7: note: class simdpp::arch_avx2::int16<8> declared here; class int16<8, void> : public any_int16<8, int16<8,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int16<16>; T = simdpp::arch_avx2::uint16<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:104987,error,error,104987,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"Caveats:; * the copy-to-GS at the end is crashing without a good error message,; but probably permissions, even though I've given my service account; access to that bucket.; * this runs all benchmarks in replicate. We should split them up; in a randomized (deterministic?) way so that the wall time is; shorter.; * needs to dump into a database instead of json files on GS.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6908:65,error,error,65,https://hail.is,https://github.com/hail-is/hail/pull/6908,1,['error'],['error']
Availability,Certainly appears to have fixed my issue. Pipeline that went from 11 to 25 mins is now back down to 11,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4028#issuecomment-410786746:92,down,down,92,https://hail.is,https://github.com/hail-is/hail/issues/4028#issuecomment-410786746,1,['down'],['down']
Availability,"Change ""=="" and ""!="" to throw error message for off-type comparisons",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/405:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/pull/405,1,['error'],['error']
Availability,Change to `echo $SPARK_HOME/python/lib/py4j*-src.zip`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1573#issuecomment-287743256:11,echo,echo,11,https://hail.is,https://github.com/hail-is/hail/pull/1573#issuecomment-287743256,1,['echo'],['echo']
Availability,"Changes since last review:; - Method now takes expressions for call and (optionally) scores.; - Block matrix and table of scores annotated and collected from source.cols() sent to Python, processed using int indices, column names restored on python side (thanks @tpoterba); - Fixed bug that silently dropped `n_samples / block_size` proportion of pairs, Python test checks it; - Extended Python tests to compare k and scores paths, test counts, min_kinship, maf, block_size; - Tuned tolerances on comparison with R from Python; - Extended to general column key, removing unique key check, noted in docs; - MEMORY_AND_DISK caching as default (thanks @konradjk) on Scala side; - The diagonal fix meant phi is computed with parallelism up to the number of diagonal blocks, rather than parallelism 1. But that's still likely a bottleneck as phi requires computing and point-wise dividing two big gram matrices. I now write phi to disk and read it back in, which squares the parallelism up to the number of blocks in phi. I think this should also improve the stability of the many downstream calculations derived from phi, esp. if pre-emptibles are used. No longer cacheing phi, but I left caching on the other matrices. @konradjk let us know how this version compares next time you run it.; - Noted in FIXME room for further improvement when fusing blocks: `replace join with zipPartitions, throw away lower triangular blocks sooner, avoid the nulls`; - Updated docs accordingly; - Deleted a bunch of code in PCRelate and PCRelateSuite",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3211#issuecomment-376725104:483,toler,tolerances,483,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376725104,2,"['down', 'toler']","['downstream', 'tolerances']"
Availability,"Changes to make sure that only the annotation datasets are visible on the docs page, now that the `datasets.json` config file contains all available datasets. Overview:. - In `datasets.json`, moved ""key_properties"" inside an ""annotation_db"" field, like `""annotation_db"": {""key_properties"": []}`, so that only the datasets with the ""annotation_db"" key are shown in the annotation DB docs page. Removed ""key_properties"" from non-annotation datasets. - Minor reformatting changes to docs page, added a reference genome column to the HTML table. - Updated deploy script to reflect the filename change from `annotation_db.json` to `datasets.json`. - Modified checks for keys in dicts from `assert key in doc, doc` to `assert key in doc` in `DatasetVersion.from_json()` and `Dataset.from_name_and_json()`. Since the `doc` that is passed to these methods from the checked in JSON file is just a dict like `doc = {""annotation_db"": {""key_properties"": [...]}, ""description"": ..., ""url"": ..., ""versions"": [...]}` this seems to work fine. Let me know if `key in doc, doc` form was used for other reasons I've overlooked.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9546:139,avail,available,139,https://hail.is,https://github.com/hail-is/hail/pull/9546,1,['avail'],['available']
Availability,"Changes:; - correct the interpretation of less and greater.; - improve the formatting and verbiage of the docs,; - expand upon the statistical definition alluded to previously in only the less; case,; - add python tests which would have caught this error,; - add python tests which test against `scipy`,; - deprecate the use of `'two.sided'`, an R-ism, document the preferred use of; `'two-sided'`, a Python-ism, and; - fix an error message in Scala that used yet another naming of the two sided test.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8420:249,error,error,249,https://hail.is,https://github.com/hail-is/hail/pull/8420,2,['error'],['error']
Availability,"Changes:; - four containers: setup container, main container, cleanup container, keep alive container; - cleanup container waits for an HTTP message from batch before cleaning up; - keep alive container stays alive until batch sends it an HTTP message (this prevents terminated pod GC); - split `mark_complete` into three simpler methods; - extract several parts of former `mark_complete` into named helper methods; - `LogStore.results_filename` is gone, if the logs are present, the pod has already been run",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6746:86,alive,alive,86,https://hail.is,https://github.com/hail-is/hail/pull/6746,3,['alive'],['alive']
Availability,Changing the chromosome to 2 3 or 4 preserves the error. Chromosome 5 eliminates the error. fails:; ```; 	chromosome	locus	gene; 0	chr4	6109351	RNF207; 119111	chr8	51749536	PXDNL; ```; succeeds; ```; 	chromosome	locus	gene; 0	chr5	1	RNF207; 119111	chr8	51749536	PXDNL; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13339#issuecomment-1660524651:50,error,error,50,https://hail.is,https://github.com/hail-is/hail/issues/13339#issuecomment-1660524651,2,['error'],['error']
Availability,Cheatsheets page with a link to the download,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7570:36,down,download,36,https://hail.is,https://github.com/hail-is/hail/pull/7570,1,['down'],['download']
Availability,"Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3MThjYjgyZC1jNGU3LTRlNWEtODgzZi02NjQ0NjlmYzA4MGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjcxOGNiODJkLWM0ZTctNGU1YS04ODNmLTY2NDQ2OWZjMDgwYSJ9fQ=="" width=""0"" height=""0""/>;  [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr).  [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings).  [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""718cb82d-c4e7-4e5a-883f-664469fc080a"",""prPublicId"":""718cb82d-c4e7-4e5a-883f-664469fc080a"",""dependencies"":[{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.11.2""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-JUPYTERSERVER-6099119""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[461],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Generation of Error Message Containing Sensitive Information](https://learn.snyk.io/lesson/error-message-with-sensitive-information/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14070:3691,Error,Error,3691,https://hail.is,https://github.com/hail-is/hail/pull/14070,2,"['Error', 'error']","['Error', 'error-message-with-sensitive-information']"
Availability,Checked that PartitioningSuite doesn't get an out of memory error on bgen branch and ExprSuite.testImpexes takes less than a second now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1748#issuecomment-298948635:60,error,error,60,https://hail.is,https://github.com/hail-is/hail/pull/1748#issuecomment-298948635,1,['error'],['error']
Availability,"Checkpointing the VCF made it, if anything, slower.; ```; 254.81s call hail/methods/relatedness/test_pc_relate.py::test_pc_relate_against_R_truth; 189.52s call hail/methods/test_pca.py::test_spectra_2[triplet0]; 95.37s call hail/vds/test_vds.py::test_truncate_reference_blocks; 92.80s call hail/methods/test_qc.py::Tests::test_vep_grch38_against_dataproc; 86.83s call hail/backend/test_service_backend.py::test_tiny_driver_has_tiny_memory; 68.86s call hail/matrixtable/test_matrix_table.py::test_read_write_balding_nichols_model; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13076#issuecomment-1564883408:0,Checkpoint,Checkpointing,0,https://hail.is,https://github.com/hail-is/hail/pull/13076#issuecomment-1564883408,1,['Checkpoint'],['Checkpointing']
Availability,"Christina reports https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/initialization.20action.20failed.20in.20starting.20cluster:; ```; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [d0a8142009bf49a1a51f5276576aeddb] failed with error:; Google Cloud Dataproc Agent reports job failure. If logs are available, they can be found in 'gs://dataproc-c3e3c3c1-4a54-41e4-aa06-83d5d2ce80ec-us/google-cloud-dataproc-metainfo/c174dc73-2817-4ec1-8c2d-ae4e0c4f91ae/jobs/d0a8142009bf49a1a51f5276576aeddb/driveroutput'.; Traceback (most recent call last):; File ""/Users/cchen/anaconda/envs/hail-env/bin/hailctl"", line 10, in <module>; sys.exit(main()); File ""/Users/cchen/anaconda/envs/hail-env/lib/python3.7/site-packages/hailctl/__main__.py"", line 90, in main; module(args); File ""/Users/cchen/anaconda/envs/hail-env/lib/python3.7/site-packages/hailctl/dataproc/cli.py"", line 99, in main; jmp[args.module].main(args, pass_through_args); File ""/Users/cchen/anaconda/envs/hail-env/lib/python3.7/site-packages/hailctl/dataproc/submit.py"", line 72, in main; check_call(cmd); File ""/Users/cchen/anaconda/envs/hail-env/lib/python3.7/subprocess.py"", line 347, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', 'ukbb_hdpca.py', '--cluster=chen', '--files=', '--py-files=/var/folders/6h/ll2dv8t15zs9pzf4g6kjb2rrt2fc9q/T/pyscripts_2740r0cj.zip', '--properties=']' returned non-zero exit status 1.; ```; The file does not exist but there are files with the same prefix but a `.000000001` suffix or similar. Grace reports (a possibly unrelated issue) https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/Cryptic.20array.20concordance.20error:; ```; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [873db5659acd43f7b539dcb17182959d] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""/miniconda3/bin/hailctl"", line 10, in <module>; sys.ex",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6565:160,ERROR,ERROR,160,https://hail.is,https://github.com/hail-is/hail/issues/6565,4,"['ERROR', 'avail', 'error', 'failure']","['ERROR', 'available', 'error', 'failure']"
Availability,Clarify language about data download in GWAS tutorial,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5060:28,down,download,28,https://hail.is,https://github.com/hail-is/hail/pull/5060,1,['down'],['download']
Availability,"Clarifying for future devs: the Batch.read_input is probably just causing the script to grow large enough that we start using scripts which need to be uploaded separately from the job. Attempting to replicate with; ```. In [6]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(300):; ...: j = b.new_job(); ...: j.command(f'echo {""a"" * 11 * 1024}'); ...: b.run(); ```. triggers https://github.com/hail-is/hail/issues/14051. I'll try to fix both.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13940#issuecomment-1834357495:370,echo,echo,370,https://hail.is,https://github.com/hail-is/hail/issues/13940#issuecomment-1834357495,1,['echo'],['echo']
Availability,ClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:170); at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:45); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(Trav,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2824,Heartbeat,HeartbeatReceiver,2824,https://hail.is,https://github.com/hail-is/hail/issues/4780,2,['Heartbeat'],['HeartbeatReceiver']
Availability,"Closes https://github.com/hail-is/hail/issues/14652. See https://github.com/populationgenomics/hail/pull/346. Thanks for the contribution @illusional!. Gives Dataproc clusters started via `hailctl dataproc start` internet access by default, since we need it to install some of our dependencies, per the error message in the linked issue.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14653:303,error,error,303,https://hail.is,https://github.com/hail-is/hail/pull/14653,1,['error'],['error']
Availability,Closing as we're going down a different path.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5117#issuecomment-455789526:23,down,down,23,https://hail.is,https://github.com/hail-is/hail/pull/5117#issuecomment-455789526,1,['down'],['down']
Availability,Closing due to lack of reproduction. Please feel free to comment and ping me if you can provide more details!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12717#issuecomment-1467001174:69,ping,ping,69,https://hail.is,https://github.com/hail-is/hail/issues/12717#issuecomment-1467001174,1,['ping'],['ping']
Availability,Closing this for now until we have a plan for versioning cloudtools. This change would require not using the hard coded init_notebook.py available on GCS right now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6118#issuecomment-493502443:137,avail,available,137,https://hail.is,https://github.com/hail-is/hail/pull/6118#issuecomment-493502443,1,['avail'],['available']
Availability,Closing while I address test failure.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1548#issuecomment-286622901:29,failure,failure,29,https://hail.is,https://github.com/hail-is/hail/pull/1548#issuecomment-286622901,1,['failure'],['failure']
Availability,Closing while I resolve test failures and do some clean up,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2254#issuecomment-332244947:29,failure,failures,29,https://hail.is,https://github.com/hail-is/hail/pull/2254#issuecomment-332244947,1,['failure'],['failures']
Availability,Closing. The latter issue will be addressed with better handing of categorical covariates down the line.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1156#issuecomment-422471680:90,down,down,90,https://hail.is,https://github.com/hail-is/hail/issues/1156#issuecomment-422471680,1,['down'],['down']
Availability,"Code:; ```python3; import hail as hl; from hail import ir. hl.init(); mt = hl.import_vcf('path/to/vcf'); mt = hl.MatrixTable(ir.MatrixKeyRowsBy(mt._mir, ['locus'], is_sorted=True)); ht = mt._localize_entries('_e', '_c'); j = hl.Table._multi_way_zip_join([ht, ht], 'd', 'g'); j.write('tst.ht'); ```. Java Stack Trace:; ```; py4j.protocol.Py4JJavaError: An error occurred while calling z:is.hail.expr.ir.Interpret.interpretJSON.; : java.util.NoSuchElementException: key not found: alleles; 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.MapLike$class.apply(MapLike.scala:141); 	at scala.collection.AbstractMap.apply(Map.scala:59); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.rvd.RVDType.<init>(RVDType.scala:24); 	at is.hail.expr.ir.TableMultiWayZipJoin.execute(TableIR.scala:669); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:775); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:93); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:63); 	at is.hail.expr.ir.Interpret$.interpretJSON(Interpret.scala:22); 	at is.hail.expr.ir.Interpret.interpretJSON(Interpret.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.Reflec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5396:355,error,error,355,https://hail.is,https://github.com/hail-is/hail/issues/5396,1,['error'],['error']
Availability,Codegen cast errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446:13,error,errors,13,https://hail.is,https://github.com/hail-is/hail/issues/3446,1,['error'],['errors']
Availability,"Command:. hail read -i /user/aganna/annotated_test22.vds \; filtervariants expr \; --keep -c 'v.contig == ""22""' \; annotatevariants expr -c 'va.andrea.URV = (va.qc.nNonRef == 1 && va.exac.info.AC.isEmpty)' \; annotatevariants expr -c 'va.andrea.URVEXAC = (va.qc.nNonRef == 1 && (va.exac.info.AC.isEmpty || va.exac.info.AC[1] < 3))' \; exportvariants -c 'v, va.andrea.URV ,va.andrea.URVEXAC, va.qc.nNonRef' -o file:///humgen/atgu1/fs03/wip/aganna/HCSCORE/test. Error:. [Stage 1:> (268 + 184) / 14326]Exception in thread ""main"" org.apache.spark.SparkException: Job aborted due to stage failure: Task 37 in stage 1.0 failed 30 times, most recent failure: Lost task 37.29 in stage 1.0 (TID 3338, dataflow02.broadinstitute.org): java.lang.IndexOutOfBoundsException: 1. [hail.log.txt](https://github.com/broadinstitute/hail/files/250349/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/367:460,Error,Error,460,https://hail.is,https://github.com/hail-is/hail/issues/367,3,"['Error', 'failure']","['Error', 'failure']"
Availability,"Command:. hail-new read -i /user/lfran/exac_all.split.vds \; filtersamples --remove -c ""file:///humgen/atgu1/fs03/wip/aganna/HCSCORE/CANCER/samples_to_keep.sample_list"" \; variantqc \; filtervariants --keep -c 'va.qc.MAC > 0' \; count \; filtersamples --keep -c 'false' \; write -o /user/aganna/exac_noCANCER.split.onlygeno.vep.NEWHAIL.vds. Error:. Exception in thread ""main"" java.lang.NoClassDefFoundError: org/broadinstitute/hail/methods/VCFReport$; at org.broadinstitute.hail.driver.Main$.runCommands(Main.scala:125); at org.broadinstitute.hail.driver.Main$.main(Main.scala:276); at org.broadinstitute.hail.driver.Main.main(Main.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: org.broadinstitute.hail.methods.VCFReport$; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357). Hail log attached. [hail.log.txt](https://github.com/broadinstitute/hail/files/225215/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/309:341,Error,Error,341,https://hail.is,https://github.com/hail-is/hail/issues/309,1,['Error'],['Error']
Availability,"Commandline:. ```; hail -l /xchip/cga_home/gtiao/Hail/hail.re-import.log importvcf $VCF \; filtervariants all \; count \; filtersamples list -i 'file:///xchip/cga_home/gtiao/37k/germline_cancer_joint_calling.restricted_samples.sample_list' --remove \; count \; exportsamples -c 's.id' -o file:///xchip/cga_home/gtiao/37k/Hail/samples_after_removing_restricted.txt; ```. Error message:. ```; hail: info: running: exportsamples -c s.id -o file:///xchip/cga_home/gtiao/37k/Hail/samples_after_removing_restricted.txt; hail: exportsamples: fatal: does not support multiallelics.; Run `splitmulti' first.; ```. It works if I insert ""splitmulti"" after the import command, but then I drop all variants, so this seems a very silly requirement.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/382:370,Error,Error,370,https://hail.is,https://github.com/hail-is/hail/issues/382,1,['Error'],['Error']
Availability,Commandline:. ```; hail-new -l /home/unix/gtiao/hail.rename.log \; read -i /user/gtiao/37k/germline_cancer_joint_calling.no_restricted.GQ20_AB.split.VEP.vds \; renamesamples -i file:///xchip/cga_home/gtiao/37k/Hail/germline_cancer_joint_calling.no_restricted.GQ20_AB.split.VEP.sample_id_map.txt \; write -o /user/gtiao/37k/germline_cancer_joint_calling.no_restricted.GQ20_AB.split.VEP.no_spaces.vds. ```. Error message:. ```; hail: info: running: read -i /user/gtiao/37k/germline_cancer_joint_calling.no_restricted.GQ20_AB.split.VEP.vds; [Stage 0:=============================> (1 + 1) / 2]hail: info: running: renamesamples -i file:///xchip/cga_home/gtiao/37k/Hail/germline_cancer_joint_calling.no_restricted.GQ20_AB.split.VEP.sample_id_map.txt; hail: renamesamples: caught exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/xchip/cga_home/gtiao/37k/Hail/germline_cancer_joint_calling.no_restricted.GQ20_AB.split.VEP.sample_id_map.txt at 175616 exp: -1352655701 got: 441984571. ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/347:405,Error,Error,405,https://hail.is,https://github.com/hail-is/hail/issues/347,2,"['Error', 'error']","['Error', 'error']"
Availability,"Comments addressed. You asked about scalars so I've rounded that out with support for any combination of scalar and block matrix, as well as unary + and -, testing in notebook along the way. I've marked the class with experimental.rst until I've stabilized the interface with robust testing of all operations in subsequent broadcasting PR. I fixed the process_joins bug as noted, but stopped there in this PR since just switching to select_entries will end up calling the expression machinery twice. The right solution requires simultaneous changes on the Scala side. I'll make a PR to check if `entry_expr` is a field, if not to use `select_entries` to make it one, and then change `MatrixTable.writeBlockMatrix` to take a field rather than an expression. Sound good?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3072#issuecomment-370569833:276,robust,robust,276,https://hail.is,https://github.com/hail-is/hail/pull/3072#issuecomment-370569833,1,['robust'],['robust']
Availability,Compilation errors,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9648#issuecomment-717421895:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/pull/9648#issuecomment-717421895,1,['error'],['errors']
Availability,Compile results in fatal error: lz4.h: No such file or directory,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4880:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/issues/4880,1,['error'],['error']
Availability,Compiling NativeBoot.cpp fails with error message about -march=sandybridge flag,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4305:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/issues/4305,1,['error'],['error']
Availability,Confirmed that the hailctl bit works:; ```; (base) dking@wm28c-761 hail % hailctl config set http/timeout_in_seconds 1234s; Error: bad value '1234s' for parameter <ConfigVariable.HTTP_TIMEOUT_IN_SECONDS: 'http/timeout_in_seconds'> should be a float or an int like 42.42 ; or 42; (base) dking@wm28c-761 hail % hailctl config set http/timeout_in_seconds 42 ; (base) dking@wm28c-761 hail % hailctl config set http/timeout_in_seconds 42.0; (base) dking@wm28c-761 hail % hailctl config set http/timeout_in_seconds 60 ; (base) dking@wm28c-761 hail % cat ~/.config/hail/config.ini ; [query]; backend = spark; jar_url = gs://hail-query-ger0g/jars/dking/uk4prwgezgva/5fc88d5a4b614454004226f5c77ea72efee1e38f.jar. [batch]; remote_tmpdir = gs://1-day/; billing_project = hail; backend = service. [aiocloudflare]. [global]; domain = hail.is. [gcs_requester_pays]; project = broad-ctsa. [http]; timeout_in_seconds = 60. ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14206#issuecomment-1915030577:124,Error,Error,124,https://hail.is,https://github.com/hail-is/hail/pull/14206#issuecomment-1915030577,1,['Error'],['Error']
Availability,"Confirmed, this failure is not happening on local. . ```sh; (base) alex:~/projects/hail/hail:$ ./gradlew test --tests is.hail.expr.ir.ForwardLetsSuite.testForwardingOps; :checkSettings; check: seed = 1, size = 1000, count = 10; :compileJava UP-TO-DATE; :generateBuildInfo; :nativeLib; c++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home/include/darwin Region.cpp -MG -M -MF build/Region.d -MT build/Region.o; c++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home/include/darwin Hadoop.cpp -MG -M -MF build/Hadoop.d -MT build/Hadoop.o; c++ -o build/Region.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home/include/darwin -MD -MF build/Region.d -MT build/Region.o -c Region.cpp; c++ -o build/Hadoop.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home/include/darwin -MD -MF build/Hadoop.d -MT build/Hadoop.o -c Hadoop.cpp; c++ -fvisibility=default -dynamiclib -Wl,-undefined,dynamic_lookup -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083#issuecomment-492893925:16,failure,failure,16,https://hail.is,https://github.com/hail-is/hail/pull/6083#issuecomment-492893925,1,['failure'],['failure']
Availability,"Connector@1433e9ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-01-22 13:11:22 Utils: INFO: Successfully started service 'SparkUI' on port 4040.; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1fc6c1cc{/jobs,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@75771d8a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@56931c6{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@7d4d6f14{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@23f9d06d{/stages,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5cdf8858{/stages/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3418c91b{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6e2585c5{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2063dbf5{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4035fb2e{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3520067{/storage,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@ca57ac0{/storage/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24ce0621{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5067b2fc{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-22 13:11:22 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5058985f{/environme",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:4922,AVAIL,AVAILABLE,4922,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['AVAIL'],['AVAILABLE']
Availability,"Consider an annotate variants like this:. ```; va.annot.annot = if (isMissing(va.annot.annot.gene) && isDefined(va.annot_MESA.gene)) va.annot_MESA; else if (isMissing(va.annot.annot.gene) && isDefined(va.annot_FinEst.annot.gene)) va.annot_FinEst.annot; else va.annot.annot; ```. If `va.annot_MESA` and `va.annot_FinEst.annot` are not the same the following error arrises, but doesn't give much information as to what went wrong. ```; hail: fatal: annotatevariants expr: expected same-type `then' and `else' clause, got `Struct' and `Struct'; <input>:2: else if (isMissing(va.annot.annot.gene) && isDefined(va.annot_FinEst.annot.gene)) va.annot_FinEst.annot ; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1167:357,error,error,357,https://hail.is,https://github.com/hail-is/hail/issues/1167,1,['error'],['error']
Availability,Consider that `hl.len(mt.AD) == hl.len(mt.alleles)`. We should `die` if this is unsatisfied instead of throw index out of bounds errors when we index into arrays.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5157:129,error,errors,129,https://hail.is,https://github.com/hail-is/hail/issues/5157,1,['error'],['errors']
Availability,"Consider three alleles. ```; GT: 1/2; GQ: 10. 0 | 1000; 1 | 1000 10; 2 | 1000 0 20; +-----------------; 0 1 2; ```. Want to preserve:; - PL(GT) = 0. ### Algorithms. Suppose we remove allele 2. There are two options:; - (_minning_) in the PL array convert occurences of 2 to 0 (""downcode to ref"") and take minimums where there are multiple likelihoods for a single genotype; also downcode GT to ref; - (_subsetting_) subset the PL array (i.e. remove entries with 2's); set GT to the genotype with the minimum likelihood. ### Interpretations. The qualitative interpretation of _minning_ is a belief that the alternate is real but we want to shift the probability mass to 0 (thus changing our interpretation of 0 from ""reference"" to ""reference or something not listed""). The qualitative interpretation of _subsetting_ is a belief that the alternate is not-real and we want to discard any probability mass associated with the alternate. ### Results. The _minning_ algorithm produces. ```; GT: 0/1; GQ: 10. 0 | 20; 1 | 0 10; +-----------; 0 1; ```. The _subsetting_ algorithm produces. ```; GT: 1/1; GQ: 990. 0 | 990; 1 | 990 0; +----------; 0 1; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/551#issuecomment-240823343:278,down,downcode,278,https://hail.is,https://github.com/hail-is/hail/issues/551#issuecomment-240823343,2,['down'],['downcode']
Availability,"Consider, for example, https://ci.hail.is/batches/7490668/jobs/240 and https://cloudlogging.app.goo.gl/BZfqkc6SCM5RfPs79 in which a PR fails because hello does not come alive fast enough. Presumably the 10mCPU is a little limiting.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13123:169,alive,alive,169,https://hail.is,https://github.com/hail-is/hail/pull/13123,1,['alive'],['alive']
Availability,"Consider, for example, this deploy: https://ci.hail.is/batches/7956812. `test-dataproc-37` succeeded but `test-dataproc-38` failed (it timed out b/c the master failed to come online). You can see the error logs for the cluster here: https://cloudlogging.app.goo.gl/t1ux8oqy11Ba2dih7. It states a certain file either did not exist or we did not have permission to access it. [`test_dataproc-37`](https://batch.hail.is/batches/7956812/jobs/193) and [`test_dataproc-38`](https://batch.hail.is/batches/7956812/jobs/194) started around the same time and both uploaded four files into:. gs://hail-30-day/hailctl/dataproc/ci_test_dataproc/0.2.121-7343e9c368dc/. And then set it to public read/write. The public read/write means that permissions are not the issue. Instead, the issue is that there must be some sort of race condition in GCS which means that if you ""patch"" (aka overwrite) an existing file, it is possible that a concurrent reader will see the file as not existing. Unfortunately, I cannot confirm this with audit logs of the writes and read because [public objects do not generate audit logs](https://cloud.google.com/logging/docs/audit#data-access).; > Publicly available resources that have the Identity and Access Management policies [allAuthenticatedUsers](https://cloud.google.com/iam/docs/overview#allauthenticatedusers) or [allUsers](https://cloud.google.com/iam/docs/overview#allusers) don't generate audit logs. Resources that can be accessed without logging into a Google Cloud, Google Workspace, Cloud Identity, or Drive Enterprise account don't generate audit logs. This helps protect end-user identities and information.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13573:200,error,error,200,https://hail.is,https://github.com/hail-is/hail/pull/13573,2,"['avail', 'error']","['available', 'error']"
Availability,Consistent scala.MatchError: ArrayBuffer error while running pipeline on Cray,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1151:41,error,error,41,https://hail.is,https://github.com/hail-is/hail/issues/1151,1,['error'],['error']
Availability,"Context (which however conflates a few different issues): https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/Error.20__C1188collect_distributed_array/near/276162426. Running the `prepare_gnomad_v3_variants` step of the https://github.com/broadinstitute/gnomad-browser pipeline using Hail 0.2.105 results in the following error:. ```; Traceback (most recent call last):; File ""/tmp/bc960dc2a938406794277b1c01c577dd/gnomad_v3_variants.py"", line 53, in <module>; run_pipeline(pipeline); File ""/tmp/bc960dc2a938406794277b1c01c577dd/pyfiles_2z60b0es.zip/data_pipeline/pipeline.py"", line 200, in run_pipeline; File ""/tmp/bc960dc2a938406794277b1c01c577dd/pyfiles_2z60b0es.zip/data_pipeline/pipeline.py"", line 167, in run; File ""/tmp/bc960dc2a938406794277b1c01c577dd/pyfiles_2z60b0es.zip/data_pipeline/pipeline.py"", line 133, in run; File ""<decorator-gen-1066>"", line 2, in write; File ""/opt/conda/default/lib/python3.8/site-packages/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/conda/default/lib/python3.8/site-packages/hail/table.py"", line 1335, in write; Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 105, in execute; raise e.maybe_user_error(ir) from None; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 99, in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); File ""/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py"", line 1304, in __call__; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 31, in deco; raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: IllegalArgumentException: requirement failed: Invalid method, methods may have at most 255 arguments, found 1163; Retu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12533:138,Error,Error,138,https://hail.is,https://github.com/hail-is/hail/issues/12533,2,"['Error', 'error']","['Error', 'error']"
Availability,"Context (which however conflates a few different issues): https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/Error.20__C1188collect_distributed_array/near/276162426. Running the `prepare_gtex_v7_expression_data` step of the https://github.com/broadinstitute/gnomad-browser pipeline using Hail 0.2.105 results in the following error:. ```; Traceback (most recent call last):; File ""/tmp/dc052bbb66544877a73c723ac0a0dc46/genes.py"", line 327, in <module>; run_pipeline(pipeline); File ""/tmp/dc052bbb66544877a73c723ac0a0dc46/pyfiles_h7wv4zl3.zip/data_pipeline/pipeline.py"", line 200, in run_pipeline; File ""/tmp/dc052bbb66544877a73c723ac0a0dc46/pyfiles_h7wv4zl3.zip/data_pipeline/pipeline.py"", line 167, in run; File ""/tmp/dc052bbb66544877a73c723ac0a0dc46/pyfiles_h7wv4zl3.zip/data_pipeline/pipeline.py"", line 132, in run; File ""/tmp/dc052bbb66544877a73c723ac0a0dc46/pyfiles_h7wv4zl3.zip/data_pipeline/data_types/gtex_tissue_expression.py"", line 14, in prepare_gtex_expression_data; File ""<decorator-gen-1060>"", line 2, in export; File ""/opt/conda/default/lib/python3.8/site-packages/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/conda/default/lib/python3.8/site-packages/hail/table.py"", line 1098, in export; Env.backend().execute(; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 105, in execute; raise e.maybe_user_error(ir) from None; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 99, in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); File ""/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py"", line 1304, in __call__; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 31, in deco; raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: MethodTooLargeException: Method too large: __C444collect_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12531:138,Error,Error,138,https://hail.is,https://github.com/hail-is/hail/issues/12531,2,"['Error', 'error']","['Error', 'error']"
Availability,"Context (which however conflates a few different issues): https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/Error.20__C1188collect_distributed_array/near/276162426. Running the `prepare_pext` step of the https://github.com/broadinstitute/gnomad-browser pipeline using Hail 0.2.105 results in the following error:. ```; 2022-12-01 05:56:34.825 Hail: INFO: Loading <StructExpression of type struct{ensg: str, symbol: str, max_pexts: str, Spleen: str, Brain_FrontalCortex_BA9_: str, SmallIntestine_TerminalIleum: str, Artery_Coronary: str, Skin_SunExposed_Lowerleg_: str, Brain_Hippocampus: str, Esophagus_Muscularis: str, Brain_Nucleusaccumbens_basalganglia_: str, Artery_Tibial: str, Brain_Hypothalamus: str, Adipose_Visceral_Omentum_: str, Brain_CerebellarHemisphere: str, Nerve_Tibial: str, Breast_MammaryTissue: str, Liver: str, Skin_NotSunExposed_Suprapubic_: str, AdrenalGland: str, Pancreas: str, Lung: str, Pituitary: str, Muscle_Skeletal: str, Colon_Transverse: str, Artery_Aorta: str, Heart_AtrialAppendage: str, Adipose_Subcutaneous: str, Esophagus_Mucosa: str, Heart_LeftVentricle: str, Brain_Cerebellum: str, Brain_Cortex: str, Thyroid: str, Stomach: str, WholeBlood: str, Brain_Anteriorcingulatecortex_BA24_: str, Brain_Putamen_basalganglia_: str, Brain_Caudate_basalganglia_: str, Colon_Sigmoid: str, Esophagus_GastroesophagealJunction: str, Brain_Amygdala: str, mean_proportion: str}> fields. Counts by type:; str: 42; Traceback (most recent call last): (0 + 1) / 1]; File ""/tmp/22ce8d09e1014663bbe5d8b6f080b286/genes.py"", line 327, in <module>; run_pipeline(pipeline); File ""/tmp/22ce8d09e1014663bbe5d8b6f080b286/pyfiles_zcrmfxsz.zip/data_pipeline/pipeline.py"", line 200, in run_pipeline; File ""/tmp/22ce8d09e1014663bbe5d8b6f080b286/pyfiles_zcrmfxsz.zip/data_pipeline/pipeline.py"", line 167, in run; File ""/tmp/22ce8d09e1014663bbe5d8b6f080b286/pyfiles_zcrmfxsz.zip/data_pipeline/pipeline.py"", line 133, in run; File ""<decorator-gen-1066>"", line 2, in write",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:138,Error,Error,138,https://hail.is,https://github.com/hail-is/hail/issues/12532,2,"['Error', 'error']","['Error', 'error']"
Availability,Control-C to stop this server and shut down all kernels (twice to skip confirmation).; [W 21:29:03.750 NotebookApp] No web browser found: could not locate runnable browser. Dans; [I 21:44:38.439 NotebookApp] Writing notebook server cookie secret to /home/jovyan/.local/share/jupyter/runtime/notebook_cookie_secret; [I 21:44:38.808 NotebookApp] [jupyter_nbextensions_configurator] enabled 0.4.1; [I 21:44:38.898 NotebookApp] Jupyter-Spark enabled!; [I 21:44:38.942 NotebookApp] JupyterLab extension loaded from /opt/conda/lib/python3.6/site-packages/jupyterlab; [I 21:44:38.942 NotebookApp] JupyterLab application directory is /opt/conda/share/jupyter/lab; [I 21:44:38.945 NotebookApp] Serving notebooks from local directory: /home/jovyan; [I 21:44:38.945 NotebookApp] The Jupyter Notebook is running at:; [I 21:44:38.946 NotebookApp] http://(notebook-worker-v7fr4 or 127.0.0.1):8888/instance/notebook-worker-service-sv5jl/?token=...; [I 21:44:38.946 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).; [I 21:44:55.324 NotebookApp] 302 GET /instance/notebook-worker-service-sv5jl/?access_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6Ik16YzNRekpFUXpWRk5VSXdPRE0yTmpJMFF6VkZPVVk1TkRZME9UZzJOa00xUkRBek1ERTJOZyJ9.eyJpc3MiOiJodHRwczovL2hhaWwuYXV0aDAuY29tLyIsInN1YiI6Imdvb2dsZS1vYXV0aDJ8MTEwNzI2NTIxOTIxMjQ5NDQzNzYwIiwiYXVkIjpbImhhaWwiLCJodHRwczovL2hhaWwuYXV0aDAuY29tL3VzZXJpbmZvIl0sImlhdCI6MTU0OTIzMDI2MSwiZXhwIjoxNTQ5MjM3NDYxLCJhenAiOiJURDc4azIzQ2NkTTRwTVdvWVp3WXdLSmJRUEJqMDZqWSIsInNjb3BlIjoib3BlbmlkIHByb2ZpbGUifQ.p3HjkP5t3xrGMGOG8kkCocRCg6BRSrGiO_ymwjqQt-omgk55KnObZCJXFX20BM6n6azzNvF_8EpruB3iSRAFiuhwVvHyabwvRpSZAy3giOpYyxgnj4mPlphdAF9c0yduIU-VpLA6ifaqF9Tj69pfMlFfdjo5ku1tkJnRIkysWYB58bXCqRp9dYSYxZZ45X52YOoP_VrnyyIWX4AvZnp-1Cy9nssFV6l6j2PJmvqkMPLR0suS-lR6NK6PMRRiOessKZy3SXwLJv1oLhJW7qFFEb8kP9pG7zoW0v-TpP9f-XBH0UE9WNaIyur0QOU80qsUa7CmjMdLoi7klDBqdfx-Mg&token=ef8707c52ba1439e9b7ebf78e136075d (10.32.13.94) 0.85ms; alexkotlar:~/projects/hail,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5243#issuecomment-460092942:1871,down,down,1871,https://hail.is,https://github.com/hail-is/hail/pull/5243#issuecomment-460092942,1,['down'],['down']
Availability,"Copied over from the Zulip thread:. Dan and I still have work to figure out the authentication strategy for browser-based REST requests, but as a workaround I've added a tiny aiohttp proxy that uses the python client library to fulfill the requests, which could enable local frontend work while we figure out the right way to do authentication and streaming data through websockets. Implementing the polling and separating it logically from the view components was actually a nice little case study in how to do this in React/Svelte, but is far from an honest or thorough comparison. If you want to run it for yourself, you can pull down the branch in that PR and then do the following (which I'll write dev docs for if this is something that we actually want to check in):. Install node if you do not have it; Run npm install in the $HAIL, $HAIL/js_common, and $HAIL/batch2/react-batch (or svelte-batch) directories; In one terminal in $HAIL/batch2, run python proxy.py; In another terminal in one of the react-batch or svelte-batch directories, run npm run dev; Go to localhost:3000 in your browser if it didn't pop up automatically",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10504:633,down,down,633,https://hail.is,https://github.com/hail-is/hail/pull/10504,1,['down'],['down']
Availability,"Copy pattern from other services: tolerate preemptibles, min 3 replicas, auto-scale up to 10.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7287:34,toler,tolerate,34,https://hail.is,https://github.com/hail-is/hail/pull/7287,1,['toler'],['tolerate']
Availability,"Cotton -- I fixed the changes you suggested and it should be ready to be merged. For the multiarray of size 0, I tested that you can create the object, but using the apply for (0,0) throws an error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/79#issuecomment-161677715:192,error,error,192,https://hail.is,https://github.com/hail-is/hail/pull/79#issuecomment-161677715,1,['error'],['error']
Availability,"Could you give some context on the two different places in the driver we're checking the number of attempts? What are those two places, and why do we need two?. Also, have you done anything to test how much adding joins with the `attempts` table slows down those queries?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14682#issuecomment-2356218496:252,down,down,252,https://hail.is,https://github.com/hail-is/hail/pull/14682#issuecomment-2356218496,1,['down'],['down']
Availability,Could you please fix the error messages? See above.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3234#issuecomment-376664624:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/3234#issuecomment-376664624,1,['error'],['error']
Availability,Couldn't build with sbt after googleFS changes. Couldn't download the proper LZ4 dependency.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8475:57,down,download,57,https://hail.is,https://github.com/hail-is/hail/pull/8475,1,['down'],['download']
Availability,Couldn't reopen #9074. This PR errors if any of the input or output paths have unescaped wildcard characters in them.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9087:31,error,errors,31,https://hail.is,https://github.com/hail-is/hail/pull/9087,1,['error'],['errors']
Availability,"Current Plan:. - input pod; exit 0 if any files exist in /io/; if pod is preempted, delete the pvc and start a new pod. - main pod; init container touches /io/some_file_main; if /io/some_file_main exists, exit 0; If pod is preempted, delete pvc and start a new input pod (rollback). - output pod; init container checks /io/some_file_output; if /io/some_file_output exists, exit 0; touch /io/some_file_output at the end of running the output pod successfully",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6494#issuecomment-506534967:272,rollback,rollback,272,https://hail.is,https://github.com/hail-is/hail/issues/6494#issuecomment-506534967,1,['rollback'],['rollback']
Availability,"Current State; ---. When a commit is merged into a deployable target branch, the [CI deploys that commit](https://github.com/hail-is/hail/blob/master/ci/ci/prs.py#L166-L242). If the deploy job fails, we just [log the failure and change nothing](https://github.com/hail-is/hail/blob/master/ci/ci/prs.py#L295-L313). Since `PRS.latest_deployed` for the given target ref is not changed, the CI will attempt to deploy the latest SHA at the next heal point. We heal periodically, when master changes, when review statuses change, and probably elsewhere. Anywhere we call `PRS.heal_target`. Desired State; ---. Instead, we should track the last successful deploy as well as all the failing deploys since then. This enables us to a) not redeploy a failing deploy and b) find the most recent successful deploy and re-deploy that one. If the most recent successful deploy fails again, we should probably error very loudly. Note that when the CI first comes up there will be no most recent successful deploy. The possible situations are:. - most recent deploy succeeded. - no deploy has ever succeeded. - a deploy has succeeded, but some number of SHAs since then have all failed . Motivation; ---. We want to ensure there is a deployed artifact. For some projects a deploy failure does not leave the universe in a bad state. For example, hail itself updates the latest-hash file after all artifact uploads have succeed. For some projects, a half-way passing deployment will interrupt our users.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4435:217,failure,failure,217,https://hail.is,https://github.com/hail-is/hail/issues/4435,3,"['error', 'failure']","['error', 'failure']"
Availability,"Current State; ---. When a new PR is created or the source SHA for a PR changes, a build is unconditionally started for that SHA merged with the latest target SHA. When the target SHA changes, all PR builds for that target SHA are killed. When a target SHA changes, the CI heals that target. When healing a target, the CI attempts to avoid n^2 unnecessary builds. It achieves this by serializing the build+merge of approved PRs for a given target. When there are no approved PRs, the CI will build every remaining PR with pending/`Buildable` status. If a PR is unapproved and there are a number of approved PRs, it is likely the PR will spend a significant amount of time as ""pending"" as it waits for the approved PRs to be merged. Desired State; ---. The CI should track if a source SHA has ever been tested (success or failure). If the target SHA changes, a build should only be killed if the source SHA has been successfully tested before. If the source SHA changes, a PR build should be killed regardless of whether the old source SHA has been successfully built before.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4438:821,failure,failure,821,https://hail.is,https://github.com/hail-is/hail/issues/4438,1,['failure'],['failure']
Availability,Current behavior is it's testing both D_== and abs(d1 -d2) <= tolerance. Now `absolute=True` specifies use `abs(d1-d2)`. Behavior used to be D_== for everything until I changed it for the BGEN test. So `absolute=True` should only be in the BGEN tests.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3364:62,toler,tolerance,62,https://hail.is,https://github.com/hail-is/hail/pull/3364,1,['toler'],['tolerance']
Availability,"Current master on representative dataset:. ```; [Stage 1:=======================================================> (29 + 1) / 30]hail: info: running: filtervariants intervals -i file:///mnt/lustre/tpoterba/chr1.intervals --keep; hail: info: running: count; [Stage 2:======================================================>(661 + 2) / 663]hail: info: count:; nSamples 5,231; nVariants 76,015; hail: info: timing:; read: 5.760s; filtervariants intervals: 386.191ms; count: 32.617s; total: 38.763s; ```. and new:. ```; [Stage 1:=======================================================> (29 + 1) / 30]hail: info: running: filtervariants intervals -i file:///mnt/lustre/tpoterba/chr1.intervals --keep; hail: info: pruned 0 redundant intervals; hail: info: interval filter loaded 67 of 663 partitions; hail: info: running: count; [Stage 2:=======================================================> (65 + 2) / 67]hail: info: count:; nSamples 5,231; nVariants 76,015; hail: info: timing:; read: 9.911s; filtervariants intervals: 445.193ms; count: 3.356s; total: 13.712s; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1041#issuecomment-257949200:715,redundant,redundant,715,https://hail.is,https://github.com/hail-is/hail/pull/1041#issuecomment-257949200,1,['redundant'],['redundant']
Availability,"Currently if there are duplicated chr:pos:ref:alt in an annotation file, for example read by `annotatevariants table`, also the variants in the vds get duplicated. This is clearly not nice. So instead think on a better behaviour. But do not just issue an error, because otherwise is a pain.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/389:255,error,error,255,https://hail.is,https://github.com/hail-is/hail/issues/389,1,['error'],['error']
Availability,"Currently the binding structure is redundantly specified in two places: Binds.scala, and the parser. We need the binding structure in the parser to propagate the environment, so we can annotate `Ref` nodes (and a few other things) with their types. But we can't use Binds.scala because we don't yet have an IR. This PR removes environment maintenance from the parser by deferring type annotation to a separate pass (which is simple, because it can use the Binds.scala infrastructure). One consequence is that we can't assign types to nodes like `Ref` during parsing, which means we can't ask for the type of any node during parsing, and by extension we can't ask for types of children in IR node constructors. Instead, all typechecking logic is moved to the `TypeCheck` pass. Some benefits of this change:; * The parser is simpler, as it doesn't have to maintain a typing environment.; * Binds.scala is now the single source of truth on the binding structure of the IR.; * Instead of typechecking being split in an ad-hoc way between IR constructors and the `TypeCheck` pass, all typechecking and type error reporting logic is in one place.; * The parser parses a context-free grammar, no more and no less. If the input is gramatically correct, the parser succeeds.; * We can round trip IR with type errors through the text representation. For instance, if we log an IR that fails TypeCheck, we can copy the IR from the log, parse it, then debug. This change was motivated by my work in progress to convert the parser to use the SSA grammar, which this should greatly simplify. I chose to make the type annotation pass after parsing mutate the IR in place (with the unfortunate exception of `Apply`, which can change into an `ApplyIR` or `ApplySpecial`. Do these really need to be separate nodes?). The type of a `Ref` node was already mutable to allow this sort of deferred annotation, and I've had to make a few other things mutable as well. Alternatively we could rebuild the entire IR to include t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13990:35,redundant,redundantly,35,https://hail.is,https://github.com/hail-is/hail/pull/13990,2,"['mainten', 'redundant']","['maintenance', 'redundantly']"
Availability,Currently the linear SKAT routine is implemented to be optimal for the case of (genetic variants) k < n (genetic samples). Implementation will process sets of variants associated to the same gene in such a way that there is no redundant computation in the algorithm. . cases handled:; hard call genetic data; dosage genetic data; k << n - (Cannot explicitly form a matrix containing all the genotype data) . ran on chromosome 22 1kgDataset with approximately 100 intervals and the program runs in about 3-4 minutes with 2 workers and 12 pre-emptibles with 8 cores each.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1973#issuecomment-320358482:227,redundant,redundant,227,https://hail.is,https://github.com/hail-is/hail/pull/1973#issuecomment-320358482,1,['redundant'],['redundant']
Availability,"Currently the` nvidia-container-toolkit` is installed both in the vm startup script and in the worker docker image. The toolkit must be installed in the startup script to be able to configure docker with the command `nvidia-ctk runtime configure --runtime=docker`. This command cannot be run from Dockerfile.worker because it gets the error `""unable to flush config: unable to open /etc/docker/daemon.json for writing: open /etc/docker/daemon.json: no such file or directory""`.; The toolkit also has to be installed in Dockerfile.worker since that is where crun is invoked from. To execute the nvidia hook, the toolkit needs to be installed in that container. We could probably find a workaround to this if you would like but it only increased the worker image from 1.47Gb to 1.55Gb so it seems pretty small.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13430#issuecomment-1710796481:335,error,error,335,https://hail.is,https://github.com/hail-is/hail/pull/13430#issuecomment-1710796481,1,['error'],['error']
Availability,"Currently there are multiple compatible versions of the `CADD` (1.4 and 1.6) and `gnomad_genome_sites` (2.1.1 and 3.1) annotation datasets, which leads to an error in `index_compatible_version`. This PR addresses that by annotating with the highest version number if there are multiple compatible versions of the same dataset. Will likely add fix in future to allow user to specify the version they would like to use, this was just a fairly quick and easy fix in the meantime.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10868:158,error,error,158,https://hail.is,https://github.com/hail-is/hail/pull/10868,1,['error'],['error']
Availability,"Currently there are some tests failures, but they are stemming from me running more tests than I expect to it would seem (i.e. trying to run the NDArray write tests in JVM byte code world). General review of the byt ecode generation stuff would still be appreciated, I'll debug the testing stuff when I get a chance.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6874#issuecomment-521662062:31,failure,failures,31,https://hail.is,https://github.com/hail-is/hail/pull/6874#issuecomment-521662062,1,['failure'],['failures']
Availability,"Currently there is a race condition in which we can shut down the filestore before; the aiohttp app stops accepting connections. If that happens, jobs will get; partially scheduled on the worker, but there will be no working file store so the; jobs cannot complete successfully. The partially scheduled jobs in turn leave the; worker in a bad, non-idle state.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10949:57,down,down,57,https://hail.is,https://github.com/hail-is/hail/pull/10949,1,['down'],['down']
Availability,"Currently, `ggplot` expects a `Table` to be passed in as its data, and errors if passed a `MatrixTable`. With this change, the following code:. ```python; import hail as hl; mt = hl.utils.range_matrix_table(10, 10); mt = mt.annotate_entries(entry_idx = mt.row_idx + mt.col_idx); mt.show(); ```. Which produces a `MatrixTable` that looks like this:. ```; +---------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+; | row_idx | 0.entry_idx | 1.entry_idx | 2.entry_idx | 3.entry_idx | 4.entry_idx | 5.entry_idx | 6.entry_idx | 7.entry_idx |; +---------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+; | int32 | int32 | int32 | int32 | int32 | int32 | int32 | int32 | int32 |; +---------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+; | 0 | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |; | 1 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |; | 2 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |; | 3 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |; | 4 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 |; | 5 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 |; | 6 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 |; | 7 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 |; | 8 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 |; | 9 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |; +---------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+; showing the first 8 of 10 columns; ```. Can be plugged into `ggplot` like so:. ```python; from hail.ggplot import *; fig = ggplot(mt, aes(x=mt.row_idx, y=mt.entry_idx)) + geom_point(); fig.show(); ```. To produce this plot:. <img width=""1512"" alt=""Screen Shot 2022-10-07 at 15 30 50"" src=""https://user-images.githubusercontent.com/84595986/194639655-e88de8fa-2992-4e57-ad06-5f6164dc4d84.png"">. This is accomplished using `Expr._to_table` to transform the `MatrixTable` such that the fields used to generate the plot can be straig",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12293:71,error,errors,71,https://hail.is,https://github.com/hail-is/hail/pull/12293,1,['error'],['errors']
Availability,"Currently, an instance that is `inactive` in batch and `Terminated` per the cloud will enter the second branch and we will call `deactivate`, which since the instance is already inactive will be a no-op. We really want the third branch to be executed in which we call delete on the instance, so that the inactive instances don't hang around forever. Vedant and I paired on this and did some case analysis to restructure the conditions here a little bit. The order of the conditions now doesn't matter and is hopefully more explicit. We also decided that an unspoken case (deleted but not terminated) should be an error scenario, let me know if you think that is an appropriate exception to log here.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11392:613,error,error,613,https://hail.is,https://github.com/hail-is/hail/pull/11392,1,['error'],['error']
Availability,"Currently, attempting to bit shift by zero bits throws an error. ```; $ hl.eval(hl.bit_rshift(4, 0)); HailUserError: Error summary: HailException: cannot shift by a negative value: 4 >> 0; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9843:58,error,error,58,https://hail.is,https://github.com/hail-is/hail/pull/9843,2,"['Error', 'error']","['Error', 'error']"
Availability,"Currently, attempting to start a Dataproc cluster without either a region argument or a configured `dataproc/region` results in a long error message `subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'clusters', 'create', ... ]' returned non-zero exit status 1` with the actual cause obscured above the traceback. That cause is:; ```; Failed to find attribute [region]. The attribute can be set in the following ways:; - provide the argument [--region] on the command line; - set the property [dataproc/region]; ```. There is some logic to show a nicer error message if no region is provided. However, that is only shown if `gcloud config get-value dataproc/region` fails. When `dataproc/region` is not set, that command succeeds and outputs an empty string. This change handles that case and shows the nicer error message.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8791:135,error,error,135,https://hail.is,https://github.com/hail-is/hail/pull/8791,3,['error'],['error']
Availability,"Currently, constructing a `hl.Struct` is slower than I'd like, since it requires copying every field from the input `kwargs` into the `Struct` object's `__dict__`. This PR's main goal was to avoid the need to do that, by just using the input `kwargs` dict we were already saving as `_fields`. . When working on this, I also noticed that we allowed users to mutate fields of a struct, and we didn't do so in a consistent way (`s.a` vs `s[""a""]` could return different answers). I avoid that by throwing an error from now on if a user tries to modify one of the ""main"" fields of the struct (i.e. the ones that are in the `_fields` array).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10968:504,error,error,504,https://hail.is,https://github.com/hail-is/hail/pull/10968,1,['error'],['error']
Availability,"Currently, if the type of the `default` argument to `dict.get` does not match the dictionary's value type, the error message contains the dictionary's type and the `default` argument's type. However, the `default` argument's type should be compared to the dictionary's **value** type. This can be particularly confusing when dealing with nested dictionaries. For example:; ```python; d = hl.dict({""foo"": {""foo"": 1}}); d.get(""somekey"", hl.dict({""bar"": {""bar"": 2}})); ```; results in:; ```; TypeError: 'get' expects parameter 'default' to have the same type as the dictionary ; value type, found 'dict<str, dict<str, int32>>' and 'dict<str, dict<str, int32>>'; ```. This change puts the value type instead of the dictionary type in the error message and slightly rewords the message to be clearer about which type is which.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7377:111,error,error,111,https://hail.is,https://github.com/hail-is/hail/pull/7377,2,['error'],['error']
Availability,"Currently, if we have a file structure like:. a/; b/; aa/; bb/. A glob pattern like `*/b` will raise FileNotFoundError beacuse; we try to list the file or folder named ""b"" inside `aa`. We should; not error. We should return `['a/b']`. It is insufficient to avoid FileNotFoundError altogether because; the Hadoop API treats paths without globs differently. In particular,; listing the path `aa/b` should raise an error. This change fixes behavior in the first case and treats the second; case explicitly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11905:200,error,error,200,https://hail.is,https://github.com/hail-is/hail/pull/11905,2,['error'],['error']
Availability,"Currently, jobs in hail batch can only be run on n1 machines but with the rise of deep learning in bioinformatics, the ability to run jobs on g2 machines, as well as other GPU supported machines, is an important and exciting addition to hail batch. This PR highlights the steps needed to add new machine types into hail batch and could be used as a template for further development support. . The changes in this PR can broadly be divided into additions to the job crun container and insertion of g2 resources (CPU, RAM, L4 Accelerator) into the resources table for billing. This PR uses the NVIDIA Container Toolkit, which allows the creation of GPU accelerated containers. This toolkit is integrated with docker via the parameters runtime=nvidia and the specification of GPUs is made through gpus all. The toolkit is installed in the batch worker VM startup script and the corresponding docker parameters are configured if the machine type is g2, so there is no change to the docker configuration for n1 machines. For the toolkit to work there is a nvidia hook that needs to be injected into the crun config. These modifications are also done based on machine type. On the billing side, the existing pricing setup was expanded to include g2 machines. The g2 instance cores and RAM are inserted into the database, and the SKUs are hard coded. For future machine type incorporation or updates, [https://cloud.google.com/skus/?currency=USD&filter=](https://cloud.google.com/skus/?currency=USD&filter=) may serve as a useful resource to identify relevant SKU ids. A new resource type was also added for the accelerator, including preemptible and non-preemtible. Finally, g2 machines mount the worker data disk under the name nvme0n2 so the code is updated to reflect this. Future work may want to investigate a way to automatically detect what the proper disk name is or make the disk naming logic more robust.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13430:1903,robust,robust,1903,https://hail.is,https://github.com/hail-is/hail/pull/13430,1,['robust'],['robust']
Availability,"Currently, on mobile browsers, the home page of [hail.is](https://hail.is/) is shrunk down to the point where it's difficult to read without zooming in. This adds a [viewport tag](https://developer.mozilla.org/en-US/docs/Mozilla/Mobile/Viewport_meta_tag) to improve that layout. ## Before:. ![before](https://user-images.githubusercontent.com/1156625/59926804-12a60f00-9409-11e9-80c5-52fe4c8ddd66.png). ## After:. ![after](https://user-images.githubusercontent.com/1156625/59926813-16d22c80-9409-11e9-958c-8553ef583be8.png)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6432:86,down,down,86,https://hail.is,https://github.com/hail-is/hail/pull/6432,1,['down'],['down']
Availability,"Currently, tasks to schedule new instances are put on the event loop inside the `Pool` and `JobPrivateInstanceManager` constructors. `Pool.create` and `JobPrivateInstanceManager.create` first instantiate an object of their respective type and then load existing instances from the database into the in-memory instance collection. This could potentially cause the create instances loop to trigger while we're drawing ""existing"" instances, which causes the assertion error in https://github.com/hail-is/hail-tasks/issues/24 when the create instances loop and load instances query race to add the instance to the in-memory data structure. This change moves the task creation from the constructor to the `create` method, so we don't start creating instances until all existing instances are accounted for. I think I would have liked to simply pass the constructor a list of instances, but we can't create an `Instance` without an `InstanceCollection`. Resolves hail-is/hail-tasks#24. I also threw in a bit of cleanup, i.e. removing some variable assignments that didn't seem very helpful and resolving a lint issue where we used `items` where we could just use `values`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11766:465,error,error,465,https://hail.is,https://github.com/hail-is/hail/pull/11766,1,['error'],['error']
Availability,"Currently, the Hail datasets API only has the pan-UKB datasets available via the Amazon S3 bucket. This PR makes the pan-UKB datasets available via GCS as well (from the `gs://ukb-diverse-pops-public` bucket), and updates the summary statistics and meta-analysis MatrixTables to reflect the most up-to-date release.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12073:63,avail,available,63,https://hail.is,https://github.com/hail-is/hail/pull/12073,2,['avail'],['available']
Availability,"Currently, the MJS and MJC requests from the worker to the driver for a given job can race, as they are run as independent asyncio tasks. This results in unnecessary database load and deadlocks between the MJS and MJC SQL procedures. Rather than address the procedures directly, we enforce that we will never run MJS and MJC concurrently. The system is resilient to never receiving an MJS (as MJC will add any attempt data if not present), so we can make the following changes to the worker:; - Serialize the submission of MJS and MJC requests by having the MJC task wait on the MJS future; - Give up retrying MJS once the job has completed because we will instead just send an MJC. This could potentially reduce the database load for very short jobs. I ran a load test of 10k `true` jobs and `sleep 5` jobs a few times against my namespace and saw 0 deadlocks ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11824:353,resilien,resilient,353,https://hail.is,https://github.com/hail-is/hail/pull/11824,1,['resilien'],['resilient']
Availability,"Currently, the `_csrf` cookie is made available to all subdomains of `.hail.is`. This means that if I first visit `batch.hail.is` I get a `_csrf` cookie set for `.hail.is`. That cookie is then reused if I visit `ci.hail.is`. Even more awkward, the same value of the cookie will get reused if I then visit `batch.azure.hail.is`. This isn't that big of a deal, these can all be considered part of the same application that the hail team delivers and secures, but it is very little work to set stricter bounds on where this cookie is sent. By removing the `domain` attribute and using `samesite='strict'`, the cookie's domain will be set by the browser to the domain of the request whose response included the `Set-Cookie` header, e.g. `batch.hail.is` or `internal.hail.is`. `Strict` mode then ensures that the cookie will only be sent to that exact domain, meaning that each application is guaranteed to receive the `_csrf` token that it itself delivered, and a `_csrf` token from CI cannot be used to take actions against Batch. This should not have an adverse impact on existing users' browser sessions. In `render_template` we preserve the value of an existing `_csrf` cookie so this change should do the following:; - Logged in user visits a page with an existing widely scoped (`.hail.is`) `_csrf` cookie; - The server returns a `Set-Cookie` header with a new `_csrf` cookie for strictly the `batch.hail.is` domain but with the same token value as the original `_csrf` cookie; - The user now has two cookies and the browser could send either one on a given request, but it does not matter because they have the same value; - If the user logs out and back in, their old widely scoped cookie will be cleared and they only get the strict cookie from now on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14180:38,avail,available,38,https://hail.is,https://github.com/hail-is/hail/pull/14180,1,['avail'],['available']
Availability,"Currently, the only way to check if Hail can read URLs with a given scheme (`gs`, `s3`, etc) is to attempt to read a URL with that scheme. However, the same exception type is thrown whether the scheme is not supported or the file doesn't exist or something else went wrong and the error message is the only way to determine what went wrong. This adds a `hl.hadoop_scheme_supported` function, which returns a boolean indicating whether or not a URL scheme is supported. Discussed on Zulip: https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/Get.20supported.20URL.20schemes. @johnc1231",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10555:281,error,error,281,https://hail.is,https://github.com/hail-is/hail/pull/10555,1,['error'],['error']
Availability,"Currently, when a QoB worker job fails in a way that prevents it from writing a result file with the error's stack trace in it, the Batch worker that started the job tries to get the result file anyway, and when it fails, raises a 404. This change retrieves the stack trace from the QoB job and raises an error with the stack trace included.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12468:101,error,error,101,https://hail.is,https://github.com/hail-is/hail/pull/12468,2,['error'],['error']
Availability,"Currently, when a job-deletion event arrives on a worker, it removes the job from its running list of jobs and enqueues a future to run that job's deletion/cleanup. If a deletion removes all running jobs from a worker, and the worker does not receive new work, it could potentially idle out and shutdown before the job has finished cleanup in another task. One specific example of where this could go wrong is that worker shutdown can delete the compute client that the job's cleanup step needs to detach/delete a disk. The worker should never shut down while operations are still in progress, so we should only ever remove a job once its deletion has completed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11802:549,down,down,549,https://hail.is,https://github.com/hail-is/hail/pull/11802,1,['down'],['down']
Availability,"Customize export variant- and genotype-level fields.; Upgrade to SorlJ 6, add dependencies.; Support SolrCloud.; Retry on Solr error.; Only insert non-null fields.; Only export called non-ref genotypes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/497:127,error,error,127,https://hail.is,https://github.com/hail-is/hail/pull/497,1,['error'],['error']
Availability,"D$class.takeAsBytes(RVD.scala:243); is.hail.rvd.OrderedRVD.takeAsBytes(OrderedRVD.scala:21); is.hail.rvd.RVD$class.take(RVD.scala:247); is.hail.rvd.OrderedRVD.take(OrderedRVD.scala:21); is.hail.table.Table.take(Table.scala:990); is.hail.table.Table.showString(Table.scala:1031); sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); java.lang.reflect.Method.invoke(Method.java:498); py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); py4j.Gateway.invoke(Gateway.java:280); py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); py4j.commands.CallCommand.execute(CallCommand.java:79); ```. Also under Failed Stages, the Failure Reason was given as:; ```; Job aborted due to stage failure: Task 0 in stage 10.0 failed 20 times, most recent failure: Lost task 0.19 in stage 10.0 (TID 526, ccarey-sw-svrp.c.ukbb-robinson.internal, executor 43): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TBinary$.allocate(TBinary.scala:101); 	at is.hail.annotations.RegionValueBuilder.fixupBinary(RegionValueBuilder.scala:263); 	at is.hail.annotations.RegionValueBuilder.fixupStruct(RegionValueBuilder.scala:319); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:288); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$31$$anonfun$apply$21.apply(Relational.scala:975); 	at is.hail.expr.MatrixMapRows$$anonfun$31$$anonfun$apply$21.apply(Relational.scala:964); 	at scala.collection.Iterator$$anon$11.next(I",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508:7626,failure,failure,7626,https://hail.is,https://github.com/hail-is/hail/issues/3508,1,['failure'],['failure']
Availability,"Dan's OOO this week. It's a Python lint failure:; ```; + cd /io/repo; + make check-hail; make -C hail/python check; make[1]: Entering directory '/io/repo/hail/python'; python3 -m flake8 --config ../../setup.cfg hail; python3 -m flake8 --config ../../setup.cfg hailtop; hailtop/aiogoogle/auth/credentials.py:43:1: W293 blank line contains whitespace; hailtop/aiogoogle/auth/credentials.py:47:5: E303 too many blank lines (2); hailtop/aiogoogle/auth/credentials.py:105:1: E302 expected 2 blank lines, found 1; make[1]: Leaving directory '/io/repo/hail/python'; make[1]: *** [Makefile:12: check] Error 1; make: *** [Makefile:13: check-hail] Error 2; Status; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10647#issuecomment-876439207:40,failure,failure,40,https://hail.is,https://github.com/hail-is/hail/pull/10647#issuecomment-876439207,3,"['Error', 'failure']","['Error', 'failure']"
Availability,"Dan, I went down a rabbit hole with this one. Updated bootstrap (XSS exploit protection, not EOL), jQuery (a bunch of security patches), focused on using flex box for layout, and fixed many of the inconsistencies I found on the docs page (the way the header was laid out, namely lack of element alignment with rest of docs and odd centering, the weirdness of having two home buttons named Hail, Annotation Database didn't scope styles so changed docs nav layout, broken navbar menu, etc).; - Also removes navbar code duplication in docs. Also after speaking with Jackie, restored fixed navbar on docs (so that it stays in place during scrolling). This may cause issues with (especially older) mobile devices, but those probably aren't spending much time on the docs page anyway. Works great on narrow views as well. Since 0.1 doesn't appear to be built, if these changes can affect that will need to be addressed. Before: https://youtu.be/I-Awgx3spnQ; After: https://youtu.be/ff1387vDsQ8. cc @cseed",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6789#issuecomment-522140293:12,down,down,12,https://hail.is,https://github.com/hail-is/hail/pull/6789#issuecomment-522140293,1,['down'],['down']
Availability,"Danfeng was seeing this error trying to unpersist a matrix table:. ```; >>> mt = hl.utils.range_matrix_table(10, 10); >>> mt = mt.persist(); >>> mt = mt.unpersist(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/wang/code/hail/hail/python/hail/matrixtable.py"", line 2896, in unpersist; return Env.backend().unpersist_matrix_table(self); TypeError: unpersist_matrix_table() missing 1 required positional argument: 'storage_level'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5246:24,error,error,24,https://hail.is,https://github.com/hail-is/hail/pull/5246,1,['error'],['error']
Availability,"Dear hail team,. I am trying to get familiar with hail by filtering and doing simple stuff I usually do on VCFs with softwares like bcftools.; I am working with Hail version 0.2.57-582b2e31b8bd; I splitted my VCF from multiallelic to biallelic with:; `data_tmp_bi = hl.split_multi_hts(data_tmp)`; Then I want to update the allele counts the same way as what I saw in your documentation:; `data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info))`; but I get this error:; ```; File ""<ipython-input-29-3595a23add68>"", line 1, in <module>; data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info)). TypeError: struct() got multiple values for keyword argument 'AC'; ```; The workaround I have been using is then to create a new info field called 'AC2', to then drop the 'AC' field and then recreate the 'AC' field with `annotate_rows` with to finally drop 'AC2'. Which is a long workaround:; ```; data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC2=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info)); data_tmp_bi = data_tmp_bi.annotate_rows(info=data_tmp_bi.info.drop('AC')); data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC2, **data_tmp_bi.info)); data_tmp_bi = data_tmp_bi.annotate_rows(info=data_tmp_bi.info.drop('AC2')); ```. On top of this, I filter by column some samples with `filter_cols`, so then, I want to update fields like allele count again, so I would still need to use the same workaround as above, otherwise I get the same error. Do you have an idea of what the problem might be? Or a better way of doing this than what I am using?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9685:532,error,error,532,https://hail.is,https://github.com/hail-is/hail/issues/9685,2,['error'],['error']
Availability,"Dear hail team,. I would like to delete the gcvf information in the matrix table. I run:. mt = mt.transmute_entries(**mt.gvcf_info). **1. error in the hail terminal:** ; 2022-03-24 14:51:45 Hail: ERROR: Analysis exception: 'MatrixTable.transmute_entries': name collision with field indexed by ['row']: 'AS_MQRankSum'; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1132>"", line 2, in transmute_entries; File ""/PATH_OMIT/.local/lib/python3.7/site-packages/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/PATH_OMIT/.local/lib/python3.7/site-packages/hail/matrixtable.py"", line 1952, in transmute_entries; check_annotate_exprs(caller, named_exprs, self._entry_indices, set()); File ""/PATH_OMIT/.local/lib/python3.7/site-packages/hail/utils/misc.py"", line 468, in check_annotate_exprs; check_collisions(caller, list(named_exprs), indices); File ""/PATH_OMIT/.local/lib/python3.7/site-packages/hail/utils/misc.py"", line 363, in check_collisions; raise ExpressionException(msg); hail.expr.expressions.base_expression.ExpressionException: 'MatrixTable.transmute_entries': name collision with field indexed by ['row']: 'AS_MQRankSum'. **2. Details in mt.gcvf_info:**; <StructExpression of type struct{AC: array<int32>, AF: array<float64>, AN: int32, AS_BaseQRankSum: array<float64>, AS_FS: array<float64>, AS_InbreedingCoeff: array<float64>, AS_MQ: array<float64>, AS_MQRankSum: array<float64>, AS_QD: array<float64>, AS_QUALapprox: array<int32>, AS_RAW_BaseQRankSum: str, AS_RAW_MQ: array<float64>, AS_RAW_MQRankSum: array<tuple(float64, int32)>, AS_RAW_ReadPosRankSum: array<tuple(float64, int32)>, AS_ReadPosRankSum: array<float64>, AS_SB_TABLE: array<array<int32>>, AS_SOR: array<float64>, AS_VarDP: array<int32>, BaseQRankSum: float64, ExcessHet: float64, FS: float64, InbreedingCoeff: float64, MQ: float64, MQRankSum: float64, MQ_DP: int32, QD: float64, QUALapprox: int32, RAW_GT_COUNT: array<int32>, RAW_MQ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11660:138,error,error,138,https://hail.is,https://github.com/hail-is/hail/issues/11660,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,Default Mathjax CDN is no longer active. https://www.mathjax.org/cdn-shutting-down/,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2145:78,down,down,78,https://hail.is,https://github.com/hail-is/hail/pull/2145,1,['down'],['down']
